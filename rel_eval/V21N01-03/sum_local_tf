================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[1896] 本稿では，複数の出力ラベル間の依存関係という，従来研究が用いてこなかった手がかりを利用する手法を提案する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[2248] そして，計算機に人間作業者の癖を模倣させることによって，（それが真に良い分類であるかは別として）人間作業者の分類を正解としたときの精度が向上することを期待する．

================================================================
[section type  : proposed_method]
[section title : 問題設定]
================================================================
[1807] [MATH]は図[REF_fig:tree]のように木構造で組織化されているとする．

================================================================
[section type  : proposed_method]
[section title : 提案手法]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : 大域モデル]
-----------------------------------------------------
  [1880] 具体的には，階層的複数ラベル文書分類を構造推定問題とみなし，[MATH]が作る部分木に対してスコアを定義する．
-----------------------------------------------------
  [subsection title : 動的計画法による解探索]
-----------------------------------------------------
  [1968] [MATH]は，[MATH]を根とする部分木の集合から，スコアが最大のものを再帰的に探索する．
-----------------------------------------------------
  [subsection title : ラベル間依存の利用]
-----------------------------------------------------
  [2010] この文書に対して「林業一般」というラベルはそれほど不適切には見えないが，枝分かれ特徴量を持たないモデルは，「林業一般」を付与しない理由を，[MATH]に対応する重みですべて説明しなければならない．
-----------------------------------------------------
  [subsection title : 大域訓練]
-----------------------------------------------------
  [2224] Passive-Aggressiveを採用した理由としては，実装の簡便さ，バッチ学習と異なり，大量の訓練データに容易に対応可能なオンライン学習であること，次節で述べるように並列分散化が容易に実現できることが挙げられる．
-----------------------------------------------------
  [subsection title : 大域訓練の並列分散化]
-----------------------------------------------------
  [1709] しかも，大域訓練はモデルを一枚岩とするため，モデルを局所分類器に分割して並列化することができない．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : データ]
-----------------------------------------------------
  [1508] ただし，いくつかの辺は中間層を飛ばす（例えば，第2層のノードの子が第4層にある場合がある）．
-----------------------------------------------------
  [subsection title : モデル設定]
-----------------------------------------------------
  [2152] [1] \REQUIRE文書[MATH] \ENSUREラベル集合[MATH] \STATE[MATH],  [MATH] \WHILE{[MATH]が空でない} \STATE[MATH] [MATH]の最初の要素を取り出す,  [MATH] \FORALL{ [MATH]の子である[MATH]} \STATE[MATH] \ENDFOR\STATE[MATH] \IF{[MATH]が空} \STATE[MATH],ただし[MATH]は[MATH]の子のなかで一番高いスコア[MATH]を持つ\ENDIF\FORALL{[MATH]} \IF{[MATH]が葉} \STATE[MATH] \ELSE\STATE[MATH]を[MATH]に追加\ENDIF\ENDFOR\ENDWHILE
-----------------------------------------------------
  [subsection title : 評価尺度]
-----------------------------------------------------
  [1763] もう一つは，ラベルを単位とした評価尺度で，通常の適合率，再現率およびF値が用いられる．
-----------------------------------------------------
  [subsection title : 結果]
-----------------------------------------------------
  [2392] このように，より小さなモデルでより高い精度が得られたことは，出力すべき複数ラベルの間にはラベル階層に基づく依存関係があるという我々の仮定を支持するものと考える．
-----------------------------------------------------
  [subsection title : 議論]
-----------------------------------------------------
  [2044] 大域モデルの重み[MATH]自体は，大域訓練(GT)だけでなく，枝刈り型で用いた2値分類器群を連結することによっても構成できる(LT)．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[2292] ラベルの異なり数が大きな場合について，[CITE]は，ラベル集合を低次元の直交座標系に写像し，この空間上で非階層型の分類器を学習する手法を提案している．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[2060] この結果は，人間作業者が複数のラベル候補から出力を選択する際，ラベル階層に基づいて，競合する候補の相対的な重要性を考慮していることを示唆する．

