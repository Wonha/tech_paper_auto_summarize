
評価データとしてJSTPlusを用いる．
JSTPlusは科学技術振興機構が作成している科学技術文献のデータベースである．
各文書は，標題，抄録，著者一覧，ジャーナル名，分類コード一覧や，その他数多くの項目からなる．
文書例を図[REF_fig:jstplus-example]に示す．
実験では，標題と抄録を文書分類に用いるテキストとし，分類コードを付与すべきラベルとみなす．
また，2010年の文献のうち，日本語の標題と日本語の抄録の両方を含むものを実験の対象とした．
その結果，455,311件の文書を得た．
これを409,892件の訓練データと45,419件の評価データに分割した．
ラベル（分類コード）は3,209個からなり，これは4,030個の辺に対応する．
ラベル階層は，根を除いて，最大で5階層となっている．
ただし，いくつかの辺は中間層を飛ばす（例えば，第2層のノードの子が第4層にある場合がある）．
各文書は平均で1.85個のラベルが付与されている（分散は0.85）．
文書ごとの最大ラベル数は9である．
文書の特徴関数[MATH]には以下の2種類の特徴量を用いる．
ジャーナル名．
2値特徴量で，各文書につき1個の特徴量が発火する．
標題と抄録中の内容語．
値は頻度．
ただし，標題中の内容語の頻度は2倍する．
内容語抽出には，形態素解析器JUMANおよび構文解析器KNPを用いた．
まずJUMANによって各文を単語列に分割し，次にKNPが持つ規則を使って内容語にタグ付けした．
各文書は平均で380文字を含んでいた．
これは内容語としては120語に相当する．
大域訓練で訓練された大域モデル(GM-GT)について，枝分かれ特徴量(BF)を用いた場合と用いなかった場合を比較する．
大域モデルの繰り返しパラメータ混ぜ合わせ法については，訓練データを10個の断片に分割し，反復数は[MATH]とする．
枝分かれ特徴量について，[MATH]とする．
その他の比較対象として，従来研究を参考にして以下のモデルを用いる．
非階層型(FLAT)はラベル階層を無視し，各ラベル[MATH]を文書[MATH]に付与すべきか否かを独立に決定する．
そのために各[MATH]に対して2値分類器を用意する．
分類器の実装手法としては，ナイーブベイズ，ロジスティック回帰，サポートベクタマシンなどが用いられてきたが，本稿では，提案手法との比較のためにPassive-Aggressiveアルゴリズム[CITE]を用いる．
ラベル[MATH]に対する2値分類器は重みベクトル[MATH]を持つ．
スコア[MATH]が正のとき，[MATH]を[MATH]に付与する．
ただし，文書に対して最低1個のラベルを付与する．
そのために，いずれのラベルも正のスコアを取らない場合は，一番高いスコアを持つラベルを1個採用する．
[MATH]を訓練するために，元の訓練データ[MATH]を以下のようにして[MATH]に変換する．
各文書はラベル[MATH]を持つとき正例，そうでなければ負例となる．
擬似コードをAlgorithm [REF_alg:pa-binary]に示す．
ここで，パラメータ[MATH]は[MATH]とする．
訓練の反復数は[MATH]とする．
なお，各2値分類器は独立なので，訓練は容易に並列化できる．
[t]   \DeclarePairedDelimiter\norm   \algsetup{indent=1.2em}
[1] \REQUIRE訓練データ[MATH] \ENSURE重みベクトル[MATH] \STATE[MATH] \FOR{[MATH]} \STATE[MATH]をシャッフル\FORALL{[MATH]} \STATE[MATH] \IF{[MATH]} \STATE[MATH] \STATE[MATH] \ENDIF\ENDFOR\ENDFOR
枝刈り型(PRUNE)はラベル階層を利用する手法であり，ラベル階層に対応する2値分類器の集合を持つ[CITE]．
各2値分類器はラベル階層上の辺[MATH]とひも付けされ，重み[MATH]を持つ．
[MATH]は，[MATH]を[MATH]のいずれかの子孫に割り当てるべきであることを表す．
これらの2値分類器も並列に訓練できる．
パラメータ[MATH]の値，訓練の反復数は非階層型と同じとする．
枝刈り型には誤り伝播[CITE]とよばれる問題が知られている．
すなわち，階層上位の分類器による誤りから回復する手段がないため，累積的に誤りが作用する．
誤り伝播を軽減するために様々な手法が提案されているが，煩雑さを避けるため，本稿では，Algorithm [REF_alg:td-search]に示す単純な実装を採用する．
各ノード[MATH]において，局所分類器が正のスコアを返す子すべてを採用する（4--7行目）．
ただし，いずれの子も正のスコアを得ない場合は，一番高いスコアを得た子を1つ採用する（8--10行目）．
この操作を葉に到達するまで繰り返す．
2値分類器の訓練データ[MATH]の構築方法としては，以下の2種類を試す．
全訓練データを利用する[CITE]．
各文書は[MATH]のいずれかの子孫のラベルが割り当てられていれば正例，そうでなければ負例となる．
正例はALLと同じだが，負例を[MATH]の兄弟の子孫が割り当てられている場合に限定する．
こうすることで，全体として小さなモデルが学習される．
なぜなら，数の多い階層下位の分類器に与えられる訓練データが小さくなるからである．
従来研究ではSIBを採用する場合が多い[CITE]．
[t]   \DeclarePairedDelimiter\norm   \algsetup{indent=1.2em}
[1] \REQUIRE文書[MATH] \ENSUREラベル集合[MATH] \STATE[MATH],  [MATH] \WHILE{[MATH]が空でない} \STATE[MATH] [MATH]の最初の要素を取り出す,  [MATH] \FORALL{ [MATH]の子である[MATH]} \STATE[MATH] \ENDFOR\STATE[MATH] \IF{[MATH]が空} \STATE[MATH],ただし[MATH]は[MATH]の子のなかで一番高いスコア[MATH]を持つ\ENDIF\FORALL{[MATH]} \IF{[MATH]が葉} \STATE[MATH] \ELSE\STATE[MATH]を[MATH]に追加\ENDIF\ENDFOR\ENDWHILE
複数ラベル分類に対する評価尺度は数多く存在するが，大きく2種類に整理できる．
1つは，文書を単位とした評価尺度で，しばしば用例ベースの尺度とよばれる[CITE]．
文書単位の尺度として，適合率(EBP)，再現率(EBR)およびF値(EBF)が以下のように定義される．
\mathrm{EBP} = \frac{1}{T} \sum_{i=1}^T \frac{|\mathcal{M}_i \cap\hat{M}_i|}{|\hat{M}_i|}
\mathrm{EBR} = \frac{1}{T} \sum_{i=1}^T \frac{|\mathcal{M}_i \cap\hat{M}_i|}{|\mathcal{M}_i|}
\mathrm{EBF} = \frac{1}{T} \sum_{i=1}^T \frac{2 |\mathcal{M}_i \cap\hat{M}_i|}{|\hat{M}_i| + |\mathcal{M}_i|}
ここで[MATH]はテストデータ中の文書数，[MATH]は[MATH]番目の文書の正解ラベル集合，[MATH]はそれに対応するシステムの出力とする．
もう一つは，ラベルを単位とした評価尺度で，通常の適合率，再現率およびF値が用いられる．
ただし，複数のラベルの集計方法としてマクロ平均とマイクロ平均がある[CITE]．
そのため合計で，LBMaP，LBMaR，LBMaF，LBMiP，LBMiRおよびLBMiFの6種類の尺度を用いる．
最後に階層的な評価も行う[CITE]．
これは，出力ラベルがラベル階層上において正解と近いときに「部分点」を与えるものである．
今回のように循環がない木構造を仮定した場合，適合率(hP)および再現率(hR)は以下のように定義される．
\mathrm{hP} = \frac_{i=1}^T |\mathrm{tree}(\mathcal{M}_i) \cap\mathrm{tree}(\hat{M}_i)| _{i=1}^T |\mathrm{tree}(\hat{M}_i)|
\mathrm{hR} = \frac_{i=1}^T |\mathrm{tree}(\mathcal{M}_i) \cap\mathrm{tree}(\hat{M}_i)| _{i=1}^T |\mathrm{tree}(\mathcal{M}_i)|
F値(hF)はhPとhRの調和平均として定義される．
各種モデルの精度比較を表[REF_tb:experiments-summary]に示す．
枝分かれ特徴量を組み込んだ大域モデル(GM-GT-BF)が7種類の尺度で最高精度を得た．
枝分かれ特徴量なしのモデル(GM-GT)と比較すると，EBP，LBMaR以外の尺度でGM-GT-BFが上回り，すべてのF値を改善した．
この改善は統計的に有意([MATH])であった．
大域モデルを非階層型(FLAT)と比較すると，適合率の改善が著しい一方，再現率に大きな差は見られない．
2種類の枝刈り型(PRUNE)を比較すると，兄弟のみで訓練する場合(SIB)の方が全体的にやや良い精度が得られた．
しかし，多くの尺度で非階層型に敗れており，従来研究の結果を再現する形となっている．
誤り例を見ると，誤って採用したラベル，誤って採用しなかったラベルのいずれも，正解ラベルから離れて人間として改めて判断すると，必ずしも誤りとは言い切れない場合が少なくなかった．
特に，該当文書にとって周辺的な話題を表すラベルをどこまで採用べきかを判断するのが難しかった．
なお，モデル間の分類結果の差分からは，明確な誤り，改善の傾向をつかむのは困難であった．
時間はテストデータの分類に要した時間であり，モデルの読み込み時間は含まない．
予想される通り，枝刈り型が圧倒的に速い．
GM-GT-BFはPRUNE-ALLと比較して約60倍の時間を要した．
しかし，FLATと比較すると，階層を利用するにも関わらず，約18%の増加にとどまっている．
これは，GM-GT-BFのモデルの大きさがFLATよりも約16%小さいことで説明できるかもしれない．
モデルの大きさは重みベクトル中で，絶対値が[MATH]より大きい要素の数とする．
大きさはPRUNE-SIBが最小で，PRUNE-ALLが最大となった．
GM-GT-BFがGM-GTよりも大きさを約9%削減したことは特筆に値する．
訓練に用いたPassive-Aggressiveアルゴリズムには重みを0につぶそうとする仕組みがないことから，大きさが削減された理由は，学習過程でGM-GT-BFがGM-GTよりも予測を誤る回数が少なかったからと考えられる．
このように，より小さなモデルでより高い精度が得られたことは，出力すべき複数ラベルの間にはラベル階層に基づく依存関係があるという我々の仮定を支持するものと考える．
大域モデルの重み[MATH]自体は，大域訓練(GT)だけでなく，枝刈り型で用いた2値分類器群を連結することによっても構成できる(LT)．
大域モデルの性質をさらに調べるために，こうしたモデルとの比較も行った．
表[REF_tb:experiments-dp]に大域モデルの訓練方法の比較結果を示す．
訓練データとしてSIBを用いた場合，極端に多くの候補を出力するようになり，その結果，極端に低い適合率と高い再現率を得た．
SIBという限定されたデータで訓練された局所的な分類器に対して，大域モデルが未知の文書の分類を行わせたため，このような不安定な振る舞いとなった．
一方，訓練データとしてALLを用いた場合，枝刈り型(PRUNE-ALL)から精度を大幅に向上させ，大域訓練とくらべても遜色のない精度が得られた．
モデルの大きさや分類速度において大域訓練に劣りはするものの，大域モデルの最適化を行わずにこのような高精度が得られたことは興味深い．
これは，訓練手法に改善の余地があることを示唆する．
本稿では10並列による繰り返しパラメータ混ぜ合わせ法を用いたが，今後の最適化技術の発展が期待される．
表[REF_tb:experiments-training]に訓練データに対する精度を示す．
訓練データに対しては非階層型(FLAT)が一番高い精度を示し，ALLにより局所訓練された大域モデル(GM-LT-ALL)がそれに続いた．
大域訓練を行った場合(GM-GT-BF)との比較から，局所訓練が過学習をもたらしているとみられる．
また，局所訓練と大域モデルの組み合わせにより，枝刈り型探索が誤りの主要因であることが確認できた．
すなわち，PRUNE-ALLを訓練データに適用したところ，33%の文書について，PRUNE-ALLが出力したラベル集合よりも，正解ラベル集合の方が大域モデルにおいて高いスコアを持っていた．
言い換えると，正しく探索を行えば犯さない誤りであった．
ただし，この高い数値には過学習の影響も含まれており，同じ操作をテストデータに適用した場合は，割合は14%に下がった．
より詳細にモデルを調べるために，辺に分解した結果を示す．
図[REF_fig:size-score-comp]はGT-BF，LT-ALL，LT-SIBの比較である．
図(a)から(c)は辺に対応する局所ベクトルの大きさを示す．
ここで，大きさの定義は表[REF_tb:experiments-summary]と同じである．
辺を子の階層によって集約し，大きさを平均した結果を示す．
一般に，上位階層ほど多数の有効な重みベクトルが必要となることが確認できる．
GT-BFはLT-ALLよりも大きさが小さいが，辺ごとの大きさの比率は似通っている．
LT-SIBと比較すると，GT-BFは上位階層では小さいが，下位階層では大きな有効重みベクトルを持つ．
LT-SIBでは兄弟からの識別のみを考慮していたが，大域学習ではすべての辺が適切なスコアを返す必要があるため，有効重みベクトルがより大きくなったとみられる．
図(d)から(f)は，各辺が得たスコアの絶対値の平均を表す．
ここで，スコアは，テストデータに対するモデル出力から計算されたものである．
これにより，どの階層の辺が強くモデル出力に影響しているかが推測できる．
この結果から，上位階層ほど大きな影響を持つことがわかる．
しかし，GT-BFは他とくらべて上位階層の影響が小さい．
すなわち，GT-BFにおいては下位階層の辺が相対的に重要な役割を果たしている．
枝分かれ特徴量に対応する重みを図[REF_fig:br-heatmap]にヒートマップとして示す．
各要素の値は，親ノードに与えられた重み（ノードごとの重みと共有された重みの和）を平均したものである．
平均化された値はすべて負となり，子の数が増えるにつれてペナルティが単調増加した．
異なる階層間の重みの比較は，それらが重みベクトルの他の部分の値に依存するため難しい．
しかし，下位ノードほど子の数に応じた重みの落差が大きいという結果は，階層上近いラベル候補同士ほど強い競合関係にあるという我々の仮説を支持しているようにみえる．
最後に，訓練データおよび評価データの正解ラベルについて，正解ラベルを被覆する最小の部分木を作り，親が採用する子の数を調べた．
採用した子の数が複数である割合は，根で34.9%，第1層で10.1%，第2層で4.6%，第3層で1.5%，第4層で0.6%であり，下位ノードほど強い競合関係にあることが確認できた．
