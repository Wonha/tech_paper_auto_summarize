#!/usr/bin/perl
use strict;
use warnings;
use diagnostics;
use MeCab;
use utf8;
use feature "switch";
use Encode;

binmode(STDOUT, ":utf8"); 

my @a_pth_src_dir = glob "./logs/V03*";
@a_pth_src_dir = grep { -d } @a_pth_src_dir;

my %h_fn_sumz_for = (
		intro						=>	"sum_intro_tfidf",
		related_study		=>	"sum_rels_tfidf",
		proposed_method	=>	"sum_prom_tfidf",
		experiment			=>	"sum_expr_tfidf",
		conclusion			=>	"sum_conc_tfidf",
);

for my $pth_src_dir (@a_pth_src_dir) {
	opendir my $fh_src_dir, $pth_src_dir or die "Cannot open $pth_src_dir: $!";
	print "$pth_src_dir\n";	

	for ( readdir $fh_src_dir ) {
		when ( "intro" ) { 
			print "	intro\n";	
			tf_idf( {
					path_src_dir => $pth_src_dir,
					sec_name => "intro",
					sum_result => "sum_intro_tfidf",
					} );

		}	when ( "related_study" ) {
			print "	related_study\n";
			tf_idf( {
					path_src_dir => $pth_src_dir,
					sec_name => "related_study",
					sum_result => "sum_rel_tfidf",
					} );

		} when ( "proposed_method" ) {
			print "	proposed_method\n";
			tf_idf( {
					path_src_dir => $pth_src_dir,
					sec_name => "proposed_method",
					sum_result => "sum_porp_tfidf",
					} );

		} when ( "experiment" )	{
			print "	experiment\n";
			tf_idf( {
					path_src_dir => $pth_src_dir,
					sec_name => "experiment",
					sum_result => "sum_expr_tfidf",
					} );
			
		} when ( "conclusion" ) {
			print "	conclusion\n";
			tf_idf( {
					path_src_dir => $pth_src_dir,
					sec_name => "conclusion",
					sum_result => "sum_conc_tfidf",
					} );
			
		} default { "								bypass $_\n"}
	}
	print "\n";
}
print "processed over ".scalar @a_pth_src_dir." dirctories\n";

sub tf_idf {
	my $hr_arg = shift;

### read section files' contents
	my @a_line;

	my $pth_section = $hr_arg->{path_src_dir}.'/'.$hr_arg->{sec_name};
	open my $fh_sec, '<:encoding(UTF-8)', $pth_section or die "Cannot open $pth_section: $!";
	my $lines = join '', <$fh_sec>; # need to discard new-line. my $lines = join '', chomp <$fh_sec>;  
	@a_line = split /\.|\．/,$lines; # this line discard '.' or '. '. so, @a_line = $lines =~ /(.*)(?:.|．)/s would be better choice.
	close $fh_sec;

### read tf_idf_weight file in src dir
	my %h_tfidf_score_for;

	my $pth_tfidf = $hr_arg->{path_src_dir}.'/'.'tf_idf_weight';
	open my $fh_tfidf, '<:encoding(UTF-8)', $pth_tfidf or die "Cannot open $pth_tfidf: $!";
	while (<$fh_tfidf>) {
		next if ( $_ eq '');
		chomp;
		%h_tfidf_score_for = /(\w+) : (\w+)/g;
	}
	close $fh_tfidf;

### mecab each line, get sent score
	my @a_score;
	
	for my $idx (0..$#a_line) {
		my @a_word;
		my $model = new MeCab::Model( '' );
		my $c = $model->createTagger();
		for (my $m = $c->parseToNode($a_line[$idx]); $m; $m = $m->{next}) {
			my $term = $m->{surface};
			$term = decode('utf8', $term);
			push @a_word, $term if ( $term =~ /^\w+$/u );
		}
		$a_score[$idx] += $h_tfidf_score_for{$_} for (@a_word);
	}

### get the highest scored sentence
	my $top_score_line_idx = 0;

	for my $idx (1..$#a_line) {
		 $top_score_line_idx = $idx if ( $a_score[$idx] > $top_score_line_idx );
	}

### output top score sent
	my $pth_out = $hr_arg->{path_src_dir}.'/'.$hr_arg->{sum_result};
	open my $fh_out, '>:encoding(UTF-8)', $pth_out or die "Cannot open $pth_out: $!";
	print $fh_out $a_line[$top_score_line_idx];
	close $fh_out;
}

sub write {
}
#
#
#
##	1. by_score subroutine apply
## 2. calculate score from entire document.
## 3. stop word.
#
## open directory  './logs'
#my $path_logs = './logs';
#opendir my $dh, $path_logs || die "Cannot open $path_logs: $!";
#
## traverse inside of './logs'
#for my $dir_ent (sort readdir $dh) {
#	next if (-d $dir_ent) or $dir_ent eq '.' or $dir_ent eq '..';
#	
#	# put current directory entry into path
#	my $path_src_dir = $path_logs."/".$dir_ent;
#	
#	# set name of input and output file.
#	my $name_input = "/intro";
#	my $name_output = "/sum_intro";
#	
#	{	
#		# set	path of input file and read from input file
#		my $path_src = $path_src_dir.$name_input;
#		open my $fh, "<:encoding(UTF-8)", $path_src || die "Cannot open $path_src: $!";
#		my $contents_src = join '',<$fh>;
#		close $fh;
#
#		#	train term frequency from '$intro_contents' and save score in '%term_score'.
#		my $model = new MeCab::Model( '' );
#		my $c = $model->createTagger();
#		my %term_score;
#		for (my $m = $c->parseToNode($contents_src); $m; $m = $m->{next}) {
#			$term_score{$m->{surface}}++;
#		}
#
#		# calculate sentence score.
#		my @sents_src = split /\.|\．/u, $contents_src;
#		my %sent_score;
#		for my $sent (@sents_src) {
#			my $score = 0;
#			for (my $m = $c->parseToNode($sent); $m; $m = $m->{next}) {
#				$score += $term_score{$m->{surface}};
#			}
#			$sent_score{$sent} = $score;
#		}
#
##sort by_score keys %sent_score
#		# get top score sentence.
#		my @sent_keys = keys %sent_score;
#		my $top_sent = $sent_keys[0];
#		for my $idx (1..$#sent_keys) {
#			if ( $sent_score{$top_sent} < $sent_score{$sent_keys[$idx]}) {
#				$top_sent = $sent_keys[$idx];
#			}
#		}
#
#		
#		# set output file and open output file
#		my $path_out = $path_src_dir.$name_output;
#		open my $fh_sum, ">", $path_out || die "Cannot open $path_out: $!";
#		print $fh_sum "$top_sent";
#		close $fh_sum;
#		print <<"END";
#
#		************     $path_src     ************
#
#$top_sent
#
#score is : $sent_score{$top_sent}
#END
#	}
#
#}
#
#closedir $dh;
#
#
##sub by_score {
##	$sent_score{$b} <=> $sent_score{$a};
##}
