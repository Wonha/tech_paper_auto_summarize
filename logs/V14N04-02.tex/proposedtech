    \documentclass[japanese]{jnlp_1.3e}
\usepackage{jnlpbbl_1.1}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}

\Volume{14}
\Number{4}
\Month{July}
\Year{2007}
\received{2006}{6}{23}
\revised{2006}{8}{18}
\accepted{2007}{1}{23}

\setcounter{page}{23}

\jtitle{日英特許コーパスからの専門用語対訳辞書の自動獲得}
\jauthor{下畑さより\affiref{Author_1} \and 井佐原　均\affiref{Author_2}\affiref{Author_3}}
\jabstract{
本論文では，日英特許コーパスを用いて専門用語の対訳辞書を作成する方法について述べる．提案手法は，言語単位としての妥当性と分野による出現の偏りを数値化することで，コーパス中の単語（列）を専門用語として抽出し，和英辞書などの既知の対訳用語セット（seed word リスト）を介して，コーパスにおける各専門用語の共起パターンを計測し，その類似性が高い用語ペアを対訳として対応付ける．この時，対象となるコーパス間で文脈が類似している対訳のみをseed wordに利用する点が特徴である．本手法を日本語特許抄録とその英訳に適用したところ，専門用語の抽出精度は日本語で90\%，英語で93\%となった．また，訳語対応付けでは，各専門用語の対訳として1位に対応付けられた対訳候補の正解率が53\%（日英）と66\%（英日），10位以内に対応付けられた対訳候補の正解率が83\%（日英）と90\%（英日）と，従来研究と比べて高い精度を得ることができた．本論文ではさらに，PAJの日本語抄録と米国特許抄録を用いた実験を行い，コーパスの違いによる実験結果の違いについても考察する．
}
\jkeywords{機械翻訳，専門用語，辞書，特許}

\etitle{ Retrieving Translation Candidates from Patent Corpora }
\eauthor{Sayori Shimohata\affiref{Author_1} \and Hitoshi Isahara\affiref{Author_2}\affiref{Author_3}} 
\eabstract{
This paper describes a method for retrieving technical terms and finding their translations from bilingual patent corpora. The method extracts terms from each monolingual corpus and finds their translations by using a list of bilingual word pairs called ``seed words''. In the term extraction process, we quantify the unithood and termhood of word sequences to determine if they are technical terms. In the translation alignment process, we select seed words whose contexts are similar in the target corpora. We conducted experiments in term extraction and translation alignment with patent abstracts of Japan and the United States. In the term extraction, the proposed method has achieved a precision of 90\% for Japanese term extraction and 93\% for English term extraction. In the translation alignment, the accuracy was 53\% (Japanese to English) and 66\% (English to Japanese) for the top candidates and 83\% (J to E) and 90\% (E to J) for the top 10 candidates. Comparison of the results between parallel corpora and comparable corpora is also described.
}
\ekeywords{Machine translation, Technical terms, Dictionary, Patent }

\headauthor{下畑，井佐原}
\headtitle{日英特許コーパスからの専門用語対訳辞書の自動獲得}

\affilabel{Author_1}{沖電気工業株式会社ユビキタスサービスプラットフォームカンパニー}{Ubiquitous Service Platform Company, Oki Electric Industry Co., Ltd.}
\affilabel{Author_2}{独立行政法人情報通信研究機構情報通信部門けいはんな情報通信融合研究センター自然言語グループ}{National Institute of Information and Communications Technology}
\affilabel{Author_3}{神戸大学大学院自然科学研究科}{Kobe University Graduate School of Science and Technology}


\begin{document}
\maketitle

\section{コーパスを利用した対訳辞書構築の要素技術}

コーパスから専門用語の対訳辞書を構築するには，2つのフェーズがある．第1フェーズは単言語コーパスから専門用語を抽出するフェーズ，第2フェーズは抽出された2言語の専門用語を対応付けるフェーズである．以下では，それぞれのフェーズについて，従来技術を説明する．

\subsection{専門用語の抽出}

コーパスから専門用語を抽出する場合には，コーパス中に出現する用語候補を切り出し，その用語候補の言語単位としての妥当性（ユニット性）と分野における専門性（ターム性）を測定して専門用語と認められるかどうかを判定する方法が一般的である．用語候補は，基本的に単語 N-gram である\footnote{日本語や中国語のように単語境界のない言語では，文字N-gramを用いる場合もある．}．ただし，単語N-gramを単純に頻度順に抽出するだけでは断片的な単語列が多数含まれるので，いかにユニット性とターム性を計測し，不要な単語列を抑制するかが重要になる．

\cite{Shimohata97} は，隣接する単語のばらつきの度合いによって単語列のユニット性を測る手法を提案した．\cite{Ananiadou94}， \cite{Frantzi_and_Ananiadou99}は入れ子構造を持つコロケーションからユニット性の高い要素に高いスコアをつけるC-valueと呼ばれる手法を提案している．また，\cite{Nakagawa03}は，名詞のbigramから得られる統計量を利用して，複合名詞のスコア付けを行なう方法を提案している．その他にも，形態素解析や構文解析を行って，特定の構成要素をもつ単語列（例えば名詞句）を抽出するという方法が考えられる．いずれの手法においても，専門用語としての妥当性を数値化することは難しく，専門用語の抽出は各手法の指標に基づいてスコア付けした用語候補から，対象となるコーパスの量や獲得語数の条件などに応じて行うのが一般的である．また，\cite{Ananiadou94}，\cite{Frantzi_and_Ananiadou99}， \cite{Nakagawa03}の手法では，複合語，特に複合名詞を対象としており，名詞以外の語句や1語からなる専門用語の抽出は行わない．

\subsection{専門用語の訳語推定}

2言語のコーパスから対訳辞書を抽出する研究は，大きく2つに分類される．1つは，パラレルコーパスを用いる方法，もう1つはコンパラブルコーパスを用いる方法である\footnote{ここでパラレルコーパスとは文単位で対応づけられた対訳テキストの集合を，コンパラブルコーパスとは文書単位で内容が類似した対訳テキストの集合を指す．}．パラレルコーパスを用いる方法では，基本的に1対1の文対応を前提にしており，対応する行における単語および単語列の同時出現確率の対数尤度を利用する．2言語間で候補語どうしの同時出現確率を計算し，その値が高いものを翻訳対として抽出する方法が一般的に行われている(\cite{Kupiec93}; \cite{Dagan_and_Church94}; \cite{Smadja93};  \cite{Kitamura_and_Matsumoto04}) ．これらの方法では，80\%〜90\%の高い精度を達成しているが，1対1の文対応がついたコーパスは非常に少なく，現実には類似度の高いコーパスに段落対段落レベルの粗い対応付けを利用したり，文対応付け手法(\cite{Gale_and_Church93}; \cite{Utiyama_and_Isahara03})を用いて擬似的に文対応をつけたりする処理が必要である．

それに対して，コンパラブルコーパスは比較的容易に入手可能である．コンパラブルコーパスの場合には，パラレルコーパスのように単語の同時出現確率を直接測ることができないので，既知の単語対を介して，対象とする2言語の候補語における共起語ベクトルの類似度を計算し，類似度の高い用語対を対訳として抽出する (\cite{Fung_and_McKeown97}; \cite{Fung_and_Yee98}; \cite{Rapp99})．

\cite{Rapp99}は，2言語のテキストで出現する単語の共起マトリックスを作成し，その類似度を最大化する方法を提案した．英独の基本的な語による実験では，訳語候補を辞書登録語に限定し，1位正解率72\%，10位以内正解率89\%を得ている．また，\cite{Fung_and_McKeown97} は，既に対応づけられた対訳語（seed word と呼ぶ）のリストを用いて，各言語における未知語とseed word list の単語とのコーパス中での共起を調べ，その共起ベクトルの類似度を測って，類似度の高い単語ペアを対訳語として抽出する方法を提案した．日英経済紙による実験では，訳語候補の1位正解率約30\%，20位以内正解率76\%を得ている．また，\cite{Fung_and_Yee98} では，seed word に重みづけをすることで \cite{Fung_and_McKeown97} の対応付け精度を改良している．

さらに最近では，Webから得られた文書を用いて訳語推定を行なう研究も提案されている(\cite{Utsuro05}\cite{Cao_and_Li02})．\cite{Utsuro05}は言語横断検索によって対応付けられた日英関連記事からパラレルコーパスの手法，および，コンパラブルコーパスの手法によって訳語対応を推定している．また，\cite{Cao_and_Li02}では基本語対訳時書中の訳語の組み合わせを訳語候補としてWebを検索し，訳語対応を推定している．

コンパラブルコーパスを用いる手法は，パラレルコーパスを用いる手法に比べて訳語推定の精度が低い．また実験も小規模で，実用化を想定した設定になっていないことが多い．精度が低い原因は対象となるコーパスの性質によるものが大きいが，類似度を測るベクトルの要素が，用語の文脈を特徴付けられていないことも重要な問題である．
本論文では，特許文書を対象に，コンパラブルコーパスの手法を用いて専門用語の対訳を抽出する．特許文書は文が長く，多数の専門用語が含まれているという特徴がある．この特徴を利用して，両言語コーパスに頻出し，かつ，その出現傾向が類似する専門用語をseed wordとすることにより，コンパラブルコーパスにおける語訳対応付けの精度向上を目指す．

コンパラブルコーパスの手法を採用する理由は，柔軟性が高く，あらゆる対応度の対訳コーパスに適用可能だからである．特許文書は，PAJのようにほぼ1対1の対訳があるものから，国内出願と外国出願した特許のように文書単位の対訳があるもの，単言語でしか存在しないものまで様々である\footnote{PAJは，基本的にはアブストラクト単位の対訳であるが，文レベルで対応しているものも多い．構成文数を見ると，遺伝子分野のPAJ1年分11,781件中，両言語で文数が一致しているものは4,608件 (39.1\%), 一致していないものが7,173件 (60.9\%) であった．}．対応度の高い対訳コーパスについては，文対応付け手法によって擬似的にパラレルコーパスを作成し，パラレルコーパスの手法を適用することも可能であるが，PAJ以外の特許文書については文レベルの対応をとることは現実的ではない．それに対して，コンパラブルコーパスの手法は，文対応を考慮しなければパラレルコーパスに対しても適用することが可能である．

以下，第3章では提案手法の詳細について説明し，第4章以降では提案手法に基づいて行なった実験の結果について報告する．さらに，提案手法とパラレルコーパスを用いる手法や他のコンパラブルコーパスを用いる手法との比較も行なう．


\section{アルゴリズム}

本論文の専門用語およびその対訳の獲得プロセスを図1に示す．本手法は，1．専門用語の抽出，2．seed word リストの作成，3．seed word を用いた専門用語の訳語推定という3つのステップから構成される．第1のステップでは，日英特許コーパスより専門用語を抽出し，第2のステップでは，日英特許コーパスと対訳辞書を使ってseed word リストを作成する．そして第3のステップでは，抽出された専門用語とseed wordリストとの共起ベクトルを求め，共起ベクトルの類似度の高い用語どうしを対訳として抽出する．以下では，それぞれのステップについて順に説明していく．
\begin{figure}[t]
\label{fig:outline}
\begin{center}
    \includegraphics{14-4ia2f1.eps}
\caption{専門用語および対訳獲得のプロセス}
\end{center}
\end{figure}

\subsection{専門用語の抽出}\label{sec:extractTerm}

専門用語候補の抽出には，隣接文字（単語）の分散の度合いに基づく専門用語抽出手法\cite{Shimohata97}を用いる．この手法は，「文字列（単語列）が意味のあるまとまりである場合，その前後には様々な文字（単語）が出現する」という考えに基づき，隣接文字の分散の度合いによって単語列のユニット性を測るものである．ただし，この手法では単語列の専門性の高さは考慮していないので，上記手法による抽出結果の頻度および$\mathit{tf} \bullet \mathit{idf}$を求め，各単語列のターム性を計測する．具体的な手順は以下の通りである．

\begin{enumerate}
\item コーパスを形態素解析し，句読点を含まない，単語列の最初と最後が自立語であるなどの条件の下で，n-gram 単語列$T_{l} = \{t_{1}, t_{2},...t_{n} \}$を抽出する．
\item $t_{i}$の前に出現する単語群$W^{i}_{L} = \{w^{i}_{1}, w^{i}_{2},…w^{i}_{m}\}$から，$t_{i}$の前に出現する単語のばらつきの度合$H(t_{i},W^{i}_{L})$を求める．ここで，$\mathit{freq}(t_{i})$は単語列$t_{i}$の出現する回数，$\mathit{freq}(t_{i},w^{i}_{j})$は単語列$t_{i}$と単語$w^{i}_{j}$が連続して出現する回数である．
\begin{gather}
 H(t_{i},W^{i}_{L}) = - \sum^{m}_{j=1} P(t_{i},w^{i}_{j}) \bullet \log P(t_{i},w^{i}_{j}) \\
 P(t_{i},w^{i}_{j}) = \frac{ \mathit{freq}(t_{i},w^{i}_{j}) }{ \mathit{freq}(t_{i}) }
\end{gather}

\item  (2)と同様に，$t_{i}$の後ろに出現する単語群$W^{i}_{R} =\{w^{i}_{1}, w^{i}_{2},…w^{i}_{m}\} $から，$t_{i}$の後ろに出現する単語のばらつきの度合$H(t_{i},W^{i}_{R})$を求める．

\item $\mathit{tf} \bullet \mathit{idf}(t_{i})$によって$t_{i}$のターム性を求める．
\begin{gather}
\mathit{tf} \bullet \mathit{idf}(t_{i}) = \mathit{freq}(t_{i}) \bullet \log ( \frac{N}{\mathit{df}(t_{i})}) \\
N = 全文書数 \nonumber \\
\mathit{df}(t_{i})=t_{i}が出現する文書数 \nonumber
\end{gather}

\item (2)〜(4)で得られた$H(t_{i},W^{i}_{L})$，$H(t_{i},W^{i}_{R})$，$tf \bullet \mathit{idf}(t_{i})$，および，$\mathit{freq}(t_{i})$が，
それぞれ，閾値$\mathit{varMin}$，$\mathit{tfidfMin}$，$\mathit{freqMin}$を超える単語列$t_{i}$を専門用語として抽出する．
\pagebreak
\begin{gather*}
 H(t_{i},W^{i}_{L}) \geq \mathit{varMin} \\
 H(t_{i},W^{i}_{R}) \geq \mathit{varMin} \\
 \mathit{tf} \bullet \mathit{idf}(t_{i}) \geq \mathit{tfidfMin} \\
 \mathit{freq}(t_{i}) \geq \mathit{freqMin} 
\end{gather*}

\end{enumerate}

\subsection{seed word リストの作成}\label{sec-SeedWord}

\cite{Fung_and_McKeown97}では，「文書Tにおいて用語Aと用語Bの関連度が高い場合，別の言語の文書T$'$において用語Aの訳語であるA$'$と用語Bの訳語であるB$'$も関連度が高い」という仮説に基づき，seed word リストと呼ばれる既知の翻訳対と，対応付け候補の各用語との対象コーパスにおける関連度を測り，関連度の高い用語どうしを対応付けている．ここで，用語の関連度とは，一定の範囲内（例えば，文，パラグラフなど）における出現文脈の類似度である．つまり，単言語コーパス内でのseed word リストの単語と用語との共起を調べ，2言語間で各用語の共起パターンの類似度を測って，類似度の高いものを翻訳対として抽出する．seed wordには，対象コーパスに一定回数以上出現する辞書登録語で，かつ一対一に対応のつく翻訳対を用いている．

提案手法も上記の手法を踏襲するが， seed word 獲得時にも翻訳対獲得時と同様にseed word候補語どうしの共起を調べ，出現文脈が類似している翻訳対のみを seed word として採用する．つまり，対象コーパスにおいて有効な seed word のみを利用することにより，候補語の対応付けにおける精度の向上を計る．

具体的な，seed wordリスト作成プロセスは以下の通りである．

\begin{enumerate}
\item 言語$J$と$E$の対訳辞書$D_{\mathit{JE}}$より，コーパス$C_{J}$および$C_{E}$に出現頻度の閾値$\mathit{freqMin}$を超えて出現する辞書登録語の集合$D_{\mathit{JE}}=\{ \langle d^{J}_{i},d^{E}_{i} | \mathit{freq}(d^{J}_{i}) \geq \mathit{fregMin} ; \mathit{freq}(d^{E}_{i}) \geq \mathit{freqMin} \rangle \}$を抽出する．ここで$C_{L}$は言語$L$のコーパスを，$d^{L_{1 }}_{i}$は$D_{L_{1},L_{2}}$における言語$L_{1}$の$i$番目の単語を表す．また，$d^{L2}_{i}$は$d^{L1}_{i}$と対訳関係にある言語$L_{2}$の単語である．
\item 言語$L$の$i$番目の単語$d^{L}_{i}$に対して，$d^{L}_{i}$と$\{ d^{L}_{1},d^{L}_{2},...d^{L}_{n} \}$との，コーパスにおける一定の範囲内（例えば，一定語数内，一文内，パラグラフ内など）での共起頻度の列ベクトル$\mathit{Cmat}(d^{L}_{i} \equiv [ c(d^{L}_{i},d^{L}_{1}),c(d^{L}_{i},d^{L}_{2}),...c(d^{L}_{i},d^{L}_{n}) ]^{T})$を求める．$c(x,y)$は，単語$x$と単語$y$の共起回数である．
\item  対訳関係にある$d^{J}_{i}$と$d^{E}_{i}$の共起ベクトルの類似度$\mathit{Sim}(d^{J}_{i},d^{E}_{i})$を求め，類似度が閾値を超えるデータの対をseed wordリスト$SW_{\mathit{JE}}$として抽出する．ここで，
\[ \mathit{SW}_{\mathit{JE}} = \{ \langle d_{J},d_{E} \rangle | \mathit{Sim}(d^{J}_{i},d^{E}_{i}) \geq \mathit{simMin} \} \] とし，
類似度$\mathit{Sim}(d^{J}_{i},d^{E}_{i})$は，以下の式によって得る．
\pagebreak
\begin{equation}
\mathit{Sim}(d^{J}_{i},d^{E}_{i}) = \sqrt{ \sum_{1 \leq j \leq n} (\frac{c(d^{J}_{i},d^{J}_{j})}{C_{J}の総文数} - \frac{c(d^{E}_{i},d^{E}_{j})}{C_{E}の総文数})^2 }
\end{equation}

\end{enumerate}

\subsection{専門用語の訳語推定}

訳語対応づけは，\ref{sec-SeedWord}で述べた seed word 作成と同様のプロセスによって行なう．

\begin{enumerate}
\item 両言語のコーパスから抽出された専門用語の集合$T_{J}$および$T_{E}$の各用語$t^{L}_{i}$と，seed wordリスト$\mathit{SW}_{\mathit{JE}}$の各要素$d^{L}_{k}$との各コーパスにおける共起頻度を計数し，共起ベクトル$\mathit{Cmat}(t^{L}_{i})$を作成する．
\item $T_{J}$と$T_{E}$のすべての用語の組み合わせにおける共起マトリクスの類似度$\mathit{Sim}(t^{J}_{i},t^{E}_{j})$を求め，類似度の高いデータの対を対訳として抽出する．
\end{enumerate}



\end{document}
