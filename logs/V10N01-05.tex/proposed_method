対象とする複数文書

複数文書要約において，これまでに処理対象とされている文書集合は以下の2種
に大別できる\cite{article8}．

\begin{enumerate}
 \item[(1)] 情報検索結果である文書集合
 \item[(2)] ある特定の話題(トピック)に関する文書集合
\end{enumerate}

(1)の分類を対象とした複数文書要約の研究としては，
\cite{article41}などがある．
(1)では，ユーザが入力した検索要求(すなわち，単語群)を含む全ての文書が該当
する．
このため，要約の対象となる文書の数が多い．
また，検索結果には，様々な出来事を扱った文書が多く含まれるだけでなく，ユー
ザが必要としない文書も多く含まれる可能性も高い．
こうした多様で大量の文書集合に対して，理想的な要約を作成することは困難で
あるという問題がある．

一方，(2)の分類を対象とした複数文書要約の研究としては，
\cite{article38,article39,article40}などがある．
TSC，DUC で扱われている複数文書もこの範疇に入る． また，こうした文書集合
を
抽出するための研究は Topic Detection and Tracking (TDT)\cite{article37}
などで盛んに行われている．
(2)の分類に属する文書集合は，特定の話題(出来事)に関連する文書集合であるの
で，一つのまとまったストーリが形成されていると考えられる．
こうした文書集合は，意味的に良くまとまっているという特徴を持っているので，
要約対象とする文書集合としても適している．

本稿では，理想的な要約を作成することが比較的，容易であると考えられる分類
(2)に属する文書集合から重要文を抽出する手法を提案する．特に，
McKeownの分類\cite{article51}や野畑らの分類\cite{article42}による
Single-Event に属する文書集合を処理の対象とする．

Support Vector Machine に基づく複数文書からの重要文抽出手法

\subsection{SVM による文のランキング}

SVM は，Vapnik によって提案された
2値分類のための教師あり学習アルゴリズムである\cite{article12}．
近年，様々な自然言語処理のタスクに適用され，その有効性が報告されている
\cite{article13,article14,article15,article16}．SVM は既に自然言語処理
の分野でもよく知られているので，本稿では詳しい説明を省略する．
解説記事\cite{article52}などを参照されたい．

SVMでは，学習データを${\bf x}_i(1 \le i \le n)$としたときに，テストデー
タ${\bf x}$を判別す
る判別関数$f({\bf x})={\rm sgn}(g({\bf x}))$が以下の式で与えられる．

\begin{equation}
 g({\bf x})  =    \sum_{i=1}^n w_i K ({\bf x}_i,{\bf x}) + b 
\end{equation}

$w_i$，$b$は定数である．
ここで，$w_i \ne 0$となるベクトルはサポートベクトルと呼ばれ，学習データ
中の正例，負例を代表する．結局，判別関数はサポートベクトルのみで記述
される．$K({\bf x}_i,{\bf x})$はカーネル関数と呼ばれる．様々なカーネル関
数が提案されているが，本稿では多項式カーネル(式2)を用いる．

\begin{equation}
 K({\bf x},{\bf y})  =   ({\bf x} \cdot {\bf y} +1)^d 
\end{equation}

重要文抽出は，
要約率で指定された重要文の数を$Num$とした時に，重要度の高い上位$Num$件の
文を重要文とみなし，それ以外を非重要文と見なす2値分類問題と考えることが
できる．
しかし，重要文抽出では，指定された要約率に応じた数だけ文を抽出する必要が
ある．
判別関数$f({\bf x})$を用いて重要文であるかどうかの判断を行った場合には，
重要文と判定された文の数が要約率で指定された文の数をみたすとは限らず，問
題となる．
そこで本稿では，入力となる複数文書集合に含まれる全ての文に対して
$g({\bf x})$の値を用いてランキングを行い，指定された要約率をみたすように
文を抽出する．

\subsection{素性}

複数文書からの重要文抽出は，話題に関する文書集合を連結して
1文書とみなせば，従来
の単一文書からの重要文抽出と同等である．
しかし，文書集合中の任意の文が，それが属する文書において重要かどうかとい
う観点だけでなく，文書集合全体において重要かどうかという観点も扱う必要が
ある．
よって本稿では，
1文書のみで決定することのできる素性(単一文書用素性)と文書集合が与えられ
たときに決定することのできる素性(複数文書用素性)
の2種の素性を用いる．以下に詳細を述べる．

また，素性ベクトル${\bf x}_j$の各要素は0か1の2値となるように${\bf x}_j$
を定義した．2値とならない素性は，$[0,1]$の値に正規化\footnote{
単一文書用の素性は文書内での最大値で割ることによって正規化する．複数文書
用の素性は，文書集合内での最大値や後述するクラスタ内での最大値で割るこ
とによって正規化する．
}し，その後，正規化した値が$[0,1]$を10分割した区間
$[0.0,0.1)$,$[0.1,0.2)$,$\cdots$,$[0.9,1.0]$のどこに属するかを表す10次元
の2値ベクトルに変換した．たとえば，文$S_j$のある素性$F(S_j)が0.75$であれば，
これが
ベクトル$0000000100$に変換され，素性ベクトル${\bf x}_j$の要素の内の10
個となる．こうして，最終的に，各文の素性ベクトル${\bf x}_j$の次元は 583
となる．

\subsubsection{単一文書用素性}

従来より，単一文書からの重要文抽出において，多くの文の素性が過去の研究に
より報告されている．本稿ではこうした素性を参考にするだけでなく，
文に出現する固有表現と係り受け構造を考慮したTF$\cdot$IDFを文の素性とし
て導入した．


\subsubsection*{文の位置\cite{article2}}

特定の話題に関する文書集合を$E$とし，$E$に含まれる任意の文書を$D_i$，
$D_i$に含ま
れる任意の文を$S_j$，任意のパラグラフを$P_k$とする．
ここで，
文$S_j$の位置を表す素性として，$D_i$における$S_j$の位置
$\mbox{Posd}(S_j)$と$P_{k}$における$S_j$の位置$\mbox{Posp}(S_j)$を以下
の式で定義する．

\begin{eqnarray}
 \mbox{Posd}(S_j) &=& 1 - \mbox{BD}_i(S_j)/M(D_i) \nonumber\\
 \mbox{Posp}(S_{j}) &=& 1 - \mbox{BP}_{k}(S_j)/M(P_{k}) \nonumber
\end{eqnarray}

ここで，$M(D_i)$は$D_i$の文字数，$\mbox{BD}_i(S_j)$は，文
書の先頭から$S_j$までの文字数である．$M(P_{k})$は$P_{k}$の
文字数，$\mbox{BP}_{k}(S_j)$はそのパラグラフの先頭から$S_j$までの
文字数を表す．

\subsubsection*{文の長さ\cite{article27}}

文$S_j$の長さを表わす素性として，$\mbox{Len}(S_j)$を以下の式で定義する．

\[
 \mbox{Len}(S_j) = M(S_j)
\]

\noindent ただし，$M(S_j)$は文$S_j$の文字数を表す．

\subsubsection*{{\bf {\rm TF$\cdot$IDF}}\cite{article4}}

文$S_j$に含まれる単語の重み(TF$\cdot$IDF値)に基づいた素性として，
$\mbox{Score}(S_j)$を以下の式で定義する．
なお，本稿では，
形態素解析器「茶筌」\cite{chasen}を用いて解析した結果，
名詞および未知語と判定されたものを処理対象とした．以下の記述におい
て，単語とは名詞および未知語を指すものとする．

\[
 \mbox{Score}(S_j) = \sum_{t \in T(S_j)} tf(t,S_j) \cdot w(t,D_i)
\]

ここで，$T(S_j)$は$S_j$に出現する単語の集合である．
$tf(t,S_j)$は$S_j$における単語$t$の出現頻度であり，$w(t,D_i)$は文
書$D_i$における単語$t$のTF$\cdot$IDF値である．$w(t,D_i)$は 
SMART で用いられている以下の式で定義する．

\[
 w(t,D_i) = 0.5 \left(1+\frac{tf(t,D_i)}{tf_{max}(D_i)}\right) \cdot \mbox{log} \left( \frac{N}{df(t)} \right)
\]

$tf(t,D_i)$は，単語$t$の文書$D_i$における出現頻度，$tf_{max}(D_i)$は文書
$D_i$に
含まれる単語の最大頻度，$df(t)$は，データベースにおいて単語$t$を含む文書
の数である．
$N$はデータベースとする文書集合に含まれる文書数である．
本稿では，データベースとは毎日新聞99年の1年分(112401文書)をさす．

\subsubsection*{キーワード密度\cite{article25}}

まず，$D_i$に出現する単語の集合を$T(D_i)$とする．$T(D_i)$に含まれる全て
の単語に対して$w(t',D_i)$を求め，それらの平均と標準偏差を$\mu$，$\sigma$
とした場合に$\mu+0.5\sigma \le w(t',D_i)$をみたした$t'$の集合を$T_{sig}$
とする．ここで，$T_{sig}$に含まれる単語の密度に基づいた$S_j$の素性を
\cite{article29}で提案された以下の式を用いて定義する．

\[
 \mbox{Den}(S_j) = \frac{\sum_{t \in T_{sig}} w(t,D_i)}{d(S_j)}
\]

$T_{sig}$に含まれる単語でかつ$S_j$に出現する単語集合を$T_{sig}(S_j)$とし，
$k(\ge 2)$番目に出現した$t'' \in T_{sig}(S_j)$と$k-1$番目に出
現した$t''\in T_{sig}(S_j)$の距離(何単語離れているか)を$dist_k$として，
$d(S_j)$は，以下の式で定義される．

\[
 d(S_j) = \frac{\sqrt{\sum_{k=2}^{|T_{sig}(S_j)|} (dist_k)^2}}{|T_{sig}(S_j)|-1} 
\]

$d(S_j)$は$S_j$に出現する単語$t \in T_{sig}(S_j)$の2乗平均距離を表しており，
これが小さいことは，それらが密集して出現していることを意味する．


\subsubsection*{タイトルとの類似度\cite{article2}}

文$S_j$と$S_j$を含む文書$D_i$のタイトル$H_l$との類似度
$\mbox{Sim}(S_j,H_l)$を以下の cosine measure を用いて定義し，これを$S_j$
の素性とする．


\[
 \mbox{Sim}(S_j,H_l) = \frac{\vec v(S_j) \cdot \vec v(H_l)}{ \left \Vert \vec v(S_j)
 \right \Vert \left \Vert \vec v(H_l) \right \Vert}
\]

ここで，$\vec v(S_j)$，$\vec v(H_l)$は，単語を素性としてその有無を素性の
値とする2値ベクトルである．

\subsubsection*{係り受け関係を考慮したTF$\cdot$IDF}

文の構文的な構造に着目し，述語を修飾する文節集合に含まれる単語の重みを考
慮したTF$\cdot$IDFを定義する．
述語を修飾する文節の中で最も多くの
情報を持っていると考えられる文節集合の重要度$\mbox{Score}_{d}$，
述語を直接修飾する文節集合の重要度$\mbox{Score}_{w}$として，以下の式で定
義する．

\begin{eqnarray}
 \mbox{Score}_{d}(S_j) &=& \sum_{t \in T_d(S_j)} w(t,D_i)\nonumber\\
 \mbox{Score}_{w}(S_j) &=& \sum_{t \in T_w(S_j)} w(t,D_i)\nonumber
\end{eqnarray}

$\mbox{Score}_{d}$は，係り受け構造木の最長パスを形成する文節集合に含まれ
る単
語の集合$T_{d}(S_j)$に着目したTF$\cdot$IDF値の総和，$\mbox{Score}_{w}$は，
最終文節に直接係る文節集合に含まれる単語の集合$T_{w}(S_j)$に着目したTF
$\cdot$IDF値の総和である．
なお，係り受け解析には
Cabocha\footnote{
http://cl.aist-nara.ac.jp/\~{}taku-ku/software/cabocha
}を用いた．

\subsubsection*{固有表現}

Nobataら\cite{article5}は，文書のタイトルに出現する固有表現に着目した重
要文抽出手法を提案している．しかし，
文書中に出現する全ての固有表現が文の重要度に影響を与えると予想されるので，
本稿では
$S_j$に特定の種類の固有表現が存在する場合に1，存在しない場合に0をとる2値
の素性を定義する．
\cite{article1}でも固有表現を素性として用いているが，本稿での分類
のように詳細ではない．
ここでの固有表現とは Information Retrieval and Extraction Exercise
(IREX) \cite{article35} の固有表現基準による固有
表現および数値表現を指し，以下の8種に分類される．固有表現の抽出には磯崎
のアルゴリズム\cite{article7}を用いた．

\begin{quote}
 PERSON，LOCATION，ORGANIZATION，ARTIFACT，DATE，MONEY，PERCENT，TIME
\end{quote}

\subsubsection*{接続詞\cite{article3}}

$S_j$に特定の接続詞が出現した場合に1，出現しなかった場合に0
をとる2値の素性を定義する．
接続詞は50種である．

\subsubsection*{助詞\cite{article3}}

$S_j$に特定の助詞が出現した場合に1，出現しなかった場合に0
をとる2値の素性を定義した．
助詞は，``格助詞$-$一般''(11種)とトピックマーカとされる係助詞(「は」，
「も」)の計13種である．

\subsubsection*{文末表現(小分類および大分類)\cite{article3,article6}}

$S_j$に特定の小分類に属する文末表現が出現した場合に1，出現しなかった場合
に0をとる2値の素性を定
義し，大分類についても同じく2値の素性を定義する．

文末表現の分類については，福本らの分類\cite{article30}に加え
「特殊」，「署名」，「その他」を加えた21種を用いた．「特殊」は会話文
などのかぎ括弧で終わる文，「署名」は文
書の著者を示す文を指す．
大分類については，福本らの分類\cite{article30}，
田村らの分類\cite{article31}に「その他」を加
えた4種を用いた．分類ルールについては，文献\cite{article30,article31}を
参照されたい．分類の詳細を以下に示す．

大分類:~意見
\begin{quote}
 小分類:~意見，問掛，要望
\end{quote}

大分類:~断定
\begin{quote}
 小分類:~断定，推量，理由，判断，義務
\end{quote}

大分類:~叙述
\begin{quote}
 小分類:~叙述，可能，伝聞，様態，存在，継続，状態，使役，現在，過去
\end{quote}

大分類:~その他
\begin{quote}
 小分類:~特殊，署名，その他
\end{quote}

\subsubsection*{修辞関係\cite{article34}}

田村らの手法\cite{article31}を用いて
$S_j$の修辞関係(計4種)を決定し，$S_j$が$S_{j-1}$に対して特定の
修辞関係である場合に1，そうでない場合に0をとる2値の素性を定義する．
修辞関係は，
「順接」，「転換」，「結論」，「説明」の4種である．
修辞関係の決定ルールについては
文献\cite{article30,article31}を参照されたい．

\subsubsection*{用言}

$S_j$に出現する用言を日本語語彙大系\cite{article18}を用いて分類し，
$S_j$に特定の分類の用言が出現したときに1，出現しなかった場合に0をとる素
性を定義する．日本語語
彙大系における用言の基本分類は36であるが，多義語は複数の基本分類に属する．
よって，多義を考慮して「基本分類の組」も一つの分類とみなし，合計366分類
とした．

\subsubsection{複数文書用の素性}

任意の文$S_j$に対し，複数の文書が与えられた場合に定義できる素性として，
以下の3種の素性を定義した．

\subsubsection*{文書集合全体における位置}

文$S_j$の位置を表す素性として，文書集合$E$における位置
$\mbox{Post}(S_j)$を以下の式で定義する．

\begin{eqnarray}
 \mbox{Post}(S_j) &=& 1 - \mbox{BE}(S_j)/M(E) \nonumber
\end{eqnarray}

ただし，$M(E)$は文書集合に含まれる文書の文字数の合計，$\mbox{BE}(S_j)$
は，$E$中の文書を時系列\footnote{
文書番号と時系列は一致していると仮定した．
}でソートした後，文書ごとの区切りを無視して1
文書とみなした場合の先頭から$S_j$までの文字数である．


\subsubsection*{文書集合に特徴的な単語によるTF$\cdot$IDF}

本稿で対象とする複数文書は何らかの観点に基づいて集められた文書集合である．
よって，これらの文書集合に特徴的な単語は重要文抽出のための手がかりとして
有効である．
文書集合に特徴的な単語としては，文書集合を得るための検索要求に含まれる
単語であると考えること
も可能
であるが，検索要求に含まれる単語だけでは情報が少ないという問題がある．さ
らに，本稿では検索は用いていない．
そこで，本稿では
与えられた文書集合の情報を用いて特徴的な語を認定する手法を採る．

従来より，
母集団となる文書集合からある特定の文書集合を抽出した場合，取り出した文書
集合に特徴的な単
語を認定する手法として，$\chi^2$検定を用いた手法\cite{article43,article45}やAICを
用いた手法\cite{article44}が提案されている．本稿では，これらの手法を拡張し
て MDL 原理を用いて入力とする文書集合に特徴的な単語を認定する．

\begin{table}[t]
 \begin{center}
  \caption{$2 \times 2$ 分割表}
  \label{tab01}
  \begin{tabular}{l|l|l}
   \hline
   \hline
   & $c$  & $\neg c$ \\
   \hline
   $t$ &$n_{11}$ & $n_{12}$\\
   $\neg t$ & $n_{21}$& $n_{22}$\\
   \hline
  \end{tabular}
 \end{center}
\end{table}

まず，ある文書集合$c$に出現する全ての単語$t$に対して，表\ref{tab01}に示す$2
\times 2$分割表を得る．ここで，$n_{11}$は，文書集合$c$において$t$
が出現する文書数，$n_{12}$は，$c$以外の文書集合において$t$が出現する文書
数である．$n_{21}$は，
$c$において$t$が出現しない文書数，$n_{22}$は，$c$以外の文書集合におい
て$t$が出現しない文
書数である．この時，$t$と$c$の間に依存関係があるとするモデル(DM)と独立で
あるとするモデル(IM)を考え，$t$がどちらに良く当てはまる
かを調べることで$t$が$c$に特徴的な語かどうかの判断をする．

DM，IM に対する MDL 値はそれぞれ以下の式で求まる．

\begin{eqnarray}
 \mbox{MDL}_{DM}(t,c) &=& - \mbox{MLL}_{DM}(t,c) - \frac{k_{DM}}{2} \mbox{log}N \\
 \mbox{MDL}_{IM}(t,c) &=& - \mbox{MLL}_{IM}(t,c) - \frac{k_{IM}}{2} \mbox{log}N
\end{eqnarray}

\noindent ただし，$k_{DM}$，$k_{IM}$はそれぞれのモデルにおける自由パラメー
タの数であり，$k_{DM}=3$，$k_{IM}=2$である\cite{article50}．$N$は先述し
たデータベース中の全文書
数であり，$N=n_{11}+n_{12}+n_{21}+n_{22}$である．さらに，$\mbox{MLL}_{DM}$，
$\mbox{MLL}_{IM}$はそれぞれのモデルにおける最大対数尤度であり，以下の式
で求まる\cite{article50}．

\begin{eqnarray}
 \mbox{MLL}_{DM}(t,c) &=& (n_{11}+n_{12})\log(n_{11}+n_{12})+(n_{11}+n_{21})\log(n_{11}+n_{21}) \nonumber\\
 &+& (n_{21}+n_{22})\log(n_{21}+n_{22})+(n_{12}+n_{22})\log(n_{12}+n_{22}) \nonumber\\
&-& 2N \log N \nonumber\\
 \mbox{MLL}_{IM}(t,c) &=& n_{11}\log n_{11} +n_{12}\log n_{12}+n_{21}\log n_{21}+n_{22}\log n_{22} -N \log N \nonumber
\end{eqnarray}

MDL の値は小さいほど優れたモデルである．
ここで，AICの場合\cite{article49}と同様に2つのモデルの差が1以上ならば有意な差であると考えた．よって，以下の式をみたす$t$
を$c$に特徴的な語として認定する．

\[
 \mbox{MDL}_{IM}(t,c) - \mbox{MDL}_{DM}(t,c) \ge 1
\]

ここで，$c$として文書集合$E$，$E$において，同日に出現した文書の集合
$C_{i}$の2つを考える．$C_i$を考える理由は時間が進むにつれて新たに出現す
る単語を認定するためである．
$c=E$の時に上記条件をみたす単語集合を
$T'(E)$，$c=C_i$の時に$T'(C_i)$とする．それぞれの場合の文$S_j$の素性を
以下の式で定義する．

\[
 \mbox{Score}_{E}(S_j) = \sum_{t \in T(S_j) \cap T'(E)}tf(t,S_j) \cdot w(t,D_i)
\]

\[
 \mbox{Score}_{C}(S_j) = \sum_{t \in T(S_j) \cap T'(C_i)}tf(t,S_j) \cdot w(t,D_i)
\]

\noindent ただし，$S_j \in C_i$．上式はそれぞれ，文書集合$E$に特徴的な単
語，$E$の部分文書集合$C_i$に特徴的な単語にのみ着目した単語重要度の総和で
ある．


\subsubsection*{文書のジャンル}

重要文抽出の対象となる文書集合には様々なジャンルの文書が含まれる場合があ
る．この時，あるジャンルの文書には重要文が少ないなど文書のジャン
ルが文の重要度に影響を与えることが考えられる．
そこで，
本稿では$S_j$が特定のジャンルの文書に属する場合に1，属さない場合に0とす
る2値の素性
を定義する．ここでのジャンルとは新聞記事の紙面の情報をもとにした下記の分
類である．

\begin{quote}
 報道，社説，解説，読書，総合，特集，科学
\end{quote}


冗長性削減の有効性

\begin{figure}[tb]
 \begin{center}
  \begin{minipage}{.75\linewidth}
   \begin{screen}
   $A = \{\}$;\\
   $R = \{S_1,S_2,\cdots,S_\ell\}$;\\
   $N = 出力すべき文数$;\\
   $\mbox{While}(|A| < N)\{$
   \begin{quote}
    $S^* = \mbox{MMR}(A,R)$;\\
    $A = A \cup \{S^*\}$;\\
    $R = R - \{S^*\}$;
   \end{quote}
   \}\\
   Aを出力．\\
  ただし，\noindent
   \[
   \mbox{MMR}(A,R) =
   \left\{ \begin{array}{ll}
   \displaystyle
    \mathop{\rm argmax}_{S_i \in R} s(g(S_i))\\
   \displaystyle
    \mathop{\rm argmax}_{S_i \in R} \lambda s(g(S_i)) - (1- \lambda)\mathop{\rm max}_{S_j \in A}\mbox{Sim}(S_i,S_j)\\
	   \end{array} \right.
   \]
   \end{screen}
  \end{minipage}
 \end{center}
   \caption{MMR による文の再ランキング}
   \label{fig01}
\end{figure}

一般的に，複数文書からの重要文を抽出した場合，抽出された文間で内容が重
複する可能性があるということが言われている\cite{article8}．重要文として抽
出された文集合から
このような冗長性を削減する方法として，Carbonell らは，Maximum Marginal
Relevance (MMR) という指標を用いて，ある観点でランキングされた文に別の観
点を導入し，再ラン
キングする手法を提案している\cite{article48}．
本稿でも MMR を使った場合に SVM の重要文の抽出精度がどのように変化するか
を調べる．

MMR を用いた文の再ランキングアルゴリズムを図\ref{fig01}に示す．$R$は文集
集合に含まれる文の集合を表し，$A$は出力となる文集合を表す．$s(x)$は，
シグモイド関数$s(x)= 1/(1+\mbox{exp}(-\beta x))$を表し，$\beta=1$とした．
$s(g(S_i))$は，式(1)の値を0〜1
に正規化した値となる．$\mbox{Sim}(S_i,S_j)$は，文$S_i$と$S_j$の単語の重
複度を cosine measure で表した指標である．3.2.1節のタイトルとの類似度と
同様に計算する．
ここでの MMR は SVM の判別関数の値から既に選択した文との重
複度をペナルティとして引いたものである．$\lambda$はそれぞれの項の重みを
決めるパラメータである．
MMR を用いることで，冗長性の低い(重複の少ない)文集合を得られることが期待
できる．図\ref{fig02}に$\lambda$を1〜0.8まで0.05刻で変化させた場合の SVM
の抽出精度を示す．

\begin{figure}[p]
 \begin{center}
  \vspace*{-1em}
  \begin{tabular}{c}
   要約率10\,\%\\
 \epsfile{file=graph3/Small.eps,scale=1.1}\\
   要約率30\,\%\\
  \epsfile{file=graph3/Medium.eps,scale=1.1}\\
   要約率50\,\%\\
  \epsfile{file=graph3/Large.eps,scale=1.1}\\
  \end{tabular}
  \caption{MMR を用いた場合の抽出精度の変化}
  \label{fig02}
 \end{center}
\end{figure}

図\ref{fig02}より，どのセットに対しても10\,\%，30\,\%の要約率では
SVMの抽出精度は低下するだけであり，MMR が有効でないことがわ
かる．これは，10\,\%，30\,\%の要約率では，SVM による抽出結果に文単位での
冗長性が無いことを示している．
複数の文書からの重要文抽出では冗長性を削減することが有効で
あるといわれていたが，今回の実験では10\,\%，30\,\%の低い要約率では有効でない
という結果となった．
この傾向は SVM だけでなく，Lead 手法，TF$\cdot$IDFでも同様であった．
このような結果の原因として，重要文の抽出もととなる文集合に文を単位とした
冗長性が少な
いため，抽出された文にも結果として冗長性が少なかったということが考えられる．
特に，評価実験の対象とした文集合が全て単一の情報源(毎日新聞)から得られた
ものであることの影響が大きい．

このような文を単位とした冗長性が少ないデータに対して MMR が及ぼす悪影
響の原因について考える．
$\mbox{Sim}(S_i,S_j)$は2文間に共通する単語に依存する．ここで，ある文集合
において
全く冗長性が無い(文の意味的な内容に重複がない)ことをどの2文間にも共通す
る単語が無いことと捉える．この
場合，$\mbox{Sim}(S_i,S_j)$は常に0となり，ランキングに対する MMR の悪影
響は無い．
しかし，実際には，文の意味としては異なるが，共通する単語は存在するような
文の組は多数存在する．よって，$\mbox{Sim}(S_i,S_j)$が0とならず，再ランキ
ングに悪影響を及ぼす．
ただし，複数の情報源から得た文集合であれば，類似度の高い2文はほぼ同
一の意味を持つ傾向が強いと予想されるので，MMRによる再ランキングは有効に
働くと考える．

一方，50\,\%の要約率ではわずかではあるが，抽出精度の向上が見られた．特に，
SVM(C)では1.5\,\%程度，抽出精度が向上している．
以下にSVM(C)において MMR が
有効に働いた例を示す．上の文が正解文として残った文で下の文が上の文
に対して類似していることで削除(下位にランク)された文である．

\begin{itemize}
 \item 16、チェルノブイリ原子力発電所を2000年までに閉鎖するという
       ウクライナが行った新たな約束を歓迎する。
 \item また、声明には、ウクライナのチェルノブイリ原子力発電所を来年まで
       に閉鎖することを改めて確認、金融犯罪への取り組み強化も盛り込んだ。
\end{itemize}

このように2文間に共通する単語が多く，意味的にも類似した文の組がある場合
には，MMR は有効である．先にも述べたが，今回の実験に用いたデータにはこう
した例は少ない．よって，多数の文を抽出する50\,\%の要約率でしか効果が確認で
きなかったと考える．

ただし，文を単位とした冗長性は少ないが，語句単位での冗長性は数多く見られ
た．一例を以下に示す．

\begin{quote}
 {\bf ブラジルの通貨レアルの切り下げ}と中央銀行総裁の辞任によるショック
 が，$\cdots$．\\
 宮沢喜一蔵相は14日の閣議後会見で，{\bf ブラジルの通貨レアル切り下げ}
 で$\cdots$．\\
 {\bf ブラジルの通貨レアル切り下げ}を受けた中南米は13日，$\cdots$．
\end{quote}

\noindent このように語句を単位とした冗長性は多く存在するので，単一の情報
源を対象とした場合には，文を単位とした冗長性ではなく，語句を単位とした冗
長性を削減する手法を考える必要がある．

