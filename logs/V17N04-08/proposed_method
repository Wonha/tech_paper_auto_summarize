統計翻訳システム

\subsection{基本概念}

日英の統計翻訳は，日本語文$j$が与えられたとき，全ての組合せの中から確率
が最大になる英語文$\hat{e}$を探索することで翻訳を行う~\cite{IBM}．以下に
その基本式を示す．
\[
\hat{e}=argmax_{e}P(j|e)P(e)
\]

$P(j|e)$は翻訳モデル，$P(e)$は言語モデルと呼ぶ．翻訳モデルは日本語と英
語が対になった対訳コーパスから学習して作成する．また，言語モデルは，出
力文側の言語である英語コーパスから学習して作成する．デコーダは言語モデ
ルと翻訳モデルを用いて，尤度の最も高い英文を生成する．


\subsection{翻訳モデル}

\begin{table}[b]
\caption{フレーズテーブルの例}
\label{tbl:フレーズテーブルの例}
\input{09table01.txt}
\end{table}

翻訳モデルは，日本語の単語列から英語の単語列または英語の単語列から日本
語の単語列へ，確率的に翻訳を行うモデルである．翻訳モデルには，大きくわ
けて語に基づく翻訳モデルと句に基づく翻訳モデルがある．初期の統計翻訳
では，語に基づく翻訳モデルを用いていたが，現在は句に基づく
翻訳モデルが翻訳精度が高いため主流になっている．句に基づく翻訳モデルでは，日本語や英
語の単語列と確率は，フレーズテーブルで管理される~\cite{moses}．
表\ref{tbl:フレーズテーブルの例}にフレーズテーブルの例を示す．



このテーブルは，左から，``日本語フレーズ''，``英語フレーズ''，``フレー
ズの英日翻訳確率$P(j|e)$''，``英日方向の単語の翻訳確率の積''，``フレー
ズの日英翻訳確率$P(e|j)$''，``日英方向の単語の翻訳確率の積''である．


\subsection{フレーズテーブルの作成法}

句に基づく翻訳モデルは，原言語の単語列から目的言語の単語列の翻訳に対し
て確率を付与する．これをフレーズテーブルで管理する．以下に作成手順につ
いて説明する．



\begin{description}

\item[手順1] 単語alignmentの計算（日英，英日）

まず，IBMモデル~\cite{IBM}を利用することで，単語alignmentを得る．これを
英日，日英の両方向に対して行う．つまり，学習データに対して，英日方向の
単語alignmentと日英方向の単語alignmentを計算する．このtoolとして
GIZA++~\cite{giza}が用いられる．


\item[手順2] 単語列alignmentの計算（union と intersection）

次に，英日・日英両方向の単語alignmentから，英日・日英両方向に1対多の対
応を認めた単語列alignmentを求める．この単語列alignmentは英日・日英両方
向の単語対応の積集合(intersection)と和集合(union)を利用してヒューリス
ティックスで求める~\cite{Och}．尚，積集合(intersection)は，両方向ともに
単語alignmentが存在する場合のみ単語列alignmentを残し，和集合(union)は，
少なくとも片方向に単語alignmentが存在する場合に単語列alignmentを残す．
対称な単語列対応を求めるヒューリスティックス(grow-diag-final)は，まず積
集合から始まり，和集合にしかない単語対応が妥当であるかを判断しながら，
単語対応を徐々に加える~\cite{tsukuba}．なお通常の統計翻訳では，
grow-diag-finalが利用されている．

\begin{table}[b]
\caption{対訳文の例}
\label{対訳文の例}
\input{09table02.txt}
\end{table}

\item[手順3] フレーズテーブルの抽出

単語列alignmentから，ヒューリステックを用いて日本語単語列と英語単語列の
フレーズ対を得る．そのフレーズ対に対して翻訳確率を計算してフレーズテー
ブルを作成する．表\ref{対訳文の例}を学習データとしたとき，
grow-diag-finalで作成されたフレーズテーブルを表\ref{tbl:作成されたフレー
  ズテーブルの例(grow-diag-final)}に示す．また，intersectionで作成され
たフレーズテーブルを表\ref{tbl:作成されたフレーズテーブルの例
  (intersection)}に示す．

パラメータintersectionで作成したフレーズテーブルは，多くのフレーズ対を
持ち，かつ長いフレーズ対を含むことが分かる．

\end{description}




\begin{table}[t]
\caption{grow-diag-finalで作成されたフレーズテーブル（全12フレーズ）}
\label{tbl:作成されたフレーズテーブルの例(grow-diag-final)}
\input{09table03.txt}
\end{table}
\begin{table}[t]
\caption{intersectionで作成したフレーズテーブルの例（全185フレーズから一部抜粋）}
\label{tbl:作成されたフレーズテーブルの例(intersection)}
\input{09table04.txt}
\end{table}





\subsection{言語モデル}

言語モデルは，目的言語の単語列に対して，それらが起こる確率を与えるモデ
ルである．日英翻訳では，より英語らしい文に対して高い確率を与えること
で，翻訳モデルで翻訳された訳文候補の中から英語として自然な文を選出す
る．言語モデルとしては$N$-gramモデルが代表的である．

尚，学習データに表れない単語連鎖確率値を0.0とすると，テストデータにおい
て，目的言語の全ての単語列の確率が0.0になって，単語列が出力されないこと
がある．そのため，学習データに存在しない単語連鎖確率は，スムージングに
よって0.0以外の確率を割り当てる．代表的なスムージング法として，Backoff
やKneser-Neyがある．これらは高次の$N$-gramに，低次の$N$-gramと閾値を掛
けて利用する．

\subsection{デコーダ}

デコーダは翻訳モデルと言語モデルの確率が最大となる文を探索し，出力
する．デコーダとしてmoses~\cite{moses}が代表的である．mosesはいくつかの
パラメータを設定することが出来る．mosesで設定できるパラメータの例を以下
に示す．

\begin{itemize}
\item weight-l…言語モデルの重み 
\item weight-t…翻訳モデルの重み
\item weight-d…単語の移動の距離の重み
\item weight-w…目的言語の長さに関するペナルティ
\item distortion-limit…フレーズの並び変えの範囲の制限値
\end{itemize}

これらのパラメータは，パラメータチューニング（\ref{sec:papametertuning}節）
を行うことで最適値を求めることが出来る．

\subsection{パラメータチューニング}
\label{sec:papametertuning}

正解があるdevelopmentデータに対して評価値を最大にするように，デコー
ダのパラメータを最適化することができる．これをパラメータチューニングと
呼ぶ．この方法として，Minimum Error Rate Training (MERT)~\cite{mert}が一
般的によく利用される．MERTは， developmentデータの，各文について上位
$N$個（通常100個） の翻訳候補を出力し，目的の評価値（通常BLEU）を最大に
するようにデコーダのパラメータの値を調節する．

通常，パラメータチューニングを行うと，テストデータのBLEUスコアは上
昇する．しかし，実験条件を変更するたびに，パラメータチューニングを行うと，
多くの時間がかかる．また，本研究では，全ての実験において，実験
条件を同一にする必要がある．そのため，パラメータの最適化は行わない．


自動的に作成したフレーズテーブルへの翻訳対の追加（提案方法）

\subsection{翻訳対への翻訳確率の付与}

手作業で作成された翻訳対を，自動的に作成したフレーズテーブルに追加するた
めに，翻訳対に翻訳確率を付与する必要がある．この翻訳確率として，自動作
成したフレーズテーブルの翻訳確率を利用する．ただし，フレーズテーブルを
作成するときにパラメータgrow-diag-finalを用いると，確率が付与される翻訳対
は少ない．そこで，翻訳確率を与えるためのフレーズテーブルには，多くのフレー
ズ対を作成するパラメータintersectionを用いて作成する．


\subsection{翻訳対の追加手順}

手作業で作成した翻訳対をフレーズテーブルに追加する手順を
図\ref{fig:手作業で作成したフレーズ対への確率値の付与方法}に示す．

\begin{figure}[t]
\begin{center}
\includegraphics{17-4ia9f1.eps}
\end{center}
\caption{手作業で作成したフレーズ対への確率値の付与方法}
\label{fig:手作業で作成したフレーズ対への確率値の付与方法}
\end{figure}


手作業で作成した翻訳対をフレーズテーブルに追加する手順を以下に示す．

\begin{table}[t]
\caption{パラメータintersectionで作成したフレーズテーブルの例}
\label{tbl:パラメータintersectionで作成したフレーズテーブルの例}
\input{09table05.txt}
\end{table}

\begin{description}

\item[手順1] 前処理

日英重複文文型パターン辞書~\cite{tori}から対訳文を抽出し
``chasen~\cite{chasen}''で形態素解析を行う．英語文に対しては大文字の小文
字化を行う．また，句読点の前にスペースを入れる．
前処理を行った後の対訳文の具体例を表\ref{tbl:対訳文の例}に示す．

\item[手順2] intersectionを用いたフレーズテーブルの作成

手順1で抽出した対訳文を用いてフレーズテーブルを作成する．作成時のパラメー
タにはintersectionを用いる．作成したフレーズテーブルの例を表\ref{tbl:パ
ラメータintersectionで作成したフレーズテーブルの例}に示す．

\item[手順3] 手作業で作成した翻訳対への翻訳確率値を付与

手順2で作成したフレーズテーブルを参照して，手作業で作成した翻訳対に翻訳
確率値を付与する．翻訳対が``オーバー コート を 脱ぎ捨て $|||$ flung his coat
off''の場合は1行目のフレーズ対の翻訳確率値``0.5 3.88199e-08 0.5
6.46865e-06''を付与する．


\item[手順4] grow-diag-finalをもちいたフレーズテーブルの作成

手順1で抽出した対訳文を用いてフレーズテーブルを作成する．作成時のパラ
メータにはgrow-diag-finalを用いる．作成したフレーズテーブルの例を表
\ref{tbl:パラメータgrow-diag-finalで作成したフレーズテーブルの例}に示す．

\item[手順5] フレーズテーブルの追加

\pagebreak
手順4で作成したフレーズテーブルに，手順3で作成した翻訳確率を付与した翻訳
対を追加する．

\end{description} 

\begin{table}[t]
\caption{パラメータgrow-diag-finalで作成したフレーズテーブルの例}
\label{tbl:パラメータgrow-diag-finalで作成したフレーズテーブルの例}
\input{09table06.txt}
\end{table}
\begin{table}[t]
\caption{確率値を付与した翻訳対を追加したフレーズテーブルの例}
\label{tbl:確率値を付与した翻訳対を追加したフレーズテーブルの例}
\input{09table07.txt}
\end{table}

尚，本稿では，手順4で作成したフレーズテーブルを用いた翻訳をベースライン
と呼び，手順5のフレーズテーブルを用いた翻訳を提案手法と呼ぶ．



翻訳実験
\label{翻訳実験の結果}

翻訳実験は，単文と重複文の2種類で行う．

\subsection{学習データ}
\label{sec:trainingdata}

単文の翻訳実験には，電子辞書などから抽出した単文10万文対~\cite{murakami}を学習データとして用いる．重複文の翻訳実験には日英重複文
文型パターン辞書~\cite{tori}から抽出した対訳文対，121,913文対を用いる．
尚，単文10万文は，日本語が単文であるが，対訳英文は単文とは限らず複文の
場合もある．重複文121,913文は，日本文が重文もしくは複文であるが，英文は
複文とは限らず単文である場合もある．

前処理[手順1]を行った対訳文の例を表\ref{tbl:対訳文の例}に示す．



\subsection{手作業で作成された翻訳対}
\label{sec:translationpair}

手作業で作成された翻訳対は，日英重複文文型パターン辞書~\cite{tori}から抽
出した対訳コーパスから作成された翻訳対261,453個を用いる． この翻訳対
は，プロの翻訳者が手動で作成した対訳対で，単語，句，節の単位で対応づけ
られている．また，この翻訳対は日本語文が重複文で英語が単文もしくは重複
文である対訳コーパスから抽出されている．文献~\cite{ikehara} に，この翻
訳対の詳しい説明がある．基本的には，日本語文と英語文の対訳文から日本語パターンと英語パターンを
作成する．このとき，作成できる日英翻訳対を利用する．
翻訳対の抽出において，長さの制限は行っていない．
また，重複する句は抽出していない．
例を表\ref{tbl:翻訳対の作成例}に示す．

\begin{table}[t]
\caption{対訳文の例}
\label{tbl:対訳文の例}
\input{09table08.txt}
\end{table}
\begin{table}[t]
\caption{翻訳対の作成例}
\label{tbl:翻訳対の作成例}
\input{09table09.txt}
\end{table}

手作業で作成された翻訳対の例を
表{\ref{tbl:手作業で作成された翻訳対の例}}に示す．
翻訳対の分布図を図{\ref{fig:手作業で作成した翻訳対の単語数の分布図}}に示す．
この図では，縦軸が全体
に占める割合で，横軸が1つの翻訳対における単語数である．日本語における
単語数を■，英語における単語数を□で示している．これからわかるよう
に，2単語のフレーズが最も多く，単語数と，その単語数がしめる割合
は，zipfの法則に沿っていることがわかる．なお，本稿では，手作業で作成さ
れた単語列の対訳対を翻訳対と呼ぶ．


\subsection{テストデータ}
\label{sec:testdata}

テストデータには，電子辞書などから抽出した単文1,000文対~\cite{murakami}を用
いる．重複文の翻訳実験には日英重複文文型パターン辞書~\cite{tori}から抽出
した対訳文対1,000文対を用いる．ただし，テストデータは
学習データ（\ref{sec:trainingdata}節）や
手作業で作成された翻訳対（\ref{sec:translationpair}節）と，
別の辞書を利用する．従って，テストデータは，学習データや
翻訳対に対してopen dataとなる．

\begin{table}[t]
\caption{手作業で作成された翻訳対の例}
\label{tbl:手作業で作成された翻訳対の例}
\input{09table10.txt}
\end{table}
\begin{figure}[t]
\begin{center}
\includegraphics{17-4ia9f2.eps}
\end{center}
\caption{手作業で作成した翻訳対の単語数の分布図}
\label{fig:手作業で作成した翻訳対の単語数の分布図}
\vspace{-1\baselineskip}
\end{figure}




\subsection{翻訳モデルと言語モデルとデコーダ}

\begin{enumerate}

\item{フレーズテーブルの作成}

翻訳モデルはフレーズテーブルで管理される．フレーズテーブルの作成に
は，train-phrase-model.perl~\cite{pharaoh}を用いて自動的に作成する．尚，
本稿では，プログラムで自動作成した単語列の対訳対をフレーズ対と呼ぶ．ま
た，フレーズ対の最大の単語数を決めるmax phrase lengthは20とする．


\item{$N$-gram モデルの学習} 

言語モデルには，
$N$-gramモデルを用いる．$N$-gramモデルの学習には，
``SRILM~\cite{srilm}''を用いる．本研究では5-gramモデルを用いる．また，ス
ムージングのパラメータには，Kneser-Neyである``-ukndiscount''を用いる．


\item{デコーダ}

デコーダは``moses~\cite{moses}''を用いる．また，翻訳モデルには，日英翻訳
確率と英日翻訳確率の相互情報を用いる~\cite{closs}．したがって，翻訳モデ
ルの重み``weight-t''は``0.5 0 0.5 0 0''とする．また，翻訳時にフレーズの
位置の変化に柔軟に対応するため，単語の移動重み``weight-d''は0.2とする．
また単語の移動距離の制限``distortion-limit''は，$-1$（無制限を意味）とす
る．その他は，default値とする．

\end{enumerate}


\subsection{評価方法}

評価は，コンピュータによる自動評価と人間による評価の，2種類で行う．

\begin{enumerate}

\item{自動評価}

機械翻訳システムの翻訳精度を自動評価する手法として，あらかじめ実験者が
用意した正解文と，翻訳システムが出力した文とを比較する手法が利用されて
いる．この自動評価法には多くの方法が提案されている．本研究では，
$N$-gramを用いたBLEU~\cite{BLEU}と類似単語辞書を用いた
METEOR~\cite{METEOR}を用いる．

\item{人間による評価}

人間による評価として，対比較実験を行う．得られた英文から100文をラン
ダムに抽出し，ベースラインの翻訳結果と提案手法の翻訳結果のどちらの翻訳
結果が優れているかを人間で判断する．その際，本研究において固有名詞の未知
語はローマ字変換して評価し，それ以外の未知語は存在しないとして評価
を行う．

\end{enumerate}


\begin{table}[b]
\vspace{-1\baselineskip}
\caption{総フレーズ数}
\label{tbl:総フレーズ数}
\input{09table11.txt}
\end{table}


\subsection{実験結果　フレーズテーブルの増加数}

ベースラインのフレーズ数，確率値が付与できた翻訳対の数，
最終的に作成されたフレーズ数を表\ref{tbl:総フレーズ数}に示す．

手作業で作成された翻訳対は，261,453対であった．しかし約半数以上に対して
確率値を付与できなくて，削除されていることがわかる．また，提案法におけ
るフレーズテーブルのフレーズ数は，ベースラインと比較すると約2割増加して
いる．

確率が付与された翻訳対の例を表\ref{tbl:確率値が付与された翻訳対の例}に示す．


\subsection{実験結果　翻訳精度の評価}
\label{subsec:翻訳精度の評価}

\begin{enumerate}
\item{自動評価}

日英翻訳のテストデータには，単文1,000文と重複文1,000文を用いる．ベー
スラインと提案手法の翻訳精度の自動評価の結果を表\ref{tbl:日英翻訳の実験結果（テストデータ1,000文）}に示す．

結果から，単文，重複文のいずれの翻訳においても提案手法の翻訳精度が向
上していることが分かる．

\begin{table}[b]
\caption{確率値が付与された翻訳対の例}
\label{tbl:確率値が付与された翻訳対の例}
\input{09table12.txt}
\end{table}
\begin{table}[b]
\caption{実験結果（テストデータ1,000文）}
\label{tbl:日英翻訳の実験結果（テストデータ1,000文）}
\input{09table13.txt}
\end{table}
\begin{table}[b]
\caption{対比較実験の結果}
\label{tbl:対比較実験の結果}
\input{09table14.txt}
\end{table}


\item{人間による対比較実験}
\label{sec:対比較実験}

表\ref{tbl:日英翻訳の実験結果（テストデータ1,000文）}の日英翻訳結果からラン
ダムに抽出した100文に対して，人間による対比較実験を行う．
対比較実験において，
ベースラインの翻
訳結果の方が，優れていると評価した文を，``提案手法 ×''とする．提案手法
の翻訳結果が，ベースラインの翻訳結果より優れていると評価した文を，``提案
手法 ○''とする．また，ベースラインと提案手法で翻訳結果が変化しなかった文
を``変化無し''とする．
対比較実験の結果を表\ref{tbl:対比較実験の結果}に示す．



結果から，全ての翻訳において，提案手法が優れている割合が高くなっている
ことが分かる．

\end{enumerate}



翻訳対の翻訳確率の重みの最適化
\label{sec:翻訳対の翻訳確率の重みの最適化}


\ref{翻訳実験の結果}章の実験では，手作業によって作成した翻訳対
に，パラメータintersectionで作成した翻訳確率を付与した．しかし，手作業
で作成された翻訳対は信頼性が高いと考えられる．そこで，翻訳対に付与する
翻訳確率の重みを大きくした方が翻訳精度が向上すると考えられる．そこで，
翻訳対に付与する翻訳確率の重みを大きくした実験を行う．


\subsection{翻訳確率の重みを変えた翻訳実験}

単文および重複文の翻訳実験において，手作業で作成した翻訳対の翻訳確率の
重みを2倍，4倍，8倍に変化させたときの，BLEUスコアとMETEORの変化を調査す
る．結果を表\ref{tbl:翻訳確率の重みを変化させた時の翻訳実験結果}に示す．

\begin{table}[b]
\caption{翻訳確率の重みを変化させた時の翻訳実験結果}
\label{tbl:翻訳確率の重みを変化させた時の翻訳実験結果}
\input{09table15.txt}
\end{table}
\begin{table}[b]
\caption{対比較実験の結果}
\label{tbl1:対比較実験の結果}
\input{09table16.txt}
\end{table}



日英の翻訳において，単文の翻訳時には翻訳確率の重みを2倍，重複文の翻訳
時には8倍にした時に翻訳精度がもっとも良かった．最適な翻訳確率の重みを用い
たときの提案手法の翻訳精度と，ベースラインの翻訳精度の差を比較した場合，
BLEUでは，単文で0.9\%，重複文で0.8\%向上していることがわかる．


\subsection{対比較実験}
\label{sec1:対比較実験}

表\ref{tbl:翻訳確率の重みを変化させた時の翻訳実験結果}の翻訳結果100文に
対して，表\ref{tbl:対比較実験の結果}と同じ条件で対
比較実験を行った結果を表\ref{tbl1:対比較実験の結果}に示す．

表\ref{tbl:対比較実験の結果}と比較すると，特に重複文において改善が見られる．

\subsection{対比較実験の解析}

表\ref{tbl1:対比較実験の結果}における対比較実験の例文を以下に示す．

\begin{enumerate}

\item{提案手法が優れている例}

提案手法が優れていると評価した例を
表\ref{tbl1:対比較実験の結果 提案手法が優れていると評価した例（日英翻訳の単文）}
に示す．


\begin{table}[b]
\caption{提案手法が優れていると評価した例}
\label{tbl1:対比較実験の結果 提案手法が優れていると評価した例（日英翻訳の単文）}
\input{09table17.txt}
\end{table}



\item{提案手法が劣っていると評価した例}

提案手法が劣っていると評価した例を
表\ref{tb11:対比較実験の結果 提案手法が劣ると評価した例（日英翻訳の単文）}に示す．


\end{enumerate}

\begin{table}[t]
\caption{提案手法が劣ると評価した例}
\label{tb11:対比較実験の結果 提案手法が劣ると評価した例（日英翻訳の単文）}
\input{09table18.txt}
\end{table}



\subsection{パラメータを最適化した翻訳実験}

\begin{enumerate}

\item{パラメータの最適化}

通常，統計翻訳においては，翻訳精度の向上を目的として，パラメータの最適
化を行う．この節では，パラメータの最適化を行ったときの，提案方法の
有効性を調査する．パラメータの最適化には，Minimum Error Rate
Training (MERT)~\cite{mert} を用いる．尚，フレーズテーブルの作成には
mosesに付属しているtrain-factored-phrase-model.perlを用いる．ま
た，reorderingモデルも組み込む．

\item{developmentデータ}

developmentデータは，単文の実験も重複文の実験も，テストデータ
（\ref{sec:testdata}節）と同一の辞書から抽出したデータを利用する．単文
の翻訳実験には，developmentデータに単文100文を使用してパラメータの最適
化を行う．重複文の翻訳実験にはdevelopmentデータに重複文1,000文を使用し
てパラメータの最適化を行う．


\item{翻訳実験の結果}

翻訳実験の結果を表\ref{tbl:最適化したパラメータを用いた実験結果}に示す．



表{\ref{tbl:最適化したパラメータを用いた実験結果}}の結果から，パラメー
タの最適化を行った翻訳実験においても，BLEUが単文において0.9\%，重複文に
おいて0.2\%上昇し，提案手法の有効性が示された．

\end{enumerate}

\begin{table}[t]
\caption{パラメータチューニングを行った実験結果}
\label{tbl:最適化したパラメータを用いた実験結果}
\input{09table19.txt}
\end{table}




考察

\subsection{提案手法の効果の分析}

表\ref{sec1:対比較実験}の対比較実験の結果において，翻訳結果が変化した78文
中，58文が提案手法が優れていると評価した．この評価の理由として，妥当な語
順による向上と未知語の減少に分けることが出来る．以下にその分析結果を述べ
る．

\begin{enumerate}

\item{妥当な語順による向上}

提案手法の翻訳結果がベースラインと比較して，妥当な語順となって文質が
向上したと判断した例を表\ref{tbl:妥当な語順の例 日英翻訳}に示す．


\item{未知語の減少}

未知語が減少したことにより翻訳精度が向上した例を表\ref{tbl:未知語が減少
した例 日英翻訳}に示す．



\item{妥当な語順になった文と未知語が減少した文の比較}

提案手法が優れていると評価した58文において，未知語が減少した文数と，妥当
な語順になった文数を表\ref{tbl:文質が向上した文数と未知語が減少した文数の
比較}に示す．


表\ref{tbl:文質が向上した文数と未知語が減少した文数の比較}から， 約8割
の文が，未知語の減少よりも妥当な語順になって翻訳精度が向上していると判
断された．つまり，提案手法の有効性は，主に妥当な語順になった文の増加に
あると言える．

\end{enumerate}

\begin{table}[t]
\caption{妥当な語順による向上例}
\label{tbl:妥当な語順の例 日英翻訳}
\input{09table20.txt}
\end{table}





\subsection{今後の課題}

今後の課題として，以下の項目がある．

\begin{enumerate}

\item{手作業で作成された翻訳対の翻訳確率の最適化}

手作業で作成された翻訳対は信頼性が高いため，翻訳確率値が大きい方が，高
い翻訳精度が得られると考え，第\ref{sec:翻訳対の翻訳確率の重みの最適化}
章において翻訳対に付与した翻訳確率の重みを変化させて翻訳実験を行った．
この結果，翻訳精度が向上した（表\ref{tbl:翻訳確率の重みを変化させた時の
  翻訳実験結果}）．しかし，重みを大きすぎると翻訳精度が低下した．この結
果から，重みの最適化が必要であると考えている．そ
して，この重みの最適化にMERTが使用できると考えている．

\item{翻訳確率値を付与できなかった翻訳対の追加}

本研究では約26万個の手作業で作成された翻訳対のうち，約13万個の翻訳対に
翻訳確率値を付与できた．そして，翻訳確率値を付与できなかった翻訳対約13
万個は，削除した．そこで，翻訳確率値を付与できなかった翻訳対約13万個に
対して，翻訳確率として閾値を与えて，翻訳実験を行った．しかし，どのよう
な閾値を与えても，BLEU, METEORともに低下した．今後，確率を付与できなかっ
た翻訳対の，確率の付け方を考えてみたい．


\item{述語節に関する翻訳対の追加}

翻訳において，述語節が正しく翻訳されているか否かは，人間の評価において
重要な判断要素となりやすい．つまり，述語節が正しく翻訳されると，文の意
味が分かりやすくなり，人間による翻訳精度の評価が向上する，そこで，今後
は特に，述語節に関する翻訳対を追加し，翻訳精度の調査を行いたいと考えて
いる．また，英辞郎~\cite{eijiro}には，手作業によって作成された200万以上
の日英の翻訳対がある．これを利用することでさらに翻訳精度が向上すると考
えている．

\end{enumerate}

\begin{table}[t]
\caption{未知語が減少した例}
\label{tbl:未知語が減少した例 日英翻訳}
\input{09table21.txt}
\end{table}
\begin{table}[t]
\caption{妥当な語順になった文数と未知語が減少した文数の比較}
\label{tbl:文質が向上した文数と未知語が減少した文数の比較}
\input{09table22.txt}
\end{table}


