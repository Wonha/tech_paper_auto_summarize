\section{はじめに}
一つ一つの単語はしばしば複数の品詞（即ち, 品詞の曖昧性）を持
ち得る. しかしながら, その単語が一
旦文に組み込まれば, 持ち得る品詞はその前後の品詞によって唯一に決まる場合が多い. 
品詞のタグづけはこのような曖昧性を文脈を用いることによって除去することである.

品詞タグづけの研究は, 特に英語や日本語などにおいて多数行なわれてきた. これら
の研究を通じ, これまで
主に四つのアプローチ, 即ち, ルールベースによるもの~\cite{garside,hindle,brill},
HMMやn-gramを用い
た確率モデルに基づいたもの~\cite{church,derose,cutting,weischedel,merialdo,schutze}, 
メモリベースのもの~\cite{daelemans:96,marquez},
そしてニューラルネットを用いたもの~\cite{nakamura,schmid,ma}が提案された. 
これらの研究では, 
大量の訓練データ（例えば\cite{schmid}においては1,000,000個のデータ）
を用いれば, そのいずれの手法を用いても,
未訓練データへのタグづけを95\%以上の正解率で行なえることを示した.
しかしながら, 実際, 英語や日本語などを除いた数多くの言語（例えば本稿で取
り上げたタイ語）に関しては, コーパス自体もまだ整備段階にあるのが現状で, 
予め大量の訓練データを得るのが困難である.
従って, これらの言語にとっては, 
如何に少ない訓練データで十分実用的で高い正解率の品詞タグづけシステ
ムを構築するかが重要な課題となる.

これまで提案された確率モデルやニューラルネットモデルのほとんどはタグづけ
に長さが固定の文脈を用いるものであり（HMMモデルにおいても状態遷移を定義す
るのに固定されたn-gramベースのモデルを用いる）, 入力の各構成部分は同一の
影響度を持つものとされていた. 
しかし, 訓練データが少ない場合, タグづけ結果の確信度を高めるために, まず
できるだけ長い文脈を用い, 訓練データの不足から確定的な答えが出ない場合
に順次文脈を短くするといった
ようにフレキシブルにタグづけすることが必要とされよう. そして, 
客観的な基準で入力の各構成部分の品詞タグづけへの影響度を計り, 
その影響度に応じた重みをそれぞれの構成部分に与えればより望ま
しいであろう.
そこで, シンプルで効果的と思われる解決法は
マルチモジュールモデルを導入することである.
マルチモジュールモデルとは, 複数のそれぞれ異なった長さの文脈を入力
としたモジュールとそれらの出力を選別するセレクターから構成されるシステム
のことである. しかし, このようなシステムを例えば確率モデルや
メモリベースモデルで実現しようとすると, それぞれ以下に述べる不具合が生じる.
確率モデルは, 比較的短い文脈を用いる場合には, 必要とされるパラメターの数
はそれほど多くならない. しかし, ここで提案しているような複数のモジュール
を場合に応じて使い分けるようなシステムでは, ある程度の長さの文脈を用いる
ことが必要となり, 確率モデルのパラメターの数が膨大になる.
例えば, 品詞が50種類ある言語を左右
最大三つの単語の情報を文脈としてタグづけを行なう場合,
その最長文脈を入力としたn-gramベース確率モデルにおいては,
サイズが$50^7=7.8 \times 10^{11}$のn-gramテーブルを用意しなければならない. 
一方, IGTreeのようなメモリベースモデル
\cite{daelemans:96}においては, 品詞タグづけに実際に用いる特徴の数
はそのツリーを張るノード（特徴）の範囲内で可変であり, 各特徴のタグ
づけへの影響度もそれらを選択する優先順位で反映される. しかしながら, 
特徴の数を大きく取った場合, この手法によるタグづけの計算コストが非常にかかっ
てしまうケースが生じる. 実際, Daelmansらのモデル~\cite{daelemans:96}においては
ノードの数は僅か４に設定されており, 実質的に固定長さの文脈を用いていると
見てもよい.

本稿では, 複数のニューラルネットで構成されるマルチニューロタガーを提案す
る. 品詞のタグづけは, 長さが固定の文脈を用いるのではなく, 
最長文脈優先でフレキシブルに行なわれる. 個々のニューラルネットの訓練は
それぞれ独立に行なわれるのではなく, 短い文脈での訓練結果（訓練で獲得した
重み）を長い文脈での訓練の初期値として使う. その結果, 訓練時間が大幅に短
縮でき, 複数のニューラルネットを用いても訓練時間はほとんど変わらない.
タグづけにおいては, 目標単語自身の影響が最も強く, 前後の単語もそれぞれ
の位置に応じた影響度を持つことを反映させるために,
入力の各構成部分は情報量最大を考慮して訓練デー
タから得られるインフォメーションゲイン（略してIGと呼ぶ）を影響度として
重み付けられる, その結果, 訓練時間が更に大幅に短縮され, タグづけの性能も
僅かながら改善される. 計算機実験の結果, マルチニューロタガーは,
8,322文の小規模タイ語コーパスを訓練に用いることにより, 
未訓練タイ語データを94\%以上の正解率でタグづけすることができた.
この結果は, どの固定長さの文脈を入力としたシングルニューロタガーを用いた
場合よりも優れ, マルチニューロタガーはタグづけ過程において動的に適切な長
さの文脈を見つけていることを示した. 

以下, ２章では品詞タグづけ問題の定式化, ３章ではインフォメーションゲイン
（IG）
の求め方,  ４章ではマルチニューロタガーのアーキテクチャ, そして５章では計算
機実験の結果について順に述べていく.

