最大エントロピー法（ME法）を用いた学習および分類実験

テキストの自動分類には，1) テキストの表層的な統計情報を用いた手法と，
2) シソーラスや辞書など人手で作成された言語知識の意味体系を用いた手法
がある．上述のとおり，現在のところ，回答の意図を知るための，意図と表現
形式を結びつけるような意味体系は存在しない．したがって，本研究では
\fig{figure3}に示したように，表層的な統計情報を用いて，前章で決定した
意図タグを自由回答テキストの分類先とする分類実験を行う．

\begin{figure}[t]
\begin{center}
\leavevmode
\epsfile{file=clip003.eps,width=.6\columnwidth}
\caption{自由回答の自動分類に関するシステム設計}
\label{fig:figure3}
\end{center}
\end{figure}

本章では，意図タグ付き正解データから各意図タグの特徴表現である素性とし
てのN-gramを自動抽出し，さらに意図タグ付き正解データから，素性を付与し
た訓練データを自動的に作成する方法について説明する．訓練データから統計
情報を学習する際には，最大エントロピー法を用いる．学習によるテキスト分
類の研究には，決定木を使ったものもあるが\cite{nakano:98}，本研究では，
高い精度を安定して出せることが期待できる最大エントロピー法を使っている．
しかし，今回，学習アルゴリズムを替えての精度比較は行っていない．自由回
答テキストの自動分類の可能性を確認する目的で利用している．以下，
\fig{figure3}の流れに従って，学習と分類実験について述べる．

\subsection{素性の抽出と訓練データの作成}
\label{ssec:data_preparation}

\ssec{answer}で説明した意図タグ付き正解データからN-gram抽出によって素
性を取り出す．後で詳しく述べるが，素性はME法によって学習される意図タグ
付き正解データにおいて，各意図タグを付与された回答文の特徴にあたる．素
性として，1〜15文字までの任意の連続文字列（N-gram）を使い，意図分類の
キーになるような表現を学習によって取り出している．例えば，「要望・提案」
という意図タグのついた「徹底的に違法駐車の取り締まりを行うべき」という
例文では，「徹／徹底／徹底的／...／底／底的／...／うべき／べ／べき／き」
などが素性として自動的に取り出される．また，文末情報は重要であると判断
し，文末に「\$」を挿入している．つまり文末の文字列は，文中の文字列と区
別してとらえることができる（例「のでは\$」）．また，文末の句点の有無は
回答によって異なるので，書式を統一させるために省いている．実際には，
912文の意図タグ付き正解データに現れた，5回以上出現のすべてのN-gramを素
性として約300種類（平均282個）を用意した．対象とした学習データのデータ
量が少ないため，5回以上出現の素性に絞っている．

ME法を用いた学習部への入力データとなる訓練データは，意図タグつき正解デー
タに対して，ここで抽出された素性が各文に出現しているかどうかを自動的に
調べその結果を表としたものである．\tab{training_data}に示すように，人
手で付与されたタグが1または0の値で表されている．回答テキストの事例に対
して該当する意図タグが1，そうでないタグは0である．意図タグは一回答文に
対して一つ付与されているため，1の値が複数与えられることはない．右側の
項目列はN-gram抽出によって取り出された素性で，事例の中に現れていれば1，
そうでなければ0が与えられる．


\begin{table}[t]
\begin{center}
\leavevmode
\caption{訓練データ例}
\label{tab:training_data}
\begin{tabular}{l|c@{}c@{}c@{}c@{}c@{}c|c@{}c@{}c@{}c@{}c@{}c@{}c@{}c}
\multicolumn{1}{c|}{事例}
&\multicolumn{6}{c|}{意図タグ}
&\multicolumn{8}{c}{素性}\\
&メ, &賛, &反, &要, &事, &疑
&Cさん, &に賛成\$, &賛, &べき\$, &締, &の, &です, &ていま \\ \hline \hline
Aさんに賛成です．
&0 &1 &0 &0 &0 &0
&0 &1 &1 &0 &0 &0 &1 &0 \\ \hline
Cさんの意見に賛成．
&0 &1 &0 &0 &0 &0
&1 &1 &1 &0 &0 &1 &0 &0 \\ \hline
違法駐車の取り締まりを行うべき．
&0 &0 &0 &1 &0 &0
&0 &0 &0 &1 &1 &1 &0 &0 \\ \hline
ドイツの厳格さを見習うべきである．
&0 &0 &0 &1 &0 &0
&0 &0 &0 &1 &0 &1 &0 &0 \\ \hline
事故が増えています．
&0 &0 &0 &0 &1 &0
&0 &0 &0 &0 &0 &0 &0 &1 \\
\multicolumn{15}{c}{:}
\end{tabular}
\end{center}
\end{table}


素性としてN-gramを抽出した理由は，新聞記事と異なり自由回答テキストには
表現形式に個人差や表現のゆれなどが現れやすいためである．例えば「〜しな
ければならない」という表現に対して，等価の意味の「しなくてはならない」
だけでなく，自由回答テキストでは「しなくちゃならない」「しなきゃならな
い」「しなくては」「しなきゃ」「しなければ」など様々な表現のバリエーショ
ンが回答に現れるため，あらかじめ形態素辞書などに登録しておくことが難し
い．なお，N-gramを用いたテキスト分類には，Eメールの分類を目的にした研
究がある\cite{cavnar:94}．メールにおけるスペルミスや文法誤り，またOCR 
でテキストを読み込む際の認識誤りなどに対処するためにN-gramが利用されて
いる．

\subsection{ME法による学習}
\label{ssec:learning}
この節では自由記述テキストの各回答文（事例）に付与するべき意図タグの尤
もらしさを計算するモデルについて述べる．われわれはこのモデルをMEモデル
として実装した．

MEモデルでは，確率分布の式は以下のように求められる．文脈の集合を$B$，
出力値の集合を$A$とするとき，文脈$b (\in B)$で出力値$a (\in A)$となる
事象$(a,b)$の確率分布$p(a,b)$をMEにより推定することを考える．出力値$a$
は$n$個の出力値$a_{i}~(1 \le i \le n)$のいずれかであるとし，文脈$b$は
$k$ 個の素性$f_{j}~(1 \le j \le k)$の集合で表す．そして，文脈$b$におい
て，素性$f_{j}$が観測されかつ出力値$a$が$a_{i}$となるときに1を返す以下
のような関数を定義する．


\begin{eqnarray*}
g_{i,j}(a,b) &= &\left\{\begin{array}{ll}
1 & ({\rm if}~exist(b,f_{j})=1~~\&~~a=a_{i}) \\
0 & (それ以外) \\
\end{array} \right.
\end{eqnarray*}

これを素性関数と呼ぶ．ここで，$exist(b, f_{j})$は，文脈$b$において素性
$f_{j}$が観測される場合に1を返す関数とする．われわれの場合，素性として
は文を構成するN-gramを用いる．例えば，素性関数として次のようなものを用
いる．詳しくは次節で述べる．


\begin{eqnarray*}
g_{i,j} &= &\left\{\begin{array}{ll}
1 & ({\rm if}~exist(b,f_{j})=1,~f=$``さんに賛成''$~~\&~~a=$``賛成''$) \cr
0 & (それ以外) \\
\end{array} \right.
\end{eqnarray*}

次に，それぞれの素性が既知のデータ中に現れた割合は未知のデータも含む全
データ中においても変わらないとする制約を加える．つまり，推定するべき確
率分布$p(a,b)$による素性$f_{j}$の期待値と，既知データにおける経験確率
分布$\tilde{p}(a,b)$による素性$f_{j}$の期待値が等しいと仮定する．これ
は以下の制約式で表せる．

\begin{eqnarray*}
\sum_{a \in A, b \in B} p(a,b)\,g_{i,j}(a,b) &= &\sum_{a \in A, b \in B}
\tilde{p}(a,b)\,g_{i,j}(a,b)~~~for~~ \forall i \forall j
\end{eqnarray*}

この式で，$p(a,b)=p(b)\,p(a|b)=\tilde{p}(b)\,p(a|b)$という近似を行い以
下の式を得る．

\begin{eqnarray}
\sum_{a \in A, b \in B} \tilde{p}(b)\,p(a|b)\,g_{i,j}(a,b) &= &\sum_{a
\in A, b \in B}\tilde{p}(a,b)\,g_{i,j}(a,b)~~~for~~\forall i \forall j
\label{eq:eq4}
\end{eqnarray}
ここで，$\tilde{p}(b)$，$\tilde{p}(a,b)$は，$freq(b)$，$freq(a,b)$をそ
れぞれ既知データにおける事象$b$の出現頻度，出力値$a$と事象$b$の共起頻
度として以下のように推定する．

\begin{eqnarray*}
\tilde{p}(b) &= &\frac{freq(b)}{\sum_{b \in B}freq(b)}
\end{eqnarray*}

\begin{eqnarray*}
\tilde{p}(a,b) &= &\frac{freq(a,b)}{\sum_{a \in A,b \in B}freq(a,b)}
\end{eqnarray*}
次に，\eq{eq4}の制約を満たす確率分布$p(a,b)$のうち，エントロピー

\begin{eqnarray*}
H(p) &= &-\sum_{a \in A, b \in B}\tilde{p}(b)\,p(a|b)\,\log(p(a,b))
\end{eqnarray*}
を最大にする確率分布を推定するべき確率分布とする．これは，\eq{eq4}の制
約を満たす確率分布のうちで最も一様な分布となる．このような確率分布は唯
一存在し，以下の確率分布$p^{\ast}$として記述される．

\begin{eqnarray}
p^{\ast}(a|b) =
\frac{\prod_{i,j}\alpha_{i,j}^{g_{i,j}(a,b)}}{Z_{\alpha}(b)}~~~(0<\alpha_{i,j}\le\infty)
\label{eq:eq8}
\end{eqnarray}

\begin{eqnarray*}
Z_{\alpha}(b) &= &\sum_{a}\prod_{i,j}\alpha_{i,j}^{g_{i,j}(a,b)}
\end{eqnarray*}
ただし，

\begin{eqnarray*}
\alpha_{i,j} &= &e^{\lambda_{i,j}}
\end{eqnarray*}
であり，$\lambda_{i,j}$は素性関数$g_{i,j}(a,b)$の重みである．この重み
は文脈$b$のもとで出力値$a$となることを予測するのに素性$f_{j}$がどれだ
け重要な役割を果たすかを表している．訓練集合が与えられたとき，
$\lambda_{i,j}$の推定にはImproved Iterative Scaling（IIS）アルゴリズム
\cite{pietra:95}が用いられる．ここでは，\eq{eq8}の導出については文献
\cite{berger:96,jaynes:59,jaynes:79}などを参照されたい．

\subsection{実験方法}

ここでは，実験の概要について説明する．\ssec{data_preparation}で説明し
た訓練データを入力として，ME法を用い，任意の入力に対して各意図タグが分
類先となる確率を学習する．分類実験では，912文の実験データに対して
N-gram抽出を行い，抽出したN-gramを素性として利用する．意図タグが分類先
となる確率の学習結果を用いて，その確率値がもっとも大きい意図タグを解と
する．

分類先の決定方法について述べる．着目する回答文にどの意図タグが付与され
るべきかについては，あらかじめ設定された閾値$\alpha$よりも解の確信度が
高いか等しい場合に，着目する意図タグを分類先とする．閾値は，0から1まで
の値をとる．解の確信度は，ME法で分類先を決定する際に算出される確率
$\beta$とする．すなわち，分類を決めるための判定条件は$\beta \ge
\alpha$ であり，この条件を満たす場合に解とする．解析結果のうち，もっと
も確率の値が大きい分類を解とする．\\
データ量が十分でないため，10分割のクロスバリデーションによる評価を行っ
ている．

\subsection{実験結果}

前節で述べたとおり，意図タグ付き正解データを訓練データとした学習結果を
用いて意図タグの分類実験を行った．結果は\tab{result}に示すとおりである．
\tab{result}は，実験方法を説明する際に述べた閾値が0の結果である．最左
列には分類先の意図タグが記されており，各意図タグに対する適合率および再
現率が示されている．タグ名の「要提」は「要望・提案」の略記である．意図
タグ全体に対するタグ付与結果は，再現率・適合率ともに76\,\%の精度が得られ
た．再現率は実験結果の正解数を意図タグ付き正解データのデータ数で割った
もの，適合率は実験結果の正解数をシステムが出力したデータ数で割ったもの
を示している．

ここで，意図タグのうち，もっとも頻度の高い事実タグの正解データ数420件
をデータ総数912件で割った値，すなわちすべてに事実というタグを付与した
際の正解の割合をベースラインとみなす．この場合，ベースラインの精度は 
46\,\%となる．われわれの手法の精度は76\,\%であったので，この手法はベースラ
インより精度が高いことがわかる．

疑問タグは適合率が81.3\,\%と比較的高い値が出ているのに対し，再現率は55.3
\,\%とやや低い．また，事実タグでは再現率に高い値が見られる．これらについ
ては後で考察する．四列目からは各意図タグの分類先の個数が示されている．
同じ意図タグの行と列が交差するセルに正しく分類された個数が示されている．
この誤りの傾向については，\sec{consideration}で考察する．


\begin{table}[t]
\begin{center}
\leavevmode
\caption{実験結果}
\label{tab:result}
\begin{tabular}{|l|r|r||r|r|r|r|r|r||r|}
\hline
&\multicolumn{1}{c|}{再現率(\%)}
&\multicolumn{1}{c||}{適合率(\%)}
&\multicolumn{1}{c|}{メタ}
&\multicolumn{1}{c|}{賛成}
&\multicolumn{1}{c|}{反対}
&\multicolumn{1}{c|}{要提}
&\multicolumn{1}{c|}{疑問}
&\multicolumn{1}{c||}{事実}
&\multicolumn{1}{c|}{正解データ}
\\ \hline \hline
メタ &0 &0 &0 &1 &0 &6 &0 &9 &16 \\ \hline
賛成 &83.3 &83.3 &0 &40 &0 &4 &0 &4 &48 \\ \hline
反対 &0 &0 &0 &4 &0 &2 &0 &7 &13 \\ \hline
要提 &77.7 &76.3 &0 &2 &1 &286 &4 &75 &368 \\ \hline
疑問 &55.3 &81.3 &0 &0 &0 &7 &26 &14 &47 \\ \hline
事実 &81.9 &75.9 &3 &1 &0 &70 &2 &344 &420 \\ \hline
\hline
総数 &76.3 &76.3 &3 &48 &1 &375 &32 &453 &912 \\ \hline
\end{tabular}
\end{center}
\end{table}


\begin{figure}[t]
\begin{center}
\leavevmode
\epsfile{file=clip004.eps,width=.6\columnwidth}
\caption{実験結果の再現率と適合率}
\label{fig:figure4}
\end{center}
\end{figure}

\begin{figure}[t]
\begin{center}
\leavevmode
\epsfile{file=clip005.eps,width=.6\columnwidth}
\caption{下位分類タグの分類結果}
\label{fig:figure5}
\end{center}
\end{figure}

\fig{figure4}のグラフは，閾値を0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,
0.8, 0.9, 0.95, 0.98, 0.99とした場合の再現率と適合率を示している．閾値
を上げることにより，再現率が下がり適合率は上がっている．また，
\fig{figure5}に示すように，意図タグの下位分類については賛成および反対
が誰に対するものかを区分した「個人」「政策」のうち，閾値が0の際の再現
率および適合率が96.7\,\%（\fig{figure5}のC1），要望・提案の具体性・抽象
性を区分した
「具体」「抽象」の再現率および適合率が70.7\,\%（\fig{figure5}のC2），事
実の捉え方を区分した「ネガティブ」「ポジティブ」「中立」の再現率および
適合率が64.5\,\%（\fig{figure5}のC3），また，事実が事実的認識を述べたも
のか，回答者の主張であるかを区別した「事実」「事実（主張）」の再現率お
よび適合率が57.9\,\%（\fig{figure5}のC4）であった．

