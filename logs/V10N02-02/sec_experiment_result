テキストの自動分類には，1)テキストの表層的な統計情報を用いた手法と，2)シソーラスや辞書など人手で作成された言語知識の意味体系を用いた手法がある．
上述のとおり，現在のところ，回答の意図を知るための，意図と表現形式を結びつけるような意味体系は存在しない．
したがって，本研究では\fig{figure3}に示したように，表層的な統計情報を用いて，前章で決定した意図タグを自由回答テキストの分類先とする分類実験を行う．
本章では，意図タグ付き正解データから各意図タグの特徴表現である素性としてのN-gramを自動抽出し，さらに意図タグ付き正解データから，素性を付与した訓練データを自動的に作成する方法について説明する．
訓練データから統計情報を学習する際には，最大エントロピー法を用いる．
学習によるテキスト分類の研究には，決定木を使ったものもあるが[CITE]，本研究では，高い精度を安定して出せることが期待できる最大エントロピー法を使っている．
しかし，今回，学習アルゴリズムを替えての精度比較は行っていない．
自由回答テキストの自動分類の可能性を確認する目的で利用している．
以下，\fig{figure3}の流れに従って，学習と分類実験について述べる．
\ssec{answer}で説明した意図タグ付き正解データからN-gram抽出によって素性を取り出す．
後で詳しく述べるが，素性はME法によって学習される意図タグ付き正解データにおいて，各意図タグを付与された回答文の特徴にあたる．
素性として，1〜15文字までの任意の連続文字列（N-gram）を使い，意図分類のキーになるような表現を学習によって取り出している．
例えば，「要望・提案」という意図タグのついた「徹底的に違法駐車の取り締まりを行うべき」という例文では，「徹／徹底／徹底的／.
..
／底／底的／.
..
／うべき／べ／べき／き」などが素性として自動的に取り出される．
また，文末情報は重要であると判断し，文末に「$」を挿入している．
つまり文末の文字列は，文中の文字列と区別してとらえることができる（例「のでは$」）．
また，文末の句点の有無は回答によって異なるので，書式を統一させるために省いている．
実際には，912文の意図タグ付き正解データに現れた，5回以上出現のすべてのN-gramを素性として約300種類（平均282個）を用意した．
対象とした学習データのデータ量が少ないため，5回以上出現の素性に絞っている．
ME法を用いた学習部への入力データとなる訓練データは，意図タグつき正解データに対して，ここで抽出された素性が各文に出現しているかどうかを自動的に調べその結果を表としたものである．
\tab{training_data}に示すように，人手で付与されたタグが1または0の値で表されている．
回答テキストの事例に対して該当する意図タグが1，そうでないタグは0である．
意図タグは一回答文に対して一つ付与されているため，1の値が複数与えられることはない．
右側の項目列はN-gram抽出によって取り出された素性で，事例の中に現れていれば1，そうでなければ0が与えられる．
素性としてN-gramを抽出した理由は，新聞記事と異なり自由回答テキストには表現形式に個人差や表現のゆれなどが現れやすいためである．
例えば「〜しなければならない」という表現に対して，等価の意味の「しなくてはならない」だけでなく，自由回答テキストでは「しなくちゃならない」「しなきゃならない」「しなくては」「しなきゃ」「しなければ」など様々な表現のバリエーションが回答に現れるため，あらかじめ形態素辞書などに登録しておくことが難しい．
なお，N-gramを用いたテキスト分類には，Eメールの分類を目的にした研究がある[CITE]．
メールにおけるスペルミスや文法誤り，またOCRでテキストを読み込む際の認識誤りなどに対処するためにN-gramが利用されている．
この節では自由記述テキストの各回答文（事例）に付与するべき意図タグの尤もらしさを計算するモデルについて述べる．
われわれはこのモデルをMEモデルとして実装した．
MEモデルでは，確率分布の式は以下のように求められる．
文脈の集合を[MATH]，出力値の集合を[MATH]とするとき，文脈[MATH]で出力値[MATH]となる事象[MATH]の確率分布[MATH]をMEにより推定することを考える．
出力値[MATH]は[MATH]個の出力値[MATH]のいずれかであるとし，文脈[MATH]は[MATH]個の素性[MATH]の集合で表す．
そして，文脈[MATH]において，素性[MATH]が観測されかつ出力値[MATH]が[MATH]となるときに1を返す以下のような関数を定義する．
これを素性関数と呼ぶ．
ここで，[MATH]は，文脈[MATH]において素性[MATH]が観測される場合に1を返す関数とする．
われわれの場合，素性としては文を構成するN-gramを用いる．
例えば，素性関数として次のようなものを用いる．
詳しくは次節で述べる．
次に，それぞれの素性が既知のデータ中に現れた割合は未知のデータも含む全データ中においても変わらないとする制約を加える．
つまり，推定するべき確率分布[MATH]による素性[MATH]の期待値と，既知データにおける経験確率分布[MATH]による素性[MATH]の期待値が等しいと仮定する．
これは以下の制約式で表せる．
この式で，[MATH]という近似を行い以下の式を得る．
ここで，[MATH]，[MATH]は，[MATH]，[MATH]をそれぞれ既知データにおける事象[MATH]の出現頻度，出力値[MATH]と事象[MATH]の共起頻度として以下のように推定する．
次に，\eq{eq4}の制約を満たす確率分布[MATH]のうち，エントロピー
を最大にする確率分布を推定するべき確率分布とする．
これは，\eq{eq4}の制約を満たす確率分布のうちで最も一様な分布となる．
このような確率分布は唯一存在し，以下の確率分布[MATH]として記述される．
ただし，
であり，[MATH]は素性関数[MATH]の重みである．
この重みは文脈[MATH]のもとで出力値[MATH]となることを予測するのに素性[MATH]がどれだけ重要な役割を果たすかを表している．
訓練集合が与えられたとき，[MATH]の推定にはImproved Iterative Scaling（IIS）アルゴリズム[CITE]が用いられる．
ここでは，\eq{eq8}の導出については文献[CITE]などを参照されたい．
ここでは，実験の概要について説明する．
\ssec{data_preparation}で説明した訓練データを入力として，ME法を用い，任意の入力に対して各意図タグが分類先となる確率を学習する．
分類実験では，912文の実験データに対してN-gram抽出を行い，抽出したN-gramを素性として利用する．
意図タグが分類先となる確率の学習結果を用いて，その確率値がもっとも大きい意図タグを解とする．
分類先の決定方法について述べる．
着目する回答文にどの意図タグが付与されるべきかについては，あらかじめ設定された閾値[MATH]よりも解の確信度が高いか等しい場合に，着目する意図タグを分類先とする．
閾値は，0から1までの値をとる．
解の確信度は，ME法で分類先を決定する際に算出される確率[MATH]とする．
すなわち，分類を決めるための判定条件は[MATH]であり，この条件を満たす場合に解とする．
解析結果のうち，もっとも確率の値が大きい分類を解とする．
データ量が十分でないため，10分割のクロスバリデーションによる評価を行っている．
前節で述べたとおり，意図タグ付き正解データを訓練データとした学習結果を用いて意図タグの分類実験を行った．
結果は\tab{result}に示すとおりである．
\tab{result}は，実験方法を説明する際に述べた閾値が0の結果である．
最左列には分類先の意図タグが記されており，各意図タグに対する適合率および再現率が示されている．
タグ名の「要提」は「要望・提案」の略記である．
意図タグ全体に対するタグ付与結果は，再現率・適合率ともに76 %の精度が得られた．
再現率は実験結果の正解数を意図タグ付き正解データのデータ数で割ったもの，適合率は実験結果の正解数をシステムが出力したデータ数で割ったものを示している．
ここで，意図タグのうち，もっとも頻度の高い事実タグの正解データ数420件をデータ総数912件で割った値，すなわちすべてに事実というタグを付与した際の正解の割合をベースラインとみなす．
この場合，ベースラインの精度は46 %となる．
われわれの手法の精度は76 %であったので，この手法はベースラインより精度が高いことがわかる．
疑問タグは適合率が81.3 %と比較的高い値が出ているのに対し，再現率は55.3  %とやや低い．
また，事実タグでは再現率に高い値が見られる．
これらについては後で考察する．
四列目からは各意図タグの分類先の個数が示されている．
同じ意図タグの行と列が交差するセルに正しく分類された個数が示されている．
この誤りの傾向については，\sec{consideration}で考察する．
\fig{figure4}のグラフは，閾値を0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98, 0.99とした場合の再現率と適合率を示している．
閾値を上げることにより，再現率が下がり適合率は上がっている．
また，\fig{figure5}に示すように，意図タグの下位分類については賛成および反対が誰に対するものかを区分した「個人」「政策」のうち，閾値が0の際の再現率および適合率が96.7 %（\fig{figure5}のC1），要望・提案の具体性・抽象性を区分した「具体」「抽象」の再現率および適合率が70.7 %（\fig{figure5}のC2），事実の捉え方を区分した「ネガティブ」「ポジティブ」「中立」の再現率および適合率が64.5 %（\fig{figure5}のC3），また，事実が事実的認識を述べたものか，回答者の主張であるかを区別した「事実」「事実（主張）」の再現率および適合率が57.9 %（\fig{figure5}のC4）であった．
テキストの自動分類には，1)テキストの表層的な統計情報を用いた手法と，2)シソーラスや辞書など人手で作成された言語知識の意味体系を用いた手法がある．
上述のとおり，現在のところ，回答の意図を知るための，意図と表現形式を結びつけるような意味体系は存在しない．
したがって，本研究では\fig{figure3}に示したように，表層的な統計情報を用いて，前章で決定した意図タグを自由回答テキストの分類先とする分類実験を行う．
本章では，意図タグ付き正解データから各意図タグの特徴表現である素性としてのN-gramを自動抽出し，さらに意図タグ付き正解データから，素性を付与した訓練データを自動的に作成する方法について説明する．
訓練データから統計情報を学習する際には，最大エントロピー法を用いる．
学習によるテキスト分類の研究には，決定木を使ったものもあるが[CITE]，本研究では，高い精度を安定して出せることが期待できる最大エントロピー法を使っている．
しかし，今回，学習アルゴリズムを替えての精度比較は行っていない．
自由回答テキストの自動分類の可能性を確認する目的で利用している．
以下，\fig{figure3}の流れに従って，学習と分類実験について述べる．
\ssec{answer}で説明した意図タグ付き正解データからN-gram抽出によって素性を取り出す．
後で詳しく述べるが，素性はME法によって学習される意図タグ付き正解データにおいて，各意図タグを付与された回答文の特徴にあたる．
素性として，1〜15文字までの任意の連続文字列（N-gram）を使い，意図分類のキーになるような表現を学習によって取り出している．
例えば，「要望・提案」という意図タグのついた「徹底的に違法駐車の取り締まりを行うべき」という例文では，「徹／徹底／徹底的／.
..
／底／底的／.
..
／うべき／べ／べき／き」などが素性として自動的に取り出される．
また，文末情報は重要であると判断し，文末に「$」を挿入している．
つまり文末の文字列は，文中の文字列と区別してとらえることができる（例「のでは$」）．
また，文末の句点の有無は回答によって異なるので，書式を統一させるために省いている．
実際には，912文の意図タグ付き正解データに現れた，5回以上出現のすべてのN-gramを素性として約300種類（平均282個）を用意した．
対象とした学習データのデータ量が少ないため，5回以上出現の素性に絞っている．
ME法を用いた学習部への入力データとなる訓練データは，意図タグつき正解データに対して，ここで抽出された素性が各文に出現しているかどうかを自動的に調べその結果を表としたものである．
\tab{training_data}に示すように，人手で付与されたタグが1または0の値で表されている．
回答テキストの事例に対して該当する意図タグが1，そうでないタグは0である．
意図タグは一回答文に対して一つ付与されているため，1の値が複数与えられることはない．
右側の項目列はN-gram抽出によって取り出された素性で，事例の中に現れていれば1，そうでなければ0が与えられる．
素性としてN-gramを抽出した理由は，新聞記事と異なり自由回答テキストには表現形式に個人差や表現のゆれなどが現れやすいためである．
例えば「〜しなければならない」という表現に対して，等価の意味の「しなくてはならない」だけでなく，自由回答テキストでは「しなくちゃならない」「しなきゃならない」「しなくては」「しなきゃ」「しなければ」など様々な表現のバリエーションが回答に現れるため，あらかじめ形態素辞書などに登録しておくことが難しい．
なお，N-gramを用いたテキスト分類には，Eメールの分類を目的にした研究がある[CITE]．
メールにおけるスペルミスや文法誤り，またOCRでテキストを読み込む際の認識誤りなどに対処するためにN-gramが利用されている．
この節では自由記述テキストの各回答文（事例）に付与するべき意図タグの尤もらしさを計算するモデルについて述べる．
われわれはこのモデルをMEモデルとして実装した．
MEモデルでは，確率分布の式は以下のように求められる．
文脈の集合を[MATH]，出力値の集合を[MATH]とするとき，文脈[MATH]で出力値[MATH]となる事象[MATH]の確率分布[MATH]をMEにより推定することを考える．
出力値[MATH]は[MATH]個の出力値[MATH]のいずれかであるとし，文脈[MATH]は[MATH]個の素性[MATH]の集合で表す．
そして，文脈[MATH]において，素性[MATH]が観測されかつ出力値[MATH]が[MATH]となるときに1を返す以下のような関数を定義する．
これを素性関数と呼ぶ．
ここで，[MATH]は，文脈[MATH]において素性[MATH]が観測される場合に1を返す関数とする．
われわれの場合，素性としては文を構成するN-gramを用いる．
例えば，素性関数として次のようなものを用いる．
詳しくは次節で述べる．
次に，それぞれの素性が既知のデータ中に現れた割合は未知のデータも含む全データ中においても変わらないとする制約を加える．
つまり，推定するべき確率分布[MATH]による素性[MATH]の期待値と，既知データにおける経験確率分布[MATH]による素性[MATH]の期待値が等しいと仮定する．
これは以下の制約式で表せる．
この式で，[MATH]という近似を行い以下の式を得る．
ここで，[MATH]，[MATH]は，[MATH]，[MATH]をそれぞれ既知データにおける事象[MATH]の出現頻度，出力値[MATH]と事象[MATH]の共起頻度として以下のように推定する．
次に，\eq{eq4}の制約を満たす確率分布[MATH]のうち，エントロピー
を最大にする確率分布を推定するべき確率分布とする．
これは，\eq{eq4}の制約を満たす確率分布のうちで最も一様な分布となる．
このような確率分布は唯一存在し，以下の確率分布[MATH]として記述される．
ただし，
であり，[MATH]は素性関数[MATH]の重みである．
この重みは文脈[MATH]のもとで出力値[MATH]となることを予測するのに素性[MATH]がどれだけ重要な役割を果たすかを表している．
訓練集合が与えられたとき，[MATH]の推定にはImproved Iterative Scaling（IIS）アルゴリズム[CITE]が用いられる．
ここでは，\eq{eq8}の導出については文献[CITE]などを参照されたい．
ここでは，実験の概要について説明する．
\ssec{data_preparation}で説明した訓練データを入力として，ME法を用い，任意の入力に対して各意図タグが分類先となる確率を学習する．
分類実験では，912文の実験データに対してN-gram抽出を行い，抽出したN-gramを素性として利用する．
意図タグが分類先となる確率の学習結果を用いて，その確率値がもっとも大きい意図タグを解とする．
分類先の決定方法について述べる．
着目する回答文にどの意図タグが付与されるべきかについては，あらかじめ設定された閾値[MATH]よりも解の確信度が高いか等しい場合に，着目する意図タグを分類先とする．
閾値は，0から1までの値をとる．
解の確信度は，ME法で分類先を決定する際に算出される確率[MATH]とする．
すなわち，分類を決めるための判定条件は[MATH]であり，この条件を満たす場合に解とする．
解析結果のうち，もっとも確率の値が大きい分類を解とする．
データ量が十分でないため，10分割のクロスバリデーションによる評価を行っている．
前節で述べたとおり，意図タグ付き正解データを訓練データとした学習結果を用いて意図タグの分類実験を行った．
結果は\tab{result}に示すとおりである．
\tab{result}は，実験方法を説明する際に述べた閾値が0の結果である．
最左列には分類先の意図タグが記されており，各意図タグに対する適合率および再現率が示されている．
タグ名の「要提」は「要望・提案」の略記である．
意図タグ全体に対するタグ付与結果は，再現率・適合率ともに76 %の精度が得られた．
再現率は実験結果の正解数を意図タグ付き正解データのデータ数で割ったもの，適合率は実験結果の正解数をシステムが出力したデータ数で割ったものを示している．
ここで，意図タグのうち，もっとも頻度の高い事実タグの正解データ数420件をデータ総数912件で割った値，すなわちすべてに事実というタグを付与した際の正解の割合をベースラインとみなす．
この場合，ベースラインの精度は46 %となる．
われわれの手法の精度は76 %であったので，この手法はベースラインより精度が高いことがわかる．
疑問タグは適合率が81.3 %と比較的高い値が出ているのに対し，再現率は55.3  %とやや低い．
また，事実タグでは再現率に高い値が見られる．
これらについては後で考察する．
四列目からは各意図タグの分類先の個数が示されている．
同じ意図タグの行と列が交差するセルに正しく分類された個数が示されている．
この誤りの傾向については，\sec{consideration}で考察する．
\fig{figure4}のグラフは，閾値を0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98, 0.99とした場合の再現率と適合率を示している．
閾値を上げることにより，再現率が下がり適合率は上がっている．
また，\fig{figure5}に示すように，意図タグの下位分類については賛成および反対が誰に対するものかを区分した「個人」「政策」のうち，閾値が0の際の再現率および適合率が96.7 %（\fig{figure5}のC1），要望・提案の具体性・抽象性を区分した「具体」「抽象」の再現率および適合率が70.7 %（\fig{figure5}のC2），事実の捉え方を区分した「ネガティブ」「ポジティブ」「中立」の再現率および適合率が64.5 %（\fig{figure5}のC3），また，事実が事実的認識を述べたものか，回答者の主張であるかを区別した「事実」「事実（主張）」の再現率および適合率が57.9 %（\fig{figure5}のC4）であった．
