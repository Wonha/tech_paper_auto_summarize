================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.24656] 用例ベース翻訳は，これまで，経験則にもとづく指標／基準により用例を選択してきた．
[i:4, score:0.28794] さらに，本モデルは用例と入力文のコンテキストの類似度を自然に翻訳確率に取り込む拡張も可能である．
[i:5, score:0.26585] 実験の結果，本モデルを用いたシステムは，従来の経験則によるシステムの精度を僅かに上回り，用例ベース翻訳の透明性の高いモデル化を実現することに成功した．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:12, score:0.26708] 一方，統計ベース翻訳は，翻訳確率を緻密に計算するため，基本的には，翻訳用例を小さな語／句単位に分解して学習を行う．
[i:28, score:0.28855] また，提案する翻訳確率は容易に拡張可能であり，用例と入力文のコンテキストの類似度を確率モデルに取り込むことも可能である．
[i:29, score:0.26965] 実験の結果，提案手法は，従来の経験則に基づいた翻訳システムよりも僅かに高い精度を得て，用例ベース翻訳の透明性の高いモデル化を実現することに成功したので報告する．

================================================================
[section type  : proposed_method]
[section title : 提案手法]
================================================================
[i:36, score:0.23244] 用例ベース翻訳の基本的な原則はできるだけ大きなサイズの用例を用いて翻訳文を生成することである．
[i:47, score:0.24708] 次に，各部分木[MATH]それぞれについて,もっとも翻訳確率[MATH](この確率の計算方法は次節にて述べる)の高い用例を選び，それらの積を翻訳文の翻訳確率[MATH]とする:
[i:54, score:0.24776] この理由は，大きな用例は安定した翻訳先を持つ傾向にあるため，高い翻訳確率を持ち，当然，その積である翻訳文の確率[MATH]も自然と高くなるからである．
-----------------------------------------------------
  [subsection title : パラメータの推定]
-----------------------------------------------------
  [i:lead, score:0.20909] 本節では，用例の翻訳確率の推定方法を述べる．
.....
  [i:61, score:0.20909] 本節では，用例の翻訳確率の推定方法を述べる．
  [i:62, score:0.13951] まず，英語部分木[MATH]と日本語部分木[MATH]からなる用例があるとする．
  [i:63, score:0.13086] この翻訳確率[MATH]は，アライメントされたコーパス中での対応[MATH]の出現頻度を直接数えて求める:
-----------------------------------------------------
  [subsection title : 入力文と用例のコンテキストの類似度を取り込んだ確率モデル]
-----------------------------------------------------
  [i:lead, score:0.24809] 用例の選択にあたって重要な手がかりは入力文と用例の一致するサイズであり，それは，2.1節で提案された翻訳確率の枠組みで実現されている．
.....
  [i:78, score:0.25128] このフィルタリングの操作は，用例のサイズごとに翻訳確率を計算する手法を，類似度にまで拡大したものであり，自然な拡張であるといえる．
  [i:82, score:0.25420] 本節の提案手法では，用例``CDをかける''と入力文``レコードをかける''の[MATH]が0.8であるとすると，同じく0.8以上の[MATH]を持つ用例だけを用いて翻訳確率を計算する．
  [i:84, score:0.26636] このように類似したコンテキストを持つ用例の翻訳確率は自然と高くなる傾向をもつ．

================================================================
[section type  : proposed_method]
[section title : 翻訳システムの構成]
================================================================
[i:92, score:0.01329] 提案するシステムは，次の2つのモジュールから構成される：
[i:93, score:0.13048] アライメント・モジュール：コーパスから用例を構築するモジュール，
[i:94, score:0.07619] 翻訳モジュール：翻訳を行うモジュール．
-----------------------------------------------------
  [subsection title : アライメント・モジュール]
-----------------------------------------------------
  [i:lead, score:0.03107] ステップ1：対訳文の依存構造への変換
.....
  [i:106, score:0.13571] ステップ3：用例データベースの構築
  [i:107, score:0.23648] 最後に，アライメントされた対訳文（図[REF_f_te_c6_te.eps]左）から，用例データベースを構築する．
  [i:108, score:0.14973] この際，システムは，あらゆる対応の組み合わせを生成し，その周辺の句（これはコンテキストの類似度を計算する際に用いる）とともにデータベースに登録する（図[REF_f_te_c6_te.eps]右）．
-----------------------------------------------------
  [subsection title : 翻訳モジュール]
-----------------------------------------------------
  [i:lead, score:0.02121] ステップ1：入力文の解析
.....
  [i:112, score:0.31365] 入力文のあらゆる可能な部分木の組み合わせに分解し（前章の図[REF_f_prob.eps]の左），それらの部分木それぞれについて，用例データベース中を検索し，前章の手法にて，その翻訳確率を計算する．
  [i:113, score:0.21495] そして，最も翻訳確率の高くなる用例の組み合わせを採用する．
  [i:118, score:0.26023] 例えば，2つの翻訳用例（TE1，TE2）を結合して翻訳文を生成する場合を考える（図[REF_f_d1.eps]）．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
-----------------------------------------------------
  [subsection title : 実験設定]
-----------------------------------------------------
  [i:lead, score:0.22632] 提案手法の妥当性を検証するため，用例ベース翻訳システム[CITE]の用例選択部分を提案手法に置き換えて実験を行った．
.....
  [i:126, score:0.22632] 提案手法の妥当性を検証するため，用例ベース翻訳システム[CITE]の用例選択部分を提案手法に置き換えて実験を行った．
  [i:133, score:0.16228] BASIC:経験則によるメジャーにより用例を選択するシステム[CITE]．
  [i:136, score:0.21081] BASELINE:用例ベース翻訳のベースライン．
-----------------------------------------------------
  [subsection title : 評価]
-----------------------------------------------------
  [i:lead, score:0.02898] 評価は，表[REF_eval]の自動評価尺度を用い，IWSLT04[CITE]と同様の以下の条件で行った．
.....
  [i:139, score:0.02898] 評価は，表[REF_eval]の自動評価尺度を用い，IWSLT04[CITE]と同様の以下の条件で行った．
  [i:140, score:0.00822] 大文字／小文字の差異の無視．
  [i:143, score:0.01520] 数字はスペルアウトする（20,000→Twenty Thousand）．
-----------------------------------------------------
  [subsection title : 結果]
-----------------------------------------------------
  [i:lead, score:0.01577] 各手法の精度を表[REF_t1]に示す．
.....
  [i:146, score:0.23393] また，両者の精度は，商用システム(C1,C2)や用例ベース翻訳のベースライン(baseline)と比べてはるかに高く，現実的な精度上での比較であることが分かる．
  [i:161, score:0.19141] 複数の用例がみな同じアライメントの誤り方をするわけではないので，without_simは必然的にアライメント誤りの影響を受けにくいと考えられる．
  [i:164, score:0.19821] しかし，(1)アライメント誤りによる精度の低下は，モデルの定式化の妥当性とは別個の問題である点，また，(2)実験は，ドメインを絞った翻訳実験であり，コンテキストを考慮する必要性が少ない点，これらの2点を考慮すると，コンテキストの類似度の定式化の妥当性は，実験によって確かめられたと考えられる．
-----------------------------------------------------
  [subsection title : 誤り分析]
-----------------------------------------------------
  [i:lead, score:0.11390] proposedのより具体的な分析のため，proposedの翻訳結果から，100翻訳文を無作為抽出し，それらを人手でチェックした．
.....
  [i:166, score:0.11390] proposedのより具体的な分析のため，proposedの翻訳結果から，100翻訳文を無作為抽出し，それらを人手でチェックした．
  [i:167, score:0.07740] この結果，49の翻訳文が正解であり，51の翻訳文が不正解であると判定された．
  [i:173, score:0.07791] 参考までに，表[REF_翻訳例]に翻訳例と分類結果の一部を示す．
-----------------------------------------------------
  [subsection title : コーパスサイズと精度]
-----------------------------------------------------
  [i:lead, score:0.12132] 最後に，コーパスサイズ（トレーニングセットの対訳文数）と翻訳精度（BLEU）の関係について調査した．
.....
  [i:177, score:0.16245] このことから，proposedの方が用例の不足に対してより頑健であることが分かる．
  [i:178, score:0.13055] また，スコアは今回の実験の最大の用例数([MATH])で飽和していない．
  [i:179, score:0.12974] このことから，もし，より多くの用例を得ることができれば，より高い精度を得ることが期待される．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:180, score:0.27061] これまで様々な用例ベース翻訳システムが提案されてきたが，それらは経験則に基づいて用例を選択しており，提案手法のような確率的な尺度に注意を払っていない．
[i:181, score:0.22088] 例えば，[CITE]はマニュアルドメインの用例ベース翻訳システムを提案した．
[i:183, score:0.19822] [CITE]は，一致サイズとコンテキストの類似度の両方を用いて用例を選択している．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:186, score:0.24414] 本稿では，大きな用例ほど翻訳確率が高くなるという考えに基づき，翻訳確率だけを用いて用例を選択する用例ベース翻訳手法を提案した．
[i:187, score:0.18179] 実験の結果は，従来の経験則による用例選択を行うシステムよりも僅かに高い精度を得ることができ，提案手法の妥当性を示している．
[i:188, score:0.24099] 本研究により，これまで，統計ベース翻訳と比べて不透明であった用例ベース翻訳のアルゴリズムを定式化することでき，今後より一層緻密な用例ベース翻訳の議論が可能になると考えている．

