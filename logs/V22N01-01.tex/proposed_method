雑談対話の特徴
\label{sec-char-dialogs}

まず我々は，2名の参加者による雑談対話を収集し，その対話に述語項構造デー
タの付与を行った．雑談対話は，参加者が自由なテーマ（話題）を設定し，キー
ボード対話形式で収集した．したがって，音声対話に含まれるような相槌や言
い直しは少ない．参加者の話題は，食事，旅行，趣味，テレビ・ラジオなどで
ある．述語項構造アノテーションは，NAISTテキストコーパス
\cite{iida-EtAl:2007:LAW,Iida:NAISTCorpus2010j}に準拠する形で行っ
た．雑談対話と，その述語項構造解析アノテーションの例を図
\ref{fig-chat-dialog}に示す
\footnote{対話中に一人称・二人称代名詞が陽に出現する場合，アノテータに
対してexo1/exo2との区別は指示しなかった．しかし，
述語と同一発話内ではその代名詞を項に使う場合が多く，異なる発
話の場合，出現した代名詞をゼロ代名詞照応先とするのではなく
外界照応 (exo1/exo2) とする傾向が高かった．}．

\begin{figure}[b]
\input{01fig01.txt}
\caption{雑談対話とその述語項構造アノテーションの例}
\label{fig-chat-dialog}
\par\small
太字は述語，$[ ]$は文内の項，$( )$は文間の項または外界照応を表す．\\ 
また，\texttt{exo1}，\texttt{exo2}，\texttt{exog}はそれぞれ一人称／二人称ゼロ代名詞，それ以外の外界照応を表す．
\end{figure}
\begin{table}[b]
\caption{コーパスサイズ}
\label{tbl-corpus-size}
\input{01table01.txt}
\end{table}

今回作成した雑談対話コーパスと，NAISTコーパス
\footnote{NAIST コーパスはバージョン1.5を用い，文節化の前処理を行った上
で使用した．1 文節に複数の述語が含まれている場合は，前方に出現した述
語のみを対象とした．} の統計量を表\ref{tbl-corpus-size}に示す．対話コー
パスは，NAISTコーパスの約1/10のサイズである．また，1文/発話の長さ（形
態素数）は，雑談対話コーパスはNAISTコーパスの1/3程度と短い． NAISTコー
パスは，訓練，開発，テストに3分割したのに対し，対話コーパスは訓練とテス
トの2分割とした．

対話の特徴を分析するため，この 2 つのコーパスの比較を行った．表
\ref{tbl-arg-distrib}は，訓練セットにおける項の分布を示したものである．
各項は，述語との位置関係や文法関係などにより問題の難しさが異なるため，
以下の6タイプに分類した．最初の2つ（係受および文内ゼロ）は述語と項が同
じ文に存在する場合である．

\begin{table}[t]
\caption{訓練セットにおける項の分布}
\label{tbl-arg-distrib}
\input{01table02.txt}
\end{table}

\begin{itemize}
\item \textbf{係受:} 述語と項が直接の係り受け関係にある場合
\item \textbf{文内ゼロ:} 述語と項が同じ文（発話）内にあるが，直接の
係り受け関係がない場合
\item \textbf{文間ゼロ:} 述語と項が異なる文にある場合
\item \textbf{exo1/exo2/exog:} 項が記事（対話）内に存在しない外界照応．そ
れぞれ，一人称ゼロ代名詞，二人称ゼロ代名詞，それ以外（一般）を表す．
\end{itemize}

これを見ると，対話ではすべての格で，係受タイプの項が減少している．それ
以外のタイプについては，ガ格と，ヲ格ニ格で傾向が異なっている．
ガ格では，文内ゼロ代名詞も対話の場合に減少し，減少分は一人称・二人称外
界照応 (exo1, exo2) に割り当てられている．つまり，ガ格では，文内の項が
減少し，ゼロ代名詞が新聞に比べて頻発する．ただし，その先行詞は一人称・
二人称代名詞である可能性が高いと言うことができる．
ヲ格ニ格では，係受タイプの項の減少分は，文間ゼロ代名詞またはその他の外
界照応(exog)に割り振られている．つまり，新聞記事では，大部分は述語と同
じ文内に現れていたヲ格ニ格の項が，対話では別の発話に現れることが多くな
り，1文に閉じない照応解析が重要となる．



ゼロ代名詞照応付き述語項構造解析
\label{sec-basic-strategy}

\subsection{基本方式}
\label{sec-architecture}

本稿でベースとする述語項構造解析は，
\citeA{imamura-saito-izumi:2009:Short} の方法である．これは，新聞
記事を対象とした方法であるが，文内に存在する項，文間の項，外界照応を同
時に解析できるという特徴があるため，対話の解析にも適していると判断した．

処理は，記事（対話）全体を入力とし，各文（発話）ごとに以下のステップを
実行する．
\pagebreak

\begin{enumerate}
\item 入力文を形態素・構文解析する．構文解析時には，同時に文節とその主
辞を特定しておく．なお，今回は対話コーパスに関しては，形態素解析器
MeCab \cite{kudo-yamamoto-matsumoto:2004:EMNLP}
，構文解析器CaboCha \cite{Kudo:Cabocha2002}
で形態素・文節係り受け・主辞情報を自動付与した．NAISTコー
パスに関しては，NAISTコーパス1.5付属のIPA体系の形態素・構
文情報を利用した
\footnote{NAISTコーパス1.5は，IPA体系の形態素，文節，主辞情報を含んだ形
で配布されている．京都大学テキストコーパス4.0
（http://nlp.ist.i.kyoto-u.ac.jp/index.php?京都大学テキストコーパス）と，
毎日新聞1995年版記事データを合成することで，係り受け情報を含む完全な
NAISTコーパスが構成できるようになっている．}．
\item 文から述語文節を特定する．今回は評価のため，コーパスの正解述語を
用いたが，対話システム組み込みの際には，主辞が動詞，形容詞，形容動詞，
名詞＋助動詞「だ」の文節を述語文節とし，品詞パターンで決定する．
\item 対象述語の存在する文，およびそれより前方の文から，項の候補となる
文節を取得する．文節の内容語部を候補名詞句とする．具体的には，以下の
文節が候補となる．

\begin{itemize}
  \item 対象述語の文に含まれる，内容語部が名詞句であるすべ
  ての文節を文内の候補とする．その際，述語文節との係り受け関係は考慮し
  ない．
  \item 対象述語より前方の文から，文脈的に項の候補となりうる文節を加え
  ，文間の候補とする．詳細は\ref{sec-context-processing}
  節で述べる．
  \item 記事内に実体を持たない疑似候補として，外界照応 (exo1, exo2,
  exog) と，任意格のため格を必要としない (NULL) を特殊名詞句として加え
  る．
\end{itemize}
\item 述語文節，項の候補名詞句，両者の関係を素性化し，ガ，ヲ，ニ格独立
に，候補からもっとも各格にふさわしい名詞句を選択器で選択する
（図\ref{fig-struct}）．
\end{enumerate}

\begin{figure}[b]
\begin{center}
\includegraphics{22-1ia1f2.eps}
\end{center}
\caption{項選択の例}
\label{fig-struct}
\end{figure}

本稿では，\citeA{imamura-saito-izumi:2009:Short}の方式から，若干の
変更を行っている．変更点は以下のとおりである．

\begin{itemize}
\item \citeA{imamura-saito-izumi:2009:Short}では，特殊名詞句は1種
類（NULLのみ）であったが，本稿では4種類 (NULL, exo1, exo2, exog) に拡
張した．\citeA{Hangyo:ZeroAnaphra2014j}は，外界照応を含む一人称，
二人称ゼロ代名詞（論文では著者・読者表現）の照応解析を行うことで，そ
れ以外のゼロ代名詞の照応解析精度も向上したと報告している．本稿でも，
特殊名詞句の種別を増やすこととする．
\item 素性が異なる．本稿では，\ref{sec-features}節で述べる素性を使用し
たが，これは\citeA{imamura-saito-izumi:2009:Short}の基本素性を拡
張，追加したものである．また，文脈を考慮する素性（文献ではSRLOrder，
Used）は使用せず，簡略化した．これは，文脈管理を外部モジュールに任
せるためで，詳細は\ref{sec-context-processing}で述べる．
\item 係り受け言語モデル（\ref{sec-dependency-lm}節参照）を1種類から3種
類に拡張した．
\end{itemize}


\subsection{選択器のモデル}
\label{sec-selector-models}

選択器のモデルは，最大エントロピー分類に基づく．具体的には，選択器は記
事内の述語$v$ごとに，候補名詞句集合$\textbf{N}$から，以下の式を満たす名
詞句$\hat{n}$を選択する．
\begin{align}
\hat{n} & = \mathop{\rm argmax}_{n_j \in \textbf{N}} P(d(n_j)=1 | X_j; M_c) \\
P(d(n_j)=1|X_j;M_c) & = \frac{1}{Z_{c}(X)} 
\exp \sum_{k} \{ \lambda_{ck} f_k(d(n_j)=1,X_j) \} \\
Z_{c}(X) & = \sum_{n_j \in \textbf{N}} \exp \sum_k \{\lambda_{ck} f_k(d(n_j)=1,X_j) \} 
	\label{eqn-normalizer}\\
X_j & = \langle n_j, v, A \rangle
\end{align}

ただし，$n$は1つの候補名詞句，$\textbf{N}$は候補名詞句集合，$d(n_j)$は，
名詞句$n_j$ が項となったときのみ1となる関数，$M_c$は格$c$（ガ，ヲ，ニの
いずれか）のモデルである．また，$f_k(d(n_j)=1, X_j)$は素性関数，
$\lambda_{ck}$は格毎の素性関数の重み，$v$,$A$はそれぞれ述語，および形態
素・構文解析済みの記事全体である．

訓練時には，ある述語の候補名詞句集合ごとに，正解の名詞句と，それ以外の
すべての候補名詞句との事後確率差を大きくするように学習する．具体的には，
以下の損失関数を最小化するモデル$M_c$を，格ごとに学習する．
\begin{align}
\ell_{c} & =
- \sum_{i} \log P(d(n_i)=1|X_i;M_c) 
+ \frac{1}{2C} \sum_{k} ||\lambda_{ck}||^{2}
\label{eqn-loss-function}
\end{align}
ただし，$n_i$は，訓練セットの$i$番目の述語に対する正解名詞句，$X_i$は，
訓練セットの$i$番目の正解名詞句，述語，記事の組$\langle n_i, v_i, A_i
\rangle$，$C$は過学習を制御するためのハイパーパラメータで，開発セットに
おける精度が最高になるように，あらかじめ設定しておく．式
(\ref{eqn-normalizer})で，述語の候補名詞句集合毎に正規化を行っているた
め，(\ref{eqn-loss-function})式では，候補名詞句集合から，正解名詞句が選
ばれた時に確率1.0，それ以外の名詞句では確率0.0 に近づくようにモデルが学
習される．


\subsection{素性}
\label{sec-features}

選択器で使用する素性に関しては，英語の意味役割付与に関する研究（たとえ
ば\citeA{Gildea:PredArgs2002}）と同様に，(1)述語に関する素性，
(2)名詞句に関する素性，(3)両者の関係に関する素性を使用する．詳細を表
\ref{tbl-feature-list}に示す．

\begin{table}[b]
\caption{素性テンプレート一覧}
\label{tbl-feature-list}
\input{01table03.txt}
\end{table}

二値の素性関数は，テンプレートの引数が完全一致したときのみ1，それ以外で
は0を返す関数である．たとえばPred素性において，主辞形態素の見出しが1万
種類あったとすると，1万の二値関数が定義され，主辞形態素の見出しと一致し
た関数だけが1を返す．実数値の素性関数は，テンプレートの引数に応じた実数
を返す． なお，これらは名詞句の選択用モデルの素性であるので，名詞句
Nounと，すべての二値素性を組み合わせた素性も使用している．

本稿で特徴的な素性は，大規模データから自動構築した必須格情報Frameと係り
受け言語モデル（3種類）であるが，これらについては
\ref{sec-large-resources}節で述べる．


\subsection{文脈処理}
\label{sec-context-processing}

本稿では，人とコンピュータの対話システム実現のための解析器を想定してい
る．この対話システムは，ユーザとシステムが交互に発話するもので，システ
ムに組み込まれた対話管理部が両者の発話履歴や，現在話されている話題（焦
点）を管理する．述語項構造解析部はユーザ発話を解析し，発話生成部がシ
ステム発話を生成するというものである．

従来の述語項構造解析器も，現在の解析対象文より以前の文を文脈として利用
し，ゼロ代名詞照応解析に利用している．
\citeA{imamura-saito-izumi:2009:Short}は，解析器内部で以前の文や話
題（焦点）の管理（これを文脈管理と呼ぶ）を行っていた．
しかし，述語項構造解析器内部で文脈管理を行うより，対話システムの対話管
理部が文脈管理を行った方が，ユーザ発話とシステム発話を協調的に管理でき
る可能性が高い．本稿ではこのように考え，文脈管理は外部モジュールの担当
と位置付ける．そして評価用に，新聞記事と対話で同じ文脈管理方法を使用す
る．
なお，本稿の方式は，選択器に与える文間の候補名詞句を取捨選択することに
よって文脈の制御を行っているので，候補名詞句を外部モジュールから陽に与
えることで，文脈管理方法を変更することができる．

今回使用した文脈管理方法は，具体的には以下のとおりである．

\begin{itemize}
\item 対象述語の発話より以前の発話をさかのぼり，他の述語を含む発話（こ
れを有効発話と呼ぶ）を見つける．これは，述語を含まない発話を無視するた
めである．
\item 有効発話と対象述語の発話の間に出現した全名詞句と，有効発話の述語
で項として使われた名詞句（有効発話内の場合もあれば，それ以前の発話の
名詞句の場合もある）を候補として加える．項として使われた名詞句は，
その後も繰り返し使われることが多く，これに制限することで，効率的に候
補を削減することができるという観察結果に基づく
\cite{imamura-saito-izumi:2009:Short}．また，項として使われてい
る限り，さかのぼる文数に制限がないため，広い文脈を見ることができる．
\end{itemize}


雑談対話への適応
\label{sec-adaptation}

前節で述べた方法は，対話，新聞記事に共通の処理である．これを対話解析に
適したものにするため，パラメータの適応，および大規模コーパスから自動獲
得した知識の適用を行う．

\subsection{モデルパラメータの適応}

NAISTコーパスと対話コーパスの項分布の差異は，選択器のモデルパラメータを
ドメイン適応することで調整する．本稿では，モデルパラメータの適応手法と
して，素性空間拡張法\cite{daumeiii:2007:ACLMain}を用いる．これは，
素性空間を3倍に拡張することで，ソースドメインデータをターゲットドメイン
の事前分布とみなすのと同じ効果を得る方法である．

具体的には，以下の手順で選択器のモデルを学習・適用する．

\begin{enumerate}
\item まず，素性空間を共通，ソース，ターゲットの 3 つに分割する．
\item NAISTコーパスをソースドメインデータ，対話コーパスをターゲットドメ
インデータとみなし，NAISTコーパスから得られた素性を共通とソース空間に
コピーして配置する．対話コーパスから得られた素性は共通とターゲット空
間にコピーして配置する．
\item 拡張された素性空間上で，通常通りパラメータ推定を行う．結果，ソー
ス・ターゲットデータ間で無矛盾な素性は，共通空間のパラメータが強調さ
れ（絶対値が大きくなる），ドメインに依存する素性は，ソースまたはター
ゲット空間のパラメータが強調される．
\item 選択器が項を選択する際は，ターゲット空間と共通空間の素性だけ用い
る．この空間のパラメータは，ターゲットドメインに最適化されているだけ
でなく，ソースドメインデータだけに現れた共通空間の素性も利用して，項
選択ができる．
\end{enumerate}


\subsection{大規模コーパスからの知識獲得}
\label{sec-large-resources}

本稿では，訓練コーパスに含まれない未知語への対策として，大規模コーパス
から自動獲得した2種類の知識を利用する．どちらも大規模平文コーパスを自動
解析して，集計やフィルタリングをすることで獲得する
\cite{Kawahara:CaseFrame2005j,sasano-kawahara-kurohashi:2008:PAPERS,sasano-EtAl:2013:EMNLP}
．当然誤りも含むが，新出語に対しても，ある程度の確かさで情報を与えるこ
とができる．これらを選択器の素性として使い，モデルを学習することにより，
情報の信頼度に応じたパラメータが学習される．


\subsubsection{必須格情報（Frame素性）}
\label{sec-case-lex}

格フレームは，述語の必須格と，その格を埋める名詞句の種類（通常は意味ク
  ラス）を保持するフレーム形式の情報で，述語項構造解析や意味役割付与の
重要な手がかりとなる．本稿で使う必須格情報は，格フレームのうち，格が必
要か否か（必須格か任意格か）だけについて情報を与える辞書である．

本稿の必須格情報は，大規模平文テキストコーパスから，以下の方法で自動構
築する．これは，(1)項が述語と直接係り受け関係にある場合，述語に対する項
の格は，項の名詞句に付随する格助詞と一致することが多い，(2)必須格なら，
その格の出現率は他の述語より平均的に高い\footnote{ゼロ代名詞化されている場合は，項が述語と同じ文に
現れないため，必須格であっても，出現率は100\%にはならない．そのため，
出現した/しないという二値では，必須格性は判断できないと考えた．}，と
いう仮定をもとにしている．

\begin{itemize}
\item まず，本稿の述語項構造解析と同様（\ref{sec-architecture}節参照）
に，平文を形態素・構文解析し，品詞パターンで述語文節とその主辞を特定す
る\footnote{ただし，受身・使役の助動詞が述語文節に含まれる場合は，別述語
として扱うように，助動詞と合成した述語を新たに生成した．}．
\item 述語文節に直接係る文節を取得し，機能語部に格助詞を持つ文節だけを
残す．もし，そのような文節が1つ以上あるなら，その述語を集計対象として，
述語頻度，格助詞の出現頻度を集計する．
\item 述語に関しては，高頻度述語から順番に，最終的な辞書サイズを考慮し
て選択する．個々の格に関しては，以下の条件をすべて満たす格を，必須格
とみなす．
  \begin{itemize}
  \item $\langle \text{述語}v, \text{格}c \rangle$が，対数尤度比検
  定において，危険率0.1\%以下で有意に多く共起していること（$p \leq
  0.001$; $\text{対数尤度比} \geq 10.83$）．
  \item 各述語における格$c$の出現率が，全述語における格の出現率（平均）
  より10\%以上高いこと．
  \end{itemize}
\end{itemize}

以上の方法で，2種類の必須格情報辞書を作成した．一つは，ブログ約1年分
（約23億文．以下Blogコーパスと呼ぶ）から，48万述語の情報を獲得した（こ
れをBlog辞書と呼ぶ）．もう一つは新聞記事12年分（約770万文．以下Newsコー
パスと呼ぶ）から約20 万述語の情報を獲得した（同News辞書）．

\begin{table}[b]
\caption{必須格辞書の述語カバー率と精度（対話コーパス訓練セットで測定した場合）}
\label{tbl-oci-dict}
\input{01table04.txt}
\end{table}

表\ref{tbl-oci-dict}は，雑談対話コーパス訓練セットの正解述語項構造と必
須格情報辞書を比較し，必須格情報辞書の述語カバー率と格毎の精度を算出し
たものである．述語カバー率は，対話コーパスに出現した述語が必須格情報辞
書に含まれている場合，カバーしたと判断した．結果，Blog辞書で98.5\%，
News辞書で96.4\%で，ほぼ等しかった．また，格毎の精度は，正解の述語項構
造に格が付与されているか否かと，必須格情報上の必須格性が一致しているか
どうかを測定したもので，Blog辞書，News辞書でほぼ同じ傾向を示している．
格毎に見ると，ガ格の精度が低いが，これは，雑談対話コーパスでは，ほぼす
べての述語に対してガ格が付与されている（つまり，ガ格が必須）にも関わら
ず，BlogコーパスやNewsコーパスではそれがゼロ代名詞化されているため，自
動獲得では必須格とは判断できなかったためである．ヲ格の全体精度は91\% 以
上と，格によっては高い精度を持つ辞書となっている．



\subsubsection{係り受け言語モデル}
\label{sec-dependency-lm}

係り受け言語モデル(language model; LM)は，三つ組$\langle \text{述語}
v, \text{格}c, \text{名詞句}n \rangle$の共起のしやすさを表現するモ
デルである．頻出表現に高いスコアを与えることによって，出現する単語間に
意味的関連が存在することを表現する意図がある．ここでは，述語$v$, 格
$c$, 名詞句$n$ それぞれの生成確率をn-gram モデルで算出し，選択器の識別
モデルで全体最適化を行う．具体的には，以下の実数値を算出し，表
\ref{tbl-feature-list}の係り受け言語モデル素性の素性関数値として使用す
る．その結果，選択器は，候補名詞句集合から，頻出表現に含まれる名詞句
$n$を優先して選択することになる． なお，未知語を表す特殊単語
\texttt{<unk>}を含む確率で補正してる理由は，対数確率（{$-\infty$〜
$0.0$}の範囲）を正の値に補正するためである．

\begin{itemize}
\item $\log P(n | c, v) - \log P(\texttt{<unk>} | c, v)$
\item $\log P(v | c, n) - \log P(v | c, \texttt{<unk>})$
\item $\log P(c | n) - \log P(c | \texttt{<unk>})$
\end{itemize}

本稿の係り受け言語モデルは，
\citeA{imamura-saito-izumi:2009:Short}が 1 種類（{$\log P(n|c,v)$}
  相当）のみ使用していたのに対し，識別モデルが互いに依存しあう素性を含
めることができるという特徴を利用し，3 種類に拡張している．また，述語
$v$から見た格$c$の生成確率 ({$\log P(c|v)$}) は，述語ごとに格を必要とす
る度合であり，必須格情報と重なるため，係り受け言語モデルからは除外した．

3種類の係り受け言語モデルは，\ref{sec-case-lex}節で抽出した述語，格，名
詞句を集計し，SRILM \cite{Stolcke:SRILM2011}でバックオフモデルを構
築した．

係り受け言語モデルも，Blogコーパス，Newsコーパスからそれぞれ作成した．
これを，それぞれBlog言語モデル，News言語モデルと呼ぶ．言語モデルのカバー
率を，雑談対話コーパス訓練セットに出現する三つ組が係り受け言語モデルの
元になった三つ組に含まれるかどうかで測定すると，Blog 言語モデルの場合，
76.4\%をカバーしていた．一方，Newsの言語モデルの場合，カバー率は38.3\%
だった．News言語モデルに比べ，Blog言語モデルは対話コーパスに出現する係
り受けの三つ組のカバレッジが高い\footnote{バックオフモデルの場合，モデル中に三つ組が存在しなく
ても，二つ組を組み合わせるなどして，素性関数としては何らかの値を返すこ
とができる．}．


