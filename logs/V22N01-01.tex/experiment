実験
\label{sec-experiments}

本節では，表\ref{tbl-corpus-size}に示したコーパスを用い，対話における述
語項構造解析の精度を，パラメータ適応，大規模コーパスから自動獲得した知
識の効果という観点から評価する．評価はすべて雑談対話コーパステストセッ
トで行う．評価指標には，項の適合率，再現率から算出したF値を用いる．


\subsection{実験1: パラメータ適応の効果}
\label{sec-exp-parameter-adaptation}

まず，パラメータ適応の効果を測定するため，訓練方法を変えた3方式の比較
を行った．表\ref{tbl-result-dialog}の(a)，(b)，(c)カラムがその結果で，
それぞれ(a)素性空間拡張によるドメイン適応を行った場合（適応．提案法），
(b) NAISTコーパスだけで訓練した場合（NAIST訓練．従来の新聞記事用解析に
相当），(c)対話コーパスだけで訓練した場合（対話訓練）を表す．

\begin{table}[b]
\caption{対話テストセットにおける方式・必須格情報・係り受け言語モデルごとのF値}
\label{tbl-result-dialog}
\input{01table05.txt}
\par\vspace{8pt}\small
表中の太字は，全方式のうち，F値最高を指す．また，記号 $\heartsuit$, $\diamondsuit$, $\spadesuit$, $\clubsuit$ は，(a)
と，それぞれ(b) (c) (d) (e)の比較で，有意によかったものを表す．有意差検定は，ブートストラップ再サンプリング法（1,000回測定）を使用し，危険率を
5\%とした．
\end{table}

まず，(a)適応と(b) NAIST訓練を比較すると，多くの場合，適応の方が有意に精
度がよいという結果になった（$\heartsuit$記号が有意差ありを表す）．特に
合計の精度では，すべての格で適応が有意に勝っている．タイプ別の精度を見
ると，特徴的なのは，ガ格の一人称，二人称外界照応 (exo1, exo2) である．
これらはガ格の項のうちの約28\% を占めているが，exo1で70.2\%，exo2で
46.8\%のF値で解析可能となった．他にも，ヲ格ニ格の文間ゼロ，exogなど，
NAIST訓練ではほとんど解析できなかったタイプの項が解析できるようになった．

(a)適応と(c)対話訓練を比較すると（$\diamondsuit$参照），雑談対話コーパ
スは訓練セットのサイズが小さいにも関わらず，両者の精度が近くなった．適
応の合計精度が有意に良かったのは，ニ格のみである．これには2つの理由が考
えられる．

\begin{itemize}
\item 対話コーパス量が十分であり，NAISTコーパスの影響をほとんど受けな
い場合．
\item 適応がNAISTコーパスの知識を活かしきっていない場合．言い換えると，
NAISTコーパスに出現する言語現象と，対話に出現する言語現象に重なりが少
ないため，NAISTコーパスが影響しない場合．
\end{itemize}

前者の場合，コーパスサイズに対する学習曲線が今回のデータ量で飽和してい
ることで検証できる．本稿で作成した対話コーパスはNAISTコーパスの約1/10の
訓練セットであるため，学習曲線は描かなかった．後者の場合，対話コーパス
サイズを大きくすると，述語項構造解析の精度も向上する．今後，さらに対話
コーパスを作成し，検証する必要がある．


\subsection{実験2: 自動獲得知識の比較}

表\ref{tbl-result-dialog}の(a) (d) (e)は，提案方法（適応）の評価結果
である．ただし，必須格情報および係り受け言語モデルは，それぞれ
(a) $\langle$Blog, Blog$\rangle$，(d) $\langle$News, Blog$\rangle$，
(e) $\langle$Blog, News$\rangle$に変えて評価している．

まず，必須格情報辞書を(a) Blogから(d) Newsに変えた場合を比較すると
（$\spadesuit$参照），両者の間で有意差があったのは，ヲ格の文内ゼロのみ
で，ほぼすべての場合で有意差はなかった．

一方，係り受け言語モデルを(a) Blogから(e) Newsに変更すると（$\clubsuit$
参照），若干精度に差が出た．特に，文法関係より意味関係を重視する文内・
文間ゼロでは，有意に精度が悪化したものが多く（ガ格の文間ゼロ，ヲ格の文
内・文間ゼロ，ニ格の文内ゼロ），その結果，合計の精度でも，ヲ格は約3ポ
イント低下した．ゼロ代名詞照応のように，述語と項の間に文法的な関係が弱
い場合，意味的関連性を共起から判断する係り受け言語モデルが相対的に重要
となる．そのため，係り受け言語モデルの違いが精度に影響しやすい．

図\ref{fig-coverages}は，適応方式において，それぞれ必須格情報辞書の述語
カバー率，係り受け言語モデルの三つ組$\langle \textrm{述語}v,
\textrm{格}c, \textrm{名詞句}n \rangle$のカバー率を意図的に変化させて，
述語項構造解析のF値を測定したグラフである．必須格情報，係り受け言語モデ
ルともに，Blogコーパスから作成したものを利用した．必須格情報のカバー率
は高頻度述語から順番に，雑談対話コーパス訓練セットの述語のカバー率が指
定した割合になるまで選択した．係り受け言語モデルの三つ組は，同じく雑談
対話コーパス訓練セット上での三つ組カバー率が指定した割合になるまで，ラ
ンダムに選択した\footnote{係り受け言語モデルは，確率モデルであるため，
三つ組の頻度を基準に取捨選択すると，確率分布が変化する．確率分布を変
えずにカバー率を変えるため，ランダム選択とした．}．グラフに示したF値
は，格の合計である．

\begin{figure}[t]
\begin{center}
\includegraphics{22-1ia1f3.eps}
\end{center}
\caption{自動獲得知識のカバレッジと述語項構造解析精度}
\label{fig-coverages}
\end{figure}

図\ref{fig-coverages}(a)をみると，必須格情報については，格の種類にかか
わらず，述語カバー率を変えてもほぼ同じ精度となった．この理由を分析した
ところ，テストセットに出現する大部分の述語は，訓練セットに出現したため
であった．実際，雑談対話テストセットに出現する5,333述語のうち，4,442 
述語（83.3\%）は雑談対話コーパス訓練セット，またはNAISTコーパス訓練セッ
トに出現していた．つまり，訓練セットだけでテストセッ
トの大部分をカバーできており，それ以外の述語しか，必須格情報が有効に作
用しなかったため，カバー率の影響がほとんど出なかったと考えられる．

一方，係り受け言語モデルの三つ組は，雑談対話テストセットに出現した
5,056組（外界照応\texttt{exo1}, \texttt{exo2}, \texttt{exog}は除く）の
うち，訓練セットがカバーしたのは1,063組（21.0\%）であっ
た．そのため，図\ref{fig-coverages}(b)のように，係り受け言語モデルのカ
バー率を上げると，述語項構造解析の精度も向上した．ただし，ガ格に関して
は，自動獲得元コーパスにおいてもガ格がゼロ代名詞化され，自動獲得精度が
十分ではなかったため，カバー率を上げても述語項構造解析精度は向上しなかっ
た．

まとめると，自動獲得した知識は，訓練コーパスのカバレッジが高い部分では
効果がほとんどなく，低い部分を補完するのに有効である．そのため，雑談対
話のように幅広い話題を対象とする対話には適している．


\subsection{雑談対話コーパスを使用せずに適応する場合}

ドメイン適応のシチュエーションとして，新聞記事コーパスしか存在しない状
況で，述語項構造解析器を対話に適応させなければならない場合が考えられる．
本節では，NAISTテキストコーパスと自動獲得知識だけでモデルを学習し，自動
獲得知識がどの程度有効か，検証する．

表\ref{tbl-effect-of-knowledge}は，NAISTコーパス訓練セットでモデルを学
習し，雑談対話コーパステストセットでF値を測定した結果である．ただし，自
動獲得知識の組み合わせ{$\langle \text{必須格情報}, \text{係り受け言語モデル} \rangle$}は，(b){$\langle \text{Blog}, \text{Blog}
\rangle$}，(b-1){$\langle \text{なし}, \text{Blog}\rangle$}，
(b-2){$\langle \text{Blog}, \text{なし} \rangle$}，(b-3){$\langle
\text{なし}, \text{なし}\rangle$}に変えている．(b)は，表
\ref{tbl-result-dialog}の再掲である．

\begin{table}[b]
\caption{NAIST訓練における自動獲得知識の効果（自動獲得知識はBlog）}
\label{tbl-effect-of-knowledge}
\input{01table06.txt}
\par\vspace{8pt}\small
表中の記号 $\dag$, $\S$, $\ddag$は，(b)と，それぞれ(b-1) (b-2) (b-3)との比較で，有意によかったものを表す．有意差検定は，ブートストラップ再サ
ンプリング法（1,000回測定）を使用し，危険率を5\%とした．なお．(b)は，表\ref{tbl-result-dialog}の再掲である．
\end{table}

これを見ると，多くの場合で(b){$\langle \text{Blog},
\text{Blog}\rangle$}が有意に勝っており，自動獲得知識が有効に作用して
いると言ってよい．

しかし，これらはすべてNAIST訓練の結果であり，ほとんど（またはまったく）
解析できなかったタイプの項（たとえば，ガ格のexo1, exo2，ヲ格の文間ゼロ，
  ニ格の文内・文間ゼロ）は，必須格情報辞書，係り受け言語モデルをどのよ
うに変えようとも，ほとんど解析できない状況には変わりはなかった．

本稿の提案方式である表\ref{tbl-result-dialog}の(a)適応は，NAIST 訓練で
は解析できなかったタイプの項も解析できるようにする効果があった．自動獲
得した知識は，すでに解析できるタイプの項の精度改善には効果があるが，対
話で新たに出現したタイプの項を解析する効果はない．したがって，たとえ少
量でも対話の述語項構造データを作成し，適応させることが望ましい．


\subsection{対話解析例}
\label{sec-err-analysis}

図\ref{fig-analysis-example}は，旅行に関する雑談対話の一部について，正
解述語項構造，(a)適応方式，(b) NAIST訓練方式，(b-3) NAIST 訓練（ただし，
  必須格情報辞書，係り受け言語モデルなし）の出力を並べて表示したもので
ある．発話ごとに差異を分析すると，以下の特徴が得られた．

\begin{figure}[p]
\input{01fig04.txt}
\caption{対話例と，正解述語項構造および述語項構造解析結果（*は解析誤りを表す）}
\label{fig-analysis-example}
\end{figure}

\begin{itemize}
\item 発話番号1で，正解がexogになっているのは，アノテータは，
「話した」のは発話者ABの両方であると判断したためである．本発話の解釈に
よっては，exo1でも誤りではないと思われる．
\item 発話番号2のガ格の正解はexo2である．しかし，(a)適応は，
exo1を選択した．日本語の場合，一人称・二人称は，文末表現（この例では
「下さい」）に特徴が現れるが，選択器にSuffix素性があるにも関わらず，正
しく選択できなかった．
\item 発話番号3のガ格の正解はexo1である．(a)適応は正しく選択したが，
(b)(b-3) NAIST訓練は，一人称／二人称の外界照応をほとんど選択しないため，
発話番号1に現れた「私」を選択した．
しかし，発話番号1の「私」は発話者Aを示しており，発話番号3のexo1（発話者
  B）とは異なる．もし文間ゼロタイプの項を割り当てるとすると，発話番号2
の「あなた」が正解となる．本稿では，外界照応と人称代名詞を別に扱ってい
るが，本来は共参照解析を導入して，exo1/exo2と「私」「あなた」が同一実体
であることを認識すべきである．その際，発話者がどちらなのか意識して，同
一性を判断する必要がある．\\
発話番号6にも同様な現象が現れているが，ガ格正解exo2に相当する表現が発話
番号2「あなた」まで遡らなければならないため，(b)(b-3) NAIST訓練では，
exogとなった．
\item 発話番号3のニ格の正解は「海外旅行」だが，(b-3) NAIST訓
練（自動獲得知識なし）では，NULLと誤った．「海外旅行にはまる」は，
NAISTコーパス訓練セットには出現せず，係り受け言語モデルの三つ組に出現
する表現だったため，係り受け言語モデルなしのNAIST訓練では解析に失敗し
た．
\item 発話番号5のニ格の正解は，「スペインとポルトガル」であ
るべきだが，本稿の方式は文節を単位に処理するため，2文節以上にまたがる
名詞句は，主辞だけを付与する仕様である．\\
また，発話番号4のガ格の正解は，直前発話（発話番号3）全体と考えることも
できる．しかし，文節単位に格要素を割り当てるため，アノテータはもっとも
近い表現「海外旅行」を正解として割り当てた．
\item 発話番号6において，(a)適応は，ニ格「ポルトガル」を前
文から正しく補完した．なお，「ポルトガルに行く」は，NAISTコーパス訓練
セットには存在しないが，係り受け言語モデルの三つ組には存在する表現であ
る．
\end{itemize}


