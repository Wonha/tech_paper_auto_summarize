    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvipdfm]{graphicx}
\usepackage{amsmath}
\usepackage{array}


\Volume{22}
\Number{1}
\Month{March}
\Year{2015}

\received{2014}{6}{26}
\revised{2014}{9}{30}
\accepted{2014}{11}{7}

\setcounter{page}{3}

\jtitle{対話解析のためのゼロ代名詞照応解析付き述語項構造解析}
\jauthor{今村　賢治\affiref{NTT}\affiref{NICT} \and 東中竜一郎\affiref{NTT} \and 泉　　朋子\affiref{NTT}}
\jabstract{
本稿では，日本語を対象とした対話用述語項構造解析を提案する．従来，述語
項構造解析は，主に新聞記事を対象に研究されてきた．新聞と対話ではさまざ
まな違いが存在するが，本稿ではこれを包括的に扱うため，対話用述語項構造
解析器の構築を，新聞から対話への一種のドメイン適応とみなす．具体的には，
対話では省略や代名詞化が新聞記事に比べて頻繁に現れるため，ゼロ代名詞照
応機能付きの述語項構造解析をベースとし，これを対話に適応させる．パラメー
タ適応と，訓練コーパスがカバーしきれない語彙知識を大規模平文コーパスか
ら自動獲得することにより，新聞記事用のものに比べ，対話に対して高精度な
述語項構造解析を実現した．
}
\jkeywords{述語項構造解析，ゼロ代名詞照応，対話，ドメイン適応，係り受け言語モデル}

\etitle{Predicate-Argument Structure Analysis and Zero-Anaphora Resolution for Dialogue Analysis}
\eauthor{Kenji Imamura\affiref{NTT}\affiref{NICT} \and Ryuichiro Higashinaka\affiref{NTT} \and Tomoko Izumi\affiref{NTT}} 
\eabstract{
This paper presents a predicate-argument structure (PAS) analysis for
dialogue systems in Japanese.  Conventional PAS analyses have been
applied to newspaper articles; however, there are differences between
newspapers and dialogues.  Therefore, to comprehensively deal with
these differences, we constructed a PAS analyzer for dialogues as a
type of domain adaptation from newspapers.  Because pronominalization
and ellipses frequently appear in dialogues, we utilized a strategy
that simultaneously resolves zero-anaphora and adapts our PAS analyzer
to dialogues.  By incorporating parameter adaptation and automatically
acquiring knowledge from large text corpora, we performed a PAS
analysis that is specific to dialogues.  Our PAS analyzer has a higher
accuracy compared with the analyzer for newspaper articles.}
\ekeywords{Predicate-Argument Structure Analysis, Zero-anaphora Resolution, Dialogue, Domain Adaptation, Dependency Language Models}

\headauthor{今村，東中，泉}
\headtitle{対話解析のためのゼロ代名詞照応解析付き述語項構造解析}

\affilabel{NTT}{日本電信電話株式会社，NTTメディアインテリジェンス研究所}{NTT Media Intelligence Laboratories, NTT Corporation}
\affilabel{NICT}{現在，独立行政法人情報通信研究機構}{Presently with National Institute of Information and Communications Technology}



\begin{document}
\maketitle

\section{雑談対話の特徴}
\label{sec-char-dialogs}

まず我々は，2名の参加者による雑談対話を収集し，その対話に述語項構造デー
タの付与を行った．雑談対話は，参加者が自由なテーマ（話題）を設定し，キー
ボード対話形式で収集した．したがって，音声対話に含まれるような相槌や言
い直しは少ない．参加者の話題は，食事，旅行，趣味，テレビ・ラジオなどで
ある．述語項構造アノテーションは，NAISTテキストコーパス
\cite{iida-EtAl:2007:LAW,Iida:NAISTCorpus2010j}に準拠する形で行っ
た．雑談対話と，その述語項構造解析アノテーションの例を図
\ref{fig-chat-dialog}に示す
\footnote{対話中に一人称・二人称代名詞が陽に出現する場合，アノテータに
対してexo1/exo2との区別は指示しなかった．しかし，
述語と同一発話内ではその代名詞を項に使う場合が多く，異なる発
話の場合，出現した代名詞をゼロ代名詞照応先とするのではなく
外界照応 (exo1/exo2) とする傾向が高かった．}．

\begin{figure}[b]
\input{01fig01.txt}
\caption{雑談対話とその述語項構造アノテーションの例}
\label{fig-chat-dialog}
\par\small
太字は述語，$[ ]$は文内の項，$( )$は文間の項または外界照応を表す．\\ 
また，\texttt{exo1}，\texttt{exo2}，\texttt{exog}はそれぞれ一人称／二人称ゼロ代名詞，それ以外の外界照応を表す．
\end{figure}
\begin{table}[b]
\caption{コーパスサイズ}
\label{tbl-corpus-size}
\input{01table01.txt}
\end{table}

今回作成した雑談対話コーパスと，NAISTコーパス
\footnote{NAIST コーパスはバージョン1.5を用い，文節化の前処理を行った上
で使用した．1 文節に複数の述語が含まれている場合は，前方に出現した述
語のみを対象とした．} の統計量を表\ref{tbl-corpus-size}に示す．対話コー
パスは，NAISTコーパスの約1/10のサイズである．また，1文/発話の長さ（形
態素数）は，雑談対話コーパスはNAISTコーパスの1/3程度と短い． NAISTコー
パスは，訓練，開発，テストに3分割したのに対し，対話コーパスは訓練とテス
トの2分割とした．

対話の特徴を分析するため，この 2 つのコーパスの比較を行った．表
\ref{tbl-arg-distrib}は，訓練セットにおける項の分布を示したものである．
各項は，述語との位置関係や文法関係などにより問題の難しさが異なるため，
以下の6タイプに分類した．最初の2つ（係受および文内ゼロ）は述語と項が同
じ文に存在する場合である．

\begin{table}[t]
\caption{訓練セットにおける項の分布}
\label{tbl-arg-distrib}
\input{01table02.txt}
\end{table}

\begin{itemize}
\item \textbf{係受:} 述語と項が直接の係り受け関係にある場合
\item \textbf{文内ゼロ:} 述語と項が同じ文（発話）内にあるが，直接の
係り受け関係がない場合
\item \textbf{文間ゼロ:} 述語と項が異なる文にある場合
\item \textbf{exo1/exo2/exog:} 項が記事（対話）内に存在しない外界照応．そ
れぞれ，一人称ゼロ代名詞，二人称ゼロ代名詞，それ以外（一般）を表す．
\end{itemize}

これを見ると，対話ではすべての格で，係受タイプの項が減少している．それ
以外のタイプについては，ガ格と，ヲ格ニ格で傾向が異なっている．
ガ格では，文内ゼロ代名詞も対話の場合に減少し，減少分は一人称・二人称外
界照応 (exo1, exo2) に割り当てられている．つまり，ガ格では，文内の項が
減少し，ゼロ代名詞が新聞に比べて頻発する．ただし，その先行詞は一人称・
二人称代名詞である可能性が高いと言うことができる．
ヲ格ニ格では，係受タイプの項の減少分は，文間ゼロ代名詞またはその他の外
界照応(exog)に割り振られている．つまり，新聞記事では，大部分は述語と同
じ文内に現れていたヲ格ニ格の項が，対話では別の発話に現れることが多くな
り，1文に閉じない照応解析が重要となる．



\section{ゼロ代名詞照応付き述語項構造解析}
\label{sec-basic-strategy}

\subsection{基本方式}
\label{sec-architecture}

本稿でベースとする述語項構造解析は，
\citeA{imamura-saito-izumi:2009:Short} の方法である．これは，新聞
記事を対象とした方法であるが，文内に存在する項，文間の項，外界照応を同
時に解析できるという特徴があるため，対話の解析にも適していると判断した．

処理は，記事（対話）全体を入力とし，各文（発話）ごとに以下のステップを
実行する．
\pagebreak

\begin{enumerate}
\item 入力文を形態素・構文解析する．構文解析時には，同時に文節とその主
辞を特定しておく．なお，今回は対話コーパスに関しては，形態素解析器
MeCab \cite{kudo-yamamoto-matsumoto:2004:EMNLP}
，構文解析器CaboCha \cite{Kudo:Cabocha2002}
で形態素・文節係り受け・主辞情報を自動付与した．NAISTコー
パスに関しては，NAISTコーパス1.5付属のIPA体系の形態素・構
文情報を利用した
\footnote{NAISTコーパス1.5は，IPA体系の形態素，文節，主辞情報を含んだ形
で配布されている．京都大学テキストコーパス4.0
（http://nlp.ist.i.kyoto-u.ac.jp/index.php?京都大学テキストコーパス）と，
毎日新聞1995年版記事データを合成することで，係り受け情報を含む完全な
NAISTコーパスが構成できるようになっている．}．
\item 文から述語文節を特定する．今回は評価のため，コーパスの正解述語を
用いたが，対話システム組み込みの際には，主辞が動詞，形容詞，形容動詞，
名詞＋助動詞「だ」の文節を述語文節とし，品詞パターンで決定する．
\item 対象述語の存在する文，およびそれより前方の文から，項の候補となる
文節を取得する．文節の内容語部を候補名詞句とする．具体的には，以下の
文節が候補となる．

\begin{itemize}
  \item 対象述語の文に含まれる，内容語部が名詞句であるすべ
  ての文節を文内の候補とする．その際，述語文節との係り受け関係は考慮し
  ない．
  \item 対象述語より前方の文から，文脈的に項の候補となりうる文節を加え
  ，文間の候補とする．詳細は\ref{sec-context-processing}
  節で述べる．
  \item 記事内に実体を持たない疑似候補として，外界照応 (exo1, exo2,
  exog) と，任意格のため格を必要としない (NULL) を特殊名詞句として加え
  る．
\end{itemize}
\item 述語文節，項の候補名詞句，両者の関係を素性化し，ガ，ヲ，ニ格独立
に，候補からもっとも各格にふさわしい名詞句を選択器で選択する
（図\ref{fig-struct}）．
\end{enumerate}

\begin{figure}[b]
\begin{center}
\includegraphics{22-1ia1f2.eps}
\end{center}
\caption{項選択の例}
\label{fig-struct}
\end{figure}

本稿では，\citeA{imamura-saito-izumi:2009:Short}の方式から，若干の
変更を行っている．変更点は以下のとおりである．

\begin{itemize}
\item \citeA{imamura-saito-izumi:2009:Short}では，特殊名詞句は1種
類（NULLのみ）であったが，本稿では4種類 (NULL, exo1, exo2, exog) に拡
張した．\citeA{Hangyo:ZeroAnaphra2014j}は，外界照応を含む一人称，
二人称ゼロ代名詞（論文では著者・読者表現）の照応解析を行うことで，そ
れ以外のゼロ代名詞の照応解析精度も向上したと報告している．本稿でも，
特殊名詞句の種別を増やすこととする．
\item 素性が異なる．本稿では，\ref{sec-features}節で述べる素性を使用し
たが，これは\citeA{imamura-saito-izumi:2009:Short}の基本素性を拡
張，追加したものである．また，文脈を考慮する素性（文献ではSRLOrder，
Used）は使用せず，簡略化した．これは，文脈管理を外部モジュールに任
せるためで，詳細は\ref{sec-context-processing}で述べる．
\item 係り受け言語モデル（\ref{sec-dependency-lm}節参照）を1種類から3種
類に拡張した．
\end{itemize}


\subsection{選択器のモデル}
\label{sec-selector-models}

選択器のモデルは，最大エントロピー分類に基づく．具体的には，選択器は記
事内の述語$v$ごとに，候補名詞句集合$\textbf{N}$から，以下の式を満たす名
詞句$\hat{n}$を選択する．
\begin{align}
\hat{n} & = \mathop{\rm argmax}_{n_j \in \textbf{N}} P(d(n_j)=1 | X_j; M_c) \\
P(d(n_j)=1|X_j;M_c) & = \frac{1}{Z_{c}(X)} 
\exp \sum_{k} \{ \lambda_{ck} f_k(d(n_j)=1,X_j) \} \\
Z_{c}(X) & = \sum_{n_j \in \textbf{N}} \exp \sum_k \{\lambda_{ck} f_k(d(n_j)=1,X_j) \} 
	\label{eqn-normalizer}\\
X_j & = \langle n_j, v, A \rangle
\end{align}

ただし，$n$は1つの候補名詞句，$\textbf{N}$は候補名詞句集合，$d(n_j)$は，
名詞句$n_j$ が項となったときのみ1となる関数，$M_c$は格$c$（ガ，ヲ，ニの
いずれか）のモデルである．また，$f_k(d(n_j)=1, X_j)$は素性関数，
$\lambda_{ck}$は格毎の素性関数の重み，$v$,$A$はそれぞれ述語，および形態
素・構文解析済みの記事全体である．

訓練時には，ある述語の候補名詞句集合ごとに，正解の名詞句と，それ以外の
すべての候補名詞句との事後確率差を大きくするように学習する．具体的には，
以下の損失関数を最小化するモデル$M_c$を，格ごとに学習する．
\begin{align}
\ell_{c} & =
- \sum_{i} \log P(d(n_i)=1|X_i;M_c) 
+ \frac{1}{2C} \sum_{k} ||\lambda_{ck}||^{2}
\label{eqn-loss-function}
\end{align}
ただし，$n_i$は，訓練セットの$i$番目の述語に対する正解名詞句，$X_i$は，
訓練セットの$i$番目の正解名詞句，述語，記事の組$\langle n_i, v_i, A_i
\rangle$，$C$は過学習を制御するためのハイパーパラメータで，開発セットに
おける精度が最高になるように，あらかじめ設定しておく．式
(\ref{eqn-normalizer})で，述語の候補名詞句集合毎に正規化を行っているた
め，(\ref{eqn-loss-function})式では，候補名詞句集合から，正解名詞句が選
ばれた時に確率1.0，それ以外の名詞句では確率0.0 に近づくようにモデルが学
習される．


\subsection{素性}
\label{sec-features}

選択器で使用する素性に関しては，英語の意味役割付与に関する研究（たとえ
ば\citeA{Gildea:PredArgs2002}）と同様に，(1)述語に関する素性，
(2)名詞句に関する素性，(3)両者の関係に関する素性を使用する．詳細を表
\ref{tbl-feature-list}に示す．

\begin{table}[b]
\caption{素性テンプレート一覧}
\label{tbl-feature-list}
\input{01table03.txt}
\end{table}

二値の素性関数は，テンプレートの引数が完全一致したときのみ1，それ以外で
は0を返す関数である．たとえばPred素性において，主辞形態素の見出しが1万
種類あったとすると，1万の二値関数が定義され，主辞形態素の見出しと一致し
た関数だけが1を返す．実数値の素性関数は，テンプレートの引数に応じた実数
を返す． なお，これらは名詞句の選択用モデルの素性であるので，名詞句
Nounと，すべての二値素性を組み合わせた素性も使用している．

本稿で特徴的な素性は，大規模データから自動構築した必須格情報Frameと係り
受け言語モデル（3種類）であるが，これらについては
\ref{sec-large-resources}節で述べる．


\subsection{文脈処理}
\label{sec-context-processing}

本稿では，人とコンピュータの対話システム実現のための解析器を想定してい
る．この対話システムは，ユーザとシステムが交互に発話するもので，システ
ムに組み込まれた対話管理部が両者の発話履歴や，現在話されている話題（焦
点）を管理する．述語項構造解析部はユーザ発話を解析し，発話生成部がシ
ステム発話を生成するというものである．

従来の述語項構造解析器も，現在の解析対象文より以前の文を文脈として利用
し，ゼロ代名詞照応解析に利用している．
\citeA{imamura-saito-izumi:2009:Short}は，解析器内部で以前の文や話
題（焦点）の管理（これを文脈管理と呼ぶ）を行っていた．
しかし，述語項構造解析器内部で文脈管理を行うより，対話システムの対話管
理部が文脈管理を行った方が，ユーザ発話とシステム発話を協調的に管理でき
る可能性が高い．本稿ではこのように考え，文脈管理は外部モジュールの担当
と位置付ける．そして評価用に，新聞記事と対話で同じ文脈管理方法を使用す
る．
なお，本稿の方式は，選択器に与える文間の候補名詞句を取捨選択することに
よって文脈の制御を行っているので，候補名詞句を外部モジュールから陽に与
えることで，文脈管理方法を変更することができる．

今回使用した文脈管理方法は，具体的には以下のとおりである．

\begin{itemize}
\item 対象述語の発話より以前の発話をさかのぼり，他の述語を含む発話（こ
れを有効発話と呼ぶ）を見つける．これは，述語を含まない発話を無視するた
めである．
\item 有効発話と対象述語の発話の間に出現した全名詞句と，有効発話の述語
で項として使われた名詞句（有効発話内の場合もあれば，それ以前の発話の
名詞句の場合もある）を候補として加える．項として使われた名詞句は，
その後も繰り返し使われることが多く，これに制限することで，効率的に候
補を削減することができるという観察結果に基づく
\cite{imamura-saito-izumi:2009:Short}．また，項として使われてい
る限り，さかのぼる文数に制限がないため，広い文脈を見ることができる．
\end{itemize}


\section{雑談対話への適応}
\label{sec-adaptation}

前節で述べた方法は，対話，新聞記事に共通の処理である．これを対話解析に
適したものにするため，パラメータの適応，および大規模コーパスから自動獲
得した知識の適用を行う．

\subsection{モデルパラメータの適応}

NAISTコーパスと対話コーパスの項分布の差異は，選択器のモデルパラメータを
ドメイン適応することで調整する．本稿では，モデルパラメータの適応手法と
して，素性空間拡張法\cite{daumeiii:2007:ACLMain}を用いる．これは，
素性空間を3倍に拡張することで，ソースドメインデータをターゲットドメイン
の事前分布とみなすのと同じ効果を得る方法である．

具体的には，以下の手順で選択器のモデルを学習・適用する．

\begin{enumerate}
\item まず，素性空間を共通，ソース，ターゲットの 3 つに分割する．
\item NAISTコーパスをソースドメインデータ，対話コーパスをターゲットドメ
インデータとみなし，NAISTコーパスから得られた素性を共通とソース空間に
コピーして配置する．対話コーパスから得られた素性は共通とターゲット空
間にコピーして配置する．
\item 拡張された素性空間上で，通常通りパラメータ推定を行う．結果，ソー
ス・ターゲットデータ間で無矛盾な素性は，共通空間のパラメータが強調さ
れ（絶対値が大きくなる），ドメインに依存する素性は，ソースまたはター
ゲット空間のパラメータが強調される．
\item 選択器が項を選択する際は，ターゲット空間と共通空間の素性だけ用い
る．この空間のパラメータは，ターゲットドメインに最適化されているだけ
でなく，ソースドメインデータだけに現れた共通空間の素性も利用して，項
選択ができる．
\end{enumerate}


\subsection{大規模コーパスからの知識獲得}
\label{sec-large-resources}

本稿では，訓練コーパスに含まれない未知語への対策として，大規模コーパス
から自動獲得した2種類の知識を利用する．どちらも大規模平文コーパスを自動
解析して，集計やフィルタリングをすることで獲得する
\cite{Kawahara:CaseFrame2005j,sasano-kawahara-kurohashi:2008:PAPERS,sasano-EtAl:2013:EMNLP}
．当然誤りも含むが，新出語に対しても，ある程度の確かさで情報を与えるこ
とができる．これらを選択器の素性として使い，モデルを学習することにより，
情報の信頼度に応じたパラメータが学習される．


\subsubsection{必須格情報（Frame素性）}
\label{sec-case-lex}

格フレームは，述語の必須格と，その格を埋める名詞句の種類（通常は意味ク
  ラス）を保持するフレーム形式の情報で，述語項構造解析や意味役割付与の
重要な手がかりとなる．本稿で使う必須格情報は，格フレームのうち，格が必
要か否か（必須格か任意格か）だけについて情報を与える辞書である．

本稿の必須格情報は，大規模平文テキストコーパスから，以下の方法で自動構
築する．これは，(1)項が述語と直接係り受け関係にある場合，述語に対する項
の格は，項の名詞句に付随する格助詞と一致することが多い，(2)必須格なら，
その格の出現率は他の述語より平均的に高い\footnote{ゼロ代名詞化されている場合は，項が述語と同じ文に
現れないため，必須格であっても，出現率は100\%にはならない．そのため，
出現した/しないという二値では，必須格性は判断できないと考えた．}，と
いう仮定をもとにしている．

\begin{itemize}
\item まず，本稿の述語項構造解析と同様（\ref{sec-architecture}節参照）
に，平文を形態素・構文解析し，品詞パターンで述語文節とその主辞を特定す
る\footnote{ただし，受身・使役の助動詞が述語文節に含まれる場合は，別述語
として扱うように，助動詞と合成した述語を新たに生成した．}．
\item 述語文節に直接係る文節を取得し，機能語部に格助詞を持つ文節だけを
残す．もし，そのような文節が1つ以上あるなら，その述語を集計対象として，
述語頻度，格助詞の出現頻度を集計する．
\item 述語に関しては，高頻度述語から順番に，最終的な辞書サイズを考慮し
て選択する．個々の格に関しては，以下の条件をすべて満たす格を，必須格
とみなす．
  \begin{itemize}
  \item $\langle \text{述語}v, \text{格}c \rangle$が，対数尤度比検
  定において，危険率0.1\%以下で有意に多く共起していること（$p \leq
  0.001$; $\text{対数尤度比} \geq 10.83$）．
  \item 各述語における格$c$の出現率が，全述語における格の出現率（平均）
  より10\%以上高いこと．
  \end{itemize}
\end{itemize}

以上の方法で，2種類の必須格情報辞書を作成した．一つは，ブログ約1年分
（約23億文．以下Blogコーパスと呼ぶ）から，48万述語の情報を獲得した（こ
れをBlog辞書と呼ぶ）．もう一つは新聞記事12年分（約770万文．以下Newsコー
パスと呼ぶ）から約20 万述語の情報を獲得した（同News辞書）．

\begin{table}[b]
\caption{必須格辞書の述語カバー率と精度（対話コーパス訓練セットで測定した場合）}
\label{tbl-oci-dict}
\input{01table04.txt}
\end{table}

表\ref{tbl-oci-dict}は，雑談対話コーパス訓練セットの正解述語項構造と必
須格情報辞書を比較し，必須格情報辞書の述語カバー率と格毎の精度を算出し
たものである．述語カバー率は，対話コーパスに出現した述語が必須格情報辞
書に含まれている場合，カバーしたと判断した．結果，Blog辞書で98.5\%，
News辞書で96.4\%で，ほぼ等しかった．また，格毎の精度は，正解の述語項構
造に格が付与されているか否かと，必須格情報上の必須格性が一致しているか
どうかを測定したもので，Blog辞書，News辞書でほぼ同じ傾向を示している．
格毎に見ると，ガ格の精度が低いが，これは，雑談対話コーパスでは，ほぼす
べての述語に対してガ格が付与されている（つまり，ガ格が必須）にも関わら
ず，BlogコーパスやNewsコーパスではそれがゼロ代名詞化されているため，自
動獲得では必須格とは判断できなかったためである．ヲ格の全体精度は91\% 以
上と，格によっては高い精度を持つ辞書となっている．



\subsubsection{係り受け言語モデル}
\label{sec-dependency-lm}

係り受け言語モデル(language model; LM)は，三つ組$\langle \text{述語}
v, \text{格}c, \text{名詞句}n \rangle$の共起のしやすさを表現するモ
デルである．頻出表現に高いスコアを与えることによって，出現する単語間に
意味的関連が存在することを表現する意図がある．ここでは，述語$v$, 格
$c$, 名詞句$n$ それぞれの生成確率をn-gram モデルで算出し，選択器の識別
モデルで全体最適化を行う．具体的には，以下の実数値を算出し，表
\ref{tbl-feature-list}の係り受け言語モデル素性の素性関数値として使用す
る．その結果，選択器は，候補名詞句集合から，頻出表現に含まれる名詞句
$n$を優先して選択することになる． なお，未知語を表す特殊単語
\texttt{<unk>}を含む確率で補正してる理由は，対数確率（{$-\infty$〜
$0.0$}の範囲）を正の値に補正するためである．

\begin{itemize}
\item $\log P(n | c, v) - \log P(\texttt{<unk>} | c, v)$
\item $\log P(v | c, n) - \log P(v | c, \texttt{<unk>})$
\item $\log P(c | n) - \log P(c | \texttt{<unk>})$
\end{itemize}

本稿の係り受け言語モデルは，
\citeA{imamura-saito-izumi:2009:Short}が 1 種類（{$\log P(n|c,v)$}
  相当）のみ使用していたのに対し，識別モデルが互いに依存しあう素性を含
めることができるという特徴を利用し，3 種類に拡張している．また，述語
$v$から見た格$c$の生成確率 ({$\log P(c|v)$}) は，述語ごとに格を必要とす
る度合であり，必須格情報と重なるため，係り受け言語モデルからは除外した．

3種類の係り受け言語モデルは，\ref{sec-case-lex}節で抽出した述語，格，名
詞句を集計し，SRILM \cite{Stolcke:SRILM2011}でバックオフモデルを構
築した．

係り受け言語モデルも，Blogコーパス，Newsコーパスからそれぞれ作成した．
これを，それぞれBlog言語モデル，News言語モデルと呼ぶ．言語モデルのカバー
率を，雑談対話コーパス訓練セットに出現する三つ組が係り受け言語モデルの
元になった三つ組に含まれるかどうかで測定すると，Blog 言語モデルの場合，
76.4\%をカバーしていた．一方，Newsの言語モデルの場合，カバー率は38.3\%
だった．News言語モデルに比べ，Blog言語モデルは対話コーパスに出現する係
り受けの三つ組のカバレッジが高い\footnote{バックオフモデルの場合，モデル中に三つ組が存在しなく
ても，二つ組を組み合わせるなどして，素性関数としては何らかの値を返すこ
とができる．}．


\section{まとめ}
\label{sec-conclusion}

本稿では，対話解析のための述語項構造解析を提案した．われわれはこれを新
聞から対話への一種のドメイン適応とみなし，従来新聞記事で研究されていた
述語項構造解析を，対話に適用した．対話と新聞記事では項の分布が異なるた
め，素性空間拡張法を用いて，モデルパラメータを適応させた．また訓練コー
パスに現れない未知語を補完するため，大規模平文データから，必須格情報，
係り受け言語モデルを自動獲得し，項選択器のモデルに適用した．

結果，少量でも対話コーパスを訓練に加えることで，新聞記事のコーパスだけ
では解析できなかったタイプ（ガ格の一人称・二人称ゼロ代名詞や，文間ゼロ
  代名詞，外界照応）も解析可能となった．ただし，パラメータ適応自体の効
果は限定的であった．また，自動獲得知識の有効性は，訓練セットがテストセッ
トをどの程度カバーしているかに依存する．必須格情報は，テストセットに出
現する述語の大部分が訓練セットに出現していたため，必須格情報のカバレッ
ジの影響はほとんどなかった．一方係り受け言語モデルでは，テストセットに
出現する述語，格，名詞句の三つ組の21\%しか訓練セットでカバーしていなかっ
たため，カバレッジの高いモデルの精度が向上した．特に，ヲ格ニ格に関して
は，三つ組カバレッジが高い方が，ゼロ代名詞照応解析精度の向上に寄与する
ことを確認した．

なお，必須格情報および係り受け言語モデルは，格フレームの選択選好とみな
すこともできる．格フレームは，大規模コーパスから自動獲得したものが存在
するので\cite{Kawahara:CaseFrame2005j}，これを利用する方法もある．
両者の比較は，今後検討してゆきたい．

今回は，パラメータ分布の差異，語彙のカバレッジに着目したが，新聞と対話
では，他にもさまざまな違いがあると考えられる．たとえば，話者交替は対話
特有の現象であるが，それが述語項構造やゼロ代名詞にどう影響するかなどは，
本稿では扱わなかった．また，われわれは文脈管理に，対話システムの発話管
理機能を利用することを考えているが，対話システムとしての有効性評価も実
施する予定である．

\acknowledgment

本論文の一部は，the 25th International Conference on Computational
Linguistics (COLING 2014)で発表したものである
\cite{imamura-higashinaka-izumi:2014:Coling}．


\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Carreras \BBA\ M{\`{a}}rquez}{Carreras \BBA\
  M{\`{a}}rquez}{2004}]{carreras-marquez:2004:CONLL}
Carreras, X.\BBACOMMA\ \BBA\ M{\`{a}}rquez, L. \BBOP 2004\BBCP.
\newblock \BBOQ Introduction to the CoNLL-2004 Shared Task: Semantic Role
  Labeling.\BBCQ\
\newblock In {\Bem HLT-NAACL 2004 Workshop: 8th Conference on Computational
  Natural Language Learning (CoNLL-2004)}, \mbox{\BPGS\ 89--97}, Boston,
  Massachusetts, USA.

\bibitem[\protect\BCAY{Carreras \BBA\ M{\`{a}}rquez}{Carreras \BBA\
  M{\`{a}}rquez}{2005}]{carreras-marquez:2005:CoNLL}
Carreras, X.\BBACOMMA\ \BBA\ M{\`{a}}rquez, L. \BBOP 2005\BBCP.
\newblock \BBOQ Introduction to the {CoNLL}-2005 Shared Task: Semantic Role
  Labeling.\BBCQ\
\newblock In {\Bem Proceedings of the 9th Conference on Computational Natural
  Language Learning (CoNLL-2005)}, \mbox{\BPGS\ 152--164}, Ann Arbor, Michigan,
  USA.

\bibitem[\protect\BCAY{Coppola, Moschitti, \BBA\ Riccardi}{Coppola
  et~al.}{2009}]{coppola-moschitti-riccardi:2009:NAACLHLT09-Short}
Coppola, B., Moschitti, A., \BBA\ Riccardi, G. \BBOP 2009\BBCP.
\newblock \BBOQ Shallow Semantic Parsing for Spoken Language
  Understanding.\BBCQ\
\newblock In {\Bem Proceedings of Human Language Technologies: The 2009 Annual
  Conference of the North American Chapter of the Association for Computational
  Linguistics, Companion Volume: Short Papers}, \mbox{\BPGS\ 85--88}, Boulder,
  Colorado, USA.

\bibitem[\protect\BCAY{Daum\'{e}}{Daum\'{e}}{2007}]{daumeiii:2007:ACLMain}
Daum\'{e}, III, H. \BBOP 2007\BBCP.
\newblock \BBOQ Frustratingly Easy Domain Adaptation.\BBCQ\
\newblock In {\Bem Proceedings of the 45th Annual Meeting of the Association of
  Computational Linguistics}, \mbox{\BPGS\ 256--263}, Prague, Czech Republic.

\bibitem[\protect\BCAY{Gerber \BBA\ Chai}{Gerber \BBA\
  Chai}{2012}]{Gerber:NomPredArgs2012}
Gerber, M.\BBACOMMA\ \BBA\ Chai, J.~Y. \BBOP 2012\BBCP.
\newblock \BBOQ Semantic Role Labeling of Implicit Arguments for Nominal
  Predicates.\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 38}  (4), \mbox{\BPGS\
  755--798}.

\bibitem[\protect\BCAY{Gildea \BBA\ Jurafsky}{Gildea \BBA\
  Jurafsky}{2002}]{Gildea:PredArgs2002}
Gildea, D.\BBACOMMA\ \BBA\ Jurafsky, D. \BBOP 2002\BBCP.
\newblock \BBOQ Automatic Labeling of Semantic Roles.\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 28}  (3), \mbox{\BPGS\
  245--288}.

\bibitem[\protect\BCAY{萩行\JBA 河原\JBA 黒橋}{萩行 \Jetal
  }{2014}]{Hangyo:ZeroAnaphra2014j}
萩行正嗣\JBA 河原大輔\JBA 黒橋禎夫 \BBOP 2014\BBCP.
\newblock 外界照応および著者・読者表現を考慮した日本語ゼロ照応解析.\
\newblock \Jem{自然言語処理}, {\Bbf 21}  (3), \mbox{\BPGS\ 563--600}.

\bibitem[\protect\BCAY{林部\JBA 小町\JBA 松本}{林部 \Jetal
  }{2014}]{Hayashibe:PredArgs2014j}
林部祐太\JBA 小町守\JBA 松本裕治 \BBOP 2014\BBCP.
\newblock 述語と項の位置関係ごとの候補比較による日本語述語項構造解析.\
\newblock \Jem{自然言語処理}, {\Bbf 21}  (1), \mbox{\BPGS\ 3--25}.

\bibitem[\protect\BCAY{Hovy, Marcus, Palmer, Ramshaw, \BBA\ Weischedel}{Hovy
  et~al.}{2006}]{hovy-EtAl:2006:HLT-NAACL06-Short}
Hovy, E., Marcus, M., Palmer, M., Ramshaw, L., \BBA\ Weischedel, R. \BBOP
  2006\BBCP.
\newblock \BBOQ OntoNotes: The 90\% Solution.\BBCQ\
\newblock In {\Bem Proceedings of the Human Language Technology Conference of
  the NAACL, Companion Volume: Short Papers}, \mbox{\BPGS\ 57--60}, New York,
  USA.

\bibitem[\protect\BCAY{飯田\JBA 小町\JBA 井之上\JBA 乾\JBA 松本}{飯田 \Jetal
  }{2010}]{Iida:NAISTCorpus2010j}
飯田龍\JBA 小町守\JBA 井之上直也\JBA 乾健太郎\JBA 松本裕治 \BBOP 2010\BBCP.
\newblock 述語項構造と照応関係のアノテーション：NAIST
  テキストコーパス構築の経験から.\
\newblock \Jem{自然言語処理}, {\Bbf 17}  (2), \mbox{\BPGS\ 25--50}.

\bibitem[\protect\BCAY{Iida, Komachi, Inui, \BBA\ Matsumoto}{Iida
  et~al.}{2007}]{iida-EtAl:2007:LAW}
Iida, R., Komachi, M., Inui, K., \BBA\ Matsumoto, Y. \BBOP 2007\BBCP.
\newblock \BBOQ Annotating a Japanese Text Corpus with Predicate-Argument and
  Coreference Relations.\BBCQ\
\newblock In {\Bem Proceedings of the Linguistic Annotation Workshop},
  \mbox{\BPGS\ 132--139}, Prague, Czech Republic.

\bibitem[\protect\BCAY{Imamura, Higashinaka, \BBA\ Izumi}{Imamura
  et~al.}{2014}]{imamura-higashinaka-izumi:2014:Coling}
Imamura, K., Higashinaka, R., \BBA\ Izumi, T. \BBOP 2014\BBCP.
\newblock \BBOQ Predicate-Argument Structure Analysis with Zero-Anaphora
  Resolution for Dialogue Systems.\BBCQ\
\newblock In {\Bem Proceedings of COLING 2014, the 25th International
  Conference on Computational Linguistics: Technical Papers}, \mbox{\BPGS\
  806--815}, Dublin, Ireland.

\bibitem[\protect\BCAY{Imamura, Saito, \BBA\ Izumi}{Imamura
  et~al.}{2009}]{imamura-saito-izumi:2009:Short}
Imamura, K., Saito, K., \BBA\ Izumi, T. \BBOP 2009\BBCP.
\newblock \BBOQ Discriminative Approach to Predicate-Argument Structure
  Analysis with Zero-Anaphora Resolution.\BBCQ\
\newblock In {\Bem Proceedings of the ACL-IJCNLP 2009 Conference Short Papers},
  \mbox{\BPGS\ 85--88}, Singapore.

\bibitem[\protect\BCAY{Jiang \BBA\ Ng}{Jiang \BBA\
  Ng}{2006}]{jiang-ng:2006:EMNLP}
Jiang, Z.~P.\BBACOMMA\ \BBA\ Ng, H.~T. \BBOP 2006\BBCP.
\newblock \BBOQ Semantic Role Labeling of NomBank: A Maximum Entropy
  Approach.\BBCQ\
\newblock In {\Bem Proceedings of the 2006 Conference on Empirical Methods in
  Natural Language Processing}, \mbox{\BPGS\ 138--145}, Sydney, Australia.

\bibitem[\protect\BCAY{河原\JBA 黒橋}{河原\JBA
  黒橋}{2005}]{Kawahara:CaseFrame2005j}
河原大輔\JBA 黒橋禎夫 \BBOP 2005\BBCP.
\newblock 格フレーム辞書の漸次的自動構築.\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (2), \mbox{\BPGS\ 109--131}.

\bibitem[\protect\BCAY{Komachi, Iida, Inui, \BBA\ Matsumoto}{Komachi
  et~al.}{2007}]{Komachi:PredArgs2007}
Komachi, M., Iida, R., Inui, K., \BBA\ Matsumoto, Y. \BBOP 2007\BBCP.
\newblock \BBOQ Learning-Based Argument Structure Analysis of Event-Nouns in
  Japanese.\BBCQ\
\newblock In {\Bem Proceedings of the Conference of the Pacific Association for
  Computational Linguistics (PACLING)}, \mbox{\BPGS\ 208--215}, Melbourne,
  Australia.

\bibitem[\protect\BCAY{Kudo \BBA\ Matsumoto}{Kudo \BBA\
  Matsumoto}{2002}]{Kudo:Cabocha2002}
Kudo, T.\BBACOMMA\ \BBA\ Matsumoto, Y. \BBOP 2002\BBCP.
\newblock \BBOQ Japanese Dependency Analysis using Cascaded Chunking.\BBCQ\
\newblock In {\Bem CoNLL 2002: Proceedings of the 6th Conference on Natural
  Language Learning 2002 (COLING 2002 Post-Conference Workshops)}, \mbox{\BPGS\
  63--69}, Taipei, Taiwan.

\bibitem[\protect\BCAY{Kudo, Yamamoto, \BBA\ Matsumoto}{Kudo
  et~al.}{2004}]{kudo-yamamoto-matsumoto:2004:EMNLP}
Kudo, T., Yamamoto, K., \BBA\ Matsumoto, Y. \BBOP 2004\BBCP.
\newblock \BBOQ Applying Conditional Random Fields to Japanese Morphological
  Analysis.\BBCQ\
\newblock In {\Bem Proceedings of EMNLP 2004}, \mbox{\BPGS\ 230--237},
  Barcelona, Spain.

\bibitem[\protect\BCAY{Laparra \BBA\ Rigau}{Laparra \BBA\
  Rigau}{2013}]{laparra-rigau:2013:ACL2013}
Laparra, E.\BBACOMMA\ \BBA\ Rigau, G. \BBOP 2013\BBCP.
\newblock \BBOQ ImpAr: A Deterministic Algorithm for Implicit Semantic Role
  Labelling.\BBCQ\
\newblock In {\Bem Proceedings of the 51st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, \mbox{\BPGS\
  1180--1189}, Sofia, Bulgaria.

\bibitem[\protect\BCAY{M\`arquez, Carreras, Litkowski, \BBA\
  Stevenson}{M\`arquez et~al.}{2008}]{Marquez:SRLSurvay2008}
M\`arquez, L., Carreras, X., Litkowski, K.~C., \BBA\ Stevenson, S. \BBOP
  2008\BBCP.
\newblock \BBOQ Semantic Role Labeling: An Introduction to the Special
  Issue.\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 34}  (2), \mbox{\BPGS\
  145--159}.

\bibitem[\protect\BCAY{松林\JBA 飯田\JBA 笹野\JBA 横野\JBA 松吉\JBA 藤田\JBA
  宮尾\JBA 乾}{松林 \Jetal }{2014}]{Matsubayashi:PredArgsData2014j}
松林優一郎\JBA 飯田龍\JBA 笹野遼平\JBA 横野光\JBA 松吉俊\JBA 藤田篤\JBA
  宮尾祐介\JBA 乾健太郎 \BBOP 2014\BBCP.
\newblock 日本語文章に対する述語項構造アノテーション仕様の考察.\
\newblock \Jem{自然言語処理}, {\Bbf 21}  (2), \mbox{\BPGS\ 333--377}.

\bibitem[\protect\BCAY{Palmer, Gildia, \BBA\ Kingsbury}{Palmer
  et~al.}{2005}]{Palmer:PropBank2005}
Palmer, M., Gildia, D., \BBA\ Kingsbury, P. \BBOP 2005\BBCP.
\newblock \BBOQ The Proposition Bank: An Annotated Corpus of Semantic
  Roles.\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 31}  (1), \mbox{\BPGS\
  71--105}.

\bibitem[\protect\BCAY{Pradhan, Moschitti, \BBA\ Xue}{Pradhan
  et~al.}{2012}]{conll2012-shared-task}
Pradhan, S., Moschitti, A., \BBA\ Xue, N.\BEDS\ \BBOP 2012\BBCP.
\newblock {\Bem Joint Conference on EMNLP and CoNLL: Proceeding of the Shared
  Task: Modeling Multilingual Unrestricted Coreference in Onto Notes}, Jeju,
  Korea.

\bibitem[\protect\BCAY{Pradhan, Ward, \BBA\ Martin}{Pradhan
  et~al.}{2008}]{Pradhan:SRLAdaptation2008}
Pradhan, S.~S., Ward, W., \BBA\ Martin, J.~H. \BBOP 2008\BBCP.
\newblock \BBOQ Towards Robust Semantic Role Labeling.\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 34}  (2), \mbox{\BPGS\
  289--310}.

\bibitem[\protect\BCAY{Ruppenhofer, Ellsworth, Petruck, Johnson, \BBA\
  Scheffczyk}{Ruppenhofer
  et~al.}{2006}]{RuppenhoferEtAl2006:ExtTeoryAndPractice}
Ruppenhofer, J., Ellsworth, M., Petruck, M.~R., Johnson, C.~R., \BBA\
  Scheffczyk, J. \BBOP 2006\BBCP.
\newblock {\Bem FrameNet II: Extended Theory and Practice}.
\newblock International Computer Science Institute, Berkeley, California.
\newblock Distributed with the FrameNet data.

\bibitem[\protect\BCAY{Sasano, Kawahara, \BBA\ Kurohashi}{Sasano
  et~al.}{2008}]{sasano-kawahara-kurohashi:2008:PAPERS}
Sasano, R., Kawahara, D., \BBA\ Kurohashi, S. \BBOP 2008\BBCP.
\newblock \BBOQ A Fully-Lexicalized Probabilistic Model for Japanese Zero
  Anaphora Resolution.\BBCQ\
\newblock In {\Bem Proceedings of the 22nd International Conference on
  Computational Linguistics (COLING 2008)}, \mbox{\BPGS\ 769--776}, Manchester,
  UK.

\bibitem[\protect\BCAY{Sasano, Kawahara, Kurohashi, \BBA\ Okumura}{Sasano
  et~al.}{2013}]{sasano-EtAl:2013:EMNLP}
Sasano, R., Kawahara, D., Kurohashi, S., \BBA\ Okumura, M. \BBOP 2013\BBCP.
\newblock \BBOQ Automatic Knowledge Acquisition for Case Alternation between
  the Passive and Active Voices in Japanese.\BBCQ\
\newblock In {\Bem Proceedings of the 2013 Conference on Empirical Methods in
  Natural Language Processing}, \mbox{\BPGS\ 1213--1223}, Seattle, Washington,
  USA.

\bibitem[\protect\BCAY{Stolcke, Zheng, Wang, \BBA\ Abrash}{Stolcke
  et~al.}{2011}]{Stolcke:SRILM2011}
Stolcke, A., Zheng, J., Wang, W., \BBA\ Abrash, V. \BBOP 2011\BBCP.
\newblock \BBOQ SRILM at Sixteen: Update and Outlook.\BBCQ\
\newblock In {\Bem Proceedings of IEEE Automatic Speech Recognition and
  Understanding Workshop (ASRU 2011)}, Waikoloa, Hawaii, USA.

\bibitem[\protect\BCAY{Taira, Fujita, \BBA\ Nagata}{Taira
  et~al.}{2008}]{taira-fujita-nagata:2008:EMNLP}
Taira, H., Fujita, S., \BBA\ Nagata, M. \BBOP 2008\BBCP.
\newblock \BBOQ A Japanese Predicate Argument Structure Analysis using Decision
  Lists.\BBCQ\
\newblock In {\Bem Proceedings of the 2008 Conference on Empirical Methods in
  Natural Language Processing}, \mbox{\BPGS\ 523--532}, Honolulu, Hawaii, USA.

\bibitem[\protect\BCAY{平\JBA 田中\JBA 藤田\JBA 永田}{平 \Jetal
  }{2014}]{Taira:PredArgs2014j}
平博順\JBA 田中貴秋\JBA 藤田早苗\JBA 永田昌明 \BBOP 2014\BBCP.
\newblock ビジネスメールに対する日本語述語項構造解析の検討.\
\newblock \Jem{言語処理学会第 20 回年次大会発表論文集}, \mbox{\BPGS\
  1019--1022}, 札幌.

\bibitem[\protect\BCAY{Tur, Hakkani-T{\"{u}}r, \BBA\ Chotimongkol}{Tur
  et~al.}{2005}]{Tur:UnderstandingSRL2005}
Tur, G., Hakkani-T{\"{u}}r, D., \BBA\ Chotimongkol, A. \BBOP 2005\BBCP.
\newblock \BBOQ Semi-Supervised Learning for Spoken Language Understanding
  Using Semantic Role Labeling.\BBCQ\
\newblock In {\Bem Proceedings of Automatic Speech Recognition and
  Understanding Workshop (ASRU 2005)}, \mbox{\BPGS\ 232--237}, San Juan, Puerto
  Rico.

\bibitem[\protect\BCAY{吉川\JBA 浅原\JBA 松本}{吉川 \Jetal
  }{2013}]{Yoshikawa:PredArgs2013j}
吉川克正\JBA 浅原正幸\JBA 松本裕治 \BBOP 2013\BBCP.
\newblock Markov Logic による日本語述語項構造解析.\
\newblock \Jem{自然言語処理}, {\Bbf 20}  (2), \mbox{\BPGS\ 251--271}.

\end{thebibliography}

\begin{biography}

\bioauthor{今村　賢治}{
1985年千葉大学工学部電気工学科卒業．
同年〜2014年日本電信電話株式会社．
1995年〜1998年NTTソフトウェア株式会社．
2000年〜2006年ATR音声言語コミュニケーション研究所．
2014年より株式会社 ATR-Trek所属として，独立行政法人情報通信研究機構(NICT)へ出向．
現在NICT先進的音声翻訳研究開発推進センター専門研究員．
主として自然言語処理技術の研究・開発に従事．博士（工学）．
電子情報通信学会，情報処理学会，言語処理学会，ACL各会員．}

\bioauthor{東中竜一郎}{
1999年に慶應義塾大学環境情報学部卒業，
2001年に同大学大学院政策・メディア研究科修士課程，
2008年に博士課程修了．博士（学術）．
2001年に日本電信電話株式会社入社．
現在，NTT メディアインテリジェンス研究所にて勤務．
音声言語メディアプロジェクトにて，質問応答システム・音声対話システムの研究に従事．
言語処理学会，人工知能学会，情報処理学会，電子情報通信学会，各会員．
2004年から2006年にかけて，英国シェフィールド大学客員研究員．}

\bioauthor{泉　　朋子}{
2005年北海道教育大学国際理解教育課程卒業，
2007年ボストン大学大学院人文科学部応用言語学科修了，
2008年日本電信電話株式会社入社．
2014年京都大学大学院情報学研究科博士後期課程修了．博士（情報学）．
現在，NTTメディアインテリジェンス研究所研究員，自然言語処理研究開発に従事．
言語処理学会会員．}




\end{biography}


\biodate


\end{document}
