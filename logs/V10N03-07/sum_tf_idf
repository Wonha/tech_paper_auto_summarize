================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:3, score:225] コンテストには，我々は，サポートベクトルマシン法，シンプルベイズ法，またそれらの組み合わせのシステム二つの合計4システムを提出し，組合わせシステムが参加システム中もっとも高い精度(0.786)を得た．
[i:4, score:123] コンテストの後，シンプルベイズ法で用いていたパラメータを調節したところさらに高い精度を得た．
[i:5, score:120] 現在もっとも性能の高いシステムは二つのシンプルベイズ法を組み合わせたシステムであり，その精度は0.793である．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:13, score:172] その結果，シンプルベイズ法とサポートベクトルマシン法が比較的よい精度を出したのでその二つの機械学習手法を基本とすることにした．
[i:15, score:181] コンテストには，シンプルベイズ法，サポートベクトルマシン法，またそれらの組み合わせのシステム二つの合計四つのシステムをコンテストに提出した．
[i:21, score:126] [REF_sec:ml_method]節でわれわれが利用した機械学習手法について述べ，[REF_sec:sosei]節でその機械学習手法で用いる素性について述べ，[REF_sec:experiment]節でその機械学習手法と素性を用いた実験とその考察について述べる．

================================================================
[section type  : proposed_method]
[section title : 多義性解消の重要性]
================================================================
[i:37, score:70] ここで例えばEDR辞書[CITE]を利用すると，「虎」の同義語としては「トラ」「酒酔」「酒酔い」「酔客」「酔狂人」「酔人」が得られる．
[i:38, score:65] これは「虎」には「虎という動物」と「酒に酔った人」の二つの意味があり，この後ろの「酒に酔った人」の意味の場合の同義語が得られて「酒酔い」などの不要な同義語が得られるのである．
[i:42, score:84] ここで多義性の解消をし，ここでの「虎」の意味は「虎という動物」と認識し同義語は「トラ」だけであるとしてから，解の抽出をした方が誤る可能性は減るのである．

================================================================
[section type  : proposed_method]
[section title : 問題設定]
================================================================
[i:50, score:54] SENSEVAL2の日本語辞書タスクでは，評価用のデータとしては100単語(このうち50単語が名詞で50単語が動詞)についてそれぞれ100事例が与えられ，合計10000事例が与えられた．
[i:52, score:42] このコーパスは毎日新聞の1994年の3,000個の記事を用いたもので，コーパス中の主要な名詞，動詞，形容詞(総数：約15万個)に対して，岩波国語辞典に基づいて定義された語義がふられている．
[i:54, score:51] また，精度の評価には，SENSEVAL2のホームページより取得できるscorer2という評価用プログラムによって算出される，mixed-grained scoreという値が用いられた．

================================================================
[section type  : proposed_method]
[section title : 機械学習手法]
================================================================
[i:55, score:81] 一般に，単語多義性解消問題の場合，各単語にふられる語義は，単語ごとにかわるので，機械学習手法による実験は各単語ごとに逐次的に行なわれる．
[i:61, score:77] シンプルベイズ法
[i:64, score:70] 本節ではこれらの個々の機械学習手法の説明と，これらの機械学習手法のいくつかを組み合わせる融合手法について説明する．
-----------------------------------------------------
  [subsection title : シンプルベイズ法]
-----------------------------------------------------
  [i:lead, 129] シンプルベイズ法は，ベイズの定理に基づいて各分類になる確率を推定し，その確率値が最も大きい分類を求める分類とする方法であり，多義性解消の研究における基本的な方法である．
.....
  [i:65, score:129] シンプルベイズ法は，ベイズの定理に基づいて各分類になる確率を推定し，その確率値が最も大きい分類を求める分類とする方法であり，多義性解消の研究における基本的な方法である．
  [i:70, score:67] [MATH]と[MATH]は，それぞれ学習データから推定された確率で，分類aの出現の確率，分類aのときに素性[MATH]を持つ確率を意味する．
  [i:74, score:55] }ただし，[MATH]と[MATH]は，それぞれ，素性[MATH]を持ちかつ分類が[MATH]である事例の個数，分類が[MATH]である事例の個数を意味する．
-----------------------------------------------------
  [subsection title : 決定リスト法]
-----------------------------------------------------
  [i:lead, 76] これは，素性[MATH]と分類先[MATH]の組を規則とし，それらをあらかじめ定めた優先順序でリストに蓄えておき，リストで優先順位の高いところから，入力と素性が一致する規則を利用して分類先を求める方法である[CITE]．
.....
  [i:77, score:76] これは，素性[MATH]と分類先[MATH]の組を規則とし，それらをあらかじめ定めた優先順序でリストに蓄えておき，リストで優先順位の高いところから，入力と素性が一致する規則を利用して分類先を求める方法である[CITE]．
  [i:80, score:47] }この方法は，以下の式で与えられる，ある文脈[MATH]での分類[MATH]を出力する確率[MATH]がもっとも高い分類[MATH]を解とする方法と等価であり，本稿では実際にはこの方法を用いて分類先を特定する．
  [i:84, score:63] }また，[MATH]は学習データで素性[MATH]を文脈に持つ場合の分類[MATH]の出現の割合である．
-----------------------------------------------------
  [subsection title : サポートベクトルマシン法]
-----------------------------------------------------
  [i:lead, 79] サポートベクトルマシン法は，空間を超平面で分割することにより2つの分類からなるデータを分類する手法である．
.....
  [i:85, score:79] サポートベクトルマシン法は，空間を超平面で分割することにより2つの分類からなるデータを分類する手法である．
  [i:101, score:84] サポートベクトルマシン法は分類の数が2個のデータを扱うもので，通常これにペアワイズ手法を組み合わせて用いることで，分類の数が3個以上のデータを扱うことになる[CITE]．
  [i:102, score:112] ペアワイズ手法とは，N個の分類を持つデータの場合，異なる二つの分類先のあらゆるペア(N(N-1)/2個)を作り，各ペアごとにどちらがよいかを2値分類器(ここではサポートベクトルマシン法)で求め，最終的にN(N-1)/2個の2値分類器の分類先の多数決により，分類先を求める方法である．
-----------------------------------------------------
  [subsection title : 融合手法]
-----------------------------------------------------
  [i:lead, 70] 本節では，いくつかの機械学習を組み合わせて用いる融合手法について説明する．
.....
  [i:110, score:275] 融合手法2二種類のシンプルベイズ([MATH]=0.01)と二種類のサポートベクトルマシンの合計四種類のシステムの組み合わせただし，ここでいう二種類は[REF_sec:sosei]節で後述する素性(解析に用いる情報)をすべて用いた場合と，KNP構文素性のみを削除した場合の二つの場合を意味する．
  [i:111, score:179] 融合手法3シンプルベイズ([MATH]=0.0001)とサポートベクトルマシンの組み合わせ
  [i:112, score:278] 融合手法4二種類のシンプルベイズ([MATH]=0.0001)と二種類のサポートベクトルマシンの合計四種類のシステムの組み合わせただし，ここでいう二種類は[REF_sec:sosei]節で後述する素性(解析に用いる情報)をすべて用いた場合と，KNP構文素性のみを削除した場合の二つの場合を意味する．

================================================================
[section type  : proposed_method]
[section title : 素性(解析に用いる情報)]
================================================================
[i:114, score:76] 前節で種々の機械学習の説明を述べたが，それぞれの手法ともに素性(解析に用いる情報)を定義しなければ，その手法を用いることができない．
[i:125, score:75] 解析する形態素の直前の形態素の単語自身，その単語の分類語彙表[CITE]の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞細細分類情報
[i:138, score:93] UDC素性RWCコーパスには，各記事ごとに図書館などで書籍の分類に用いられる，国際十進分類(UDC)がふられている．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[i:141, score:102] 本節ではまず[REF_sec:experiment1]節で，コンテストに提出したシステム，また，コンテストの後に改良したシステムについて記述し，その後[REF_sec:experiment2]節で，素性を変更した実験について記述する．
-----------------------------------------------------
  [subsection title : コンテストの実験結果(一部コンテスト後のシステムも含む)]
-----------------------------------------------------
  [i:lead, 244] われわれはSENEVAL2のコンテストに四つのシステム(CRL1からCRL4)，すなわち，サポートベクトルマシン，シンプルベイズ([MATH])，融合手法1，融合手法2を提出した．
.....
  [i:142, score:244] われわれはSENEVAL2のコンテストに四つのシステム(CRL1からCRL4)，すなわち，サポートベクトルマシン，シンプルベイズ([MATH])，融合手法1，融合手法2を提出した．
  [i:160, score:240] 融合手法としてはシンプルベイズ法でのパラメータ調整が適切でない場合つまり，[MATH]のとき，サポートベクトルマシンが0.783でシンプルベイズが0.778でそれらの融合が0.786であったので，精度向上を実現できる場合があることがわかる．
  [i:161, score:200] しかし，シンプルベイズ法でのパラメータ調整を適切にした場合つまり，[MATH]のとき，サポートベクトルマシンが0.783でシンプルベイズが0.790でそれらの融合が0.787であったので，精度向上を実現できていない．
-----------------------------------------------------
  [subsection title : 素性を変更した実験]
-----------------------------------------------------
  [i:lead, 49] 次に解析に用いる情報，すなわち，素性を変更した場合の実験を行なった．
.....
  [i:175, score:179] この実験では融合手法は用いず，シンプルベイズ([MATH])，サポートベクトルマシン，決定リストで行なった．
  [i:182, score:142] シンプルベイズ法では，名詞50単語，動詞50単語でも，全素性を用いる方法が安定して最も高い精度を獲得した．
  [i:183, score:140] サポートベクトルマシン法では，名詞ではUDC素性を用いない方法が最もよく，動詞では文字列素性のみを用いる方法がもっともよかった．

================================================================
[section type  : proposed_method]
[section title : 関連文献]
================================================================
[i:199, score:253] その意味で，日本語多義解消の問題で「シンプルベイズ法」「決定リスト法」「サポートベクトルマシン法」の三つの機械学習手法，さらには，素性を変化させた場合の実験結果を示している本稿は，今後の日本語単語の多義語の曖昧性解消の問題を考えるための資料として非常に役に立つものと思われる．
[i:218, score:120] 中野らの報告では，AdaBoostを利用することで決定リスト法，シンプルベイズ法よりも高い精度を得たと報告している．
[i:221, score:117] しかし，中野らはわれわれのシステムでは用いていない日本語語彙体系[CITE]の辞書の情報を用いており，中野らの方が素性の情報が少ないとは言い切れないので，われわれのシステムの素性の情報でAdaBoostを利用するとさらによい精度を得ることができるかどうかはわからない．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:233, score:197] 我々は，サポートベクトルマシン法，シンプルベイズ法，またそれらの組み合わせのシステム二つの合計4システムを提出し，組合わせシステムが参加システム中もっとも高い精度(0.786)を得た．
[i:234, score:123] コンテストの後，シンプルベイズ法で用いていたパラメータを調節したところさらに高い精度を得た．
[i:235, score:120] 現在もっとも性能の高いシステムは二つのシンプルベイズ法を組み合わせたシステムであり，その精度は0.793である．

