本節では多義性解消の重要性を例を用いながら説明する．
例えば，最近重要視されつつある質問応答[CITE]の問題を考えてみる．
ここで，質問応答の質問として以下のようなものがあったとしよう．
「トラは天王寺動物園にはどのくらいいますか。
」
ここで質問応答システムの知識源として，
「天王寺動物園にはトラが11頭飼育されており…」
があったとする．
この場合システムは「どのくらい」などの表現から数量表現が解とわかるのでこの知識源から「11頭」を解として正しく抽出することができる．
しかし，質問が以下のようであったとしよう．
「虎は天王寺動物園にはどのくらいいますか。
」
この質問では先の質問の「トラ」が「虎」に変わっている．
この場合，「トラ」と「虎」が同一であることを計算機に認識させなければならないが，これをするためには計算機に単語の意味に関する情報を与えておかなければならない．
ここで例えばEDR辞書[CITE]を利用すると，「虎」の同義語としては「トラ」「酒酔」「酒酔い」「酔客」「酔狂人」「酔人」が得られる．
これは「虎」には「虎という動物」と「酒に酔った人」の二つの意味があり，この後ろの「酒に酔った人」の意味の場合の同義語が得られて「酒酔い」などの不要な同義語が得られるのである．
この不要な同義語を使って解の抽出を試みる場合，例えば
「昨夜未明，天王寺動物園で5人の酒酔い客が暴れだし…」
という文が知識中にある場合，誤って「５人」を解として取り出してしまう可能性がある．
ここで多義性の解消をし，ここでの「虎」の意味は「虎という動物」と認識し同義語は「トラ」だけであるとしてから，解の抽出をした方が誤る可能性は減るのである．
「虎」の場合はまだ意味が二つであったからよいが，高頻度に用いられる平易な語ほど語義の数が多く，この問題は深刻なものとなる．
このことから，多義性の解消の重要性がわかる．
ここでは質問応答の場合の例をあげたが各解析システムにおいて多義性の解消は同様に重要なものとなろう．
例えば，照応解析[CITE]においても，ある語Aが「人間」と「物」の二つの意味をもっていて，物しか指示しない「それ」という指示詞が出現した場合，語Ａの多義性を解消し，もし「人間」であるということがわかれば，この「それ」の指示先は語Aではありえないとわかり他の指示先の候補を探せばよいとわかる．
また，機械翻訳でも訳し分けが必要な語は多義性を解消しなければ正しい翻訳をすることができない．
このように多義性の解消は種々の場面で役に立つものである．
本節ではSENSEVAL2の日本語辞書タスクの問題設定について説明する．
SENSEVAL2の日本語辞書タスクでは，評価用のデータとしては100単語(このうち50単語が名詞で50単語が動詞)についてそれぞれ100事例が与えられ，合計10000事例が与えられた．
学習用のデータとしては，RWCコーパス[CITE]が与えられた．
このコーパスは毎日新聞の1994年の3,000個の記事を用いたもので，コーパス中の主要な名詞，動詞，形容詞(総数：約15万個)に対して，岩波国語辞典に基づいて定義された語義がふられている．
このタスクの目的は，この語義をその単語のまわりの情報などを用いて推定することである．
また，精度の評価には，SENSEVAL2のホームページより取得できるscorer2という評価用プログラムによって算出される，mixed-grained scoreという値が用いられた．
一般に，単語多義性解消問題の場合，各単語にふられる語義は，単語ごとにかわるので，機械学習手法による実験は各単語ごとに逐次的に行なわれる．
つまり，学習器は単語の異なり数の分だけ作成する．
しかし本タスクでは，あらかじめ50個が名詞で，50個が動詞であるとわかっている．
このため，システムは，単語ごとだけでなく，単語と品詞の組に対して個々に作成した．
本コンテストの場合，50個の名詞と50個の動詞が対象であったので，合計100個の学習器を作ることになる．
本稿では学習器のために用いる機械学習手法としては，以下の方法を利用した．
シンプルベイズ法
決定リスト法
サポートベクトルマシン法
本節ではこれらの個々の機械学習手法の説明と，これらの機械学習手法のいくつかを組み合わせる融合手法について説明する．
シンプルベイズ法は，ベイズの定理に基づいて各分類になる確率を推定し，その確率値が最も大きい分類を求める分類とする方法であり，多義性解消の研究における基本的な方法である．
文脈[MATH]で分類[MATH]を出力する確率は以下の式で与えられる．
{
}ただし，ここで文脈[MATH]は，あらかじめ設定しておいた素性[MATH]の集合である．
[MATH]は，文脈[MATH]の出現確率で，今回の場合分類aに非依存で定数のため，計算しない．
[MATH]と[MATH]は，それぞれ学習データから推定された確率で，分類aの出現の確率，分類aのときに素性[MATH]を持つ確率を意味する．
[MATH]として最尤推定し求めた値を用いると，しばしば値がゼロになり，式([REF_eq:simple_bayes])の値がゼロになり分類先を決めるのが難しい場合が多い．
このため，スムージングがなされるが，本稿では以下のスムージングをしたものを用いる．
{
}ただし，[MATH]と[MATH]は，それぞれ，素性[MATH]を持ちかつ分類が[MATH]である事例の個数，分類が[MATH]である事例の個数を意味する．
[MATH]は実験で定める定数である．
本稿では，[MATH]としては0.01と0.0001を用いた．
これは，素性[MATH]と分類先[MATH]の組を規則とし，それらをあらかじめ定めた優先順序でリストに蓄えておき，リストで優先順位の高いところから，入力と素性が一致する規則を利用して分類先を求める方法である[CITE]．
本稿では優先順序としては以下のものを用いる[MATH]．
{
}この方法は，以下の式で与えられる，ある文脈[MATH]での分類[MATH]を出力する確率[MATH]がもっとも高い分類[MATH]を解とする方法と等価であり，本稿では実際にはこの方法を用いて分類先を特定する．
{
}ただし，[MATH]は以下の式によって与えられる．
{
}また，[MATH]は学習データで素性[MATH]を文脈に持つ場合の分類[MATH]の出現の割合である．
サポートベクトルマシン法は，空間を超平面で分割することにより2つの分類からなるデータを分類する手法である．
このとき，2つの分類が正例と負例からなるものとすると，学習データにおける正例と負例の間隔(マージン)が大きいもの(図[REF_fig:margin]参照)ほどオープンデータで誤った分類をする可能性が低いと考えられ，このマージンを最大にする超平面を求めそれを用いて分類を行なう．
基本的には上記のとおりであるが，通常，学習データにおいてマージンの内部領域に少数の事例が含まれてもよいとする手法の拡張や，超平面の線形の部分を非線型にする拡張(カーネル関数の導入)がなされたものが用いられる．
この拡張された方法は，以下の識別関数を用いて分類することと等価であり，その識別関数の出力値が正か負かによって二つの分類を判別することができる[CITE]．
{
}ただし，[MATH]は識別したい事例の文脈(素性の集合)を，[MATH]と[MATH]は学習データの文脈と分類先を意味し，関数[MATH]は，{
}であり，また，各[MATH]は式([REF_eq:svm5])と式([REF_eq:svm6])の制約のもと式([REF_eq:svm4])の[MATH]を最大にする場合のものである．
{
} {
} {
}また，関数[MATH]はカーネル関数と呼ばれ，様々なものが用いられるが本稿では以下の多項式のものを用いる．
{
} [MATH]は実験的に設定される定数である．
本稿ではすべての実験を通して[MATH],[MATH]はそれぞれ1と2に固定した．
ここで，[MATH]となる[MATH]は，サポートベクトルと呼ばれ，通常，式([REF_eq:svm1])の和をとっている部分はこの事例のみを用いて計算される．
つまり，実際の解析には学習データのうちサポートベクトルと呼ばれる事例のみしか用いられない．
サポートベクトルマシン法は分類の数が2個のデータを扱うもので，通常これにペアワイズ手法を組み合わせて用いることで，分類の数が3個以上のデータを扱うことになる[CITE]．
ペアワイズ手法とは，N個の分類を持つデータの場合，異なる二つの分類先のあらゆるペア(N(N-1)/2個)を作り，各ペアごとにどちらがよいかを2値分類器(ここではサポートベクトルマシン法)で求め，最終的にN(N-1)/2個の2値分類器の分類先の多数決により，分類先を求める方法である．
本稿のサポートベクトルマシン法は，上記のようにサポートベクトルマシン法とペアワイズ手法を組み合わせることによって実現される．
本節では，いくつかの機械学習を組み合わせて用いる融合手法について説明する．
われわれの融合手法では，それぞれの単語ごとに用いる機械学習手法を変更する．
(厳密には，本稿の場合は単語と名詞の組に対して学習器を作成しているので，この融合手法はそれぞれの単語と名詞の組ごとに機械学習手法を変更することになる．
)各単語ごとに用いられる機械学習手法は，融合する機械学習手法のうち学習データでの10分割のクロスバリデーションの精度がもっともよかったものとする．
われわれは融合手法としては以下の五つの手法を試した．
融合手法1
シンプルベイズ([MATH]=0.01)とサポートベクトルマシンの組み合わせ
融合手法2
二種類のシンプルベイズ([MATH]=0.01)と二種類のサポートベクトルマシンの合計四種類のシステムの組み合わせ
ただし，ここでいう二種類は[REF_sec:sosei]節で後述する素性(解析に用いる情報)をすべて用いた場合と，KNP構文素性のみを削除した場合の二つの場合を意味する．
融合手法3
シンプルベイズ([MATH]=0.0001)とサポートベクトルマシンの組み合わせ
融合手法4
二種類のシンプルベイズ([MATH]=0.0001)と二種類のサポートベクトルマシンの合計四種類のシステムの組み合わせ
ただし，ここでいう二種類は[REF_sec:sosei]節で後述する素性(解析に用いる情報)をすべて用いた場合と，KNP構文素性のみを削除した場合の二つの場合を意味する．
融合手法5
[MATH]=0.01のシンプルベイズと[MATH]=0.0001のシンプルベイズの組み合わせ
前節で種々の機械学習の説明を述べたが，それぞれの手法ともに素性(解析に用いる情報)を定義しなければ，その手法を用いることができない．
本節ではその素性の説明を行なう．
[REF_sec:mondai_settei]節の問題設定で述べたように，本稿の問題設定では，日本語文の入力を与えられたときに，その入力中の語義タグがふられていた各形態素に対して，その語義の分類を推定して出力することになっている．
このため，解析に用いる情報，すなわち，素性は入力される日本語文から取り出すことになる．
本稿では素性としては以下のものを定義する．
文字列素性
解析する形態素自身の文字列
解析する形態素の直前の1〜3 gramの文字列
解析する形態素の直後の1〜3 gramの文字列
RWC形態素素性
解析する形態素自身のRWCコーパスの品詞情報，品詞細分類情報，品詞細細分類情報
解析する形態素の直前の形態素の単語自身，その単語の分類語彙表[CITE]の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞細細分類情報
解析する形態素の直後の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞細細分類情報
JUMAN形態素素性
コーパスをJUMAN[CITE]で形態素解析し，その結果を素性として利用する．
解析する形態素自身のJUMANの解析結果の品詞情報，品詞細分類情報，品詞活用形情報
解析する形態素の直前の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報
解析する形態素の直後の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報
構文素性
コーパスをKNP[CITE]で構文解析し，その結果を素性として利用する．
解析する形態素を含む文節自身，また，その文節が体言かいなか，付属語の品詞，品詞細分類，活用情報
解析する形態素を含む文節の係り先の文節の自立語，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報
解析する形態素を含む文節の係り元の文節の自立語，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報．
ただし，すべての場合において，付属語の情報を併用する．
同一文内共起素性
コーパスをJUMANで形態素解析し，その解析結果の形態素列を素性として利用する．
同一文中の各形態素，また，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁．
UDC素性
RWCコーパスには，各記事ごとに図書館などで書籍の分類に用いられる，国際十進分類(UDC)がふられている．
この情報は各記事がどういう分野のものかを示している．
解析対象とする形態素を含む記事のUDCコードの最初の1桁，2桁，3桁．
本節では関連文献について説明する．
英語単語の多義語の曖昧性解消に機械学習手法を用いた研究は極めて多数存在する[CITE]が，日本語単語の多義語の曖昧性解消に機械学習手法を用いた研究は，SENSEVAL2以前はほとんどなかった[CITE]．
例えば，新納の研究では語の多義の解消ではなく，同音異義語の判別を扱っていた．
その意味で，日本語多義解消の問題で「シンプルベイズ法」「決定リスト法」「サポートベクトルマシン法」の三つの機械学習手法，さらには，素性を変化させた場合の実験結果を示している本稿は，今後の日本語単語の多義語の曖昧性解消の問題を考えるための資料として非常に役に立つものと思われる．
次にいくつかの関連研究を紹介したい．
まず，SENSEVAL2で英語を含む数多くの言語で優秀な成績をとっていたYarowskyらのシステム[CITE]について説明する．
Yarowskyらのシステムは，シンプルベイス法と決定リストの組み合わせであり，決定リストで求まる確信度が高いところでは決定リストの手法の解を用い，それ以外の場合は種々の手法の多数決の結果を解とする手法である．
確信度を用い決定リストで確実に求まるところだけを別個に扱っているところが興味深い．
次に，SENSEVAL2の日本語辞書タスクに参加していた八木らのシステム[CITE]について説明する．
八木らのシステムは決定リスト法を機械学習手法として用いており，学習用のデータとして，RWCコーパス以外に岩波国語辞典の例文のデータを用いていることを特徴としている．
RWCコーパスでの語義の定義は岩波国語辞典を用いているため，岩波国語辞典の例文のデータも語義解析のための学習データとして利用できるのである．
八木らの研究ではこの例文データも利用した場合の方が利用しない場合よりも精度が高かったとしている．
この結果は，われわれの研究でもこのデータを追加で用いることで精度を向上できる可能性を示唆するものであり，興味深い．
次に，高村らの素性空間を再構成する手法[CITE]について説明する．
この研究は英語を対象に行なわれており，機械学習手法としてはサポートベクトルマシン法を利用している．
この手法は学習に用いる素性を構成し直すところに特徴がある．
普通に抽出した素性だけでなく，その素性の分布に対して独立成分分析や主成分分析を行ない，元々の素性よりも一段抽象化したような素性を新たに作り出し，これも素性として追加で用いる方法である．
この素性を再構成する方法を含めた複数のシステムの多数決を用いる方法で，単純なサポートベクトルマシン法の性能を上回ったとしている．
独立成分分析などにより素性の情報を抽象化することでデータスパースネス対策などに役立っていると思われ，興味深い．
最後に，中野らのAdaBoostを用いた手法[CITE]を説明する．
この研究ではSENSEVAL2日本語タスクのデータを対象としており，AdaBoostを機械学習手法として利用している．
AdaBoostは正しく分類された事例の重みを下げ，誤って分類された事例の重みを上げて，再学習をする手法である．
中野らの報告では，AdaBoostを利用することで決定リスト法，シンプルベイズ法よりも高い精度を得たと報告している．
ただし，その最高精度は79.1 %であり，われわれの最高精度の79.3 %より若干低い．
しかし，この結果はわれわれのシステムの素性の情報が豊かであるためである可能性があり，われわれのシステムの素性の情報でAdaBoostを利用するとさらによい精度を得ることができる可能性がある．
しかし，中野らはわれわれのシステムでは用いていない日本語語彙体系[CITE]の辞書の情報を用いており，中野らの方が素性の情報が少ないとは言い切れないので，われわれのシステムの素性の情報でAdaBoostを利用するとさらによい精度を得ることができるかどうかはわからない．
また，われわれのシステムの素性の情報の方が豊富であっても，われわれのシステムの素性でAdaBoostが本当によい精度を出せるかどうかはわからない．
次に，多義性の研究に直接は関係はないが，複数の機械学習の方法を組み合わせるのに，スタッキングを用いる手法[CITE]について説明したい．
スタッキングを用いる手法とは，もともとの素性の他に，複数の機械学習の結果を素性として追加し，その追加された素性を用いて機械学習を行なう方法である．
従来は複数の機械学習の方法の融合には多数決が多く用いられていたが，スタッキングの方法ではどの機械学習の方法がよいかを学習することになっておりたいていの場合で多数決の方法よりも精度が高くなると思われる．
このスタッキングを利用する研究としては，形態素解析のもの[CITE]や固有名詞表現抽出のもの[CITE]などがある．
本稿でのシステムの融合では，各単語でもっとも精度の高い手法を利用していた．
このわれわれの融合手法は各単語ごとに用いる手法を最尤推定で求めるものになっていて少々は融合に学習を用いていることにはなっている．
しかし，手法の組み合わせにおいても強力な学習手法を用いた方が精度はよいと思われるので，われわれの手法でもスタッキングを利用することを考えた方がよい．
以上，種々の有力な関連研究を紹介した．
それぞれの手法ともに特徴的な要素を持っており，[REF_sec:experiment2]節の最後に述べた考察と含めてそれらを総合的に考察し，それぞれの手法の良い面を組み合わせることで，さらによりよい多義解消を行なえると思われる．
本節では多義性解消の重要性を例を用いながら説明する．
例えば，最近重要視されつつある質問応答[CITE]の問題を考えてみる．
ここで，質問応答の質問として以下のようなものがあったとしよう．
「トラは天王寺動物園にはどのくらいいますか。
」
ここで質問応答システムの知識源として，
「天王寺動物園にはトラが11頭飼育されており…」
があったとする．
この場合システムは「どのくらい」などの表現から数量表現が解とわかるのでこの知識源から「11頭」を解として正しく抽出することができる．
しかし，質問が以下のようであったとしよう．
「虎は天王寺動物園にはどのくらいいますか。
」
この質問では先の質問の「トラ」が「虎」に変わっている．
この場合，「トラ」と「虎」が同一であることを計算機に認識させなければならないが，これをするためには計算機に単語の意味に関する情報を与えておかなければならない．
ここで例えばEDR辞書[CITE]を利用すると，「虎」の同義語としては「トラ」「酒酔」「酒酔い」「酔客」「酔狂人」「酔人」が得られる．
これは「虎」には「虎という動物」と「酒に酔った人」の二つの意味があり，この後ろの「酒に酔った人」の意味の場合の同義語が得られて「酒酔い」などの不要な同義語が得られるのである．
この不要な同義語を使って解の抽出を試みる場合，例えば
「昨夜未明，天王寺動物園で5人の酒酔い客が暴れだし…」
という文が知識中にある場合，誤って「５人」を解として取り出してしまう可能性がある．
ここで多義性の解消をし，ここでの「虎」の意味は「虎という動物」と認識し同義語は「トラ」だけであるとしてから，解の抽出をした方が誤る可能性は減るのである．
「虎」の場合はまだ意味が二つであったからよいが，高頻度に用いられる平易な語ほど語義の数が多く，この問題は深刻なものとなる．
このことから，多義性の解消の重要性がわかる．
ここでは質問応答の場合の例をあげたが各解析システムにおいて多義性の解消は同様に重要なものとなろう．
例えば，照応解析[CITE]においても，ある語Aが「人間」と「物」の二つの意味をもっていて，物しか指示しない「それ」という指示詞が出現した場合，語Ａの多義性を解消し，もし「人間」であるということがわかれば，この「それ」の指示先は語Aではありえないとわかり他の指示先の候補を探せばよいとわかる．
また，機械翻訳でも訳し分けが必要な語は多義性を解消しなければ正しい翻訳をすることができない．
このように多義性の解消は種々の場面で役に立つものである．
本節ではSENSEVAL2の日本語辞書タスクの問題設定について説明する．
SENSEVAL2の日本語辞書タスクでは，評価用のデータとしては100単語(このうち50単語が名詞で50単語が動詞)についてそれぞれ100事例が与えられ，合計10000事例が与えられた．
学習用のデータとしては，RWCコーパス[CITE]が与えられた．
このコーパスは毎日新聞の1994年の3,000個の記事を用いたもので，コーパス中の主要な名詞，動詞，形容詞(総数：約15万個)に対して，岩波国語辞典に基づいて定義された語義がふられている．
このタスクの目的は，この語義をその単語のまわりの情報などを用いて推定することである．
また，精度の評価には，SENSEVAL2のホームページより取得できるscorer2という評価用プログラムによって算出される，mixed-grained scoreという値が用いられた．
一般に，単語多義性解消問題の場合，各単語にふられる語義は，単語ごとにかわるので，機械学習手法による実験は各単語ごとに逐次的に行なわれる．
つまり，学習器は単語の異なり数の分だけ作成する．
しかし本タスクでは，あらかじめ50個が名詞で，50個が動詞であるとわかっている．
このため，システムは，単語ごとだけでなく，単語と品詞の組に対して個々に作成した．
本コンテストの場合，50個の名詞と50個の動詞が対象であったので，合計100個の学習器を作ることになる．
本稿では学習器のために用いる機械学習手法としては，以下の方法を利用した．
シンプルベイズ法
決定リスト法
サポートベクトルマシン法
本節ではこれらの個々の機械学習手法の説明と，これらの機械学習手法のいくつかを組み合わせる融合手法について説明する．
シンプルベイズ法は，ベイズの定理に基づいて各分類になる確率を推定し，その確率値が最も大きい分類を求める分類とする方法であり，多義性解消の研究における基本的な方法である．
文脈[MATH]で分類[MATH]を出力する確率は以下の式で与えられる．
{
}ただし，ここで文脈[MATH]は，あらかじめ設定しておいた素性[MATH]の集合である．
[MATH]は，文脈[MATH]の出現確率で，今回の場合分類aに非依存で定数のため，計算しない．
[MATH]と[MATH]は，それぞれ学習データから推定された確率で，分類aの出現の確率，分類aのときに素性[MATH]を持つ確率を意味する．
[MATH]として最尤推定し求めた値を用いると，しばしば値がゼロになり，式([REF_eq:simple_bayes])の値がゼロになり分類先を決めるのが難しい場合が多い．
このため，スムージングがなされるが，本稿では以下のスムージングをしたものを用いる．
{
}ただし，[MATH]と[MATH]は，それぞれ，素性[MATH]を持ちかつ分類が[MATH]である事例の個数，分類が[MATH]である事例の個数を意味する．
[MATH]は実験で定める定数である．
本稿では，[MATH]としては0.01と0.0001を用いた．
これは，素性[MATH]と分類先[MATH]の組を規則とし，それらをあらかじめ定めた優先順序でリストに蓄えておき，リストで優先順位の高いところから，入力と素性が一致する規則を利用して分類先を求める方法である[CITE]．
本稿では優先順序としては以下のものを用いる[MATH]．
{
}この方法は，以下の式で与えられる，ある文脈[MATH]での分類[MATH]を出力する確率[MATH]がもっとも高い分類[MATH]を解とする方法と等価であり，本稿では実際にはこの方法を用いて分類先を特定する．
{
}ただし，[MATH]は以下の式によって与えられる．
{
}また，[MATH]は学習データで素性[MATH]を文脈に持つ場合の分類[MATH]の出現の割合である．
サポートベクトルマシン法は，空間を超平面で分割することにより2つの分類からなるデータを分類する手法である．
このとき，2つの分類が正例と負例からなるものとすると，学習データにおける正例と負例の間隔(マージン)が大きいもの(図[REF_fig:margin]参照)ほどオープンデータで誤った分類をする可能性が低いと考えられ，このマージンを最大にする超平面を求めそれを用いて分類を行なう．
基本的には上記のとおりであるが，通常，学習データにおいてマージンの内部領域に少数の事例が含まれてもよいとする手法の拡張や，超平面の線形の部分を非線型にする拡張(カーネル関数の導入)がなされたものが用いられる．
この拡張された方法は，以下の識別関数を用いて分類することと等価であり，その識別関数の出力値が正か負かによって二つの分類を判別することができる[CITE]．
{
}ただし，[MATH]は識別したい事例の文脈(素性の集合)を，[MATH]と[MATH]は学習データの文脈と分類先を意味し，関数[MATH]は，{
}であり，また，各[MATH]は式([REF_eq:svm5])と式([REF_eq:svm6])の制約のもと式([REF_eq:svm4])の[MATH]を最大にする場合のものである．
{
} {
} {
}また，関数[MATH]はカーネル関数と呼ばれ，様々なものが用いられるが本稿では以下の多項式のものを用いる．
{
} [MATH]は実験的に設定される定数である．
本稿ではすべての実験を通して[MATH],[MATH]はそれぞれ1と2に固定した．
ここで，[MATH]となる[MATH]は，サポートベクトルと呼ばれ，通常，式([REF_eq:svm1])の和をとっている部分はこの事例のみを用いて計算される．
つまり，実際の解析には学習データのうちサポートベクトルと呼ばれる事例のみしか用いられない．
サポートベクトルマシン法は分類の数が2個のデータを扱うもので，通常これにペアワイズ手法を組み合わせて用いることで，分類の数が3個以上のデータを扱うことになる[CITE]．
ペアワイズ手法とは，N個の分類を持つデータの場合，異なる二つの分類先のあらゆるペア(N(N-1)/2個)を作り，各ペアごとにどちらがよいかを2値分類器(ここではサポートベクトルマシン法)で求め，最終的にN(N-1)/2個の2値分類器の分類先の多数決により，分類先を求める方法である．
本稿のサポートベクトルマシン法は，上記のようにサポートベクトルマシン法とペアワイズ手法を組み合わせることによって実現される．
本節では，いくつかの機械学習を組み合わせて用いる融合手法について説明する．
われわれの融合手法では，それぞれの単語ごとに用いる機械学習手法を変更する．
(厳密には，本稿の場合は単語と名詞の組に対して学習器を作成しているので，この融合手法はそれぞれの単語と名詞の組ごとに機械学習手法を変更することになる．
)各単語ごとに用いられる機械学習手法は，融合する機械学習手法のうち学習データでの10分割のクロスバリデーションの精度がもっともよかったものとする．
われわれは融合手法としては以下の五つの手法を試した．
融合手法1
シンプルベイズ([MATH]=0.01)とサポートベクトルマシンの組み合わせ
融合手法2
二種類のシンプルベイズ([MATH]=0.01)と二種類のサポートベクトルマシンの合計四種類のシステムの組み合わせ
ただし，ここでいう二種類は[REF_sec:sosei]節で後述する素性(解析に用いる情報)をすべて用いた場合と，KNP構文素性のみを削除した場合の二つの場合を意味する．
融合手法3
シンプルベイズ([MATH]=0.0001)とサポートベクトルマシンの組み合わせ
融合手法4
二種類のシンプルベイズ([MATH]=0.0001)と二種類のサポートベクトルマシンの合計四種類のシステムの組み合わせ
ただし，ここでいう二種類は[REF_sec:sosei]節で後述する素性(解析に用いる情報)をすべて用いた場合と，KNP構文素性のみを削除した場合の二つの場合を意味する．
融合手法5
[MATH]=0.01のシンプルベイズと[MATH]=0.0001のシンプルベイズの組み合わせ
前節で種々の機械学習の説明を述べたが，それぞれの手法ともに素性(解析に用いる情報)を定義しなければ，その手法を用いることができない．
本節ではその素性の説明を行なう．
[REF_sec:mondai_settei]節の問題設定で述べたように，本稿の問題設定では，日本語文の入力を与えられたときに，その入力中の語義タグがふられていた各形態素に対して，その語義の分類を推定して出力することになっている．
このため，解析に用いる情報，すなわち，素性は入力される日本語文から取り出すことになる．
本稿では素性としては以下のものを定義する．
文字列素性
解析する形態素自身の文字列
解析する形態素の直前の1〜3 gramの文字列
解析する形態素の直後の1〜3 gramの文字列
RWC形態素素性
解析する形態素自身のRWCコーパスの品詞情報，品詞細分類情報，品詞細細分類情報
解析する形態素の直前の形態素の単語自身，その単語の分類語彙表[CITE]の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞細細分類情報
解析する形態素の直後の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞細細分類情報
JUMAN形態素素性
コーパスをJUMAN[CITE]で形態素解析し，その結果を素性として利用する．
解析する形態素自身のJUMANの解析結果の品詞情報，品詞細分類情報，品詞活用形情報
解析する形態素の直前の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報
解析する形態素の直後の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報
構文素性
コーパスをKNP[CITE]で構文解析し，その結果を素性として利用する．
解析する形態素を含む文節自身，また，その文節が体言かいなか，付属語の品詞，品詞細分類，活用情報
解析する形態素を含む文節の係り先の文節の自立語，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報
解析する形態素を含む文節の係り元の文節の自立語，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報．
ただし，すべての場合において，付属語の情報を併用する．
同一文内共起素性
コーパスをJUMANで形態素解析し，その解析結果の形態素列を素性として利用する．
同一文中の各形態素，また，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁．
UDC素性
RWCコーパスには，各記事ごとに図書館などで書籍の分類に用いられる，国際十進分類(UDC)がふられている．
この情報は各記事がどういう分野のものかを示している．
解析対象とする形態素を含む記事のUDCコードの最初の1桁，2桁，3桁．
本節では関連文献について説明する．
英語単語の多義語の曖昧性解消に機械学習手法を用いた研究は極めて多数存在する[CITE]が，日本語単語の多義語の曖昧性解消に機械学習手法を用いた研究は，SENSEVAL2以前はほとんどなかった[CITE]．
例えば，新納の研究では語の多義の解消ではなく，同音異義語の判別を扱っていた．
その意味で，日本語多義解消の問題で「シンプルベイズ法」「決定リスト法」「サポートベクトルマシン法」の三つの機械学習手法，さらには，素性を変化させた場合の実験結果を示している本稿は，今後の日本語単語の多義語の曖昧性解消の問題を考えるための資料として非常に役に立つものと思われる．
次にいくつかの関連研究を紹介したい．
まず，SENSEVAL2で英語を含む数多くの言語で優秀な成績をとっていたYarowskyらのシステム[CITE]について説明する．
Yarowskyらのシステムは，シンプルベイス法と決定リストの組み合わせであり，決定リストで求まる確信度が高いところでは決定リストの手法の解を用い，それ以外の場合は種々の手法の多数決の結果を解とする手法である．
確信度を用い決定リストで確実に求まるところだけを別個に扱っているところが興味深い．
次に，SENSEVAL2の日本語辞書タスクに参加していた八木らのシステム[CITE]について説明する．
八木らのシステムは決定リスト法を機械学習手法として用いており，学習用のデータとして，RWCコーパス以外に岩波国語辞典の例文のデータを用いていることを特徴としている．
RWCコーパスでの語義の定義は岩波国語辞典を用いているため，岩波国語辞典の例文のデータも語義解析のための学習データとして利用できるのである．
八木らの研究ではこの例文データも利用した場合の方が利用しない場合よりも精度が高かったとしている．
この結果は，われわれの研究でもこのデータを追加で用いることで精度を向上できる可能性を示唆するものであり，興味深い．
次に，高村らの素性空間を再構成する手法[CITE]について説明する．
この研究は英語を対象に行なわれており，機械学習手法としてはサポートベクトルマシン法を利用している．
この手法は学習に用いる素性を構成し直すところに特徴がある．
普通に抽出した素性だけでなく，その素性の分布に対して独立成分分析や主成分分析を行ない，元々の素性よりも一段抽象化したような素性を新たに作り出し，これも素性として追加で用いる方法である．
この素性を再構成する方法を含めた複数のシステムの多数決を用いる方法で，単純なサポートベクトルマシン法の性能を上回ったとしている．
独立成分分析などにより素性の情報を抽象化することでデータスパースネス対策などに役立っていると思われ，興味深い．
最後に，中野らのAdaBoostを用いた手法[CITE]を説明する．
この研究ではSENSEVAL2日本語タスクのデータを対象としており，AdaBoostを機械学習手法として利用している．
AdaBoostは正しく分類された事例の重みを下げ，誤って分類された事例の重みを上げて，再学習をする手法である．
中野らの報告では，AdaBoostを利用することで決定リスト法，シンプルベイズ法よりも高い精度を得たと報告している．
ただし，その最高精度は79.1 %であり，われわれの最高精度の79.3 %より若干低い．
しかし，この結果はわれわれのシステムの素性の情報が豊かであるためである可能性があり，われわれのシステムの素性の情報でAdaBoostを利用するとさらによい精度を得ることができる可能性がある．
しかし，中野らはわれわれのシステムでは用いていない日本語語彙体系[CITE]の辞書の情報を用いており，中野らの方が素性の情報が少ないとは言い切れないので，われわれのシステムの素性の情報でAdaBoostを利用するとさらによい精度を得ることができるかどうかはわからない．
また，われわれのシステムの素性の情報の方が豊富であっても，われわれのシステムの素性でAdaBoostが本当によい精度を出せるかどうかはわからない．
次に，多義性の研究に直接は関係はないが，複数の機械学習の方法を組み合わせるのに，スタッキングを用いる手法[CITE]について説明したい．
スタッキングを用いる手法とは，もともとの素性の他に，複数の機械学習の結果を素性として追加し，その追加された素性を用いて機械学習を行なう方法である．
従来は複数の機械学習の方法の融合には多数決が多く用いられていたが，スタッキングの方法ではどの機械学習の方法がよいかを学習することになっておりたいていの場合で多数決の方法よりも精度が高くなると思われる．
このスタッキングを利用する研究としては，形態素解析のもの[CITE]や固有名詞表現抽出のもの[CITE]などがある．
本稿でのシステムの融合では，各単語でもっとも精度の高い手法を利用していた．
このわれわれの融合手法は各単語ごとに用いる手法を最尤推定で求めるものになっていて少々は融合に学習を用いていることにはなっている．
しかし，手法の組み合わせにおいても強力な学習手法を用いた方が精度はよいと思われるので，われわれの手法でもスタッキングを利用することを考えた方がよい．
以上，種々の有力な関連研究を紹介した．
それぞれの手法ともに特徴的な要素を持っており，[REF_sec:experiment2]節の最後に述べた考察と含めてそれらを総合的に考察し，それぞれの手法の良い面を組み合わせることで，さらによりよい多義解消を行なえると思われる．
