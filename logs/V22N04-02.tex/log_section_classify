intro        found : \section{はじめに}
experiment   found : \section{実験}
conclusion   found : \section{おわりに}
proposedtech found : \section{Introduction}
proposedtech found : \section{Background}
proposedtech found : \section{Stack Depth of Existing Transition Systems}
proposedtech found : \section{Left-corner Dependency Parsing}
proposedtech found : \section{Empirical Stack Depth Analysis}
proposedtech found : \section{Parsing Experiment}
proposedtech found : \section{Related Work and Discussion}
proposedtech found : \section{Conclusion}

fgrep searched
\section{Introduction}
In addition to this introductory section, this article is organized as follows.
\section{Background}
\subsection{Left-corner Parsing Strategy}
In this section, we describe left-corner parsing as a parsing strategy.
\subsection{Dependency-to-CFG Reduction}
\section{Stack Depth of Existing Transition Systems}
\subsection{Transition-based Dependency Parsing}
\subsection{Arc-Standard}
\subsection{Arc-eager}
\subsection{Other Systems}
\section{Left-corner Dependency Parsing}
In this section, we develop our dependency transition system using the left-corner strategy.
\subsection{Inference Rules of Resnik (1992)}
\subsection{Dummy Node}
\subsection{Transition System}
\subsection{Oracle and Spurious Ambiguity}
\subsection{Stack Depth of the Transition System}
\section{Empirical Stack Depth Analysis}
In this section, we evaluate the cross-linguistic coverage of our developed transition system.
\subsection{Settings}
\subsection{Stack Depth for General Sentences}
\subsection{Comparing with Randomized Sentences}
\subsection{Token-level and Sentence-level Coverage Results}
In this section, we focus on depth$_{re}$, which calculates the exact center-embeddedness and may be more applicable to some applications.
\section{Parsing Experiment}
\subsection{Feature}
\subsection{Settings}
\subsection{Results on the English Development Set}
We train the model in section 2-21 of the WSJ Penn Treebank \cite{Marcus93buildinga}, which are converted into dependency trees using the penn converter.\footnote{http://nlp.cs.lth.se/software/treebank\_converter/}
To explore the first question posed at the beginning of this section, we compare parse accuracies under each stack depth bound with several beam sizes, with results shown in Figure \ref{fig:accuracy-depth}.
\subsection{Result on CoNLL Datasets}
\section{Related Work and Discussion}
\section{Conclusion}
