================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.41310] この場合の要約の質は，検索質問-要約文書間の関連性判定が，検索質問-原文書の間の関連性判定に一致する度合で評価されるので，検索を考慮した要約が必要となる．
[i:2, score:0.37826] 検索質問により語の重みにバイアスを与え，語の重要度を求める従来手法とは異なり，我々の方法では，検索された文書間の表層的類似性を適切に説明する語に高い重みを付与する．
[i:3, score:0.48167] 具体的には，検索文書集合に階層的クラスタリングを適用することにより，文書間の類似性構造を抽出するとともに，各クラスタにおける各語の出現確率から，その構造を説明するのに寄与する単語により高い重みを与える．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:10, score:0.41157] この際，情報検索結果文書に対する要約の質の良さは，要約文書-検索質問間の関連性判定と原文書-検索質問間の関連性判定の一致の良さで測ることができよう．
[i:23, score:0.40000] 以上の点を踏まえて，本稿では，検索文書集合から得られる情報を語の重みづけに利用し，検索文書の要約に役立てる新しい手法を提案する．
[i:26, score:0.51714] 文書間の類似性構造を語の重みに写像する方法として，我々は，各クラスタ内での語の確率分布に注目し，情報利得比(Information Gain Ratio, IGR)[CITE]と呼ばれる尺度を用いる．

================================================================
[section type  : proposed_method]
[section title : 検索文書集合中の語に対する情報利得比に基づく重みづけ]
================================================================
-----------------------------------------------------
  [subsection title : 検索文書要約の特質]
-----------------------------------------------------
  [i:lead, score:0.30381] 検索文書の要約は，以下の点で通常の文書要約と異なる．
.....
  [i:42, score:0.42715] これは，検索質問中の語や句は利用者の情報要求を端的に示すので，要約文書にもその語や句が含まれるべきであるという直観に基づくもので，「検索質問バイアス方式に基づく要約(Query-biased Summarization)」と呼ばれる．
  [i:44, score:0.35564] 検索質問中の表現をそのまま用いるために，検索エンジンにおける工夫が要約文書に反映されない．
  [i:47, score:0.40011] 検索質問との関連性が低い文書に対しては，検索質問バイアス方式は通常の文書要約になってしまう．
-----------------------------------------------------
  [subsection title : 提案手法の概略]
-----------------------------------------------------
  [i:lead, score:0.09025] 我々の提案手法の概略を図[REF_Fig:Overview]に示す．
.....
  [i:59, score:0.45466] ステップ[REF_step:clustering]においては，検索質問に関連する文書とそうでない文書がクラスタ構造の中で分離されることが期待され，なおかつ，それらの文書部分集合においても類似性に基づく細分類がなされると考えられる．
  [i:67, score:0.47136] ここで，我々の方法では，検索文書の属する部分クラスタだけが，クラスタリングアルゴリズムにる部分クラスタ解析の対象となる(図[REF_Fig:SuperCluster]の左部分木)のに対し，検索されなかった文書の属するクラスタ(図[REF_Fig:SuperCluster]の右部分木)についてはそれ以上の解析が不要である点に注意されたい．
  [i:68, score:0.47580] 後に述べる情報利得比の計算においては，検索されなかった文書の属するクラスタについては，その中に存在する語の頻度だけが分かればよい．
-----------------------------------------------------
  [subsection title : 最大距離アルゴリズムによる階層的クラスタリング]
-----------------------------------------------------
  [i:lead, score:0.24401] 検索された文書集合の類似性の解析には，文書間の距離の定義とその距離に基づく文書集合の構造化が必要となる．
.....
  [i:89, score:0.33556] しかし，この種の方法はクラスタ構造を無理に二分木に当てはめるため，文書間距離の順序関係は構造に反映されるものの，その絶対値については捨象されてしまう．
  [i:104, score:0.32488] 最大距離アルゴリズムにおいては，まず文書集合から2個以上のクラスタ中心を選択し，次に，残りの文書を最近のクラスタ中心と同じクラスタに配置する．
  [i:116, score:0.33362] 以上のアルゴリズムは，単一の文書集合を文書間距離にしたがって複数個の部分クラスタに分割する非階層的なアルゴリズムである．
-----------------------------------------------------
  [subsection title : 情報利得比に基づく語の重要度]
-----------------------------------------------------
  [i:lead, score:0.20054] クラスタの木における各接点(内点)は，あるクラスタとそれを分割して得られた互いに素な部分クラスタの関係，すなわち，クラスタの分割の仕方を表現している．
.....
  [i:119, score:0.39962] この分割の仕方はクラスタ内の文書の類似度に従って決定されるので，これを文書内の語の重みに反映させることができれば，複数文書間の類似性という巨視的な情報を，文書内の語の重みという微視的な情報に還元できると考えられる．
  [i:149, score:0.63080] また，すべての検索文書を同時に要約し，一覧形式で利用者に提示するというインタフェースにおいては，クラスタの木の根接点からその文書に対応する葉接点に至るすべての分割で得られたの情報利得比を何らかの形で統合し，これを語の重みとすることが考えられる．
  [i:152, score:0.59367] 本稿では，すべての検索文書を同時に要約し，一覧形式で利用者に提示するという最も基本的なインタフェースを想定し，図[REF_Fig:IGRSum]ならびに式([REF_Eq:IGRsum])に示す情報利得比の重みなしの和を採用する．

================================================================
[section type  : proposed_method]
[section title : 重要文抽出に基づく要約文書生成]
================================================================
[i:165, score:0.38922] しかし，我々の目的は，前節で述べた語の重みづけが検索文書要約において有効であることを示すことである．
[i:168, score:0.29080] ある決められた要約の長さに達するまで，原文書から重要度の高い順に文を取り出していく．
[i:169, score:0.27856] 取り出した文を原文書における出現順に並べ変えて要約文書を得る．

================================================================
[section type  : experiment_result]
[section title : 評価]
================================================================
[i:171, score:0.32411] まずは，検索タスクの精度・効率の良さと言う観点から，評価型情報検索ワークショップであるNTCIR2[CITE]におけるTSC(Text Summarization Challenge)における「課題B IRタスク用要約」(以下，TSC Task Bと呼ぶ)に基づいて評価を行なう[CITE]．
[i:172, score:0.33011] つぎに，幾つかの例により，我々の方式が各語に与える重要度を，検索質問を考慮しない語の重みづけ手法(TF値，TF・IDF値)と比較することにより，我々の重要度計算手法の特徴を定性的に評価する．
[i:183, score:0.28362] 文書の総形態素数が150より短い場合には要約をせずに原文書を提示する．
-----------------------------------------------------
  [subsection title : 情報検索タスクにおける要約品質の評価実験の概要]
-----------------------------------------------------
  [i:lead, score:0.27313] 図[REF_Fig:SummaryInIR]に情報検索タスクにおける要約品質の評価実験の概要を示す．
.....
  [i:186, score:0.35344] TSC Task Bにおいては，TSC実行委員会より配布されたデータセットに，12のトピックがあり，それぞれ，検索要求1，検索文書50文書から構成されている．
  [i:189, score:0.32033] 提出された要約文書に対して，TSC実行委員会による被験者を用いた評価が行なわれた．
  [i:197, score:0.33086] よって，両者の一致の判定においては，A判定の文書だけを関連文書とする場合(Answer Level A)と，A判定に加えてB判定の文書も関連文書とする場合(Answer Level B)が考えられる．
-----------------------------------------------------
  [subsection title : 総合評価]
-----------------------------------------------------
  [i:lead, score:0.18445] 表[REF_Table:EvaluationResultAll]に個別の評価尺度についての結果を他の参加システム(8システム)ならびにTSC実行委員会が準備したベースラインシステム(3システム)と比較して示す．
.....
  [i:199, score:0.45346] ベースラインシステムは，「全文提示(Fulltext)」(要約率100%)，「質問バイアス付きTFに基づく方式(TF with QB)」(要約率20%)，「文書の先頭を採るリード方式(Lead)」(要約率20%)である．
  [i:200, score:0.28373] 質問バイアス付きTF法は，TFを語の重みとして重要文抽出を行なうものであるが，この時に，検索質問に現れる語について2倍の重みを与えている．
  [i:204, score:0.24916] 被験者が1検索要求に関するタスク(50文書)に要した時間(TIME)
-----------------------------------------------------
  [subsection title : 適合性判断のための所要時間とその精度に関する評価]
-----------------------------------------------------
  [i:lead, score:0.34923] 情報検索の結果の文書に対する要約においては，利用者が行なう適合性判断のための時間の短さと，適合性判断の正確さが共に達成されることが必要である．
.....
  [i:211, score:0.34923] 情報検索の結果の文書に対する要約においては，利用者が行なう適合性判断のための時間の短さと，適合性判断の正確さが共に達成されることが必要である．
  [i:226, score:0.34927] \multicolumn{3}{c}{Proposed:我々の手法，Fulltext:原文書，TF with QB:質問バイアス付き}
  [i:229, score:0.32707] また，判定時間と要約文書の平均文字数の間の関係を図[REF_Fig:Time-Length]に示す．
-----------------------------------------------------
  [subsection title : トピック毎の適合性判断の精度に関する評価]
-----------------------------------------------------
  [i:lead, score:0.11668] これまで示した結果では，全てのトピックに亙る平均値を用いてタスクの遂行精度を議論してきたが，当然，トピックによって各システムの精度が異なるはずである．
.....
  [i:232, score:0.24224] そこで，我々の手法と各ベースライン手法による要約において，トピック毎のタスク遂行精度をプロットした．
  [i:233, score:0.26992] Answer Level A,Bの場合をそれぞれ図[REF_Fig:Topic-RPF]に示す．
  [i:242, score:0.17806] \multicolumn{3}{c}{(B) Answer Level B }
-----------------------------------------------------
  [subsection title : 適合と判断した被験者の数による要約の質の定量的評価]
-----------------------------------------------------
  [i:lead, score:0.32535] 要約文書の質を今少し詳細に検討するために，各々の文書に対して，関連性有り(YES)と答えた被験者の人数を調べる．
.....
  [i:243, score:0.32535] 要約文書の質を今少し詳細に検討するために，各々の文書に対して，関連性有り(YES)と答えた被験者の人数を調べる．
  [i:244, score:0.32649] この人数はトピックに対する生成された要約文書の関連度の高さを表す尺度と考えられる．
  [i:245, score:0.37177] そこで，原文書を関連性判定(A,B,C)によって分類し，その要約に対してYESと判定した人数毎に文書頻度を集計し，プロットした．
-----------------------------------------------------
  [subsection title : 語の重み付けに対する評価]
-----------------------------------------------------
  [i:lead, score:0.09915] 語の重みづけについては正解というものがないので，定量的にその評価をすることが難しい．
.....
  [i:248, score:0.21537] ここでは，最も基本的な重みづけである，TF値，TF・IDF値による重みと，本手法の重みづけを実例により比較し，定性的に我々の語の重要度決定手法の特徴を検討する．
  [i:251, score:0.34584] このトピックについて，原文書の関連度がそれぞれ，A，B，Cであるものを一つずつ選択し，各種の語の重みけを行なった結果について，上位10位までを求めた．
  [i:253, score:0.27363] 表においてIGRsumは式([REF_Eq:IGRsum])に示される情報利得比の和であり，TFIDFIGRsumはTF・IDF値にIGRsumを乗じた値である．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
-----------------------------------------------------
  [subsection title : タスク遂行の精度]
-----------------------------------------------------
  [i:lead, score:0.43242] TSC Task Bは，利用者(被験者)が要約文書を読むことにより，原文書のトピックに対する関連度を推定するタスクであった．
.....
  [i:254, score:0.43242] TSC Task Bは，利用者(被験者)が要約文書を読むことにより，原文書のトピックに対する関連度を推定するタスクであった．
  [i:259, score:0.42306] 本節では検索質問に対して適合文書(A判定)のみを正解とした評価(Answer Level A)について考察を行なう．
  [i:267, score:0.42562] まず，表[REF_Table:EvaluationResultAll]によると，所要時間単独についていえば，我々のシステムが生成した要約に対し，被験者が適合性判定に要した時間は，1トピック(50文書)あたり8分33秒であった．
-----------------------------------------------------
  [subsection title : 適合と判断した被験者の数による要約の質の定量的評価]
-----------------------------------------------------
  [i:lead, score:0.38879] 図[REF_Fig:Rel-Judge](A)についてみると，トピックに対する原文書の関連度がAの場合には，いずれのシステムにおいても，当然ながら，3人が一致してYESとする場合が最も多く，2人，1人，0人と順に頻度が低くなっていく．
.....
  [i:301, score:0.38879] 図[REF_Fig:Rel-Judge](A)についてみると，トピックに対する原文書の関連度がAの場合には，いずれのシステムにおいても，当然ながら，3人が一致してYESとする場合が最も多く，2人，1人，0人と順に頻度が低くなっていく．
  [i:303, score:0.28009] すなわち，関連性のある文書については，他の手法より質の高い要約が生成されていたと考えられる．
  [i:305, score:0.27901] つまり，関連判定に重要な部分は必ずしも文頭にあるわけではなく，一般的な新聞記事の要約で良い戦略の一つとされるLead手法が情報検索タスクにおいては，必ずしも有効ではないことがわかる．
-----------------------------------------------------
  [subsection title : 語の重み付けに関する考察]
-----------------------------------------------------
  [i:lead, score:0.26598] 我々の提案する語の重みづけについてその特徴を実例(検索トピック1027,「ハイビジョンテレビ」)により考察する．
.....
  [i:314, score:0.26598] 我々の提案する語の重みづけについてその特徴を実例(検索トピック1027,「ハイビジョンテレビ」)により考察する．
  [i:315, score:0.46356] 表[REF_Table:weight1027A]において，我々が最終的に用いる語の重みであるTFIDFIGRsumの列に示されるように，関連度Aの文書においては，検索トピックに陽に示されている語はもちろんのこと，「BS」，「番組」，「デジタル」，「申請」，「衛星」，「郵政省」など，そのトピックに関連する語も上位に重み付けられていることが分かる．
  [i:319, score:0.33499] 関連度BやCの文書についても，表[REF_Table:weight1027B],[REF_Table:weight1027C]に示されるとおり，トピックに関連の深い語が上位に重み付けられていることが見てとれる．
-----------------------------------------------------
  [subsection title : 語の重みづけの品質と検索文書の数ならびに品質に関する考察]
-----------------------------------------------------
  [i:lead, score:0.34177] 本手法による重みづけは，クラスタリングの対象となる文書の件数ならびに検索結果の質と密接な関係にある．
.....
  [i:324, score:0.55557] さて，本手法で語の重みに用いている情報利得比の和は，クラスタ構造に則した分布をしている語に高い重みを与えるものであるから，検索文書をクラスタリングした結果，どのようなクラスタ構造が形成されるかによって，各語の重みが決まる．
  [i:326, score:0.49994] さらに，本手法では，図[REF_Fig:SuperCluster]に示すように文書データベース中の全文書が所属するクラスタを最上位に考え，検索文書群とそれ以外の文書群の間の差異についても重みに反映しているので，全体のクラスタ構造は情報検索の精度とも関係がある．
  [i:347, score:0.55563] 節[REF_Sec:語の重みづけの品質と検索文書数に関する考察]でも述べた通り，検索質問との関連性が低い文書が多くなると，検索質問に述べられたトピックとは関連性の低い語が，クラスタ形成の際に支配的になる事も有り得る．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:367, score:0.49418] このシステムでは，検索結果を文書間の類似度に基づいてクラスタリングし，各クラスタごとにクラスタに多く含まれる語と，そのクラスタを代表する文書のタイトルを，そのクラスタの要約として出力する．
[i:369, score:0.50422] FukuharaらやRadevらも，Eguchiらと同様に検索結果を文書間の類似度に基づいてクラスタリングし，各クラスタごとに要約を出力している．
[i:378, score:0.48213] 特にCarbonellら[CITE]は，極大限界適合度(Maximal Marginal Relevance,MMR)という概念を導入し，検索質問と検索文書の類似度ならびに，ある文書とそれよりも上位の文書との間の冗長性に基づいて，検索文書の再順位づけを行なうとともに，これを，パッセージ検索に利用することによって要約生成を行なう手法を提案している．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:380, score:0.45490] 本稿では，複数の検索文書の間に存在する類似性の構造を階層的クラスタリングにより抽出し，その構造を適切に説明するか否かに応じて情報利得比に基づき語に重みをつける手法を提案した．
[i:381, score:0.36631] TSCでの実験の結果，この方法に基づく重要文抽出型の要約手法は，検索文書の要約において，非常に有効であることが示された．
[i:382, score:0.35984] 今後の課題としては，節[REF_Sec:語の重みづけの品質と検索文書の数ならびに品質に関する考察]に述べたように本手法と検索文書の数ならびに品質の間の定量的な関係を明らかにすることが挙げられる．

