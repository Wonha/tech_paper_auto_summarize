
検索文書の要約は，以下の点で通常の文書要約と異なる．
検索質問文が与えられている．
複数の要約文書が同時に得られている．
そして，ある一度の検索の結果という点において文書間に類似性が認められる．
いずれの情報も，検索文書の要約においては有効な手がかりと考えられる．
ここでは，これらの手掛かりを語の重みづけに用いることを考察する．
まず初めに考えられる手法は，Tombrosら[CITE]が提案するように，検索質問中の語を重要語として考え，他の語よりも重みを高する方法である．
これは，検索質問中の語や句は利用者の情報要求を端的に示すので，要約文書にもその語や句が含まれるべきであるという直観に基づくもので，「検索質問バイアス方式に基づく要約(Query-biased Summarization)」と呼ばれる．
この方法は，検索質問を考慮するだけであるので，実装が簡単であり，ある程度の効果が報告されているが，次の欠点が存在する．
検索質問中の表現をそのまま用いるために，検索エンジンにおける工夫が要約文書に反映されない．
例えば，各種フィードバックや検索質問の拡張などは，検索質問を修正/更新することによって検索効率を上げている．
検索エンジンは検索質問文に関連する文書ばかりではなく，関連性の低い文書も結果として返すことがある．
検索質問との関連性が低い文書に対しては，検索質問バイアス方式は通常の文書要約になってしまう．
そこで，我々は二番目の選択肢である，検索質問文を使わずに，検索文書集合のみを用いて重みづけることを考える．
検索結果の質が非常に悪くない限り，検索文書集合には検索質問に関する情報が暗に含まれていると期待できるので，その情報を引き出すのである．
しかし，各文書に共通する語を抽出するといった単純な方法では精度が良くないことは容易に想像される．
なぜならば，検索結果の文書集合には，もちろん検索質問との関連性が高い文書も含まれるが，関連性の低い文書も含まれるからである．
しかも，その度合は検索エンジンの精度に依存してしまう．
よって，単純に文書に共通する語などを取り出すだけでは達成できない．
我々は以上の点を踏まえて次節に示す枠組を提案する．
我々の提案手法の概略を図[REF_Fig:Overview]に示す．
これは，次の2つの指針の組み合わせたものである．
検索文書集合に対し階層的クラスタリングを行ない，文書間の類似性の構造を抽出する．
文書間の類似性の構造と語の確率分布に基づいて各語の重み付けを行なう．
ステップ[REF_step:clustering]においては，検索質問に関連する文書とそうでない文書がクラスタ構造の中で分離されることが期待され，なおかつ，それらの文書部分集合においても類似性に基づく細分類がなされると考えられる．
我々の手法では，語を次元とする文書ベクトルの類似度による階層的クラスタリングを用い，クラスタリングアルゴリズムとしては最大距離アルゴリズムを採用した．
ここで注意すべきことは，検索されなかった文書，すなわち，文書データベース中の残りの文書の存在を類似性構造の中に組み込む必要があることである．
なぜならば，クラスタ構造において，一番上位のクラスタは与えられた構造として扱う以外になく，類似性の解析の対象とならないからである．
検索文書全体の類似性構造は，検索されなかった文書集合との対比によって，初めて明らかになる．
この類似性構造は，全文書集合と検索質問との間の類似性を反映するので，非常に重要なものである．
このため，図[REF_Fig:SuperCluster]に示すように検索文書集合から得られたクラスタ構造の根の上にもう一つ仮想的なクラスタを設ける．
そのクラスタには，検索文書の属する部分クラスタとそれ以外の文書が属する部分クラスタが存在する．
ここで，我々の方法では，検索文書の属する部分クラスタだけが，クラスタリングアルゴリズムにる部分クラスタ解析の対象となる(図[REF_Fig:SuperCluster]の左部分木)のに対し，検索されなかった文書の属するクラスタ(図[REF_Fig:SuperCluster]の右部分木)についてはそれ以上の解析が不要である点に注意されたい．
後に述べる情報利得比の計算においては，検索されなかった文書の属するクラスタについては，その中に存在する語の頻度だけが分かればよい．
これは，あらかじめ求めておいた文書データベース中の語の頻度より，簡単に求めることができる．
よって，我々の手法において実際に文書クラスタリングが行なわれるのは，検索結果として利用者に提示する文書に限定される．
これは通常数十文書程度であるから，文書クラスタリングにおける計算量はあまり問題とならない．
このようにして求められた類似性構造は文書を一つの単位とする巨視的な情報であるので，要約のためには，これを文や句，単語を単位とするより微視的な情報に還元する必要がある．
これがステップ[REF_step:weighting]である．
このステップにおいては，各クラスタが部分クラスタに分割されるにあたって，句や単語などより微視的な単位がどれ位寄与しているかを表す指標を定め，これをその語句の重要度とする．
我々はその指標として情報利得比を用いる．
このようにして求められた情報利得比を，既存の方法でも用いられている重みである，語の文書内頻度(term frequency, TF)，文書頻度の逆数(inverse document frequency, IDF)[CITE]と組み合わせることにより，総合的な語の重要度をとする．
これら三種類の重みは，以下の通り，異なる文書情報から得られるものであることに注意されたい．
よって，これらの組み合わせにより，検索文書の要約に適した総合的な重みが得られると期待できる．
語の文書内頻度個別の文書における各語の分布より決まる重要度で，ある文書中でのその語の重要度を表す．
クラスタ分割に対する語の出現確率に関する情報利得比検索文書の類似性構造であるクラスタの分割により決まる重要度で，そのクラスタ構造におけるその語の重要度を表す．
文書頻度の逆数検索対象の全文書により決まる重要度で，全検索対象文書集合におけるその語の重要度を表す．
検索された文書集合の類似性の解析には，文書間の距離の定義とその距離に基づく文書集合の構造化が必要となる．
これには様々な方法が考えられるが，本稿では文書間の距離として，様々な場面で利用され，かつ，簡便なTF・IDF法ならびにベクトル空間法に基づく方法を採用する[CITE]．
また，文書集合の類似性に関する解析には，階層的クラスタリングを用いる．
階層的クラスタリングアルゴリズムには，併合法などが良く用いられる[CITE]．
しかし，この種の方法はクラスタ構造を無理に二分木に当てはめるため，文書間距離の順序関係は構造に反映されるものの，その絶対値については捨象されてしまう．
ここでは，文書の類似度に応じて多分岐構造を生成でき，文書間距離の絶対値情報がなるべく保存されるアルゴリズムが望ましい．
そのようなアルゴリズムとして，我々は最大距離アルゴリズム[CITE]を採用した．
この最大距離アルゴリズムは，本来，非階層的なクラスタを生成するものであるが，これを分割の結果得られた部分クラスタに再帰的に適用することにより階層構造を得る．
この方法では，各クラスタが3以上のクラスタに分割されることもある．
ベクトル空間モデルに基づき，各文書[MATH]をn次元空間上の点[MATH]により表現する．
[MATH]は文書[MATH]において語[MATH]に割り当てられた重みである．
重み[MATH]としては語[MATH]のTF・IDF値とする．
このとき，文書[MATH]と文書[MATH]の距離dを文書ベクトル間のユークリッド距離を用いて，次のように定義する．
ただし，
である．
\comment{後に述べる実験においては，語として，名詞のみを扱った．
文書からの名詞抽出には形態素解析器JUMAN3.61[CITE]を用いた．
また，[MATH], [MATH]は検索対象である毎日新聞94年，95年，97年，98年のすべての記事から求めた．
} 最大距離アルゴリズムにおいては，まず文書集合から2個以上のクラスタ中心を選択し，次に，残りの文書を最近のクラスタ中心と同じクラスタに配置する．
その主要部分はクラスタ中心を求める部分であり，以下の手続きからなる．
文書集合[MATH]から距離の最も大きい二文書を取り出し，これらを要素とする集合を作成する．
これを初期のクラスタ中心の集合[MATH]とする．
クラスタ中心集合[MATH]において，クラスタ中心間での最大距離を求める．
これを，[MATH]とする．
[MATH]中の各文書[MATH]について，すべてのクラスタ中心との距離を求め，その最小値を既存クラスタ中心からの距離[MATH]とする．
既存クラスタ中心からの距離が最も大きい文書[MATH]を[MATH]から取り出す．
もし，[MATH]ならば，その文書をクラスタ中心集合[MATH]に追加する．
そうでなければ，終了．
なお，[MATH]は[MATH]なる定数であり，値が大きいほどクラスタの分割数が少なくなる．
一般には[MATH]とすることが多い．
以上のアルゴリズムは，単一の文書集合を文書間距離にしたがって複数個の部分クラスタに分割する非階層的なアルゴリズムである．
これを各部分クラスタに対して再帰的に適用することにより，階層的なクラスタ構造を生成する．
クラスタの木における各接点(内点)は，あるクラスタとそれを分割して得られた互いに素な部分クラスタの関係，すなわち，クラスタの分割の仕方を表現している．
この分割の仕方はクラスタ内の文書の類似度に従って決定されるので，これを文書内の語の重みに反映させることができれば，複数文書間の類似性という巨視的な情報を，文書内の語の重みという微視的な情報に還元できると考えられる．
我々は，この考え方に基づき，次の2つの段階から構成される方法を提案する．
各クラスタについて，その部分クラスタの構造から，各語の重みを決定する．
一つの文書は，クラスタの木の根接点から対応する葉接点に至るクラスタ分割の系列によって指し示される．
よって，各文書における語の重みは，各分割で得られた語の重みを統合して得る．
このうち，特に重要なのは[REF_Step:IGR]である．
その基本的な考え方は，クラスタの分割構造を決定することに寄与する語に高い重みを与えるというものである．
例として，図[REF_Fig:PartitionWordDist]のように，あるクラスタ[MATH]が3つの部分クラスタ([MATH],[MATH],[MATH])に分割されている場合を考える．
図中，記号[MATH],[MATH],[MATH]〜[MATH]は各々単語に対応するとする．
さて，語[MATH]はクラスタ[MATH]における頻度が最も高いので，このクラスタの特徴を表す語と考えることができる．
しかし，各部分クラスタに注目すると，いずれも均等に出現しているため，部分クラスタの選択においては役立たないことがわかる．
一方，語[MATH]はクラスタ[MATH]において頻度はさほど高くはないが，部分クラスタ[MATH]に集中して登場している．
この場合，語[MATH]が出現しているか否かを調べることによって，部分クラスタを言い当てることができるので，クラスタの分割構造に対する寄与度は，語[MATH]は語[MATH]よりも高いと考えられる．
我々はこの寄与度を適切に表す尺度として，次に述べる情報利得比を用いる．
情報利得比は，決定木学習システムC4.5において属性選択を行なうために導入された[CITE]．
C4.5においては，ある属性を決定木の分岐におけるテストとしたときに，その属性がどれくらい適切にクラスの出現を予測できるかを表す尺度として用いられている．
我々は，表[REF_Table:OurMethod_VS_C4.5]に示す対応の下，クラスタの構造を決定木の構造と見なすことにより，情報利得比を用いる．
C4.5においては属性の評価値として情報利得比を用いていたが，我々の方法においては，属性ではなくクラスに対応する単語に対する評価値として情報利得比を用いる．
クラスタ[MATH]における単語[MATH]の情報利得比[MATH]は次の様に求められる．
情報利得[MATH]は，クラスタ[MATH]の分割の前後における，語[MATH]の確率分布に関するエントロピーの減少量を表す．
[MATH]は，クラスタ[MATH]の分割に関するエントロピーである．
情報利得比[MATH]は，これらの比として定義される．
例として，図[REF_Fig:PartitionWordDist]における各語について，上述の方法により情報利得比を計算してみると次の通りとなる．
{
} [MATH]や[MATH]のようにクラスタ構造に沿って現れる語は値が大きく，語[MATH]のように網羅的に分布する場合には値が小さいことは既に述べたとおりである．
一方，語[MATH]のように一部のクラスタに集中してはいるものの，他のクラスタにも低い確率ではあるが出現する場合には，値が低くなることがみてとれる．
さらに，語[MATH]とほぼ同じく偏りがあるが出現確率が低い語[MATH]については，その値が相対的に低くなる．
式([REF_Eq:IGR])に示される情報利得比は，各クラスタの分割毎に得られる．
これらを，ある文書中のある語の重みとして利用する方法には，利用者向けインタフェースの設計に応じて，いくつか考えられる．
例えば，クラスタ構造を利用者に提示しながら，部分クラスタを順次利用者に選択してもらうような対話的インタフェースにおいては，各選択点において利用者が注目しているクラスタにおける情報利得比を利用し，語の重みを求めることが考えられる．
また，すべての検索文書を同時に要約し，一覧形式で利用者に提示するというインタフェースにおいては，クラスタの木の根接点からその文書に対応する葉接点に至るすべての分割で得られたの情報利得比を何らかの形で統合し，これを語の重みとすることが考えられる．
この時，統合の方法には様々な方法が考えられ得る．
例えば，ある階層の値を採用する，最大値を採る，すべての値を和もしくは積により統合する，などである．
本稿では，すべての検索文書を同時に要約し，一覧形式で利用者に提示するという最も基本的なインタフェースを想定し，図[REF_Fig:IGRSum]ならびに式([REF_Eq:IGRsum])に示す情報利得比の重みなしの和を採用する．
この方法では，すべてのクラスタ分割における情報利得比を等しく考慮することになる．
以上で定義された情報利得比[MATH]に基づく重みにより，文書[MATH]中の語[MATH]の重要度[MATH]を定義する．
以前述べたように，語の重要度にはTF，IDF，IGRの各値の組み合わせを考えるが，各値が独立に重要度に寄与するものとし，組み合わせ方法として積を用いる．
なお，上記の重みを求めるにあたって，変更可能なパラメタを導入し，訓練事例などを用いて，これを適切な値に設定する(チューニングする)ことも考えられる．
例えば，情報利得比の統合を，各階層の情報利得比の重み付き和により実現し，その重みをパラメタとすることが考えられる．
また，上述の[MATH]の式を積ではなく，重み付き和として定義し，重みをパラメタとすることも一案である．
しかし，本稿では以下に述べる理由によりパラメタのチューニングが難しいと判断したために素朴な統合方式を採用した．
情報検索タスクにおける要約では外的な評価(特定タスクの遂行精度により行なう要約手法の評価)によっているために，評価結果を再利用して，このタスクに適合したより良いパラメタ値を求めるといった方向に発展させることがし難い．
例えば，節[REF_Sec:評価]で述べる評価に用いたTSC Task Bでは，生成された要約文章に対して被験者による適合性評価が行なわれるものの，適合性判定を適切に行なうことができる要約文章を人間に生成してもらうという段階はないために，いわゆる「正解要約」がない．
また，仮にそのような「正解要約」を作成したとしても，適合性判定を正しく行なうことができる要約には様々な亜種が考えられるので，「正解要約」と同じ要約を作成することがこのタスクの本質的であるかという疑問が残る．
もちろん，評価・パラメタ再設定・再評価といったチューニングのためのループに被験者の評価を組み入れることも不可能ではないが，膨大な人的資源を必要とするために，我々はこの手法を採用しなかった．
語の重みは要約生成における基本要素であるから，ほとんどの要約手法に我々の手法を組み込むことができると考えられる．
しかし，我々の目的は，前節で述べた語の重みづけが検索文書要約において有効であることを示すことである．
そこで，次に示す，語の重要度だけによる最も基本的な要約手法を以降の評価実験で用いる．
文書[MATH]中の文[MATH]の重要度は次式の通り，文中のキーワードの重みの和を文の長さで正規化したものとする．
ある決められた要約の長さに達するまで，原文書から重要度の高い順に文を取り出していく．
取り出した文を原文書における出現順に並べ変えて要約文書を得る．
