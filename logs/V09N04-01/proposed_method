検索文書集合中の語に対する情報利得比に基づく重みづけ
  \label{Sec:検索文書集合中の語に対する情報利得比に基づく重みづけ}

\subsection{検索文書要約の特質}
  \label{Sec:検索文書要約の特質}

検索文書の要約は，以下の点で通常の文書要約と異なる．
\begin{itemize}
 \item 検索質問文が与えられている．
 \item 複数の要約文書が同時に得られている．
       そして，ある一度の検索の結果という点において文書間に類似性が認め
       られる．
\end{itemize}
いずれの情報も，検索文書の要約においては有効な手がかりと考えられる．
ここでは，これらの手掛かりを語の重みづけに用いることを考察する．

まず初めに考えられる手法は，Tombrosら
\cite{Tombros:AdvantagesOfQueryBiasedSummariesInInformationRetrieval}が
提案するように，検索質問中の語を重要語として考え，他の語よりも重みを高す
る方法である．これは，検索質問中の語や句は利用者の情報要求を端的に示すので，
要約文書にもその語や句が含まれるべきであるという直観に基づくもので，
「検索質問バイアス方式に基づく要約(Query-biased Summarization)」と呼ばれる．

この方法は，検索質問を考慮するだけであるので，実装が簡単であり，
ある程度の効果が報告されているが，次の欠点が存在する．
\begin{itemize}
 \item 検索質問中の表現をそのまま用いるために，
       検索エンジンにおける工夫が要約文書に反映されない．
       例えば，各種フィードバックや検索質問の拡張などは，
       検索質問を修正/更新することによって検索効率を上げている
       \footnote{
       ここでは，既存の情報検索システムに対するバックエンドとして要約生成
       システムを利用する場合を想定している．この場合，情報検索システムを
       運用している組織と要約サービスを提供している組織が必ずしも一致しな
       い．この状況においては，情報検索システムが行なっている工夫に関する
       情報が利用できない．一方，もしも情報検索システムの行なうフィードバッ
       クや検索質問拡張の情報が利用できるのであれば，更新後の検索要求に基
       づき，検索質問によるバイアス手法を適用することも可能である．
       }．
 \item 検索エンジンは検索質問文に関連する文書ばかりではなく，
       関連性の低い文書も結果として返すことがある．検索質問との関連性が
       低い文書に対しては，検索質問バイアス方式は通常の文書要約になって
       しまう．
\end{itemize}

そこで，我々は二番目の選択肢である，
検索質問文を使わずに，検索文書集合のみを用いて重みづけることを考える．
検索結果の質が非常に悪くない限り，検索文書集合には検索質
問に関する情報が暗に含まれていると期待できるので，
その情報を引き出すのである．
しかし，各文書に共通する語を抽出するといった単純な方法では精
度が良くないことは容易に想像される．なぜならば，検索結果の文書集合には，
もちろん検索質問との関連性が高い文書も含まれるが，関連性の低い文書も含ま
れるからである．しかも，その度合は検索エンジンの精度に依存してしまう．よっ
て，単純に文書に共通する語などを取り出すだけでは達成できない．
我々は以上の点を踏まえて次節に示す枠組を提案する．

\subsection{提案手法の概略}

我々の提案手法の概略を図\ref{Fig:Overview}に示す．
これは，次の2つの指針の組み合わせたものである．
\begin{enumerate}
 \item 検索文書集合に対し階層的クラスタリングを行ない，文書間の類似性の構造を抽出する．\label{step:clustering}
 \item 文書間の類似性の構造と語の確率分布に基づいて各語の重み付けを行なう．\label{step:weighting}
\end{enumerate}

\begin{figure}[htbp]
\begin{center}
\epsfile{file=overview.eps,scale=0.6}
\end{center}
\caption{提案手法の枠組}\label{Fig:Overview}
\end{figure}
ステップ\ref{step:clustering}においては，
検索質問に関連する文書とそうで
ない文書がクラスタ構造の中で分離されることが期待され，なおかつ，それらの
文書部分集合においても類似性に基づく細分類がなされると考えられる．
我々の手法では，語を次元とする文書ベクトルの類似度による階層的クラスタリン
グを用い，クラスタリングアルゴリズムとしては最大距離アルゴリズムを採用した．

ここで注意すべきことは，検索されなかった文書，すなわち，文書データベース中の残りの文書の存在を類似性構造の中に組み
込む必要があることである．なぜならば，クラスタ構造において，一番上位のク
ラスタは与えられた構造として扱う以外になく，類似性の解析の対象とならない
からである．検索文書全体の類似性構造は，検索されなかった文書集合との対比によって，初めて明らかになる．この類似性構造は，全文書集合と検索質問との間の類似性を反映するので，非常に重要なものである．
このため，図\ref{Fig:SuperCluster}に示すように検索文書集合から得られたクラスタ構造の根の上にもう一つ仮想的なクラスタを設ける．
そのクラスタには，検索文書の属する部分クラスタとそれ以外の文書が属する部分クラスタが存在する．
ここで，我々の方法では，検索文書の属する部分クラスタだけが，
クラスタリングアルゴリズムにる部分クラスタ解析の対象となる(図
\ref{Fig:SuperCluster}の左部分木)のに対し，
検索されなかった文書の属するクラスタ(図\ref{Fig:SuperCluster}の右部分木)に
ついてはそれ以上の解析が不要である点に注意されたい．
後に述べる情報利得比の計算においては，検索されなかった文書の属するクラスタについては，その中に存在する語の頻度だけが分かればよい．これは，あらかじめ求めておいた文書データベース中の語の頻度より，簡単に求めることができる．
よって，我々の手法において実際に文書クラスタリングが行なわれるのは，検索結
果として利用者に提示する文書に限定される．これは通常数十文書程度であるから，文書クラスタリングにおける計算量はあまり問題とならない．

\begin{figure}[htbp]
\begin{center}
\epsfile{file=highest_cluster_en.eps,scale=0.5}
\end{center}
\caption{検索文書に対するクラスタ構造}\label{Fig:SuperCluster}
\end{figure}

このようにして求められた類似性構造は文書を一つの単位とする巨視的な情報で
あるので，要約のためには，これを文や句，単語を単位とするより微視的な情報
に還元する必要がある．これが ステップ\ref{step:weighting}である．このス
テップにおいては，各クラスタが部分クラスタに分割されるにあたって，
句や単語などより微視的な単位がどれ位寄与しているかを表す指標を定め，これを
その語句の重要度とする．我々はその指標として情報利得比を用いる．

このようにして求められた情報利得比を，既存の方法でも用いられている重みである，
語の文書内頻度(term frequency, TF)，文書頻度の逆数(inverse document
frequency,
IDF)\cite{Salton:TermWeightingApproachesInAutomaticTextRetrieval,Baeza-Yates:ModernInformationRetrieval}
と組み合わせることにより，総合的な語の重要度をとする．こ
れら三種類の重みは，以下の通り，異なる文書情報から得られるものであること
に注意されたい．よって，これらの組み合わせにより，検索文書の要約に適した
総合的な重みが得られると期待できる．

\begin{itemize}
 \item 語の文書内頻度

       個別の文書における各語の分布より決まる重要度で，
       ある文書中でのその語の重要度を表す．

 \item クラスタ分割に対する語の出現確率に関する情報利得比

       検索文書の類似性構造であるクラスタの分割により決まる重要度で，そ
       のクラスタ構造におけるその語の重要度を表す．

 \item 文書頻度の逆数

       検索対象の全文書により決まる重要度で，全検索対象文書集合における
       その語の重要度を表す．
\end{itemize}


\subsection{最大距離アルゴリズムによる階層的クラスタリング}

検索された文書集合の類似性の解析には，文書間の距離の定義とその距離に基づ
く文書集合の構造化が必要となる．これには様々な方法が考えられるが，本稿で
は文書間の距離として，様々な場面で利用され，かつ，簡便なTF・IDF法ならび
にベクトル空間法に基づく方法を採用する\cite{Baeza-Yates:ModernInformationRetrieval}．また，文書集合の類似性に関する解
析には，階層的クラスタリングを用いる．

階層的クラスタリングアルゴリズムには，併合法などが良く用いられる\cite{Frakes:InformationRetrieval}．しかし，
この種の方法はクラスタ構造を無理に二分木に当てはめるため，文書間距離の順
序関係は構造に反映されるものの，その絶対値については捨象されてしまう．
ここでは，
文書の類似度に応じて多分岐構造を生成でき，文書間距離の絶対値情報がなるべ
く保存されるアルゴリズムが望ましい．そのようなアルゴリズムとして，我々は
最大距離アルゴリズム\cite{長尾:パターン情報処理}を採用した．
この最大距離アルゴリズムは，本来，非階層
的なクラスタを生成するものであるが，これを分割の結果得られた部分クラスタ
に再帰的に適用することにより階層構造を得る．この方法では，各クラスタが3
以上のクラスタに分割されることもある．

\subsubsection{文書間距離}
\label{Sec:文書間距離}

ベクトル空間モデルに基づき，各文書$D_i$をn次元空間上の点$(weight_{i1},weight_{i2},\ldots,weight_{in})$により表現する．
$weight_{ik}$ は文書$D_i$において語$w_k$に割り当てられた重みである．
重み$weight_{ik}$としては語$w_k$のTF・IDF値とする．
このとき，文書$D_i$と文書$D_j$の距離dを文書ベクトル間のユークリッド距離を用いて，次のように定義する．
\begin{eqnarray}
  d(D_i, D_j) & = &\sqrt{\sum_{k} (weight_{ik} - weight_{jk})^2},\\
 weight_{ik} & = & tf(D_i,w_k)idf(w_k), \nonumber\\
 tf(D_i,w_k) & = & \frac{freq(D_i,w_k)}{|D_i|}, \nonumber\\
 idf(w_k)  & = & 1 + \log_2 \frac{N}{df(w_k)},\nonumber
\end{eqnarray}
ただし，
\begin{quote}
  \begin{tabular}{ll}
   $freq(D_i,w_k)$ : & 文書$D_i$での語$w_k$の出現頻度\\
   $|D_i|$ :& 文書$D_i$中の形態素数\\
   $df(w_k)$  :& 検索対象の全文書集合における語$w_k$を含む文書数\\
   $N$ :& 検索対象の全文書の数
  \end{tabular}
\end{quote}
である．
\comment{
後に述べる実験においては，語として，名詞のみを扱った．
文書からの名詞抽出には形態素解析器JUMAN3.61\cite{juman3.61}を用いた\footnote{品詞細分類において，普通名詞，サ変名詞，固有名詞，地名，人名，組織名，数詞，名詞接尾辞，未定義語-その他，未定義語-カタカナ，未定義語-アルファベットをもつ形態素を取り出した．また，これらが連続した場合には，その形態素列を複合語として認定し，一単語としても取り出した．よって，複合語については，複合語自身とその構成素となった形態素の両者が文書ベクトルの成分として考慮されている}．
また，$df(w_k)$, $N$は検索対象である毎日新聞94年，95年，97年，98年のすべての記
事から求めた．
}

\subsubsection{最大距離アルゴリズム}

最大距離アルゴリズムにおいては，まず文書集合から2個以上のクラスタ中心を
選択し，次に，残りの文書を最近のクラスタ中心と同じクラスタに配置する．
その主要部分はクラスタ中心を求める部分であり，以下の手続きからなる．
\begin{enumerate}
 \item 文書集合$DS$から距離の最も大きい二文書を取り出し，これらを要素とする
       集合を作成する．これを初期のクラスタ中心の集合$C$とする．
 \item クラスタ中心集合$C$において，クラスタ中心間での最大距離を求める．
       これを，$d_{max}$ とする．
 \item $DS$中の各文書$D_i$について，すべてのクラスタ中心との距離を求め，
       その最小値を既存クラスタ中心からの距離 $d(D_i,C)$とする．
        既存クラスタ中心からの距離が最も大きい文書$D_d$を$DS$から取り出す．
 \item もし，$d(D_d,C) \ge \alpha\cdot d_{max}$ならば，
       その文書をクラスタ中心集合$C$に追加する．
       そうでなければ，終了．
\end{enumerate}
なお，$\alpha$は $0.5 \leq \alpha < 1.0$なる定数であり，値が大きいほどクラ
スタの分割数が少なくなる．一般には$0.5$とすることが多い．

以上のアルゴリズムは，単一の文書集合を文書間距離にしたがって複数個の部分
クラスタに分割する非階層的なアルゴリズムである．これを各部分クラスタに対
して再帰的に適用することにより，階層的なクラスタ構造を生成する．

\subsection{情報利得比に基づく語の重要度}

クラスタの木における各接点(内点)は，あるクラスタとそれを分割して得られた
互いに素な部分クラスタの関係，すなわち，クラスタの分割の仕
方を表現している．この分割の仕方はクラスタ内の文書の類似度に従って決定され
るので，これを文書内の語の重みに反映させることができれば，複数文書間の類
似性という巨視的な情報を，文書内の語の重みという微視的な情報に還元できる
と考えられる．

我々は，この考え方に基づき，次の2つの段階から構成される方法を提案する．
\begin{enumerate}
 \item 各クラスタについて，その部分クラスタの構造から，各語の重みを決定する．
       \label{Step:IGR}
 \item 一つの文書は，クラスタの木の根接点から対応する葉接点に至るクラスタ分
       割の系列によって指し示される．よって，各文書における語の重みは，
       各分割で得られた語の重みを統合して得る．\label{Step:IGRintegrate}
\end{enumerate}
このうち，特に重要なのは\ref{Step:IGR}である．その基本的な考え方は，クラ
スタの分割構造を決定することに寄与する語に高い重みを与えるというものである．
例として，図\ref{Fig:PartitionWordDist}のように，あるクラスタ$C_0$が3つの
部分クラスタ($C_1$,$C_2$,$C_3$)に分割されている場合を考える．図中，記号
$A$,$B$,$D$〜$G$は各々単語に対応するとする．
さて，語$A$はクラスタ$C_0$における頻
度が最も高いので，このクラスタの特徴を表す語と考えることができる．しかし，
各部分クラスタに注目すると，いずれも均等に出現しているため，部分クラスタの
選択においては役立たないことがわかる．
一方，語$F$はクラスタ$C_0$において頻度はさほど高
くはないが，部分クラスタ$C_3$に集中して登場している．この場合，語$F$が出現
しているか否かを調べることによって，部分クラスタを言い当てることができるの
で，クラスタの分割構造に対する寄与度は，語$F$は語$A$よりも高いと考え
られる．我々はこの寄与度を適切に表す尺度として，次に述べる情報利得比を用いる．
\begin{figure}[htbp]
\begin{center}
\epsfile{file=term_dist_ex.eps,scale=0.8}
\end{center}
\caption{語の出現分布とクラスタの分割}
\label{Fig:PartitionWordDist}
\end{figure}


\subsubsection{情報利得比}

情報利得比は，決定木学習システムC4.5において属性選択を行なうために導入され
た\cite{C4.5-E,Mitchell:MachineLearning}．C4.5においては，ある属性を決定木
の分岐におけるテストとしたときに，その属性がどれくらい適切にクラスの出現を
予測できるかを表す尺度として用いられている．我々は，表
\ref{Table:OurMethod_VS_C4.5}に示す対応の下，クラスタの構造を決定木の構造
と見なすことにより，情報利得比を用いる．
\begin{table}[htbp]
\caption{提案手法とC4.5における計算方法の対応}
\label{Table:OurMethod_VS_C4.5}
\begin{center}
\begin{tabular}{|l|l|}
\hline
提案手法         &  C4.5\\
\hline
クラスタの分割構造 & 属性によるテスト\\
単語の出現確率     & クラスの出現確率\\
\hline
\end{tabular}
\end{center}
\end{table}
C4.5においては属性の評価値として情報利得比を用いていたが，我々の方法にお
いては，属性ではなくクラスに対応する単語に対する評価値として情報利得比を
用いる．

クラスタ$C$における単語$w$の情報利得比$gain\_r(w,C)$は次の様に求められる．
\begin{eqnarray}
 gain\_r(w,C) & = & \frac{gain(w,C)}{split\_info(C)} \label{Eq:IGR}\\
 gain(w,C) & = & entropy(w,C) - entropy_{p}(w,C)\nonumber\\
 entropy(w,C) & = & -p(w|C)\log_2 p(w|C) \nonumber\\
           &   & - (1-p(w|C))\log_2 (1-p(w|C))\nonumber\\
 p(w|C)    & = & freq(w,C)/|C|\nonumber\\
 entropy_{p}(w,C) & = & \sum_{i} \frac{|C_i|}{|C|} entropy(w,C_i)\nonumber\\
 split\_info(C) & = & - \sum_{i} \frac{|C_i|}{|C|} \log  \frac{|C_i|}{|C|}\nonumber\\
 freq(w,C) & : & \mbox{クラスタ$C$中の語$w$の頻度}\nonumber\\
 C_i & : & \mbox{$C$における$i$番目の部分クラスタ}\nonumber\\
 |C_i| & :& \mbox{クラスタ$C_i$中の総形態素数}\nonumber
\end{eqnarray}

情報利得$gain(w,C)$ は，クラスタ$C$の分割の前後における，語$w$の確率分布に関するエントロピーの減少量を表す．
$split\_info(C)$は，クラスタ$C$の分割に関するエントロピーである．
情報利得比 $gain\_r(w,C)$ は，これらの比として定義される．

例として，図\ref{Fig:PartitionWordDist}における各語について，上述の方法によ
り情報利得比を計算してみると次の通りとなる．
{\small
\[
 gain\_r(\mbox{B},C_0) \simeq gain\_r(\mbox{F},C_0) >
 gain\_r(\mbox{E},C_0) = gain\_r(\mbox{G},C_0) > gain\_r(\mbox{D},C_0) >
 gain\_r(\mbox{A},C_0)
\]
\[
 gain\_r(\mbox{A},C_0) = 0.000,
 gain\_r(\mbox{B},C_0) = 0.161,
 gain\_r(\mbox{D},C_0) = 0.031,
\]
\[
 gain\_r(\mbox{E},C_0) = 0.080,
 gain\_r(\mbox{F},C_0) = 0.157,
 gain\_r(\mbox{G},C_0) = 0.080
\]
}
$B$や$F$のようにクラスタ構造に沿って現れる語は値が大きく，語$A$のように網
羅的に分布する場合には値が小さいことは既に述べたとおりである．
一方，語$D$のように一部のクラスタに集中してはいるものの，他のクラ
スタにも低い確率ではあるが出現する場合には，値が低くなることがみてとれる．
さらに，語$F$とほぼ同じく偏りがあるが出現確率が低い語$E$については，
その値が相対的に低くなる．

\subsubsection{情報利得比に基づく語の重要度}

式(\ref{Eq:IGR})に示される情報利得比は，各クラスタの分割毎に得られる．
これらを，ある文書中のある語の重みとして利用する方法には，
利用者向けインタフェースの設計に応じて，
いくつか考えられる．

例えば，クラスタ構造を利用者に提示しながら，部分クラスタを順次利用者に選
択してもらうような対話的インタフェースにおいては，各選択点において利用者
が注目しているクラスタにおける情報利得比を利用し，語の重みを求めることが
考えられる．

また，すべての検索文書を同時に要約し，一覧形式で利用者に提示するというイ
ンタフェースにおいては，クラスタの木の根接点からその文書に対応する葉接点
に至るすべての分割で得られたの情報利得比を何らかの形で統合し，これを語の
重みとすることが考えられる．
この時，統合の方法には様々な方法が考えられ得る．
例えば，ある階層の値を採用する，最大値を採る，すべての値を和もしくは積に
より統合する，などである．

本稿では，すべての検索文書を同時に要約し，一覧形式で利用者に提示するとい
う最も基本的なインタフェースを想定し，図\ref{Fig:IGRSum}ならびに式
(\ref{Eq:IGRsum})に示す情報利得比の重みなしの和を採用する．
この方法では，すべてのクラスタ分割における情報利得比を等しく考慮することになる．

\begin{eqnarray}
  igr(w,D) & = & \sum_{C \in Cset(D)} gain\_r(w,C) \label{Eq:IGRsum}\\
  Cset(D)  & : & \mbox{文書$D$の属するすべてのクラスタの集合} \nonumber
\end{eqnarray}
\begin{figure}[htbp]
\begin{center}
\epsfile{file=add_igr_en.eps,scale=0.4}
\end{center}
\caption{情報利得比による各文書中の語の重みづけ}
\label{Fig:IGRSum}
\end{figure}

以上で定義された情報利得比$igr(w,D)$に基づく重みにより，
文書$D$中の語$w$の重要度 $weight(w,D)$ を定義する．
以前述べたように，語の重要度には TF，IDF，IGRの各値の組み合わせを考えるが，
各値が独立に重要度に寄与するものとし，
組み合わせ方法として積を用いる．
\begin{eqnarray}
  weight(w,D) & = & igr(w,D)\cdot tf(w,D)\cdot idf(w)
\end{eqnarray}

なお，上記の重みを求めるにあたって，変更可能なパラメタを導入し，訓練事例な
どを用いて，これを適切な値に設定する(チューニングする)ことも考えられる．例
えば，情報利得比の統合を，各階層の情報利得比の重み付き和により実現し，その
重みをパラメタとすることが考えられる．また，上述の$weight(w,D)$の式を積で
はなく，重み付き和として定義し，重みをパラメタとすることも一案である．

しかし，本稿では以下に述べる理由によりパラメタのチューニングが難しいと判断
したために素朴な統合方式を採用した．

情報検索タスクにおける要約では外的な評価(特定タスクの遂行精度により行なう
要約手法の評価)によっているために，評価結果を再利用して，このタスクに適合
したより良いパラメタ値を求めるといった方向に発展させることがし難い．例えば，
節\ref{Sec:評価}で述べる評価に用いたTSC Task Bでは，
生成された要約文章に対して被験者による適合性評価が行なわれるものの，適合性
判定を適切に行なうことができる要約文章を人間に生成してもらうという段階はな
いために，いわゆる「正解要約」がない．また，仮にそのような「正解要約」を作
成したとしても，適合性判定を正しく行なうことができる要約には様々な亜種が考
えられるので，「正解要約」と同じ要約を作成することがこのタスクの本質的であ
るかという疑問が残る．もちろん，評価・パラメタ再設定・再評価といったチュー
ニングのためのループに被験者の評価を組み入れることも不可能ではないが，膨大
な人的資源を必要とするために，我々はこの手法を採用しなかった．



重要文抽出に基づく要約文書生成

語の重みは要約生成における基本要素であるから，ほとんどの要約手法に我々の
手法を組み込むことができると考えられる．しかし，我々の目的は，前節で述べ
た語の重みづけが検索文書要約において有効であることを示すことである．そこ
で，次に示す，
語の重要度だけによる最も基本的な要約手法を以降の評価実験で用いる．
\begin{enumerate}
 \item 文書$D$中の文$s$の重要度は次式の通り，文中のキーワードの重みの和を文の長さで正規化したものとする．
       \begin{eqnarray}
	s\_imp(s,D) & = & \frac{\displaystyle\sum_{w \in keyw(s)} weight(w,D)}{|s|} \\
	keyw(s) & : & \mbox{文$s$中のキーワードのリスト}\nonumber\\
        |s| & : & \mbox{文$s$の総形態素数}\nonumber
       \end{eqnarray}

 \item ある決められた要約の長さに達するまで，
       原文書から重要度の高い順に文を取り出していく．
 \item 取り出した文を原文書における出現順に並べ変えて要約文書を得る．
\end{enumerate}

NTCIR2 TSC Task B に参加した他システムの概要
\label{Appendix:NTCIR2 TSC Task B に参加した他システムの概要}

NTCIR2 TSC Task B に参加した他システムについて，
NTCIR2 Workshop論文集に基づきその概略を述べる\cite{
Nobata:SentenceExtractionSystemAssemblingMultipleEvidence,
Nakao:HowSmallADistinctionAmongSummariesCanTheEvaluationMethodIdentify,
Hirao:TextSummarizationBasedOnHanningWindowAndDependencyStructureAnalysis,
Oka:PhraseRepresentationSummarizationMethodAndItsEvaluation
}．
なお，システム Sys 7 については，その詳細は不明である．

\subsection{ベースライン TF with QB}
TSC実行委員会が提供するベースラインの一つで，
文抽出型でスコアの上位の文から指定の要約率になるまで抽出．
要約率は20\%(文を単位とする)．
各文のスコアは，内容語(名詞，動詞，形容詞，未定義語)のTFの和であるが，
検索トピック中の語にはバイアスが与えられ，2倍の重みとする．
この「2倍」という定数がどのように決定されたか，
例えば，何らかのチューニングが施されているかなどは不明である．


\subsection{ベースライン Lead}
TSC実行委員会が提供するベースラインの一つで，
文抽出型で本文の先頭から指定の要約率になるまで抽出．
要約率は20\%(文を単位とする)．

\subsection{ベースライン Fulltext}
TSC実行委員会が提供するベースラインの一つで，
原文書のうち，表題(見出し文)ならびに本文をそのまま返すもの．
要約率は100\%(文を単位とする)．


\subsection{システム Sys 1, Sys 2} \comment{CRL+NYUグループ}
文抽出型でスコアの上位の文から指定の要約率になるまで抽出．
要約率は10\%(Sys 1)ならびに50\%(Sys 2)．
文のスコアは，次の3つの値を重み付きで加算したものである．
(1)文書中の文の位置に基づくスコアで，文書の先頭ならびに文末に高い重みを付与
する．
(2)文長に基づくスコアで長いものに高い重みをつける．
(3)名詞のTF・IDF値の和をスコアとしたもの．ただし，
   見出しに含まれる名詞ならびに固有表現(Named Entity)については，
   そのTF・IDF値を加算し，
   トピック中のDESCRIPTIONおよびNARRATIVEフィールドの名詞に対しては，さらに，
   TF・IDF値を2倍にする．

\subsection{システム Sys 3, Sys 4} \comment{富士Xerox}

語と語の間の重要な関係を見つけ出し，それを元に要約を句レベルで生成する．
その関係の重みは各語の重みの和に関係の重みを乗じたものである．
各語の重みは TF・IDF値で求めるが，
トピック中の語については高い重みを与える(詳細は不明)．
語の間の関係については，格による依存関係には高い値を，
等位接続などには低い値を与える．
要約文書の長さは文字数で与えられ，100文字以内(Sys 3)もしくは150文字以内(Sys 4)である．

\subsection{システム Sys 6} \comment{NTT通信研}
文抽出型で，ハニング関数を用いた窓により各パッセージの重要度を計算し，その	中から重要文を抽出する．
パッセージの重要度計算においてはトピック内の語のみに注目する．
また，文書の先頭部分は無条件に加える．
要約率は明示されていないが，35\%程度である．


\subsection{システム Sys 8, Sys 9}\comment{富士通研グループ}

文抽出型で，与えられたキーワードを網羅する文を優先しつつ，
全てのキーワードが要約文書に出現するまで文を抽出する．
キーワードは，文書タイトル，文書の先頭段落(Sys 8のみ)，
話題構造の境界にある文中の語(Sys 9のみ)，
トピック中のDESCRIPTIONならびにNARRATIVEから，それぞれ，
名詞，動詞，形容詞 を取り出したものである．


\begin{biography}
\biotitle{略歴}
\bioauthor{森 辰則}{
1986年横浜国立大学工学部情報工学科卒業．
1991年同大学大学院工学研究科博士課程後期修了．
工学博士．
同年，同大学工学部助手着任．
同講師を経て現在，同大学大学院環境情報研究院助教授．
この間，1998年2月より11月までStanford大学客員研究員．
自然言語処理，情報検索，情報抽出などの研究に従事．
言語処理学会，情報処理学会，人工知能学会，日本ソフトウェア科学会，日本認知
 科学会，ACM, AAAI各会員．
}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}
