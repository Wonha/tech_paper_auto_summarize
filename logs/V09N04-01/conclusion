考察


\subsection{タスク遂行の精度}

TSC Task Bは，利用者(被験者)が要約文書を読むことにより，原文書のト
ピックに対する関連度を推定するタスクであった．よって，この場合の要約は報知
的(informative)である必要はなく，指示的(indicative)でありさえすれば良い．

このような要約においては，原文書に関する細かいニュアンスが伝達されるエレガ
ントな要約文書が生成される必要はなく，適切なキーワードの選択とそのキーワー
ドがどのような文脈で現れているかを説明する文書部分の抽出が適切にできればよい
と考えられる．この考え方に従えば，キーワードの抽出の精度が高ければ，我々が
用いた程度の文抽出による要約機構でもタスクを十分遂行できる要約文書が得られるはずである．

以下ではAnswer Level A,B に分けて，上記の観点からタスク遂行の精度を考察す
る．

\subsubsection{Answer Level A}
\label{Sec:Answer Level A}

本節では検索質問に対して適合文書(A判定)のみを正解とした評価(Answer Level
A)について考察を行なう．表\ref{Table:EvaluationResultAll}によると，我々の
手法は，再現率，適合率，F値すべてにおいて，他のすべての参加システムよりも
高い値を示している．

ベースラインシステムとの比較においては，我々のシステムの適合率はLead手法よ
りも1.5ポイント低い値を示しているものの，それ以外は勝っている．Lead手法は，
再現率が他の手法に比べて一番低いため総合指標であるF値においてはさほど高く
なく，我々のシステムよりも7.7ポイント低い．すなわち，Lead手法は適合率重視
の手法と見なすことができる．

質問バイアス付きTF法と比較してみると，再現率において
10.9ポイント，適合率において2.7ポイント，F値において7.0ポイント勝っている．
このことは，検索文書の要約においては，必ずしも検索要求を直接使用しなくても，
検索文書群だけで同等以上の質を持つ要約が可能であることを示している．

次に，適合性判断の所要時間とタスク遂行の精度について考える．まず，表
\ref{Table:EvaluationResultAll}によると，所要時間単独についていえば，我々
のシステムが生成した要約に対し，被験者が適合性判定に要した時間は，1トピッ
ク(50文書)あたり8分33秒であった．これは，TSCに参加した9システム中，3番めに
短いものであった．また，すべての参加システムの平均タスク時間は1トピック当
たり 9分8秒 であり，我々の要約の適合性判定に要する時間はこれよりも短い．そ
して，所要時間と各種評価値の関係を示す図\ref{Fig:Time-RPF}(A)においては，
概ね，左上に位置するシステムの性能が良いと考えられるので，我々のシステムは
他のシステムに勝っていると言えよう．特に，再現率は適合率に比べてシステム間
での格差が大きく，我々のシステムの再現率の高さが見てとれる．

図\ref{Fig:Topic-RPF}(A)によれば，他のベースラインシステムはトピックによっ
て，再現率が大きく変動しているが，我々のシステムはトピックにあまり依
存せず安定して高い再現率を示している．これは，被験者が，関連文書(関連度A)の
要約に対して適合すると概ね正しく判断したことを示す．一方，適合率についてい
えば，他のベースラインシステムとほぼ同様の傾向で，我々のシステムもトピック
によってその精度が大きく変動している．これは，トピックによっては，我々のシ
ステムが，非関連文書(関連度B,C)に対して一見すると関連性があると見誤る文を抽
出し，要約の一部として提示していることを表す．以上をまとめると，まず，我々
の手法は，トピックに関連する文を原文書から積極的に抽出していることがわかる．
一方，そのような文の周囲の文脈については，抽出を促す戦略を採っていないこと
から，それらの抽出洩れにより，非関連文書に対して関連性があると見誤るような
要約を生成する可能性もあることがわかる．

なお，図\ref{Fig:Time-Length}をみると，要約文書長と適合性判定の所要時間は
一定時間のオフセット(5分52秒)がついているものの，システムの違いによらず，
ほぼ，比例関係となっている．一方，各システムの出力する要約文書については，
適合性判定の精度にばらつきが見られる．よって，要約文書の適合性判定時間は適
合性判定の結果によらず，要約文書の長さのみに依存していると考えられる．


\subsubsection{Answer Level B}
\label{Sec:Answer Level B}

本節ではB判定まで含めた評価(Answer Level B)について考察を行なう．他のシ
ステムと比較して，再現率が第2位と高いものの，適合率は第7位，F値は第4位と
相対順位が低くなった．Answer Level B の評価においては，Answer Level Aよ
りも正解の数が多くなるので，一般に，Answer Level Aに比べて，再現率が下降
し，適合率が高くなる．再現率についていえば，Answer Level Aにおいて，高い
適合率となったシステムほど減少が激しくなる．一方，適合率については，B判
定のものがAnswer Level A での誤判定となっているのであれば，その値の上昇
が著しい．

我々のシステムの場合，再現率が 0.907 から 0.754 へと激しく低下しており，
図\ref{Fig:Topic-RPF}(B)に示される通り，トピック毎の変動が大きくなっている．
しかし，その順位について言えば，2位であるので相対的には他のシステムよりも高いことがわかる．
つまり，関連文書(評価A,B)に対して正しく関連性の判定が行なわれた要約文書の数は他のシステムよりも多い．

一方で，適合率の上昇は他のシステムより低いので，被験者が関連度評価Cの文書
の要約に対しても適合であると判定を下した数が多かったことになる．これは，
Answer Level Aの考察で述べたことを裏付けており，トピックに関連する文の抽出
は成功しているものの，その文脈が脱落する場合も少なからずあることを示してい
る．ただし，図\ref{Fig:Time-RPF}(B)や図\ref{Fig:Topic-RPF}(B)が示すとおり，
適合率のシステム間の差異は再現率ほど大きくなく，また，Answer Level Aの適合
率に比べてもシステム間の格差が小さくなっている．

\subsubsection{提案手法とベースラインとの差異に関する検定}

前節までに述べたタスクの遂行精度において，提案手法と他の手法の間に有意な差
があるか否かを検証するためには，統計検定を行なう必要がある．

しかし，TSC実行委員会が提供する結果情報において，トピック毎の個別の評価が
得られるのは自システムならびにベースライン三種のみだけである．そこで，ここ
では，提案手法がベースライン三種との間に有意な差があるかを検証する．

総合性能を表すF値についてトピック毎の値の差に基づきWilcoxonの符号順位検定
を行なった．提案手法と各ベースラインを比較した時に「F値に差が無い」という
帰無仮説に対する有意確率pを表\ref{Table:Wilcoxon}に示す．

\begin{table}[htbp]
 \caption{本手法とベースラインとの間の差異に関するWilcoxon符号順位検定の結果}
 \label{Table:Wilcoxon}
 \begin{center}
  \begin{tabular}{|l|l|l|l|}
   \hline
                & 対 TF with QB	 & 対 Lead  & 対 Fulltext\\
   \hline
   Answer Level A & $\bf{p=0.0161 < 0.05}$  &
                       $\bf{p=0.0400 < 0.05}$ & $p=0.0522 > 0.05$\\
   \hline
   Answer Level B	& $p=0.4238 > 0.05$ &
                       $\bf{p=0.0332 < 0.05}$& $p=0.9097 > 0.05$\\
   \hline
   \end{tabular}\\
  \vspace*{5pt}
  太字は有意水準5\%の下で差があることが示されたもの．
  \end{center}
\end{table}

この表によると，Answer Level Aにおいては，
提案手法がベースラインTF with QBならびにLeadに対して，有意水準5\%の下で，
差を持つことが示されている．Fulltextとの比較については，有意水準5\%の下での差
異を示すことができなかったが，帰無仮説を採択する確率が5.2\%程度で同有意水
準との差は僅差である．

一方，Answer Level Bにおいては，ベースラインとの差が Answer Level Aほど顕
著ではない．有意水準5\%の下で差がある事が示されたのはLead手法との対比だけ
であった．


\subsection{適合と判断した被験者の数による要約の質の定量的評価}

図\ref{Fig:Rel-Judge}(A)についてみると，トピックに対する原文書の関連度が
Aの場合には，いずれのシステムにおいても，当然ながら，3人が一致してYESとす
る場合が最も多く，2人，1人，0人と順に頻度が低くなっていく．我々の手法につ
いてみ
ると，他のベースライン手法に比べて，3人が一致してYESと答えた頻度が高くなっ
ており，一方，1人，2人がYESと答えた頻度が低くなっている．すなわち，関連性
のある文書については，他の手法より質の高い要約が生成されていたと考えられる．
また，Lead手法については，3人が一致してNOとつけた件数が他のベースラインよ
りも多くなっている．つまり，関連判定に重要な部分は必ずしも文頭にあるわけで
はなく，一般的な新聞記事の要約で良い戦略の一つとされるLead手法が情報検索タ
スクにおいては，必ずしも有効ではないことがわかる．

一方，関連度Bが与えられている原文書についていえば，
本来はNOであるべきであるから，YESとした人数が0の場合の頻度が大きく，
3人の場合の頻度が少なくなる傾向にあるはずである．
ただし，関連性が一部認められる記事の要約に対する評価であるから，
要約の仕方によっては1〜2人程度の人がYESと判定する頻度も(C)の場合に比べて
多くなることが予想される．
図\ref{Fig:Rel-Judge}(B)をみると，TF手法を除いて，この傾向がみられ，
特にLead手法において顕著である．
TF手法においては，0人の頻度が少なく，被験者3人のうち1人以上が関連性があると判定
していることがわかる．

そして，図\ref{Fig:Rel-Judge}(C)についてみると，概ね，0人，1人，2人，3人と
順に頻度が低くなっていく．
誤った判定の箇所，すなわち1人，2人，3人の箇所をみると，
ベースライン手法よりも我々の手法のほうが上方にグラフが描かれている．
すなわち，他のベースライン手法よりも関連度Cの文書に対して誤って関連性があ
ると判断した被験者が多かったことを示している．
これは，節\ref{Sec:Answer Level A}ならびに
節\ref{Sec:Answer Level B}で考察したことを再確認するものである．


\subsection{語の重み付けに関する考察}

我々の提案する語の重みづけについてその特徴を実例(検索トピック1027,「ハイビ
ジョンテレビ」)により考察する．
表\ref{Table:weight1027A}において，
我々が最終的に用いる語の重みであるTFIDFIGRsumの列に示されるように，
関連度Aの文書においては，検索トピックに陽に示されて
いる語はもちろんのこと，「BS」，「番組」，「デジタル」，「申請」，「衛星」，
「郵政省」など，そのトピックに関連する語も上位に重み付けられていることが分
かる．その一方で，TF・IDF値では上位にあった非関連語「SDTV」(標準テレビ)につ
いては，上位10位から姿を消している．
これらの効果は，TF・IDFの列とIGRsumの列を比較すれば分かるが，
IGRsumの成分が主に寄与している．
そして，このような重みづけは質問バイアス付きTF手法では，質問拡張
\cite{Baeza-Yates:ModernInformationRetrieval,Salton:ImprovingRetrievalPerformanceByRelevanceFeedback}
などを別途行なわない限り実現できないものである．

関連度BやCの文書についても，表
\ref{Table:weight1027B},\ref{Table:weight1027C}に示されるとおり，トピック
に関連の深い語が上位に重み付けられていることが見てとれる．
また，関連度Cの例では，IGRsumの値が低いものも上位に見られるが，いずれもトピッ
クとは関係の薄い語である．

\subsection{語の重みづけの品質と検索文書の数ならびに品質に関する考察}
\label{Sec:語の重みづけの品質と検索文書の数ならびに品質に関する考察}

本手法による重みづけは，クラスタリングの対象となる文書の件数ならびに検索結
果の質と密接な関係にある．

本来ならば，TSC Task Bと同一条件の下で，要約の対象となる文書数ならびに検索
結果の質を変化させての追加検証が必要であるが，TSC Task Bと同一被験者による
再実験が困難であるため，ここでは，定性的な考察を行なう．定量的な考察は今後
の課題としたい．

さて，本手法で語の重みに用いている情報利得比の和は，クラスタ構造に則した分
布をしている語に高い重みを与えるものであるから，検索文書をクラスタリングし
た結果，どのようなクラスタ構造が形成されるかによって，各語の重みが決まる．

クラスタ構造は対象となる文書間の類似性により求めるので，検索文書のうち，クラ
スタリングの対象となる文書群(以下，単に検索文書群と呼ぶ)について，その数と
文書間の類似度に密接な関係がある．さらに，本手法では，図
\ref{Fig:SuperCluster}に示すように文書データベース中の全文書が所属するクラ
スタを最上位に考え，検索文書群とそれ以外の文書群の間の差異についても重みに
反映しているので，全体のクラスタ構造は情報検索の精度とも関係がある．

そこで，以下では，上記二点について個別に考察を行なう．


\subsubsection{語の重みづけの品質と検索文書数に関する考察}
\label{Sec:語の重みづけの品質と検索文書数に関する考察}

採用する文書が少ない場合と多い場合について考察する．
まず，採用する文書数が少ない場合について，検索文書群と残りの文書群との対比
から得られる重み，ならびに，検索文書群をクラスタリングした結果から得られる
重みがどのようになるかを考える．最終的な語の重みはこれらの和である．

文書数が少ない場合には，文書集合中の総単語数ならびに個々の単語の頻度も小さ
くなるので， 平滑化(smoothing)をせずに単語頻度から語の出現確率を直接推定す
ると，語の頻度の小さな差異が語の出現確率の大きな変化となることがある．この
時，残りの文書群における単語の出現確率との差が大きくなれば，その語の重みが
不当に高くなる可能性がある．本稿では用いてはいないが，単語出現確率の推定に
おいては平滑化を考慮すべきであろう．

検索文書のクラスタリングについては，クラスタ中の文書数ならびにクラスタ構造
の枝分かれが少なくなるので，各文書間の類似性関係がクラスタ構造に大きな影響
を与える．そして，情報利得比の計算においては，語の重要度が個別文書における
語の現れ方に敏感になる．
           
一方，採用する文書数が大きい場合には，個々の単語の出現頻度が相対的に大きく
なることと，個々の文書間の類似度がクラスタ構造に与える効果が分散・平滑化さ
れることにより，上記と逆の傾向があると考えられる．

ただし，検索質問との関連性が低い文書が数多くなってくると，検索質問に述べら
れたトピックとは関連性の低い語がクラスタ形成の際に支配的になる事も有り得る．
この場合は，本来のトピックに関連する語には相対的に低い重みしか与えられない．
これは，検索文章群において，より重要な項目を強調するという点では正しい重み
の付き方ではあるが，本来のトピックとの関連性判定という観点からは，誤らせる
方向にバイアスがかかってしまう．このような場合にはTombrosら
\cite{Tombros:AdvantagesOfQueryBiasedSummariesInInformationRetrieval}の提
案するような検索質問によるバイアス方式の方が適切な結果を与えるので，両者を
併用する方法も検討すべきであろう．


\subsubsection{語の重みづけの品質と情報検索の品質に関する考察}

検索結果の質も，検索文書群と残りの文書群との対比から得られる語の重み，なら
びに，検索文書群をクラスタリングした結果から得られる語の重みの両者に影響を
与える．

まず，検索文書群と残りの文書群との対比から得られる語の重みについて考える．
この段階で検索質問に関連する語に比重がおかれた適切な重みづけがなされるため
には，残りの文書集合と比較して検索文書集合側に関連文書が多く存在し，それに
伴い関連する語の出現確率が偏る必要がある．情報検索の質が非常に悪く，文書集
合からほぼランダムに検索文書が取り出されるのであれば，検索文書集合とそれ以
外の文書集合の間で各語の出現確率に見られる差異は小さく，対比によって得られ
る語の重みはいずれも小さな値に留まる．一方，検索エンジンが，検索質問に従っ
て，ある程度分布の偏った文書集合を返すとすれば，その度合に応じて，検索質問
に関連する語の重みも高くなる．

次に検索文書群をクラスタリングした結果から得られる語の重みについて考える．
節\ref{Sec:語の重みづけの品質と検索文書数に関する考察}でも述べた通り，検索
質問との関連性が低い文書が多くなると，検索質問に述べられたトピックとは関連
性の低い語が，クラスタ形成の際に支配的になる事も有り得る．この場合は，本来
のトピックに関連する語とは別の語に高い重みが与えられる．この時には，検索質
問によるバイアス方式の方が性能が良いと考えられる．

前項とともに以上をまとめると，我々の重み付け方式が十分な効果を発揮するためには，
\begin{description}
 \item[条件 1] 情報検索エンジンの精度が悪くない事
 \item[条件 2] 検索質問に関連する文書が検索結果中にある程度存在する事
\end{description}
の二点を満足することが必要であると考えられる．また，
これらの条件を満足しない場合，特に，条件2を満たさない場合にも対応できるた
めには，検索質問によるバイアス方式との併用を検討することも重要であろう．
本節の定量的な評価とともに今後の課題としたい．


おわりに

本稿では，複数の検索文書の間に存在する類似性の構造を階層的クラスタリングに
より抽出し，その構造を適切に説明するか否かに応じて情報利得比に基づき語に重
みをつける手法を提案した．TSCでの実験の結果，この方法に基づく重要文抽出型
の要約手法は，検索文書の要約において，非常に有効であることが示された．

今後の課題としては，節
\ref{Sec:語の重みづけの品質と検索文書の数ならびに品質に関する考察}
に述べたように本手法と検索文書の数ならびに品質の間の定量的な関係を明らかに
することが挙げられる．また，情報利得比に基づく語の重みを，
対話型の情報検索インタフェース中で利用することを検討することも課題である．
本稿では，クラスタ構造の全部分を均一に語の重みに反映させて要約を作成した．
一方で，対話型のインタフェースとしては，
利用者が部分クラスタを選択しながら，目的の情報に辿りつくというものも考えられる．
この場合，提示された箇所のクラスタ構造のみを考慮して，
要約を生成することができると考えられる．
さらに，複数文書の要約において我々の枠組がどの様に役立つのかも検討したい．

\acknowledgment

本研究を進めるにあたり，本学大学院生であった菊池美和さん(現在，(株)NTTデータ)ならびに吉田和史さん(現在，三菱電機(株))に多大なる御協力を頂きました．ここに感謝いたします．
また，国立情報学研究所主催のNTCIRならびにTSC1を企画・運営し，
評価用データを作成していただいた皆様に感謝致します．
なお，本研究を遂行するにあたって，CD-毎日新聞94年版，95年版，97年版，98年版を利用させていただきました．使用許諾をしていただいた毎日新聞社，ならびに，
同データの研究利用に対して御尽力いただいた皆様に感謝致します．
最後になりましたが，数多くの有益なコメントを頂いた査読者の方に感謝いたします．

本研究の一部は文部科学省科学研究費特定領域研究「ITの深化の基盤を拓く情報学
研究」(課題番号 13224041，14019041)により支援を受けております．

\bibliographystyle{jnlpbbl}
\bibliography{summarization,InformationRetrieval,learning,algorithms,manual}

