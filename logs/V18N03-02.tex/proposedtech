    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\newcommand{\argmax}{}
\newcommand{\argmin}{}



\Volume{18}
\Number{3}
\Month{June}
\Year{2011}

\received{2010}{9}{30}
\accepted{2010}{11}{9}

\setcounter{page}{247}

\jtitle{ラベルなしデータの二段階分類とアンサンブル学習に基づく\\
	半教師あり日本語語義曖昧性解消}
\jauthor{井上　裁都\affiref{Author_1} \and 斎藤　博昭\affiref{Author_1}}
\jabstract{
本稿では，パラメータ調整を簡略化したブートストラッピング的手法による
日本語語義曖昧性解消を提案する．
本稿で取り上げるブートストラッピングとは，ラベルなしデータを既存の
教師あり学習手法を用いて分類し，その中で信頼度の高いデータを
ラベル付きデータに加え，この手順を反復することによって分類の性能を向上させる
半教師あり学習手法である．
従来のブートストラッピングによる語義曖昧性解消においては，プールサイズ，
ラベル付きデータに追加するラベルなしデータの事例数，手順の反復回数といった
パラメータをタスクに合わせ調整する必要があった．
本稿にて提案する手法はヒューリスティックと教師あり学習（最大エントロピー法）
によるラベルなしデータの二段階の分類，および学習に用いるラベルなしデータの
条件を変えた複数の分類器のアンサンブルに基づく．
これにより必要なパラメータ数は一つになり，
かつパラメータの変化に対し頑健な語義曖昧性解消を実現する．
SemEval-2 日本語タスクのデータセットを用いたベースラインの教師あり手法との
比較実験の結果，パラメータの変化に対し最高で 1.8 ポイント，
最低でも 1.56 ポイントの向上が見られ，提案手法の有効性を示せた．
}
\jkeywords{語義曖昧性解消，半教師あり学習，ブートストラッピング，最大エントロピー法，アンサンブル学習，頑健性}

\etitle{Semi-Supervised Japanese Word Sense Disambiguation\\
	Based on Two-Stage Classification of Unlabeled Data\\
	and Ensemble Learning}
\eauthor{Tatsukuni Inoue\affiref{Author_1} \and Hiroaki Saito\affiref{Author_1}} 
\eabstract{
In this paper, we propose a bootstrapping-like method 
which eases optimal and empirical parameter selection 
for Japanese word sense disambiguation. 
Bootstrapping means, in this paper, semi-supervised learning methods 
based on the following procedures: 
(1) train a classifier on labeled examples, 
(2) use the classifier to select confident unlabeled examples, 
(3) add them to the labeled examples, 
(4) repeat steps 1--3. 
Traditional bootstrapping methods require empirical selection for 
the parameters including the pool size, the number of 
the most confident examples and the number of iterations. 
Our method uses two-stage unlabeled example classification 
based on heuristics and a supervised method (Maximum Entropy classifier) 
and combines a series of classifiers along a sequence of varying conditions. 
This method requires only one parameter 
and enables parameter robust word sense disambiguation. 
Experiments compared with the baseline supervised method 
on the Japanese WSD task of SemEval-2 shows that our method obtained 
accuracy improvement between 1.8 and 1.56 points.
}
\ekeywords{Word sense disambiguation, Semi-supervised learning, Bootstrapping, Maximum entropy, Ensemble learning, Robustness}

\headauthor{井上，斎藤}
\headtitle{ラベルなしデータの二段階分類とアンサンブル学習に基づく半教師あり日本語語義曖昧性解消}

\affilabel{Author_1}{慶應義塾大学大学院理工学研究科}{Graduate School of Science and Technology, Keio University}



\begin{document}
\maketitle


\section{提案手法}
\label{sec:method}

提案手法は\ref{sec:intro}節で述べたラベルなしデータの二段階の分類と
その結果を用いたアンサンブル学習による最終分類器作成の全三段階からなる．
手法の流れを次に，また本手法に基づくシステム全体像を図\ref{fig:img01}に示す．

\begin{figure}[b]
 \begin{center}
  \includegraphics{18-3ia2f1.eps}
 \end{center}
  \caption{提案手法システム全体像}
  \label{fig:img01}
\end{figure}

\vspace{0.5\baselineskip}
\begin{center}
\begin{minipage}{0.85\hsize}
\begin{description}
\item[Stage 1] ヒューリスティックによる分類\\
（手掛り語獲得，手掛り付き事例抽出・分類1回目）
\item[Stage 2] 教師あり学習手法による分類\\
（手掛り付き事例分類2回目，二次分類器作成）
\item[Stage 3] アンサンブル学習による最終分類器作成
\end{description}
\end{minipage}
\end{center}
\vspace{0.5\baselineskip}

まず図\ref{fig:img01}の見方を述べる．
長方形の囲みは各種処理，楕円の囲みは各処理の出力を示す．
各種処理の中には語義分類の処理が三回登場するが，
これらの括弧内の分類器はそれぞれの分類処理のために
作成し使用する分類器を示している．
実線の矢印は各処理において入出力されるデータの流れを示す．
点線は入出力するデータへの処理に利用するデータであり，
分類器作成のために訓練データとして用いるデータも含まれる．
図\ref{fig:img01}における訓練データとはオリジナルのラベル付きデータを指す．
本システムにおける最終的な語義曖昧性解消の対象は，
テストデータとして図\ref{fig:img01}のように入力し，
その結果は語義分類最終結果として出力される．

図\ref{fig:img01}に基づく本システムの概観は次のようになる．
まず本システムの最初の手順は手掛り語の獲得である．
手掛り語は訓練データから抽出する形で獲得する．
第二の手順はラベルなしデータからの手掛り付き事例の獲得である．
手掛り付き事例の獲得は，
手掛り語を用いたラベルなしデータからの手掛り付き事例の抽出・分類（1回目），
訓練データを用いて作成された一次分類器による手掛り付き事例の語義分類，
一次分類器による分類結果に基づく手掛り付き事例の分類（2回目）といった
多段の手順により実現される．
最後の手順はテストデータの語義曖昧性解消である．
これは獲得した手掛り付き事例と訓練データを用いた二次分類器の作成，
および異なる条件で作成された複数の二次分類器による
テストデータの分類結果に基づく最終分類器の判定より構成される．

本節では，以後本手法を全三段階に区切り，詳述していく．
ここで一つ注意点がある．
それは今，本システムを上述のように手掛り語，手掛り付き事例，
語義分類最終結果と出力されるデータに着目し，手順を三つに区切ったが，
これは以後に述べる三段階の手順と対応関係にないということである．
具体的には，手法第一段階は図\ref{fig:img01}の手掛り語獲得から
手掛り付き事例抽出・分類1回目まで，
手法第二段階は一次分類器による手掛り付き事例の分類から
二次分類器によるテストデータの語義分類まで，
手法第三段階は最終分類器によるテストデータの語義分類のみと対応する．

手法第一段階はヒューリスティックによるラベルなしデータの分類として一括りし，
手掛り語ならびに手掛り付き事例の詳細と併せて\ref{sec:first}節にて詳述する．
手法第二段階はラベルなしデータから抽出した手掛り付き事例の
教師あり学習手法による分類とその結果に基づく二次分類器の作成として括り出し，
詳細を\ref{sec:second}節にて述べる．
手法第三段階はアンサンブル学習による最終分類器の作成として括り，
\ref{sec:third}節にて詳述する．
\ref{sec:summary}節では本手法のまとめをする．
このような手法の全三段階の区切りは，\ref{sec:exp}節にて述べる
実験結果の考察において意味を持つことになる．

なお本稿では，訓練データ，テストデータおよびラベルなしデータはいずれも
UniDic\footnote{http://www.tokuteicorpus.jp/dist/}を用いて形態素解析済み
\footnote{SemEval-2日本語タスクのデータセットはUniDicを用いた
自動解析およびその人手での修正が施されている．} であり，訓練データにおいてラベルは各形態素に付与されているものとする．
また本稿では便宜上，形態素を単語または語とも呼ぶことにする．



\subsection{Stage 1：ヒューリスティックによる分類}
\label{sec:first}

分類第一段階は訓練データからの手掛り語の獲得ならびにヒューリスティックによる
ラベルなしデータからの手掛り付き事例の抽出・分類（1回目）からなる．


\subsubsection{手掛り語の獲得}

本手法で獲得する手掛り語$W_{ts}$とは，訓練データ$L$において語義ラベルが
付与された対象語\footnote{本稿では語義曖昧性解消の対象語を単に「対象語」と呼ぶ．} $t$の前後$n_w$語以内において共起する内容語
\footnote{具体的には\ref{sec:exp}節参照のこと．} の表層形であり，かつ与えられた訓練データ内で共起する$t$に付与された
語義ラベルが必ずある一つの語義ラベル$s$に定まる語の集合とする．
後者の条件は，$s$が付与された$t$を$t_s$とすると，
形態素$w_j$共起の下で$t$が$t_s$である確率を$p(t_s|w_j)$とすると，
\begin{equation}
p(t_s|w_j)=1 \label{eq1}
\end{equation}
を満たす$w_j$であることとも書き換えることができる．
前者の条件にある窓幅$n_w$については\ref{sec:third}節で詳述する．

このような条件を満たす$w_{ts} \in W_{ts}$が
語義ラベルが付与されていない$t$と共起したとき，
この$t$は単純に式(\ref{eq1})より$t_s$である可能性が高いと考え，
以後$W_{ts}$は$t$の語義曖昧性解消の手掛りとして利用する．
また表層形を条件としたのは，基本形，品詞といった情報は表層形と比べ情報の
粒度が荒く，表層形の方が手掛りとしての信頼性が高いと考えたことによる．

もし式(\ref{eq1})を満たす$w_j$が$L$全体で一度だけ出現する語である場合，
$t$が$t_s$に決定付けられる可能性は低いとも考えられるが，
これは二度以上出現する語の場合も大差はないと筆者は考える．
$p(t_s|w_j)$は語義曖昧性解消において単純ベイズや決定リストのルールの
信頼度などにしばしば用いられ
\footnote{ここでは$w_j$は任意の素性である．}，
その中で$p(t_s|w_j)$をスムージングして用いる例もいくつかある
\cite{Yarowsky95,Yagi01,Tsuruoka02}．
しかしこの場合は最適な閾値を求める必要があり，
問題がかえって難しくなってしまう．
このため，今回は単純な式(\ref{eq1})を$w_{ts}$の条件とした．

なお上述の$w_{ts}$は添え字が示すように共起する$t_s$に
付与されていた$s$の情報を含む．
よって実際の手掛り語獲得では，例えば対象語が「相手」，
$n_w=2$，訓練データの一つに「相手に取って不足はない」があり，
この文中の「相手」に``117-0-0-3''という語義ID\footnote{ここに示したIDはSemEval-2日本語タスクにて用いられたもの．
上位二つの数字は見出し語のID，残り二つはそれぞれ
語義の大分類，中分類のIDを示す．
なお``117-0-0-3''の辞書定義文は「自分と対抗して物事を争う人」である．} が付与されていたとする．
このとき「取っ」という語が訓練データにおいて``117-0-0-3''の語義の
「相手」とのみ共起するのであれば，この訓練データからは《取っ, 117-0-0-3》
という二つ組一つを抽出する．



\subsubsection{手掛り付き事例抽出・分類（1回目）}

ここでは，まず手掛り付き事例抽出の手順を述べる前に
SemEval-2日本語タスクにおける対象語$t$の表記ゆれへの対処について述べる．
SemEval-2においては$t$について与えられる情報は訓練データ$L$を除くと
与えられた辞書に記述された見出し語$H_t$と語義の語釈文$D_t$のみであり，
$t$の表記に関する情報は充分には与えられない．
例えば，$t$の一つに「子供」があるが，これは他にも「子ども」「こども」
といった表記があるのに対し，$H_t$にない「子ども」という表記の情報は
与えられていない．
この問題に対処しない場合，ラベルなしデータから$t$の事例を
充分な数獲得できないだけでなく，
$t$の表記により語義の傾向が変わる場合も考えられ，
抽出する事例の語義に偏りが生まれる可能性も考えられる．
このため，UniDicの辞書を用いて，
以下の手順で$t$の取り得る表記（表層形）$E_t$の獲得を行った．
なお下記のStep 2では実際には$E_{t0}$からひらがなのみで構成される
表層形を除外して$V_t$を抽出している．
これはこのような語は語彙素の同定が困難であり
表層形獲得精度の低下を招くためである．
また$e_t \in E_t$は品詞細分類の情報も合わせて獲得し，
以後$t$の事例としてこの二つ組の情報が一致するものを獲得する．

\vspace{0.5\baselineskip}
\begin{center}
\begin{minipage}{0.85\hsize}
\underline{対象語表層形の獲得手順}
\begin{description}
\item[Step 1] $t$に対し$L$と$H_t$から獲得可能な全ての表層形$E_{t0}$を抽出する．
\item[Step 2] $E_{t0}$と対応する語彙素$V_t$をUniDicの辞書から抽出する．
\item[Step 3] $V_t$の全表層形$E_{t1}$をUniDicの辞書から抽出する．
\item[Step 4] $E_{t0}$および$E_{t1}$を合わせて対象語の表層形$E_t$として獲得する．
\end{description}
\end{minipage}
\end{center}
\vspace{0.5\baselineskip}

続いて，獲得した手掛り語$W_{ts}$および対象語の表層形$E_t$を用いて
ラベルなしデータ$U$より手掛り付き事例の抽出および1回目の分類を行う．
手順を以下に示す．

\vspace{0.5\baselineskip}
\begin{center}
\begin{minipage}{0.85\hsize}
\underline{手掛り付き事例抽出・\mbox{分類（1回目）の手順}}
\begin{description}
\item[Step 1] $U$から$e_t \in E_t$と一致する表層形の形態素を探索し，
発見したら$i_{t0}$とする．
\item[Step 2] $i_{t0}$の前後$n_w'$語以内に$w_{ts} \in W_{ts}$が共起する場合，
$i_{t0}$を手掛り付き事例$i_{ts1} \in I_{ts1}$として抽出する．
\end{description}
\end{minipage}
\end{center}
\vspace{0.5\baselineskip}

手掛り付き事例$I_{ts1}$とは対象語$t$の前後に手掛り語$w_{ts}$が共起する
事例を指し，上記手順より抽出される．
また，ここで抽出される$I_{ts1}$の$s$は$w_{ts}$の添え字の$s$であり，
$i_{t0}$に$s$を付与することで分類したとみなすことができる．
よって上記手順では，手掛り付き事例の抽出と分類を同時に行っていると解釈できる．
一方で，$i_{t0}$の集合$I_{t0}$と$\bigcup_{s}I_{ts1}$の差集合は
語義ラベルが付与されないということで，
語義判定不可に分類されたと考えることもできる．

上記手順を具体例を挙げ説明すると次のようになる．
$E_t$に「相手」，$W_{ts}$に《取っ, 117-0-0-3》が含まれているとし，$U$より
「ゼネコン三十一社を相手取って一人あたり三千三百万円の損害賠償を求めた」
という文に対し上記手順を適用するとする．
また，$n_w'=2$とする．
この場合，文中の「相手」が$i_{t0}$となり，$t$の前後2語以内に
「取っ」が共起するため，$s={}$``117-0-0-3''とし，
$i_{t0}$を手掛り付き事例$i_{ts1}$として抽出する．

さて，ここでパラメータ$n_w'$についてであるが，
これは$W_{ts}$獲得に用いるパラメータ$n_w$とは区別する．
さらに$n_w'$の値は上述の例と同様に``2''と固定する．
この2という数は\ref{sec:second}節で述べる教師あり学習による分類の素性として
対象語前後``2''語以内の形態素を用いることと対応するのだが，
その理由を列挙すると以下のようになる．

\begin{enumerate}
\item $W_{ts}$獲得に用いる訓練データ$L$は本タスクにおいて数少ない
信頼できるデータである．したがって，$L$からは出来る限り多くの特徴を抽出したい．
\item 一方，ラベルなしデータ$U$は多量に存在するが，これを自動的に分類した
データは当然ながら必ずしも信頼できるわけではない．
\item 反復回数一回でなるべく信頼性が高くかつ充分な数のデータの獲得が望ましい．
\item $n_w'$を教師あり学習の素性抽出の範囲と一致させた場合，
抽出した手掛り付き事例$i_{ts1}$の素性に必ず$w_{ts}$が含まれる．
このため，$i_{ts1}$を教師あり手法で再分類したとき高精度の分類が期待できる．
\item $w_{ts}$は$n_w$に関わらず式(\ref{eq1})を満たす．
つまりある程度の範囲までは$n_w$を大きくすることで
信頼性を維持しつつ多数の$w_{ts}$を獲得できる．
\item $w_{ts}$が充分な数あれば，一度の処理で多数の$U$を分類し
やはり充分な数のデータを$L$に加えることができる．
\end{enumerate}

上述の理由には従来法の欠点と提案法の利点の両方が含まれている．
その対応関係は，理由(4)は(2)への対処であり，
(5)は(4)の補足かつ(1)への対処であり，(6)は(5)を踏まえた(3)への対処となる．
またここに述べた理由は，\ref{sec:second}節にて述べる
手掛り付き事例分類2回目において，\ref{sec:intro}節で述べたパラメータ
$P$, $G$, $R$が削減可能となる理由にもなる．
詳しくは\ref{sec:second}節にて改めて述べる．

以上のアルゴリズムをもって，本手法の第一段階とする．
節題の通り，本処理は経験則に基づく部分が多い．
しかし，本処理は以降の処理においても必要とされる性質を備えている．
これらは\ref{sec:second}節および\ref{sec:third}節にて詳述する．


\subsection{Stage 2：教師あり学習手法による分類}
\label{sec:second}

分類第二段階では\ref{sec:first}節で抽出・分類した手掛り付き事例に対し，
オリジナルの訓練データから得られる一次分類器を用いて2回目の分類を行う．
そして，その結果得られる手掛り付き事例を用いて二次分類器を作成する．


\subsubsection{教師あり学習手法}

本手法で用いる教師あり学習手法は最適化にL-BFGS \cite{Liu89}を用いた
最大エントロピー法\cite{Nigam00a}とした．
この理由はSemEval-2日本語タスクフォーマルラン参加チームの一つの報告
\cite{Fujita10}に最大エントロピー法が有効というものがあったためである．
また学習の素性もFujitaらの報告を参考に次のように設定した．

\begin{itemize}
\item 範囲\\対象語前後2語以内
\item 1グラム素性\\
形態素の表層形\\
形態素の基本形\footnote{本研究では用言の基本形のカナ表記を「基本形」とする．
詳しくは\ref{sec:exp}節参照のこと．}
\item 2グラム・3グラム・対象語を含むスキップ2グラム素性\\
形態素の表層形\\
形態素の基本形\\
形態素の品詞と対象語との相対位置の組合せ\\
形態素の品詞細分類と対象語との相対位置の組合せ
\end{itemize}

具体的には，対象語「相手」の事例「相手に取って不足はない」
に対しては次の素性が獲得できる．
下記例中の``*''を含む素性はスキップ2グラムを示す．
また品詞に付与されている番号は対象語との相対位置である．

\vspace{0.5\baselineskip}
\begin{center}
\begin{minipage}{0.85\hsize}
\small
相手，に，取っ，トル，相手 に，に 取っ，相手 に 取っ，相手 * 取っ，
に トル，相手 に トル，相手 * トル，名詞$_0$ 助詞$_1$，助詞$_1$ 動詞$_2$，
名詞$_0$ 助詞$_1$ 動詞$_2$，名詞$_0$ * 動詞$_2$，
名詞-普通名詞-一般$_0$ 助詞-格助詞$_1$，助詞-格助詞$_1$ 動詞-一般$_2$，
名詞-普通名詞-一般$_0$ 助詞-格助詞$_1$ 動詞-一般$_2$，
名詞-普通名詞-一般$_0$ * 動詞-一般$_2$
\end{minipage}
\end{center}
\vspace{0.5\baselineskip}


\subsubsection{手掛り付き事例分類（2回目）}

前述の学習手法，素性，そして訓練データ$L$を用いて
一次分類器$C_1$を作成し，$C_1$を用いて\ref{sec:first}節で
抽出・分類した手掛り付き事例$I_{ts1}$を再分類する．
この分類2回目の結果が分類1回目の結果と一致する，つまり
$C_1$の$i_{ts1} \in I_{ts1}$の分類結果を$c_1(i_{ts1})$としたとき，
$c_1(i_{ts1})=s$である場合，$i_{ts1}$を$i_{ts2} \in I_{ts2}$とし$L$に加え，
これを用いて$C_1$同様に二次分類器$C_2$を作成する．

\ref{sec:first}節で述べたように$i_{ts1}$はその素性に
必ず手掛り語$w_{ts}$を含む．
そのため$c_1(i_{ts1})$は$s$と一致する可能性が高いが，実際に一致を確認し，
一致しなければ$C_2$作成においてこの手掛り付き事例は使わない．
この結果，$C_2$作成に用いられる$I_{ts2}$のラベル$s$は
信頼性の高いものとなる．

このシステムの重要な点は単に二種類の分類手法の結果が
合致するものを選択することではない．
そうだとすれば，分類1回目は一般的な教師あり学習手法を
用いても良いことになってしまう．
重要なのは分類2回目にて$C_1$が高い精度で分類可能な
事例$I_{ts1}$を分類1回目において選択していることにある．
つまり，{\bf 分類1回目が分類2回目の精度向上を明確に支援している}
ことがポイントである．
これにより$I_{ts2}$全てを$L$に加えても信頼性は保持され，
同時に充分な数のブートストラッピングが可能になる．
これは従来法において必要だった\ref{sec:intro}節に挙げたパラメータ，
ラベル付きデータ$L$に加える事例の個数$G$および手順の反復回数$R$を
決めることなしに適切な事例を$L$に加えられることも意味する．
なぜなら，$G$を定めずとも全事例を$L$に加えればよく，
$R$を定めずとも一度の実行で充分な数の事例の獲得が可能だからである．
またプールサイズ$P$については，Blumらの考察\cite{Blum98}
から考えるとブートストラッピングの反復において意味を持つ値であると思われる．
よって，反復回数1の本手法は単にプールを設定する必要がなく，
事例を全てのラベルなしデータ$U$から抽出することで処理できる．

また，$W_{ts}$は$n_w>2$であれば$L$の素性にない語
（つまり対象語から3語以上離れた位置にある語）を含むことから，
$I_{ts1}$の素性はやはり$L$の素性にない語を含む．
すると$I_{ts1}$が分類2回目の結果，$L$に追加されれば，
上述の通り分類2回目の信頼性は高いと言えるため，$C_2$は$C_1$と比べ
正しく分類できる$U$が増える可能性が高い．
したがって，本手法は$U$の$L$への追加における効率性が
高い手法であるとも言うことができる．

上述の性質はCo-trainingとの類似性を指摘することもできる．
Co-trainingは\ref{sec:intro}節で述べたように二つの素性集合のうち
一方のみに基づいて分類することで他方の素性について新しい規則の獲得が
期待できるのが特徴である．
本手法では，$W_{ts}$と$C_1$に用いる素性の二種類の素性を
実質的に両方考慮して手掛り付き事例を分類している．
しかし，$C_2$に用いる素性は後者の素性のみである．
つまり，一方は他方の一部ということになるが，
一方の素性で分類した結果を他方の素性を用いる分類器の訓練データに
加えるという点ではCo-trainingと共通する．
その一方で，提案手法は$L$に追加する$U$の分類に二種類，
つまり全ての素性を用いており，一方のみを使う場合と比較すると
分類結果の信頼性が高いという利点がある．
このような変則的なCo-trainingと通常のCo-trainingの間にどのような差異が
生まれるかは未調査だが，ここに述べた性質は性能の向上に結び付くと期待される．

本処理の直感的な意味としては，$C_1$にまず簡単な問題を解かせ，
その結果を$C_2$の学習に利用していると解釈できる．
一方で従来のブートストラッピングは，難易度がランダムな問題を複数解かせ，
その中でシステムが自信を持って答えられるものから学習すると考えられる．
しかし後者の場合，回答に対し「間違った自信」を持ってしまい，
結果として不適切な学習をしてしまう危険性があり得る．
前者の，つまり提案した手法は，確実ではないが$C_1$が解くのが簡単であろう
問題を選択しており，この危険性はいくらか低減していると推測される．
この推測が正しいとすれば，$C_1$に提示する問題を選択する
分類1回目の処理は重要な意味を持つことになる．
また，ここで提示するのは勿論ラベルなしの文章であるが，
見方を変えると「良い文章」をシステムに提示することで
より良い学習が可能になると考えられ，興味深い．



\subsection{Stage 3：アンサンブル学習による最終分類器作成}
\label{sec:third}

本節では\ref{sec:second}節で作成した二次分類器$C_2$をアンサンブルして
最終分類器$C_3$を作成する方法を述べる．
アンサンブルには\ref{sec:first}節の手掛り語抽出において
決定法を保留していた窓幅$n_w$を利用する．
すなわち，$n_w$をパラメータとする二次分類器を$C_2(n_w)$とし，
$n_w$を変化させた$C_2(n_w)$を複数組合せ$C_3$とする．
組合せの方法は各最大エントロピー分類器が出力する
各ラベルの推定確率の中で最高値を出力した分類器の判定を採用する方式とする．
つまり入力を$\mathbf{x}$，$C_2(n_w)$が$\mathbf{x}$に対し出力する
語義$s$である推定確率を$p(s|\mathbf{x},n_w)$とすると，
\begin{equation}
s_*(\mathbf{x})=\argmax_{s} \left[ \max_{n_w}p(s|\mathbf{x},n_w) \right]
\label{eq2}
\end{equation}
より求まる$s_*(\mathbf{x})$を$C_3$の出力とする．

式(\ref{eq2})の方式で良い結果が得られる根拠は
手掛り語$W_{ts}$の条件の一つである式(\ref{eq1})にある．
式(\ref{eq1})の制約の下で$n_w$の値を大きくしたとき，
得られる$W_{ts}$に以下の二つの変化が見られる．

\begin{itemize}
\item $n_w$変化前になくかつ$n_w$変化後に式(\ref{eq1})を満たす語が追加される．
\item $n_w$変化前にはあるが$n_w$変化後に式(\ref{eq1})を満たさなくなる語が削除される．
\end{itemize}

ここで重要なのは後者の性質である．
式(\ref{eq1})の性質上，後者の変化より$W_{ts}$から削除された語は
$n_w$をどんなに大きくしても再度$W_{ts}$に追加されることは絶対にない．
$n_w$変化後に削除される語は必ずしも重要度が高い語とも低い語とも言えないが，
少なくとも一度は$W_{ts}$の条件を満たすため重要度が高い語を含む可能性は高い．
よって，$n_w$の変化によって変わる各$W_{ts}$の集合には他の集合にはない
重要度の高い$W_{ts}$が含まれている可能性が少なからずあるということになる．
したがって，$n_w$の差異により各分類器に長所・短所が生まれ，
アンサンブル学習の効果が生まれやすいということができる．
逆に，$C_2$をアンサンブルしない場合，
$n_w$の差異により性能に大きく差がつくと考えられ，
$n_w$をパラメータとした調整は難しいと考えられる．

また$n_w$を増やせば，それだけ対象語から離れた位置にある語を特徴とすることに
なるため，少しずつ$W_{ts}$の信頼性が落ちていくものと考えられるが，
これに伴い任意の$s$に対し$C_2(n_w)$の$s$の推定確率
$p(s|\mathbf{x},n_w)$も落ちていくと予想される．
すると，$C_3$の出力を式(\ref{eq2})を満たす$s_*(x)$としたが，
$n_w$の増大に従い$C_2(n_w)$の判定が採用される確率も減少していくと考えられる．
よって，$n_w$の増大は$W_{ts}$の信頼性の減少を意味するが，
同時に$C_2(n_w)$の判定の採用確率も減ぜられる．
このため本手法は$n_w$の増大に対し頑健な
アンサンブル手法であるとも言うことができる．

本手法はMihalceaのSmoothed Co-training \cite{Mihalcea04a}
およびWangらTrajectory Basedの手法\cite{Wang04}と類似性を持つ．
まずWangらは文脈の大きさを変えながら複数のNaive Bayes分類器を
作成しているが，提案手法の処理はこれとよく似ている．
Wangらの手法は文脈の大きさというパラメータの影響の差による性能差が
小さくなることで性能が上がると見られるが，本手法でも同様の効果が期待できる．
またMihalceaはCo-trainingの反復過程にて分類器の多数決を適用した結果，
反復回数の差による性能差が小さくなりかつ全体的な性能も向上したと報告したが，
本手法における分類器の組合せにおいても同様の効果が期待できる．

なお，分類器の組合せのもう一つの単純な方式として
推定確率を重みとした重み付き多数決方式，つまり
\begin{equation}
s_*(x)=\argmax_{s} \left[ \sum_{n_w}p(s|\mathbf{x},n_w) \right]
\label{eq3}
\end{equation}
が考えられる．ここで記号の意味は式(\ref{eq2})と同じである．
しかし，式(\ref{eq3})の方式は事前実験の結果，
式(\ref{eq2})の方式ほどは良くないことがわかった．
これは，$n_w$の増大に伴い$C_2(n_w)$の推定確率が低くなることに変わりはないが，
式(\ref{eq2})と比べ$n_w$の大きな$C_2(n_w)$の判定が
より重めに考慮されていることが原因と思われる．

最後に本手法唯一のパラメータである$n_w$の変化の範囲について述べる．
一つの方法としては範囲を設けない，つまり任意の$n_w$を許すことが考えられるが，
当然ながら$n_w$を増やすことで計算時間が増加する．
また，$n_w$の増大に伴う分類器の信頼性の減少に対し
ある程度は頑健であるとはいえ，限度の存在があり得る．
このため$n_w$の変化の範囲には何らかの閾値を定めるのが妥当と考えられる．
\ref{sec:exp}節で述べる実験ではパラメータ$n_{\max}$を定め，
$1 \leq n_w \leq n_{\max}$の範囲で$n_w$を1刻みで変化させるとし，$n_{\max}$の
変化により語義曖昧性解消の性能がどのように変化していくか見ていく．


\subsection{まとめ}
\label{sec:summary}

提案手法を一つのアルゴリズムとして表現すると次のようになる．

\vspace{0.5\baselineskip}
\begin{center}
\begin{minipage}{0.85\hsize}
\begin{description}
\item[Step 0] $n_w$を初期値($=1$)に設定する．
\item[Step 1] 訓練データ$L$中の語義ラベル$s$が付与された対象語を$T_s$とする．
\item[Step 2] $t_s \in T_s$前後$n_w$語以内の式(\ref{eq1})を満たす
内容語の表層形を手掛り語$W_{ts}$として獲得する．
\item[Step 3] ラベルなしデータ$U$から対象語$t$に対する事例$I_{t0}$を抽出する．
\item[Step 4] $i_{t0} \in I_{t0}$の前後$n_w'=2$以内に$w_{ts} \in W_{ts}$
が出現するとき，$i_{t0}$を手掛り付き事例$i_{ts1} \in I_{ts1}$として抽出する．
\item[Step 5] $L$を用いて一次分類器$C_1$を作成し
$i_{ts1}$を分類した結果を$c_1(i_{ts1})$とする．
\item[Step 6] $c_1(i_{ts1})=s$であるとき，$i_{ts1}$を
$i_{ts2} \in I_{ts2}$とする．
\item[Step 7] $L$に$I_{ts2}$を加え二次分類器$C_2$を作成する．
\item[Step 8] $n_w$を$1 \leq n_w \leq n_{\max}$の範囲で変化させ，Step 1から7まで繰り返す．
\item[Step 9] Step 8で得られた$C_2$をアンサンブルして最終分類器$C_3$とする．
\end{description}
\end{minipage}
\end{center}
\vspace{0.5\baselineskip}

まず着目すべきは本手法はStep 8に示した$n_{\max}$以外に
パラメータが存在しないことである．
そして\ref{sec:exp}節で示すようにこのパラメータの設定は比較的容易である．

次に留意すべきは\ref{sec:intro}節で述べた$P$, $G$, $I$といった
パラメータがないにも関わらず，
ブートストラッピングの効果が充分に見込めるという点である．
このメカニズムは，上記Step 2に示した手掛り語$W_{ts}$の条件，
Step 4の$I_{ts1}$の抽出の条件，Step 6の$I_{ts2}$抽出の条件，さらにStep 8, 9が
巧妙に作用しあっていることに基づいている．

最後に注意すべきは，本手法はStep 0から9までの1度の実行だけで，
充分なブートストラッピングが可能であり，2回以上の反復を必要としない点である．
しかし，Step 4の$I_{ts1}$の抽出は必然的に再現率を犠牲にするため，
本手法1回の実行で完全な学習ができる訳ではない．
本手法の反復による更なる精度の向上は今後の課題である．



\end{document}
