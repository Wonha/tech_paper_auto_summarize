\section{はじめに}


本論文では，SENSEVAL2 の日本語翻訳タスクに対して
帰納論理プログラミング（Inductive Logic Programing，以下 ILP と略す）を適用する．
背景知識として分類語彙表を利用することで，正解率 54.0\,\% を達成した．
この値は，訓練データを新たに作成しない翻訳タスク参加の他システムと比較して優れている．

SENSEVAL2 の日本語翻訳タスクは，Translation Memory（以下 TM と略す）と呼ばれる
日英対訳対が与えられ，テスト文中の該当単語を英訳する際に利用できる TM の例文番号を返す
タスクである\footnote{厳密には，英訳自体を解答としてもよいが，
ここではこの解答形式は考慮しない．}\cite{sen2}．
これは英訳を語義と考えた場合の多義語の曖昧性解消問題となっており，分類問題の一種である．
このため従来から活発に研究されている帰納学習手法を用いて解決可能である．
おそらく大規模かつ高品質な訓練データを用いたシステムが，
コンテストで優秀な成績を納めるはずである．

しかし翻訳タスクでは大規模かつ高品質な訓練データを用意するコストが高い．
TM は1つの単語に対して平均して 21.6 例文がある．
今仮にある単語 A の例文として\( id_1 \) から \( id_{20} \)までの20例文が 
TM に記載されているとする．
新たに訓練データを作成する場合，単語 A を含む新たな文を持ってきて，
\( id_1 \) から \( id_{20} \) のどれか 1 つのラベルをその事例に与える必要がある．
〇か×かの二者択一は比較的容易であるが，20個のラベルの中から
最も適切な1つを選ぶのは非常に負荷のかかる作業である．
この理由のために，実際のコンテストにおいて，
大規模かつ高品質な訓練データを用意する方法をとったシステムは 1 つ（ Ibaraki ）だけであった．
ここでは訓練データを新たに作成せずに，日本語翻訳タスクを解決することを目標とする．
訓練データを新たに作成しないとしても，TM の例文は訓練データとして扱える．
ただし TM の例文を訓練データと見た場合，その量は少量と言わざるをえない．
つまり問題は，少量の訓練データからどのようにして精度の高い分類規則を獲得するかである．
そのための戦略として ILP を用いる．

少量の訓練データからどのようして分類規則を学習したらよいかは，
機械学習における 1 つの重要な課題である．
その解決方法として背景知識の利用が提案されている\cite{ipsj-kaisetu}．
背景知識とは，訓練データには明示されない問題固有の知識であり，
広く捉えれば，人間の持つ常識的知識と考えて良い．
一種の知識データベースである．問題はその背景知識を，
どのように学習手法に取り入れてゆくかである．その解決のために提案されているのが ILP である．
ILP は訓練データを述語論理の形式で表し，そこから分類規則に相当する規則
（述語論理の形式では節に対応）を導出する．
知識データベースは述語論理の形式によって自然に表現できるので，
背景知識の利用の観点からは ILP を用いた学習戦略が優れている\cite{furukawa}．
更に ILP の背景知識では，複雑なグラフ構造を持ったものも表現できるので，
近年，CMU の機械学習チームは Web ページの文書分類に ILP を利用している\cite{webkb}．
更にいくつかの自然言語処理への応用も知られている\cite{cohen}\cite{califf}\cite{shimazu}．

本論文では，ILP の処理系として Muggleton による Progol を利用する\cite{muggen2}．
Progol によって多義語の曖昧性解消を行う．そして背景知識としては分類語彙表\cite{bunrui-tab}を利用する．
以下2章で多義語の曖昧性解消を ILP で行う方法を示す．
3章では分類語彙表をどのように背景知識として組み込むかを説明し，
4章で実験，5章で考察を述べ，最後にまとめる．


