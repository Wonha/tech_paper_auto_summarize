\section{実験}


本論文では ILP の実装システムとして Muggleton による  Progol\cite{muggen2} を利用した．
Progol への入力形式は，Prolog 形式の述語や節であり，本論文で説明に用いた形式で行える．
ILP の実装システムは他にも存在するが，Progol が最もよく利用される代表的なシステムである．

まず，TM の形態素解析結果から素性（\verb|e1|，\verb|e2|，\verb|e3|，\verb|e4|）を抽出する．
また例文番号を分類先のクラスとする．
例文番号，クラス，素性の情報を節に変換し，Progol の入力ファイルを作成する．入力ファイルを 
Progol に読み込ませて，規則を生成した．
テストは翻訳タスクのコンテストで用いられた全 40 単語（各単語 30問，計 1,200問）が対象である．
それらに対して，Progol により得られた規則を使い，多義語の曖昧性解消のテストを行った（実験1）．
次に，TM の例文の他に背景知識として分類語彙表を用いて，Progol により規則を生成した．
得られた規則を使い，40 単語に対してテストを行った（実験2）．
実験1と実験2の結果を\mbox{表\ref{result1}}に示す．
\mbox{表\ref{result1}}の TM の列は実験 1 の結果を示し，
TM+背景知識 の列は実験 2 の結果を示している．

\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{背景知識の効果}\label{result1}
    \begin{tabular}{|c|c|c||c|c|c|} \hline
　見出し　   & 　　TM　　 &  TM+背景知識   & 　　↓　　 & 　　↓　　  & 　　↓　　　 \\ \hline
    ataeru &  0.167   &    0.167   &      kiroku &  0.267   &    0.267  \\
      baai &  0.033   &    0.033   &       koeru &  0.967   &    0.867  \\
   chikaku &  0.333   &    0.500   &     kokunai &  1.000   &    1.000  \\
   chushin &  0.367   &    0.367   &      kotoba &  0.700   &    0.933  \\
      deru &  0.333   &    0.333   &         mae &  0.167   &    0.000  \\
     egaku &  0.333   &    0.333   &      mamoru &  0.033   &    0.033  \\
    hakaru &  0.600   &    0.567   &       matsu &  0.867   &    0.867  \\
      hana &  0.667   &    0.700   &      miseru &  0.733   &    0.933  \\
    hantai &  0.800   &    0.933   &    mitomeru &  0.233   &    0.233  \\
       ima &  0.067   &    0.867   &      mondai &  0.533   &    0.533  \\
       imi &  0.400   &    0.567   &    motomeru &  0.867   &    0.867  \\
     ippan &  0.333   &    0.533   &       motsu &  0.333   &    0.867  \\
     ippou &  0.633   &    0.533   &        mune &  0.233   &    0.267  \\
        iu &  0.033   &    0.033   &        noru &  0.300   &    0.267  \\
     jidai &  0.700   &    0.733   &      shimin &  0.867   &    0.967  \\
    jigyou &  0.500   &    0.500   &      sugata &  0.200   &    0.133  \\
    kaku\_n &  0.800  &    0.733   &      tsukau &  0.700   &    0.667  \\
    kaku\_v &  0.967  &    0.967   &     tsukuru &  0.633   &    0.367  \\
       kau &  0.467   &    0.833   &    tsutaeru &  0.400   &    0.367  \\
      kiku &  0.500   &    0.500   &       ukeru &  0.400   &    0.433  \\ \hline
   ↓       &   ↓    &     ↓     &   平均       &  0.487   &    0.540  \\  \hline
    \end{tabular}
  \end{center}
\end{table}

平均の正解率は TM のみは 48.7\,\% であり，TM+背景知識 では 54.0\,\% であった．
分類語彙表を背景知識として用いた効果が確認できる．
またこの 54.0\,\% という値は，付加的な訓練データを用いない
翻訳タスクの他のシステムの正解率と比較しても，優秀な値と言える．

次に確率統計的な手法の1つである決定リストと比較してみる．
論文\cite{shinnou-sen2} では翻訳タスクの正解から語義（例文番号）をグループ化して，
TM の例文番号をグループ化することで，正解率が向上することを述べている．
そのため翻訳タスクに対する学習手法を比較する場合，TM の例文のグループ化を揃える
必要がある．そこで，ここでは論文\cite{shinnou-sen2}と同じ手法を用いて，
正解データから例文をクラスタリングし，同一の訓練データを用いることにした．
確率統計的な学習手法としては，決定リストを用いた（実験3）．
実験の結果を\mbox{表\ref{result2}} に示す．

\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{決定リストとの比較}\label{result2}
    \begin{tabular}{|c|c|c||c|c|c|} \hline
見出し　   &  決定リスト & 　ILP　  & 　↓　　 & 　　↓　　 & 　↓　　 \\ \hline
    ataeru &  0.333   &  0.867    &      kiroku & 0.833    &  0.933    \\         
      baai &  0.367   &  0.933    &       koeru & 0.633    &  0.600    \\         
   chikaku &  0.367   &  0.467    &     kokunai & 1.000    &  0.633    \\         
   chushin &  0.200   &  0.700    &      kotoba & 0.967    &  0.967    \\         
      deru &  0.367   &  0.233    &         mae & 0.267    &  0.200    \\         
     egaku &  0.567   &  0.267    &      mamoru & 0.367    &  0.833    \\         
    hakaru &  0.733   &  0.900    &       matsu & 0.867    &  0.767    \\         
      hana &  0.800   &  0.933    &      miseru & 0.933    &  0.733    \\         
    hantai &  0.900   &  0.967    &    mitomeru & 0.200    &  0.300    \\         
       ima &  0.367   &  0.933    &      mondai & 0.533    &  0.467    \\         
       imi &  0.767   &  1.000    &    motomeru & 0.633    &  0.000    \\         
     ippan &  0.333   &  0.567    &       motsu & 0.900    &  0.833    \\         
     ippou &  0.500   &  0.767    &        mune & 0.267    &  0.300    \\         
        iu &  0.733   &  0.900    &        noru & 0.300    &  0.433    \\         
     jidai &  0.567   &  0.233    &      shimin & 0.567    &  0.433    \\         
    jigyou &  0.667   &  0.567    &      sugata & 0.367    &  0.233    \\         
    kaku\_n & 0.300   &  0.800    &      tsukau & 0.533    &  0.967    \\         
    kaku\_v & 0.967   &  0.967    &     tsukuru & 0.033    &  0.233    \\         
       kau &  0.733   &  0.533    &    tsutaeru & 0.367    &  0.200    \\         
      kiku &  0.467   &  0.500    &       ukeru & 0.333    &  0.100    \\ \hline  
   ↓      &  ↓   &    ↓     &  平均       &  0.548   &  0.605     \\  \hline
    \end{tabular}
  \end{center}
\end{table}

平均の正解率は決定リストでは 54.8\,\% であったが，本手法では 60.5\,\% の結果を得た．
つまり TM だけを用いた学習システムとしては，決定リストよりも ILP の方が優れていた．

ただし，いくつかの単語については，実験3での ILP の正解率が，実験1での ILP の正解率や，
実験3での決定リストの正解率よりも，極端に低くなっている．
例えば，mokuteki，jidai，ukeru，baai，egaku，ima などである．
これらの正解率が極端に下がっている理由は，学習結果として生成された節の順序の問題である．
これは，default 規則にあたるものを適切に設定できなかったことを意味している．
これについては次節の考察に記述する．


