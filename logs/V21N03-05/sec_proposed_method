本章では，まず，解析対象である絵本データベースの紹介を行う（[REF_sec:ehon-db]節）．
次に，新聞などの一般向けテキストと絵本のテキストを比較し，違いを調査する（[REF_sec:mojisyu]節）．
また，評価，実験用に形態素情報を付与した絵本のラベルありデータ（フルアノテーションデータ）を紹介する（[REF_sec:full-ano]節）．
本稿では構築中の絵本データベースを解析対象とする[CITE]．
絵本データベースは，発達心理学における研究や，子供の興味や発達に応じた絵本リコメンデーションを目的として構築されている．
含まれる絵本は，2010年度の紀伊国屋書店グループの売上冊数が上位のファーストブック（以下，\first{}）と絵本（以下，\ehon）計1,010冊，および，福音館書店の月刊誌（以下，\kodomo）190冊，合計1,200冊である．
これらの選定理由は，前者は多くの子供に読まれていると考えられること，後者は対象年齢が比較的はっきりしていることである．
後者の対象年齢は0・1・2歳向け（以下，\kod{012}），年少（3歳児）向け（以下，\kod{3}），年中（4歳児）向け（以下，\kod{4}），年長（5歳児）向け（以下，\kod{5}）とわかれている．
本稿では，これらをまとめて絵本と呼ぶこととする．
なお，\kodomo以外で対象年齢が記載されていた絵本は，463冊(45.8%)にとどまり，その記載方法も「3歳から小学校初級むき」「乳児から」「4才から」のように多様で，\kodomoのように1歳単位で対象年齢が設定されている絵本は少ない．
本稿では，絵本の本文のテキストを解析対象とする．
本文のテキストは人手で入力されている．
また文や文節の途中での改行など元のページのレイアウトも忠実に再現されている（例\refs{ex-org}）．
なお，絵本データベースの1,200冊のサイズは表[REF_tb:size]の通りである．
\exもういつはるがきて、なつがきたのか、いつが
あきで、いつがふゆなのか、わかりません。
（バージニア・リー・バートン，石井桃子・訳「ちいさいおうち」p. 24（1954，岩波書店））
絵本のテキストの特徴を調べるため，絵本と一般的なコーパスにおける文字種の割合を比較する．
表[REF_tb:mojisyu]に，絵本1,200冊（表[REF_tb:size]）における文字種と，現代日本語書き言葉均衡コーパス（以下，\bccwj），京都大学テキストコーパス（以下，京大コーパス），および，基本語データベース[CITE]（以下，\lxd）の定義文，例文に出現する文字種の数と割合を示す．
表[REF_tb:mojisyu]から，他のコーパスに比べ，絵本の場合，ひらがなと空白が占める割合が圧倒的に高いことがわかる．
また逆に，漢字が占める割合は非常に低い．
表[REF_tb:mojisyu]には，参考として，一文に含まれる平均文字数，および，平均形態素数も記載した．
但し，絵本の場合は，一行に含まれる平均文字数を記載しており，必ずしも文単位ではない．
また，平均形態素数について，絵本は未知であり，\bccwjは品詞体系が異なるため記載していない．
精度評価のために，絵本の一部に正解の形態素区切り，IPA品詞，読み，できるだけ漢字表記にした原形を付与したフルアノテーションデータ（ラベルありデータ）を作成した．
ただし，活用型と活用形は付与していない．
付与自体が難しいことと，作業量が増えるためにコストと時間がかかること，これらの情報を今後利用する予定がないことが理由である．
絵本に出現した文\refs{eva-org}に対するフルアノテーションデータを\refs{ehon-full}に示す．
ただし\refs{ehon-full}では，形態素区切りは\jpn[,]{}で示し，形態素は\jpn[出現形/品詞/読み/原形]{}の形で示し，漢字表記にした原形には\ul{下線}を引いた（以降の例でも同様）．
\exめには、いちごのあかいみをいれました。
（舟崎靖子「もりのおかしやさん」p. 11（1979，偕成社））
\exめ/名詞-一般/メ/\ul{目},に/助詞-格助詞-一般/ニ/に,は/助詞-係助詞/ハ/は,、/記号-読点/、/、,いちご/名詞-一般/イチゴ/\ul{苺},の/助詞-連体化/ノ/の, /記号-空白/ / ,あかい/形容詞-自立/アカイ/\ul{赤い}, /記号-空白/ / ,み/名詞-一般/ミ/\ul{実},を/助詞-格助詞-一般/ヲ/を, /記号-空白/ / ,いれ/動詞-自立/イレ/\ul{入れる},まし/助動詞/マシ/ます,た/助動詞/タ/た,。
/記号-句点/。
/。
アノテーションは，言語学者や研究者ではない一般の作業者によって行ったが，特に活用語に対するアノテーションは難しく，既存のラベルありデータを参照しながら作業を行った．
また，作業者による不一致や判断のゆれをなくすため，一定の作業の後には同じ出現形の形態素に異なる品詞や原形が振られたものをリストアップし，統一的に確認，修正を行う作業を繰り返した．
なお，実際の作業では，アノテーションしたデータを順次学習データに追加することで，解析精度自体を高めながら作業を進めた（[REF_sec:exp-add-ehon]章参照）．
フルアノテーションを行う対象データは2通りの方法で選んだ．
まず，対象年齢がはっきりしている\kodomo 190冊を対象とした．
また，それ以外の\first, \ehonの中から，絵本をランダムに選び，さらにランダムに1ページずつ選んで対象とした（以下，\random）．
サイズは表[REF_tb:test-size]の通りである．
フルアノテーションデータは，[REF_sec:exp-adult]章の教師なし分野適応実験の評価用データとして利用するほか，[REF_sec:exp-add-ehon]章の教師あり分野適応実験の学習，評価用データとして利用する．
本稿では，既存の辞書やラベルありデータを，対象分野である絵本の特徴にあわせて自動的に変換する手法を提案する．
学習器は学習データと独立に選ぶことができるが，本稿では，京都テキスト解析ツールキット\kytea [CITE]の学習機能を利用する．
\kyteaでは，点予測を採用しており，分類器の素性として，周囲の単語境界や品詞等の推定値を利用せずに，周囲の文字列の情報のみを利用する．
そのため，柔軟に言語資源を利用することができ，分野適応が容易だという特徴がある[CITE]．
\kyteaのモデル学習時には，フルアノテーションデータ，部分アノテーションデータ，辞書などの言語資源が利用できる．
これらの言語資源は，それぞれ複数利用することができる．
また，辞書と部分アノテーションデータはなくてもよい．
ここで，フルアノテーションデータとは，文全体に形態素情報が付与されたデータである（[REF_sec:full-ano]節，例\refs{ehon-full}）．
また，部分アノテーションデータとは，文の一部にだけ単語境界や形態素情報が付与されたデータである．
例えば，例\refs{ehon-part}のように，文\refs{eva-org}の\jpn[め]{}と\jpn[み]{}にだけ形態素情報をアノテーションしたデータを，部分アノテーションデータとして利用することができる．
誤りやすい語や分野特有の語にだけ集中的にアノテーションを付与して利用できるため，能動学習や分野適応に有効である．
\exめ/名詞-一般/メ/\ul{目},には、いちごのあかい,み/名詞-一般/ミ/\ul{実},をいれました。
なお，\kyteaの配布版モデルでは，単語分割とUniDicの品詞大分類，読みの付与を行っているが，他の種類の品詞や情報を推定するモデルの構築も可能である．
本稿では，既存言語資源との整合性を考慮し，品詞はIPA品詞体系に準拠した．
さらに，元の漢字表記の推定も同時に行う．
つまり，単語分割，IPA品詞体系の品詞，読み，漢字表記による原形推定を出力とするモデルを構築する．
本稿では，フルアノテーションデータとして，コーパス\hinoki [CITE]を用いる．
\hinokiには，\lxdの定義文，例文，京大コーパスの全文が含まれている．
さらに教師あり分野適応の実験（[REF_sec:exp-add-ehon]章）では，絵本のフルアノテーションデータも利用する．
辞書には，\naistj（以下，\ntj），\lxd，および，日本語語彙大系[CITE]の固有名詞，および，動植物名を利用する．
但し，\lxdと日本語語彙大系は，本来IPA品詞体系ではないため，自動的に品詞を変換した．
本章では，絵本を形態素解析するときに起こる精度低下の原因を調査する．
[REF_sec:mojisyu]節では，一般的なテキストと比べて，絵本のテキストでは，空白，ひらがなが圧倒的に多く，漢字が非常に少ないことを示した．
これらの違いのうち，直感的には，ひらがなによる曖昧性の増加が精度低下の主要因であり，空白は解析の手がかりとなるように感じられる．
しかしこれまで，この直感が正しいかどうか，また，実際にどの程度精度への影響があるのかを調査した研究はない．
そこで本章では，ひらがなと空白の形態素解析への影響を調査する．
調査用の評価データとして，絵本の\kodomoのフルアノテーションデータをいくつかのルールに沿って自動的に変換したデータを作成する．
つまり，絵本に出現した文\refs{eva-org}（[REF_sec:full-ano]節）から空白を削除したもの（文\refs{eva-del}），空白を読点に変換したもの（文\refs{eva-punc}），ひらがなをできるだけ漢字に変換したもの（文\refs{eva-han}），漢字に変換し，かつ，空白を削除したもの（文\refs{eva-handel}），漢字に変換し，かつ，空白を読点に変換したもの（文\refs{eva-hanpunc}）を作成した．
\exめには、いちごのあかいみをいれました。
\exめには、いちごの、あかい、みを、いれました。
\ex目には、苺の赤い実を入れました。
\ex目には、苺の赤い実を入れました。
\ex目には、苺の、赤い、実を、入れました。
調査のため，\hinokiコーパスと\naistjなどの辞書（[REF_sec:morph-kytea]章）をそのまま学習に利用したモデル（以下，\kytea（\Def））を構築する．
これは，一般的な形態素解析モデルと同じような学習条件に相当する．
また，表[REF_tb:morph-ex]（[REF_sec:introduction]章）で利用した既存の形態素解析モデルの中で最も誤りの少なかった\mecabも利用する．
表[REF_tb:res-bunseki]に，評価用データ（文\refs{eva-org}，および，文\refs{eva-del}から文\refs{eva-hanpunc}）のそれぞれに対し，形態素解析を実行し，形態素区切りと品詞一致精度を調べた結果を示す．
表[REF_tb:res-bunseki]の\pos\refs{eva-org}の列が，絵本のテキストをそのまま解析した場合の精度であり，\kytea（\Def）では63.0%，\mecabでは83.2%だった．
\mecabはひらがなのままの評価データの場合でも，ひらがなを考慮しない一般的な学習条件で学習した\kytea（\Def）よりも精度が高い．
しかし，新聞である京大コーパスを対象とした場合98%以上の精度が報告されているのに比べると，はるかに低い精度である．
ここで，空白の影響を分析する．
\kytea（\Def）では，空白を削除すると精度が向上する．
また，空白を読点に変更すると精度はさらに向上する．
これは，学習データに空白が出現しないため，学習できていないためだと考えられる．
空白をただ削除するよりも，読点に変更した方が精度が高くなることから，空白の働きをうまく学習することができれば，区切りの判別の手がかりとして有効に働くだろうことが予想できる．
実際，\mecabの場合，空白は区切りの判別のための手がかりとして有効に利用されているようであり，空白を削除するとむしろ精度は低下する．
また，空白を読点に変更した場合と空白のままの場合の精度は同程度であり，空白が読点の代わりを果たしていることが伺える．
特に，\refs{err-del}のように，擬音語や擬態語が連なる場合，空白を削除すると，解析が非常に困難になっており，空白の有無が形態素の判別に有効な手がかりであることがわかる．
\ex「こちょこちょこちょこちょ
{（豊田一彦「こちょこちょももんちゃん」p. 24（2010，童心社））}
COR:「,\ul{こちょ, ,こちょ, ,こちょ, ,こちょ}
RES:「,\ul{こ,ちょこ,ちょこちょこ,ちょ}
（ただし，COR:は正解，RES:は空白を削除した場合の結果）
次に，ひらがなが多いことによる影響を分析する．
評価データ中のひらがなを漢字に変換した場合，\kytea（\Def）でも\mecabでも，ひらがなのままの評価データより高い精度が得られる．
空白を読点に変換した場合の精度（表[REF_tb:res-bunseki]の\pos\refs{eva-punc}と\pos\refs{eva-hanpunc}）で比較すると，\kytea（\Def）では[MATH]%，\mecabでは[MATH]%精度が向上しており，漢字は大きな手がかりとなっていることがわかる．
つまり，一般的なテキストとの大きな違いのうち，ひらがなによる曖昧性の増大が解析精度の低下の主な要因だといえる．
なお，元データのままだと解析に失敗するが，漢字に変換すると正解する例には，\refs{err-org}などがあった．
\exみずをのみにきたうしさんに{（たちもとみちこ「おほしさま」p. 10（2006，教育画劇））}
COR:みず,を, ,のみ,に,き,た, ,うし,さん,に,
RES:みず,を, ,のみ,に,\ul{きた}, ,\ul{うしさん},に
RES2:水,を, ,飲み,に,\ul{来,た}, ,\ul{牛,さん},に
（ただし，COR:は正解，RES:は結果，RES2:は漢字に変換した場合の結果）
本章では，絵本の特徴に合わせたラベルありデータと辞書の変換方法を提案する（[REF_sec:train-data]，[REF_sec:dic]節）．
また，ラベルありデータと辞書の変換と追加の必要性について議論する（[REF_sec:comp-kudo]節）．
[REF_sec:bunseki]章で示したように，絵本の解析では，空白の働きを学習することと，ひらがなが多い文でも解析できることが必要である．
そこで，既存のラベルありデータである\hinokiコーパスを3通りの方法で自動的に変換する．
例えば，文\refs{lxdex-org}は，\lxdでの見出し語\jpn[きしめん]{}に付与された例文である．
この文に，まず，句読点の直後を除く文節毎に空白を挿入する（文\refs{lxdex-sp}）．
また，すべての漢字をひらがなの読みに変換する（文\refs{lxdex-hira}）．
句読点の直後を除く文節毎に空白を挿入し，かつ，ひらがなに変換する（文\refs{lxdex-hirasp}）．
このように，元の文に対して3通りの変換を行い，ラベルありデータデータを作成する．
\ex寄せ鍋,に,きしめん,を,入れる,。
\ex寄せ鍋,に, ,きしめん,を, ,入れる,。
\exよせなべ,に,きしめん,を,いれる,。
\exよせなべ,に, ,きしめん,を, ,いれる,。
さらに，元の漢字表記の推定も同時に行うため，元の漢字表記による原形を利用する．
つまり，文\refs{lxdex-hira}や\refs{lxdex-hirasp}のようにひらがなに変換した場合でも，原形は漢字表記を利用する．
そのため，例えば\refs{lxdex-hira}は，実際には\refs{lxdex-hira-full}のような形で与えられる．
\exよせなべ/名詞-一般/ヨセナベ/\ul{寄せ鍋},に/助詞-格助詞-一般/ニ/に,きしめん/名詞-一般/キシメン/きしめん,を/助詞-格助詞-一般/ヲ/を,いれる/動詞-自立/イレル/\ul{入れる},。
/記号-句点/。
/。
[REF_sec:exp-adult]章では，ラベルありデータの変換方法毎の効果を検証するため，これらの組み合わせを変えて利用した場合の精度評価を行う．
なお，空白の挿入に利用した文節区切りや，ひらがなへの変換に利用した読みは，元々コーパスに付与されていたものであり，自動的に変換することができる．
本稿では\hinokiコーパスを利用したが，京大コーパスでも文節情報や読みは付与されているため，同様の変換ができる．
また\bccwjにも読みは付与されている．
文節情報は付与されていないが，形態素情報は付与されているため，助詞と自立語が連続する箇所に空白をいれるなどの簡単なルールによって，同様の自動的変換が可能である．
[REF_sec:morph-kytea]章で紹介した通り，辞書には\ntj，\lxd，日本語語彙大系の固有名詞，および，動植物名を利用しており，これらを絵本の特徴にあわせて変換する．
まず，\ntjと\lxdの漢字やカタカナのエントリをひらがなに変換したエントリも作成し，辞書に追加する．
固有名詞や動植物名は，カタカナで表記されることも多いため，カタカナ，ひらがなの両方に変換したエントリも作成し，辞書に追加する．
このとき，原形には漢字やカタカナの表記を用いる．
例えば，\jpn[伊予柑]{}の場合，元の見出し語から得られる辞書エントリは\refs{iyokan-org}となるが，ひらがなのエントリ\refs{iyokan-hira}とカタカナのエントリ\refs{iyokan-kata}も追加した．
しかし，人名の固有名詞だけは，カタカナはカタカナのまま，ひらがなはひらがなのまま原形とした．
これは，ひらがなで出てくる人名の漢字表記が何かは決められないためである．
最終的に利用した辞書サイズは，表[REF_tb:dic-size]の通りである．
\ex伊予柑/名詞-一般/イヨカン/伊予柑\exいよかん/名詞-一般/イヨカン/伊予柑\exイヨカン/名詞-一般/イヨカン/伊予柑
[CITE]は，Web上のひらがな交じり文に対する形態素解析手法の提案にあたり，次のように述べている．
ひらがな交じりの解析も，通常の日本語の文の解析であることには変わりがないため，以下のような一般的に用いられている既存手法で解析精度を向上させることが可能である．
1.ひらがな単語のユーザ辞書への追加
2.ひらがな交じり文を含む学習データを人手で作成し，再学習
1.は簡単な手法であるが，ひらがなは日本語の機能語に用いられているため，むやみにひらがな語を追加すると副作用により精度が低下する可能性がある．
2.の方法は学習データの作成が必要なためコストが高い．
これらの理由によって，[CITE]では，辞書への追加や学習データの追加は行われていない．
[CITE]の手法は，広い分野に対して安定的に比較的高い精度で解析を行える．
しかし，特定の分野における実用を考えた場合，対象分野においてより高い精度を得ることが重要である．
確かに，1.に関して，ひらがな語を多く追加することによる副作用の可能性は否定できないが，絵本の場合，いずれの語でもひらがなで記述される可能性があるため，すべてのエントリをひらがなにする必要がある．
また，2.に関しては，提案手法では自動的に学習データを作成するので問題ない．
本稿では，提案手法で変換・作成した辞書と学習データを学習に用いることで，絵本に対しては既存モデルより高い精度が得られることを示す（[REF_sec:exp-adult]章）．
ただし，本提案手法で得られる精度は，既存モデルよりは高いが，実用的にはまだ改良の必要がある．
そのため，さらなる精度向上のためには，能動学習や対象分野のラベルありデータの構築が必要となるが，その際も，ベースとなるモデルの精度がより高い方がより効率的である．
