本章では，前章で提案した手法により変換した既存言語資源だけを学習に利用する評価実験，つまり，教師なし分野適応の実験を行う．
前章で紹介した通り，ラベルありデータは3通りの変換により作成した．
これらと，変換前のラベルありデータを組み合わせて学習に用いた場合の精度評価を行った（表[REF_tb:res]）．
表[REF_tb:res]では，形態素区切り，および，品詞の細分類までが一致した精度を示している．
表[REF_tb:res]は，絵本に出現した文に対する解析精度であり，表[REF_tb:res-bunseki]の左端\pos{元データ\refs{eva-org}}の列に当たる．
比較のため，表[REF_tb:res]にも結果を再掲した．
既存言語資源をそのまま学習に利用した場合，精度は63.0%と非常に低いが，空白を追加したり，ひらがなに変換した学習データを利用することで，88.5%まで精度を向上できた．
つまり，新聞データなどの一般向けのテキストを学習データに利用する場合でも，絵本での出現傾向にあわせて変換することで，相当な精度向上が出来た．
ここで，空白を追加した学習データだけを利用する場合[B]より，空白を追加しない学習データも利用する[C]の方が精度が高かった．
これは，すべての絵本で全文節ごとに空白が入るわけではないので，両方を学習に利用した方が良かったのだと考えられる．
同様に，ひらがなに変換した学習データだけを利用するより，漢字のままの学習データも利用する方が若干精度が高かった．
これは，すべての絵本で漢字が全く出現しないわけではないためだと考えられる．
以降，最も高い精度を得られたラベルありデータ（表[REF_tb:res] [C]の``両方利用\refs{lxdex-org}〜\refs{lxdex-hirasp}''）を\bestHINOKI，得られたモデルを用いた解析器を\kytea (\bestHINOKI)と呼び，これをベースに，さらに改良を加えることを検討したい．
また，絵本によって，空白や漢字の含有率は非常に異なるため，これらの含有率によって学習に利用するデータを変更することも考えられる．
[REF_sec:exp-adult]章の実験では，ラベルありデータとして既存言語資源から得たコーパスだけを用いた．
しかし分野適応では，同じ分野のラベルありデータを追加すると精度が向上することはよく知られており，本章では，絵本自体のラベルありデータを学習に用いた実験を行う．
本章の目的は二つある．
一つは，提案手法によって既存言語資源から自動的に獲得したラベルありデータが，どの程度の絵本自体のフルアノテーションデータと同程度の効果があるかを調べることである．
もう一つは，絵本自体へアノテーションするときの効率的な方法を示すことである．
本節では，フルアノテーションデータ\kodomo（[REF_sec:full-ano]節）の各絵本をそれぞれ10分割し，それらを徐々に学習データに追加した場合の学習曲線を調べる．
ここで，[REF_sec:exp-adult]章で最も良い精度を得た学習データである\bestHINOKIと絵本を両方学習に利用する場合と，絵本だけを学習に利用する場合の両方の実験を行った．
また，評価は2通り行う．
つまり，学習データを追加した絵本と，(1)同じ絵本のテキストによる評価（\kodomoを利用），(2)違う絵本のテキストによる評価（\randomを利用），を行う．
本節での精度評価は，品詞まで一致した精度に加え，原形まで一致した精度評価も行っている．
本稿で構築している形態素解析モデルでは，出現形がひらがなでも，原形は出来る限り漢字表記を推定している（[REF_sec:train-data]節）．
ひらがなで出現した語に対し，漢字表記を推定することができれば，その後の解析に有用だからである．
例えば，\jpn[め]{}という語が\jpn[目]{}なのか\jpn[芽]{}なのか，\jpn[はな]{}という語が\jpn[鼻]{}なのか\jpn[花]{}なのか，などは，幼児の言語発達を調べるときにも区別する必要がある[CITE]．
これは，本来，語義曖昧性解消問題として取り組むべき課題かもしれないが，形態素解析時に同時に推定が可能なら利便性が高い．
そこで，本節では，形態素解析時の漢字の原形推定をどの程度の精度で行うことができるかも同時に調査した．
ここで，図[REF_fig:lc-self-POS], [REF_fig:lc-self-BS2]は，\kodomoの各絵本の1/10を評価データとし，それ以外を順次追加した場合の学習曲線を示している．
また，図[REF_fig:lc-rand-POS], [REF_fig:lc-rand-BS2]は，\randomを評価データとした場合の精度を示しており，\kodomoのすべてを学習データに追加した場合の精度も示している．
また，図[REF_fig:lc-self-POS], [REF_fig:lc-rand-POS]は，品詞一致の精度，図[REF_fig:lc-self-BS2], [REF_fig:lc-rand-BS2]は，原形まで一致した精度を示している．
ただし，学習データでは，コーパス\hinokiの漢字等による原形をそのまま原形として利用したため，学習データの原形に表記ゆれが存在する．
そこで，原形一致精度の評価時には，\jpn[仔牛]{}と\jpn[子牛]{}，\jpn[雄]{}と\jpn[オス]{}のように，表記ゆれだとみなせるものは正解に含めている．
また，\mecabは漢字表記による原形推定はしないため，ひらがなの原形も正解とした．
標準表記の決定，学習データの標準表記への変換は今後の課題としたい．
提案手法で作成した\bestHINOKIの効果を調べる．
図[REF_fig:lc-self-POS]〜[REF_fig:lc-rand-BS2]から，すべての場合で，\bestHINOKIに絵本データを追加した方が，絵本データだけの場合や，\bestHINOKIだけの場合より精度が向上しており，絵本とは全く異なる一般向けのテキストであっても，\bestHINOKIを学習に利用する方が良いことがわかる．
特に，図[REF_fig:lc-rand-POS], [REF_fig:lc-rand-BS2]に示した通り，別の絵本(\random)に対する精度は，学習データに絵本だけを用いる場合より非常に高い．
\randomの場合，品詞一致でも，原形一致でも，絵本の学習データだけで\kytea (\bestHINOKI)と同等の精度を得るには，\kodomoのフルアノテーションデータ約11,000行，90,000形態素が必要である．
これは，\kodomoのフルアノテーションデータの8/10近くにあたる．
これだけのフルアノテーション作業には相当な時間とコストがかかっており，提案手法による自動的な変換による精度向上の効果は高い．
なお，\randomに対する精度は，すべての\kodomoを学習データに追加した場合で，形態素区切り98.3%，品詞完全一致91.1%，品詞大分類94.7%，原形一致89.0%だった．
これが，新しい絵本を解析する場合の精度にあたる．
本節では，同じ絵本を学習データとして追加した場合の効果を調べる．
図[REF_fig:lc-self-POS], [REF_fig:lc-self-BS2]から，同じ絵本の学習データは非常に有効であることがわかる．
\bestHINOKIを使わない場合でも，同じ絵本の10分の2を学習データとして用いただけで\kytea (\bestHINOKI)の精度より高い精度を得ることができる．
このように，同じ絵本のデータの追加のほうが効果が圧倒的に高いため，同じ分量のアノテーションを行うのであれば，少しずつでも，できるかぎり全ての絵本からアノテーションすることが望ましい．
同じ絵本のアノテーションが特に有効な理由には，同じ固有名詞（[REF_sec:errors], [REF_sec:add-proc]節参照）や，同じ表現が出現することがあげられるだろう．
絵本は，例えば，例\refs{ex-repeat}のように一部の語を変えて同じ表現が繰り返されることが多く，一部をアノテーションする効果が高い．
なお，\refs{ex-repeat}の絵本の場合，\jpn[なんてなく？]{}は11回出現している．
\exかえるは
\ul{なんてなく？}
にわとりは
\ul{なんてなく？}  （凹工房「どうぶつなんてなく？」p. 2--3（2008，ポプラ社））
本節では，絵本を学習データに追加した場合の，誤り内容の変化を調査する．
解析を誤った語を品詞毎に集計し，\pos{動詞}\pos{名詞-固有名詞}\pos{感動詞}について，それぞれ図[REF_fig:lc-self-err-VERB]と[REF_fig:lc-rand-err-VERB]，[REF_fig:lc-self-err-PROP]と[REF_fig:lc-rand-err-PROP]，[REF_fig:lc-self-err-KANDO]と[REF_fig:lc-rand-err-KANDO]に示した．
図[REF_fig:lc-self-err-VERB]〜[REF_fig:lc-rand-err-KANDO]では，誤りの絶対数と，全誤り数に占める対象品詞の割合をプロットしている．
誤りの絶対数はどの品詞でも減少しているが，全誤りに占める各品詞の割合を見ると，比較的学習しにくい品詞がわかる．
\pos{動詞}（図[REF_fig:lc-self-err-VERB], [REF_fig:lc-rand-err-VERB]）は\kodomoでも\randomでも相対的に上昇している．
\pos{固有名詞}（図[REF_fig:lc-self-err-PROP], [REF_fig:lc-rand-err-PROP]）の場合，\kodomoでは急激に割合が下がるが，\randomでは逆に相対的に上昇している．
\pos{固有名詞}は，絵本間で共通のものが少なく，しかも，ひらがな（\jpn[ぐり]{}，\jpn[ぐら]{}[MATH]，\jpn[もものこ]{}など）や，ひらがなカタカナ混じり（\jpn[ウサこ]{}，\jpn[ネコみ]{}[MATH]など）など，非常に解析が難しいものが多いからだと思われる．
対照的に，\pos{感動詞}（図[REF_fig:lc-self-err-KANDO], [REF_fig:lc-rand-err-KANDO]）は，\randomでも誤る割合が下がっている．
これは，異なる絵本でも共通の表現が多いためだと考えられる．
例えば，\random側で，\bestHINOKIだけでは正解しなかったが，絵本を追加していくことで正解するようになった感動詞には，\jpn[あっぷっぷ]{}，\jpn[ごくろうさま]{}，\jpn[ギャオー]{}などがあった．
