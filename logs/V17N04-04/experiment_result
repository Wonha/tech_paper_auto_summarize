
実験にはSemeval-2007 Shared task [CITE]の訓練データ部分を用いる．
このうちランダムに抜き出した[MATH]をテストデータとして用い，残りの[MATH]で訓練，開発を行う．
評価は役割に関するMicro F1平均とMacro F1平均[CITE]で行う．
役割句[MATH]の特徴には，既存研究によって有効と報告された素性[CITE]を用いた．
これらは，フレーム，フレーム想起単語，主辞，内容語，先頭／末尾単語，左右の兄弟ノードの主辞，句の統語範疇，句の位置，態，統語パス（有効／無向／部分），支配範疇，主辞のSupersense，想起単語と主辞の組，想起単語と統語範疇の組，態と句の位置の組である．
単語を用いた素性には，表層形の他に，品詞や語幹を用いたものも使用している．
構文解析には[CITE]のreranking parserを用い，Supersense素性には，[CITE]のSuper Sense Taggerの出力を用いる．
ベースライン分類器では役割の汎化を用いず，元の意味役割のみを利用した分類を行い，結果[MATH]のMicro F1値を得た．
表[REF_integration]に，それぞれの汎化指標を用いた場合の役割分類のMicro F1とMacro F1を示す．
この実験設定においてMicro F1は役割全体の分類精度と等価であるが，この値は各指標で[MATH]から[MATH]の向上が見られた．
また，最も高い精度は，全ての汎化指標によるラベルを同時に利用したモデルで得られ，ベースラインに対して[MATH]のエラー削減を実現した．
この結果は，異なる種類の指標が互いにそれらを補完しあうことを示すものである．
汎化指標ごとの性能をみると，記述子による効果が最も高く，フレームの階層関係を用いた汎化はこれに及ばなかった．
また，主題役割による結果は，役割の[MATH]しか主題役割と関連付けることが出来なかったため，比較的小さな向上に留まったものの，有意な上昇を示した．
[CITE]の実験では，FrameNetの階層関係は良い結果を得られなかったが，我々の汎化方法では有意な精度向上を確認した．
また，我々は記述子において，従来の置き換えによる方法と，記述子ラベルとフレーム固有の役割ラベルを同時に利用する方法を比較した（表[REF_integration]の[MATH]行目と[MATH]行目）．
結果として，単に元の役割を同時に利用する場合でも，汎化ラベルに単純に置き換える従来の方法よりも正確に役割を推定出来ることを確認した．
また，Macro F1の値から，我々の提案する汎化指標が低頻度の役割に対する分類精度を効果的に向上させたことが窺える．
表[REF_sparseness]では，役割を事例数ごとに分け，それぞれの分類精度を示した．
ここでも，我々の提案する汎化指標が特に事例の少ない役割の分類を助けている事が分かる．
上述の実験では，特に記述子による汎化で顕著な向上が見られたため，この理由を細かく分析することにした．
表[REF_coreness]は，役割の中心性ごとにそのタイプの役割だけから記述子の汎化ラベルを作成し，評価セット全体のMicroF1を測ったものである．
結果からは，記述子が特に周辺的な役割の汎化に有効であることが分かる．
表[REF_class_instances]は，それぞれの中心性に割り当てられる役割の数，及び役割あたりの事例数，各中心性における記述子の数，記述子あたりの事例数を表したものである．
ここで特徴的なのは，peripheralに分類される1,924の役割は250という比較的小さな数の記述子に纏まっていることである．
これは，フレームに意味の依存が薄い役割に同一の記述子が付けられやすいという傾向を示しており，この傾向によって，記述子が特に周辺的な役割をフレーム横断的に汎化する良い指標になっていると考えられる．
役割間の階層関係を用いた汎化については，関係の型と階層を辿る深さによる効果の違いを調べた．
表[REF_relation-accuracy]はそれぞれのMicro F1を示したものである．
タイプ別にみると，特に継承と使用でその他の関係よりも精度の向上が見られた．
それら以外のものは，関係の出現数そのものが少なかったために，差が少なく，効果の違いを考察するに至らなかった．
また，深い階層関係を持つ役割については，一代先の汎化ラベルだけを用いるよりも，階層を伝って辿れる全てのラベルを用いて汎化する方が，より効果があることを確認した．
先行関係については，最も効果の見られた祖先を辿る方法を採用することにした．
また，最も高い性能は，階層上の全ての関係を利用した場合に得られた．
表[REF_coreness-f1]は中心性のタイプ別に見た，各汎化指標を用いたモデルの適合率，再現率，Micro F1である．
coreに相当する意味役割は，汎化を利用しない場合でも[MATH]の分類精度が得られており，全ての汎化指標で比較的高い分類精度となった．
peripheralとextra-thematicに関しては，最も簡潔な方法である記述子による方法がその他の指標を上回った．
表[REF_top1000]には，重みの絶対値が上位[MATH]の特徴関数を，タイプ別に分類した．
この表から，汎化指標の特徴は，記述子と意味型のグループと固有役割と階層関係のグループの二つのグループに分かれることが分かる．
記述子と意味型では，先頭単語やsupersenseなどの，付加詞の特徴付けを行う素性との組み合わせが高い重みを持つ．
固有役割と階層関係では，統語パスや内容語，主辞などの，語彙的或いは構造的な素性と強い結びつきがある．
このことは，記述子や意味型を用いた汎化が周辺的，或いは付加詞に対応する役割に対して有効であり，階層関係を用いた汎化がcoreの役割に効果的であることを示唆する．
PropBankにおける実験では，二つのことを検証する．
一つ目は，従来PropBank上での意味役割の汎化で議論されてきたARGタグと主題役割の効果の違いを明らかにすることである．
既存研究におけるARGタグと主題役割の比較では，意味役割付与タスク全体を通した精度比較しか行ってこなかった[CITE]．
しかしながら，意味役割付与は複雑な問題が絡み合うタスクなため，そのような比較では，最終的な精度に影響する原因がどの部分で生じたかが不明瞭になりがちである．
特に構文解析時のエラーは，多くの複雑で不整合な統語構造を生むため，意味役割付与の精度に大きく影響することが知られている[CITE]．
幸い，PropBankはPennTreebankと同一のテキストに対するコーパスなため，PennTreebankの人手による正解構文木が利用可能である．
そこで，我々はこの構文木を入力として利用することで，構文解析エラーの影響を無くしたより厳密な状況を作り，理想的な状況下での役割分類結果のエラー分析を行うことによって，二つの汎化指標が捉えている役割の性質の違いを正確に分析する．
二つ目では，これらの指標に加え，我々の提案した新しい三つの指標について，それらの汎化性能を比較する．
比較は，役割全体の分類精度に加えて，対象動詞に関する素性を除いた設定での評価と，未知動詞に対する評価の三つで行う．
実験にはPenn Treebank IIコーパスのWall Streed Journal部分と，それに対応するPropBankのデータを用いる．
Wall Street Journalのうち，02-21節を訓練に，24節を開発に，23節を評価に利用する．
この実験では，各アノテーションに対してSemLinkによって与えられる動詞クラスと主題役割の情報を用いているため，[CITE]の方法に準じて，SemLink 1.1によって主題役割に写像出来るアノテーションだけを実験セットとして用いる．
その数は70,397アノテーションであり，PropBank全体の[MATH]にあたる．
また，すでにフレームに独立なラベルとして定義されているAMタグは取り除き，フレーム固有の意味役割として定義されているARG0-5のみの分類精度によって評価を行う．
役割句[MATH]に対する特徴には，FrameNetの場合と同じく，既存研究で効果が確認された素性を用いる．
具体的には，フレーム，対象動詞，主辞，内容語，先頭／末尾語，左右姉妹句の主辞，句の統語範疇，句の位置，態，統語パス，句に含まれる固有表現カテゴリ，統語フレーム，前置詞句の先頭語，対象動詞と主辞の組，態と統語範疇の組，統語フレームと前置詞句の線統語の組である．
単語を用いた素性には，表層形の他，品詞や語幹を用いたものも併せて利用する．
固有表現抽出には，CoNLL-2008 shared task [CITE]のopen-challenge datasetに与えられた，意味タガー[CITE]の三つの出力結果を用いる．
ARGタグと主題役割についての比較では，まず役割全体の分類精度による評価を行った．
表[REF_table:moreLess]はこれらの汎化指標を個別に用いた際の分類精度を示す．
記号***は，汎化ラベルを用いないモデルに比べてMcNemarテストにより[MATH]で有意であることを意味する．
役割分類に理想的な入力が与えられた場合，役割の汎化を行わないモデルでも96.7%以上の精度を実現することが可能であった．
ARGタグと主題役割を用いた場合には，どちらのモデルも，汎化を行わない場合に比べて分類精度が向上した．
また，その効果は事例の少ない役割に対して特に明確に確認できる．
表[REF_table:moreLess]における列「[MATH]」と列「[MATH]」は，事例数が200を超えるフレームと50未満のフレームに対する分類精度を表す．
これらから，役割の汎化を行わなかった場合には，事例数50未満のフレームに対する精度が，200を超えるフレームに比べて約[MATH]ポイントと大きく低下することが分かる．
一方で，ARGタグや主題役割は，役割をフレームに独立な少数のラベルに汎化するため，事例の少ない役割をより頑健に分類することが出来る．
[CITE]と[CITE]は，主題役割を用いた意味役割付与はARGタグを用いる場合に比べて，性能が若干低下すると報告した．
しかし我々の実験では，これら二つの汎化ラベルの結果に有意な差は認められなかった([MATH])．
図[REF_fig:reduce]の学習曲線を見ても，ARGタグと主題役割の曲線は近く，[CITE]と[CITE]が指摘したような主題役割に対する訓練データの不足は確認出来なかった．
また，[CITE]は，ARGタグのうち特にARG2で不整合があるとしたが，我々の実験のように，理想的な入力と，フレームによる選択可能なラベルの制約が与えられた場合，ARGタグと主題役割のどちらにおいてもARG0-5の各タグをほぼ同精度で分類することが出来た（表[REF_table:argF1]）．
これは表[REF_table:featureDistribution]に見られるように，verb+pathなどの動詞に関する組み合わせ特徴によって，各役割の動詞に対する個別の振る舞いを学習していることと，フレームによる選択可能なラベルの制限によって，主題役割のうちPatientやThemeなどの統語的に類似する性質を持つ役割の混在がある程度制限されるためと思われる．
我々は二つの汎化指標の特徴についてより詳しく分析するために，それぞれのモデルで生じたエラーを人手でチェックし，二つのモデルで分類結果の食い違った事例を分析した．
図[REF_fig:errMap]は，ARGタグモデルと主題役割モデルの，互いに一方が正解し一方が間違った事例と，双方が間違った事例について，それらの正解ラベルと推定ラベルの組を分類したものである．
表(A)はARGタグモデルで正解し，主題役割モデルで間違った事例であるが，最初の三行のエラーは，異なる動詞クラスの間で，主題役割の統語位置に不整合が出ることが原因である．
例えば，クラスamuse-31.1，appeal-31.4の動詞について，Causeは主語の位置に現れる傾向にあり，Experiencerはその他の場所に現れる傾向があるが，クラスmarvel-31.3では逆の傾向がある．
また，Destination[MATH]Themeのケースは，一般的に前置詞句として現れるDestinationが，動詞クラスspray-9.7，fill-9.8，butter-9.9，image_impression-25.1においては目的語の位置に現れやすいことが原因である．
一方で，PropBankは各動詞に対して，主語の位置に現れやすい役割にARG0を，目的語の位置に現れやすい役割にARG1を主に割り当てているために，ARGタグにはこのような曖昧性さが起こりにくい．
表(B)には逆に，主題役割モデルで正解し，ARGタグモデルで間違った事例を示す．
最初の行は主題役割の有効性を表す良い例である．
ARGタグは主に統語的特徴に基づいたグループであるため，ARG1が主語の位置に出てきた場合にこれをARG0と間違いやすい．
それとは対照に，主題役割はより意味的属性を考慮したグループに分割されているので，主語の位置に現れるPatientに対して，統語素性からのペナルティが小さい．
その結果，ARG0を用いる場合よりもこれらの役割が比較的正しく分類された．
また，表(C)の，ARGタグと主題役割両方のモデルで間違う事例にもいくつかの傾向が見られる．
例えば，能格動詞が自動詞として使われるときや，Themeが目的語として現れにくい動詞クラスなどで多くの間違いが見られる．
これらの改善のためには，動詞或いは動詞クラスに対してより詳細化された統語的意味的情報が必要だと思われる．
表[REF_fig:errMap]からは，総じて二つの汎化ラベルが意味役割の汎化において異なる利点を持っていることが分かる．
さらに，表[REF_table:incorporate]に見られるように，これら二つの汎化ラベルを同時に利用したモデルの結果も，二つの汎化ラベルが異なる効果をもたらしたことを示す結果となった．
記号***はARGタグのみを使うモデルに比べて，そのモデルの精度がMcNemarテストにおいて[MATH]で有意であることを示す．
ARGタグ+主題役割のモデルはARGモデルに比べて[MATH]のエラーを削減した．
このモデルにさらに元の意味役割ラベルを加えた固有役割+ARGタグ+主題役割モデルについても実験を行ったが，ARGタグ+主題役割モデルに対して性能の有意な向上は得られなかった．
これは，既に対象動詞との組み合わせを用いたいくつかの特徴がARGタグ+主題役割モデルに含まれているためと思われる．
次に，既存の汎化手法と我々の提案する汎化手法についての比較を示す．
この実験では，汎化性能を比較する三つの設定を用意した．
設定(A)は[REF_sec:pbVsTr]節で利用した[REF_sec:propbank-setting]節の設定である．
設定(B)は(A)と同じデータセットにおいて，フレームと対象動詞に由来する全ての特徴を取り除いたモデルの精度を測るものである．
この設定では，各汎化ラベルが動詞固有の情報を使わずに，汎化ラベルのみでどれほどの精度を実現するかを評価する．
設定(C)では，コーパス中の低頻度動詞に関する事例を取り除くことにより人工的に未知動詞を作り，それらの動詞に対する意味役割の分類精度を評価する．
この設定は，実際に未学習の動詞が表れたときに，それぞれの汎化指標が頑健にラベルの推定を行えるかを調べるものである．
ここでは出現回数が[MATH]回以下の，1,190の動詞に関する事例をコーパス中から抜き出し，この抜き出した事例を評価セットとして利用する．
図[REF_unseenList]は抜き出した動詞の抜粋である．
この操作により実際に抜き出された役割の事例数は[MATH]となった．
表[REF_table:unseenAcc]に実験結果を示す．
設定(A)において最も高い性能を示したのはARGタグ+主題役割モデルであり，より細かい粒度の汎化ラベルを加えたモデルは，ARGタグ+主題役割モデルに及ばなかった．
また，(B)，(C)の結果からは，ARGタグ+主題役割モデルが，ARGタグや主題役割を単独で使うモデルに比べて，大きく向上させていることが分かる．
特に，未知動詞に対する性能を評価している設定(C)では，ARGタグや主題役割を個別に用いる方法では，十分な汎化の効果が得られないことが分かる．
我々の提案する細粒度の汎化指標は，ARGタグや主題役割と組み合わせて利用することによって，(B)，(C)の分類精度を向上させることを確認した．
特に，意味述語と動詞クラスを用いた汎化が効果的に性能を向上させた．
また，未知動詞に関する実験である(C)において最も高い性能を示したのは，ARGタグ+主題役割+意味述語モデルであり，ARGタグのみを用いた場合に比べて[MATH]%のエラー削減を実現した．
これは言い換えれば，各動詞について十分な学習が出来る場合には，細粒度の汎化によって全体の精度を落とすことがあり，一方で，動詞個別の学習が不十分な場合には，異なる観点を織り交ぜた細粒度の汎化が分類精度の向上をもたらすということを意味する．
この結果で興味深いのは，従来，意味役割付与においてあまり用いられてこなかった動詞クラスの情報が，意味役割を細かいレベルで適切に汎化し，意味役割分類の頑健性を向上させるということである．
この結果は，意味役割付与問題において，役割分類の事前処理，或いは結合モデルとして，対象動詞の動詞クラスを求めることの有用性を表している．
今後は，対象動詞に対するフレーム及び動詞クラスを特定する処理を含めた精度の評価が必要であろう．
