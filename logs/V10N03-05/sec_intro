本論文では，SENSEVAL2の日本語翻訳タスクに対して帰納論理プログラミング（Inductive Logic Programing，以下ILPと略す）を適用する．
背景知識として分類語彙表を利用することで，正解率54.0 %を達成した．
この値は，訓練データを新たに作成しない翻訳タスク参加の他システムと比較して優れている．
SENSEVAL2の日本語翻訳タスクは，Translation Memory（以下TMと略す）と呼ばれる日英対訳対が与えられ，テスト文中の該当単語を英訳する際に利用できるTMの例文番号を返すタスクである[CITE]．
これは英訳を語義と考えた場合の多義語の曖昧性解消問題となっており，分類問題の一種である．
このため従来から活発に研究されている帰納学習手法を用いて解決可能である．
おそらく大規模かつ高品質な訓練データを用いたシステムが，コンテストで優秀な成績を納めるはずである．
しかし翻訳タスクでは大規模かつ高品質な訓練データを用意するコストが高い．
TMは1つの単語に対して平均して21.6例文がある．
今仮にある単語Aの例文として[MATH]から[MATH]までの20例文がTMに記載されているとする．
新たに訓練データを作成する場合，単語Aを含む新たな文を持ってきて，[MATH]から[MATH]のどれか1つのラベルをその事例に与える必要がある．
〇か×かの二者択一は比較的容易であるが，20個のラベルの中から最も適切な1つを選ぶのは非常に負荷のかかる作業である．
この理由のために，実際のコンテストにおいて，大規模かつ高品質な訓練データを用意する方法をとったシステムは1つ（Ibaraki）だけであった．
ここでは訓練データを新たに作成せずに，日本語翻訳タスクを解決することを目標とする．
訓練データを新たに作成しないとしても，TMの例文は訓練データとして扱える．
ただしTMの例文を訓練データと見た場合，その量は少量と言わざるをえない．
つまり問題は，少量の訓練データからどのようにして精度の高い分類規則を獲得するかである．
そのための戦略としてILPを用いる．
少量の訓練データからどのようして分類規則を学習したらよいかは，機械学習における1つの重要な課題である．
その解決方法として背景知識の利用が提案されている[CITE]．
背景知識とは，訓練データには明示されない問題固有の知識であり，広く捉えれば，人間の持つ常識的知識と考えて良い．
一種の知識データベースである．
問題はその背景知識を，どのように学習手法に取り入れてゆくかである．
その解決のために提案されているのがILPである．
ILPは訓練データを述語論理の形式で表し，そこから分類規則に相当する規則（述語論理の形式では節に対応）を導出する．
知識データベースは述語論理の形式によって自然に表現できるので，背景知識の利用の観点からはILPを用いた学習戦略が優れている[CITE]．
更にILPの背景知識では，複雑なグラフ構造を持ったものも表現できるので，近年，CMUの機械学習チームはWebページの文書分類にILPを利用している[CITE]．
更にいくつかの自然言語処理への応用も知られている[CITE][CITE][CITE]．
本論文では，ILPの処理系としてMuggletonによるProgolを利用する[CITE]．
Progolによって多義語の曖昧性解消を行う．
そして背景知識としては分類語彙表[CITE]を利用する．
以下2章で多義語の曖昧性解消をILPで行う方法を示す．
3章では分類語彙表をどのように背景知識として組み込むかを説明し，4章で実験，5章で考察を述べ，最後にまとめる．
