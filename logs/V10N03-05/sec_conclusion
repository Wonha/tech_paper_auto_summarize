背景知識を用いても必ずしも正解率が高くなるとは限らないことは容易に予想がつく．
実際に，実験1，2でも精度が下がる単語がいくつか存在する．
また，実験3と同様の課題についてさらに分類語彙表を背景知識として用いた実験も行ったが，この場合の平均の正解率も60.5 %から58.9 %に低下した．
分類語彙表を用いることで，単語を語義に一般化すれば，ある部分では効果があるが，別の部分では過度の一般化になるので，その影響が現れると精度は下がる．
過度の一般化への対処は今後の課題である．
また節を規則として見た場合，節の適用順序が重要になる．
これは入力事例と訓練事例に矛盾がないことを仮定する論理を基盤とする推論では問題にならない．
しかし現実の問題では訓練データに矛盾する入力も有り得る．
例えば，以下のケースを考えてみる．
class(X,c1) :- attr_1(X, a).
class(X,c2) :- attr_2(X, b).
節Aは事例の1番目の素性の値がaなら分類クラスがc1であることを示し，節Bは事例の2番目の素性の値がbなら分類クラスがc2であることを示している．
この2つの規則が学習されたということは，訓練データ内には，1番目の素性の値がaでしかも2番目の素性の値がbの事例が存在しなかったことを意味する．
また同時にそのような事例が存在しないことも仮定したことになる．
ところが，現実にはそのような事例が入力されることもある．
この場合，上記の規則では，クラスはc1と識別される．
一方，上記の規則の順序を変更し，以下の形にすれば，クラスはc2と識別される．
class(X,c2) :- attr_2(X, b).
class(X,c1) :- attr_1(X, a).
節の出現順序はProgolでは考慮されていないようである．
訓練データに対応する述語や節の与える順序が，生成される節の順序に影響する．
本実験ではこの点は何も対策をたてずに，学習された節をそのまま適用した．
しかしこのような節の順序はdefault規則が何に対応するかという問題にもなっており，正解率に大きく影響する．
実験3で正解率が大きく下がる単語は，みなこの問題がからんでいた．
この対策も今後の課題である．
また上記の問題とも関連するがILPでは頻度の情報がなくなってしまう．
例えば，上記の節Bに合致した訓練事例の数が10,000で，節Aに合致した訓練事例の数が1のとき，普通に考えれば合致する事例数の多い節Bを優先させるのが正しいであろう．
しかしILPでは，頻度の情報が節Bと節Aに反映されず，結果として同じ重みを与えている形になる．
この問題は，確率と論理を結び付ける研究と関連しており，いまだ決定版は出ていない状況である[CITE]．
少量の訓練データしかない場合，識別精度を高めるには，訓練データ以外の情報，つまり背景知識をいかに取り込むかが重要である．
今回の実験では背景知識として分類語彙表を用いたが，単語を語義で一般化することは通常の確率統計的な手法でも実現可能であり[CITE]，この点ではILPを用いた利点は少ない．
ただし翻訳タスクでは背景知識の利用という観点以外からも，ILPを用いた方が適切であると思われる．
なぜならここで扱っている少量のデータは統計学でいうサンプルではないからである．
例えば，仮に
語義c1の例文1からe1=aとe2=bいう素性語義c2の例文2からe1=cとe2=dいう素性語義c1の例文3からe1=aとe2=eいう素性
が得られたとする．
確率統計的な手法では，以下の5つの確率が高くなる．
確率対応する例文------------------------------ P(c1|e1=a)例文1，例文3 P(c1|e2=b)例文1 P(c1|e2=e)例文3 P(c2|e1=c)例文2 P(c2|e2=d)例文2
そして特にP(c1|e1=a)の確率が高くなる．
同じクラスc1の例文1と3に素性e1=aが発生しているからである．
ただし，このような確率の算出が妥当なのは，例文1，2，3がサンプル，つまり等確率で現れる事例という仮定がある．
TMの例文はサンプルではありえない．
例えば，ある単語は90 %以上の割合で，語義c1の意味用法で利用されるとしても，TMのその単語の例文の90 %以上が語義c1の例文であることはない．
つまり，TMの例文数から素性に重みをつけるのは意味がない．
そのためTMから得られる素性は，同じ重みで評価するのが妥当であろう．
今回ILPが決定リストよりも優れた結果を出せた要因がそこにあると思われる．
またILPの背景知識として，今回は分類語彙表を用いたが，任意の節が組み込めることは大きな魅力である．
特に，Webページは解析の観点によっては，複雑な構造をもつことになり，そのような複雑なデータ構造からの学習にはILPが利用できるため，今後応用範囲が広がる研究分野だと思われる．
本論文では，SENSEVAL2の日本語翻訳タスクに対してILPを適用した．
ILPは背景知識を容易に学習に組み込めるという確率統計的な手法にはない長所がある．
翻訳タスクは少量の訓練データしか利用できない分類問題と見なせるため，翻訳タスクはILPの格好の応用となっている．
ここではILPの実装システムとしてProgol，背景知識として分類語彙表を利用することで，正解率54.0 %を達成した．
この値は，訓練データを新たに作成しない翻訳タスクの他システムと比較して優れている．
また語義のクラスを同一にした訓練データを用いて，確率統計的手法の1つである決定リストと比較したところ，決定リストの正解率54.8 %に対して，ILPでは60.5 %となり，決定リストよりも良い結果が得られた．
分類語彙表を利用した場合の過度の一般化をどう押さえるか，出力される規則の優先順序をどのように制御するかが今後の課題である．
背景知識を用いても必ずしも正解率が高くなるとは限らないことは容易に予想がつく．
実際に，実験1，2でも精度が下がる単語がいくつか存在する．
また，実験3と同様の課題についてさらに分類語彙表を背景知識として用いた実験も行ったが，この場合の平均の正解率も60.5 %から58.9 %に低下した．
分類語彙表を用いることで，単語を語義に一般化すれば，ある部分では効果があるが，別の部分では過度の一般化になるので，その影響が現れると精度は下がる．
過度の一般化への対処は今後の課題である．
また節を規則として見た場合，節の適用順序が重要になる．
これは入力事例と訓練事例に矛盾がないことを仮定する論理を基盤とする推論では問題にならない．
しかし現実の問題では訓練データに矛盾する入力も有り得る．
例えば，以下のケースを考えてみる．
class(X,c1) :- attr_1(X, a).
class(X,c2) :- attr_2(X, b).
節Aは事例の1番目の素性の値がaなら分類クラスがc1であることを示し，節Bは事例の2番目の素性の値がbなら分類クラスがc2であることを示している．
この2つの規則が学習されたということは，訓練データ内には，1番目の素性の値がaでしかも2番目の素性の値がbの事例が存在しなかったことを意味する．
また同時にそのような事例が存在しないことも仮定したことになる．
ところが，現実にはそのような事例が入力されることもある．
この場合，上記の規則では，クラスはc1と識別される．
一方，上記の規則の順序を変更し，以下の形にすれば，クラスはc2と識別される．
class(X,c2) :- attr_2(X, b).
class(X,c1) :- attr_1(X, a).
節の出現順序はProgolでは考慮されていないようである．
訓練データに対応する述語や節の与える順序が，生成される節の順序に影響する．
本実験ではこの点は何も対策をたてずに，学習された節をそのまま適用した．
しかしこのような節の順序はdefault規則が何に対応するかという問題にもなっており，正解率に大きく影響する．
実験3で正解率が大きく下がる単語は，みなこの問題がからんでいた．
この対策も今後の課題である．
また上記の問題とも関連するがILPでは頻度の情報がなくなってしまう．
例えば，上記の節Bに合致した訓練事例の数が10,000で，節Aに合致した訓練事例の数が1のとき，普通に考えれば合致する事例数の多い節Bを優先させるのが正しいであろう．
しかしILPでは，頻度の情報が節Bと節Aに反映されず，結果として同じ重みを与えている形になる．
この問題は，確率と論理を結び付ける研究と関連しており，いまだ決定版は出ていない状況である[CITE]．
少量の訓練データしかない場合，識別精度を高めるには，訓練データ以外の情報，つまり背景知識をいかに取り込むかが重要である．
今回の実験では背景知識として分類語彙表を用いたが，単語を語義で一般化することは通常の確率統計的な手法でも実現可能であり[CITE]，この点ではILPを用いた利点は少ない．
ただし翻訳タスクでは背景知識の利用という観点以外からも，ILPを用いた方が適切であると思われる．
なぜならここで扱っている少量のデータは統計学でいうサンプルではないからである．
例えば，仮に
語義c1の例文1からe1=aとe2=bいう素性語義c2の例文2からe1=cとe2=dいう素性語義c1の例文3からe1=aとe2=eいう素性
が得られたとする．
確率統計的な手法では，以下の5つの確率が高くなる．
確率対応する例文------------------------------ P(c1|e1=a)例文1，例文3 P(c1|e2=b)例文1 P(c1|e2=e)例文3 P(c2|e1=c)例文2 P(c2|e2=d)例文2
そして特にP(c1|e1=a)の確率が高くなる．
同じクラスc1の例文1と3に素性e1=aが発生しているからである．
ただし，このような確率の算出が妥当なのは，例文1，2，3がサンプル，つまり等確率で現れる事例という仮定がある．
TMの例文はサンプルではありえない．
例えば，ある単語は90 %以上の割合で，語義c1の意味用法で利用されるとしても，TMのその単語の例文の90 %以上が語義c1の例文であることはない．
つまり，TMの例文数から素性に重みをつけるのは意味がない．
そのためTMから得られる素性は，同じ重みで評価するのが妥当であろう．
今回ILPが決定リストよりも優れた結果を出せた要因がそこにあると思われる．
またILPの背景知識として，今回は分類語彙表を用いたが，任意の節が組み込めることは大きな魅力である．
特に，Webページは解析の観点によっては，複雑な構造をもつことになり，そのような複雑なデータ構造からの学習にはILPが利用できるため，今後応用範囲が広がる研究分野だと思われる．
本論文では，SENSEVAL2の日本語翻訳タスクに対してILPを適用した．
ILPは背景知識を容易に学習に組み込めるという確率統計的な手法にはない長所がある．
翻訳タスクは少量の訓練データしか利用できない分類問題と見なせるため，翻訳タスクはILPの格好の応用となっている．
ここではILPの実装システムとしてProgol，背景知識として分類語彙表を利用することで，正解率54.0 %を達成した．
この値は，訓練データを新たに作成しない翻訳タスクの他システムと比較して優れている．
また語義のクラスを同一にした訓練データを用いて，確率統計的手法の1つである決定リストと比較したところ，決定リストの正解率54.8 %に対して，ILPでは60.5 %となり，決定リストよりも良い結果が得られた．
分類語彙表を利用した場合の過度の一般化をどう押さえるか，出力される規則の優先順序をどのように制御するかが今後の課題である．
