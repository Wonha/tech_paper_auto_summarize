考察


背景知識を用いても必ずしも正解率が高くなるとは限らないことは容易に予想がつく．
実際に，実験1，2でも精度が下がる単語がいくつか存在する．
また，実験3と同様の課題についてさらに分類語彙表を背景知識として用いた実験も行ったが，
この場合の平均の正解率も 60.5\,\% から 58.9\,\% に低下した．
分類語彙表を用いることで，単語を語義に一般化すれば，
ある部分では効果があるが，別の部分では過度の一般化になるので，
その影響が現れると精度は下がる．過度の一般化への対処は今後の課題である．

また節を規則として見た場合，節の適用順序が重要になる．
これは入力事例と訓練事例に矛盾がないことを仮定する
論理を基盤とする推論では問題にならない．
しかし現実の問題では訓練データに矛盾する入力も有り得る．
例えば，以下のケースを考えてみる．

\begin{verbatim}
            class(X,c1) :- attr_1(X, a).    
            class(X,c2) :- attr_2(X, b).    
\end{verbatim}

節 A は事例の1番目の素性の値が a なら分類クラスが c1 であることを示し，
節 B は事例の2番目の素性の値が b なら分類クラスが c2 であることを示している．
この 2 つの規則が学習されたということは，訓練データ内には，
1番目の素性の値が a でしかも2番目の素性の値が b の事例が存在しなかったことを意味する．
また同時にそのような事例が存在しないことも仮定したことになる．
ところが，現実にはそのような事例が入力されることもある．
この場合，上記の規則では，クラスは c1 と識別される．
一方，上記の規則の順序を変更し，以下の形にすれば，クラスは c2 と識別される．

\begin{verbatim}
            class(X,c2) :- attr_2(X, b).    
            class(X,c1) :- attr_1(X, a).    
\end{verbatim}

節の出現順序は Progol では考慮されていないようである．
訓練データに対応する述語や節の与える順序が，生成される節の順序に影響する．
本実験ではこの点は何も対策をたてずに，学習された節をそのまま適用した．
しかしこのような節の順序は default 規則が何に対応するかという
問題にもなっており，正解率に大きく影響する．
実験3で正解率が大きく下がる単語は，みなこの問題がからんでいた．
この対策も今後の課題である．

また上記の問題とも関連するが ILP では頻度の情報がなくなってしまう．
例えば，上記の節 B に合致した訓練事例の数が 10,000 で，節 A に合致した訓練事例の数が 1 のとき，
普通に考えれば合致する事例数の多い節 B を優先させるのが
正しいであろう．しかし ILP では，頻度の情報が節 B と節 A に反映されず，結果として
同じ重みを与えている形になる．
この問題は，確率と論理を結び付ける研究と関連しており，
いまだ決定版は出ていない状況である\cite{furukawa}．

少量の訓練データしかない場合，識別精度を高めるには，訓練データ以外の情報，
つまり背景知識をいかに取り込むかが重要である．
今回の実験では背景知識として分類語彙表を用いたが，単語を語義で一般化することは
通常の確率統計的な手法でも実現可能であり\cite{almuallim}，
この点では ILP を用いた利点は少ない．
ただし翻訳タスクでは背景知識の利用という観点以外からも，ILP を用いた方が
適切であると思われる．なぜならここで扱っている少量のデータは統計学でいうサンプルではないからである．
例えば，仮に

\begin{verbatim}

       語義 c1 の例文1から e1=a と e2=b いう素性
       語義 c2 の例文2から e1=c と e2=d いう素性
       語義 c1 の例文3から e1=a と e2=e いう素性

\end{verbatim}
\noindent
が得られたとする．確率統計的な手法では，以下の5つの確率が高くなる．

\begin{verbatim}

        確率          対応する例文
      ------------------------------
        P(c1|e1=a)    例文1，例文3
        P(c1|e2=b)    例文1
        P(c1|e2=e)    例文3
        P(c2|e1=c)    例文2
        P(c2|e2=d)    例文2

\end{verbatim}

\noindent
そして特に\verb# P(c1|e1=a) #の確率が高くなる．同じクラス c1 の例文1と3
に素性\verb| e1=a |が発生しているからである．ただし，このような確率の算出が妥当なの
は，例文1，2，3がサンプル，つまり等確率で現れる事例という仮定がある．
TM の例文はサンプルではありえない．例えば，ある単語は 90\,\% 以上の割合で，語義 c1 の意味用法で
利用されるとしても，TM のその単語の例文の 90\,\% 以上が語義 c1 の例文であることはない．
つまり，TM の例文数から素性に重みをつけるのは意味がない．
そのため TM から得られる素性は，同じ重みで評価するのが妥当であろう．
今回 ILP が決定リストよりも優れた結果を出せた要因がそこにあると思われる．

また ILP の背景知識として，今回は分類語彙表を用いたが，任意の節が組み込める
ことは大きな魅力である．特に，Web ページは解析の観点によっては，複雑な構造をもつことになり，
そのような複雑なデータ構造からの学習には ILP が利用できるため，
今後応用範囲が広がる研究分野だと思われる．


おわりに


本論文では，SENSEVAL2 の日本語翻訳タスクに対して ILP を適用した．
ILP は背景知識を容易に学習に組み込めるという確率統計的な手法にはない長所がある．
翻訳タスクは少量の訓練データしか利用できない分類問題と見なせるため，
翻訳タスクは ILP の格好の応用となっている．
ここでは ILP の実装システムとして Progol，背景知識として分類語彙表を利用することで，
正解率 54.0\,\% を達成した．
この値は，訓練データを新たに作成しない翻訳タスクの他システムと比較して優れている．
また語義のクラスを同一にした訓練データを用いて，確率統計的手法の1つである
決定リストと比較したところ，決定リストの正解率 54.8\,\%に対して，ILP では 60.5\,\%となり，
決定リストよりも良い結果が得られた．

分類語彙表を利用した場合の過度の一般化をどう押さえるか，
出力される規則の優先順序をどのように制御するかが今後の課題である．




\bibliographystyle{jnlpbbl}
\bibliography{ilp}

\begin{biography}
\biotitle{略歴}
\bioauthor{新納 浩幸}{
1985年東京工業大学理学部情報科学科卒業．
1987年同大学大学院理工学研究科情報科学専攻修士課程修了．
同年富士ゼロックス，翌年松下電器を経て，
1993年茨城大学工学部システム工学科助手．
1997年同学科講師，2001年同学科助教授．
情報処理学会，人工知能学会，言語処理学会，ACL 各会員．博士(工学)．}

\bioauthor{阿部 修也}{
2001年茨城大学工学部システム工学科卒業.
2003年茨城大学大学院理工学研究科システム工学専攻博士前期課程修了．
同年4月より株式会社システム計画研究所．}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}
\end{biography}

