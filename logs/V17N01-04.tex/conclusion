\section{まとめ}

文字列によるテキスト分類において，条件付確率を用いて文書の特徴集合を選択する代わりに，反復度を用いて特徴選択を行い，ニュース記事のコーパスであるReuters-21578，20newsgroupsと，スパムメールのコーパスであるTREC 
2006 Spam 
Corpusのテキスト分類の結果の比較を行った．反復度によって特徴選択した特徴集合を用いると条件付確率による特徴集合を用いた場合に比べて，ニュース記事の分類では平均79.65{\%}から平均83.39{\%}と，平均3.74{\%}だけテキスト分類の結果を改善することを報告し，スパムメールの分類では分類結果を平均90.23{\%}から平均93.15{\%}と平均2.93{\%}だけ結果を改善することを報告した．このとき，その両方の実験において，提案する反復度を用いる手法と条件付確率を用いるZhangら手法の間に有意差があることを確認した．

また，本実験では提案手法である反復度を用いて特徴集合を選択する方法と単語を特徴集合とする方法との比較についてもZhangらの手法との比較と同様にして行った．Reuters-21578，20newsgroupsを用いたニュース記事の分類においては両手法の間に有意差は確認できなかった．しかし，TREC 
2006 Spam 
Corpusを用いたスパムメールの分類においては，反復度による特徴抽出法を用いると，単語を特徴集合とする場合に比べて分類結果を，平均92.11{\%}から平均93.15{\%}と平均1.04{\%}だけ改善するということを報告した．そして，このとき危険率1{\%}の検定を行い両手法の間に有意差があるということを確認した．この結果の一つの要因として，反復度を用いて抽出される部分文字列に，条件付き確率を用いる手法で抽出される部分文字列に比べて別の部分文字列と解釈されにくい部分文字列や，単語による方法では抽出できない単語と単語を結ぶような文字列が含まれていると言うことが考えられる．よって，本研究は意味ある結果となったといえる．


\acknowledgment

この研究は，住友電工情報システムとの共同研究の成果です．データの解析には，戦略的情報通信開発推進制度(SCOPE)の課題「実空間情報処理のためのインターユビキタスネットワークの研究」の成果の分析技術を利用しました．

また，多くの有益なご指摘を頂いた査読者の方々に感謝致します．


\bibliographystyle{jnlpbbl_1.4}
\begin{thebibliography}{}


\item
Manning, C. and Schutze H. (1999). ``Foundations of Statistical Natural 
Language Processing.'' MIT Press, Cambridge.

\item
Zhang, D. and Lee, W. S. (2006). ``Extracting Key-Substing-Group Features for 
Text Classification.'' In \textit{Proceedings of the 12th ACM SIGKDD international 
Conference on Knowledge Discovery and Data Mining}, pp.~474--483.

\item
Peng, F., Shuurmans D., and Wang, S. (2004). ``Augmenting Naive Bayes text 
classifier with statistical language models.'' \textit{Information Retrieval}, 
\textbf{7} (3-4), pp.~317--345.

\item
Lodhi, H., Saunders, C., Shawe-Taylor, J., Cristianini, N., and Watkins, C. 
(2001). ``Text Classification Using String Kernels.'' \textit{Journal of Machine 
Learning Research (JMLR)}, pp.~419--444.

\item
Goodman, J. (2001). ``A bit progress in language modeling, extended version.'' 
Technical report, Microsoft Research, pp.~403--434.

\item
Church, K. W. (2000). ``Empirical Estimates of Adaptation: The chance of Two 
Noriegas is closer to p/2 than p2.'' In \textit{Proceedings of 18th International 
Conference on Computational Linguistics}, \textbf{1}, pp.~180--186.

\item
Cristianini, N. and Shawe-Taylor, J. (2000). ``An Introduction to Support Vector 
Machines.'' Cambridge University Press, Camridge.

\item
Dumais, S., Platt, J., Hecherman, D., and Sahami, M. (1998). ``Inductive learning 
algorithms and representations for text categorization.'' In \textit{Proceedings of 
the 7th ACM International Conference on Information and Knowledge 
Management}, pp.~148--155.

\item
Mitchell, T. (1997). ``Machine Learning.'' McGraw Hill, international edition.

\item
Geng, Xiubo, Liu, Tie-Yan, Qin, Tao, and Li, Hang (2007). ``Feature Selection for 
Ranking.'' \textit{SIGIR '07: Proceedings of the 30th annual international ACM SIGIR 
conference on Research and development in information retrieval}, pp.~407--414.

\item
Takeda, Y. and Umemura K. (2002). ``Selecting indexing strings using 
adaptation.'' \textit{Proceedings of the 25th Annual International ACM SIGIR 
Conference on Research and Development in Information Retrieval}, pp.~11--15.

\item
Yiming, Yang and Pedersen, Jan O. (1997). ``A comparative study on feature 
selection in text categorization.'' \textit{Proceedings of ICML-97 14th 
International Conference on Machine Learning}, pp.~412--420.

\item
平田勝大, 岡部正幸, 梅村恭司 (2007). 文字列を特徴量とし反復度を用いたテキスト分類. 
情報処理学会研究会報告, \textbf{76}, pp.~121--126.

\end{thebibliography}


\clearpage

