\section{実験}

実験は，ニュースのトピック分類とSpam分類の2種類のタスクについて行い，それぞれのタスクについて，関連研究の手法の分類結果と反復度による特徴集合を用いた場合の分類結果の比較を行う．


\subsection{ニュースのトピック分類実験}

この実験には，Reuters-21578\footnote{
	http://www.daviddlewis.com/resources/testcollections/reuters21578/}と
20newsgroups\footnote{
	http://people.csail.mit.edu/jrennie/20Newsgroups/}の
2つの英語コーパスを使用し，各文書には前処理として，アルファベット以外の文字を空白に変換し，2文字以上空白が続く場合は空白1文字に変換するという処理を行う．

テキスト分類に適用可能な分類学習器は数多くあるが，本実験では特徴選択方法の比較を行うので，適切と考えられる分類学習器について実験を行った．分類学習器にはZhangらの先行研究と同じく線形カーネルを利用したSVMを用いる．線形カーネルを利用したSVMの識別関数は次式のように表される．
\[
 f(\mathbf{x})= \sum^{d}_{j=1} w_{j} x_{j} + b
\]
ここで，\textbf{x}は識別対象となる文書ベクトル，x$_{j}$は\textbf{x}の要素jの値，w$_{j}$は重みベクトル\textbf{w}の要素jの値，dは\textbf{x}の要素数，bはバイアス項である．\textbf{w}とbは学習によって決定される．

我々の提案手法では，\textbf{x}の要素集合として，反復度によって特徴選択した文字列集合を用いる．また，比較対象として，2章の先行研究において説明した条件付確率によって特徴選択した文字列集合を\textbf{x}の要素集合とした方法をベースラインに用いる．また，単語を特徴集合とする方法との比較として，最小出現頻度lと最大出現頻度hで選択した単語集合を\textbf{x}の要素集合とした方法とも比較する．x$_{j}$の値は3手法ともtfidfによって計算された値を用いる．tfidfの計算式は2章で記述した式を用いる．

実際のSVMの学習には，SVMツールのひとつであるSVMlight\footnote{ 
http://svmlight.joachims.org/}を使用し，すべてデフォルトのパラメータで学習を行う．複数トピックの分類に対しては，ターゲットとするトピックに属する文書を正例，そのトピックに属さない文書を負例とした2クラスによる学習を各トピックについて行う．結果の評価には次の3つの尺度を利用する．
{\allowdisplaybreaks
\begin{align*}
\text{適合率} & =\frac{\text{トピックに属すると分類した文書の正解文書数}}
	{\text{トピックに属すると分類した文書数}}  \\[1zw]
\text{再現率} & = \frac{\text{トピックに属すると分類した文書の正解文書数}}
	{\text{コーパス中の正解文書数}} \\[1zw]
\text{F値} & = \frac{2 \times \text{適合率} \times \text{再現率}}
	{\text{適合率} + \text{再現率}}
\end{align*}
}


\subsubsection{Reuters-21578}

Reuters-21578は，英語のテキスト分類の標準的なコーパスであり，先行研究でも用いられている．このコーパスのうち，「ModApte」学習・テストセットを使用し，本文のうちTITLEタグとBODYタグのついた文書を使用する．さらに，Reuter-21578の文書に含まれるトピックのうちの文書数の多い上位10トピックについてテキスト分類を行う．ただし，各文書は複数のトピックに属することがあり，その場合，正例として使用される文書は負例として同時に使用しないこととした．分類は，ひとつの文書が各トピックに対して属するか属さないかをSVMを用いて判定することによって行う．学習には，学習用文書セットの全9,603文書を使用し，テストには学習文書とは異なるテストセットの全3,299文書を使用する．表2に学習セットおよびテストセットにおける上位10トピックの正例の文書数を示す．後述の実験において，正例の文書数が少ないときに提案方法が優位であることを述べるために，このデータを示した．このコーパスに対して，次の3つの特徴集合を用いた場合のテキスト分類を行い，その結果を比較する．


\begin{table}[b]
\caption{学習セットの文書数}
\input{05table02.txt}
\end{table}

\begin{itemize}
\item 反復度：提案手法である，反復度を用い文字列を選択した特徴集合
\item 条件付確率：Zhangら(Zhang and Lee 2006)が提案した条件付確率を用いて文字列を選択した特徴集合．ベースラインとして用いる．
\item 単語：スペースを区切りとした単語からなる特徴集合
\end{itemize}

また，各特徴集合のパラメータ設定と選択された特徴数を以下に示す．

\begin{itemize}
\item 反復度：l=80, h=8000, a=0.3（3章参照）として7,099文字列が選択された．
\item 条件付確率：l=80, h=8000, b=8, p=0.8, q=0.8（2章参照）として8,438文字列が選択された．
\item 単語：l=10, h=8000として6,581単語が選択された．
\end{itemize}

条件付確率による手法のパラメータは先行研究と同様のパラメータを使用し，反復度のパラメータおよび単語の特徴選択のパラメータは学習用文書セットでの4分割交差検定法においてF値の平均が最も良くなる値を調べ決定している．ただし，文字列を特徴集合とする場合は，空白で始まる文字列は特徴集合からは除く．これは，英語の単語が空白で区切られているためである．以上の実験結果を図1, 図2, 図3, 表3に示す．


\begin{figure}[b]
\begin{center}
\includegraphics{17-1ia5f1.eps}
\end{center}
 \caption{適合率}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{17-1ia5f2.eps}
\end{center}
 \caption{再現率}
\end{figure}

図1および図2に注目して文字列に対する特徴選択を比較すると，トピック上位3つのearn, 
acqおよびmoney-fxについては条件付確率による特徴集合を用いたトピック分類との差が適合率，再現率ともにほとんどないが，これら以外の7トピックについては，反復度による特徴集合を用いたトピック分類の方が結果が良くなり，特に再現率が大きく改善された．図3，表3のF値でも同様に，上位3トピックのearn, 
acqおよびmoney-fxでは条件付確率を用いた場合と比べてF値はあまり変わらないが，これら以外のトピックでは反復度を用いた方が改善された．

\begin{figure}[t]
\begin{center}
\includegraphics{17-1ia5f3.eps}
\end{center}
 \caption{F 値}
\end{figure}
\begin{table}[t]
\caption{F値}
\input{05table03.txt}
\end{table}

10個のトピックの内，反復度が優れた結果を出したものは8個であり，劣った結果であってもF値は0.20{\%}しか差が出ない．一方，マクロ平均ではF値に3.74{\%}の差があり，反復度の方が良い性能を示した．マイクロ平均ではF値に約1.39{\%}の差があり，反復度の方が良い性能を示した．ただし，このコーパスにおいてはearnとacqで全体の約65{\%}のドキュメントがあり，文書数が偏っている．これはこのテストセットに特殊なケースであり，カテゴリごとの平均で比較する方が実際の性能を反映すると考えられる．単語を特徴集合とした方法と比較すると，図3，表3のように，結果の優劣はトピック毎に異なる．10トピック中6トピックについては反復度による方法の方が，F値が良くなるという結果になった．F値のマクロ平均は反復度による方法と単語による方法を比較するとほぼ等しくなった．



\subsubsection{20newsgroups}

20newsgroupsは20のトピックに属する文書からなる．分類は，Reuters-21578と同様にひとつの文書が各トピックに属するか属さないかをSVMを用いて判定することによって行う．このコーパスには，学習文書11,314とテスト文書7,532文書が含まれており，トピック間での文書数の違いはあまりない．実験では，文書中のFrom，Subjectおよびニュース本文の文書から特徴に使用する部分文字列を選択し，テキスト分類を行う．この実験における，各特徴集合のパラメータ設定と選択された特徴数は以下の通りである．

\begin{itemize}
\item 反復度：l=100, h=200000, a=0.1として69,653文字列が選択された．
\item 条件付確率：l=100, h=200000, b=8, p=0.8, q=0.8として24,732文字列が選択された．
\item 単語：l=5, h=10000として26,573単語が選択された．
\end{itemize}

l, h, aのパラメータは学習文書での4分割交差検定法によって再設定した．ただし，このコーパスにおいてもReuters-21578と同様に，先頭が空白で始まる文字列は特徴として用いる文字列から除外した．また，学習時に負例の文書数が正例と比べ非常に多いことがSVMのモデルに大きな影響を与えてしまったため，正例と負例の判定エラーに対するコスト比の値を文書数の比に近い値である20に設定し学習を行う．以上の条件において20のトピックに分類した結果，F値のマクロ平均は反復度による方法で76.05{\%}，条件付確率による方法で74.75{\%}，単語による方法で76.71{\%}となった．このように，このコーパスにおいても反復度による特徴選択の方が条件付確率による特徴選択よりも良い性能を示した．トピックごとの比較では，20トピック中10トピックにおいて反復度による方法が単語よりも良くなるという結果になった．しかしながら，その差はほとんどないといえる．


\subsection{Spam分類実験}

本実験ではTREC 2006 Spam Corpus\footnote{ 
http://trec.nist.gov/data/spam.html}をコーパスとして用いた．このコーパスはSpam分類のために作られたもので，コーパスにはヘッダ情報が含まれ，一般的な英語文章とは異なる構造をしているという特徴がある．コーパスの資料には正確な定義はないが，コーパス作成者が主観的に有用なテキストをHam，それ以外をSpamとしたものと考えられる．これを用いた実験で分類精度が向上すれば，実際のSpam分類においても分類精度が向上すると考えられる．


\subsubsection{実験方法}

トレーニングデータとしてSpam, Ham 
それぞれ100個，分類対象（テストデータ）として，Spam, Ham 
それぞれ200個をランダムに選ぶ．記号，マルチバイト文字は前処理段階でカットし，分類に用いない．このようにして20個の文書セットを構成し，この文書セットそれぞれに対して以下の分類実験を行う．

まず，学習データから次の3つの特徴集合を構成する．

\begin{itemize}
\item 反復度を用いて特徴選択した文字列からなる特徴集合 (AS) 
\item 条件付確率を用いて特徴選択した文字列からなる特徴集合 (CS)
\item スペースを区切りとした単語からなる特徴集合 (WS)
\end{itemize}

各手法のパラメータは文書セットごとに交差検定により設定する．ただし，条件付確率による手法のパラメータは先行研究(Zhang 
et al. 
2006)と同様の値を用いることとする．また，反復度による手法のパラメータl, hは条件付き確率と同様の値に設定する．テキストの学習分類は4.1節と同様に行い，評価も4.1節と同様にF値を用いて行うこととする．


\subsubsection{実験結果}

4.2.1節で述べたようにトレーニング，テストデータのセットを20個作り，それぞれに対して，特徴集合としてAS, CS, WSそれぞれを用いて分類を行う．このようにして得られた分類結果を表 
4に示す．表 4において，このF値は (SpamのF値+HamのF値) / 2 として得た平均値である．表 
5には各文書セットに対する反復度の手法のパラメータaと，単語の手法のパラメータlを示す．ここで，反復度の手法のパラメータはaを交差検定で求め，l, hはl=80, h=8000で固定し，条件付確率の手法のパラメータはl=80, h=8000, b=8, p=0.8, q=0.8で固定する．また，単語の手法のパラメータlは交差検定で求め，hはh=8000で固定とした．これは，h=8000を設定すると各文書セットで良い分類結果を示し，その付近で変化させても分類結果に影響がなかったためである．表では固定されたパラメータについては表記を省略したが，本文中に記したパラメータを使った．


表 4を見ると，文書セットを変えたときには平均的に反復度が優れた分類結果を示し，条件付確率がもっとも悪い結果を示していることがわかる．反復度を用いた結果は単語を用いた結果より平均1.04{\%}，条件付確率を用いた結果より平均2.93{\%}だけF値が高い．表から，全20の文書セットすべての分類結果において，反復度を用いた方が条件付き確率を用いるよりも良い分類結果を示していることが分かる．このことから，反復度を用いて選択した文字列を特徴集合とするのは条件付確率を用いる方法と比較して有効であると考えられる．反復度を用いる方法と単語を用いる方法のF値を比較すると，20回の分類実験のうち，反復度が単語よりも良い結果となったのが16回で，悪い結果となったのが3回，同じ値となったのが1回であった．この結果について符号検定を行い，両手法のF値の間に有意な差があるかどうかを考える．まず，帰無仮説H$_{0}$と対立仮説H$_{1}$を以下に示すように定める．

\begin{table}[t]
\caption{各手法の平均 F 値}
\input{05table04.txt}
\end{table}
\begin{table}[t]
\caption{設定したパラメータ}
\input{05table05.txt}
\vspace{-0.5\baselineskip}
\end{table}

\begin{itemize}
\item H$_{0}$：反復度を用いる方法と単語を用いる方法のF値の間に差がない．
\item H$_{1}$：反復度を用いる方法は単語を用いる方法のF値の間に差がある．
\end{itemize}

両手法の結果が同じ値となった場合，単語を用いる方法の方が優れていると見なすと，
\pagebreak
両手法のF値の分布が等しいという仮定の下で単語を用いる方法の結果が20回の内4回反復度よりも良くなる確率は，
\[
 \frac{1}{2^{20}}({}_{20}C_{4} + {}_{20}C_{3} + {}_{20}C_{2} + {}_{20}C_{1} + 1) 
	= 0.0059089 \cdots < 0.01
\]
となるため，有意水準1{\%}で帰無仮説は棄却され，対立仮説が採択される．このことから，反復度を用いる方法は単語を用いる手法よりもF値において有意な差があると考えることができる．表 
5をみると，単語の手法のパラメータlはほとんどが10以下で，まれに大きな値をとることがわかる．また，反復度の手法のパラメータaは0.2から0.4程度の値をとることがわかる．


