本章ではまず，我々のモデルのベースとなっているAirentiらの伝達行為理解のモデルについて概観した後，我々のモデルで拡張を行った点を中心に各段階での処理について説明する．
対話における認知プロセスのモデル化では，相手の発話を聞いてから自分の発話を生成するまでに，どのようなプロセスによって，どのような信念の変化が起こっているのかをとらえる必要がある．
Airentiらは，この認知プロセスを会話ゲームと行動ゲームという2つのゲームによってモデル化し，主に伝達行為を理解するという側面においての分析を行っている[CITE]．
会話ゲームは(1)意味理解，(2)意図理解，(3)伝達効果，(4)意図生成，(5)応答生成の5段階に分れており，各段階の処理における目標とするタスクの集合および処理の流れを決めるメタルールからなっている．
図[REF_airenti]にAirentiらの提案した会話ゲームを示す．
ここで用いる述語の定義を付録[REF_appendixA]に示す．
これらのプロセスは標準的な処理では(1)から(5)までが順に行われ，いずれかの段階でタスクが達成できなかった場合は，即座に応答生成に行く．
[htbp]
意味理解
if [MATH] then goto意図理解; else goto応答生成
意図理解
if [MATH] then goto心的状態の更新; else goto応答生成
心的状態の更新
if [MATH] then [MATH];
if [MATH] then [MATH];
if [MATH] then [MATH];
goto意図生成
意図生成
if [MATH] then [MATH];
if [MATH] then [MATH];
if [MATH] then [MATH];
goto応答生成
応答生成
not specified
会話ゲームは，基本的に理解から生成に至るまでの1ターンを説明するために用いられたもので，対話全体を管理できるほどには具体化されていない．
また，会話ゲームを対話全体が扱える程度に拡張しようとすると，明確化対話の挿入や応答の省略などの現象を会話ゲームの規則として記述せねばならず，規則の組合わせが手に負えないほどの量になってしまうことが予測される．
一方，行動ゲームは妥当性条件と参加者の行為の集合からなるとされている(図[REF_airenti2])．
しかし，どのような知識表現を用いるか，どのような推論ができるのかが明確にされていないため，意味理解段階において，ある表層発話がその行動ゲームの手となるかどうかの判定に用いられたり，意図理解段階において，ある行為がその行動ゲームの手となるかどうかの判定に用いられたりしており，あやふやな位置付けになっている．
我々は，対話における言語構造に関して，会話ゲーム中の局所的な制約として記述するのではなく，行動ゲームと同様に認知プロセス中から参照されるものとして，言語構造を表現した空間を設定する．
行動ゲームに対応するものを問題解決空間，言語構造を表現したものを会話空間と定義する．
このことによって，各プロセスの処理は比較的単純でありながら，対話の局所的な単位であるやりとりにおけるフェーズの把握や対話全体における問題解決過程の把握ができるモデルとなる．
我々の認知プロセスモデルの概要を図[REF_model]に示す．
さらに我々はこのモデルの各段階において，音声の誤認識への対処が行えるように拡張を行った．
認知プロセスに誤認識への対処法を組み込むアプローチは，発話理解や問題解決構造に組み込む方法に比べて，発話スタイルやタスクへの依存度が少ないので，より一般性のある方法であるといえる．
以後，我々のモデルにおける各段階での処理について，主にAirentiらのモデルをどのように拡張したかという視点から説明する．
Airentiらのモデルにおける意味理解段階の処理は，ゴールとして[MATH]または[MATH]を得ることとしている．
後者は，発話が直接に行動ゲームの手となるような場合(行動ゲームgreetingにおける``Have a nice day.''のような発話)であり，システムとの対話においては例外的であると思われるので，ここでは前者の拡張について議論する．
Airentiらは表層発語内行為(assertive, interrogative, directive)から話者の意味したもの(述語express中の命題)を導き出す規則を明示しているが，自然な音声対話においては述語の省略や代用表現(「〜お願いします」など)がよく用いられるので，表層的な情報だけでは話者の意味したものが特定できない場合が多い．
そこで，対話の局所的な情報を何らかの形式で保持しておき，それを参照しながら意味表現を生成する処理が必要になる．
我々のモデルでは，表層発語内行為と発語内行為との対応規則を用いるのではなく，ロバストパーサの出力として仮定している「全体として整合した部分的な意味表現」を，局所的な対話文脈に位置付けるという方法で意味理解を行っている．
ここで部分的な意味表現とは，キーワード・句・文のそれぞれのレベルで解析できた範囲でロバストパーサが出力する意味表現であり，例えば述語部分の解析に失敗した場合には，句に相当する意味表現が複数出力されることを仮定している．
それが全体として整合しているとは，複数出力された意味表現を組み合わせてひとつの発話の意味表現を構成し得ることを指しており，一文一格の原理を満たさない場合や，従属関係になりえない述語レベルの意味表現が複数ある場合などは全体として整合していないことになり，ロバストパーサの段階で解析失敗となる．
この意味表現を対話文脈に位置付けるという方法は発話には文脈独立な意味表現が存在するという表層発語内行為仮説(literal meaning hypothesis) [CITE]に基づいたものであり，処理は以下の2段階に分割される．
入力発話から，全体として整合した部分的な意味表現を抽出する．
これは表層情報のみから決まるもので，理想的には表層発語内行為と命題内容を導き出す．
その部分意味情報から発語内行為への対話文脈に応じたマッピングを行う．
ここで，(1)の段階が達成されない場合(すなわちロバストパーサによって何も意味表現が生成されない場合)は，応答生成段階に制御を移し，再入力を促す発話を生成する．
(1)の処理をいかに頑健に行うかということはロバストパーサの問題であり本稿では扱わないが，この時点でいかなる誤りも存在しないと仮定するわけではない．
すなわち，表層発語内行為や命題内容を構成する要素の中に音声の誤認識による誤りが含まれている場合でも，これ以降の処理で検出・修復を行う．
例えば(1)の段階の処理としては，個人スケジュール管理タスクにおける「2時から会議を登録して下さい．
」というユーザ[MATH]からシステム[MATH]への発話に対して，その命題内容
register([[start_time, 2], [obj, meeting]])を抽出し，表層発語内行為を組み合わせて，
[MATH]
という命題が共有信念として得られる．
これに続く(2)の処理として，この共有信念からユーザの発語内行為を認識することを目的とする．
発語内行為の認識の前提として，意味理解段階ではまず発語内行為の分類を考える．
発語内行為は大きく働き掛けと応答に分類できるので，ここでは命題内容と表層発語内行為を基にして得られた共有信念から，以下のどちらに分類できる行為であるかを認識し，その表明された内容を共有信念とすることを意味理解段階の目標とする．
ユーザ[MATH]がシステム[MATH]に行為[MATH]をしてほしい([MATH])と表明した(働き掛け)
ユーザ[MATH]が信念[MATH]を持っている([MATH])ということを表明した(応答)
しかし，表層発語内行為には働き掛け／応答の双方の機能と対応するものがあり，また，音声対話によく出現する述語の省略・代用表現によって，この機能を決定するためには対話の局所的な知識が必要となる．
我々のモデルでは[REF_conv]章で述べる会話空間に対して，ここで得られた要素を局所的対話文脈に位置づけるという処理を行うことによって，これらの問題を扱っている．
さらに会話空間では入力発語内行為および命題が，現在維持している対話履歴と整合しているかどうかを判定し，整合していなければ誤認識とみなして応答生成段階に処理を移し，問い返しの応答を生成する．
以上の意味理解段階の処理をまとめると図[REF_step1]に示すようになる．
[htbp]
意味理解
if [MATH]
then goto意図理解;
else goto応答生成
対話において発語内行為を成功させるには，話者の意図と，その意図を伝えようとする意図(伝達意図)とが聴者に理解されることが必要であり，さらにそれらが相互に信念として持たれている必要がある[CITE]．
すなわち，対話において聴者が話者の意図を理解する(あるいは話者の発語内行為が成功する)とは，「話者の意図と，その意図を伝達しようとする意図とを話者と聴者の共有信念とすること」である．
では，ここでは話者の持つ意図はどの程度具体化されているべきであろうか．
対話システムが知的な振る舞いをするためには，対話がタスク構造に従って構造化されており，かつ各副対話が適切にその機能を明らかにされている必要がある[CITE]．
すなわち話者の意図として話者が持つプランが聴者に理解されている状況が望ましい．
よって，意図理解段階の目的は，話者の発語内行為およびプランを認識することとなる．
しかし，対話の初期段階では話者のプランに関して複数の候補が考えられる状況がある．
この場合，どのようにして対話を維持するかについて，異なる対話戦略が考えられる．
例えば，[CITE]においては，プラン候補が複数ある場合に，それらに(1)前提の失敗，(2)順序不整合，(3)より良いプランの存在，(4)欠点なし，のいずれかのラベルを付け，ラベルが同じものに揃うまで詳細化のための副対話を行うアルゴリズムが提案されている．
この手法はシステムが扱うプランが多数ある場合に有効であると考えられるが，必ずしも全てのタスクが副対話生成による冗長性をカバーするほどの数のプラン候補を持つとは限らない．
Airentiらのモデルにおいては，この段階で相手の行動ゲームが認識されなければ応答段階に処理を移すことになっている．
これは，相手の発話によって行動ゲームが唯一に同定されなければ，その発話内容を無視して行動ゲームの同定を行うための発話を生成することを意味するので，協調的なシステムの振る舞いとしては適当ではない．
我々は，冗長な詳細化用副対話やユーザ発話を無視した副対話の生成を避けるために，プランが唯一に特定できなければ，表層的なやりとり規則で対話を維持し，漸進的にプランを認識する方法を提案している[CITE]．
対話の初期段階，すなわちプランがまだ共有信念になっていない段階では，相手の発語内行為の意図に加えて，話者のプランを伝えようとする意図([MATH])を共有信念とするよう試みる．
ここで，話者のプランを伝達しようとする意図を共有信念とすることができれば，心的状態の更新に進む．
プラン認識の方法は[REF_prob]章で説明する．
一方，プランが認識できなかった場合は，会話空間上で典型的なやりとりを構成するような展開を行って，意図生成に進む．
ここで典型的なやりとりとは，相手の発話と，その発話に含まれる情報のみで対応できる応答からなるものであり，質問に対する回答や情報伝達に対する受諾などの発話対からなるものである．
一方，プランがすでに共有信念になっている場合は，その実行のステップとなる行為または情報を伝えようとする意図([MATH])を共有信念とする．
意味理解段階の処理をまとめると図[REF_step2]に示すようになる．
[htbp]
意図理解
if [MATH]
then goto心的状態の更新;
else goto意図生成
この段階では意図理解の結果に基づいて，必要があれば心的状態を更新する．
ここでの処理はAirentiらのモデルと同様である．
意図理解で新たにプランが認識された場合は，以下の(1)の処理を行いながら，入力発話に応じて(2)または(3)の処理を行う．
既にプランを意図している場合は，(2)または(3)の処理を行う．
ここでの推論は対話エージェントとしての協調原則[CITE]に基づいたものである．
(1)および(2)は入力されたプランや行為の要求を処理するという意味でattentiveness constraintを実現したものであり，(3)は共有知識の食い違いを最小限にするshared knowledge preferenceを実現したものである．
話者の意図があるプランを提示するものであれば，そのプランが達成不可能でなければ(問題解決空間においてそのプランを達成するのに必要な分割リンクのうち，達成不可能であることが判明しているものがなければ)，そのプランを意図する
([MATH])．
話者の意図がある行為をすることであれば，その行為が何らかの役割を果たすものであり(その行為と認識済みのプランが分割リンクを介して繋がっている)，かつ達成不可能でなければ，その行為を意図する([MATH])．
話者の意図がある信念を表明するものであり，自分がそれと矛盾する信念を持っていなければ，その信念を保持する([MATH])．
これらの処理を行った後，意図生成に移る．
心的状態の更新段階の処理をまとめると図[REF_step3]に示すようになる．
[htbp]
心的状態の更新
if [MATH] then [MATH];
if [MATH] then [MATH];
if [MATH] then [MATH];
goto意図生成
ここで得られた命題は，以後の発話の処理に用いる．
共有信念として持ったゴールについては，それを達成することを対話の目標とし，目標達成に関連する命題については，これと矛盾する命題がユーザによって言及された(すなわち現在の発話または過去の発話のどちらかに認識エラーが存在した)ことを検出するのに用いられる．
ここでは意図理解の結果と心的状態の更新の結果から，次にどのような意図を持つべきかを決める．
この段階では，我々のモデルはAirentiらのモデルの詳細化と位置付けられるが，その詳細化はAirentiらのモデルでは考慮されていなかった認識誤りに基づく誤解の解消に役立つ発話の生成に寄与するものである．
具体的には，相手のプラン・働き掛け・応答が受け入れられないときに，その根拠となる命題を心的状態および問題解決空間で探索し，相手の発話内容の問い返しとともに，受け入れられない根拠を応答として述べることによって対話参加者間の信念の違いを明示するものである．
この信念の違いが認識誤りによって生じた場合は，それを修正する副対話が生成される．
我々のモデルにおける意図生成は以下の規則に従って行われる．
ユーザのプランを認識した場合
心的状態の更新段階において，プランを遂行するという意図を持った場合，(2)の処理に移り，ユーザの働き掛けに応じた意図を生成することによって暗にプランを意図することを示す([MATH])．
心的状態の更新において，プランを受け入れない(プランは認識できたがそれを意図しない)と決めた場合は，システムの知識の中にそのプランを達成不能にするものがある場合なので，システムはプランを受け入れないことを明示的に示すと共に，そのプランの障害になっている命題をユーザに伝える．
([MATH])
あるプランを認識しそれを遂行するという意図を持った場合(あるいは既にプランが認識されている場合)，ユーザの働き掛けに応じて意図を生成する．
ユーザの働き掛けが情報要求ならば，検索結果をユーザに応答する意図([MATH])を持つ．
ユーザの働き掛けが行為要求ならば，その行為が達成可能であるかどうかを問題解決空間で調べる．
行為が達成可能である場合，その行為を遂行し，さらに問題解決空間を探索し，そのプラン遂行に役立つ新たな行為[MATH]を行う意図を伝達する意図([MATH])を持つ．
新たな行為[MATH]の決定に関しては[REF_prob]章で述べる．
提案された行為が達成不可能であるか，または共有されているプランのステップではない場合は，その行為を行わないということと，その理由を示す命題を伝える意図([MATH])を持つ．
ユーザ発話が信念を表明するものである場合
システムが表明された命題[MATH]と矛盾する命題を持っていなければ，その命題はシステムの信念となり，そのことは明示的に示さなくてもよく，新たなステップとなる行為[MATH]を行う意図を伝達する意図([MATH])を持つ．
表明された命題[MATH]を信じないのなら否定応答をすると共に，システムが持っているそれと矛盾した命題[MATH]を伝える意図([MATH])を持つ．
意図生成段階の処理をまとめると図[REF_step4]に示すようになる．
[htbp] 意図生成
if [MATH]
then ([MATH];
if [MATH]
then [MATH];  if [MATH]
then [MATH];
goto応答生成
[CITE]では応答生成は例示に止まっている．
我々は，応答生成を起動された処理段階および伝達意図の違いによって異なったテンプレートを用いることによって実現している．
意味理解処理の失敗によって起動された場合は単なる問い返し(「もう一度言ってください」)を生成する．
意図生成から起動された場合は，表[REF_step5]に示すそれぞれの伝達意図に対応するテンプレートを用いて，応答文を生成する
[htbp] \centering
これまでに述べた認知プロセスモデルにおいて，発語内行為の理解，省略・参照表現の処理，および相手の発話に対する適切な応答発話の生成のために，会話が現在までどのように進んできたかを管理する機構が必要となる．
従来の対話モデルでは，これら(またはその一部)の処理を行うためにスタックを用いることが多かった．
例えば，Groszらのモデルでは焦点管理のために，対話のある時点でもっとも顕著な対象・属性・対話セグメントの目的をスタックを用いて管理している[CITE]．
しかし我々は，スタックの利用は以下の理由で音声対話システムには適さないと考える．
Groszらのモデルでは対話が入れ子構造をなすことを前提としてスタックを用いているが，自然な対話では入れ子が必ずしも明確になるわけではない．
音声の誤認識による誤解の修正の際には，対話履歴の任意の時点の情報が必要になるが，既にスタックからポップされた情報には原則としてアクセスできない．
我々のモデルでは会話レベルの最小単位としてやりとりを想定し，このやりとりを管理することによって，発話の対応付けを行う．
やりとりは，基本的に「働き掛け」と，その働き掛けに対する「応答」からなる．
ただし，詳細化対話や音声の誤認識の修復のために，応答の前または代りに働き掛けおよびそれに対する応答が挿入される場合もある．
このやりとり単位の管理と，そのやりとりによって達成された行為を4章で説明する問題解決空間で管理することによって，明示的な入れ子構造を用いずに，対話の流れを追跡できる．
また，参照の解釈・省略発話の解析・誤認識による誤解の解消のために，対話に現れた句レベルの情報から，発話レベルの情報，やりとりレベルの情報を階層的な動的ネットワークを用いて管理する．
この動的ネットワークを会話空間と呼ぶ．
会話空間にはフレーズノード，インスタンスノード，スロット充足ノードの3種類のノードを設定する．
インスタンスノードとスロット充足ノードは，ほぼCharniakらの定義[CITE]に従っている．
基本的にリンクは，両端のノードが表す命題間の因果関係を条件付き確率の行列を用いて表現できるようになっている．
各インスタンスノードはスロット充足ノードを経由して結合される．
ただし，フレーズノードは直接対応するインスタンスノードに結合される．
会話空間の構成要素の関係の例を図[REF_cs]に示す．
会話空間は意味理解段階と以下のような相互作用を行い，意味表現を生成し，対話の履歴を管理する．
意味理解段階からの入力は全体として整合した部分的な意味表現で，出力は発語内行為である．
意味理解の結果として得られた命題表現の中で句に相当する部分をフレーズノードとして，会話空間に導入する．
フレーズノードが意味理解で，どのような概念のインスタンスとして生成されたかを示す句レベルのインスタンスノードを生成し，フレーズノードとリンクを張る．
(2)で生成された句レベルのインスタンスノードが，発話の中でどのような役割を果たすか(構文的な意味では格に相当する)を示すスロット充足ノード，およびそれらをまとめる発話レベルのインスタンスノードを生成し，それぞれリンクを張る．
(1)で生成された発話レベルのインスタンスノードが，やりとりの中でどのような役割を果たすかを示すスロット充足ノード，およびそれらをまとめるやりとりレベルのインスタンスノードを生成し，それぞれリンクを張る．
ここまでの処理が達成されると，やりとりの中での役割を入力発話の発語内行為として出力する．
このように会話空間という形式で対話に現れた情報を管理することによって，Groszらが焦点として扱った対象・属性・対話セグメントの目的のみではなく，やりとりに現れた全ての要素を，処理対象としている発話のインスタンスノードからの距離(パスの長さ)をコストとして用いることにより優先度を付けて，誤認識による誤解の解消や省略・参照表現の処理に用いることができる．
プランが同定されるまでの対話の初期段階のやりとりや，問題解決に関係のない誤認識の修復のやりとりなどは，心的状態の更新を経ずに意味理解段階で得られたやりとりに関する情報を使って行う．
このようなやりとりは意図理解段階の処理の失敗(プラン認識の失敗および誤解の検出)によって起動される．
プラン認識の失敗の場合は，会話空間中で現在展開中のやりとり単位を継続させる発語内行為を意図生成段階へ出力する．
また，誤解が検出された場合は，修復の副対話をやりとり内に挿入し，修復発話に対応する発語内行為を意図生成段階へ出力する．
生成された発話意図から応答文を生成する際に，同じやりとりを構成する発話であれば，展開された意味表現から主題格などを省略する．
入力としては全ての要素が列挙された意味表現，出力は応答として出力するのに適切な省略を行った意味表現である．
我々のモデルでは，問題解決空間と呼ぶネットワーク構造の知識表現を用いて，タスクレベルの対話管理を行っている．
問題解決空間はタスクにおけるプランとサブプランの関係や，プランとそれを達成するための行為との関係を記述した静的ネットワークである．
本稿で説明に利用するタスクである個人スケジュール管理を行うシステムに対応した問題解決空間の例を図[REF_event]に示す．
問題解決空間では，葉ノードが行為を表し，それ以外のノードがプランを表す．
リンクは2種類あり，プランの間の抽象関係を表現する抽象化リンク(図[REF_event]の上向き太矢印)と，プランからサブプランや行為への分割を表す分割リンク(図[REF_event]の下向き細矢印)がある．
またプランの分割にはAND分割(下向き細矢印をまとめる記号のついたもの)とOR分割がある．
意図理解段階では話者のプランを認識するために，意味理解段階で得られた発語内行為を問題解決空間に渡し，プラン認識を行う．
問題解決空間におけるプラン認識には最小被覆法[CITE]を適用する．
この手法は基本的には，問題解決空間において既に実行された(または観測された)行為の全てを含むサブグラフを求めるものである．
問題解決空間のプランを表すノードの中で，各々のタスクにおける基本的なプランすなわち，1まとまりの対話によって達成されるプランをエンドイベントと呼ぶ．
ユーザが1対話において，プランを1つしか持たないという前提に立てば，プラン認識の問題はエンドイベント集合から，ユーザの持っているプランに対応する要素を1つ選ぶことになる．
問題解決空間では，意味理解結果として得られたユーザの行為を入力として，新たに入力された行為と以前に入力された行為をカバーするプランを最小被覆法を用いて認識し，プランが認識された場合はそのプランを，プラン認識に失敗した場合はそのことを意図理解段階に出力する．
発話生成段階においては，問題解決空間には意図生成段階からのユーザの行為と，更新された心的状態が入力される．
もし，ユーザの行為が情報要求であれば，データベース検索を行ってその値を答えるという処理が意図生成段階でなされるが，それ以外の場合はユーザの行為に応じて，次のシステムの行為をAND-OR木上の未達成の行為ノードとして探索し，意図生成段階に出力する．
本章では，対話モデルの各段階での処理，および会話空間・問題解決空間での処理を例によって説明する．
個人スケジュールを管理するシステム[MATH]とユーザ[MATH]との対話例を図[REF_example]に示す．
まず前提として，表層発語内行為及び命題内容の抽出はここでの対話モデルで扱う問題の対象外と想定しているので，U1に対して
という表層意味表現が得られるものとする．
これに対して，まず意味理解段階の処理としては，対話の初期状態で会話空間に何も対話履歴がない状態であることと，入力発話がdirectiveという表層発語内行為を持つことから，これをユーザの働き掛けと解釈し，
という共有信念が形成され，意味理解段階の処理が成功したことになるので，処理を次の意図理解段階に進める．
ここまでの処理を表[REF_ex-table1]に示す．
[htbp] \centering
ただし，会話空間はインスタンスノードのみの列挙
次に，意図理解段階の処理としてはユーザのプランがまだ共有信念になっていないので，
[MATH]をプラン達成のための1ステップとするようなプランが存在するかどうかを問題解決空間で探索する．
ここではregister_meeting_planが唯一に定まるので，ユーザの伝達意図として以下の2つの共有信念が形成される．
ここまでの処理を表[REF_ex-table2]に示す．
[MATH](3)
心的状態の更新の段階では，意図理解で新たにプランが認識されたので，このプランにシステムとして合意するか，また，ユーザの意図する行為を行うかどうかを決め，その結果をシステムの心的状態に反映させる．
ここでは，問題解決空間のregister_meeting_plan以下の行為ノードの中で，達成不可能であることがわかっているものがないことを確認し，このプランを意図する．
また，[MATH]がこのプラン達成のための行為であることから，これを実行することを意図する．
すなわち，ここで以下の命題をシステムの心的状態に新たに導入する．
ここまでの処理を表[REF_ex-table3]に示す．
次に，意図生成段階の処理としては，プランに合意し，ユーザの意図した行為が達成可能である場合であるので，2.6節で説明した(2-b-1)の処理を行う．
ここで，問題解決空間のregister_meeting_plan以下を探索し，新たな行為[MATH]として終了時刻の同定を選び，その達成を意図する．
ここまでの処理を表[REF_ex-table4]に示す．
次に，応答生成段階の処理としては，テンプレート[MATH]を利用して，ユーザに情報伝達行為inform_refを意図させるために，S2の質問文を生成する．
ここまでの処理を表[REF_ex-table5]に示す．
次に，述語の誤認識が生じたU3の解析例を説明する．
述語の誤認識によるエラーは，意味理解では検出できない場合がある．
その時点までの対話の文脈からして不適当な発語内行為が入力されたことが意図理解段階によって検出されて，その修復のためのやりとりがこの会話空間上で展開される．
ここまでのやりとりの展開はU1:「働き掛け」，S2:「働き掛け」となっており，会話空間上でのやりとりのパターンから，U3の発話はS2の働き掛けに対する応答またはそれに関連した働き掛けが予測されている．
しかし，U3を意味理解した結果
は，このどちらにも相当せず，述語の誤認識が起こったことが考えられる．
そこで会話空間上に修復のやりとり(S4-U5)を展開する．
ここで修復が成功したので，U3は改めて
と解釈され，以下，
意味理解: [MATH]
意図理解: [MATH]
意図生成: [MATH]
と処理され，応答発話S6が生成される．
U3の処理で示した例は述語のエラーに対処するものであった．
一方，内容語のエラーは，同一範疇の語と置換した場合は対話文脈を参照しないと検出されない場合が多い．
ここでは，問題解決空間における処理で検出可能な内容語のエラーが生じたU7の処理について説明する．
ここまでの問題解決空間の処理で，U1でユーザプランが明示されていることから，プラン認識は成功している．
その場合，それ以降の問題解決空間の役割はやりとりがそのプランを達成するためのサブプラン達成を目的とするものか，またそのサブプランが所定のインスタンスで達成可能なものかを判定することである．
S6の発話によって，場所の設定というサブプランに「小会議室」をインスタンスとして達成を試みるが，失敗したとする．
そこでこれに対応した意図生成(2.6節の(2-b-2)の場合)を行い，エラー訂正のやりとり(S8-U9)が生成される．
問題解決空間におけるこのような処理によって，内容語の誤認識にも対処できるようになっている．
