さらに，音声対話システムに適用する対話モデルには，音声の誤認識によるエラーに対処する機能が不可欠である．従来研究の多くは発話単位でのロバストな解析を実現することに目標が置かれ[CITE]，いくつかの例外を除いては，対話システムに入力される発話または意味表現はユーザの意図したものであることが前提になっていた．しかし，ある単語が同一カテゴリーの単語と置き換わった場合や選択格に関する情報が欠落していた場合などは，ロバストな解析では対処できないので，対話レベルでの対処が必要となる．

以上の議論より，我々は音声対話システムのための対話モデルとして，逐次的なモジュール結合による発話理解・生成機構，言語構造と意図構造とを区別した対話管理機構，それら相互の密接な情報のやりとりによる頑健な処理の実現が必要であると考えた．

本稿で提案するモデルは，(1)[CITE]で提案された伝達行為理解のプロセスモデルを音声対話システムに適用可能なレベルまで具体化し，(2)それらと言語構造を表現した会話空間，意図構造を表現した問題解決空間とのやりとりを規定し，(3)個々のプロセスで同定可能な誤りへの対処法を網羅的に記述したものである．このモデルを実装することによって，ある程度のエラーにも対処できる協調的な音声対話システムの実現が期待できる．以後本稿では，我々のモデルに関して発話理解・生成機構，会話レベルの管理機構，問題解決レベルの管理機構について順に説明し，最後に動作例を示す．

paragraph score: 1.07921467159392
