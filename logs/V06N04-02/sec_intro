本稿では，音声を用いて人間と機械が対話をする際の対話過程を，認知プロセスとしてとらえたモデルを提案する．
対話システムをインタラクティブに動作させるためには，発話理解から応答生成までを段階的に管理する発話理解・生成機構と，発話列をセグメント化し，焦点および意図と関連付けて構造的にとらえる対話管理機構とが必要である．
さらに，入力に音声を用いた音声対話システムでは，音声の誤認識によるエラーを扱う機構を組み込む必要がある．
これらの機構は従来，比較的独立して研究されてきた．
発話理解から応答生成までを通してモデル化したものに関しては，大きく分類して並列マルチエージェント(およびそれに付随する分散データベース)によるモデル[CITE]と，逐次的なモジュールの結合によるモデル[CITE], [CITE]とが提案されている．
並列マルチエージェントモデルは様々なレベルの制約を同時に発話理解・生成に用いているという人間の認知プロセスのモデル化になっているが，制御の難しさ・確実な動作保証の難しさから，対話システムの実現には逐次的なモジュール結合方式がよく用いられている．
逐次的なモジュール結合方式において，音声対話システムに不可欠な発話の柔軟な解釈や次発話の予測を行うためには，個々のモジュールが常に参照できる情報を集中的に管理する対話管理機構が必要になる．
対話管理機構に関して，Groszらは言語構造・意図構造・注意状態の3要素に分割してモデル化を行っている[CITE]．
言語構造をとらえる方法としては，スタックによるモデル化[CITE], [CITE], [CITE]とAND-OR木によるモデル化[CITE], [CITE], [CITE]がある．
スタックによるモデル化は実現しやすく，注意状態との関係が明確であるという利点を持つ．
しかし，入れ子構造をなさないような副対話が生じた場合にその管理が難しい．
また，ユーザから主導権を取る発話(典型的にはユーザの誤った知識・方略を協調的に修正する発話)を生成した場合には，いくつかのスタック要素のポップを伴うことが多く，ユーザが主導権を改めて取ろうとしたときに必要な情報がスタックから消えているという状況が生じる．
また，原則としてスタックからポップした情報にはアクセスできないので，音声の誤認識による誤解を(しばらく対話が進んだ後で)修正する必要のある音声対話システムに用いるには適していない．
一方，AND-OR木によるモデル化は，基本的にタスクの問題構造の記述であり，Groszらの言語構造と意図構造とを混同してしまっているので，タスクの問題構造に従わない対話(例えば詳細化対話やシステムの能力に関するメタ的な質問など)は特別に扱わなければならないという欠点を持つ．
これらのことを考え合わせると，音声対話に適した対話管理は，焦点とする範囲を適当に絞りながらも過去の対話履歴にアクセスする可能性を残した方法を用いて，言語構造と意図構造を区別して管理する必要があるといえる．
[CITE]では言語構造と意図構造とを区別してモデル化し，これらを会話ゲームと行動ゲームと呼んでいる．
しかし，それぞれのゲームがどのように表現されるかについては部分的にしか示されておらず，音声対話システムを構成するには不十分であるといえる．
さらに，音声対話システムに適用する対話モデルには，音声の誤認識によるエラーに対処する機能が不可欠である．
従来研究の多くは発話単位でのロバストな解析を実現することに目標が置かれ[CITE]，いくつかの例外を除いては，対話システムに入力される発話または意味表現はユーザの意図したものであることが前提になっていた．
しかし，ある単語が同一カテゴリーの単語と置き換わった場合や選択格に関する情報が欠落していた場合などは，ロバストな解析では対処できないので，対話レベルでの対処が必要となる．
以上の議論より，我々は音声対話システムのための対話モデルとして，逐次的なモジュール結合による発話理解・生成機構，言語構造と意図構造とを区別した対話管理機構，それら相互の密接な情報のやりとりによる頑健な処理の実現が必要であると考えた．
本稿で提案するモデルは，(1)[CITE]で提案された伝達行為理解のプロセスモデルを音声対話システムに適用可能なレベルまで具体化し，(2)それらと言語構造を表現した会話空間，意図構造を表現した問題解決空間とのやりとりを規定し，(3)個々のプロセスで同定可能な誤りへの対処法を網羅的に記述したものである．
このモデルを実装することによって，ある程度のエラーにも対処できる協調的な音声対話システムの実現が期待できる．
以後本稿では，我々のモデルに関して発話理解・生成機構，会話レベルの管理機構，問題解決レベルの管理機構について順に説明し，最後に動作例を示す．
本稿では，音声を用いて人間と機械が対話をする際の対話過程を，認知プロセスとしてとらえたモデルを提案する．
対話システムをインタラクティブに動作させるためには，発話理解から応答生成までを段階的に管理する発話理解・生成機構と，発話列をセグメント化し，焦点および意図と関連付けて構造的にとらえる対話管理機構とが必要である．
さらに，入力に音声を用いた音声対話システムでは，音声の誤認識によるエラーを扱う機構を組み込む必要がある．
これらの機構は従来，比較的独立して研究されてきた．
発話理解から応答生成までを通してモデル化したものに関しては，大きく分類して並列マルチエージェント(およびそれに付随する分散データベース)によるモデル[CITE]と，逐次的なモジュールの結合によるモデル[CITE], [CITE]とが提案されている．
並列マルチエージェントモデルは様々なレベルの制約を同時に発話理解・生成に用いているという人間の認知プロセスのモデル化になっているが，制御の難しさ・確実な動作保証の難しさから，対話システムの実現には逐次的なモジュール結合方式がよく用いられている．
逐次的なモジュール結合方式において，音声対話システムに不可欠な発話の柔軟な解釈や次発話の予測を行うためには，個々のモジュールが常に参照できる情報を集中的に管理する対話管理機構が必要になる．
対話管理機構に関して，Groszらは言語構造・意図構造・注意状態の3要素に分割してモデル化を行っている[CITE]．
言語構造をとらえる方法としては，スタックによるモデル化[CITE], [CITE], [CITE]とAND-OR木によるモデル化[CITE], [CITE], [CITE]がある．
スタックによるモデル化は実現しやすく，注意状態との関係が明確であるという利点を持つ．
しかし，入れ子構造をなさないような副対話が生じた場合にその管理が難しい．
また，ユーザから主導権を取る発話(典型的にはユーザの誤った知識・方略を協調的に修正する発話)を生成した場合には，いくつかのスタック要素のポップを伴うことが多く，ユーザが主導権を改めて取ろうとしたときに必要な情報がスタックから消えているという状況が生じる．
また，原則としてスタックからポップした情報にはアクセスできないので，音声の誤認識による誤解を(しばらく対話が進んだ後で)修正する必要のある音声対話システムに用いるには適していない．
一方，AND-OR木によるモデル化は，基本的にタスクの問題構造の記述であり，Groszらの言語構造と意図構造とを混同してしまっているので，タスクの問題構造に従わない対話(例えば詳細化対話やシステムの能力に関するメタ的な質問など)は特別に扱わなければならないという欠点を持つ．
これらのことを考え合わせると，音声対話に適した対話管理は，焦点とする範囲を適当に絞りながらも過去の対話履歴にアクセスする可能性を残した方法を用いて，言語構造と意図構造を区別して管理する必要があるといえる．
[CITE]では言語構造と意図構造とを区別してモデル化し，これらを会話ゲームと行動ゲームと呼んでいる．
しかし，それぞれのゲームがどのように表現されるかについては部分的にしか示されておらず，音声対話システムを構成するには不十分であるといえる．
さらに，音声対話システムに適用する対話モデルには，音声の誤認識によるエラーに対処する機能が不可欠である．
従来研究の多くは発話単位でのロバストな解析を実現することに目標が置かれ[CITE]，いくつかの例外を除いては，対話システムに入力される発話または意味表現はユーザの意図したものであることが前提になっていた．
しかし，ある単語が同一カテゴリーの単語と置き換わった場合や選択格に関する情報が欠落していた場合などは，ロバストな解析では対処できないので，対話レベルでの対処が必要となる．
以上の議論より，我々は音声対話システムのための対話モデルとして，逐次的なモジュール結合による発話理解・生成機構，言語構造と意図構造とを区別した対話管理機構，それら相互の密接な情報のやりとりによる頑健な処理の実現が必要であると考えた．
本稿で提案するモデルは，(1)[CITE]で提案された伝達行為理解のプロセスモデルを音声対話システムに適用可能なレベルまで具体化し，(2)それらと言語構造を表現した会話空間，意図構造を表現した問題解決空間とのやりとりを規定し，(3)個々のプロセスで同定可能な誤りへの対処法を網羅的に記述したものである．
このモデルを実装することによって，ある程度のエラーにも対処できる協調的な音声対話システムの実現が期待できる．
以後本稿では，我々のモデルに関して発話理解・生成機構，会話レベルの管理機構，問題解決レベルの管理機構について順に説明し，最後に動作例を示す．
