関連研究

テキストマイニングにおいて，クラスタリング，分類，情報抽出の研究は多数存在する(Berry 2004, 2008)．

文書の数学的表現としては，ベクトル空間法(Vector Space Model) が広く用いられている．多次元空間のベクトルを特徴量に用いるというもので，その歴史は古く (Salton 1975) で提案されている．クラスタリングに用いられる文書‐単語行列は，その自然な拡張である．

単語の表層文字列を素性として扱うような多次元空間では，個々の単語の出現頻度が低く，疎性 (Sparseness) の問題を引き起こす．この問題に対処するために，類義語処理の研究が多数存在しており，次元圧縮としてのLSI法 (Deerwester 1990)，トピックモデルとしてのpLSI法 (Hofmann 1999)，ベイズ推定を用いたLatent 
Dirchlet Allocation法 (Blei 2003) が代表的である．

クラスタリングに特異値分解や主成分分析を用いる場合の心得は，(Kobayashi 2004) に詳しい．

LSI法の数学的な基礎付けとなる特異値分解は，反復法による数値計算で行われる．大規模な疎行例のための実装には，(Dongarra 1978) や (Anderson 1999) がある．

分類問題に対する機械学習の方法としては，線形判別分析 (Fisher 1936)，サポートベクターマシン (Cortes 1995) が代表的である．本研究では，統計処理言語Rによる実装 (Karatzoglou 2004) でのサポートベクターマシンを用いる．抽出器の作成には，多クラス分類器 (Crammer 2000; Karatzoglou 2006) を用いて，2つの手法を比較する．1つは，サポートベクターマシンの事後確率を計算する方法 (Platt 2000; Lin 2007; Karatzoglou 2006) で，閾値を超える事後確率を持つクラスが存在する場合に抽出する (Manning 2008)．もう1つは，1-クラス分類 (Sch\"{o}lkopf 1999; Tax 1999; Karatzoglou 2006) である．

言語処理学会2012年度全国大会では，災害時における言語情報処理というテーマセッションで11件の発表があった．そこには，効率的な情報抽出という観点から， 
(Neubig 2012)や(岡崎 
2012)の研究がある．本研究は，クラスタリングによって分類カテゴリの決定をするところから始めるという点で，特定の種別の情報を抽出するこれらの研究とは異なる．

東日本大震災時にSNSが果たした役割については (小林 2011), (立入 2011)が刊行されている． (片瀬 2012), (遠藤 2012)でも指摘されているように，今後の震災時にSNSが取材情報源として担う役割は大きいものと思われる．なお，当時のメディアについては，(片瀬 2012), (稲泉 2012), (遠藤 2012), (福田 2012), (徳田 2011)に詳しい．



