情報抽出器を作成するまでには，第1章の図1にあるように，全体把握，抽出対象データの策定・特徴把握，情報抽出というおおまかに3つの段階を経た．
以下，それぞれについて詳しく述べる．
本研究の最終目標は，所望する情報を含むターゲットツイートを抽出する情報抽出器を作成することであるが，そのためには，そのターゲットツイートの持つ特徴をつかむことが必要である．
その作業は，そもそもどのような種類のツイートが存在するかを知り，たとえ望ましいまとまりではなかったとしても，実際に形成されたツイート群を見てみることから始まる．
つまり，ターゲットデータの抽出のためには，それに先立ち全体傾向を把握すること，すなわちクラスタリングが非常に重要なのである．
近年，SNSというメディアの急速な発展に伴って，そこでの発言の解析に関する研究もにわかに脚光を浴びてきている．
書き言葉の解析が従来の言語処理のメインターゲットであったのに対し，話し言葉に近いSNSでの発言を解析することは，新たな研究課題を含んでいるからである．
今回はそのような言語処理の課題に加え，1.7億というボリュームゆえの大規模データ処理としての課題も顕在化した．
大規模なデータを扱う場合，特定の観点を定めて，それに特化した分析を行うという方法もあるが，我々は始めから特定の観点に限定せずに分析を行いたかったため，ランダムサンプリングを行って全体を把握することにした．
サンプリングを行うことで，核心的な個々のツイートを見逃す可能性もあるが，全体を把握する場合は，出現頻度の多いものからとりかかり，その後細部に踏み込んでいくという過程をたどるため，ランダムサンプリングを行うことが自然，かつ効果的である．
また，本来“つぶやき”であるものの中から，震災時の状況把握に意味のあるツイートに効率的に接触することを目指し，“拡散させることを目的としている”すなわち“伝える意思が明確である”「拡散希望」ツイートに着目した．
実際のところ，キーフレーズ検出を行って検出されたものの中に多数の「拡散希望」ツイートが見られ，震災時に「拡散希望」ツイートが多く出回っていたことも確認されている．
1%ランダムサンプリングを行った上で「拡散希望」ツイートに限定したとはいえ，震災対応初動期間の72時間を含む11〜14日に限定しても，分析対象のツイートは3万件以上あり，全て人手で分類するには30人日程度かかることが見積もられた．
このため，何らかの自動処理が必要となったのであるが，この時点ではまだどのような分類項目が存在するかもわからず，加えて時間の経過とともに分類項目が変わっていくことが予想されたため，1日分ずつ分析対象のツイートのクラスタリングを行うことにした．
3.1.1.1「拡散希望」ツイートの特徴
「拡散希望」ツイートには次に挙げる2つの特徴があり，結果的に「拡散希望」に限定したサンプルツイートは，震災時の膨大なツイートの概観を得るのに非常に有効であった．
\hangafter=1\hangindent=4zw\hbox to4zw{特徴1：\hss}基本的には転送を利用して拡散させるため，元ツイートの完全なコピー（公式リツイート）あるいはコピーにオリジナルのコメントを加えたもの（非公式リツイート）が多い
\hangafter=1\hangindent=4zw\hbox to4zw{特徴2：\hss} ``拡散させたい＝人々にきちんと伝えたい''という意識で書かれているため，一般的なツイートよりも``書き言葉''寄りで書かれており，スラングや未知語，単語の省略などが比較的少ない．
よって，形態素解析における未知語，形態素区切り誤り，品詞誤りも少ない
特徴1に関して，今回はリツイートを予め除外しておくことを敢えて行わなかった．
リツイートの大きさも一つの情報であり，一つの作業で量と内容を合わせて概観を得るには前もってリツイートのまとめあげを行わない方が適切であると考えたからである．
特徴2に関して，3月11日の地震発生後からランダムサンプリングした，「拡散希望」だけからなるツイート100件と「拡散希望」を含まないツイート100件を調べたところ，前者では全6,909形態素中，区切り誤りが13件，品詞誤りが22件あり，後者では全3,673形態素中，区切り誤りが27件，品詞誤りが33件見つかった．
本研究では一貫して文書‐単語行列が用いられる．
この文書‐単語行列は，文書（ツイート群）に対しMeCabによって形態素解析を行った後，各文書における単語1-gramの出現頻度をベクトル空間表現に基づいて作成したものである．
続いてこの特徴量ベクトルに対し，キーワードらしさの重みづけに用いられるtf-idfの指標への変換，特異値分解などの処理を行う．
これらの文書‐単語行列に対して行う工夫については，第4章においてもう一度説明する．
大規模なデータから作成された文書‐単語行列は，一般的に大規模疎行列になる傾向があるが，本研究では，大規模疎行列に特化したアルゴリズムを用いることなく，一般的な特異値分解のアルゴリズムで事足りた．
本研究では，解析および実験を，統計処理言語Rの標準または一般に入手可能なパッケージに含まれる関数によって行った．
表1に，本研究で使用したRのパッケージ名，関数，オプションの一覧を，表2に，用いた計算環境を示す．
クラスタの粒度を任意に設定できる階層型クラスタリングは樹形図（デンドログラム）を用いて視覚的に表現される．
根元（図2の最上部分）には全てのデータが含まれ，次第に分かれて末端は全てのデータが自分自身のクラスタを形成する．
適当な高さ（図2破線）で枝刈りをすることで，切断された枝の切断部分より末端に連なるデータがまとまって1つのクラスタを形成すると解釈する（図2の●または○）．
本研究ではユークリッド距離とウォード法を用いてクラスタリングを行った．
枝刈りは，クラスタ数が文書数の1/2乗になる場所で行うように設計した．
ウォード法を用いると比較的チェイニング現象が起きにくいとされているが，著者の経験では，どのような距離関数やクラスタの組み上げ法を採用しても，多かれ少なかれチェイニング現象に遭遇することとなる．
チェイニング現象とは，根元から見て，その後更に分かれることの無い比較的小さいクラスタが次々と分離していき，枝刈りを行った際に，ボリュームが大きく特徴を見出しにくいクラスタ（図2の○印）が残る現象である．
東日本大震災の「拡散希望」ツイートをクラスタリングして顕著だったのは，分離したクラスタのうち，クラスタ内が同じツイートを元とするリツイート群となっているものが多かったことである．
リツイート群は出現単語とその頻度が非常に似ており文書ベクトルの距離が近いため，先に分離してクラスタを形成するためと思われるが，逆にこのリツイート群が取得できたことで，人手による分類の確認・修正を行う際，人が見るべきツイートが減ること，また，あるツイートに対する非公式リツイートを含むリツイートの大きさを把握することが可能となること，という2つのメリットがもたらされた．
リツイートの多さがチェイニング現象の原因であることも考えられたため，図2に示している3月11日の「拡散希望」ツイート1%サンプリング10,494件のうち全くリツイートを含まない（ツイート本文中に文字列``RT''を含まない）ツイート667件に対し，同じ手順で階層クラスタリングを行った．
その結果，最も大きなクラスタに542ツイート（全体の81%）が集まるという同様の現象が認められた．
リツイートを除かない場合は10,494件中3.275件(31%)が最大クラスタに集まっている．
クラスタリングにおいてチェイニングが起きる理由は必ずしも明確ではない(Jain 1999)が，特徴量の設計が不適切で，分類を行う際に弁別能力を持つように文書間の距離を決めらなかった，あるいは階層クラスタリングを行う際の探索アルゴリズムにおいて，得られた解が局所最適解であった，などが原因として考えられる．
本研究では，探索アルゴリズムの設計には踏み込まず，統計処理言語Rに用意されている既存のボトムアップ型クラスタリングの関数を利用し，特徴量の設計または用いる距離関数の選択を上手に行い，精度のよいクラスタリング結果を得ることを目指した．
3.1.3.1階層クラスタリングの繰り返し
「拡散希望」ツイート1%サンプリングの全分類を目標とし，自立語に限定した単語1-gramを特徴量とする文書‐単語行列を作成，クラスタリングを行った．
クラスタリングにはベクトル空間表現におけるユークリッド距離を採用し，クラスタ間距離の計算にはウォード法を，クラスタリングアルゴリズムはボトムアップ型（組み上げ法）の階層クラスタリングを採用した．
その後，所属文書数が少ない，または文章が短く語彙が少ないクラスタについて，中身を1ツイートずつ確認し，ラベルを付与した上で，目視による確認・修正（ラベル付与）が困難なクラスタを集めて再度クラスタリングを行った．
これを繰り返せば，全てのツイートにラベルを付与することが出来るが，繰り返しの手間がかかることはもとより，生成されるクラスタの数が増え続けて全体把握がかえって困難になるのを避けるため，出来上がったクラスタを内容に応じてさらにまとめ上げることが必要となる．
また，ボリュームの大きいリツイート群は1回目でほぼ出尽くすため，メリットの1つであったリツイート群を把握する効果も薄れてくる．
そこで，何度もクラスタリングを繰り返すのではなく，2回クラスタリングを行った後は，それまでに作られたラベルを分類項目として残りをそのいずれかに落とし込むという分類問題に切り替えた．
3.1.3.2多クラス自動分類の繰り返し
クラスタリングでラベルが付与されたデータを学習データとし，その時点までに作られたラベルを分類項目として，ラベル未定義のデータを対象に，機械学習による多クラス自動分類の識別を行った．
興味深いことに，クラスタリング同様半数近くが特定の分類項目に分類されており，そのような項目は所属ツイートが多く，目視で確認・修正作業（ラベル付与作業）を継続することが困難であった．
そこで，目視での確認・修正が容易な，ツイート数または語彙が少ない項目に含まれ，確認・修正（ラベル付与）作業が済んだツイートを識別対象から学習データに回し，残りのラベル未定義のツイートに対し，繰り返し機械学習による自動分類を行った．
これを2回繰り返したところで，各日9割の分類が終了した．
この際に文書‐単語行列に対して行った工夫の詳細については第4章4.3節の評価実験2で述べる．
分類は，マージン最大化学習であるサポートベクターマシンを採用し，カーネルにはガウシアンカーネルを採用した多クラス分類器を用いた．
3.1.3節においてクラスタリングの確認・修正（ラベル付与）作業を行う過程で，震災時ツイートの分析では``誰が''``誰に''向かって発言しているか，がより重要な分類軸になることが分かった．
もともとソーシャルメディアにおいては，誰もが発信者にも受信者にもなり得，そこで飛び交う情報は，内容も方向も多種多様であるが，特に震災時においては，発信者と受信者の関係性によって情報の担う役割が異なってくるからである．
例えば``被害''に関する話題は，情報の方向を軸に見ると，被災者や被災者から事情を聞いた人が被災地外に向かって被害の状況を説明する``被害実態''，逆に被災地外の人が，テレビが見られない状況にある被災者または被災地周辺に向けて余震や津波の警報を伝える``関連災害予報''，さらに，被災地外から被災者に向けて発せられた，停電時のろうそく使用による二次火災の発生を注意するなどの``二次災害注意喚起''に大別される．
同様に，``支援''に関する話題（救出に関するものは別項目）では，発信者と受信者が被災者／非被災者（支援者）のどちらであるかによって``支援を求める声''``支援を申し出る声''``企業や政府に支援を呼びかける声''``支援に関するノウハウを伝える声''などに分けられる．
例えばマスメディアであれば，取材地候補を``被害実態''の中から探し，``支援（物資）を求める声''を人々に伝えるためにツイートを見る．
被災者であれば，``支援申し出''の中に，自分が必要としているものが挙がっていないか調べる．
これはツイート文中に出現する，個々の被害名称``地震''``津波''``火災''や物資名の``衣類''``食糧''``粉ミルク''``紙おむつ''といった単語での分類では不十分である．
情報の方向の他に考えられる軸としては，何次の情報であるか（1次＝本人，2次＝本人から伝聞，3次＝間に1人介して伝聞）などもあるが，震災時においては情報の方向性がより優先すると筆者らは考えた．
そこでクラスタリングによって得られた分類項目（後述になるが第5章の表13の項目）を整理し，表3のように分類項目を再設定した．
今回は特にマスコミが重視する*印の分類項目に注目した．
「安否確認」については，マスコミが個々の氏名をツイッターから拾うことはおそらくないものの，連絡不能すなわち通信不能な情報空白地域を特定するために利用することが可能であることから，*印の分類項目とした．
以下に単語による分類から情報の方向性を加味した分類へ分類軸を変更した例を示す．
\hangafter=1\hangindent=4zw\hbox to3.5zw{例1：}「被害」
旧分類項目地震，津波，火災等その他災害，停電，電話・メール等通信状況……
新分類項目被害実態，関連災害予報，二次災害注意喚起
（地震，津波，火災，停電，通信状況等は新分類項目の細分項目へ）
\hangafter=1\hangindent=4zw\hbox to3.5zw{例2：}「支援」
旧分類項目給水，炊き出し，募金，献血……
新分類項目支援物資要請，支援申し出，支援呼びかけ，支援方法・注意点
（給水，炊き出し，募金，献血等は新分類項目の細分項目へ）
クラスタリングは似たもの同士をまとめ上げる機構ではあるが，それがデータ解析に都合のよいまとめ方をしてくれるとは限らない．
震災ツイートにおいては，前節で述べたように，単語1-gramによってまとめただけでは情報活用には不十分であった．
筆者らは，単語1-gramのみによって得られるものとは異なる分離境界を定めての，必要な情報を含むターゲットツイートを抽出する方法を模索した．
クラスタリングでは，個々のデータの些末な部分の違いを吸収し，同義語をまとめ上げる必要があるが，このターゲットデータ抽出の段階においては，出現する単語が同じであっても機能や時制や情報の方向性を弁別することが必要となる．
そこで，次節に述べるように正規表現を用いて単語1-gramより長いフレーズの正規表現ルールを書き，目的とする情報を含むツイートを得ることを試みた．
クラスタリングによってある程度まとまったツイート群を見渡し，分類項目ごとに単語1-gramを含む特徴的なフレーズを見出し，人手による正規表現ルールを作成した．
先に述べたように，震災時のツイートでは情報の方向を考えてツイートを抽出することがキーポイントになってくるのだが，発信者や受信者が具体的に明記されているツイートは少ない．
そこで，情報の方向を暗示する部分（機能表現，時制，共起語）をルールに書き加えることで，収集したいツイートのみが集まるよう工夫した．
また今回の災害に限定されないよう，固有名詞や物資の名前等個別具体的な名詞はルールに書き込まないようにした．
\settensen\hangafter=1\hangindent=4zw\hbox to3.5zw{例1：\hss} ``火災が起きています''（被害状況リポート：被災地から周辺へ）
``火災が\unc{起きないように}ブレーカーを落としてから非難を''
（二次災害への注意喚起：周辺から被災地へ）
\hangafter=1\hangindent=4zw\hbox to3.5zw{例2：\hss} ``粉ミルクが足りません''（支援物資要請：被災地から周辺へ）
``衣類を被災地に\unc{送るように}企業を動かそう''（支援呼びかけ：周辺から周辺へ）
{※ルール化および抽出したのは実線部分のみ．
点線部分は特にルール化も抽出も行ってはいないが負例として掲載．
}
表4は，「拡散希望」に限定しない全ツイートからランダムサンプリングで抽出した3月11日分1,000件と3月13日分996件に対し，両日の代表的な（特にマスコミにとって重要な）分類項目について正解付けを行った後，上記正規表現の抽出率（再現性と適合性）を測定したものである．
表4の結果をみてわかるように，正規表現ルールを作成する際は，過検出を防ぐため，適合率重視になりがちである．
しかし，人間が発見できない潜在的なルールやうまく書き下すことが困難なルールも存在することは十分予想される．
また震災時には素早く情報をつかまなければならないことから，抽出結果の適合率が悪いことは望ましくないが，再現率が悪く，情報にたどりつけないことはそれ以上に大きな問題である．
そこで，機械学習を行って再現率の向上を図る必要があるという認識に至った．
機械学習には相当数の正解事例が必要である．
時間制約のある中で，十分な数の正解事例を一から人手で集めるのは非常に困難である．
例えばマスコミが強く関心を持つ``メディア取上げ要望''は，その重要さに相反して人手で精査した「拡散希望」ツイート約3万件中には150件程度しかなく（後述5.1節表13参照），それだけでは学習データとしてはかなり少ない．
そこで，全ツイートに上記正規表現ルールを適用して集めたツイート群を正解事例として，機械学習を行うことを試みた．
このようにして集めたツイート群の中には，実際には抽出対象ツイートでないもの（不純物）も含まれているが，不純物が混入することよりも，学習事例を多く集めることを優先した．
こうして集められた正解事例からは，当然ルールに書いた特徴が再び学習されることにはなるが，集められた正解事例に共通する特徴の中には，人間が認識しておらず，明示的にルールに書かれていなかったものも存在するであろう．
よって結果的に再現率が向上することをも期待した．
抽出すべきターゲットツイートとその特徴，および抽出するにあたり注意すべき点を把握したところで，抽出元の範囲を「拡散希望」ツイートから全ツイートに広げた．
抽出元の範囲を全ツイートに広げた際に，最も問題となったのは，複数存在する抽出目標のどれにも該当しない``その他''ツイートの存在の多さである．
また忘れてはならないのは，災害時に役立つシステムであるためには，情報抽出器は常時稼働，リアルタイム（非バッチ処理），無人で運用されることが想定され，複数種類の抽出を同時に行えるようなシステムにしなければならないということである．
震災後3日目になると，震災には無関係なツイートの割合も増えてくる．
また，震災に関連してはいても，被災者から発せられている情報のみに注目することにすると，ほとんどが標的外ツイートとなり，``その他''クラスが存在しない一般的な機械学習による分類は困難になる．
このタスクは，分類と言うよりはむしろ``その他''の中から目的の情報を抜き出す``抽出''のイメージに近くなる．
初め筆者らは，``その他''をホワイトノイズ的に扱うことを試み，全く脈絡のないツイート群を``その他''クラスの学習データとして与えた．
しかし人間には特徴が見出せなくても，機械的に学習される特徴が存在し，それに近い特徴を持つツイートが集められたため，この方法は失敗に終わった．
次に，注目する集合に属するかそうでないかを判定するone-class分類を複数組み合わせることで複数のターゲットツイート群を同時に抽出することを考え，統計処理言語Rのkernlabパッケージの中のサポートベクターマシン関数ksvmに用意されたtype = ``one-svc''オプションで実験した．
実験対象データは3.2.2節で行った実験のうち3月13日分（全ツイートからのランダムサンプリング996件）である．
type = ``one-svc''オプションでは，ある一つの集合に所属するかどうかが判定されるため，複数の集合のうち，ある一つの集合（仮にクラスAとする）にのみ属し，他の集合には全て``属さない''という結果が得られた場合のみ，そのツイートがクラスAに所属する，という方針で実験を行ったところ，再現率27.8%，適合率15.9%，F値で20.2%となるなど，結果は芳しくなかった．
明確な理由は不明ながら，負例を与えることができないことが一因であることが考えられる．
そこで，関数ksvmのオプションtype = ``probabilities''を指定し，予測結果を確率値で出力させ，算出された各クラスタに所属する確率が閾値以上であればそれぞれのクラスタに属するとみなし，どのクラスタに対しても閾値以下である場合はどこにも属さないとする，という定義のもと，所属するクラスタを判定する方法(Manning 2008)を採用した．
表5にその例を示す．
閾値は各実験において，90%から95%まで1%刻みで6種類計算し，F値が最良となるものを都度採用した．
閾値を高くすると，クラスに所属すると認定されるツイートが少なくなるため再現率が下がり，閾値を低くすると，クラスに所属すると認定されるツイートが増えるため適合率が下がることが定性的に理解され，また閾値の策定自体も研究課題の一つではあるが、本研究では，どのような文書‐単語行列が最も識別率を上げるかを問題にしており，それぞれの文書‐単語行列で最もよい識別率を出す閾値を採用することとした結果，いずれの実験においても閾値95%が採用された．
情報の方向を考慮しつつ行うターゲットツイート抽出を複数種類同時に行う，というタスクの精度向上のため，文書‐単語行列に，単語1-gram素性以外にも様々な素性を投入してみた．
詳細は5.2節において考察とともに述べる．
3.1.3.1節，3.1.3.2節および3.2--3.3節において，クラスタリング，自動分類および複数同時抽出には全て文書‐単語行列が用いられている．
自動分類と複数同時抽出はいずれも学習データを用いた機械学習であり，その違いは，選択された分類項目名を出力するのか，全ての分類項目候補に対してそれぞれの確率値を出力するのか，という点だけある．
厳密には，そのことに加え，3.1.3.2節の自動分類は人手によって正確にラベル付与された文書を学習事例としているのに対し，3.2--3.3節の複数同時抽出では，正規表現でかき集めたことにより混入した``意味内容は該当しない''事例（不純物）を含む文書を学習事例としている事実がある．
ただし，本稿の主旨はこの正解事例の収集方法を比較することではなく，クラスタリング，自動分類，複数同時抽出の各局面において行われた，文書‐単語行列の変換処理の有効性を示すことである．
そこで，この3つの局面における変換処理（第1章の図1に示した\ding{"AC}tf-idf値に変換，\ding{"AD}tf-idf値に変換した後，特異値分解を行う，\ding{"AE}特異値分解を行った後，特異地で重みづけを行う，の3段階の処理．
第3段階が本研究の提案手法）の評価実験を行った．
この節に続く4.2節，4.3節4.4節は，それぞれクラスタリング，自動分類，複数同時抽出に対して行われた評価実験について詳しく述べたものであるが，ここでは全ての評価実験に共通する，文書‐単語行列に対して行った3段階の処理について説明する．
第1段階で行ったのは，作成した文書‐単語行列をtf-idf値に変換すること，すなわち文書‐単語行列にキーワードらしさで重みづけをすることである．
これにより，特徴を担う素性の影響力が強化され，出現頻度は高くても，ほとんど全ての文書に登場するような，特徴を担わない素性の影響力を弱められる．
このtf-idf値に変換した行列を[MATH]とする．
第2段階では[MATH]に対して特異値分解を行い，意味軸へのマッピングを行う（式1）．
X=U\Sigma V^{T}
ここで[MATH], [MATH]は直交行列，[MATH]は対角行列となる．
特異値分解で文書‐単語行列は左右の特異値ベクトル（直交行列）と寄与度を表す特異値（対角行列：統計処理言語Rの標準パッケージにあるsvd関数の出力では，値の大きいものから順に並んでいる）の積となっているため，式変形を行うと，すでに重みづけがなされているようにも見える（式2）．
XV=U\Sigma
ただし[MATH]　[MATH]である．
しかし，この段階ではtf-idf値をかけた文書‐単語行列[MATH]に直交行列[MATH]をかけて単語の軸を意味軸へ変換し，同じ概念を持つ異なる単語を統一的に扱えるようにしたに過ぎず，文書間の距離も不変であるため，クラスタリングには何ら影響を与えない．
この後，[MATH]のある列より右側をカットした行列，すなわち意味軸へ射影した特徴量のうち寄与度が低い部分を除く``次元縮約''を行った行列を用いてクラスタリングを行うことで，効果的なまとめ上げが可能になる．
ただし，カットオフを行うことは，寄与度に閾値[MATH] cutoffを設け，閾値以上の特徴量を採択し，閾値以下の特徴量を棄却することでしかなく，寄与度の大きさに応じた重みづけはなされていない．
第3段階では，特異値分解を行った（＝単語軸から意味軸へ射影した）文書‐単語行列に，さらに特異値で重みづけを行う．
ここで初めて特徴量に重みづけがなされる（式3, 4）．
なお，第3段階で特異値分解の後，特異値で重みづけを行う場合は，特異値分解の後すぐにカットオフを行ってから重み付けを行っても，特異値分解の後，重み付けを行ってからカットオフを行っても同じことであるが，後述するようにカットオフ値が重要なパラメタとなるため，本研究では特異値分解の後，重み付けをしてから最後にカットオフを行っている．
4.2節以降，``特異値で重みづけ''は
XV\Sigma =U\Sigma^{2}
``特異値の2乗で重みづけ''は
XV\Sigma^{2}=U\Sigma^{3}
とすることに相当する．
カットオフ[MATH] cutoffをどの位置におくか，言い換えると文書‐単語行列を特異値分解したものについて，寄与度の大きい方から何列目までを残すかで，その後のクラスタリングや分類の精度が大きく変わることが次節以降の評価実験で明らかになる．
詳細はそれぞれ4.2，4.3，4.4節で述べる．
(Kobayashi 2004)では，数百単語より大きな規模の問題ではLSIの適用が困難とある．
しかし，本研究に用いた32 GByteのRAMを搭載した計算機では，数千単語規模の行列にLSIを適用することに困難はなかった．
2種類の指標によりクラスタリング結果の評価を行う．
1つは従来から用いられているエントロピーと純度によるものである．
これらの指標は，計算機による処理のみを行うことを前提としており人手の介在を伴う作業の場合には必ずしも適切な指標ではないと筆者らは感じた．
そこで，人手の負担を考慮した評価指標を導入し，人手が介在する場合の機械の処理について検討した．
文書‐単語行列に対し，特異値分解と，それに加えて特異値による重みづけを行うことで表れる最も顕著な変化はチェイニング現象の緩和である．
図3を第3章3.1.2節の図2と比較すると，全体の形状からも，枝刈をした時の``残り物''クラスタ（所属文書数最大のクラスタ：図2では3,275ツイート，図3では1,890ツイート，いずれも《1》番クラスタ）の大きさからも，特異値分解に加えて特異値で重みづけをすることがチェイニング現象の緩和に役立つことがわかる．
図4は，3月11日の「拡散希望」ツイート1%サンプリング10,949件に対し，特異値分解なし，特異値分解のみ，特異値分解に加えて特異値の2乗および4乗で重みづけ，の各場合の，所属ツイート数の多い順に並べた上位20クラスタに含まれるツイート数を示したものである．
カットオフは後述4.2.3節の表6に示す，クラスタリングにおける従来指標（エントロピー，純度）が最良となる値（160列目，寄与度3.4%）を用いた．
カットオフ前の文書‐単語行列の列数は9,013列であった．
特異値分解や，特異値分解に加えて重みづけをすると，重みづけの乗数に応じて各クラスタに所属するツイート数がならされていく様子がわかる．
特異値分解を行っただけで重みづけをしていない場合は，特異値分解をしない場合とほとんど差がない．
クラスタリングをする際，文書‐単語行列に対して行った特異値分解と重みづけに対し，一般的なクラスタリングの評価指標であるエントロピーと純度を算出した．
エントロピーおよび純度は，クラスタリング結果と正解のコンフュージョン・マトリクスを作成して比較し，どの程度正解に近い分け方が出来たかを示す指標であり，算出にあたっては，正解が分かっていることが前提となる．
結論から言うと，表6にあるように，カットオフを適正に定めた場合は，エントロピーと純度から，特異値分解をすること，また特異値分解に加えて重みづけを行うことが有効であることがわかった．
エントロピー：
\mathit{Entropy}=\sum_{C_{i}} \frac{n_{{}_{C_{i}}}}{N} \mathit{entropy}(C_{i})
\mathit{entropy}(C_{i}) = -\sum_{h} P(A_{h}|C_{i}) \log P (A_{h}|C_{i})
P(A_{h}|C_{i}) = \frac{x_{ih}}_{j}x_{ij}
Entropy：総合エントロピー（各クラスのエントロピーを加重平均）
[MATH]:クラス[MATH]のエントロピー（``正解クラス''の散らばり度）
[MATH]:クラス[MATH]に属する文書の数
[MATH]:全文書数
[MATH]:クラス[MATH]と正解クラス[MATH]の一致度
\phantom{[MATH]: }（クラス[MATH]に所属する文書のうち正解クラス[MATH]に分類された文書の割合）
[MATH]: confusion matrix ([MATH])の[MATH]行[MATH]列成分
純度：
\mathit{Purity} = \sum_{C_{i}} \frac{n_{{}_{C_{i}}}}{N} \mathit{Purity} (C_{i})
\mathit{purity}(C_{i}) = \frac(A_{h}\cap C_{i}){n_{C_{i}}}
Purity:総合純度（各クラスの純度を加重平均）
[MATH]:クラス[MATH]の純度
[MATH]:クラス[MATH]に属する文書の数
[MATH]:全文書数
Easiness（作業容易度）：
・人手による作業の効率を考慮した新しい指標
\hangafter=1\hangindent=2zw・「クラスタリングの確認・修正作業の難易度は，クラスタの質（不純物や語彙の少なさ）だけではなく，クラスタに所属する文書の量にもよる」ことを数値化
・正解データなしでの算出が可能
現在の自然言語処理技術では，精度の良い分類が求められている場合は，少なからず人手の介在（クラスタリング結果の確認・修正すなわちラベル付与作業）が必要である．
しかし，人が集中力を途切れさせずにチェック出来るデータ数には限りがあり，せいぜい100〜200件程度である．
例えば，1,000件の文書をチェックするのに，1,000件まとめて一度に作業するよりは，200件に小分けされたものを5回に分けて作業する方が，心理的負担は少ない．
ただし，小分けされていさえすればよいということではなく，クラスタ内は適度に純度が高いことが必要である．
クラスタのボリュームの他に，クラスタ内の文章の見た目（出現単語）が似ているかどうかも作業時のストレスに大きく影響する．
自然言語処理における一般的なクラスタリングの精度を表す指標，例えばエントロピーや純度では，上記のような作業効率が考慮されていない．
また，エントロピーも純度も，正解付けが行われた後で初めて算出が可能なものであり，人手によるラベル付与作業に入る前に，そのクラスタの出来上がり具合（不純物の多少）を概観することはできない．
クラスタの出来上がり具合を知る必要がある理由は，チェイニング現象が激しい場合，所属文書数が多く，従って不純物の多い``残り物''クラスタに対しては，確認・修正のラベル付与作業を行うよりも，そのクラスタだけを取り出してもう一度クラスタリングを行う方が適切であるため，ラベル付与作業を行うかどうか事前に判断しなければならないからである．
以上の経験に基づく考察のもと，作業のしやすさを次の式で与えることとする．
\mathit{Easiness} = \sum_{C_{i}} \mathit{easiness} (C_{i})
\mathit{easiness} (C_{i}) = \left( \frac{n_{{}_{C_{i}}}}{N}\right) \times H_{C_{i}}
H_{C_{i}} = \sum_{W_{j}} P_{W_{j}} {}^{(C_{i})}\log P_{W_{j}}^{(C_{i})}
P_{W_{j}}^{(C_{i})} = \frac{n_{{}_{W_{j}}}{}^{(C_{i})}}\limits_{W_{j}}n_{W_{j}}{}^{C_{i}}
Easiness:総合作業容易度（各クラスの作業容易度の和）
[MATH]:クラス[MATH]の作業容易度
[MATH]:クラス[MATH]に属する単語のエントロピー（単語で見た場合の乱雑さ）
[MATH]:クラス[MATH]に属する文書の数
[MATH]:全文書数
[MATH]:クラス[MATH]内での単語[MATH]の出現頻度
[MATH]:クラス[MATH]に存在する単語[MATH]の総出現数
単語[MATH]についての和は，クラス[MATH]に出現するクラスについてのものである．
各クラスごとの作業容易度[MATH]はそのクラスの所属文書数（を全体の文書数で規格化したもの）と単語エントロピーの積で定義する．
値が小さい方が作業が容易である．
ここで用いる単語エントロピー[MATH]とは，クラスタリングのエントロピー[MATH]とは異なることに注意したい．
この指標の本質は，「クラスタリングの確認・修正作業の難易度は，形成されたクラスタの質（不純物や語彙の少なさ）だけではなく，クラスタに所属する文書の量にもよる」ことを数値化していることである．
またこの指標はエントロピーや純度とは異なり，文書‐単語行列が作られてさえあれば，クラスタリングが終わった段階で，正解ラベルの付与を行わずとも，そのクラスタまたは全体について算出することができる．
中規模のクラスタの確認・修正作業に取り組んではみたものの，実は選り分けが困難なクラスタであったため，半分ほど作業を進めたところで諦め，クラスタリングをやり直さざるを得なくなる，などのような事態を防ぐことが期待される．
表6にあるように，次元圧縮のカットオフ[MATH] cutoffが適切な値であれば，特異値分解すること，また特異値分解に加えて特異値で重みづけをすることは，エントロピーや純度の改善に有効であることがわかる．
[MATH] cutoffとこれらの指標の関係については今後の研究課題として興味深いところであるが，[MATH] cutoffが適切な値であれば，人手による作業を考慮した提案指標「作業容易度」で見た場合でも，特異値分解に加えて特異値で重みづけをすることが有効であるように見受けられる．
4.2.1節で触れたように，特異値分解後にさらに重みづけを行うこととチェイニング現象の緩和には何らかの相関があることが示唆されているため，この結果は「``チェイニングの度合いが少ない，すなわち枝刈りをした際のクラスタ間の大きさのバランスが取れている''ことが実現されているクラスタリングが，人手による確認・修正作業の作業効率を大きく左右する」ことをも示唆させる．
そこで次節では，``人手による確認・修正作業''の評価実験を行った．
4.2.3.1 ``人手による作業''の評価評価実験1
前節で述べた「クラスタリングに人手が介在する場合は，作業にかかるコストの観点から，“特異値分解”と“特異値分解に加えて特異値で重みづけすること”が有効である」ことを検証するため，3つのテストセットを用意し，3人の被験者にクラスタリングの結果を整理してラベルを付与する作業を行ってもらった．
各テストセットは，それぞれ3月11日地震発生以降の「拡散希望」ツイート約105万件からランダムサンプリングした1,000件のツイート3セットで，被験者は各ツイートセットに対して特異値分解をしない文書‐単語行列でのクラスタリング，特異値分解（意味軸へのマッピング）のみを行った文書‐単語行列でのクラスタリング，特異値分解を行った上でさらに特異値の2乗で重みづけをした文書‐単語行列でのクラスタリング，のいずれかについて，クラスタリング結果を確認しながらラベルを付与する作業を行った．
本研究では，特異値に重みづけをすることの効果を調べることを目的としており，``重みづけ''の代表値として，最良のエントロピーと純度を与えるカットオフ値での，最良の作業容易度を与える``2乗''を選択した．
各被験者はどのテストセットも1回ずつ接触し，どのクラスタリング方法も1度ずつ経験するようにした．
また，各テストセットとクラスタリング方法の組み合わせは[MATH]通りあるが，全ての場合の実験が行われるように実験計画を行った．
作業慣れの効果をなるべく減らすため，3人が経験するクラスタリングの順番はそれぞれ異なっており，作業に伴って現れる疲労の影響を抑えるために，各人実験作業は1日に1つのみ行うこととした．
各クラスタリング法から見ると，3種類のテストセットと，3人の被験者による重複のない9種類の実験が行われたことになり，これらを平均することによって，テストセットの内容と被験者の作業能力の差異を吸収させた．
また，各被験者が行うクラスタリング法の順が異なるように実験を行い，その結果を平均することで，作業慣れの効果を可能な限り排除した．
以上の原則に基づいて割り当てられた3人の被験者の実験スケジュールについて表7にまとめた．
テストセット1,000件にラベルを付与するのにかかった分数と，最初の60分でラベルを付与した数を表8にまとめた．
さらに，それぞれのテストセットに対して3者が付与したラベルの一致数と，その割合を表9に掲載した．
付与すべきラベル数が35種類（最初に「拡散希望」ツイートの1%サンプリングをクラスタリングした際に得られた分類項目の数）とかなり多かったにもかかわらず，平均すると84%のツイートは3人の被験者によって同じラベルが付与されていることがわかる．
これにより，必ずしも速度優先で確認・修正作業を行っていたわけではないことが示される．
表9から，(1)特定数のツイートの確認・修正作業にかかる時間で評価しても，(2)特定の時間内に確認・修正できたツイートの数で評価しても，特異値分解に加えて特異値の2乗で重みづけを行った文書‐単語行列でクラスタリングを行ったものがクラスタリングの確認・修正作業を容易にしており，それにはチェイニングの緩和現象が大きく関わっていることがわかる．
チェイニング現象の緩和がクラスタリングの確認・修正作業を容易にする一例を挙げると，テストセットBで特異値分解をしない文書‐単語行列でクラスタリングを行った場合，あるクラスタに分類された津波に関する19ツイートは，特異値分解の後重みづけをすると，11ツイートと8ツイートに分離される．
8ツイートは，全て``停電で宮城の人は大津波警報知らないそうです''というツイートのリツイートになっており，よりクラスタリングが細分化されたことになる．
一方，特異値分解をしない文書‐単語行列でクラスタリングを行った場合に生成された``公衆電話が無料になりました！携帯電話使えない方ぜひ利用して！''というツイートのリツイートが集まっていたクラスタに，特異値分解の後重みづけを行った文書‐単語行列で再度クラスタリングを行うと，``携帯電話よりも公衆電話の方が繋がります''``現在公衆電話が国内通話無料解放中です．
回線が優先的に繋がるようになっているので付近の方は公衆電話を利用しましょう''という2ツイートがそのクラスタに合流した．
これにより，このクラスタは1つのリツイートの集合ではなくなったが，ツイートの内容は殆ど同じである．
このように，特異値分解や重みづけを行うと，クラスタの分離と統合両方が生じるが，重要なことは，分離・統合を経てもクラスタの内容の均一性が保持されるということである．
以上により，今回提案した人手による作業の負担を考慮した評価指標Easinessが作業効率と同じ傾向を持つことが示され，同時に，正確さを確保しながら（すなわち人手による確認・修正を加えながら）素早く分類を行う必要がある場合には，チェイニング現象を抑えておくことが有効であること，また，特異値分解に加えて特異値で重みづけした文書‐単語行列でクラスタリングすることで，自動生成されるクラスタの質をそれほど損なわずにそのことを実現出来る，ということも示された．
クラスタリングを数回行った後，``残り物''クラスタに含まれる文書数がまだ多く，かつ人手で振られるラベルの種類が限定されてきた段階では，クラスタリングの確認・修正作業で整えられたクラスタのラベルを分類項目として，ラベル未定義の文書をそのいずれかに振り分ける自動分類を行うことで，効率的に分析対象のツイートを全分類することが出来る．
評価実験2では，3月11日分の「拡散希望」ツイートの1%サンプリングのうち，2回クラスタリングを行い，2回自動分類を行ってなおラベルが定義されなかった1,141件のツイートに対して分類項目の識別実験を行った（表10）．
分類項目が35と多かったためか，既に自動分類を2回行った後の残りのツイートに対する分類問題であったからか，全体的に識別率はそれほどよくない．
表10を見る限り，4.1節で述べたカットオフ値（特異値分解，重みづけを行った文書‐単語行列の何列目までを用いるか）を適切に選ばない限り，分類問題に対しては特異値分解を行うことは識別率の改善にはつながらない．
また，特異値分解のみと特異値分解に加えて重みづけをすることに，それほど差はない．
情報抽出器において複数同時抽出を行う際にも，文書‐単語行列に対し特異値分解と特異値による重みづけが有効かどうかを調べた．
3.2.2節で用いたのと同じ，全ツイートからランダムにサンプリングして正解付けを行った3月11日分1,000件と3月13日分996件に対し，両日の代表的な（特にマスコミにとって重要な）分類すべき項目について，複数種類の同時ターゲットツイート抽出実験を行った．
クラスタリングと同様，tf-idf値に変換した文書‐単語行列，それに加え特異値分解を行い，意味軸へのマッピングを行ったもの，さらに特異値で重み付けを加えたもので抽出率を比較した．
特異値分解，および特異値分解の後重みづけを行った文書‐単語行列に対しては，寄与度2%以下の列を削除する次元圧縮を行った．
単語1-gram素性には，自立語のほか，助動詞，副詞，連体詞，接続詞，接頭詞，感動詞を用い，助詞と記号以外のほとんどを用いることとした．
クラスタリングとは異なり，情報の方向性を，自立語以外のさまざまな部分から得られる手がかりで弁別する必要性があったからである．
素性に単語1-gram以外のものを追加した試みの詳細については5.2節で述べる．
実験の結果，ターゲットツイートの抽出に対し，特異値分解に加えて重みづけを行うことが有効なことがわかった（表11，表12）．
第1章で述べたように，そもそも学習を行うと，特徴量には最適な重みづけが行われるため，特異値分解に加えて重みづけすることの効果はあったとしても薄れるはずである．
しかし，実験の結果から，特異値分解に加えて重みづけをすることの効果がないわけではないことが見てとれる．
F値で見る限り，重みづけの乗数は2乗付近がピークになっており，クラスタリングの実験結果と合わせ，特異値による重みづけは2乗程度が適当であると考えられる．
11日の方が再現率が低いのは，“被害実態”という多種多様なツイートが所属しうる分類項目に対しての抽出実験であったため，各項目ごとの学習事例数をそろえて抽出を行った今回は，“被害実態”の細分項目1つあたりの学習事例数が相対的に少なくなってしまったことや，特異値分解の効果を大きく左右するカットオフの設定が適切ではなかったことが原因と思われる．
なお，表11，表12，表14はいずれも所属クラス判定の閾値は全て95%となっているが，これは各文書‐単語行列に対する実験で，その都度最良のF値を与える閾値を採択した結果である．
本研究の最終目的は，災害発生時に役立つ情報抽出器を作成することであったが，それに先立つ全体把握のためのクラスタリングを完遂したところで見えてきたこと，抽出器の抽出精度を挙げる段階で課題として残ったものがあるため，ここに記しておく．
「拡散希望」ツイートの1%サンプリング11〜14日分3万件の9割を分類してみて最も驚いたのは，そこに人間の善性が表れていたことである．
「ケガ人の手当ての仕方」「救出を待つ間にするべきこと」「被災生活のサバイバルノウハウ」など，マスメディアによる報道には取上げられることの少ない，口コミ系メディア特有のツイートが数多く存在した．
また，マスメディアが取り上げきれない地域の細かい情報をまとめ，ウェブ上に掲載する人が少なからずいる一方，散在するそれらの情報を必要としている人に届けようと，かなりの人が進んで仲介の役割を担ったことがうかがえる．
直接的に「生きろ！」と叫ぶ声，被災・非被災にかかわらず，全ての人に「元気を出そう」と励ます声も，情報的な価値と関係無く「拡散希望」の対象となった．
「企業に働きかけて，被災地に支援物資を送らせよう」という運動さえ起こっていた．
そこには情報収集のツールを使い回す人々の姿よりも，本心から被災者を思いやり，助けようとする人間的な温かさを持った人々の姿のイメージがあった．
表13は「拡散希望」ツイートの1%サンプリング11〜14日分3万件の全分類結果（各日1割程度が未分類）である．
表13の分類項目は，クラスタリングの結果をもとにしており，情報の方向については特に考慮していない．
災害発生時における，放送等マスメディアにとって有用な情報収集のためには，情報の方向で抽出目標のツイートを弁別することが大切であることは3.2節で特に詳しく述べた．
このため，単語1-gram素性に加え，\ding{"AC}機能表現，\ding{"AD}動詞文節（連続する動詞と助動詞はひとまとまりにする），\ding{"AE}個別正規表現（分類項目ごとの正規表現集が全体として当たったかどうかではなく，正規表現集の個々の表現に対する合致／非合致），\ding{"AF}正規表現で集めたツイート群に含まれる5-gram前後のキーフレーズ，\ding{"B0}隣接単語2-gram，\ding{"B1}自立語に限定した共起2-gram，\ding{"B2}正規表現ルールに含まれる単語とそれを特異値分解にかけて得られた類義語による限定共起2-gram，を文書‐単語行列に追加し，それぞれの効果を調べた（表14）．
予想では，多義を持つ素性である単語は再現率が高く，逆に時制や意思を表す機能表現や，文脈を形成する共起語などは，意味解釈を限定していく作用があるため適合率が高くなると思われたが，一見するとそのような効果は見られなかった．
しかし結果をよく見ると，一つの傾向が見えてくる．
限定共起語は正規表現集にある単語の中から単語リストが作られており，キーフレーズは，最初に正規表現で集めたツイート群から抽出しているため，本質的には正規表現で集めていることと変わらない．
いずれも，学習データの特徴を文書‐単語行列に反映させるために追加した素性ではあるが，その種となっているのは正規表現ルールである．
ただし，限定共起語は特異値分解により人間が気付かなかった単語も素性に組み込むことが出来，キーフレーズに関しては，正規表現により集めたツイートの中から，人間が気付かずルールに書きこまなかったフレーズをも特徴量として素性に追加することが可能になった．
これらのことから，この2つのみがF値で単語1-gramよりもよい結果をもたらしたと考えることができる．
キーフレーズと個別正規表現は重なるものも多いが，キーフレーズの方が個別の正規表現を包含している関係にあるため，個別正規表現よりも再現率が高くなっていると解釈できる．
情報の方向性を担っている（「〜ている」のような現在形が，被害実態と未来の予測や注意喚起を分けている）ように見える「時制」などを扱うために，動詞文節を試したり，副詞や助動詞を含めた隣接バイグラムを扱うなどを試みてみたが，どのような素性がそのような効果を直接的に担っているかについては，結果を出すまでには至らなかった．
情報抽出器を作成するまでには，第1章の図1にあるように，全体把握，抽出対象データの策定・特徴把握，情報抽出というおおまかに3つの段階を経た．
以下，それぞれについて詳しく述べる．
本研究の最終目標は，所望する情報を含むターゲットツイートを抽出する情報抽出器を作成することであるが，そのためには，そのターゲットツイートの持つ特徴をつかむことが必要である．
その作業は，そもそもどのような種類のツイートが存在するかを知り，たとえ望ましいまとまりではなかったとしても，実際に形成されたツイート群を見てみることから始まる．
つまり，ターゲットデータの抽出のためには，それに先立ち全体傾向を把握すること，すなわちクラスタリングが非常に重要なのである．
近年，SNSというメディアの急速な発展に伴って，そこでの発言の解析に関する研究もにわかに脚光を浴びてきている．
書き言葉の解析が従来の言語処理のメインターゲットであったのに対し，話し言葉に近いSNSでの発言を解析することは，新たな研究課題を含んでいるからである．
今回はそのような言語処理の課題に加え，1.7億というボリュームゆえの大規模データ処理としての課題も顕在化した．
大規模なデータを扱う場合，特定の観点を定めて，それに特化した分析を行うという方法もあるが，我々は始めから特定の観点に限定せずに分析を行いたかったため，ランダムサンプリングを行って全体を把握することにした．
サンプリングを行うことで，核心的な個々のツイートを見逃す可能性もあるが，全体を把握する場合は，出現頻度の多いものからとりかかり，その後細部に踏み込んでいくという過程をたどるため，ランダムサンプリングを行うことが自然，かつ効果的である．
また，本来“つぶやき”であるものの中から，震災時の状況把握に意味のあるツイートに効率的に接触することを目指し，“拡散させることを目的としている”すなわち“伝える意思が明確である”「拡散希望」ツイートに着目した．
実際のところ，キーフレーズ検出を行って検出されたものの中に多数の「拡散希望」ツイートが見られ，震災時に「拡散希望」ツイートが多く出回っていたことも確認されている．
1%ランダムサンプリングを行った上で「拡散希望」ツイートに限定したとはいえ，震災対応初動期間の72時間を含む11〜14日に限定しても，分析対象のツイートは3万件以上あり，全て人手で分類するには30人日程度かかることが見積もられた．
このため，何らかの自動処理が必要となったのであるが，この時点ではまだどのような分類項目が存在するかもわからず，加えて時間の経過とともに分類項目が変わっていくことが予想されたため，1日分ずつ分析対象のツイートのクラスタリングを行うことにした．
3.1.1.1「拡散希望」ツイートの特徴
「拡散希望」ツイートには次に挙げる2つの特徴があり，結果的に「拡散希望」に限定したサンプルツイートは，震災時の膨大なツイートの概観を得るのに非常に有効であった．
\hangafter=1\hangindent=4zw\hbox to4zw{特徴1：\hss}基本的には転送を利用して拡散させるため，元ツイートの完全なコピー（公式リツイート）あるいはコピーにオリジナルのコメントを加えたもの（非公式リツイート）が多い
\hangafter=1\hangindent=4zw\hbox to4zw{特徴2：\hss} ``拡散させたい＝人々にきちんと伝えたい''という意識で書かれているため，一般的なツイートよりも``書き言葉''寄りで書かれており，スラングや未知語，単語の省略などが比較的少ない．
よって，形態素解析における未知語，形態素区切り誤り，品詞誤りも少ない
特徴1に関して，今回はリツイートを予め除外しておくことを敢えて行わなかった．
リツイートの大きさも一つの情報であり，一つの作業で量と内容を合わせて概観を得るには前もってリツイートのまとめあげを行わない方が適切であると考えたからである．
特徴2に関して，3月11日の地震発生後からランダムサンプリングした，「拡散希望」だけからなるツイート100件と「拡散希望」を含まないツイート100件を調べたところ，前者では全6,909形態素中，区切り誤りが13件，品詞誤りが22件あり，後者では全3,673形態素中，区切り誤りが27件，品詞誤りが33件見つかった．
本研究では一貫して文書‐単語行列が用いられる．
この文書‐単語行列は，文書（ツイート群）に対しMeCabによって形態素解析を行った後，各文書における単語1-gramの出現頻度をベクトル空間表現に基づいて作成したものである．
続いてこの特徴量ベクトルに対し，キーワードらしさの重みづけに用いられるtf-idfの指標への変換，特異値分解などの処理を行う．
これらの文書‐単語行列に対して行う工夫については，第4章においてもう一度説明する．
大規模なデータから作成された文書‐単語行列は，一般的に大規模疎行列になる傾向があるが，本研究では，大規模疎行列に特化したアルゴリズムを用いることなく，一般的な特異値分解のアルゴリズムで事足りた．
本研究では，解析および実験を，統計処理言語Rの標準または一般に入手可能なパッケージに含まれる関数によって行った．
表1に，本研究で使用したRのパッケージ名，関数，オプションの一覧を，表2に，用いた計算環境を示す．
クラスタの粒度を任意に設定できる階層型クラスタリングは樹形図（デンドログラム）を用いて視覚的に表現される．
根元（図2の最上部分）には全てのデータが含まれ，次第に分かれて末端は全てのデータが自分自身のクラスタを形成する．
適当な高さ（図2破線）で枝刈りをすることで，切断された枝の切断部分より末端に連なるデータがまとまって1つのクラスタを形成すると解釈する（図2の●または○）．
本研究ではユークリッド距離とウォード法を用いてクラスタリングを行った．
枝刈りは，クラスタ数が文書数の1/2乗になる場所で行うように設計した．
ウォード法を用いると比較的チェイニング現象が起きにくいとされているが，著者の経験では，どのような距離関数やクラスタの組み上げ法を採用しても，多かれ少なかれチェイニング現象に遭遇することとなる．
チェイニング現象とは，根元から見て，その後更に分かれることの無い比較的小さいクラスタが次々と分離していき，枝刈りを行った際に，ボリュームが大きく特徴を見出しにくいクラスタ（図2の○印）が残る現象である．
東日本大震災の「拡散希望」ツイートをクラスタリングして顕著だったのは，分離したクラスタのうち，クラスタ内が同じツイートを元とするリツイート群となっているものが多かったことである．
リツイート群は出現単語とその頻度が非常に似ており文書ベクトルの距離が近いため，先に分離してクラスタを形成するためと思われるが，逆にこのリツイート群が取得できたことで，人手による分類の確認・修正を行う際，人が見るべきツイートが減ること，また，あるツイートに対する非公式リツイートを含むリツイートの大きさを把握することが可能となること，という2つのメリットがもたらされた．
リツイートの多さがチェイニング現象の原因であることも考えられたため，図2に示している3月11日の「拡散希望」ツイート1%サンプリング10,494件のうち全くリツイートを含まない（ツイート本文中に文字列``RT''を含まない）ツイート667件に対し，同じ手順で階層クラスタリングを行った．
その結果，最も大きなクラスタに542ツイート（全体の81%）が集まるという同様の現象が認められた．
リツイートを除かない場合は10,494件中3.275件(31%)が最大クラスタに集まっている．
クラスタリングにおいてチェイニングが起きる理由は必ずしも明確ではない(Jain 1999)が，特徴量の設計が不適切で，分類を行う際に弁別能力を持つように文書間の距離を決めらなかった，あるいは階層クラスタリングを行う際の探索アルゴリズムにおいて，得られた解が局所最適解であった，などが原因として考えられる．
本研究では，探索アルゴリズムの設計には踏み込まず，統計処理言語Rに用意されている既存のボトムアップ型クラスタリングの関数を利用し，特徴量の設計または用いる距離関数の選択を上手に行い，精度のよいクラスタリング結果を得ることを目指した．
3.1.3.1階層クラスタリングの繰り返し
「拡散希望」ツイート1%サンプリングの全分類を目標とし，自立語に限定した単語1-gramを特徴量とする文書‐単語行列を作成，クラスタリングを行った．
クラスタリングにはベクトル空間表現におけるユークリッド距離を採用し，クラスタ間距離の計算にはウォード法を，クラスタリングアルゴリズムはボトムアップ型（組み上げ法）の階層クラスタリングを採用した．
その後，所属文書数が少ない，または文章が短く語彙が少ないクラスタについて，中身を1ツイートずつ確認し，ラベルを付与した上で，目視による確認・修正（ラベル付与）が困難なクラスタを集めて再度クラスタリングを行った．
これを繰り返せば，全てのツイートにラベルを付与することが出来るが，繰り返しの手間がかかることはもとより，生成されるクラスタの数が増え続けて全体把握がかえって困難になるのを避けるため，出来上がったクラスタを内容に応じてさらにまとめ上げることが必要となる．
また，ボリュームの大きいリツイート群は1回目でほぼ出尽くすため，メリットの1つであったリツイート群を把握する効果も薄れてくる．
そこで，何度もクラスタリングを繰り返すのではなく，2回クラスタリングを行った後は，それまでに作られたラベルを分類項目として残りをそのいずれかに落とし込むという分類問題に切り替えた．
3.1.3.2多クラス自動分類の繰り返し
クラスタリングでラベルが付与されたデータを学習データとし，その時点までに作られたラベルを分類項目として，ラベル未定義のデータを対象に，機械学習による多クラス自動分類の識別を行った．
興味深いことに，クラスタリング同様半数近くが特定の分類項目に分類されており，そのような項目は所属ツイートが多く，目視で確認・修正作業（ラベル付与作業）を継続することが困難であった．
そこで，目視での確認・修正が容易な，ツイート数または語彙が少ない項目に含まれ，確認・修正（ラベル付与）作業が済んだツイートを識別対象から学習データに回し，残りのラベル未定義のツイートに対し，繰り返し機械学習による自動分類を行った．
これを2回繰り返したところで，各日9割の分類が終了した．
この際に文書‐単語行列に対して行った工夫の詳細については第4章4.3節の評価実験2で述べる．
分類は，マージン最大化学習であるサポートベクターマシンを採用し，カーネルにはガウシアンカーネルを採用した多クラス分類器を用いた．
3.1.3節においてクラスタリングの確認・修正（ラベル付与）作業を行う過程で，震災時ツイートの分析では``誰が''``誰に''向かって発言しているか，がより重要な分類軸になることが分かった．
もともとソーシャルメディアにおいては，誰もが発信者にも受信者にもなり得，そこで飛び交う情報は，内容も方向も多種多様であるが，特に震災時においては，発信者と受信者の関係性によって情報の担う役割が異なってくるからである．
例えば``被害''に関する話題は，情報の方向を軸に見ると，被災者や被災者から事情を聞いた人が被災地外に向かって被害の状況を説明する``被害実態''，逆に被災地外の人が，テレビが見られない状況にある被災者または被災地周辺に向けて余震や津波の警報を伝える``関連災害予報''，さらに，被災地外から被災者に向けて発せられた，停電時のろうそく使用による二次火災の発生を注意するなどの``二次災害注意喚起''に大別される．
同様に，``支援''に関する話題（救出に関するものは別項目）では，発信者と受信者が被災者／非被災者（支援者）のどちらであるかによって``支援を求める声''``支援を申し出る声''``企業や政府に支援を呼びかける声''``支援に関するノウハウを伝える声''などに分けられる．
例えばマスメディアであれば，取材地候補を``被害実態''の中から探し，``支援（物資）を求める声''を人々に伝えるためにツイートを見る．
被災者であれば，``支援申し出''の中に，自分が必要としているものが挙がっていないか調べる．
これはツイート文中に出現する，個々の被害名称``地震''``津波''``火災''や物資名の``衣類''``食糧''``粉ミルク''``紙おむつ''といった単語での分類では不十分である．
情報の方向の他に考えられる軸としては，何次の情報であるか（1次＝本人，2次＝本人から伝聞，3次＝間に1人介して伝聞）などもあるが，震災時においては情報の方向性がより優先すると筆者らは考えた．
そこでクラスタリングによって得られた分類項目（後述になるが第5章の表13の項目）を整理し，表3のように分類項目を再設定した．
今回は特にマスコミが重視する*印の分類項目に注目した．
「安否確認」については，マスコミが個々の氏名をツイッターから拾うことはおそらくないものの，連絡不能すなわち通信不能な情報空白地域を特定するために利用することが可能であることから，*印の分類項目とした．
以下に単語による分類から情報の方向性を加味した分類へ分類軸を変更した例を示す．
\hangafter=1\hangindent=4zw\hbox to3.5zw{例1：}「被害」
旧分類項目地震，津波，火災等その他災害，停電，電話・メール等通信状況……
新分類項目被害実態，関連災害予報，二次災害注意喚起
（地震，津波，火災，停電，通信状況等は新分類項目の細分項目へ）
\hangafter=1\hangindent=4zw\hbox to3.5zw{例2：}「支援」
旧分類項目給水，炊き出し，募金，献血……
新分類項目支援物資要請，支援申し出，支援呼びかけ，支援方法・注意点
（給水，炊き出し，募金，献血等は新分類項目の細分項目へ）
クラスタリングは似たもの同士をまとめ上げる機構ではあるが，それがデータ解析に都合のよいまとめ方をしてくれるとは限らない．
震災ツイートにおいては，前節で述べたように，単語1-gramによってまとめただけでは情報活用には不十分であった．
筆者らは，単語1-gramのみによって得られるものとは異なる分離境界を定めての，必要な情報を含むターゲットツイートを抽出する方法を模索した．
クラスタリングでは，個々のデータの些末な部分の違いを吸収し，同義語をまとめ上げる必要があるが，このターゲットデータ抽出の段階においては，出現する単語が同じであっても機能や時制や情報の方向性を弁別することが必要となる．
そこで，次節に述べるように正規表現を用いて単語1-gramより長いフレーズの正規表現ルールを書き，目的とする情報を含むツイートを得ることを試みた．
クラスタリングによってある程度まとまったツイート群を見渡し，分類項目ごとに単語1-gramを含む特徴的なフレーズを見出し，人手による正規表現ルールを作成した．
先に述べたように，震災時のツイートでは情報の方向を考えてツイートを抽出することがキーポイントになってくるのだが，発信者や受信者が具体的に明記されているツイートは少ない．
そこで，情報の方向を暗示する部分（機能表現，時制，共起語）をルールに書き加えることで，収集したいツイートのみが集まるよう工夫した．
また今回の災害に限定されないよう，固有名詞や物資の名前等個別具体的な名詞はルールに書き込まないようにした．
\settensen\hangafter=1\hangindent=4zw\hbox to3.5zw{例1：\hss} ``火災が起きています''（被害状況リポート：被災地から周辺へ）
``火災が\unc{起きないように}ブレーカーを落としてから非難を''
（二次災害への注意喚起：周辺から被災地へ）
\hangafter=1\hangindent=4zw\hbox to3.5zw{例2：\hss} ``粉ミルクが足りません''（支援物資要請：被災地から周辺へ）
``衣類を被災地に\unc{送るように}企業を動かそう''（支援呼びかけ：周辺から周辺へ）
{※ルール化および抽出したのは実線部分のみ．
点線部分は特にルール化も抽出も行ってはいないが負例として掲載．
}
表4は，「拡散希望」に限定しない全ツイートからランダムサンプリングで抽出した3月11日分1,000件と3月13日分996件に対し，両日の代表的な（特にマスコミにとって重要な）分類項目について正解付けを行った後，上記正規表現の抽出率（再現性と適合性）を測定したものである．
表4の結果をみてわかるように，正規表現ルールを作成する際は，過検出を防ぐため，適合率重視になりがちである．
しかし，人間が発見できない潜在的なルールやうまく書き下すことが困難なルールも存在することは十分予想される．
また震災時には素早く情報をつかまなければならないことから，抽出結果の適合率が悪いことは望ましくないが，再現率が悪く，情報にたどりつけないことはそれ以上に大きな問題である．
そこで，機械学習を行って再現率の向上を図る必要があるという認識に至った．
機械学習には相当数の正解事例が必要である．
時間制約のある中で，十分な数の正解事例を一から人手で集めるのは非常に困難である．
例えばマスコミが強く関心を持つ``メディア取上げ要望''は，その重要さに相反して人手で精査した「拡散希望」ツイート約3万件中には150件程度しかなく（後述5.1節表13参照），それだけでは学習データとしてはかなり少ない．
そこで，全ツイートに上記正規表現ルールを適用して集めたツイート群を正解事例として，機械学習を行うことを試みた．
このようにして集めたツイート群の中には，実際には抽出対象ツイートでないもの（不純物）も含まれているが，不純物が混入することよりも，学習事例を多く集めることを優先した．
こうして集められた正解事例からは，当然ルールに書いた特徴が再び学習されることにはなるが，集められた正解事例に共通する特徴の中には，人間が認識しておらず，明示的にルールに書かれていなかったものも存在するであろう．
よって結果的に再現率が向上することをも期待した．
抽出すべきターゲットツイートとその特徴，および抽出するにあたり注意すべき点を把握したところで，抽出元の範囲を「拡散希望」ツイートから全ツイートに広げた．
抽出元の範囲を全ツイートに広げた際に，最も問題となったのは，複数存在する抽出目標のどれにも該当しない``その他''ツイートの存在の多さである．
また忘れてはならないのは，災害時に役立つシステムであるためには，情報抽出器は常時稼働，リアルタイム（非バッチ処理），無人で運用されることが想定され，複数種類の抽出を同時に行えるようなシステムにしなければならないということである．
震災後3日目になると，震災には無関係なツイートの割合も増えてくる．
また，震災に関連してはいても，被災者から発せられている情報のみに注目することにすると，ほとんどが標的外ツイートとなり，``その他''クラスが存在しない一般的な機械学習による分類は困難になる．
このタスクは，分類と言うよりはむしろ``その他''の中から目的の情報を抜き出す``抽出''のイメージに近くなる．
初め筆者らは，``その他''をホワイトノイズ的に扱うことを試み，全く脈絡のないツイート群を``その他''クラスの学習データとして与えた．
しかし人間には特徴が見出せなくても，機械的に学習される特徴が存在し，それに近い特徴を持つツイートが集められたため，この方法は失敗に終わった．
次に，注目する集合に属するかそうでないかを判定するone-class分類を複数組み合わせることで複数のターゲットツイート群を同時に抽出することを考え，統計処理言語Rのkernlabパッケージの中のサポートベクターマシン関数ksvmに用意されたtype = ``one-svc''オプションで実験した．
実験対象データは3.2.2節で行った実験のうち3月13日分（全ツイートからのランダムサンプリング996件）である．
type = ``one-svc''オプションでは，ある一つの集合に所属するかどうかが判定されるため，複数の集合のうち，ある一つの集合（仮にクラスAとする）にのみ属し，他の集合には全て``属さない''という結果が得られた場合のみ，そのツイートがクラスAに所属する，という方針で実験を行ったところ，再現率27.8%，適合率15.9%，F値で20.2%となるなど，結果は芳しくなかった．
明確な理由は不明ながら，負例を与えることができないことが一因であることが考えられる．
そこで，関数ksvmのオプションtype = ``probabilities''を指定し，予測結果を確率値で出力させ，算出された各クラスタに所属する確率が閾値以上であればそれぞれのクラスタに属するとみなし，どのクラスタに対しても閾値以下である場合はどこにも属さないとする，という定義のもと，所属するクラスタを判定する方法(Manning 2008)を採用した．
表5にその例を示す．
閾値は各実験において，90%から95%まで1%刻みで6種類計算し，F値が最良となるものを都度採用した．
閾値を高くすると，クラスに所属すると認定されるツイートが少なくなるため再現率が下がり，閾値を低くすると，クラスに所属すると認定されるツイートが増えるため適合率が下がることが定性的に理解され，また閾値の策定自体も研究課題の一つではあるが、本研究では，どのような文書‐単語行列が最も識別率を上げるかを問題にしており，それぞれの文書‐単語行列で最もよい識別率を出す閾値を採用することとした結果，いずれの実験においても閾値95%が採用された．
情報の方向を考慮しつつ行うターゲットツイート抽出を複数種類同時に行う，というタスクの精度向上のため，文書‐単語行列に，単語1-gram素性以外にも様々な素性を投入してみた．
詳細は5.2節において考察とともに述べる．
3.1.3.1節，3.1.3.2節および3.2--3.3節において，クラスタリング，自動分類および複数同時抽出には全て文書‐単語行列が用いられている．
自動分類と複数同時抽出はいずれも学習データを用いた機械学習であり，その違いは，選択された分類項目名を出力するのか，全ての分類項目候補に対してそれぞれの確率値を出力するのか，という点だけある．
厳密には，そのことに加え，3.1.3.2節の自動分類は人手によって正確にラベル付与された文書を学習事例としているのに対し，3.2--3.3節の複数同時抽出では，正規表現でかき集めたことにより混入した``意味内容は該当しない''事例（不純物）を含む文書を学習事例としている事実がある．
ただし，本稿の主旨はこの正解事例の収集方法を比較することではなく，クラスタリング，自動分類，複数同時抽出の各局面において行われた，文書‐単語行列の変換処理の有効性を示すことである．
そこで，この3つの局面における変換処理（第1章の図1に示した\ding{"AC}tf-idf値に変換，\ding{"AD}tf-idf値に変換した後，特異値分解を行う，\ding{"AE}特異値分解を行った後，特異地で重みづけを行う，の3段階の処理．
第3段階が本研究の提案手法）の評価実験を行った．
この節に続く4.2節，4.3節4.4節は，それぞれクラスタリング，自動分類，複数同時抽出に対して行われた評価実験について詳しく述べたものであるが，ここでは全ての評価実験に共通する，文書‐単語行列に対して行った3段階の処理について説明する．
第1段階で行ったのは，作成した文書‐単語行列をtf-idf値に変換すること，すなわち文書‐単語行列にキーワードらしさで重みづけをすることである．
これにより，特徴を担う素性の影響力が強化され，出現頻度は高くても，ほとんど全ての文書に登場するような，特徴を担わない素性の影響力を弱められる．
このtf-idf値に変換した行列を[MATH]とする．
第2段階では[MATH]に対して特異値分解を行い，意味軸へのマッピングを行う（式1）．
X=U\Sigma V^{T}
ここで[MATH], [MATH]は直交行列，[MATH]は対角行列となる．
特異値分解で文書‐単語行列は左右の特異値ベクトル（直交行列）と寄与度を表す特異値（対角行列：統計処理言語Rの標準パッケージにあるsvd関数の出力では，値の大きいものから順に並んでいる）の積となっているため，式変形を行うと，すでに重みづけがなされているようにも見える（式2）．
XV=U\Sigma
ただし[MATH]　[MATH]である．
しかし，この段階ではtf-idf値をかけた文書‐単語行列[MATH]に直交行列[MATH]をかけて単語の軸を意味軸へ変換し，同じ概念を持つ異なる単語を統一的に扱えるようにしたに過ぎず，文書間の距離も不変であるため，クラスタリングには何ら影響を与えない．
この後，[MATH]のある列より右側をカットした行列，すなわち意味軸へ射影した特徴量のうち寄与度が低い部分を除く``次元縮約''を行った行列を用いてクラスタリングを行うことで，効果的なまとめ上げが可能になる．
ただし，カットオフを行うことは，寄与度に閾値[MATH] cutoffを設け，閾値以上の特徴量を採択し，閾値以下の特徴量を棄却することでしかなく，寄与度の大きさに応じた重みづけはなされていない．
第3段階では，特異値分解を行った（＝単語軸から意味軸へ射影した）文書‐単語行列に，さらに特異値で重みづけを行う．
ここで初めて特徴量に重みづけがなされる（式3, 4）．
なお，第3段階で特異値分解の後，特異値で重みづけを行う場合は，特異値分解の後すぐにカットオフを行ってから重み付けを行っても，特異値分解の後，重み付けを行ってからカットオフを行っても同じことであるが，後述するようにカットオフ値が重要なパラメタとなるため，本研究では特異値分解の後，重み付けをしてから最後にカットオフを行っている．
4.2節以降，``特異値で重みづけ''は
XV\Sigma =U\Sigma^{2}
``特異値の2乗で重みづけ''は
XV\Sigma^{2}=U\Sigma^{3}
とすることに相当する．
カットオフ[MATH] cutoffをどの位置におくか，言い換えると文書‐単語行列を特異値分解したものについて，寄与度の大きい方から何列目までを残すかで，その後のクラスタリングや分類の精度が大きく変わることが次節以降の評価実験で明らかになる．
詳細はそれぞれ4.2，4.3，4.4節で述べる．
(Kobayashi 2004)では，数百単語より大きな規模の問題ではLSIの適用が困難とある．
しかし，本研究に用いた32 GByteのRAMを搭載した計算機では，数千単語規模の行列にLSIを適用することに困難はなかった．
2種類の指標によりクラスタリング結果の評価を行う．
1つは従来から用いられているエントロピーと純度によるものである．
これらの指標は，計算機による処理のみを行うことを前提としており人手の介在を伴う作業の場合には必ずしも適切な指標ではないと筆者らは感じた．
そこで，人手の負担を考慮した評価指標を導入し，人手が介在する場合の機械の処理について検討した．
文書‐単語行列に対し，特異値分解と，それに加えて特異値による重みづけを行うことで表れる最も顕著な変化はチェイニング現象の緩和である．
図3を第3章3.1.2節の図2と比較すると，全体の形状からも，枝刈をした時の``残り物''クラスタ（所属文書数最大のクラスタ：図2では3,275ツイート，図3では1,890ツイート，いずれも《1》番クラスタ）の大きさからも，特異値分解に加えて特異値で重みづけをすることがチェイニング現象の緩和に役立つことがわかる．
図4は，3月11日の「拡散希望」ツイート1%サンプリング10,949件に対し，特異値分解なし，特異値分解のみ，特異値分解に加えて特異値の2乗および4乗で重みづけ，の各場合の，所属ツイート数の多い順に並べた上位20クラスタに含まれるツイート数を示したものである．
カットオフは後述4.2.3節の表6に示す，クラスタリングにおける従来指標（エントロピー，純度）が最良となる値（160列目，寄与度3.4%）を用いた．
カットオフ前の文書‐単語行列の列数は9,013列であった．
特異値分解や，特異値分解に加えて重みづけをすると，重みづけの乗数に応じて各クラスタに所属するツイート数がならされていく様子がわかる．
特異値分解を行っただけで重みづけをしていない場合は，特異値分解をしない場合とほとんど差がない．
クラスタリングをする際，文書‐単語行列に対して行った特異値分解と重みづけに対し，一般的なクラスタリングの評価指標であるエントロピーと純度を算出した．
エントロピーおよび純度は，クラスタリング結果と正解のコンフュージョン・マトリクスを作成して比較し，どの程度正解に近い分け方が出来たかを示す指標であり，算出にあたっては，正解が分かっていることが前提となる．
結論から言うと，表6にあるように，カットオフを適正に定めた場合は，エントロピーと純度から，特異値分解をすること，また特異値分解に加えて重みづけを行うことが有効であることがわかった．
エントロピー：
\mathit{Entropy}=\sum_{C_{i}} \frac{n_{{}_{C_{i}}}}{N} \mathit{entropy}(C_{i})
\mathit{entropy}(C_{i}) = -\sum_{h} P(A_{h}|C_{i}) \log P (A_{h}|C_{i})
P(A_{h}|C_{i}) = \frac{x_{ih}}_{j}x_{ij}
Entropy：総合エントロピー（各クラスのエントロピーを加重平均）
[MATH]:クラス[MATH]のエントロピー（``正解クラス''の散らばり度）
[MATH]:クラス[MATH]に属する文書の数
[MATH]:全文書数
[MATH]:クラス[MATH]と正解クラス[MATH]の一致度
\phantom{[MATH]: }（クラス[MATH]に所属する文書のうち正解クラス[MATH]に分類された文書の割合）
[MATH]: confusion matrix ([MATH])の[MATH]行[MATH]列成分
純度：
\mathit{Purity} = \sum_{C_{i}} \frac{n_{{}_{C_{i}}}}{N} \mathit{Purity} (C_{i})
\mathit{purity}(C_{i}) = \frac(A_{h}\cap C_{i}){n_{C_{i}}}
Purity:総合純度（各クラスの純度を加重平均）
[MATH]:クラス[MATH]の純度
[MATH]:クラス[MATH]に属する文書の数
[MATH]:全文書数
Easiness（作業容易度）：
・人手による作業の効率を考慮した新しい指標
\hangafter=1\hangindent=2zw・「クラスタリングの確認・修正作業の難易度は，クラスタの質（不純物や語彙の少なさ）だけではなく，クラスタに所属する文書の量にもよる」ことを数値化
・正解データなしでの算出が可能
現在の自然言語処理技術では，精度の良い分類が求められている場合は，少なからず人手の介在（クラスタリング結果の確認・修正すなわちラベル付与作業）が必要である．
しかし，人が集中力を途切れさせずにチェック出来るデータ数には限りがあり，せいぜい100〜200件程度である．
例えば，1,000件の文書をチェックするのに，1,000件まとめて一度に作業するよりは，200件に小分けされたものを5回に分けて作業する方が，心理的負担は少ない．
ただし，小分けされていさえすればよいということではなく，クラスタ内は適度に純度が高いことが必要である．
クラスタのボリュームの他に，クラスタ内の文章の見た目（出現単語）が似ているかどうかも作業時のストレスに大きく影響する．
自然言語処理における一般的なクラスタリングの精度を表す指標，例えばエントロピーや純度では，上記のような作業効率が考慮されていない．
また，エントロピーも純度も，正解付けが行われた後で初めて算出が可能なものであり，人手によるラベル付与作業に入る前に，そのクラスタの出来上がり具合（不純物の多少）を概観することはできない．
クラスタの出来上がり具合を知る必要がある理由は，チェイニング現象が激しい場合，所属文書数が多く，従って不純物の多い``残り物''クラスタに対しては，確認・修正のラベル付与作業を行うよりも，そのクラスタだけを取り出してもう一度クラスタリングを行う方が適切であるため，ラベル付与作業を行うかどうか事前に判断しなければならないからである．
以上の経験に基づく考察のもと，作業のしやすさを次の式で与えることとする．
\mathit{Easiness} = \sum_{C_{i}} \mathit{easiness} (C_{i})
\mathit{easiness} (C_{i}) = \left( \frac{n_{{}_{C_{i}}}}{N}\right) \times H_{C_{i}}
H_{C_{i}} = \sum_{W_{j}} P_{W_{j}} {}^{(C_{i})}\log P_{W_{j}}^{(C_{i})}
P_{W_{j}}^{(C_{i})} = \frac{n_{{}_{W_{j}}}{}^{(C_{i})}}\limits_{W_{j}}n_{W_{j}}{}^{C_{i}}
Easiness:総合作業容易度（各クラスの作業容易度の和）
[MATH]:クラス[MATH]の作業容易度
[MATH]:クラス[MATH]に属する単語のエントロピー（単語で見た場合の乱雑さ）
[MATH]:クラス[MATH]に属する文書の数
[MATH]:全文書数
[MATH]:クラス[MATH]内での単語[MATH]の出現頻度
[MATH]:クラス[MATH]に存在する単語[MATH]の総出現数
単語[MATH]についての和は，クラス[MATH]に出現するクラスについてのものである．
各クラスごとの作業容易度[MATH]はそのクラスの所属文書数（を全体の文書数で規格化したもの）と単語エントロピーの積で定義する．
値が小さい方が作業が容易である．
ここで用いる単語エントロピー[MATH]とは，クラスタリングのエントロピー[MATH]とは異なることに注意したい．
この指標の本質は，「クラスタリングの確認・修正作業の難易度は，形成されたクラスタの質（不純物や語彙の少なさ）だけではなく，クラスタに所属する文書の量にもよる」ことを数値化していることである．
またこの指標はエントロピーや純度とは異なり，文書‐単語行列が作られてさえあれば，クラスタリングが終わった段階で，正解ラベルの付与を行わずとも，そのクラスタまたは全体について算出することができる．
中規模のクラスタの確認・修正作業に取り組んではみたものの，実は選り分けが困難なクラスタであったため，半分ほど作業を進めたところで諦め，クラスタリングをやり直さざるを得なくなる，などのような事態を防ぐことが期待される．
表6にあるように，次元圧縮のカットオフ[MATH] cutoffが適切な値であれば，特異値分解すること，また特異値分解に加えて特異値で重みづけをすることは，エントロピーや純度の改善に有効であることがわかる．
[MATH] cutoffとこれらの指標の関係については今後の研究課題として興味深いところであるが，[MATH] cutoffが適切な値であれば，人手による作業を考慮した提案指標「作業容易度」で見た場合でも，特異値分解に加えて特異値で重みづけをすることが有効であるように見受けられる．
4.2.1節で触れたように，特異値分解後にさらに重みづけを行うこととチェイニング現象の緩和には何らかの相関があることが示唆されているため，この結果は「``チェイニングの度合いが少ない，すなわち枝刈りをした際のクラスタ間の大きさのバランスが取れている''ことが実現されているクラスタリングが，人手による確認・修正作業の作業効率を大きく左右する」ことをも示唆させる．
そこで次節では，``人手による確認・修正作業''の評価実験を行った．
4.2.3.1 ``人手による作業''の評価評価実験1
前節で述べた「クラスタリングに人手が介在する場合は，作業にかかるコストの観点から，“特異値分解”と“特異値分解に加えて特異値で重みづけすること”が有効である」ことを検証するため，3つのテストセットを用意し，3人の被験者にクラスタリングの結果を整理してラベルを付与する作業を行ってもらった．
各テストセットは，それぞれ3月11日地震発生以降の「拡散希望」ツイート約105万件からランダムサンプリングした1,000件のツイート3セットで，被験者は各ツイートセットに対して特異値分解をしない文書‐単語行列でのクラスタリング，特異値分解（意味軸へのマッピング）のみを行った文書‐単語行列でのクラスタリング，特異値分解を行った上でさらに特異値の2乗で重みづけをした文書‐単語行列でのクラスタリング，のいずれかについて，クラスタリング結果を確認しながらラベルを付与する作業を行った．
本研究では，特異値に重みづけをすることの効果を調べることを目的としており，``重みづけ''の代表値として，最良のエントロピーと純度を与えるカットオフ値での，最良の作業容易度を与える``2乗''を選択した．
各被験者はどのテストセットも1回ずつ接触し，どのクラスタリング方法も1度ずつ経験するようにした．
また，各テストセットとクラスタリング方法の組み合わせは[MATH]通りあるが，全ての場合の実験が行われるように実験計画を行った．
作業慣れの効果をなるべく減らすため，3人が経験するクラスタリングの順番はそれぞれ異なっており，作業に伴って現れる疲労の影響を抑えるために，各人実験作業は1日に1つのみ行うこととした．
各クラスタリング法から見ると，3種類のテストセットと，3人の被験者による重複のない9種類の実験が行われたことになり，これらを平均することによって，テストセットの内容と被験者の作業能力の差異を吸収させた．
また，各被験者が行うクラスタリング法の順が異なるように実験を行い，その結果を平均することで，作業慣れの効果を可能な限り排除した．
以上の原則に基づいて割り当てられた3人の被験者の実験スケジュールについて表7にまとめた．
テストセット1,000件にラベルを付与するのにかかった分数と，最初の60分でラベルを付与した数を表8にまとめた．
さらに，それぞれのテストセットに対して3者が付与したラベルの一致数と，その割合を表9に掲載した．
付与すべきラベル数が35種類（最初に「拡散希望」ツイートの1%サンプリングをクラスタリングした際に得られた分類項目の数）とかなり多かったにもかかわらず，平均すると84%のツイートは3人の被験者によって同じラベルが付与されていることがわかる．
これにより，必ずしも速度優先で確認・修正作業を行っていたわけではないことが示される．
表9から，(1)特定数のツイートの確認・修正作業にかかる時間で評価しても，(2)特定の時間内に確認・修正できたツイートの数で評価しても，特異値分解に加えて特異値の2乗で重みづけを行った文書‐単語行列でクラスタリングを行ったものがクラスタリングの確認・修正作業を容易にしており，それにはチェイニングの緩和現象が大きく関わっていることがわかる．
チェイニング現象の緩和がクラスタリングの確認・修正作業を容易にする一例を挙げると，テストセットBで特異値分解をしない文書‐単語行列でクラスタリングを行った場合，あるクラスタに分類された津波に関する19ツイートは，特異値分解の後重みづけをすると，11ツイートと8ツイートに分離される．
8ツイートは，全て``停電で宮城の人は大津波警報知らないそうです''というツイートのリツイートになっており，よりクラスタリングが細分化されたことになる．
一方，特異値分解をしない文書‐単語行列でクラスタリングを行った場合に生成された``公衆電話が無料になりました！携帯電話使えない方ぜひ利用して！''というツイートのリツイートが集まっていたクラスタに，特異値分解の後重みづけを行った文書‐単語行列で再度クラスタリングを行うと，``携帯電話よりも公衆電話の方が繋がります''``現在公衆電話が国内通話無料解放中です．
回線が優先的に繋がるようになっているので付近の方は公衆電話を利用しましょう''という2ツイートがそのクラスタに合流した．
これにより，このクラスタは1つのリツイートの集合ではなくなったが，ツイートの内容は殆ど同じである．
このように，特異値分解や重みづけを行うと，クラスタの分離と統合両方が生じるが，重要なことは，分離・統合を経てもクラスタの内容の均一性が保持されるということである．
以上により，今回提案した人手による作業の負担を考慮した評価指標Easinessが作業効率と同じ傾向を持つことが示され，同時に，正確さを確保しながら（すなわち人手による確認・修正を加えながら）素早く分類を行う必要がある場合には，チェイニング現象を抑えておくことが有効であること，また，特異値分解に加えて特異値で重みづけした文書‐単語行列でクラスタリングすることで，自動生成されるクラスタの質をそれほど損なわずにそのことを実現出来る，ということも示された．
クラスタリングを数回行った後，``残り物''クラスタに含まれる文書数がまだ多く，かつ人手で振られるラベルの種類が限定されてきた段階では，クラスタリングの確認・修正作業で整えられたクラスタのラベルを分類項目として，ラベル未定義の文書をそのいずれかに振り分ける自動分類を行うことで，効率的に分析対象のツイートを全分類することが出来る．
評価実験2では，3月11日分の「拡散希望」ツイートの1%サンプリングのうち，2回クラスタリングを行い，2回自動分類を行ってなおラベルが定義されなかった1,141件のツイートに対して分類項目の識別実験を行った（表10）．
分類項目が35と多かったためか，既に自動分類を2回行った後の残りのツイートに対する分類問題であったからか，全体的に識別率はそれほどよくない．
表10を見る限り，4.1節で述べたカットオフ値（特異値分解，重みづけを行った文書‐単語行列の何列目までを用いるか）を適切に選ばない限り，分類問題に対しては特異値分解を行うことは識別率の改善にはつながらない．
また，特異値分解のみと特異値分解に加えて重みづけをすることに，それほど差はない．
情報抽出器において複数同時抽出を行う際にも，文書‐単語行列に対し特異値分解と特異値による重みづけが有効かどうかを調べた．
3.2.2節で用いたのと同じ，全ツイートからランダムにサンプリングして正解付けを行った3月11日分1,000件と3月13日分996件に対し，両日の代表的な（特にマスコミにとって重要な）分類すべき項目について，複数種類の同時ターゲットツイート抽出実験を行った．
クラスタリングと同様，tf-idf値に変換した文書‐単語行列，それに加え特異値分解を行い，意味軸へのマッピングを行ったもの，さらに特異値で重み付けを加えたもので抽出率を比較した．
特異値分解，および特異値分解の後重みづけを行った文書‐単語行列に対しては，寄与度2%以下の列を削除する次元圧縮を行った．
単語1-gram素性には，自立語のほか，助動詞，副詞，連体詞，接続詞，接頭詞，感動詞を用い，助詞と記号以外のほとんどを用いることとした．
クラスタリングとは異なり，情報の方向性を，自立語以外のさまざまな部分から得られる手がかりで弁別する必要性があったからである．
素性に単語1-gram以外のものを追加した試みの詳細については5.2節で述べる．
実験の結果，ターゲットツイートの抽出に対し，特異値分解に加えて重みづけを行うことが有効なことがわかった（表11，表12）．
第1章で述べたように，そもそも学習を行うと，特徴量には最適な重みづけが行われるため，特異値分解に加えて重みづけすることの効果はあったとしても薄れるはずである．
しかし，実験の結果から，特異値分解に加えて重みづけをすることの効果がないわけではないことが見てとれる．
F値で見る限り，重みづけの乗数は2乗付近がピークになっており，クラスタリングの実験結果と合わせ，特異値による重みづけは2乗程度が適当であると考えられる．
11日の方が再現率が低いのは，“被害実態”という多種多様なツイートが所属しうる分類項目に対しての抽出実験であったため，各項目ごとの学習事例数をそろえて抽出を行った今回は，“被害実態”の細分項目1つあたりの学習事例数が相対的に少なくなってしまったことや，特異値分解の効果を大きく左右するカットオフの設定が適切ではなかったことが原因と思われる．
なお，表11，表12，表14はいずれも所属クラス判定の閾値は全て95%となっているが，これは各文書‐単語行列に対する実験で，その都度最良のF値を与える閾値を採択した結果である．
本研究の最終目的は，災害発生時に役立つ情報抽出器を作成することであったが，それに先立つ全体把握のためのクラスタリングを完遂したところで見えてきたこと，抽出器の抽出精度を挙げる段階で課題として残ったものがあるため，ここに記しておく．
「拡散希望」ツイートの1%サンプリング11〜14日分3万件の9割を分類してみて最も驚いたのは，そこに人間の善性が表れていたことである．
「ケガ人の手当ての仕方」「救出を待つ間にするべきこと」「被災生活のサバイバルノウハウ」など，マスメディアによる報道には取上げられることの少ない，口コミ系メディア特有のツイートが数多く存在した．
また，マスメディアが取り上げきれない地域の細かい情報をまとめ，ウェブ上に掲載する人が少なからずいる一方，散在するそれらの情報を必要としている人に届けようと，かなりの人が進んで仲介の役割を担ったことがうかがえる．
直接的に「生きろ！」と叫ぶ声，被災・非被災にかかわらず，全ての人に「元気を出そう」と励ます声も，情報的な価値と関係無く「拡散希望」の対象となった．
「企業に働きかけて，被災地に支援物資を送らせよう」という運動さえ起こっていた．
そこには情報収集のツールを使い回す人々の姿よりも，本心から被災者を思いやり，助けようとする人間的な温かさを持った人々の姿のイメージがあった．
表13は「拡散希望」ツイートの1%サンプリング11〜14日分3万件の全分類結果（各日1割程度が未分類）である．
表13の分類項目は，クラスタリングの結果をもとにしており，情報の方向については特に考慮していない．
災害発生時における，放送等マスメディアにとって有用な情報収集のためには，情報の方向で抽出目標のツイートを弁別することが大切であることは3.2節で特に詳しく述べた．
このため，単語1-gram素性に加え，\ding{"AC}機能表現，\ding{"AD}動詞文節（連続する動詞と助動詞はひとまとまりにする），\ding{"AE}個別正規表現（分類項目ごとの正規表現集が全体として当たったかどうかではなく，正規表現集の個々の表現に対する合致／非合致），\ding{"AF}正規表現で集めたツイート群に含まれる5-gram前後のキーフレーズ，\ding{"B0}隣接単語2-gram，\ding{"B1}自立語に限定した共起2-gram，\ding{"B2}正規表現ルールに含まれる単語とそれを特異値分解にかけて得られた類義語による限定共起2-gram，を文書‐単語行列に追加し，それぞれの効果を調べた（表14）．
予想では，多義を持つ素性である単語は再現率が高く，逆に時制や意思を表す機能表現や，文脈を形成する共起語などは，意味解釈を限定していく作用があるため適合率が高くなると思われたが，一見するとそのような効果は見られなかった．
しかし結果をよく見ると，一つの傾向が見えてくる．
限定共起語は正規表現集にある単語の中から単語リストが作られており，キーフレーズは，最初に正規表現で集めたツイート群から抽出しているため，本質的には正規表現で集めていることと変わらない．
いずれも，学習データの特徴を文書‐単語行列に反映させるために追加した素性ではあるが，その種となっているのは正規表現ルールである．
ただし，限定共起語は特異値分解により人間が気付かなかった単語も素性に組み込むことが出来，キーフレーズに関しては，正規表現により集めたツイートの中から，人間が気付かずルールに書きこまなかったフレーズをも特徴量として素性に追加することが可能になった．
これらのことから，この2つのみがF値で単語1-gramよりもよい結果をもたらしたと考えることができる．
キーフレーズと個別正規表現は重なるものも多いが，キーフレーズの方が個別の正規表現を包含している関係にあるため，個別正規表現よりも再現率が高くなっていると解釈できる．
情報の方向性を担っている（「〜ている」のような現在形が，被害実態と未来の予測や注意喚起を分けている）ように見える「時制」などを扱うために，動詞文節を試したり，副詞や助動詞を含めた隣接バイグラムを扱うなどを試みてみたが，どのような素性がそのような効果を直接的に担っているかについては，結果を出すまでには至らなかった．
