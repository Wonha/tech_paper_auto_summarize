\section{実験と結果}
\label{ex}

\subsection{実験設定}

本研究の実験は，先行研究である平ら~\cite{taira:2008:emnlp}と今村ら~\cite{imamura:2009:acl}の実験設定を元にする．
まずは実験に利用したデータ及びツールについて述べる．
実験データはNAISTテキストコーパスで，この最新版はバージョン$1.5$であるが，
平ら及び今村らの実験設定に合わせるため，本研究ではバージョン$1.4\beta$を選択し，
そのニュース記事及び社説記事の両方を利用する．
実験に際してこのデータを三つに分割する．
訓練データとして，1月1日から1月11日までのニュース記事と，1月から8月までの社説記事を，
開発データとしては，1月12日と1月13日のニュース記事及び，9月の社説記事を，
残りの1月14日から17日までのニュース記事と，10月から12月の社説記事を評価データとして利用するものとする．
このデータの分割方法は，平ら~\cite{taira:2008:emnlp}の方法と同じである．

次に評価データにおける統計を表\ref{sts}に示す．
この表に示される通り，述語項関係の格ラベルとしては，ガ格が一番多いことが分かる．
また，\ref{related}章でも述べた通り，述語項関係の種類として，直接の係り受け関係にあるもの（直接係り受け）が，文内のゼロ照応関係にあるもの（ゼロ照応（文内））よりも多い．
しかしながら，日本語は英語などと比較すると，
格の省略と呼ばれるゼロ照応が頻出することも確かであり，
特にガ格では無視できない数となっている．
述語項関係の種類について，より詳細な議論は\cite{iida:2006:acl}にある．

日本語には文間の述語項関係も存在するが，
本研究で扱う述語項関係は，文内のものに限られる．
\ref{method}章で述べた通り，本研究で提案するMarkov Logicを利用した手法は，
対象とする文全体で最適化を行うことで述語項関係を推定している．
この全体最適化の枠組みは，計算量の点で，文から文章へと単純に拡張することが難しい．
このことが本研究では文間の述語項関係を扱えなかった理由である．
実験では，文内の最適化を正しく行うため，文間の述語項関係を含む文については省いた上で，学習・開発・評価を行うものとする．

素性を抽出するため，本研究では，京都大学テキストコーパスの品詞タグ及び係り受けタグを利用する．
さらに，CaboCha バージョン 0.53\footnote{http:/code.google.com/p/cabocha/}を利用して，固有表現タグを付与する．
平ららの研究を参考にし，本研究でも選択選好の素性を扱うために，日本語語彙大系~\cite{ikehara:1997}を利用する．
学習及び推定には，自然言語処理向けのMarkov LogicエンジンであるMarkov thebeastを利用している．

\begin{table}[b]
\caption{評価データにおける述語項関係の統計}
\label{sts}
\input{08table05.txt}
\end{table}


\subsection{実験結果}

\begin{table}[b]
  \caption{局所モデル vs 大域モデル（潜在述語の正解率，再現率，F値）}
\label{ret1}
\input{08table06.txt}
\end{table}

まず，表\ref{ret1}に示したのは，大域的制約を利用したモデルと利用しないモデルの比較である．
\textbf{大域モデル (\textit{Global})}が，大域的制約を利用したモデルであり，
\textbf{局所モデル (\textit{Local})}が，大域的制約を利用していないモデルである．
ここで言う大域的制約とは，\ref{method}章で示した表\ref{global}と表\ref{delFormula}の論理式のことである．
表\ref{ret1}には，潜在述語それぞれについて，精度(P)，再現率(R)，F値(F)を示した．
F値で評価すれば，局所モデルに比べて大域モデルは，全ての述語について性能が改善されている．
この改善はマクネマー検定により統計的に有意であることを確認した．
大域モデルが局所モデルよりも性能が良いということは，ただ大域的制約が有効というだけでなく，
本研究で扱っている三つの部分問題，項同定 (\emph{isArg})，項候補削減 (\emph{delete})，意味役割付与 (\emph{role}) の間には相互関係があり，
同時に解くことが述語項構造解析の性能改善に意味があるということを示している．
意味役割付与の結果で特に大きく改善したのは再現率で，
より多くの述語項関係を抽出できるようになったことが分かる．

表\ref{ret3}には，大域モデルに対して，\emph{isArg}（項同定）を削除した時と，
\emph{delete}（項候補削減）を削除した時，
それぞれの意味役割付与の結果がどのように変化するかを示してある．

この表\ref{ret3}から，$\mathit{delete}$の削除は$\mathit{isArg}$よりも性能の低下が大きいことが分かる．
また，$\mathit{isArg}$の削除が精度を下げるのに対し，$\mathit{delete}$の削除は再現率を傷つけることも分かる．
両方の潜在述語を削除した時は，局所モデルと同じである．

次に，表\ref{ret2}では，意味役割付与についてより詳細な結果を示す．
この表では，意味役割付与の結果をガ格，ヲ格，ニ格，それぞれに分けて示し，
直接係り受けか，文内ゼロ照応か，その種類によっても分けている．
示した数値は全てF値である．

\begin{table}[b]
	\centering
  \caption{潜在述語($\mathit{isArg}$, $\mathit{delete}$)を削除した時の意味役割付与 (role) の解析性能}
\label{ret3}
\input{08table07.txt}
\end{table}
\begin{table}[b]
\centering
  \caption{先行研究との比較}
\label{ret2}
\input{08table08.txt}
\end{table}

大域モデルは文内ゼロ照応において，局所モデルよりも性能が高いことが分かる．
特にガ格の文内ゼロ照応では，$42.1\%$から$54.1\%$に大きく改善している．
この結果は，大域的制約により，文全体での最適化を行ったことから導かれたものと考察できる．
即ち，直接係り受け関係に無いということは，述語項間に構文的なつながりが薄いことを意味しており，
局所的な素性のみでその関係を捉えることは難しいのである．
本研究の大域的制約は特にそのような場合において大きな性能改善を実現している．

続いて先行研究である平ら及び今村らの結果との比較を行う．
この表\ref{ret2}には，格ごとに最も高い性能の数値を太字で示してある．
ガ格では，本研究の大域モデルが二つの先行研究の結果を圧倒している．
一方，ヲ格とニ格では，本研究の結果は相対的に低い数値となっている．
本研究の提案手法は，三つの格を一つのモデル（大域モデル）で扱うため，
ヲ格とニ格よりも数の多いガ格を多く同定し，出力するのである．
しかしながら，ガ格は一般に必須格と呼ばれ，述語項構造解析で最も重要な格であることが知られている．
従って，先行研究に比べ，その必須格を多く正確に抽出できる本研究の提案手法の意義は大きいと考えられる．
本研究では，今村らのように大規模データを利用していないが，
彼らのシステムと同等以上の結果を達成している．


\paragraph{誤り分析}

\begin{center}
  
  \Rubyb{この}{1} \Rubyb{ため}{2}，
  \Rubyb{灰色狼の}{3} \Rubyb{\underline{\bf 米復活を}}{4} \Rubyb{\colorbox[gray]{.75}{進める}}{5} \Rubyb{\underline{\bf 魚類野生動物局が}}{6} 
	
	\Rubyb{カナダで}{7} \Rubyb{\colorbox[gray]{.75}{捕獲した}}{8} \Rubyb{野性の}{9} \Rubyb{\underline{\bf 十二匹を}}{10} \Rubyb{\colorbox[gray]{.75}{空輸}}{11}．
\end{center}

ここで示した例文では，三つの述語（網掛け）と三つの項（下線付き）がある．
関係節を伴うために述語項関係が複雑で，システムにとって間違い易い事例である．

局所モデルでこの文を解析した場合，出力される述語項関係 ($\mathit{role}$) は，
\begin{gather*}
\{\mathit{role}(5,6,\ga),\mathit{role}(5,4,\wo),\mathit{role}(8,6,\ga),\\
\underline{\mbox{$\mathit{role}(11,2,\ga)$}},\mathit{role}(11,10,\wo)\}
\end{gather*}

まず，誤りとして挙げられる点は，``捕獲した''のヲ格が出力されていないことである．
この理由は，NAISTテキストコーパスが格フレーム辞書を持っていないため，
``捕獲した''という述語が一般にヲ格を取ることが分からないからである．

もう一つの誤りは，下線のついている$\mathit{role}(11,2,\ga)$のように，``空輸''という述語に対し，
``ため''をガ格として出力していることである．
この理由は，``ため''が``空輸''と直接係り受けの関係にあるからである．

一方，大域モデルで解析した結果を見ると，次のように改善されている．
\begin{gather*}
\{\mathit{role}(5,6,\ga),\mathit{role}(5,4,\wo),\mathit{role}(8,6,\ga),\\
\underline{\mbox{$\mathit{role}(8,10,\wo)$}}, \underline{\mbox{$\mathit{role}(11,6,\ga)$}},\mathit{role}(11,10,\wo)\}.
\end{gather*}

大域モデルは，格フレーム情報など意味的な素性が少ないにも関わらず，
``十二匹を''を``捕獲した''のヲ格として同定できている．
この述語項関係は連体修飾である関係節と被修飾名詞との間に格関係が認められる「内の関係」と呼ばれるものであり，一般に同定することが難しい．
阿辺川らは，連体修飾節と非修飾名詞が格関係にあるかどうかを判別するために，大規模データを利用している~\cite{abekawa:2005:ijcnlp}．
しかし，Markov Logicを利用した本研究の提案手法では，文内の全体最適化でそれを実現している．

さらに言えば，大域モデルでは，$\{\mathit{delete}(1), \mathit{delete}(2), \mathit{delete}(7)\}$ も出力されており，
``この''と``ため''はともに項の候補になっていない．
結果として，``魚類野性動物局が'' を正しく``空輸''に対するガ格として抽出できているのである．



