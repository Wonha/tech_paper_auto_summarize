実験

\subsection{実験条件}

本節では提案手法の有効性を示すために，少量のシードエンティティから
の新規エンティティ獲得精度を比較し，
その結果についての考察を行う．


実験には2008年5月の日本語ブログ約3000万記事を用いた．
単語及び固有表現を処理単位として素性に変換しており（以後簡単のため固有表現を含めて単語と呼ぶ），
形態素解析にはJTAG \cite{Fuchi98} を，
IREX定義に基づく固有表現抽出器には最小誤り分類基準に基づくCRFを用いた \cite{suzuki2006training}．
素性を獲得する素性テンプレートとしては``(head) \textit{entity} (mid.) \textit{attribute} (tail)''を用いた．
head, mid. tailに位置する各単語は表層，品詞，固有表現ラベルに対し，その位置情報を付加した上で素性に変換する．
文脈のウインドウサイズ ($|head|,|mid|,|tail|$) はそれぞれ最大で2単語とし，
素性は正例，負例を通じて最低5回以上出現しているものを用いた．

\begin{table}[b]
\caption{シードエンティティ及び正例属性}
\label{table:seed}
\input{03table01.txt}
\end{table}


本節では「車名」「番組名」「スポーツ組織名」の3つのドメインを対象に実験を行う．
一回の繰り返しで獲得するエンティティ種類数は $100$ 種類とし， 合計10回の繰り返しを経て，最終的に1000種類の新規エンティティを獲得する．
シードとしたエンティティと属性を表\ref{table:seed}に示す．正例属性はシードエンティティとのPMIの高いものから順に10個を選択したが，番組名においては，属性として明らかにふさわしくないと判断したものを主観的に除去した（「この間」と「さっき」）．
識別器には$SVM^{light}$ \cite{joachims1999making} の2次多項式カーネルを用いた．


トピックモデルの学習と適応にはMessage Passing Interface (MPI) で LDA を利用できる Parallel LDA を用い \cite{liu2011plda}，
トピック数100のLDAを学習，適応した．
トピックモデルの学習コーパスは，本実験で用いる2008年5月のブログコーパス31日分のうち，14日分の記事約1400万記事を用いた．
予備実験の検討より，学習におけるマルコフ連鎖モンテカルロ法のサンプリング回数は200回とし，うち50回を初期値への依存を弱めるための burn-in として用いた．



実験条件として以下の4条件に基づいて実験を行った．
\begin{itemize}
\item{1. ベースライン：\ref{sec:baseline}節で述べたものに相当する}
\item{2. ベースラインにトピック素性を追加した手法}
\item{3. 2.に対し負例生成法を追加した手法}
\item{4. 3.に対し正例の多義性解消法を追加した手法（図\ref{fig:structure}の全破線矢印部に一致）}
\end{itemize}
システムが獲得した1000個のエンティティについて，2人の評価者が商用検索エンジンを用いて検索し，エンティティと各ドメイン名のAND検索の検索結果上位40件中に，シードエンティティと同じ使い方をされているものが存在するか否かという観点で，正解または不正解のラベルを付与した．
また獲得された単語のうち，固有表現抽出器が誤って獲得した固有表現以外の単語（例えば「番組名」における「月9」等）については不正解とした．
評価者間の $\kappa$ 値は $0.895$ であった． 
2人の評価者間で評価が異なった場合，第3の評価者が評価を行い，その評価を正しい評価として用いた．


\subsection{実験結果と考察}

表\ref{table:result}に各ドメイン毎の実験結果を示す．
表中の値は精度と有意差を表している．
トピック素性を用いた手法2.においては，車名とスポーツ組織名のドメインにおいて改善を示している．

\begin{table}[b] 
\hangcaption{
3ドメインにおける各手法による評価．太字で示している数値は直前行の結果と二項検定を行い， $5\%$ の有意差水準において有意に差があったものを示している．斜体は同 $10\%$ での有意差水準の場合}
\label{table:result}
\input{03table02.txt}
\end{table}

また負例生成法は車名と番組名のドメインにおいて改善を示している．
これは，負例生成法が偽負例を選択するリスクを低減させたことが要因の1つと考えられる．
同様に正例の多義性解消法においても車名と番組名において精度の改善を示している．
スポーツ組織名のドメインにおいてはトピック素性を追加した場合に明らかな改善が見られたものの，ある程度の改善がなされてしまったために，他の2つの手法による改善は見られなかった．
車名における精度が他のドメインより低いのは，「バイク名」のような比較的近い意味のエンティティが獲得されたことに起因する．
これら似たドメインというのは，文脈的特徴が似ているだけでなく，トピックによる特徴も近くなったためと考える．

\begin{table}[b] 
\hangcaption{$z_h$, $z_l$, $z_e$の3トピックに属する特徴的な単語．獲得対象となるドメインに対し，$z_h$ は最も近い（$PT(z)$が最も高い）トピック，$z_l$ は最も遠い（$PT(z)$が最も低い）トピックを表す． $z_e$ は負例生成で選ばれる負のトピックの1つを表しており，ベースラインを用いた場合の結果に見られるエンティティのセマンティックドリフト（3行目）を抑えることに効果があったことを示している}
\label{table:real_topic}
\input{03table03.txt}
\end{table}

提案手法が有効に機能した結果，ベースラインにおいて生じていたセマンティックドリフトが軽減されたということを示すため，ターゲットドメインに近いトピックと遠いトピックに属する単語を表\ref{table:real_topic}に挙げる．
表\ref{table:real_topic}は以下に定義される正のトピック$z_h$と負のトピック$z_l$, $z_e$に属する特徴的な単語を示している．
\begin{itemize}
\item{$z_h$ （2行目） $PT(z)$が最大となるトピックであり，正のトピックとして用いられる．}
\item{$z_e$ （4行目） ベースラインにおいて観察されるエンティティのセマンティックドリフトを抑えるのに効果があったトピック．$PT(z)$ の大きい順にソートした際に下位半分に現れる負のトピックの1つから選択したトピック．
}
\item{$z_l$ （5行目） $PT(z)$を最小とするトピックであり，負のトピックとして用いられる．}
\end{itemize}
各トピックにおける特徴単語として，スコア$p(v|z)/p(v)$が最も高くなる3単語を選択した．
ここで$p(v|z)$はLDAにおけるモデルパラメータ，$p(v)$は単語$v$のユニグラム確率であり，コーパス全体からの単純な最尤推定で求められる．


正例の多義性解消法が有効に機能するためには，
正のトピック$z_h$が対象ドメインに近い必要がある．
反対に負例生成法が有効に機能するためには，下位半分のトピックに含まれるトピック $z_l$, $z_e$ が対象ドメインから遠い必要がある．
表\ref{table:real_topic}を見ると，このいずれもを満たしていることが確認できる．
例えば表中「車名」において，最も近いトピックには「車検」という単語等を含み，最も遠いトピックには「内科」という単語を含んでいるため，対象ドメインに対しそれぞれ近い単語，遠い単語が選ばれていると言える．
さらに効果的な負のトピックとして，電子機器のトピックが選ばれているために，ベースラインにおいて獲得された「iPod」等の単語が提案手法では獲得されなかった．
この傾向は「車名」以外のドメインにおいても確認でき，提案手法の語彙獲得精度の向上に繋がった要因であると考えられる．


