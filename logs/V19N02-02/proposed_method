ブートストラップ法を用いた語彙獲得における課題

\subsection{ブートストラップ法とセマンティックドリフト}

本節では，ブートストラップ法によるエンティティ獲得の基本的な処理の流れと，その課題について述べる．
はじめに，ブートストラップ法に基づくエンティティと属性の関係獲得法であるEspresso  \cite{pantel2006espresso} について述べる．
属性とは獲得対象とするエンティティ集合において，複数のエンティティが共通して関係する語（``has-a''や``is-a''等の関係）であるとする．
例えばエンティティ「ヤクルト」と「巨人」の属性は，「監督」(has-a) や「球団」(is-a) 等となる．
関係獲得タスクは語彙獲得タスクを含んだタスクと捉えられるため，両者を比較することに意味はある．
Espressoでは，初期に与えられるシードエンティティとシード属性の組から，それらを含んで出現する文脈パターンを手掛かりとして，新たなエンティティ--属性ペアに対し，自己相互情報量 (PMI) に基づいて定義されたスコア関数に基づいてスコアを付与する．
ここでの文脈パターンの例としては，「NTT」をエンティティ (X)，「株価」を属性 (Y) とした場合，
「X (NTT) /の/Y（株価）/が/反発」といったものがあげられる．
Espressoはブートストラップ法の各繰り返しにおいて，スコア関数値を高くするようなエンティティ--属性ペアを新たな正例として獲得するフェーズと，文脈パターンの獲得フェーズを交互に行い，
必要なエンティティ--属性ペア数が得られるまで繰り返す．
ブートストラップ法を用いることで少量のシードエンティティのみが与えられた場合でも，教師データを増加させつつ新たなエンティティを獲得していくことが可能なため，
本稿でもEspressoと同様，ブートストラップ法に基づいた語彙獲得を行っていく．



ブートストラップ法によって少量のシードエンティティから新たなエンティティ集合を獲得する際の主な課題として，獲得する対象が本来獲得すべき種類とは異なる対象へと次第に変わっていってしまうという現象があげられる．
例えば獲得対象が企業名である場合に，「NTT」と「トヨタ」をシードエンティティとして与え，
Espresso等のエンティティ獲得アルゴリズムにより「ヤクルト」が獲得できたとする． 
しかし「ヤクルト」には企業名以外にも，プロ野球球団名や飲料品名といった多義性が存在するため，
次の繰り返しにおいて獲得されるエンティティが「巨人」等の本来獲得対象としていたエンティティではないものに遷移していく場合がある．
この現象はセマンティックドリフトと呼ばれ，ブートストラップ法に基づく語彙獲得における精度低下の大きな要因となっている．

\subsection{識別モデルに基づくブートストラップ法と課題}
\label{sec:problem}


先行研究では，新たなエンティティを選択する際のスコア関数を独自に定義することで
セマンティックドリフトを抑え，エンティティを精度良く獲得する手法が提案されている
\cite{thelen2002bootstrapping,sarmento2007more}．
これらのスコア関数は，基本的にはEspressoと同様にシードエンティティの特徴になるべく近い特徴を持つエンティティに対し，高いスコアを与えるように設計されている．


スコア関数についての研究とは異なる観点で提案されたのがBellareらの識別モデルに基づくブートストラップ法である \cite{bellare2007lightly}．
彼らの方法では識別モデルからのスコアによってスコア関数を構築するため，柔軟な素性設計が可能となる．
例えば，「X (NTT)/の/Y（株価）/が/上昇」という文脈を考えた時，素性関数$f$によって
$f({\rm surf.}=``$の$'',{\rm position}=X+1)=1,\\ f({\rm surf.}=``$上昇$'',{\rm position}=Y+2)=1$といった素性が構築される．
BellareらはEspressoと同様に関係獲得タスクに識別モデルに基づくブートストラップ法を適用しているが，文脈パターンに相当する素性の重みは，識別学習によって自動的に付与される．
そのためEspressoにおける文脈パターン獲得フェーズは不要となり，代わりにエンティティ獲得フェーズと属性獲得フェーズとに分けた手法が提案されている．
我々はBellareらの手法に若干の変更を加えたものをベースラインとして用いることとした．このベースラインについては\ref{sec:baseline}節で詳しく述べる．


Bellareらの手法及び我々のベースラインシステムには3つの課題が残存する．
1つ目の課題は，大域的な情報が識別モデルに反映されていないという点である．
識別モデルの導入により素性の柔軟な設計が可能になった一方，彼らは局所的な文脈中の単語の表層と品詞のみを素性として用いるのみで，識別モデルの利点を積極的には用いていない．
局所的文脈に基づく素性のみでは，エンティティの曖昧性を解消できない場合がしばしばある．
例えばエンティティ「ヤクルト」は企業名としても球団名としても存在する．
「ヤクルト」に対して「捕手」のような属性を付与することによって，ある程度曖昧性を解消することは可能であるが，属性を付与した場合でもなお曖昧性が残る場合もある．
ここで属性として「広報」が与えられ，文書が次のように与えられている場合を考える．
「18日の夜，ヤクルトの広報担当者が取材に対してコメントを発表した．
18日の試合で途中退場したY選手は，診断の結果軽いねんざと診断された，とコメントは伝えている．」
一文目だけを見た場合，このヤクルトは企業名を指すか球団名を指すかは明らかではない．
文書全体を読むことで，このエンティティが「球団名」を指していることが明らかになるが，局所的な文脈パターンのみを用いた場合，文書全体からの大域的情報を利用することはできない．
我々は文書全体を通して存在するトピックを，
エンティティ識別の際の素性として用いる方法を\ref{sec:topicfeature}節において述べる．


2つ目の課題は，識別学習における負例の問題である．
識別学習では正例と負例が必要になることが一般的である．
Bellareらは現在の正例以外全てを負例として扱っているが，この場合も偽負例が混じる可能性が排除できない上，正例と負例の量が大きく乖離するというデータ非平衡の問題もある．
一方，Mintzらは複数のクラスに属する正例群を与えた後，別のクラスに属するエンティティと属性を擬似的な負例ペアとすることで負例を生成している \cite{mintz2009distant}. 
しかし，1つのクラスのみを獲得対象とする場合，このような負のクラスを加えることには人的コストがかかる上，属性を組み合わせたとしても，エンティティ「ヤクルト」に対する多義属性「広報」が存在するように，属性の多義性によって偽負例が生成されてしまう可能性がある．


3つ目の課題はシードエンティティの質及び獲得された正例エンティティの多義性についての問題である．
少量のシードエンティティのみを手がかりとして行う語彙獲得タスクでは，シードエンティティによる精度への影響は大きい．
Pantelらは大規模なWEBに対して，比較的単純なスコアリング関数を用いて効率的なエンティティ獲得手法を提案しており \cite{pantel2009web}，
10個程度のシードエンティティにより十分な精度でエンティティ集合が得られると報告している．
一方でVyasらはシードエンティティの選択によりエンティティ獲得の結果に影響が出ることを示している \cite{vyas2009helping}．
特に多義性のあるシードエンティティが混入した場合にセマンティックドリフトが生じやすく，精度の劣化は大きいと考えられるため，
Vyasらは精度を落とす可能性の高いシードを除去するアルゴリズムを提案している．
この問題はシードエンティティに限らず，獲得された後に教師データとして用いられるエンティティについても同様が生じてしまう．


我々はこれら3つの課題に対し，トピック情報を用いて解決する手法を以下で提案する．




トピック情報を用いたブートストラップ法
\label{sec:propose}

\subsection{ベースライン手法}
\label{sec:baseline}

本節ではBellareらの手法を基としたベースライン手法について述べる．
なお，本節ベースライン手法は図\ref{fig:structure}の実線矢印で，
次節以降で述べる提案手法は破線矢印で表している．
本ベースライン手法がBellareらの手法と異なる点は，獲得対象がエンティティに限られるという点である．
そのため，本ベースライン手法ではエンティティ獲得と属性獲得との交互獲得は行わず，初期に正例属性集合として与えた後の属性集合は不変であるとする．
新規属性獲得を行うことも可能ではあるが，獲得された属性集合に偽正例が混じることによってセマンティックドリフトが生じるリスクを排除するために，エンティティのみの獲得を行うこととした．

\begin{figure}[t]
\begin{center}
\includegraphics{19-2ia938f1.eps}
\end{center}
\caption{提案手法のシステム構成図}
\label{fig:structure}
\end{figure}



ベースライン法においては，はじめに人手によって $N_e$ 個の正例シードエンティティ集合$E_P$が与えられた後，シードエンティティとのPMIの大きい順に各名詞のランキングを行う．
ランキングされた名詞のうちスコアの高い方から $N_a$ 個の正例属性集合($A_p$)を選択する．
$N_e$ 及び $N_a$ は事前に調整するパラメータであり，本論文ではいずれも$10$とした．
エンティティ--属性ペアとしてのシードは，シードエンティティ集合$E_P$と正例属性集合$A_P$とを組み合わせることで得た．
次にこのエンティティ--属性ペアを，正例教師データ用の文書集合を獲得する際の検索クエリとして用いる．
検索の結果得られる，あるエンティティ--属性ペア $\{e,a\}$  を含む正例文書集合を $D_{e,a}$ と表す．
1つ1つの文書を個別に教師データとして用いるのではなく，同じエンティティ--属性ペアを含む文書をまとめることにより，過適応の緩和が期待できる．
正例文書集合$D_{e,a}$を元に$e,a$の周辺文脈についての素性化を行う一方，
学習用の負例についても文書集合全体からランダムに選択した後に素性化を行い，
これらを元に識別モデルを学習する．
次に識別モデルの適用方法について述べる．
新規正例エンティティとなりうる候補エンティティは，正例属性 $a \in A_P$ の近傍に出現する固有表現$e'$のみに限定する．
訓練データの場合と同様，過適応緩和のため，識別対象 $e',a$ は文書集合 $D_{e',a}$ としてまとめられ，素性化処理を行った後に識別モデルが適用される．
識別モデル適用の結果出力されるスコアを $s(e,a)$ とし，
正例属性集合 $A_p$ について $s(e,a)$ の和をとったスコア $\sum_{a\in A_P} s(e,a)$ の値の高い方から順に，任意の種類数の新規正例エンティティを獲得する．


\subsection{トピック素性とトピックモデル}
\label{sec:topicfeature}

\ref{sec:problem}節で1つ目の課題として述べたように，識別モデルにおける素性としてこれまでは局所的文脈に基づく素性が用いられてきた \cite{bellare2007lightly}．
我々は文脈情報に加え，トピック情報を併用することでエンティティの持つ曖昧性を解消し，セマンティックドリフトの影響を緩和する．
文書の背景にあるトピックを利用する場合，文書に対して明示的にトピックラベルが付与されているデータであれば，そのラベルを直接トピック情報として用いることができるが，
全ての文書にトピックラベルを人手で付与するにはコストがかかる．
本稿ではラベル無しの文書集合しか存在しない場合でもトピック情報の取得を可能にするため，
文書のトピックと単語との関係をモデル化するトピックモデルを用いる．
トピックモデルは，文書のトピックと関連の強い単語に高い確率を付与することで，文書をより緻密に表現できるモデルであり，
情報検索等多様なアプリケーションにおいて利用されている \cite{hofmann1999probabilistic}．
例えばある文書のトピックがスポーツであるならば，
「サッカー」といったスポーツに関する単語が出現しやすく，
「国会」といった単語が出現しにくい，
といった大域的情報を扱うことができる．

本稿ではトピックモデルとして，各文書におけるトピック間の共起関係をディリクレ分布によって表現するLatent Dirichlet Allocation (LDA) を用いることとする \cite{blei2003latent}．
LDAをはじめとするトピックモデルを用いることで，具体的には文書$d$におけるトピック$z$の事後確率$p(z|d)$を計算することが可能となる．
LDAを用いた場合，事後確率を解析的に求めることは困難であるが，変分ベイズ法を用いて近似的に事後確率を求めたり \cite{blei2003latent}，マルコフ連鎖モンテカルロ法を用いて近似的に事後確率を推定することが可能である \cite{Griffiths2004fst}．
例えば，\ref{sec:problem}節の「ヤクルト」の例に関して，トピックモデルはトピック$z=\text{``野球''}$に対して高い事後確率を付与することが期待される\footnote{$z$は離散変数上の確率変数であり，明示的にトピックを表すような単語を値とはとらない．}．
この事後確率は文書$d$のトピック$z$らしさを表現していることに他ならないので，識別における大域的素性として直接的に活用できる．
我々の手法において，エンティティ--属性ペア$e,a$に対するトピック素性$\phi_t(z,e,a)$は，LDAの事後確率に基づいて以下のように計算される．
\[
\phi_t(z,e,a)=\frac{\sum_{d \in D_{e,a}} p(z|d)}{\sum_{z^\prime }\sum_{d \in D_{e,a}} p(z^\prime |d)}.
\]



\subsection{トピック情報に基づく負例生成}
\label{sec:negative}

正例のみが存在する状況下で識別モデルを利用する際に問題となるのは，
学習用の負例をいかに生成するかという点であり，\ref{sec:problem}節において2つ目の課題としていた．
例えば初期の正例以外全てを負例として扱う場合や，ランダムに負例を選択する場合，実際には正例である事例を，誤って負例として扱ってしまう偽負例を生じてしまい，識別結果に対しても悪影響を及ぼす可能性がある．
我々の目的は偽負例の生成を抑制するというだけでなく，正例と負例の量を平衡に保ちつつ，セマンティックドリフトを緩和するために幅広いジャンルから負例としてふさわしいものを獲得することである．
本節ではトピックモデルを用いることでこのような要求を満たす負例を自動的に獲得する手法について述べる．
負例生成問題は，正例とラベルなしデータのみが存在する場合における主要な問題と捉えられている \cite{liu2002partially,li2010negative}．
しかし先行研究における手法はある程度大きな規模の正例データを想定しており，
我々が用いる非常に少量の正例データについては有効に機能しないと考えられる．




そこで，前節で用いたトピックモデルの尺度において，正例からできるだけ遠い事例を負例として選択する手法を提案する．
トピックの分布は単語の分布と比べ比較的密であり，少量の正例データからでも正のトピックが推定可能である．
各異なり単語を独立次元とするベクトル表現では，例えば「プリウス」と「キャディラック」では全く異なる次元に存在するが，トピックを独立次元とするベクトル表現で捉えると，これらの単語を含む文書は同じトピック次元上に存在する可能性が高く，逆に言えば，負例はそれ以外のトピック次元中に存在しやすい．
トピックに基づくこの尺度をトピック$z$に対する ``正のトピックスコア'' $PT(z)$ と呼び，本スコアを元に負例にふさわしい文書を選択していく．
正のトピックスコア$PT(z)$を，以下のように正例文書集合$D_{e,a}$中の各文書が与えられた時の事後確率の和として定義する．
\begin{equation}
PT(z)=\frac{\sum_{d \in {D_{e,a}}} p(z|d)}{|D_{e,a}|}．
\end{equation}
$PT(z)$の低い方から$50\%$のトピックを負のトピックとし，負のトピック各々において同数ずつ，総数が正例文書数と等しくなるように文書を選択した．
この際の文書の選択基準としては，負のトピックに対する事後確率が高く，かつエンティティ候補となり得る固有表現と属性に相当する名詞が，任意のウインドウサイズ内に現れる文書であるとした．
本実験に用いたウインドウサイズは3単語である．


\subsection{トピック情報による正例の多義性解消}
\label{sec:tpc_sel}

本節では\ref{sec:problem}節で挙げた3つ目の課題，
正例の教師データに多義性が含まれ得るという課題を解決する手法を提案する．
正例の中には多義性を持つものも存在するため，その正例が出現する全ての文書を正例の抽出対象として用いることはセマンティックドリフトを引き起こす要因となる
（例えば\ref{sec:problem}節の「ヤクルト」の例があげられる）．
従来研究ではこのようなセマンティックドリフトを引き起こす要因となるシードエンティティを除外する手法が提案されている \cite{vyas2009helping}．
これに対し，我々はトピックを用いることにより，エンティティを無条件に除外するのではなく，ドメインに合ったトピックでは活かし，ドメインから外れたトピックでは除外するといったような，細かな処理を可能とする手法を提案する．
「ヤクルト，広報」というエンティティ--属性の二つ組に加え，「ヤクルト，広報，$z=\text{``野球''}$」のような三つ組の形とすることで，より確実性の高い正例集合を作ることができる．


具体的には，前節で述べた正のトピックスコア$PT(z)$をここでも利用する．
まず，任意の閾値$th$において，$PT(z)>th$を満たすトピック$z$を正のトピックとする．
もしも条件を満たす$z$が1つもない場合は，最も$PT(z)$の高い$z$を正のトピックとする．
そして正例文書集合の中から，正のトピックに含まれる全てのトピック$z^\prime$に対し， $p(z^\prime |d)\le th $となるような文書$d$を正例文書集合から除外する．
なお，シードエンティティが与えられているか否かに関わらず，
文書単位のトピック事後確率は事前に全て計算しておくことが可能であるため，
本手法の適用は比較的高速に行うことが可能である．
本節で述べた手法は，\ref{sec:topicfeature}節のトピック素性をハード制約として用いた場合と捉えることができる．






