序論\label{sec:hajime}

自然言語処理においては，タグ付けや文書分類をはじめとするさまざまな分類タスクにおいて，分類器が出力するクラスに確信度すなわちクラス所属確率を付与することは有用である．
例えば，自動分類システムがより大きなシステムの一部を構成し，自動分類結果が別のシステムに自動入力されるような場合に，クラス所属確率は重要な役割を果たす．
この例として，ブログ記事に対してさまざまな観点から付けられたタグ（複数）をユーザに表示するシステムにおいて，タグを自動的に付与する際に，クラス所属確率が閾値より低いタグについては排除することが有効な場合がある~\cite{Ohkura06}.  同様に，手書き文字認識システムによる分類結果が，言語モデルのようなドメイン知識を組み込んだシステムの入力である場合も，クラス所属確率が用いられている~\cite{Zadrozny02}. 
また，自動的にタグ付けされた事例のうち誤分類されたものを人手により訂正したい場合に，すべての事例をチェックするのは大きなコストがかかるが，
クラス所属確率が低いものほど不正解である可能性が高いと仮定し，
クラス所属確率が閾値を下回る事例のみを訂正することにすれば，効率的な作業が行える．
さらに，自動分類結果が人間の意思決定を支援する場合においては，クラス所属確率は判断の根拠を与える．
例えば，高橋らは，
社会調査において自由回答で収集される職業データを該当する職業コードに自動分類し~\cite{Takahashi05a,Takahashi05c}, 
上位 5 位までに予測されたクラスを候補として画面に提示するシステム（NANACO システム）を開発した~\cite{Takahashi05b}.  
NANACO システムは，我が国の主要な社会調査である JGSS（Japanese General Social Surveys; 日本版総合的社会調査）\kern-0.5zw\footnote{
	\texttt{http://jgss.daishodai.ac.jp/}. JGSS プロジェクトは，シカゴ大学 NORC 
	(the National Opinion Research Center) における GSS プロジェクトの日本版であり，
	国際比較分析を可能にするために，日本の社会や態度，行動に関する調査項目を有する．
} や，
SSM 調査（Social Stratification and Social Mobility Survey; 
社会階層と社会移動調査）\kern-0.5zw\footnote{
	\texttt{http://www.sal.tohoku.ac.jp/coe/ssm/index.html}.  1995 年から 10 年ごとに
	実施されている「仕事と暮らしに関する」全国調査である．
} などに利用されているが，
システムを利用したコーダから，
提示された各クラスについてどの程度確からしいかを示すクラス所属確率を付与してほしいという要望が出されている\footnote{
	NANACO システムが適用されるたびに，コーダによるシステム評価を行っている．
}．
最後に，クラス所属確率は EM アルゴリズムにおいても有用である．
例えば，語の曖昧性解消において，あるドメインで訓練された分類器を，別のドメインのコーパス用に調整するために用いられた EM アルゴリズムにおいて，クラス所属確率は精度の向上に役立つことが報告されている~\cite{Chan06}.  

事例 $x$ があるクラス $c$ に所属するクラス所属確率 $P$ は，2 値分類，多値分類のいずれにおいても $P(x \in{c}|x)$ で表される\footnote{
	クラス所属確率 $P$ の別の定義として，
	$P(\overrightarrow{\rm X}_{i},X_{i}\in{C_{j}}|\overrightarrow{\rm V}_{j},T_{j},S,I)$ 
	で表される場合もある．
	ただし，$\overrightarrow{\rm X}_{i}$ は事例 $X_{i}$ を記述する属性のベクトル，
	$C_{j}$ はクラス $j$, $\overrightarrow{\rm V}_{j}$ は確率密度関数を具体化する
	パラメータ集合，
	$T_{j}$ は確率密度関数の数式，$S$ は許容される確率密度関数 
	$\overrightarrow{\rm V}_{j}$, $T$ の空間，$I$ は明確には表現されない暗黙の情報を
	表す~\cite{Cheeseman96}.
}．
このようなクラス所属確率の意味からは，1 つの事例が複数のクラスに所属するマルチラベル分類の可能性があってもよく~\cite{erosheva05}, 
またある事例の全クラスに対するクラス所属確率の推定値の総和が $1$ 
である必要もない~\cite{Canters02}\footnote{
	さらに，Carreiras (2005) らにおいては，$n$ 個の分類器のバギングにより生成された分類器に
	おいて，クラス所属確率の推定値として，それぞれのクラスごとに各分類器におけるクラス
	所属確率の推定値の平均をそのまま用いている~\cite{Carreiras05}.
}. 
しかし，もし，シングルラベル分類で，全クラスに対するクラス所属確率の推定値を求めることができれば，その総和が $1$ になるように正規化することが可能である．このようなクラス所属確率は「正規化されたクラス所属確率」とよばれ~\cite{Cheeseman96}, 
事後確率と考えることができる．
対象とする分類問題をシングルラベルとして扱う場合，本来は正規化されたクラス所属確率を用いる必要があると考えられる．しかし，本稿においては，事例が注目するクラスに所属するか否かという問題に対する関心により，それぞれのクラスを独立に扱うため，一部の実験を除き基本的には正規化されたクラス所属確率を用いない．
実際には，
今回の実験では，正規化を行わないクラス所属確率の推定値の総和の平均はほぼ 1 に等しく，
また限定された実験の結果ではあるが\footnote{
	3.2.2 節および 4.2.2 節において報告を行う．
}，
本稿における提案手法に関しては，正規化を行わない場合は正規化された場合とほぼ同様かやや劣る結果であるため，本稿における結論は，正規化されたクラス所属確率を用いた場合には，さらなる説得性をもつと考えられる\footnote{
	この理由は，既存の方法に関しては，正規化を行う場合の方が正規化を行わない
	場合より結果が悪いためである．ただし，一般化するにはさらなる実験が必要である．
}．

クラス所属確率の推定は，分類器が出力するスコア（分類スコア）に基づいて行われる．非常に単純には，例えばナイーブベイズ分類器や決定木では分類スコアが $[0,1]$ の値をとるために，
分類スコアをそのまま用いることができる． 
また，サポートベクターマシン (SVM) のように分類スコアが $[0,1]$ の値をとらない場合でも，
最大値や最小値を利用して確率値に変換することは容易である\footnote{
	例えば分類スコアが $f$ の場合，$(f-min)/(max-min)$~\cite{Mizil05} または 
	$(f+max)/2*max$~\cite{Zadrozny02} により $[0,1]$ の値に変換することが可能である．
	ここで，$max$, $min$ はそれぞれ分類スコアの最大値，最小値を表す．
}. 
しかし，このようにして得られた推定値は実際の値から乖離することが多い．
この理由は，例えば，ナイーブベイズ分類器が出力する確率値は，0 または 1 に近い極端な値をとることが多いために，この値をそのままクラス所属確率とすると不正確になるためである\footnote{
	Zadrozny らによれば，ナイーブベイズ分類器が出力する確率は，
	その大小関係を用いた事例のランキングをうまく行うことはできる．
}~\cite{Zadrozny02}. 
また，決定木においては，少なくとも，ナイーブベイズ分類器の場合と同様の確率値の偏りおよび，
リーフに関連する訓練事例数が少ない場合に分散が大きいという 2 つの問題\footnote{
	度数が少ないことによる信頼性の低さが原因である．
}があるが，刈り込みによっても確率値の改善は期待できないため，クラス所属確率の推定値としては使えない~\cite{Zadrozny01b}.   
SVM においても，分類スコアとして用いられる分離平面からの距離が，事例がクラスに所属する程度に正確には比例しない~\cite{Zadrozny02} ために，
単純な変換では正確な値を推定しにくい．
したがって，クラス所属確率の正確な値を推定する方法についての研究が必要である.


\begin{table}[b]
\begin{center}
\caption{ビニングによる方法において参照される正解率の例}
\raisebox{1zw}[0pt][0pt]{（ナイーブベイズ分類器を利用しビンが 3 個の場合）}
\par
\label{bining1}
\input{01table01.txt}
\end{center}
\end{table}

これまでにいくつかの方法が提案されているが，代表的なものに，
Platt の方法~\cite{Platt99} や Zadrozny らにより提案された方法~\cite{Zadrozny01a,Zadrozny01b,Zadrozny02,Zadrozny05} がある． 
Platt の方法では，SVM における分離平面からの距離を分類スコアとし，
この値をシグモイド関数を利用して $[0,1]$ 区間の値に変換してクラス所属確率値の推定値とする（図~\ref{Platt} における実線）．
例えば，訓練事例により図~\ref{Platt} の実線で表されるような変換式が得られている場合に，ある事例の分類スコアが 1.5 であれば，この事例のクラス所属確率は 0.9 であると計算される．
しかし，Platt の方法では分類器やデータセットによってはうまく推定できない場合があるとして~\cite{Bennett00,Zadrozny01b}, 
Zadrozny らは決定木やナイーブベイズ分類器に対していくつかの方法を提案した~\cite{Zadrozny01a,Zadrozny01b}. 
このうち，
ナイーブベイズ分類器に適用した「ビニングによる方法」は注目に値する．
ビニングによる方法は，
訓練事例を分類スコアの順にソートして等サンプルごとに「ビン」にまとめ，各ビンごとに正解率を計算しておいたものをクラス所属確率として利用する（表~\ref{bining1} を参照のこと．表の上段の数値（斜体）は各ビンにおける分類スコアの範囲，下段の数値は各ビンの正解率を表す）． 
すなわち，評価事例の分類スコアから該当するビンを参照し，そのビンの正解率を評価事例のクラス所属確率の推定値とする．
例えば，訓練事例により表~\ref{bining1} が作成されている場合に，未知の事例の分類スコアが 0.6 であれば，この事例のクラス所属確率は 0.46 であると推定される．
Zadrozny らは，ビニングによる方法には最適なビンの個数を決定するのが困難であるという問題があるとして，
次に Isotonic 回帰による方法を提案した~\cite{Zadrozny02}. 
Isotonic 回帰による方法もビニングによる方法と同様に，訓練事例を分類スコアの順にソートすることが前提条件であるが，
ビンとしてまとめずに事例ごとに確率（正解の場合 1, 不正解の場合 0）を付ける点が異なる．
確率値は初期値 1 または 0 で開始されるが，分類スコアと単調関係を保つようになるまで修正が繰り返され，最終的に定まった値を正解率とする（表~\ref{Isotonic1} を参照のこと．表の上段の数値（斜体）は各事例の分類スコア，下段の数値は各事例の正解率を表す）．
評価事例のクラス所属確率は，評価事例の分類スコアと等しい分類スコアをもつ事例の正解率を参照し，この値を推定値とする．
例えば，訓練事例により表~\ref{Isotonic1} が作成されている場合に，未知の事例の分類スコアが 0.8 であれば，この事例のクラス所属確率は 0.5 であると推定される.

\begin{table}[b]
\begin{center}
\caption{Isotonic 回帰による方法において参照される正解率の例（SVM を利用し事例数が 10 の場合）}
\label{Isotonic1}
\input{01table02.txt}
\end{center}
\end{table}

これまでに提案された方法\footnote{
	これらの方法についての詳しい解説はこの後 2 節で行う．
}はいずれも 2 値分類を想定しているために，
クラス所属確率の推定には推定したいクラスの分類スコアのみを用いる．
したがって，文書分類でしばしば用いられる多値分類に対しても，分類スコアを単独に用いて推定する 2 値分類に分解する方法が検討された~\cite{Zadrozny02,Zadrozny05}.  
すなわち，
多値分類をいったん 2 値分類の組に分解し，それぞれの組で 2 値分類として推定したクラス所属確率の値を最後に統合（調整）する．
多値分類を 2 値分類に分解するには，all-pairs (one-versus-one) および one-against-all (one-versus-rest) の 2 つの方法があるが，
Zadrozny らは，
分解する方法そのものに精度の違いがないことを実験により示した上で，
実験においてはいずれの場合も one-against-all を用いた．
各組の 2 値分類における推定値を統合する方法としては，
one-against-all により分解した各組（クラスの数と等しい）において推定した値の合計が 1 になるようにそれぞれの推定値を正規化する方法がよい結果を示したことを報告した\footnote{
	Zadrozny らが推定値を統合する方法として提案した他の方法については，
	2.3 節で述べる．
}~\cite{Zadrozny02}. 
また，Zadrozny らによる最新の統合方法はさらに単純で，
one-against-all により分解した 2 値分類の各組において推定したクラス所属確率をそのままそのクラスについての推定値とする\footnote{
	ただし，この推定は（$\text{分類クラスの数}-{1}$）個に対して行い，
	残りの 1 クラスについては，これらの推定値を合計したものを 1 から
	引いた値を推定値とする．
}~\cite{Zadrozny05}. 
多値分類についての推定方法については Zadrozny らの研究以外になく，
例えば，Caruana らによるクラス所属確率の推定方法の比較~\cite{Mizil05} においても，2 値分類を対象としており，多値分類に対しては，Zadrozny らの文献~\cite{Zadrozny02} の紹介にとどまっている．

しかし，多値分類は 2 値分類の場合と異なり，予測されるクラスは分類スコアの絶対的な大きさではなく相対的な大きさにより決定されるために，クラス所属確率は推定したいクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられる．したがって，多値分類においては，推定したいクラス以外のクラスの分類スコアも用いることが有効であると思われる．

本稿は，多値分類における任意のクラスについてのクラス所属確率を，複数の分類スコア，特に推定したいクラスと第 1 位のクラスの分類スコアを用いて，ロジスティック回帰により高精度に推定する方法を提案する．
本稿ではまた，複数の分類スコアを用いてクラス所属確率を推定する別の方法として，「正解率表」（表~\ref{accuracy_table1} を参照のこと．表の最左列と最上段の数値（斜体）はそれぞれ第 1 位と第 2 位に予測されたクラスに対する分類スコアの範囲，それ以外の数値は、第 1 位のクラスについての正解率を表す．）を利用する方法も提案する．
正解率表を利用する方法とは，各分類スコアのなす空間を等区間（例えば 0.5）に区切って
「セル」\footnote{
	正解率表は多次元を想定するために，
	ビンではなくセルの語を用いることにする．
}を作成し，各セルについて正解率を計算した表を用意して参照する方法である．
例えば，「正解率表」を利用する方法において，
訓練事例により表~\ref{accuracy_table1} が作成されている場合，未知の事例において第 1 位に予測されたクラスの分類スコアが 0.8, 第 2 位に予測されたクラスの分類スコアが $-0.6$ であれば，この事例の第 1 位のクラスに対するクラス所属確率は 0.67 であると推定される．
しかし，もし第 2 位に予測されたクラスの分類スコアが $-0.2$ または 0.3 であれば，第 1 位のクラスについてのクラス所属確率の推定値は，それぞれ 0.53 または 0.38 のようにより小さな値になる．
このように，提案手法は既存の方法と異なり，推定したいクラス所属確率に関連すると思われる別のクラス（例えば第 2 位のクラス）の分類スコアを直接利用することで，より正確な推定を行うことが可能になる．


\begin{table}[b]
\begin{center}
\hangcaption{複数の分類スコアを用いた正解率表の例（SVM を利用し，第 1 位と第 2 位のクラスの分類スコアを用いた場合）}
\label{accuracy_table1}
\input{01table03.txt}
\end{center}
\end{table}

以下，次節で関連研究について述べた後，
3 節では，まず第 1 位に予測されたクラスのクラス所属確率を複数の分類スコアを用いて推定する方法を提案し，実験を行う．
4 節では 3 節で得られた結論を第 2 位以下の任意のクラスに対して拡張する方法を提案し，実験を行う．
最後にまとめと今後の課題について述べる．

