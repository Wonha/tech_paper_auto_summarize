自然言語処理においては，タグ付けや文書分類をはじめとするさまざまな分類タスクにおいて，分類器が出力するクラスに確信度すなわちクラス所属確率を付与することは有用である．
例えば，自動分類システムがより大きなシステムの一部を構成し，自動分類結果が別のシステムに自動入力されるような場合に，クラス所属確率は重要な役割を果たす．
この例として，ブログ記事に対してさまざまな観点から付けられたタグ（複数）をユーザに表示するシステムにおいて，タグを自動的に付与する際に，クラス所属確率が閾値より低いタグについては排除することが有効な場合がある[CITE].
同様に，手書き文字認識システムによる分類結果が，言語モデルのようなドメイン知識を組み込んだシステムの入力である場合も，クラス所属確率が用いられている[CITE].
また，自動的にタグ付けされた事例のうち誤分類されたものを人手により訂正したい場合に，すべての事例をチェックするのは大きなコストがかかるが，クラス所属確率が低いものほど不正解である可能性が高いと仮定し，クラス所属確率が閾値を下回る事例のみを訂正することにすれば，効率的な作業が行える．
さらに，自動分類結果が人間の意思決定を支援する場合においては，クラス所属確率は判断の根拠を与える．
例えば，高橋らは，社会調査において自由回答で収集される職業データを該当する職業コードに自動分類し[CITE],上位5位までに予測されたクラスを候補として画面に提示するシステム（NANACOシステム）を開発した[CITE].
NANACOシステムは，我が国の主要な社会調査であるJGSS（Japanese General Social Surveys;日本版総合的社会調査）\kern-0.5zwや，SSM調査（Social Stratification and Social Mobility Survey;社会階層と社会移動調査）\kern-0.5zwなどに利用されているが，システムを利用したコーダから，提示された各クラスについてどの程度確からしいかを示すクラス所属確率を付与してほしいという要望が出されている．
最後に，クラス所属確率はEMアルゴリズムにおいても有用である．
例えば，語の曖昧性解消において，あるドメインで訓練された分類器を，別のドメインのコーパス用に調整するために用いられたEMアルゴリズムにおいて，クラス所属確率は精度の向上に役立つことが報告されている[CITE].
事例[MATH]があるクラス[MATH]に所属するクラス所属確率[MATH]は，2値分類，多値分類のいずれにおいても[MATH]で表される．
このようなクラス所属確率の意味からは，1つの事例が複数のクラスに所属するマルチラベル分類の可能性があってもよく[CITE],またある事例の全クラスに対するクラス所属確率の推定値の総和が[MATH]である必要もない[CITE].
しかし，もし，シングルラベル分類で，全クラスに対するクラス所属確率の推定値を求めることができれば，その総和が[MATH]になるように正規化することが可能である．
このようなクラス所属確率は「正規化されたクラス所属確率」とよばれ[CITE],事後確率と考えることができる．
対象とする分類問題をシングルラベルとして扱う場合，本来は正規化されたクラス所属確率を用いる必要があると考えられる．
しかし，本稿においては，事例が注目するクラスに所属するか否かという問題に対する関心により，それぞれのクラスを独立に扱うため，一部の実験を除き基本的には正規化されたクラス所属確率を用いない．
実際には，今回の実験では，正規化を行わないクラス所属確率の推定値の総和の平均はほぼ1に等しく，また限定された実験の結果ではあるが，本稿における提案手法に関しては，正規化を行わない場合は正規化された場合とほぼ同様かやや劣る結果であるため，本稿における結論は，正規化されたクラス所属確率を用いた場合には，さらなる説得性をもつと考えられる．
クラス所属確率の推定は，分類器が出力するスコア（分類スコア）に基づいて行われる．
非常に単純には，例えばナイーブベイズ分類器や決定木では分類スコアが[MATH]の値をとるために，分類スコアをそのまま用いることができる．
また，サポートベクターマシン(SVM)のように分類スコアが[MATH]の値をとらない場合でも，最大値や最小値を利用して確率値に変換することは容易である.
しかし，このようにして得られた推定値は実際の値から乖離することが多い．
この理由は，例えば，ナイーブベイズ分類器が出力する確率値は，0または1に近い極端な値をとることが多いために，この値をそのままクラス所属確率とすると不正確になるためである[CITE].
また，決定木においては，少なくとも，ナイーブベイズ分類器の場合と同様の確率値の偏りおよび，リーフに関連する訓練事例数が少ない場合に分散が大きいという2つの問題があるが，刈り込みによっても確率値の改善は期待できないため，クラス所属確率の推定値としては使えない[CITE].
SVMにおいても，分類スコアとして用いられる分離平面からの距離が，事例がクラスに所属する程度に正確には比例しない[CITE]ために，単純な変換では正確な値を推定しにくい．
したがって，クラス所属確率の正確な値を推定する方法についての研究が必要である.
これまでにいくつかの方法が提案されているが，代表的なものに，Plattの方法[CITE]やZadroznyらにより提案された方法[CITE]がある．
Plattの方法では，SVMにおける分離平面からの距離を分類スコアとし，この値をシグモイド関数を利用して[MATH]区間の値に変換してクラス所属確率値の推定値とする（図[REF_Platt]における実線）．
例えば，訓練事例により図[REF_Platt]の実線で表されるような変換式が得られている場合に，ある事例の分類スコアが1.5であれば，この事例のクラス所属確率は0.9であると計算される．
しかし，Plattの方法では分類器やデータセットによってはうまく推定できない場合があるとして[CITE], Zadroznyらは決定木やナイーブベイズ分類器に対していくつかの方法を提案した[CITE].
このうち，ナイーブベイズ分類器に適用した「ビニングによる方法」は注目に値する．
ビニングによる方法は，訓練事例を分類スコアの順にソートして等サンプルごとに「ビン」にまとめ，各ビンごとに正解率を計算しておいたものをクラス所属確率として利用する（表[REF_bining1]を参照のこと．
表の上段の数値（斜体）は各ビンにおける分類スコアの範囲，下段の数値は各ビンの正解率を表す）．
すなわち，評価事例の分類スコアから該当するビンを参照し，そのビンの正解率を評価事例のクラス所属確率の推定値とする．
例えば，訓練事例により表[REF_bining1]が作成されている場合に，未知の事例の分類スコアが0.6であれば，この事例のクラス所属確率は0.46であると推定される．
Zadroznyらは，ビニングによる方法には最適なビンの個数を決定するのが困難であるという問題があるとして，次にIsotonic回帰による方法を提案した[CITE].
Isotonic回帰による方法もビニングによる方法と同様に，訓練事例を分類スコアの順にソートすることが前提条件であるが，ビンとしてまとめずに事例ごとに確率（正解の場合1,不正解の場合0）を付ける点が異なる．
確率値は初期値1または0で開始されるが，分類スコアと単調関係を保つようになるまで修正が繰り返され，最終的に定まった値を正解率とする（表[REF_Isotonic1]を参照のこと．
表の上段の数値（斜体）は各事例の分類スコア，下段の数値は各事例の正解率を表す）．
評価事例のクラス所属確率は，評価事例の分類スコアと等しい分類スコアをもつ事例の正解率を参照し，この値を推定値とする．
例えば，訓練事例により表[REF_Isotonic1]が作成されている場合に，未知の事例の分類スコアが0.8であれば，この事例のクラス所属確率は0.5であると推定される.
これまでに提案された方法はいずれも2値分類を想定しているために，クラス所属確率の推定には推定したいクラスの分類スコアのみを用いる．
したがって，文書分類でしばしば用いられる多値分類に対しても，分類スコアを単独に用いて推定する2値分類に分解する方法が検討された[CITE].
すなわち，多値分類をいったん2値分類の組に分解し，それぞれの組で2値分類として推定したクラス所属確率の値を最後に統合（調整）する．
多値分類を2値分類に分解するには，all-pairs (one-versus-one)およびone-against-all (one-versus-rest)の2つの方法があるが，Zadroznyらは，分解する方法そのものに精度の違いがないことを実験により示した上で，実験においてはいずれの場合もone-against-allを用いた．
各組の2値分類における推定値を統合する方法としては，one-against-allにより分解した各組（クラスの数と等しい）において推定した値の合計が1になるようにそれぞれの推定値を正規化する方法がよい結果を示したことを報告した[CITE].
また，Zadroznyらによる最新の統合方法はさらに単純で，one-against-allにより分解した2値分類の各組において推定したクラス所属確率をそのままそのクラスについての推定値とする[CITE].
多値分類についての推定方法についてはZadroznyらの研究以外になく，例えば，Caruanaらによるクラス所属確率の推定方法の比較[CITE]においても，2値分類を対象としており，多値分類に対しては，Zadroznyらの文献[CITE]の紹介にとどまっている．
しかし，多値分類は2値分類の場合と異なり，予測されるクラスは分類スコアの絶対的な大きさではなく相対的な大きさにより決定されるために，クラス所属確率は推定したいクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられる．
したがって，多値分類においては，推定したいクラス以外のクラスの分類スコアも用いることが有効であると思われる．
本稿は，多値分類における任意のクラスについてのクラス所属確率を，複数の分類スコア，特に推定したいクラスと第1位のクラスの分類スコアを用いて，ロジスティック回帰により高精度に推定する方法を提案する．
本稿ではまた，複数の分類スコアを用いてクラス所属確率を推定する別の方法として，「正解率表」（表[REF_accuracy_table1]を参照のこと．
表の最左列と最上段の数値（斜体）はそれぞれ第1位と第2位に予測されたクラスに対する分類スコアの範囲，それ以外の数値は、第1位のクラスについての正解率を表す．
）を利用する方法も提案する．
正解率表を利用する方法とは，各分類スコアのなす空間を等区間（例えば0.5）に区切って「セル」を作成し，各セルについて正解率を計算した表を用意して参照する方法である．
例えば，「正解率表」を利用する方法において，訓練事例により表[REF_accuracy_table1]が作成されている場合，未知の事例において第1位に予測されたクラスの分類スコアが0.8,第2位に予測されたクラスの分類スコアが[MATH]であれば，この事例の第1位のクラスに対するクラス所属確率は0.67であると推定される．
しかし，もし第2位に予測されたクラスの分類スコアが[MATH]または0.3であれば，第1位のクラスについてのクラス所属確率の推定値は，それぞれ0.53または0.38のようにより小さな値になる．
このように，提案手法は既存の方法と異なり，推定したいクラス所属確率に関連すると思われる別のクラス（例えば第2位のクラス）の分類スコアを直接利用することで，より正確な推定を行うことが可能になる．
以下，次節で関連研究について述べた後，3節では，まず第1位に予測されたクラスのクラス所属確率を複数の分類スコアを用いて推定する方法を提案し，実験を行う．
4節では3節で得られた結論を第2位以下の任意のクラスに対して拡張する方法を提案し，実験を行う．
最後にまとめと今後の課題について述べる．
