日本語の話し言葉では，言い淀み，言い直し，省略などのさまざまな不適格性が生じる．
例えば，([REF_eq:Sentence1])には，(i)言い直し(「ほん」が「翻訳」に言い直されている)，(ii)助詞省略(「翻訳」の後の格助詞「を」が省略されている)の2つの不適格性がある．
\enumsentence{ほん，翻訳入れます．
}
我々が提案した話し言葉の解析手法は，適格文と不適格文を統一的に扱う統一モデルに基づいている．
不適格文を扱う手法としては，従来，二段階モデル(two-stage model)に基づいたものが多かった[CITE]．
これは，まず，通常の適格文の解析手法で入力文を解析し，それが失敗した場合に，不適格性を扱うための処理を起動する，というものである．
しかし，統一モデルは，以下の点において二段階モデルに優る．
不適格文の処理はしばしば，適格文の処理と同等な能力を必要とする．
不適格文を扱うために，従来適格文の処理に使われてきた手法を拡張して使えることが望ましい．
不適格文と適格文とが曖昧な場合がある[CITE] (([REF_eq:Sentence1])の「ほん」は「本」と同じ字面なので「本(に)翻訳(を)入れます」のような適格文としての解釈が可能)．
適格文と不適格文が統一的に扱えないと，このような曖昧性は解消できない．
話し言葉(特に音声言語)の解析に必要な実時間処理は，不適格文を処理するのに二段階の過程を経る二段階モデルでは実現できないが，統一モデルでは漸時的な処理が可能なので，実時間処理を実現しやすい．
統一モデルは人間の言語処理モデルとしても妥当である．
人間がしばしば文の途中で不適格性に気づくことは，人間が適格文の処理と並行して，不適格性の検出のための処理を行なっていることを示唆する．
以下では，この統一モデルに基づく話し言葉の解析手法の概略を説明する．
本手法は，基本的には，係り受け解析の拡張である．
入力文の依存構造を生成するために，各語(文節)の間の依存関係を調べる．
例えば，([REF_eq:Sentence2])に対する依存構造と各文節の間の文法・意味関係は([REF_eq:Depend1])のようになる．
\enumsentence{会議では翻訳も入れます．
} \enumsentence{ [\DP{loct&de}会議では\Q[\DP{obje&accAct}翻訳も\Q入れます]]}ここで，\Rel{loct}, \Rel{obje}は意味関係(それぞれ「場所」「対象」)を表し，\Rel{de}, \Rel{accAct}は文法関係(それぞれ「デ格」「目的格・能動態」)を表す．
依存構造の決定と文法・意味関係の付与は，係り文節と受け文節の間の意味的な結合の強さや文法関係の実現のしやすさ(例えば「も」は「主格」になりやすいか「目的格」になりやすいか)などを考慮して，さまざまな候補に優先度を与え，最終的に最も優先度の高い組合せを見つけることによって行なう．
本手法では，通常の係り受け解析を拡張し，言い淀み，言い直しなども語と語(文節と文節)の間の依存関係ととらえる．
例えば，言い直しを含む文([REF_eq:Sentence3])の依存構造は([REF_eq:Depend2])のようになる．
\enumsentence{ほん，翻訳入れます．
} \enumsentence{ [\DP{obje&accAct} [\DP{phonRepair}ほん\Q翻訳]\Q入れます]}ここで，\Rel{phonRepair}は「ほん」と「翻訳」の間に音韻的な原因による言い直し(以下「音韻的言い直し」)によって依存関係が生じていることを表す．
このように，不適格性を扱えるよう係り受け解析を拡張することによって，適格文の最適な解釈を求める処理と不適格性を検出・修正する処理が同じ道具だてで実現できるだけでなく，適格文と不適格文との間の曖昧性にも対処できる．
本手法による構文・意味解析の過程を簡単な例題を用いて説明する．
図[REF_fig:Process]は([REF_eq:Sentence3])の解析過程である．
この文は，言い直しと助詞省略の2つの不適格性を含む．
さらに，言い直しは適格文との間で曖昧である(「ほん」は「本」と同じ字面)．
解析過程は以下の4つのステップからなる．
入力文Aを素性構造で表現された文節の列Bに変換する．
各素性構造は，音韻情報(よみ)，統語情報(語彙，範疇，形，態)，意味情報(概念，属性)を持つ．
文節の列Bから可能な依存構造の集合Cを生成する．
依存構造の集合Cに含まれる各依存関係に対して，依存関係解釈の候補Dを生成する．
解釈の候補のおのおのには，[MATH]間の実数値で表される優先度を与える．
最も優先度の大きい解釈(Dの下線部分)を選択し，文全体の依存構造と依存関係解釈Eを出力する．
この例では，Bの文節列に対して，Cの2つの依存構造が可能であり，その中に3つの依存関係が含まれる．
それぞれの依存関係に対する解釈の候補はDのようになり，下線を引いたものが最も優先度の大きい組合せとして選択される．
この過程において，助詞省略は「目的格」に解釈され，言い直しと適格文(「本(に)入れます」)との曖昧性も解消されている．
係り受け解析を基本とする我々の構文・意味解析手法においては，依存関係解釈の候補のおのおのに[MATH]間の実数値で表される優先度が与えられる．
以下では，優先度の計算法を説明する．
我々の優先度計算法は，コーパスに基づく手法である．
優先度は，その依存関係解釈が学習データ中でどのくらいの頻度で生じているかに応じて与える．
すなわち，係り文節[MATH]と受け文節[MATH]の間の依存関係解釈[MATH]の優先度[MATH]は，次式で与えられる(係り文節[MATH]と受け文節[MATH]の間に依存関係解釈[MATH]が成り立つことを\Formula{[MATH]},\betaで表す)．
分子は依存関係解釈\Formula{[MATH]},\betaの事例の頻度であり，分母は学習データ中のすべての事例の頻度の総和である．
しかし，このままでは学習データの希薄性の問題を避けられないので，分子の\Formula{[MATH]},\betaの頻度を計算する際に，完全に一致する事例だけでなく類似した事例の頻度も考慮する．
例えば，\Formula{obje}{翻訳,入れる}の頻度を計算する際に，これと類似した事例\Formula{obje}{通訳,行なう}が学習データ中にあれば，その頻度を考慮に入れるという具合である．
これを類似性に基づくスムージング(similarity-based smoothing)とよぶ．
同じ方法が言い直しなどの不適格な依存関係の解釈の優先度計算においても利用できる．
例えば，音韻的言い直しのパターン「ほん」[MATH]「翻訳」は別のパターン「どうじ」[MATH]「同時通訳」に似ているので，前者の頻度を計算する際に，後者の頻度も考慮する．
このように，さまざまな類似性を考えることによって，適格な文法・意味関係の優先度だけでなく，不適格性による依存関係の優先度も，同じ方法で計算できる．
依存関係解釈の頻度情報を獲得するために，学習データに対し人手で依存構造を付与し，そこから依存関係解釈の事例を抽出する．
これらの事例は表[REF_tab:Instance]のような表の形で書ける．
例えば，表の1行めは，「通訳」と「行なう」の間の依存関係を「対象」に解釈する事例が学習データ中に3例あったことを表す．
表中の係り文節，受け文節の欄には，解釈候補と事例との類似度を計算する際に参照される情報が書かれている．
これらは，(a)意味関係(表の第1群)では意味情報(概念，属性)，(b)文法関係(表の第2群)では統語情報(語彙，範疇，形，態)であり，(c)言い直しの関係(表の第3群)では言い直しの種類(音韻的，統語的，意味的)に応じて異なる．
係り文節[MATH]と受け文節[MATH]の間の依存関係解釈[MATH]の優先度[MATH]は，類似性に基づくスムージングを用いると，次式のようになる．
ここで，[MATH]は解釈候補\Formula{[MATH]},\betaと事例\Formula{[MATH]}{x,y}の類似度(similarity)であり，[MATH]は解釈候補に対して類似度[MATH]を持つ事例の貢献度を決める重みづけ関数(weighting function)である．
類似度と重みづけ関数の定義はいずれも，解釈[MATH]に依存して与える．
([REF_eq:Preference2])より，依存関係解釈の優先度はその解釈が学習データ中で生じる頻度確率によって与えられ，この際，解釈の頻度はそれと似た事例の頻度を(類似度に応じて重みづけして)足し合わせることによって得られる(図[REF_fig:Preference])．
これは，クラスに基づくスムージング(class-based smoothing) [CITE]の一般化になっている．
解釈候補\Formula{[MATH]},\betaと事例\Formula{[MATH]}{x,y}の類似度[MATH]は，解釈[MATH]の種類に応じて以下のように定義される．
[MATH]と[MATH]および[MATH]と[MATH]のそれぞれについて，意味情報に関する類似度を求めたものの相乗平均．
すなわち，
ここで，[MATH]と[MATH] (および[MATH]と[MATH])の意味的類似度[MATH]は，意味シソーラス上の距離に基づいて計算する[CITE]．
意味シソーラスは角川類語新辞典[CITE]のものを用いている．
[MATH]と[MATH]および[MATH]と[MATH]のそれぞれについて，統語情報に関する類似度を求めたものの相乗平均．
すなわち，
ここで，[MATH]と[MATH] (および[MATH]と[MATH])の統語的類似度[MATH]は，統語範疇の階層上の距離に基づ
いて計算する．
統語範疇の階層は意味シソーラスを模して作成した．
[MATH]と[MATH]および[MATH]と[MATH]のそれぞれの類似度を求め，その差を1から引いたもの．
すなわち，
ここで，[MATH]と[MATH] (および[MATH]と[MATH])の類似度[MATH]は，言い直しの種類(音韻的，統語的，意味的)に応じて，[MATH], [MATH], [MATH]を用いる．
解釈[MATH]が意味関係もしくは文法関係の場合には，候補と事例に関して，係り文節同士，受け文節同士のそれぞれについて類似度を求め，その相乗平均をとる．
しかし，[MATH]が言い直しの関係の場合には同じ方法は使えない．
例えば，音韻的言い直しのパターン「ほん」[MATH]「翻訳」と別のパターン「どうじ」[MATH]「同時通訳」は，直観的に似ていると感じるが，係り文節同士(「ほん」と「どうじ」)は似ていない．
この場合，係り文節同士，受け文節同士の類似性を独立に調べるのは適当でない．
むしろ，言い直しパターン全体としての類似性を調べる必要がある．
そのために，まず，言い直しパターンを数値によってコード化する．
言い直しでは通常，係り文節(修復対象)と受け文節(訂正部分)が何らかの点において類似している．
ここで，「何らかの点」とは言い直しの種類に依存して決まる(例えば「音韻的言い直し」では音韻情報に関して類似している)．
したがって，修復対象と訂正部分の類似度によって，その言い直しのパターンをコード化することができる．
修復対象と訂正部分の類似性が大きい(あるいは小さい)言い直し同士は互いに似ていると考えることにすると，2つの言い直しパターンのコードの差によってそれらの間の類似度を定義することができる．
例えば，上記の2つの音韻的言い直しのパターンでは，[MATH]および[MATH]より，両者の類似度は[MATH]となる．
解釈候補に対して類似度[MATH]を持つ事例の貢献度を決める重みづけ関数[MATH]は以下の3条件を満たすべきである．
(i)貢献度は0以上1以下であり([MATH]の値域は[MATH])，(ii)類似度が1の事例の貢献度は最大値1をとり([MATH])，(iii)類似度が大きい事例ほど貢献度も大きい([MATH]は
単調増加関数)．
おのおのの解釈[MATH]ごとに，この3条件を満たす重みづけ関数[MATH]を，次のような単純な多項式形式で与える．
ここで，[MATH]はある正の定数であり，係数[MATH]は次式を満たす．
係数[MATH]は以下のようにして決める．
類似性に基づくスムージングは，別の見方をすると，学習データによって部分的に与えられた事例の分布から真の分布を推定しているとみることが
できる．
いま，事例\Formula{[MATH]},\betaの真の頻度を[MATH]，推定された頻度を[MATH]とすると，類
似性に基づくスムージングによる推定では，[MATH]は([REF_eq:Preference2])の分子で与えられる．
したがって，推定値の二乗誤差[MATH]のすべての事例\Formula{[MATH]},\betaにわたる和を最小にするよ
うに，重みづけ関数の係数を決めればよい．
これを行なうためには，すべての事例の真の頻度がわかっている必要がある．
ここでは，これを近似的に行なうために，学習データ中の各事例の頻度そのものが真の頻度を与えていると考え，その代わりに，各事例の推定頻度は学習データ中でその事例を除いた残りの部分から類似性に基づくスムージングによって与えられると考える(ジャックナイフ式の推定)．
簡単な計算により，この二乗誤差最小化の問題は二次計画問題に帰着できることがわかり，したがって解析的に解ける．
最後に，文法関係の解釈の優先度について注意を述べる．
([REF_eq:Depend1]), ([REF_eq:Depend2])に見られるように，適格な依存関係は意味関係と文法関係の両面から解釈される．
一般に，両者の解釈は独立ではない．
すなわち，どの意味関係解釈が選択されたかに依存して，可能な文法関係の解釈の範囲が異なる．
したがって，文法関係の優先度は条件つき(conditional)の形で与えなければならない．
係り文節[MATH]と受け文節[MATH]の間の依存関係を意味関係[MATH]と文法関係[MATH]に解釈する際の優先度は，確率論にしたがうと，次式のようになる．
ここで，文法関係解釈の優先度[MATH]は条件つきの形で与えられており，条件は意味関係解釈[MATH]と係り文節[MATH]，受け文節[MATH]によって課される．
ただし，意味関係解釈は統語情報のうち形と態は制限しない(意味関係が「対象」であっても係り文節の形は「を」「も」「無」のいずれでもあり得る)ので，[MATH], [MATH]ではこれらの情報が「関知せず(don't care)」になっている．
類似性に基づくスムージングを用いた条件つき優先度は，次式で与えられる．
ただし，分子の\Formula{[MATH]}{x,y}と分母の\Formula{[MATH]}^*,\beta^*はいずれも意味関係解釈[MATH]と共起するものだけを対象とする．
しかし，([REF_eq:Conditional1])では，今度は，分母に関して学習データの希薄性が問題になる．
そこで，分母に対しても類似性に基づくスムージングを用いる．
その結果，優先度は次式のようになる．
([REF_eq:Conditional2])がどのように働くかを簡単な例で説明する．
助詞省略を含む依存関係[\DP{obje&accAct}翻訳入れます]において，文法関係解釈\Rel{accAct}の優先度を計算することを考える(図[REF_fig:Conditional])．
分子は，解釈候補\Formula{accAct}{翻訳,入れます}と似た事例の頻度の加重和によって与えられる．
ここで，統
語情報の類似度は形が一致するときのみ非ゼロの値をとる(図[REF_fig:Conditional]で[MATH]はゼロ，[MATH]は非ゼロ)よう
に定義されており，よって，係り文節の形が「無」のもの(つまり助詞省略を含むもの)だけが分子の計算に貢献する．
一方，分母は，係り文節と受け文節がそれぞれ「サ変名詞」「がを動詞」に類似したすべての事例の頻度の加重和である．
したがって，この文法関係解釈の優先度は，概言すると，「係り文節と受け文節がそれぞれ「サ変名詞」「がを動詞」に似ている事例において，目的格の助詞が省略される確率」によって与えられる．
