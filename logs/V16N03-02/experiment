実験と評価

単語の関連性に着目した提案手法の有効性を検証するため情報検索システムテストコレクションNTCIR3-WEBを用いて，表記を用いる他の手法との比較実験を行った．比較手法としては，ベクトル空間モデル，Okapi BM25と，同じ索引語間の距離を0，それ以外を1とした素朴なEMDを用いた．


\subsection{評価方法}
\label{evaluation method}

今回の評価では，検索課題41件と正解文書とランダムに選択した文書を合わせた10,000件の文書を使用し，評価実験を行った．また，正解文書リストが存在し，各検索課題に対して，各文書がH（高適合），A（適合），B（部分的適合），C（不適合）の4段階の適合度が設定されており，以下の基準で評価する．

LEVEL1: H判定とA判定を適合

LEVEL2: H判定とA判定とB判定を適合

各検索課題に対して，10,000件の検索対象全てのスコアを求め，スコア順に並べ変える．そして，正解文書リストを参照し正解文書の順位を調べ評価する．


\subsection{評価指標}

評価指標には，各検索課題毎の平均精度 (Avelage Precision，AP)，平均精度の平均 (Mean Average Precision，MAP) と再現率—精度グラフを使用した．検索課題に対する平均精度APは式\ref{eq:average_precision}のように定義される．まず順位$i$位の文書が適合しているならば1，そうでなければ0となる変数を$z_i$とする．$S$を適合文書の総数，$n$は出力文書数である．
\begin{equation}\label{eq:average_precision}
 AP=\frac{1}{S}\sum_{i=1}^{n} \frac{z_i}{i}\left( 1+\sum_{k=1}^{i-1} z_k \right)
\end{equation}
平均精度の平均(MAP)は，全ての検索課題に対して平均精度を平均したものであり，式\ref{eq:mean_average_precision}によって求められる．具体的には，検索課題が$K$件ありそれぞれの課題に対するあるシステムの平均精度を$AP_h$と表記すれば$(h=1,...,K)$，
\pagebreak
その平均がMAPに相当し，以下の式に示す．
\begin{equation}\label{eq:mean_average_precision}
 MAP=\frac{1}{K}\sum_{h=1}^{K}AP_h
\end{equation}
再現率—精度グラフとは再現率の11個の点ごとに，41個の検索課題の精度を平均してグラフを描いたものである．


\subsection{比較手法}

本節では，提案手法との比較に用いているベクトル空間モデル\cite{Salton:75}とOkapiBM25 \cite{Robertson:95}について述べる．


\subsubsection{ベクトル空間モデル}

ベクトル空間モデルは，情報検索の分野で幅広く利用されている検索モデルである．各語の重みから構成されるベクトルとして検索課題と文書をそれぞれ表現し，二つのベクトルの成す角度の余弦によって類似度を計算する点に特徴がある．重みの種類にはいくつかの種類があるが，本実験では\ref{tf_idf}節で説明したtf・idf重みを用いる．検索課題$q$と文書$d_i$の索引語の語の総数（異なり）を$M$とすれば，文書と検索課題はそれぞれ以下のような$M$次元ベクトルで表現できる．
\begin{gather}
 d_i=(w_{i1},w_{i2},…,w_{iM}) \\
 q=(w_{q1},w_{q2},…,w_{qM})
\end{gather}
検索課題$q$に対する文書$d_i$の得点$s_q(d_i)$は2つのベクトルの角度の余弦により求まる．式を以下に示す．
\begin{equation}
 s_q(d_i)=\frac{\sum_{j=1}^M w_{ij}w_{qj}}{ \sqrt{\sum_{j=1}^M w_{ij}^{2}} \sqrt{\sum_{j=1}^M w_{qj}^{2}} }
\end{equation}


\subsubsection{Okapi BM25}

S. Robertsonを中心に開発されたOkapiと呼ばれる次世代検索システムにおいて使用されている確率型の検索モデルBM25は，ベクトル空間モデルと同等，あるいはそれ以上の性能を示すことでよく知られている．原理的には，検索課題$q$と文書ベクトル$d_i$が与えられた時に，その文書が検索課題に適合している確率を推計するものである．検索課題$q$と文書$d_i$の索引語の語の総数（異なり）を$M$とすれば，検索課題$q$に対する文書$d_i$の得点$s_q(d_i)$は以下の式で表される．
\begin{equation}
 s_q(d_i)=\sum_{j=1}^M(w_{ij}\times x_{qj} \times \tau_j)
\end{equation}
ただし，$x_{qj}$は検索課題$q$での語$t_j$の出現回数である．ここで
\begin{gather}
 w_{ij}=\frac{3.0 x_{ij}}{(0.5+1.5l_i / \bar{l})+x_{ij}} \\
 \tau_j=\log\frac{N-n_j+0.5}{n_j+0.5}
\end{gather}
である．$x_{ij}$は文書$d_i$での$t_j$の出現回数であり，$N$は文書総数で，$n_j$は語$t_j$が出現する文書数である．なお，
\begin{equation}
 l_i=\sum_{j=1}^M{x_{ij}}
\end{equation}
は文書$d_i$の長さであり，
\begin{equation}
 \bar{l}=\frac{1}{N}\sum_{i=1}^N{l_i}
\end{equation}
はデータベース全体での文書長の平均を意味する．


\subsection{評価結果}

平均精度の平均 (MAP) を表\ref{table:MAP_with_other_method}に示す．再現率—精度グラフを図\ref{fig:RPC_with_other_method(level1)}，\ref{fig:RPC_with_other_method(level2)}に示す．

\begin{table}[b]
\caption{MAP（表記のみ活用する他の手法との比較）}
\label{table:MAP_with_other_method}
\input{02table11.txt}
\end{table}

表\ref{table:MAP_with_other_method}より，LEVEL1では提案手法の精度はベクトル空間モデルより20.30\%，Okapi BM25より17.91\%，EMDより9.22\%の精度向上を達成し，LEVEL2では提案手法の精度はベクトル空間モデルより10.71\%，Okapi BM25より9.45\%，EMDより4.03\%の精度向上を達成した．

図\ref{fig:RPC_with_other_method(level1)}，\ref{fig:RPC_with_other_method(level2)}より全ての再現率レベルで精度が改善している．この結果より単語間の関連性にもとづき文書間の類似性を求める本手法が有効であることがわかる．また，ベクトル空間モデルより素朴なEMDがよりよい結果となっている．これは，EMDが輸送問題として距離を計算していることに起因する．

例えば，検索課題を$(\sqrt{3}/2,1/2)$としたとき，ベクトル空間モデルでは$(1,0)$と$(1/2,\sqrt{3}/2)$では同じ類似度の0.866となるが，EMDでは0.134と0.268と異なり，(1,0)の方が検索要求に近くなる．これは$(1,0)$では一番目の方が大きいが，$(1/2,\sqrt{3}/2)$では反転していることが理由である．本実験ではこの効果が良い方に働いていると考えられる．

\begin{figure}[t]
\begin{center}
\includegraphics{16-3ia2f6.eps}
\caption{LEVEL1での再現率—精度グラフ（他手法との比較）}
\label{fig:RPC_with_other_method(level1)}
\end{center}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics{16-3ia2f7.eps}
\caption{LEVEL2での再現率—精度グラフ（他手法との比較）}
\label{fig:RPC_with_other_method(level2)}
\end{center}
\end{figure}

次に，比較手法と提案手法が統計的に有意な差があるか検定を行った．検定方法は参考文献\cite{kishida:01}を参考にした．以下にその検定方法を述べる．

比較する2つの手法を$a$と$b$，検索課題数を$K$，検索課題$h$の平均精度を$v_h$とし，MAPを$\bar{v}=K^{-1}\sum_{h=1}^K v_h$とする．同一の検索課題に対する2つの平均精度を比較することになるので，対標本と捉えることができ，検索課題ごとの手法間の差自体を標本と考える．すると，帰無仮説「2つの手法の平均精度の母平均の差は0である」の下に正規母集団を仮定すれば，
\begin{equation}
 t=\frac{\bar{v_a}-\bar{v_b}}{\sqrt{\frac{s_a^2+s_b^2-2Cov_{ab}}{K}}}
\end{equation}
が自由度$K-1$の$t$分布に従うことになる．この時，$s_a^2$と$s_b^2$は平均精度の標本分散であり，
$Cov_{ab}$は$v_{ha}$と$v_{hb}$との共分散で，$Cov_{ab}=(K-1)^{-1}\sum_{h=1}^{K}(v_{ha}-\bar{v_a})(v_{hb}-\bar{v_b})$となる．

この検定方法を利用し，今回の実験でのLEVEL1における提案手法と比較手法の中で一番評価が高かった素朴なEMDとの評価に有意な差があるかどうか片側検定を行う．$a$を提案手法，$b$を素朴なEMDとすると，$s_a^2=0.071701$，$s_b^2=0.067863$，$\bar{v_a}-\bar{v_b}=0.044005$，$Cov_{ab}=0.056419$となるので，$t=1.723548$となる．自由度40の$t$分布に従うので，$1.723548>1.684$より，帰無仮説は棄却され，5\%水準で提案手法と素朴なEMDとの差は有意であることがわかる．また，同様の検定をベクトル空間モデルと行うと$t=3.01916$，OkapiBM25では$t=3.563336$となり1\%水準で有意な差があることを確認できた．提案手法が表記に頼る比較手法に比べ統計的に有意な差があることがわかった．


概念ベースの自動拡張手法の評価

概念ベースの自動拡張手法の効果を検証するために，自動拡張手法を用いない手法（概念ベースに存在しない索引語で同じ索引語間の距離を0それ以外の距離を1）と提案手法との比較評価を行った．評価方法は\ref{evaluation method}節と同様の方法で行った．
以下，自動拡張手法を用いないEMDと概念ベースを組み合わせた手法をEMD＋CBと記す．平均精度の平均 (MAP) を表\ref{table:MAP(level1)}に示す．再現率—精度グラフを図\ref{figure:RPC(level1)}，\ref{figure:RPC(level2)}に示す．
表\ref{table:MAP(level1)}から分かるように，LEVEL1において1.58\%の精度向上を達成し，LEVEL2において3.04\%向上している．LEVEL1においては全ての再現率レベルで提案手法がEMD+CBを上回っているが，LEVEL2においては再現率レベル0.3の点で0.0001だけEMD＋CBを下回っている．
より詳細に検証するために，検索課題ごとの平均精度の差をプロットしたものを図\ref{figure:difference_from_average_precision}に示す．横軸は本実験における検索課題の番号（1〜41）で，縦軸は検索課題毎のグラフが上に伸びているほど自動拡張手法によって精度が向上したことを示し，逆に下にのびているほど精度は低下していることを示している．この結果から検索課題14と検索課題29の時に精度の低下が著しいことがわかる．



\begin{table}[b]
\caption{MAP（自動拡張手法使用と未使用での比較）}
\label{table:MAP(level1)}
\input{02table12.txt}
\end{table}

課題14は「宮部みゆきの執筆した小説に対する書評・レビューが読みたい」という課題で，課題29は「シフォンケーキの作り方が書かれている文書を探したい．」といった課題である．これらに形態素解析を施し，検索課題idfによる不要語の削除を行うと，検索課題14は「宮部／みゆき／執筆／小説／書評／レビュー」となり，検索課題29は「シフォンケーキ／作り方」となる．このうち未定義語は「宮部／シフォンケーキ」であった．

\begin{figure}[t]
\begin{center}
\includegraphics{16-3ia2f8.eps}
\caption{LEVEL1での再現率—精度グラフ（自動拡張手法使用と未使用での比較）}
\label{figure:RPC(level1)}
\end{center}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics{16-3ia2f9.eps}
\caption{LEVEL2での再現率—精度グラフ（自動拡張手法使用と未使用での比較）}
\label{figure:RPC(level2)}
\end{center}
\end{figure}

検索課題14と検索課題29における上位25件の順位の変動を図\ref{figure:change_of_order}に示す．図\ref{figure:change_of_order}において色が付いてる文書がLEVEL1における正解文書である．一番精度低下が著しかった課題29で，EMD+CBにおいて47位であった不適合文書が提案手法では3位に，5位であった不適合文書が4位になり，適合文書が3位から5位に下がった．提案手法において5位であった高適合文書と3位であった不適合文書を図\ref{figure:high_conformity_document}，\ref{figure:non_conformity_document}に示す．
3位の文書はケーキ屋の紹介が書かれている文書で，4位の文書もケーキに関する文書であった．5位の高適合文書はシフォンケーキの作り方の手順が書いてあった．提案手法では，シフォンケーキがケーキに関する様々な語と高関連であると判定し，ケーキに関する文書が検索の上位にきてしまった．ユーザは「ケーキの作り方」と入力せず「シフォンケーキの作り方」と入力したのはケーキ全般の情報よりシフォンケーキに絞った情報が欲しいといったことを暗に示していると考えられ，シフォンケーキを定義してしまったことが悪影響を及ぼしてしまった．

\begin{figure}[t]
\begin{center}
\includegraphics{16-3ia2f10.eps}
\caption{課題別の平均精度の差}
\label{figure:difference_from_average_precision}
\end{center}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics{16-3ia2f11.eps}
\caption{課題14と課題29における上位25件のランク付け}
\label{figure:change_of_order}
\end{center}
\end{figure}

シフォンケーキのようなケーキといった一般的な語に比べ，具体的な語はユーザが検索結果を絞るために用いる語であり，具体的な語に対しては，表記に頼る方が有効に働くと考えられる．具体的な語を判別し，なんらかの対応を行うことでこの問題は解決できると考えられる．

\begin{figure}[t]
\begin{center}
\includegraphics{16-3ia2f12.eps}
\caption{高適合文書}
\label{figure:high_conformity_document}
\end{center}
\vspace{-0.5\baselineskip}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics{16-3ia2f13.eps}
\caption{不適合文書}
\label{figure:non_conformity_document}
\end{center}
\vspace{-1\baselineskip}
\end{figure}


