体系的に整理された辞書であるWordNet [CITE]を用いて単語間の距離を定義し，EMDにより文書間の類似度を定義する手法[CITE]が提案されている．
これにより単語の意味的な関連性に着目した情報検索が実現されている．
また，単語の共起情報をもとに単語間の関連性を定義し，EMDにより文書間の類似度を定義する手法が提案されている[CITE]．
この手法では，単語の共起情報を用いることにより，全ての単語間の関連性を定義し，文書間の類似度を定義することを実現している．
しかしながらこれらの手法の問題点として，WordNetなどの整理された辞書を用いる場合は，索引語の全てが辞書に含まれる保証がなく，全ての索引語間の関連性を求めることができない可能性がある．
共起情報を手がかりにした場合は，用いる文書集合の特性や容量の影響を大きく受け，正確に関連性を定義しているとは言い難い．
提案手法では，概念ベースを用いて索引語間の関連性を求め，さらに概念ベースに存在しない語においてはWebをもとに自動的に概念として定義する．
これにより，単語間の関連性をより正確に定義し，さらにあらゆる新語に対応できる索引語の網羅性を実現する．
本研究では提案手法の効果を検証するため，日本での代表的な情報検索システム評価用のテストコレクションであるNTCIRを用いた．
NTCIRは文献データ集合，検索課題集合，各検索課題に対する文献の適合不適合判定からなるもので，同一のテストコレクションを利用することにより共通の基準で情報検索システムを評価することができるようにしたものである．
その中でも，本研究では一般の利用者が実際に検索する環境に近いWeb検索用のテストコレクションであるNTCIR3-WEBを用いた．
図[REF_fig:example_of_problem]にNTCIR3-WEBの検索課題の一例を示す．
検索課題にはNUM，TITLE，DESC，NARR，CONC，RDOC，USERの7つのフィールドが含まれているが，このうち標準的なフィールドはTITLE (title)，DESC (description)，NARR (narrative)，CONC (concept)の4つである．
TITLEとは検索課題の内容を簡単に表したタイトル，DESCは検索する内容を文で記述したもの，NARRは検索する内容の詳細な説明，CONCは検索する内容を表すキーワードである．
本研究では検索要求を文章で入力するシステムの開発を想定し，DESCのみを使用する．
図[REF_fig:example_of_object]に検索対象（HTMLもしくはプレーンテキストファイル．
言語は主に日本語と英語，ごく一部にその他の言語．
100 GB）の一例を示す．
実験には検索対象のタグを省いた全文を用いる．
本研究は日本語での検索を想定している．
日本語は英語などとは異なり，単語間に明確な区切りがない．
そこで，文章から単語を切り出す必要がある．
本研究では形態素解析器を用いて行う．
日本語構造の制約を利用し，単語の切り出しや品詞を同定することを形態素解析という．
例えば，形容詞は名詞の前に付くことができるという法則である．
実際は，日本語の複雑さのため完全に単語を切り出すことは難しいが，代表的な形態素解析器である茶筌は様々な工夫により高い精度で単語を正しく切り出すことができる．
本研究では単語の切り出しに茶筌を用い，「名詞」，「形容詞」，「動詞」を索引語として用いる．
索引語に対する重み付けは，情報検索の分野で広く用いられているtf・idf重み付け[CITE]を使用する．
tf・idfによる重み付けとは，対象としている単語の頻度と網羅性に基づいた重み付け手法である．
文書[MATH]における索引語[MATH]の重み[MATH]は以下の式[REF_eq:tfidf]によって得られる．
[MATH]は文書[MATH]における索引語[MATH]の出現頻度である．
ただし，[MATH]は文書長の影響を受けやすいため，本論文では以下の式[REF_eq:tf]に示す正規化手法を用いた．
単語[MATH]の出現頻度を[MATH]，文書[MATH]に含まれる単語数を[MATH]とする．
また，[MATH]は文書数[MATH]と索引語[MATH]が出現する文書の数[MATH]によって決まり，式[REF_eq:idf]によって定義される．
本研究では不要語を削除するために評価データの実験に使用する検索対象の空間でのidf値をもとに検索対象内の不要語を削除した．
不要語とは「する」や「こと」のような，どの文書にも出現し，文書を特定するために有効でない語を指す．
検索対象の不要語削除の閾値は提案手法が適合判定レベルのLEVEL1においての評価(MAP)がidf値0から9の間で一番高くなるidf値5に設定した．
適合判定LEVELと評価(MAP)などの評価方法については[REF_evaluation method]節で述べる．
さらに検索課題空間でのidf値を利用し検索課題の索引語中の不要語を削除した．
削除の例を図[REF_fig:example_of_word]に示す．
これにより検索課題によく出現する「文書」や「様々」などの語を削除でき，検索課題として比較的意味があると考えられる「将来」，「歴史」，「地域」などを残すことができる．
この閾値は目視により設定した．
概念ベースとは複数の国語辞書や新聞などから機械的に構築した単語（概念）とその意味特徴を表す単語（属性）の集合からなる知識ベースである．
概念には属性とその重要性を表す重みが付与されている．
概念ベースには約12万語の概念表記が収録されており，1つの概念に平均約30個の属性が存在する．
ある概念[MATH]は属性[MATH]とその重み[MATH]の対の集合として，式[REF_eq:concept_base]で表される．
任意の一次属性[MATH]は，その概念ベース中の概念表記の集合に含まれている単語で構成されている．
したがって，一次属性は必ずある概念表記に一致するため，さらにその一次属性を抽出することができる．
これを二次属性と呼ぶ．
概念ベースにおいて，「概念」は[MATH]次までの属性の連鎖集合により定義されている（図[REF_fig:concept_base]）．
以下に，本研究で使用した大規模概念ベースの構築方法について述べる．
まず，基本となる概念ベースを複数の国語辞書から構築する．
概念は国語辞書の見出し語から，属性は見出し語の語義説明文の自立語から，その重みは自立語の出現頻度に基づいて決定される[CITE]．
そして，属性信頼度（語に関する種々の知識から属性としての確からしさを定量化した値）により不適切な属性の削除を行い，信頼性の高い属性を抽出する[CITE]．
これらにより概念数約3万4千語で平均属性数が16個の基本となる概念ベースが構築される．
複数の国語辞書には約12万語の見出し語（辞書に収録されている約20万語語彙のうち見出し語として不適切な表記を除去した語）があり，辞書中の語義説明文だけでは属性が付与できない語が約9万語もあった．
そこで，概念総数と属性数を拡張するために電子化新聞（毎日新聞，日本経済新聞）を用いて，各概念に対する共起語を属性候補として追加する．
この際，もともと概念ベースに定義されている概念についても，同様に属性を取得する．
その後，[REF_degree_of_association]節で説明する関連度計算により概念と属性の関連の強さを求め，その値と概念ベースの頻度情報をもとに属性の重み付けを行う．
以上の処理により本研究で使用した概念数が約12万語，平均属性数約30個の大規模概念ベース[CITE]が構築できる．
概念ベースを用いた単語間の関連性の定量化は，基本的に語意の展開結果を利用し数値として表す．
何次属性まで展開するか，どの属性を用いるかによって値が変わってくるため，状況に応じてどのように計算するかが問題になってくる．
そこで本研究では二種類の方法を使い分ける．
文書間の類似度を求めるための単語間の関連性の定量化には，概念ベースの一次属性までを使用する一致度を用い，概念ベースの自動拡張手法における単語間の関連性の定量化には，概念ベースの二次属性までを使用する関連度計算[CITE]を使用する．
二次属性までを使用する方法が，概念ベースを用いた単語間の関連性の定量化には一番有効であると報告されている[CITE]．
一次属性までしか展開しないと，関連が薄い概念同士の関連性を定量化できず，三次属性まで用いると概念とはかけ離れた語が属性となり，雑音として働くため精度が低下してしまう．
本研究では，文書を概念と文書間の類似度を求めるための単語間の関連性の定量化には一次属性までしか展開しない一致度を用いる．
これは文書を概念と見立てた場合，索引語が一次属性となり，索引語の属性が二次属性となる．
つまり，索引語の二次属性まで展開すると文書を概念とした場合の三次属性まで展開したこととなり雑音が増加し，概念（文書）とはかけ離れた語が計算に使用されてしまうためである．
任意の概念[MATH]，[MATH]について，それぞれ一次属性を[MATH]，[MATH]とし，対応する重みを[MATH]，[MATH]とする．
また，概念[MATH]，[MATH]の属性数を[MATH]個，[MATH]個[MATH]とする．
A={(a_i,u_i) \mid i=1〜L}
B={(b_j,v_j) \mid j=1〜M}
このとき，概念[MATH]，[MATH]の一致度[MATH]を以下の式[REF_eq:MatchWR1]，[REF_eq:MatchWR2]で定義する．
MatchWR(A,B)=\sum_{a_i=b_j}\min(u_i,v_j)
\min(\alpha,\beta)=
\alpha & (\beta > \alpha)
\beta & (\alpha\geq\beta)
.
ただし，各概念の重みの総和をそれぞれ1に正規化する．
概念[MATH]，[MATH]の属性[MATH]，[MATH]に対し，[MATH] =[MATH]（概念[MATH]，[MATH]に共通する属性がある）となる属性があった場合，共通する属性の重みの共通部分，つまり，重みの小さい分だけ有効に一致すると考え，その合計を一致度とする．
定義から明らかなように両概念の属性と重みの両方が完全に一致する場合には一致度は1.0となる．
関連度計算は概念の二次属性間の一致度計算により求めた値をもとに概念間の関連性を数値として算出する．
具体的には，計算する二つの概念の内，一次属性の数の少ない方の概念を[MATH]とし[MATH]，概念[MATH]の一次属性を基準とする．
そして概念[MATH]の一次属性を，概念[MATH]の各一次属性との一致度[MATH]の和が最大になるように並び替える．
これによって，概念[MATH]の一次属性と概念[MATH]の一次属性の対応する組を決める．
対応にあふれた概念[MATH]の一次属性は無視する（この時点では組み合わせは[MATH]個）．
ただし，一次属性同士が一致する（概念表記が同じ）ものがある場合([MATH])は，別扱いにする．
これは概念ベースには約12万の概念表記が存在し，属性が一致することは稀であるという考えに基づく．
従って，属性の一致の扱いを別にすることにより，属性が一致した場合を大きく評価する．
具体的には，対応する属性の重み[MATH]，[MATH]の大きさを重みの小さい方にそろえる．
このとき，重みの大きい方はその値から小さい方の重みを引き，もう一度，他の属性と対応をとることにする．
例えば，[MATH]で[MATH]とすれば，対応が決定するのは[MATH]と[MATH]であり，[MATH]はもう一度他の属性と対応させる．
このように対応を決めて，対応の取れた属性の組み合わせ数を[MATH]個とする．
このとき，概念[MATH]，[MATH]の一致度[MATH]を以下の式[REF_eq:DoA]により定義する．
関連度の値は概念間の関連の強さを0〜1の間の連続値で表す．
1に近づくほど関連が強い．
概念[MATH]と[MATH]に対して関連度計算を行った例を表[REF_table:degree_of_association]に挙げる．
最後に，概念「机」と「椅子」を例に用いて，関連度の計算例を説明する．
概念「机」と「椅子」の一次属性および二次属性を表[REF_tab:example_primary_attribute]，表[REF_table:example_secondary_attribute]に示す．
まず，概念「机」と「椅子」の一致度の計算を行う．
例えば，概念「机」の一次属性「学校」と概念「椅子」の一次属性「木」は，「木造」という共通する属性を持っているため，一致度は以下のように計算される．
同様に全ての一次属性の組み合わせについて一致度を計算した結果を表[REF_table:example_dom_matrix]に示す．
次に，関連度の計算を行う．
関連度の計算は，まず属性が完全に一致している部分から行われる．
続いて，一致度の大きい部分から順に対応を決める．
この場合，表[REF_table:example_dom_matrix]から一次属性「勉強」と「勉強」，「学校」と「教室」，「本棚」と「勉強」の順に対応が決まることになる．
結果，関連度は次式のように計算される．
DoA(机,椅子) & =1.0\times(0.3+0.3)\times(0.3/0.3)/0.2+0.4\times(0.6+0.3)\times(0.3/0.6)/2
&　+0.1\times(0.1+0.2)\times(0.1/0.2)/2
& =0.3975
本研究では[REF_addict]節で述べる概念ベースに属性として追加する概念と追加される側の概念との間の関連性の定量化に関連度計算を用いる．
概念ベースに存在しない語（未定義語）にも属性を与えなければ，未定義語と他の単語との関連性を求めることができない．
そこで，現在考えうる最大の言語データであるWeb情報をもとに未定義語の概念化を行い，概念ベースに追加する方法を提案する．
本章ではこの手法について説明する．
以下の手順により，未定義語の概念化を行うために，未定義語の属性とその重みをWebから獲得する．
入力された未定義語をキーワードとして検索エンジンを用いて検索を行い，検索上位100件の検索結果ページの内容を取得する．
HTMLタグなど不要な情報を取り除いた文書群に対して，形態素解析を行い，自立語を抽出する．
得られた自立語の中から概念ベースに存在する単語のみを未定義語の属性として抜き出す．
得られた属性の頻度にWeb上の単語のidfを統計的に調べたもの(SWeb-idf) [CITE]の値を掛け合わせたものを属性の重みとし，得られた重み順に並び替える．
SWeb-idfについては次節で説明する．
なお，SWeb-idfのデータベースに存在しない属性については，Web上にあまり存在しない単語と考え，SWeb-idf値の最大値を掛け合わせている．
表[REF_table:attribute_unknown_word]に未定義語を概念化した例を示す．
SWeb-idf (Statics Web-Inverse Document Frequency)とは，Web上の単語のidfを統計的に調べたidf値である．
まず，無作為に選んだ固有名詞1,000語を作成する．
表[REF_table:proper_noun]に無作為に選択した固有名詞の一部を示す．
この作成した1,000語に対して個々に検索エンジンで検索を行い，1語につき検索上位10件の検索結果ページの内容を取得する．
よって，得られた検索結果ページ数は10,000ページとなる．
この10,000ページから，複数の国語辞書や新聞などから概念（単語）を抽出した知識ベースである概念ベースの収録語数である約12万語とほぼ同等の単語数が得られたことから，獲得した10,000ページをWebの全情報情報空間とみなしている．
そして，その中での単語のidf値を表すSWeb-idfは，式[REF_eq:SWeb-idf]で求められる．
これらにより得られた単語とそのidf値をデータベースに登録した．
なお[MATH]項は，全文書空間（10,000ページ）に出現する概念[MATH]のページ数である．
獲得したSWeb-idfの値の例を表[REF_table:SWeb-idf]に挙げる．
なお，固有名詞の選び方を変えてもSWeb-idfの値に大きな変化は見られないという報告がなされている[CITE]．
未定義語の属性の重みはSWeb-idfによっても求まるが，Web情報と概念ベースでは語の頻度情報が異なり重みの値も変わるため，Web情報の重みをそのまま用い概念ベースに追加すると概念ベースの頻度情報に歪みが生じる．
よってSWeb-idfは未定義語の属性候補を獲得する時にのみ用い，未定義語の属性の重み付けには使用せず，概念ベースに未定義語を追加する場合には概念ベースの頻度情報を用いて重み付けを行う必要がある．
そこで，未定義語の属性に対して重みを付与する方法として，概念ベースの属性空間を考慮した重み付け手法を提案する．
概念に付与された属性は，特徴を表す語であるため，概念の説明文書であると捉えることが出来る．
この文書空間内での属性の出現頻度を，概念に対する属性の確からしさだと考える．
例として「個人情報」の属性を表[REF_table:1st_and_2nd_attribute_of_new_concept]に示す．
網掛けのセルに一次属性，各網掛けの下方のセルにはその二次属性を示している．
個人情報という概念を特徴付ける一次属性には，「個人，情報，識別，…」という属性が存在する．
これは，「個人を識別することができる情報を指す」という文書であると捉えることができる．
このように，概念に対する[MATH]次属性空間はその概念についての説明文書の集合だとみなすことができる．
この[MATH]次属性空間から算出した出現頻度を[MATH]次属性内出現頻度と呼ぶ．
本稿では2次属性空間を用いる．
3次属性空間までを用いると，概念「個人情報」に対して2次属性「力」の属性「動物，筋肉，物体，…」が含まれる．
このため，概念に関係のない語が多くなってしまうためである．
[REF_tf_idf]節で説明したtf・idf重みの考え方をもとに，未定義語の属性[MATH]の2次属性内出現頻度を[MATH]，未定義語の一次属性の総数を[MATH]とし，未定義語の属性[MATH]の概念ベース空間のidf値を[MATH]とすると，重み[MATH]は以下の式で表される．
新規概念に属性を追加した場合，その概念自身は属性として他の概念を持つが，その概念を属性として持つ概念は存在しない．
したがって，他の概念に新しく追加をした概念を属性として追加する手法が必要となる．
新概念と属性の例を表[REF_table:attribute_and_weight_of_new_concept]に示す．
新概念とその獲得した属性にはWeb上のホームページにともに出現しており，共起という関係があり，属性から見ても新概念とのなんらかの関連性があると考えられる．
このため，新概念を属性の追加候補とする．
例であると，概念「放送」，「テレビ」，「車両」に「ワンセグ」という語を属性追加候補とする．
しかし，全ての属性追加候補を属性として追加すると雑音が非常に多くなってしまう．
概念「車両」に対して「ワンセグ」という属性は不必要であるため，選別して追加を行う．
このように，新概念から取得した語に対して新概念を属性として選別して追加することを相互追加と呼ぶこととする．
選別方法としては，2次属性内出現頻度を属性数で割った値（以下2次属性内出現頻度割合と記述）が0.149以上かつ関連度0.068以上の場合に追加を行う．
選別のための閾値の設定は実験により定めた．
実験方法としては，概念とその概念と関係がある概念の組を1,780組集め，その全ての組における2次属性内出現頻度割合と関連度を求め，その平均値を閾値に設定した．
実験に使用した2対の関係がある概念の組を表[REF_table:example_of_association_word]に示す．
追加する概念[MATH]と追加される概念[MATH]との間の関連度[MATH]と追加する属性の概念ベース空間のidf値を[MATH]とすると追加した属性の重み[MATH]は以下の式で表される．
検索要求と検索対象の間の類似度を求める際，いくら単語間の関連性を正確に定義できたとしても，その値をもとにうまく計算できないと文書間の正確な類似度を求めることはできない．
計算の仕方としては，様々な方法が考えられ，例えば単語間の関連性が高い順に単語の対応をとり計算する方法などが挙げられる．
1対1で対応を取る方法では，検索要求と検索対象の語の少ない方の語の数しか対応がとれない．
例えば，検索要求の語が3語，検索対象の語が100語であった場合，検索対象の97語は計算の対象外となる．
さらに，実際の検索において，ユーザは検索要求にあまり多くの語を入力しないと考えられ，検索要求と検索対象との語数の差は非常に大きいと想定され，文書内の単語の重要性と単語間の関連性を考慮しM対Nで柔軟に対応を取る必要がある．
そこで本研究では類似画像検索の分野で注目されているEMD [CITE]を用いて文書間の類似度を算出する方法を用いる．
EMDは輸送問題における輸送コストの最適解を求めるアルゴリズムであり，需要地（供給地）の重みと需要地と供給地間の距離を定義できればどのような問題にも適用できる．
このEMDを用いることで単語の重みと単語間の関連性を考慮して柔軟に対応を取り，文書間の類似度を求めることができる．
EMDは線形計画問題の一つであるヒッチコック型輸送問題において計算される距離尺度であり，2つの離散分布において，一方の分布を他方の分布に変換するための最小コストとして定義される．
輸送問題とは，需要地の需要を満たすように供給地から需要地へ輸送を行う場合の最小輸送コストを解く問題である．
EMDを求める際，二つの分布は要素の重み付き集合として表現される．
一方の分布[MATH]を集合として表現すると，[MATH]となる．
今，分布[MATH]は[MATH]個の特徴量で表現されており，[MATH]は特徴量，[MATH]はその特徴量に対する重みである．
同様に，一方の分布[MATH]も集合として表すと，[MATH]となる．
EMDの計算は，2つの分布において特徴量の数が異なっている場合でも計算が可能であるという性質を持っている．
今，[MATH]と[MATH]の距離を[MATH]とし，全特徴間の距離を[MATH]とする．
ここで，[MATH]から[MATH]への輸送量を[MATH]とすると，全輸送量は[MATH]となる．
ここで，式[REF_eq:work]に示すコスト関数を最小とする輸送量[MATH]を求め，EMDを計算する．
ただし，上記のコスト関数を最小化する際，以下の制約条件を満たす必要がある．
f_{ij}\geq0，　1\leq i \leq m，　1\leq j \leq n
\sum_{j=1}^n f_{ij} \leq w_{p_i}，　1 \leq i \leq m
\sum_{i=1}^m f_{ij} \leq w_{q_j}，　1 \leq j \leq n
\sum_{i=1}^m\sum_{j=1}^n f_{ij} = \min\left(\sum_{i=1}^m w_{p_i}，\sum_{j=1}^n w_{q_j}\right)
ここで，式[REF_eq:st1]は輸送量が正であることを表し，[MATH]から[MATH]に送られる一方通行であることを表している．
式[REF_eq:st2]は輸送元である[MATH]の重み以上に輸送できないことを表す．
式[REF_eq:st3]は輸送先である[MATH]の重み以上に受け入れることができないことを表す．
最後に式[REF_eq:st4]は総輸送量の上限を表し，それは輸送先または輸送元の総和の小さい方に制限されることを表す．
以上の制約条件の下で求められた最適な全輸送量[MATH]を用いて分布[MATH]，[MATH]間のEMDを以下のように求める．
ここで，最適なコスト関数[MATH]をEMDとしてそのまま用いないのは，コスト関数は輸送元もしくは輸送先の重みの総和に依存するので，正規化することによってその影響を取り除くためである．
図[REF_fig:EMD_to_document]にEMDを文書検索に適用した例を示す．
EMDを文書検索に適用するには需要地と供給地，需要量と供給量，各需要地と供給地間の距離を定義する必要がある．
需要地としては，検索課題の索引語を，供給地としては検索対象の索引語を割り当てる．
需要量と供給量はそれぞれ索引語の[REF_tf_idf]節で説明したtf・idf重みを用いる．
そして，需要地と供給地間の距離は索引語間の関連性と見立てることができ，提案手法においては概念ベースを用いた一致度計算により求めることができる．
一致度は関連性が高いと値も大きくなるため，1から一致度の値を引いた値に変換する．
EMDの計算は図[REF_fig:EMD_to_document]の下方で求まる．
「梅」と「祭り」間の輸送量が1となっているのは，「梅」から「うめ」に重み2を輸送し，「梅」の余った重み1を「祭り」に輸送したためである．
このように，関連性が高い語に優先して重みを輸送し，供給量がなくなるか需要量が満たされるまで輸送を行う．
このように索引語間の関連性と重みを考慮したM対Nでの柔軟な対応が可能である．
EMDの特徴として．
索引語間の距離の値が0から1であるなら，EMDも0から1の値になる．
そして，EMDは文書間が似ていると値が低くなり，似ていないと値が高くなる．
よって値が低い文書から順にユーザに提示することで文書検索が実現できる．
