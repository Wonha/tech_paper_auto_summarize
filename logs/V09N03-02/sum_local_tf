================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[3753] 本稿では形態素解析ツールをアプリケーションとして採用し，処理時に統計情報を動的に利用することによって形態素の切り分けの精度を上げる手法と，統計情報を利用して事前に辞書登録文字列を選別し必要なコスト情報を補って辞書登録を行なう手法との2つのアプローチを提案し，さらにこの2つの手法を組み合わせてそれぞれの欠点を補う手法を提案する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[2891] 辞書ベースの自然言語処理ツールは高い精度が期待できる反面，辞書未登録語の問題があるため，統計情報を利用して辞書未登録語の抽出を行なう研究が盛んに行なわれている．

================================================================
[section type  : proposed_method]
[section title : 語句抽出]
================================================================
[3260] 未知語，専門用語，固有名詞などはドメイン固有の語句と言ってよいが，ドメイン固有の語句となりうるのは新語や複合語がほとんどで，例えば助詞のように新語の出現しないものや活用語のようにドメインによってはほとんど新語がないものなどは抽出対象となりにくく，名詞に準じる語句を抽出対象とすることでかなりの未知語，専門用語などを取得することが可能である．
-----------------------------------------------------
  [subsection title : 名詞句抽出]
-----------------------------------------------------
  [3288] またCucerzanらは文字の並びの情報を利用して少ない訓練データからの固有名詞の推定を可能にする手法を提案し，ルーマニア語や英語など複数の言語に対して有効であることを示した[CITE]．
-----------------------------------------------------
  [subsection title : 文字単位の統計情報を利用した辞書未登録語抽出]
-----------------------------------------------------
  [3342] 延澤らはこの手法を利用してドメイン固有の文字列の自動抽出を試みており，口語文章のような非文を多く含むコーパスに対しても有効であることを示した[CITE]他，固有名詞抽出など抽出対象を絞った場合などについても有効であるとしている[CITE]．

================================================================
[section type  : proposed_method]
[section title : システム概要]
================================================================
[2850] 本稿で提案するシステムは，対象ドメインのコーパスからシンプルな手法でドメイン固有の語句を抽出する延澤らの手法[CITE]を応用したものであり，辞書ベースの自然言語処理ツールの支援を目的として2方向からのアプローチを試みる．
-----------------------------------------------------
  [subsection title : システム概要]
-----------------------------------------------------
  [3083] どちらのアプローチも対象ドメインの訓練コーパスから得た統計情報を利用することで頻出文字列の認識を実現し，これに起因する解析誤りの削減を図るものである．
-----------------------------------------------------
  [subsection title : 共起関係抽出]
-----------------------------------------------------
  [3536] 文字間の共起情報が頻出文字列認識に有用であるとの延澤らの主張[CITE]に基づき，本稿では対象ドメイン固有の頻出文字列の抽出に利用する統計情報として，文字間の共起情報を採用した．

================================================================
[section type  : proposed_method]
[section title : システム M: 茶筌への組み込み]
================================================================
[3625] 本稿で提案するシステムは，日本語を対象とした形態素解析ツール・茶筌に統計情報を利用した文字列抽出モジュール(システムM)を組み込むことで統計情報の活用を図るものである．
-----------------------------------------------------
  [subsection title : 茶筌での統計情報の利用]
-----------------------------------------------------
  [3665] 本稿で提案するシステムではまず茶筌に有繋文字列抽出モジュールを組み込むことにより文字列の認識を行ない([REF_sec:ukninshiki]節)，抽出された文字列に専用の品詞名を付けることで辞書の見出し語と同等に扱うことができるようにする([REF_sec:ukriyou]節)．
-----------------------------------------------------
  [subsection title : 形態素解析時における有繋文字列の認識]
-----------------------------------------------------
  [2868] 従って図の中で評価値を繋いだ線が山状になっている部分は共起する可能性の高い部分であり，一塊の文字列である可能性が高い．
-----------------------------------------------------
  [subsection title : 形態素解析時における有繋文字列の利用]
-----------------------------------------------------
  [3347] 有繋文字列は特定の品詞に対応するものではないが，個々の有繋文字列に対してその品詞の推定を行なうことはシステムの実時間性を損ねるため，品詞「有繋文字列」を新設しこれに対して予め品詞情報を設定しておく．
-----------------------------------------------------
  [subsection title : 統計情報を組み込んだ茶筌による形態素解析例]
-----------------------------------------------------
  [3365] この例では本システムを利用し「bigram」の品詞が「有繋文字列」となったことで「など」が正しく認識されている．

================================================================
[section type  : proposed_method]
[section title : システム D: 辞書への組み込み]
================================================================
[3214] 図[REF_fig:flo-d]に本章で提案する辞書作成システムを利用して事前に作成した有繋文字列辞書を茶筌の辞書に組み込んだ場合による形態素解析の流れを示す．
-----------------------------------------------------
  [subsection title : 登録文字列の属性設定]
-----------------------------------------------------
  [3289] 登録文字列それぞれに対して適切な品詞を人手で設定することは多大な労力を必要とするだけでなく，その適切さの評価や曖昧性の問題などが存在するため，本稿では登録文字列はすべて同じ品詞とした．
-----------------------------------------------------
  [subsection title : 登録文字列の選択]
-----------------------------------------------------
  [3176] 出現頻度が1の文字列はノイズである可能性があるため登録文字列から外し，出現頻度2の時形態素コストは最大の8,000を採るように設定した．

================================================================
[section type  : proposed_method]
[section title : システム M+D: 辞書登録と切り分け処理の併用]
================================================================
[3369] 図[REF_fig:flo-md]に本稿で提案する統計情報利用システムと辞書作成システムを利用した有繋文字列辞書の両方を茶筌に組み込んだ場合による形態素解析の流れを示す．

================================================================
[section type  : experiment_result]
[section title : 実験および考察]
================================================================
[1866] 対象ドメインの持つ統計情報を利用することで形態素解析の精度の向上を図る．
-----------------------------------------------------
  [subsection title : 実験内容]
-----------------------------------------------------
  [3099] ただし，本稿の手法では名詞に準じるものを対象として考えているため，動詞，形容詞などに相当する文字列は正解文字列から除外した．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [3471] 再現率の計算には正解文字列の総数を利用しているが，この正解文字列はテストコーパスから作成したものであり，訓練コーパス中に出現しない文字列も多く存在する．
-----------------------------------------------------
  [subsection title : 実験 M: 統計情報を組み込んだ茶筌による形態素解析]
-----------------------------------------------------
  [3108] これはシステムMによる動的な統計情報の利用が正解文字列の認識に有効であることを示している．
-----------------------------------------------------
  [subsection title : 実験 D: 有繋文字列の辞書登録]
-----------------------------------------------------
  [3378] これは，辞書\posの作成では品詞の情報を利用することで未知語を含むものが優先的に登録されたためであると考えられる．
-----------------------------------------------------
  [subsection title : 実験 M+D: 辞書登録と統計情報利用システム組み込みの併用]
-----------------------------------------------------
  [3772] それに対して訓練コーパスから得られた統計情報を元に辞書未登録文字列を抽出し辞書登録を行なうシステムDは，登録文字列の絞り込みを行なうためノイズの問題を軽減することが可能であるが，柔軟な処理には不向きである．

================================================================
[section type  : conclusion]
[section title : 結論]
================================================================
[3498] 本稿で提案した手法は文字の共起頻度を元にしたものであり，構文解析などの処理は一切必要とせず，ヒューリスティクスも一切利用していない非常にシンプルなものでありながら，システムMのみで86.1%，システムDのみで71.4%，両方の併用で86.5%の未知語の解決に成功した．

