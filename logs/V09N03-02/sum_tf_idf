================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:204] 本稿では訓練コーパスから得た文字の共起情報を利用する手法で辞書未登録語の抽出を実現し，辞書ベースのシステムの精度を向上させた．
[i:2, score:272] 本稿では形態素解析ツールをアプリケーションとして採用し，処理時に統計情報を動的に利用することによって形態素の切り分けの精度を上げる手法と，統計情報を利用して事前に辞書登録文字列を選別し必要なコスト情報を補って辞書登録を行なう手法との2つのアプローチを提案し，さらにこの2つの手法を組み合わせてそれぞれの欠点を補う手法を提案する．
[i:4, score:201] 実験の結果，動的な統計情報の利用のシステムが未知語の認識に，辞書登録システムが切り分け精度の向上に有効であることが示され，2つのシステムを適切に組み合わせることによって訓練コーパスのデータで認識可能な辞書未登録語をほぼ完全に解決できた．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:6, score:142] 辞書ベースの自然言語処理ツールは高い精度が期待できる反面，辞書未登録語の問題があるため，統計情報を利用して辞書未登録語の抽出を行なう研究が盛んに行なわれている．
[i:8, score:147] 本稿ではドメイン固有の文字列の自動抽出で問題となるノイズを2方向のアプローチで解決する手法を提案する．
[i:9, score:143] 本手法は辞書ベースのツールに付加的な情報を半自動的に与えて辞書未登録語の抽出を行なうことで処理精度の向上を図るものである．

================================================================
[section type  : proposed_method]
[section title : 語句抽出]
================================================================
[i:11, score:61] 現在研究されている語句抽出システムは，ほとんどが対象を名詞に準じた単語列に限定したものである．
[i:12, score:56] これは，抽出の対象となる語句は未知語や専門用語が主であり，どちらも名詞がその大半を占めるためである．
[i:13, score:124] 未知語，専門用語，固有名詞などはドメイン固有の語句と言ってよいが，ドメイン固有の語句となりうるのは新語や複合語がほとんどで，例えば助詞のように新語の出現しないものや活用語のようにドメインによってはほとんど新語がないものなどは抽出対象となりにくく，名詞に準じる語句を抽出対象とすることでかなりの未知語，専門用語などを取得することが可能である．
-----------------------------------------------------
  [subsection title : 名詞句抽出]
-----------------------------------------------------
  [i:lead, 90] 抽出対象は主に，名詞の推定と名詞句の推定とに二分されており，特に名詞の推定では専門用語など複合語の推定を行なうものと固有名詞などの未知語を認識するものに分けられる．
.....
  [i:17, score:132] 専門用語などドメイン固有の語句の抽出では，tf・idfモデルなど語句の出現頻度を利用する手法と[MATH]-gramなど文字の共起頻度を利用する手法がある．
  [i:22, score:144] Chaらは未登録語発見のための形態素パターン辞書を利用して未登録語の認識およびタグ付けを行なう手法を提案した[CITE]．
  [i:24, score:102] またCucerzanらは文字の並びの情報を利用して少ない訓練データからの固有名詞の推定を可能にする手法を提案し，ルーマニア語や英語など複数の言語に対して有効であることを示した[CITE]．
-----------------------------------------------------
  [subsection title : 文字単位の統計情報を利用した辞書未登録語抽出]
-----------------------------------------------------
  [i:lead, 145] 文字の共起情報を利用する手法としては，[MATH]-gramの画期的な抽出法を提案しこれを利用して文中の文字列の塊を認識する長尾らの手法[CITE]などが挙げられる．
.....
  [i:27, score:187] 中渡瀬らは任意の文字列の頻度を正規化する手法を提案し，これを用いて語の境界を決定することで，辞書未登録語を獲得している．
  [i:31, score:163] 延澤らはこの手法を利用してドメイン固有の文字列の自動抽出を試みており，口語文章のような非文を多く含むコーパスに対しても有効であることを示した[CITE]他，固有名詞抽出など抽出対象を絞った場合などについても有効であるとしている[CITE]．
  [i:37, score:162] そこで本稿では，延澤らの手法の問題点を克服し，この手法を利用して辞書未登録語を抽出することで辞書ベースのツールの精度の向上を図る．

================================================================
[section type  : proposed_method]
[section title : システム概要]
================================================================
[i:38, score:155] 本稿で提案するシステムは，対象ドメインのコーパスからシンプルな手法でドメイン固有の語句を抽出する延澤らの手法[CITE]を応用したものであり，辞書ベースの自然言語処理ツールの支援を目的として2方向からのアプローチを試みる．
-----------------------------------------------------
  [subsection title : システム概要]
-----------------------------------------------------
  [i:lead, 97] 本稿では，辞書ベースの形態素解析ツールに対して統計情報を利用することでその精度の向上を図るため，以下の2つのアプローチを試みた．
.....
  [i:41, score:132] 形態素解析中に統計情報を利用してドメイン固有の語句を認識するシステムを形態素解析ツールに組み込むことで形態素解析時の誤解析を削減．
  [i:43, score:226] 形態素解析の前処理として対象ドメイン固有の文字列の辞書登録を行なうことで形態素解析時の誤解析を削減．
  [i:44, score:190] どちらのアプローチも対象ドメインの訓練コーパスから得た統計情報を利用することで頻出文字列の認識を実現し，これに起因する解析誤りの削減を図るものである．
-----------------------------------------------------
  [subsection title : 共起関係抽出]
-----------------------------------------------------
  [i:lead, 189] 文字間の共起情報が頻出文字列認識に有用であるとの延澤らの主張[CITE]に基づき，本稿では対象ドメイン固有の頻出文字列の抽出に利用する統計情報として，文字間の共起情報を採用した．
.....
  [i:47, score:189] 文字間の共起情報が頻出文字列認識に有用であるとの延澤らの主張[CITE]に基づき，本稿では対象ドメイン固有の頻出文字列の抽出に利用する統計情報として，文字間の共起情報を採用した．
  [i:51, score:119] 訓練コーパス中の文字共起頻度の数え上げにはd-bigram確率モデル[CITE]を利用した．
  [i:52, score:137] d-bigramとは距離を考慮したbigramモデルであり，abbcという文字列の場合，隣接する(a, b)などだけでなくaとcのように離れて出現する二文字の共起関係も取得する．

================================================================
[section type  : proposed_method]
[section title : システム M: 茶筌への組み込み]
================================================================
[i:58, score:52] これは茶筌に特化した手法ではなく，茶筌本体の構造を改変するものではない．
-----------------------------------------------------
  [subsection title : 茶筌での統計情報の利用]
-----------------------------------------------------
  [i:lead, 107] 茶筌は辞書ベースの形態素解析ツールであり，文単位で処理を行なう．
.....
  [i:64, score:369] 本稿で提案するシステムではまず茶筌に有繋文字列抽出モジュールを組み込むことにより文字列の認識を行ない([REF_sec:ukninshiki]節)，抽出された文字列に専用の品詞名を付けることで辞書の見出し語と同等に扱うことができるようにする([REF_sec:ukriyou]節)．
  [i:66, score:330] 本システムを組み込むことで，茶筌の持つ辞書の他に，その文中に含まれる有繋文字列を形態素の候補として利用することが可能となる．
  [i:68, score:326] 従って，辞書既登録語句は有繋文字列として抽出されることはない．
-----------------------------------------------------
  [subsection title : 形態素解析時における有繋文字列の認識]
-----------------------------------------------------
  [i:lead, 236] 文中の[MATH]番目の文字と[MATH]番目の文字の間の有繋評価値[MATH]の算出式を式([REF_exp:uk])に示す[CITE]．
.....
  [i:69, score:236] 文中の[MATH]番目の文字と[MATH]番目の文字の間の有繋評価値[MATH]の算出式を式([REF_exp:uk])に示す[CITE]．
  [i:73, score:266] 図[REF_fig:mountain-valley]に有繋評価値を利用した文字列認識の例を示す[CITE]．
  [i:76, score:233] 文中の各隣接文字ペア間の有繋評価値は，隣接文字ペアの共起頻度が高いほど高くなる．
-----------------------------------------------------
  [subsection title : 形態素解析時における有繋文字列の利用]
-----------------------------------------------------
  [i:lead, 379] 形態素解析中[REF_sec:ukninshiki]節の手法で認識された有繋文字列は専用の品詞およびコストが設定され既存の辞書の登録語と同等として形態素解析処理に利用される．
.....
  [i:79, score:379] 形態素解析中[REF_sec:ukninshiki]節の手法で認識された有繋文字列は専用の品詞およびコストが設定され既存の辞書の登録語と同等として形態素解析処理に利用される．
  [i:80, score:282] 有繋文字列は特定の品詞に対応するものではないが，個々の有繋文字列に対してその品詞の推定を行なうことはシステムの実時間性を損ねるため，品詞「有繋文字列」を新設しこれに対して予め品詞情報を設定しておく．
  [i:84, score:270] そこで，評価値によって有繋文字列を5段階に分類し，段階ごとに形態素コストを設定することで，評価値の高いものを優先的に利用できるように設定する．
-----------------------------------------------------
  [subsection title : 統計情報を組み込んだ茶筌による形態素解析例]
-----------------------------------------------------
  [i:lead, 73] 図[REF_fig:ex1newspaper]に，本システムを茶筌に組み込んだ場合の実行例を挙げる．
.....
  [i:87, score:325] 下線は辞書未登録語を，太字は有繋文字列として抽出された部分を示す．
  [i:88, score:355] 図[REF_fig:ex1newspaper]では辞書未登録語2文字列が本システムを利用することで有繋文字列として抽出されている．
  [i:90, score:286] この例では本システムを利用し「bigram」の品詞が「有繋文字列」となったことで「など」が正しく認識されている．

================================================================
[section type  : proposed_method]
[section title : システム D: 辞書への組み込み]
================================================================
[i:98, score:365] 図[REF_fig:flo-d]に本章で提案する辞書作成システムを利用して事前に作成した有繋文字列辞書を茶筌の辞書に組み込んだ場合による形態素解析の流れを示す．
[i:99, score:327] 基本的な流れは図[REF_fig:flo-o]と同じだが，利用する辞書は茶筌の基本辞書に有繋文字列辞書を組み込んだものとなっている．
[i:100, score:336] この有繋文字列辞書は訓練コーパスから作成したものであり，この辞書を組み込むことによってドメイン固有の文字列を形態素解析処理で利用する．
-----------------------------------------------------
  [subsection title : 登録文字列の属性設定]
-----------------------------------------------------
  [i:lead, 140] 辞書登録文字列の属性は以下のように決定する．
.....
  [i:105, score:292] 登録文字列に割り振る品詞として「有繋文字列」を新設した．
  [i:106, score:295] 品詞「有繋文字列」と他の品詞との接続コストの設定は茶筌の既存の品詞「名詞」中の「一般」カテゴリに準拠することとした．
  [i:108, score:279] この関数で利用するパラメータは，本稿で提案する複数の有繋文字列辞書作成手法に依存するものとする．
-----------------------------------------------------
  [subsection title : 登録文字列の選択]
-----------------------------------------------------
  [i:lead, 178] 本稿では辞書に登録する文字列の選択手法を4種類用意し，4つの辞書を作成した(表[REF_tab:jisho])．
.....
  [i:115, score:379] 訓練コーパスから抽出された有繋文字列を一人の手によってすべての候補をチェックし，そのままで辞書登録可能な有繋文字列，過接合有繋文字列から適切な部分を切り出した文字列の2種類の文字列を選択した．
  [i:116, score:303] 過分割有繋文字列については，分割され削除されていた部分が容易に推測できる場合であっても，登録文字列としなかった．
  [i:117, score:206] 登録文字列の切り出しの対象は，名詞，複合名詞，数式，数値(単位も含む)，意味のある記号の羅列，英単語の羅列とし，茶筌既登録語は登録文字列から除外した．

================================================================
[section type  : proposed_method]
[section title : システム M+D: 辞書登録と切り分け処理の併用]
================================================================
[i:135, score:333] 処理の段階で動的に有繋文字列を認識し利用するシステムMでは，ノイズを完全に防ぐことは不可能である．
[i:136, score:331] ノイズを抑えるためには，動的な処理でなく，事前に必要な有繋文字列を辞書登録してしまう方法が有効である．
[i:141, score:376] 図[REF_fig:flo-md]に本稿で提案する統計情報利用システムと辞書作成システムを利用した有繋文字列辞書の両方を茶筌に組み込んだ場合による形態素解析の流れを示す．

================================================================
[section type  : experiment_result]
[section title : 実験および考察]
================================================================
[i:145, score:61] 対象ドメインの持つ統計情報を利用することで形態素解析の精度の向上を図る．
-----------------------------------------------------
  [subsection title : 実験内容]
-----------------------------------------------------
  [i:lead, 30] 本章では，本稿で提案している2つのシステムの利用実験について報告する．
.....
  [i:152, score:209] 本稿では，統計情報利用システムの組み込みで利用する統計情報を得るための訓練コーパスおよび辞書登録のための辞書登録文字列の抽出について，同一の訓練コーパスを利用した．
  [i:156, score:181] 比較のため，テストコーパスを人手で形態素解析したものと辞書登録すべき文字列の正解リストを作成した．
  [i:162, score:176] 正解形態素解析結果中，茶筌に登録されていない文字列を正解文字列とした．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, 43] 表[REF_tab:expresult]に各実験の結果をまとめる．
.....
  [i:169, score:289] 有繋文字列と認識された箇所に対する正解形態素解析中の正解文字列の出現箇所の割合を適合率，全ての正解文字列に対して正しく認識された文字列の割合を再現率とした．
  [i:177, score:337] 有繋文字列は辞書既登録語を含まないことから，本手法が辞書未登録語の抽出に有効であると言える．
  [i:189, score:337] それに対し，本手法で採用したd-bigramはギャップのある事象の共起情報を複数組み合わせて文字列認識を行なうため，訓練コーパスに出現しない文字列についても有繋性の推定が可能である[CITE]．
-----------------------------------------------------
  [subsection title : 実験 M: 統計情報を組み込んだ茶筌による形態素解析]
-----------------------------------------------------
  [i:lead, 361] 表[REF_tab:expresult]によるとシステムMの適合率は他に比べてかなり低いが，これは形態素解析時に有繋文字列とされた文字列が他に比べて多いことにも起因する．
.....
  [i:201, score:361] 表[REF_tab:expresult]によるとシステムMの適合率は他に比べてかなり低いが，これは形態素解析時に有繋文字列とされた文字列が他に比べて多いことにも起因する．
  [i:202, score:331] システムMでは有繋文字列の絞り込みを一切行なっていないため動詞句などノイズとなる文字列を多く含むことが適合率の低下の原因である．
  [i:215, score:304] 数式中に含まれる文字列はほとんど未知語または記号として扱われるが「P(x)」など確率を示す関数などは有繋文字列として認識されており，結果的に記号タグの振られる文字列が減少した．
-----------------------------------------------------
  [subsection title : 実験 D: 有繋文字列の辞書登録]
-----------------------------------------------------
  [i:lead, 373] 本稿では，訓練コーパスを入力として抽出された有繋文字列を辞書登録候補とし，[REF_sec:jisho]節で提案した4通りの方法で辞書登録文字列の選択を行なった．
.....
  [i:219, score:373] 本稿では，訓練コーパスを入力として抽出された有繋文字列を辞書登録候補とし，[REF_sec:jisho]節で提案した4通りの方法で辞書登録文字列の選択を行なった．
  [i:222, score:327] この結果有繋文字列として出力された文字列5,402が各辞書の登録候補文字列となっており，この集合から辞書登録文字列の絞り込みを行なう．
  [i:223, score:294] 抽出された有繋文字列から選択された登録候補文字列の異なり文字列数は2,482であった．
-----------------------------------------------------
  [subsection title : 実験 M+D: 辞書登録と統計情報利用システム組み込みの併用]
-----------------------------------------------------
  [i:lead, 217] 形態素解析時の統計情報の利用を行なうシステムMは動的な文字列の切り分けを可能にし，柔軟な処理が可能となった反面，ノイズの問題が起こる．
.....
  [i:240, score:217] 形態素解析時の統計情報の利用を行なうシステムMは動的な文字列の切り分けを可能にし，柔軟な処理が可能となった反面，ノイズの問題が起こる．
  [i:241, score:253] それに対して訓練コーパスから得られた統計情報を元に辞書未登録文字列を抽出し辞書登録を行なうシステムDは，登録文字列の絞り込みを行なうためノイズの問題を軽減することが可能であるが，柔軟な処理には不向きである．
  [i:246, score:228] さらにシステムMとDを組み合わせることで訓練コーパスに出現しなかった未知語文字列が訓練コーパスの情報を利用することで正しく一塊と認識された例もあった．

================================================================
[section type  : conclusion]
[section title : 結論]
================================================================
[i:249, score:237] 本稿では辞書ベースの形態素解析ツール・茶筌を対象とし，未知語，複合語双方の解決を目的として，統計情報を形態素解析段階で動的に利用するための組み込みシステム(システムM)と，統計情報を利用した辞書作成のシステム(システムD)の2種類のアプローチを提案した．
[i:250, score:189] 本稿の手法は茶筌に特化したものではなく，辞書ベースのツールに対してそのシステムを改変することなく付加的な情報を半自動的に追加し辞書未登録語の問題の解決を図るものである．
[i:251, score:206] 本稿で提案した手法は文字の共起頻度を元にしたものであり，構文解析などの処理は一切必要とせず，ヒューリスティクスも一切利用していない非常にシンプルなものでありながら，システムMのみで86.1%，システムDのみで71.4%，両方の併用で86.5%の未知語の解決に成功した．

