================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.62977] 本稿では，置換，挿入，削除操作を行う識別的系列変換で日本語学習者作文の助詞誤りを自動訂正する．
[i:1, score:0.50175] 誤り訂正タスクの場合，難しいのは大規模な学習者作文コーパスを集めることである．
[i:5, score:0.50386] さらに疑似誤り文をソースドメイン，実際の学習者作文をターゲットドメインとしたドメイン適応を行う．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:10, score:0.51990] しかし，中国語を母語とするものにとって日本語は外国語であり，メールなどの作文には誤りを含み，意思疎通に問題となるため，それらを自動検出・訂正する技術が望まれている[CITE]．
[i:19, score:0.55054] 翻訳の考え方を使った場合，モデル学習のために，誤りを含む学習者作文とそれを訂正した修正文のペア（以下，単にペア文とも呼ぶ）が大量に必要である．
[i:25, score:0.57519] 学習者作文・修正文ペアに出現しないものであっても，言語モデル確率によって日本語の正しさが測られるため，誤り訂正の網羅性の向上が期待できる．

================================================================
[section type  : proposed_method]
[section title : 日本語学習者の誤り傾向]
================================================================
[i:39, score:0.29391] 最終的には2,770文の学習者作文データを収集し，各作文を日本語母語話者が推敲した（以下，単に修正文と呼ぶ）．
[i:40, score:0.35845] 誤りを訂正する際には，文意を変更せず，文法的に正しい日本語とするための最小限の訂正を行うよう留意した．
[i:41, score:0.34541] 言い換えると，この推敲で訂正された誤りは，訂正しないと正しい日本語にはならないものである．
-----------------------------------------------------
  [subsection title : 誤りの分類と出現分布]
-----------------------------------------------------
  [i:lead, score:0.16483] 誤り傾向の分析にあたり，まずは大分類として，文法誤り，語彙誤り，表記誤りの3種類を設定し，さらに小分類を設定した（表[REF_tbl-error-class]）．
.....
  [i:43, score:0.26555] 収集した2,770文の分析を実施したところ，訂正が可能であったものは2,171文であった．
  [i:44, score:0.34874] 訂正が出来なかったものは，全く誤りがない日本語文559文，および文として不完全な断片40文である．
  [i:46, score:0.36811] まず，誤り訂正の発生箇所は4,916箇所であり，1文あたり平均2.26箇所であった．
-----------------------------------------------------
  [subsection title : 誤り傾向]
-----------------------------------------------------
  [i:lead, score:0.24018] 今回の誤り傾向であるが，助詞誤りおよびカタカナ誤りは中国語母語話者に限らず広く外国人に共通して出現するものであると推測される．
.....
  [i:52, score:0.58600] そのため，中国語母語話者に限らず外国人の学習者作文の誤りに対する訂正対象を助詞とすることは，発生率から考えても効果的である．
  [i:64, score:0.38709] 以上の分析から，本稿では，誤りの出現頻度の高い助詞誤りを訂正対象とした．
  [i:65, score:0.46914] また，助詞の置換，挿入，削除が現れていることから，原文（入力文）を置換，挿入，削除操作することにより，誤り訂正を行う．

================================================================
[section type  : proposed_method]
[section title : 識別的系列変換]
================================================================
[i:66, score:0.37465] 本章では，ベースとなる識別的系列変換を用いた誤り訂正方式について述べる．
[i:67, score:0.53694] 本稿の誤り訂正は，学習者作文および修正文をあらかじめ形態素解析し，単語列から単語列へ変換することで行う．
[i:69, score:0.40707] 分類器を用いる誤り訂正方法と異なり，1文中の複数の誤りを一度に訂正し，助詞以外の誤りにも拡張が可能な方式である．
-----------------------------------------------------
  [subsection title : 基本方式]
-----------------------------------------------------
  [i:lead, score:0.38887] 本稿では，音声認識結果を言語処理用単語列に変換する形態素変換器[CITE]をベースにし，以下の手順で入力文の誤りを訂正する．
.....
  [i:70, score:0.38887] 本稿では，音声認識結果を言語処理用単語列に変換する形態素変換器[CITE]をベースにし，以下の手順で入力文の誤りを訂正する．
  [i:72, score:0.41630] フレーズテーブルは，助詞誤りとその訂正候補を対にして格納したものである．
  [i:73, score:0.39932] これは誤り訂正タスクにおけるConfusion Set [CITE]と同じもので，表[REF_tbl-particle-errors]をテーブル化したものである．
-----------------------------------------------------
  [subsection title : 挿入・削除操作]
-----------------------------------------------------
  [i:lead, score:0.50286] 一般的に句に基づく翻訳器は置換操作のみで翻訳を行うが，本稿で実施する誤り訂正は，助詞の置換操作のほかに，挿入，削除操作も対象となる．
.....
  [i:82, score:0.50286] 一般的に句に基づく翻訳器は置換操作のみで翻訳を行うが，本稿で実施する誤り訂正は，助詞の置換操作のほかに，挿入，削除操作も対象となる．
  [i:87, score:0.41162] この制約により，一部訂正不可能な誤りも生じる（たとえば，格助詞「に」の直後に係助詞「は」を挿入し，「に」を「には」に訂正するのは不可能となる）．
  [i:90, score:0.51051] 誤り訂正時には，フレーズラティス内に置換操作の候補と，挿入と削除操作が連続する候補が混在するが，誤り訂正モデルに従い最尤探索すると，ほとんどすべての場合，置換操作が選ばれる．
-----------------------------------------------------
  [subsection title : 素性]
-----------------------------------------------------
  [i:lead, score:0.07414] 本手法では2種類の素性を用いる．
.....
  [i:92, score:0.21770] 一つは翻訳モデルに相当する入力と出力のフレーズ対応度を測るためのマッピング素性，もう一つは言語モデルに相当する出力単語列の日本語としてのもっともらしさを測るためのリンク素性である．
  [i:94, score:0.14913] 固有表現抽出など，識別モデルを用いるタスクでは，タグを付与すべき単語のほかに，その周辺単語を素性として用いる場合が多く，今回も同様な考え方をする．
  [i:95, score:0.19999] 具体的には，当該フレーズの入力側前後2単語をウィンドウとして，1〜3-gramと当該フレーズの出力単語の対を，二値のマッピング素性として使用する．
-----------------------------------------------------
  [subsection title : 日本語平文コーパスの利用とリンク素性への組み込み]
-----------------------------------------------------
  [i:lead, score:0.42344] 誤り訂正タスクにおいては，「正しい日本語」を出力する必要があるため，リンク素性は重要であると考えられる．
.....
  [i:97, score:0.42344] 誤り訂正タスクにおいては，「正しい日本語」を出力する必要があるため，リンク素性は重要であると考えられる．
  [i:104, score:0.36737] 言い換えると，未知テキスト中に訓練コーパスと同じパターンの誤りが出現した場合，非常に高い精度で訂正ができる．
  [i:108, score:0.42761] 識別学習における二値素性と実数素性の混在は，半教師あり学習における補助モデル[CITE]と同じ考え方であり，訓練コーパス上での精度を保ちながら，未知テキストに対して頑健な訂正が行えるという利点がある．

================================================================
[section type  : proposed_method]
[section title : 疑似誤り文を用いたペア文の拡張]
================================================================
[i:109, score:0.56837] 第[REF_sec-conversion]章で述べた誤り訂正器には，学習のため，翻訳における対訳文に相当する学習者作文・修正文ペアが必要である．
[i:110, score:0.23021] しかし，実際の誤り事例を大量に収集するのは困難であるため，自動生成した疑似誤り文を用いてペア文を拡張する．
[i:111, score:0.28868] 本章では，まず疑似誤り文生成方法について説明し，ドメイン適応を利用した疑似誤り文の適用方式について説明する．
-----------------------------------------------------
  [subsection title : 疑似誤り生成]
-----------------------------------------------------
  [i:lead, score:0.30986] 前述のとおり，学習者作文・日本語修正文ペアのうちの日本語修正文に関しては，日本語平文コーパスなどから文を適当に選択することにより，容易に入手できる．
.....
  [i:115, score:0.34977] 具体的には，フレーズテーブルには，すでに誤った助詞とその訂正候補が記録されているので，これを逆に適用し，訂正候補助詞が出現したら，正しい助詞を誤らせる．
  [i:116, score:0.46200] 誤りはある確率で発生させるが，発生確率には，実誤りコーパス（学習者作文と日本語修正文ペア）上での正解助詞[MATH]とその誤り助詞[MATH]の相対頻度を使用する．
  [i:119, score:0.45562] このように生成した疑似誤り文を訓練コーパスに加えることにより，誤り訂正モデルを学習する．
-----------------------------------------------------
  [subsection title : 素性空間拡張法によるドメイン適応]
-----------------------------------------------------
  [i:lead, score:0.21533] 自動で作成した疑似誤り文の問題点は，実際の誤りの確率分布を反映している保証がない点である．
.....
  [i:122, score:0.67499] すなわち疑似誤り文コーパスをソースドメイン，実際の学習者作文コーパスをターゲットドメインとみなし，ターゲットドメインに適応させた誤り訂正モデルを学習する．
  [i:136, score:0.38461] 「機能:が:利用」は，ソースドメイン，ターゲットドメイン双方に現れ，どちらも「を」に訂正している．
  [i:142, score:0.46048] 誤り訂正時には，共通とターゲット空間の素性のみを利用してデコードが行われる．

================================================================
[section type  : experiment_result]
[section title : 誤り訂正実験]
================================================================
[i:146, score:0.00000] 
-----------------------------------------------------
  [subsection title : 実験設定]
-----------------------------------------------------
  [i:lead, score:0.39816] 本稿で誤り訂正の対象とする助詞は，ipadic-2.7.0の最上位品詞が助詞であるものすべてである．
.....
  [i:147, score:0.39816] 本稿で誤り訂正の対象とする助詞は，ipadic-2.7.0の最上位品詞が助詞であるものすべてである．
  [i:148, score:0.56394] これには，格助詞，係助詞のほか，副助詞，接続助詞，終助詞，並立助詞なども含まれ，のべ236種類あるが，後述する学習者作文コーパスに出現しない，もしくは誤りがない助詞は訂正対象にならないため，実際の訂正対象助詞は38種類である．
  [i:154, score:0.46613] また，誤り助詞と訂正助詞を対にした異なり数は，132種類（置換修正95種類，挿入14種類，削除23種類）である．
-----------------------------------------------------
  [subsection title : 実験結果1: 日本語平文コーパスの利用]
-----------------------------------------------------
  [i:lead, score:0.12706] まず，日本語平文コーパスを言語モデル確率として利用することの効果を測るため，以下の3手法について精度測定を行った．
.....
  [i:176, score:0.43494] しかし，相対向上数をみると，言語モデル確率のみは若干悪化しており（つまり過剰訂正が多い），再現率の向上が，誤り訂正の精度に直結していないことがわかる．
  [i:180, score:0.46384] これは，n-gram二値素性は確実な誤りに集中して訂正する効果があるためで，相対向上数からみると有利に働いたためと考えられる．
  [i:181, score:0.53814] 提案方式は，n-gram二値素性，言語モデル確率の併用によって，適合率を保持したまま再現率を向上させており，誤り訂正精度の向上に有効である．
-----------------------------------------------------
  [subsection title : 実験結果2: 疑似誤り文によるペア文の拡張]
-----------------------------------------------------
  [i:lead, score:0.18343] 次に，疑似誤り文の導入効果を測定する．
.....
  [i:185, score:0.43844] なお，図[REF_fig-graph1]は，誤り訂正器が出力するスコアが高い方から，ある再現率を達成するための訂正助詞を取得，適合率を算出したものである．
  [i:187, score:0.42806] SRC:疑似誤りコーパスだけを用いて誤り訂正モデルを作成した場合．
  [i:190, score:0.46241] 疑似誤りコーパスをソースドメイン，実誤りコーパスをターゲットドメインとして素性空間拡張法によるドメイン適応を行った場合．
-----------------------------------------------------
  [subsection title : 誤り訂正例]
-----------------------------------------------------
  [i:lead, score:0.25210] 実験2において，誤り発生倍率1.0のとき，提案方式(AUG)の適合率は54.8%(210/383)，再現率は19.3%(210/1087)であった．
.....
  [i:210, score:0.51192] 置換，挿入，削除操作により誤り訂正が成功したもののほか，人手評価によって許容可能と判断されたものには，係助詞「は」と格助詞「が」の置換(No. 4)や，複合名詞が正しい格助詞を補完して分割されたもの(No. 5)があった．
  [i:211, score:0.39817] 許容不可として残ったものの中には，No. 7のように慣用句を過剰訂正したもの，受動態をとらえられず，能動態の格助詞に置換したもの(No. 8)，Linuxのfreeコマンドの内容を知らないと訂正ができないもの(No. 10)があった．
  [i:213, score:0.36520] 本稿で用いた素性は訂正対象助詞の局所文脈のみであるため，大域的素性を導入しないと正しい訂正は困難なものもある．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:220, score:0.45220] 英語の前置詞・冠詞誤り訂正では，[CITE]が，前置詞周辺単語や構文解析の主辞などを素性としたME分類器を用いて，前置詞の誤り訂正を行った．
[i:225, score:0.48164] ここでは，対訳文に相当する学習者作文と日本人による修正文のペアを大量にSNSから収集し，句に基づく統計翻訳の仕組みを利用して訂正を行う．
[i:234, score:0.56025] 学習者作文の利用という観点で俯瞰すると，いずれの研究も，学習者の誤り傾向をモデルとして組み込むことにより，母語話者の記述したテキストのみを用いて誤り訂正を行う場合に比べ，訂正精度が向上したと報告している[CITE]．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:247, score:0.54320] 本稿では，中国語母語話者の日本語作文における，助詞誤り訂正法を提案した．
[i:248, score:0.52018] 誤り訂正タスクで難しいのは，誤りを含む実際の学習者作文とその修正文を入手することである．
[i:249, score:0.56936] この問題に対して，本稿では，まず日本語平文コーパスを利用して，言語モデル確率とペア文から獲得した二値素性を識別モデルの枠組みで併用し，誤り訂正の再現率を向上させた．

