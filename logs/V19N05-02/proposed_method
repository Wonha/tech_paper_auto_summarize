日本語学習者の誤り傾向
\label{sec-particle-errors}

まず，実際に外国人がどのような日本語書き誤りをしてしまうのか，日本語を
学んでいる中国語母語話者を対象に誤り例を収集した．

被験者は日本語の学習歴があり，日本の技術系大学に在籍する，もしくは卒業
した背景をもつ37名である．日本滞在歴は半年から6年程度である．各被験者
に技術系文書（Linuxマニュアル等80文）の英文と24個の図（のべ104課題）を提示
し，キーボード入力による日本語作文を実施した（これを学習者作文と呼ぶ）．
最終的には2,770文の学習者作文データを収集し，各作文を日本語母語話者が
推敲した（以下，単に修正文と呼ぶ）．誤りを訂正する際には，文意を変更せ
ず，文法的に正しい日本語とするための最小限の訂正を
行うよう留意した\footnote{ただし，用語の選択誤りは訂正した．}．
言い換えると，この推敲で訂正された誤りは，訂正しないと正しい日本語にはならないものである．


\subsection{誤りの分類と出現分布}

誤り傾向の分析にあたり，まずは大分類として，文法誤り，語彙誤り，表記誤
りの3種類を設定し，さらに小分類を設定した（表\ref{tbl-error-class}）．

収集した2,770文の分析を実施したところ，訂正が可能であったものは2,171文
であった．訂正が出来なかったものは，全く誤りがない日本語文559文，およ
び文として不完全な断片40文である．これ以降の分析は，訂正が可能であった
2,171文に対して行った．

まず，誤り訂正の発生箇所は4,916箇所であり，1文あたり平均2.26箇所であっ
た．また各誤りの種別について，誤り大分類での出現分布をみると，文法誤り
が54\%と最も多く，続いて語彙誤り28\%，表記誤りが16\%であった．これ以外
は複数の誤りが混在する複合型誤りである．さらに小分類での出現分布をみる
と，最も多く発生していたのは助詞・助動詞誤り33\%，続いてカタカナ語誤り
11\%，単語選択（類義語）の誤り10\%であった．

\begin{table}[t]
\caption{誤りの分類と誤り例}
\label{tbl-error-class}
\input{02table01.txt}
\end{table}




\subsection{誤り傾向}

今回の誤り傾向であるが，助詞誤りおよびカタカナ誤りは中国語母語話者に限
らず広く外国人に共通して出現するものであると推測される．助詞は日本語特
有の文法であり，多くの非日本語母語話者にとっては習得が難しいものである．
そのため，中国語母語話者に限らず外国人の学習者作文の誤りに対する訂正対
象を助詞とすることは，発生率から考えても効果的である．

助詞の種類によって誤り発生のしやすさは異なっているはずであり，全ての助
詞が一律に誤りとはならない．今回の作文データにおける助詞誤りについて，
さらに詳細に内訳を分析をしたところ，まず，誤りタイプとしては置換誤りが
74\%，助詞の抜けが17\%，余分な助詞の出現が9\%であった．特に置換誤りの
発生が高い．また余分な助詞の出現が9\%と非常に低く，訂正のために助詞の
削除操作が必要となるケースは少ないことがわかる．個別の助詞誤り発生回数
上位10件は表\ref{tbl-particle-errors}のとおりである．

このうち，「は→が」への置換訂正については，1文中に2回，「は／係助詞」が出
現し，片方を「が／格助詞」に置換しなければならなかったものである（たと
えば，「問題\underline{は}あるときは．．．」）．「の」の助詞抜けとして
は，「2つファイル」のように，数量表現に後続する名詞の直前の「の」が欠
けている誤りがよく見られた．また，余分な助詞「の」としては，「やったの
人」「小さいの絵」など，連体修飾で使用された動詞や形容詞に後続して「の」
が余分に存在している誤りが多い．

以上の分析から，本稿では，誤りの出現頻度の高い助詞誤りを訂正対象とした．
また，助詞の置換，挿入，削除が現れていることから，原文（入力文）を置換，
挿入，削除操作することにより，誤り訂正を行う．

\begin{table}[t]
\caption{頻出した助詞誤り}
\label{tbl-particle-errors}
\input{02table02.txt}
\end{table}



識別的系列変換
\label{sec-conversion}

本章では，ベースとなる識別的系列変換を用いた誤り訂正方式について述べる．
本稿の誤り訂正は，学習者作文および修正文をあらかじめ形態素解析し，単語
列から単語列へ変換することで行う．本方式は，基本的には識別モデルを用い
た句に基づく統計翻訳器と同等であるが，挿入，削除操作への拡張と，
言語モデル確率を扱う拡張を行っている．分類器を用いる誤り訂正
方法と異なり，1文中の複数の誤りを一度に訂正し，助詞以外の誤りにも拡張が
可能な方式である．


\subsection{基本方式}

本稿では，音声認識結果を言語処理用単語列に変換する
形態素変換器 \shortcite{Imamura:MorphTrans2011}をベースにし，
以下の手順で入力文の誤りを訂正する．

\begin{itemize}
\item まず，入力単語列でフレーズテーブルを検索し，入力側にマッチするフ
レーズを得る．フレーズテーブルは，助詞誤りとその訂正候補を対にして格納
したものである．これは誤り訂正タスクに
おけるConfusion Set \shortcite{rozovskaya-roth:2010:EMNLP}と同じもので，
表\ref{tbl-particle-errors}をテーブル化したものである\footnote{
	表\ref{tbl-particle-errors}はフレーズテーブルの一部である．
\ref{sec-experimental-settings}節で述べるように，実際にはipadic-2.7.0
の最上位品詞が「助詞」であるすべての単語間の誤りを対象とした．}．フレー
ズテーブルと照合することにより，すべての訂正候補が得られる．また，無修
正の場合を考慮し，入力単語を出力単語にコピーしたフレーズを作成し，両者
をまとめてラティス構造にパックする（図\ref{fig-lattice}）．これをフレー
ズラティスと呼ぶ．

\item フレーズラティスから，条件付き確率場(Conditional Random Fields;
CRF) \shortcite{Lafferty:CRF2001}に基づき，最尤フレーズ列を探索する．
本稿の誤り訂正では語順の変更を行わないため，探索にはViterbiアルゴリズ
ムを用いる．フレーズラティスには，非文法的系列（たとえば，図\ref{fig-lattice}では，
格助詞「を」が連続する系列も候補として存在）も
含まれるが，枝刈りなどは行わず，モデルに従い最尤探索を行う．

\item 学習時には，学習者作文と修正文に対して，DPマッチによる単語アライ
メントを行い，正解のフレーズ列を作成する．
この正解から，助詞誤りだけを取得してフレーズテーブルを作成するほか，正
解を教師データとしてCRFを学習する\footnote{
	本稿では，CRF学習のための最適化プログラムとして岡崎の
libLBFGSを用い，実装した．\\
http://www.chokkan.org/software/liblbfgs/}．
\end{itemize}

\begin{figure}[t]
\begin{center}
\includegraphics{19-5ia2f1.eps}
\end{center}
\caption{フレーズラティスの例（太線は正解系列を表す）}
\label{fig-lattice}
\end{figure}



\subsection{挿入・削除操作}

一般的に句に基づく翻訳器は置換操作のみで翻訳を行うが，本稿で実施する誤
り訂正は，助詞の置換操作のほかに，挿入，削除操作も対象となる．挿入操作
は，空単語からある単語への置換，削除操作は，ある単語から空単語への置換
とみなせるため，両者も基本的には置換操作と同等に扱い，モデルの学習・適
用を行う．

しかし，挿入操作は，全単語間に挿入される可能性があるため，ラティス構築
時にサイズが爆発するなど，非常に計算コストの高い操作である．挿入箇所を
ある程度絞ることが望ましいため，本稿では，名詞直後に後続する助詞のみ，
挿入を許可するという制約をかける．挿入は1箇所1単語のみとする．この制約
により，一部訂正不可能な誤りも生じる（たとえば，格助詞「に」の直後に係
助詞「は」を挿入し，「に」を「には」に訂正するのは不可能となる）．

なお，置換操作は，挿入操作と削除操作の連続でも表現できる．本稿では，挿
入と削除操作が連続していた場合は，置換操作になるように正解データを作成
し，モデルを学習する．誤り訂正時には，フレーズラティス内に置換操作の候
補と，挿入と削除操作が連続する候補が混在するが，誤り訂正モデルに従い最
尤探索すると，ほとんどすべての場合，置換操作が選ばれる．


\subsection{素性}

\begin{figure}[b]
\begin{center}
\includegraphics{19-5ia2f2.eps}
\end{center}
\caption{マッピング素性とリンク素性}
\label{fig-features}
\end{figure}
\begin{table}[b]
\caption{素性テンプレート}
\label{tbl-templates}
\input{02table03.txt}
\end{table}

本手法では2種類の素性を用いる．一つは翻訳モデルに相当する入力と出力の
フレーズ対応度を測るためのマッピング素性，もう一つは言語モデルに相当す
る出力単語列の日本語としてのもっともらしさを測るためのリンク素性である．
マッピング素性とリンク素性の概要を図\ref{fig-features}に，素性テンプレー
トの一覧を表\ref{tbl-templates}に示す．

固有表現抽出など，識別モデルを用いるタスクでは，タグを付与すべき単語の
ほかに，その周辺単語を素性として用いる場合が多く，今回も同様な考え方を
する．具体的には，当該フレーズの入力側前後2単語をウィンドウとして，1〜
3-gramと当該フレーズの出力単語の対を，二値のマッピング素性として使用す
る．


リンク素性に関しては，次節で詳細に述べる．



\subsection{日本語平文コーパスの利用とリンク素性への組み込み}

誤り訂正タスクにおいては，「正しい日本語」を出力する必要があるため，リ
ンク素性は重要であると考えられる．この「正しい日本語」は，既存の日本語
平文コーパスから容易に入手可能である．そこで以下の2 種類のリンク素性を
併用し，識別学習を通じて全体最適化を行う．識別モデルを用いる本稿の方式
は，相互に依存する素性を混在できるという特徴を利用している．

\begin{itemize}
\item n-gram二値素性：
出力単語の1〜3-gramを二値素性として使用する．最適化用の訓練コーパス
（学習者作文・修正文などのペア文）からしか獲得できない．個々のn-gramの
素性重みは，マッピング素性を含む他の素性との兼ね合いを考慮しながら最適
化されるため，きめ細かい最適化ができ，訓練コーパスにおける精度は高い．
言い換えると，未知テキスト中に訓練コーパスと同じパターンの誤りが出現し
た場合，非常に高い精度で訂正ができる．

\item 言語モデル確率：
出力単語列のn-gram確率（実際にはトライグラム確率）の対数値を実数素性と
して使用する．素性重みは1つしか付与されないが，言語モデルは日本語平文
コーパスから学習できるため，訓練コーパスに限らず，大量の文から構築でき
る．訓練コーパスに出現した／しないにかかわらず，日本語としての適切さを
スコアとして与えることができる．
\end{itemize}

識別学習における二値素性と実数素性の混在は，半教師あり学習における補助
モデル\shortcite{suzuki-EtAl:2009:EMNLP,Suzuki:SemiSupervised2010j}
と同じ考え方であり，訓練コーパス上での精度を保ちながら，未知テキストに
対して頑健な訂正が行えるという利点がある．



疑似誤り文を用いたペア文の拡張
\label{sec-pseudo-sentences}

第\ref{sec-conversion}章で述べた誤り訂正器には，学習のため，翻訳におけ
る対訳文に相当する学習者作文・修正文ペアが必要である．しかし，実際の誤
り事例を大量に収集するのは困難であるため，自動生成した疑似誤り文を用い
てペア文を拡張する．本章では，まず疑似誤り文生成方法について説明し，ド
メイン適応を利用した疑似誤り文の適用方式について説明する．


\subsection{疑似誤り生成}

前述のとおり，学習者作文・日本語修正文ペアのうちの日本語修正文に関して
は，日本語平文コーパスなどから文を適当に選択することにより，容易に入手
できる．よって，収集した文を，学習者作文のように誤らせることができれば，
ペア文として扱うことができる．

本稿では，\shortciteA{rozovskaya-roth:2010:NAACLHLT}と同様の生成方法を取る．
具体的には，フレーズテーブルには，すでに誤った助詞とその訂正候補が記録
されているので，これを逆に適用し，訂正候補助詞が出現したら，正しい助詞
を誤らせる．誤りはある確率で発生させるが，発生確率には，実誤りコーパス
（学習者作文と日本語修正文ペア）上での正解助詞$e$とその誤り助詞$f$の相
対頻度を使用する．すなわち，
\begin{equation}
P_{error}(f|e)  =  \frac{C(f,e)}{C(e)},
\end{equation}

ただし，$P_{error}(f|e)$は誤り発生確率，$C(f,e)$は，実誤りコーパス上で
の正解助詞$e$とその誤り助詞$f$の共起頻度，$C(e)$は同コーパス上での正解
助詞$e$の出現頻度である．

このように生成した疑似誤り文を訓練コーパスに加えることにより，誤り訂正
モデルを学習する．



\subsection{素性空間拡張法によるドメイン適応}
\label{sec-domain-adaptation}

自動で作成した疑似誤り文の問題点は，実際の誤りの確率分布を反映している
保証がない点である．より正確に実誤りに近づけるため，本稿ではドメイン適
応の技術を用いる．すなわち疑似誤り文コーパスをソースドメイン，実際の学
習者作文コーパスをターゲットドメインとみなし，ターゲットドメインに適応
させた誤り訂正モデルを学習する．

本稿では，ドメイン適応法に\shortciteA{daumeiii:2007:ACLMain}の素性空間
拡張法 (Feature Augmentation) を用いる．これは，素性空間を拡張すること
によりドメイン適応を行うもので，ソースドメインに関するモデルを事前分布
と考えることに相当する．また，学習方法（学習器）を変更する必要がないと
いう特徴がある．

素性空間拡張法を簡単に説明する．素性選択によって構築された素性は，共通，
ソース，ターゲットの素性空間に拡張して配備される．この際，ソースドメイ
ンから作成された素性 ($D_s$) は共通およびソースに，ターゲットドメイン
から作成された素性 ($D_t$) は共通およびターゲットの素性空間に配備する．
つまり，素性空間が3倍に拡張される（図\ref{fig-augment}）．

パラメータ推定は，上記素性空間上で通常どおり推定される．その結果，ソー
スドメイン，ターゲットドメインで共通に用いられる素性（つまり，ソース，
ターゲットで矛盾しない素性）に関しては，共通空間の重みが大きくなり，両
者で矛盾する素性に関しては，ソースまたはターゲット空間の素性が重くなる．
どちらか片方にしか出現しない素性については，共通空間とドメイン依存空間
の素性が重くなる．

図\ref{fig-augment}には，素性空間拡張法の適用例も示した．
ここでは，格助詞「が」を「を」に置換するか，無修正にするかという問題に
単純化する．いま，ソースドメインデータ，ターゲットドメインデータから，
以下の3種類の素性が得られたとする（表{\ref{tbl-templates}}の素性No.~11
を想定）．

\begin{itemize}
\item 「機能:が:利用」は，ソースドメイン，ターゲットドメイン双方に現れ，
  どちらも「を」に訂正している．
\item 「データ:が:変更」は，ソース，ターゲット双方に現れているが，ソー
  スドメインでは無修正，ターゲットドメインでは「を」に置換されている．
\item 「関数:が:実行」は，ソースドメインのみに現れている．
\end{itemize}

この素性空間上でパラメータ推定を行うと，「機能:が:利用」は，ドメイン間
で矛盾しないので，共通空間の重みが特に大きくなる．一方，「データ:が:変
更」は，ソース・ターゲットで矛盾しているので，共通空間の重みが0になり，
ソースまたはターゲット空間で，訂正先に依存した重みが重くなる．また，
「関数:が:実行」は，共通空間とソース空間の重みが大きくなっている．

\begin{figure}[t]
\begin{center}
\includegraphics{19-5ia2f3.eps}
\end{center}
\caption{素性空間の拡張}
\label{fig-augment}
\end{figure}

誤り訂正時には，共通とターゲット空間の素性のみを利用してデコードが行わ
れる．ターゲットドメインに最適化されているため，実際の誤り出現分布に近
くなる．また，ターゲットドメインの訓練データに現れない素性に関しても，
ソースドメインデータから学習された共通空間の素性が利用できるため，ター
ゲットドメインのみを利用するときより，未知の入力に頑健になる．
図\ref{fig-augment}の例では，ソースドメインのみに出現した「関数:が:実行」
も利用して訂正ができる．



