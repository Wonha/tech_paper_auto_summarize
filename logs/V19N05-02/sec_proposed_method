まず，実際に外国人がどのような日本語書き誤りをしてしまうのか，日本語を学んでいる中国語母語話者を対象に誤り例を収集した．
被験者は日本語の学習歴があり，日本の技術系大学に在籍する，もしくは卒業した背景をもつ37名である．
日本滞在歴は半年から6年程度である．
各被験者に技術系文書（Linuxマニュアル等80文）の英文と24個の図（のべ104課題）を提示し，キーボード入力による日本語作文を実施した（これを学習者作文と呼ぶ）．
最終的には2,770文の学習者作文データを収集し，各作文を日本語母語話者が推敲した（以下，単に修正文と呼ぶ）．
誤りを訂正する際には，文意を変更せず，文法的に正しい日本語とするための最小限の訂正を行うよう留意した．
言い換えると，この推敲で訂正された誤りは，訂正しないと正しい日本語にはならないものである．
誤り傾向の分析にあたり，まずは大分類として，文法誤り，語彙誤り，表記誤りの3種類を設定し，さらに小分類を設定した（表[REF_tbl-error-class]）．
収集した2,770文の分析を実施したところ，訂正が可能であったものは2,171文であった．
訂正が出来なかったものは，全く誤りがない日本語文559文，および文として不完全な断片40文である．
これ以降の分析は，訂正が可能であった2,171文に対して行った．
まず，誤り訂正の発生箇所は4,916箇所であり，1文あたり平均2.26箇所であった．
また各誤りの種別について，誤り大分類での出現分布をみると，文法誤りが54%と最も多く，続いて語彙誤り28%，表記誤りが16%であった．
これ以外は複数の誤りが混在する複合型誤りである．
さらに小分類での出現分布をみると，最も多く発生していたのは助詞・助動詞誤り33%，続いてカタカナ語誤り11%，単語選択（類義語）の誤り10%であった．
今回の誤り傾向であるが，助詞誤りおよびカタカナ誤りは中国語母語話者に限らず広く外国人に共通して出現するものであると推測される．
助詞は日本語特有の文法であり，多くの非日本語母語話者にとっては習得が難しいものである．
そのため，中国語母語話者に限らず外国人の学習者作文の誤りに対する訂正対象を助詞とすることは，発生率から考えても効果的である．
助詞の種類によって誤り発生のしやすさは異なっているはずであり，全ての助詞が一律に誤りとはならない．
今回の作文データにおける助詞誤りについて，さらに詳細に内訳を分析をしたところ，まず，誤りタイプとしては置換誤りが74%，助詞の抜けが17%，余分な助詞の出現が9%であった．
特に置換誤りの発生が高い．
また余分な助詞の出現が9%と非常に低く，訂正のために助詞の削除操作が必要となるケースは少ないことがわかる．
個別の助詞誤り発生回数上位10件は表[REF_tbl-particle-errors]のとおりである．
このうち，「は→が」への置換訂正については，1文中に2回，「は／係助詞」が出現し，片方を「が／格助詞」に置換しなければならなかったものである（たとえば，「問題はあるときは．
．
．
」）．
「の」の助詞抜けとしては，「2つファイル」のように，数量表現に後続する名詞の直前の「の」が欠けている誤りがよく見られた．
また，余分な助詞「の」としては，「やったの人」「小さいの絵」など，連体修飾で使用された動詞や形容詞に後続して「の」が余分に存在している誤りが多い．
以上の分析から，本稿では，誤りの出現頻度の高い助詞誤りを訂正対象とした．
また，助詞の置換，挿入，削除が現れていることから，原文（入力文）を置換，挿入，削除操作することにより，誤り訂正を行う．
本章では，ベースとなる識別的系列変換を用いた誤り訂正方式について述べる．
本稿の誤り訂正は，学習者作文および修正文をあらかじめ形態素解析し，単語列から単語列へ変換することで行う．
本方式は，基本的には識別モデルを用いた句に基づく統計翻訳器と同等であるが，挿入，削除操作への拡張と，言語モデル確率を扱う拡張を行っている．
分類器を用いる誤り訂正方法と異なり，1文中の複数の誤りを一度に訂正し，助詞以外の誤りにも拡張が可能な方式である．
本稿では，音声認識結果を言語処理用単語列に変換する形態素変換器[CITE]をベースにし，以下の手順で入力文の誤りを訂正する．
まず，入力単語列でフレーズテーブルを検索し，入力側にマッチするフレーズを得る．
フレーズテーブルは，助詞誤りとその訂正候補を対にして格納したものである．
これは誤り訂正タスクにおけるConfusion Set [CITE]と同じもので，表[REF_tbl-particle-errors]をテーブル化したものである．
フレーズテーブルと照合することにより，すべての訂正候補が得られる．
また，無修正の場合を考慮し，入力単語を出力単語にコピーしたフレーズを作成し，両者をまとめてラティス構造にパックする（図[REF_fig-lattice]）．
これをフレーズラティスと呼ぶ．
フレーズラティスから，条件付き確率場(Conditional Random Fields; CRF) [CITE]に基づき，最尤フレーズ列を探索する．
本稿の誤り訂正では語順の変更を行わないため，探索にはViterbiアルゴリズムを用いる．
フレーズラティスには，非文法的系列（たとえば，図[REF_fig-lattice]では，格助詞「を」が連続する系列も候補として存在）も含まれるが，枝刈りなどは行わず，モデルに従い最尤探索を行う．
学習時には，学習者作文と修正文に対して，DPマッチによる単語アライメントを行い，正解のフレーズ列を作成する．
この正解から，助詞誤りだけを取得してフレーズテーブルを作成するほか，正解を教師データとしてCRFを学習する．
一般的に句に基づく翻訳器は置換操作のみで翻訳を行うが，本稿で実施する誤り訂正は，助詞の置換操作のほかに，挿入，削除操作も対象となる．
挿入操作は，空単語からある単語への置換，削除操作は，ある単語から空単語への置換とみなせるため，両者も基本的には置換操作と同等に扱い，モデルの学習・適用を行う．
しかし，挿入操作は，全単語間に挿入される可能性があるため，ラティス構築時にサイズが爆発するなど，非常に計算コストの高い操作である．
挿入箇所をある程度絞ることが望ましいため，本稿では，名詞直後に後続する助詞のみ，挿入を許可するという制約をかける．
挿入は1箇所1単語のみとする．
この制約により，一部訂正不可能な誤りも生じる（たとえば，格助詞「に」の直後に係助詞「は」を挿入し，「に」を「には」に訂正するのは不可能となる）．
なお，置換操作は，挿入操作と削除操作の連続でも表現できる．
本稿では，挿入と削除操作が連続していた場合は，置換操作になるように正解データを作成し，モデルを学習する．
誤り訂正時には，フレーズラティス内に置換操作の候補と，挿入と削除操作が連続する候補が混在するが，誤り訂正モデルに従い最尤探索すると，ほとんどすべての場合，置換操作が選ばれる．
本手法では2種類の素性を用いる．
一つは翻訳モデルに相当する入力と出力のフレーズ対応度を測るためのマッピング素性，もう一つは言語モデルに相当する出力単語列の日本語としてのもっともらしさを測るためのリンク素性である．
マッピング素性とリンク素性の概要を図[REF_fig-features]に，素性テンプレートの一覧を表[REF_tbl-templates]に示す．
固有表現抽出など，識別モデルを用いるタスクでは，タグを付与すべき単語のほかに，その周辺単語を素性として用いる場合が多く，今回も同様な考え方をする．
具体的には，当該フレーズの入力側前後2単語をウィンドウとして，1〜3-gramと当該フレーズの出力単語の対を，二値のマッピング素性として使用する．
リンク素性に関しては，次節で詳細に述べる．
誤り訂正タスクにおいては，「正しい日本語」を出力する必要があるため，リンク素性は重要であると考えられる．
この「正しい日本語」は，既存の日本語平文コーパスから容易に入手可能である．
そこで以下の2種類のリンク素性を併用し，識別学習を通じて全体最適化を行う．
識別モデルを用いる本稿の方式は，相互に依存する素性を混在できるという特徴を利用している．
n-gram二値素性：出力単語の1〜3-gramを二値素性として使用する．
最適化用の訓練コーパス（学習者作文・修正文などのペア文）からしか獲得できない．
個々のn-gramの素性重みは，マッピング素性を含む他の素性との兼ね合いを考慮しながら最適化されるため，きめ細かい最適化ができ，訓練コーパスにおける精度は高い．
言い換えると，未知テキスト中に訓練コーパスと同じパターンの誤りが出現した場合，非常に高い精度で訂正ができる．
言語モデル確率：出力単語列のn-gram確率（実際にはトライグラム確率）の対数値を実数素性として使用する．
素性重みは1つしか付与されないが，言語モデルは日本語平文コーパスから学習できるため，訓練コーパスに限らず，大量の文から構築できる．
訓練コーパスに出現した／しないにかかわらず，日本語としての適切さをスコアとして与えることができる．
識別学習における二値素性と実数素性の混在は，半教師あり学習における補助モデル[CITE]と同じ考え方であり，訓練コーパス上での精度を保ちながら，未知テキストに対して頑健な訂正が行えるという利点がある．
第[REF_sec-conversion]章で述べた誤り訂正器には，学習のため，翻訳における対訳文に相当する学習者作文・修正文ペアが必要である．
しかし，実際の誤り事例を大量に収集するのは困難であるため，自動生成した疑似誤り文を用いてペア文を拡張する．
本章では，まず疑似誤り文生成方法について説明し，ドメイン適応を利用した疑似誤り文の適用方式について説明する．
前述のとおり，学習者作文・日本語修正文ペアのうちの日本語修正文に関しては，日本語平文コーパスなどから文を適当に選択することにより，容易に入手できる．
よって，収集した文を，学習者作文のように誤らせることができれば，ペア文として扱うことができる．
本稿では，[CITE]と同様の生成方法を取る．
具体的には，フレーズテーブルには，すでに誤った助詞とその訂正候補が記録されているので，これを逆に適用し，訂正候補助詞が出現したら，正しい助詞を誤らせる．
誤りはある確率で発生させるが，発生確率には，実誤りコーパス（学習者作文と日本語修正文ペア）上での正解助詞[MATH]とその誤り助詞[MATH]の相対頻度を使用する．
すなわち，
ただし，[MATH]は誤り発生確率，[MATH]は，実誤りコーパス上での正解助詞[MATH]とその誤り助詞[MATH]の共起頻度，[MATH]は同コーパス上での正解助詞[MATH]の出現頻度である．
このように生成した疑似誤り文を訓練コーパスに加えることにより，誤り訂正モデルを学習する．
自動で作成した疑似誤り文の問題点は，実際の誤りの確率分布を反映している保証がない点である．
より正確に実誤りに近づけるため，本稿ではドメイン適応の技術を用いる．
すなわち疑似誤り文コーパスをソースドメイン，実際の学習者作文コーパスをターゲットドメインとみなし，ターゲットドメインに適応させた誤り訂正モデルを学習する．
本稿では，ドメイン適応法に[CITE]の素性空間拡張法(Feature Augmentation)を用いる．
これは，素性空間を拡張することによりドメイン適応を行うもので，ソースドメインに関するモデルを事前分布と考えることに相当する．
また，学習方法（学習器）を変更する必要がないという特徴がある．
素性空間拡張法を簡単に説明する．
素性選択によって構築された素性は，共通，ソース，ターゲットの素性空間に拡張して配備される．
この際，ソースドメインから作成された素性([MATH])は共通およびソースに，ターゲットドメインから作成された素性([MATH])は共通およびターゲットの素性空間に配備する．
つまり，素性空間が3倍に拡張される（図[REF_fig-augment]）．
パラメータ推定は，上記素性空間上で通常どおり推定される．
その結果，ソースドメイン，ターゲットドメインで共通に用いられる素性（つまり，ソース，ターゲットで矛盾しない素性）に関しては，共通空間の重みが大きくなり，両者で矛盾する素性に関しては，ソースまたはターゲット空間の素性が重くなる．
どちらか片方にしか出現しない素性については，共通空間とドメイン依存空間の素性が重くなる．
図[REF_fig-augment]には，素性空間拡張法の適用例も示した．
ここでは，格助詞「が」を「を」に置換するか，無修正にするかという問題に単純化する．
いま，ソースドメインデータ，ターゲットドメインデータから，以下の3種類の素性が得られたとする（表{[REF_tbl-templates]}の素性No. 11を想定）．
「機能:が:利用」は，ソースドメイン，ターゲットドメイン双方に現れ，どちらも「を」に訂正している．
「データ:が:変更」は，ソース，ターゲット双方に現れているが，ソースドメインでは無修正，ターゲットドメインでは「を」に置換されている．
「関数:が:実行」は，ソースドメインのみに現れている．
この素性空間上でパラメータ推定を行うと，「機能:が:利用」は，ドメイン間で矛盾しないので，共通空間の重みが特に大きくなる．
一方，「データ:が:変更」は，ソース・ターゲットで矛盾しているので，共通空間の重みが0になり，ソースまたはターゲット空間で，訂正先に依存した重みが重くなる．
また，「関数:が:実行」は，共通空間とソース空間の重みが大きくなっている．
誤り訂正時には，共通とターゲット空間の素性のみを利用してデコードが行われる．
ターゲットドメインに最適化されているため，実際の誤り出現分布に近くなる．
また，ターゲットドメインの訓練データに現れない素性に関しても，ソースドメインデータから学習された共通空間の素性が利用できるため，ターゲットドメインのみを利用するときより，未知の入力に頑健になる．
図[REF_fig-augment]の例では，ソースドメインのみに出現した「関数:が:実行」も利用して訂正ができる．
まず，実際に外国人がどのような日本語書き誤りをしてしまうのか，日本語を学んでいる中国語母語話者を対象に誤り例を収集した．
被験者は日本語の学習歴があり，日本の技術系大学に在籍する，もしくは卒業した背景をもつ37名である．
日本滞在歴は半年から6年程度である．
各被験者に技術系文書（Linuxマニュアル等80文）の英文と24個の図（のべ104課題）を提示し，キーボード入力による日本語作文を実施した（これを学習者作文と呼ぶ）．
最終的には2,770文の学習者作文データを収集し，各作文を日本語母語話者が推敲した（以下，単に修正文と呼ぶ）．
誤りを訂正する際には，文意を変更せず，文法的に正しい日本語とするための最小限の訂正を行うよう留意した．
言い換えると，この推敲で訂正された誤りは，訂正しないと正しい日本語にはならないものである．
誤り傾向の分析にあたり，まずは大分類として，文法誤り，語彙誤り，表記誤りの3種類を設定し，さらに小分類を設定した（表[REF_tbl-error-class]）．
収集した2,770文の分析を実施したところ，訂正が可能であったものは2,171文であった．
訂正が出来なかったものは，全く誤りがない日本語文559文，および文として不完全な断片40文である．
これ以降の分析は，訂正が可能であった2,171文に対して行った．
まず，誤り訂正の発生箇所は4,916箇所であり，1文あたり平均2.26箇所であった．
また各誤りの種別について，誤り大分類での出現分布をみると，文法誤りが54%と最も多く，続いて語彙誤り28%，表記誤りが16%であった．
これ以外は複数の誤りが混在する複合型誤りである．
さらに小分類での出現分布をみると，最も多く発生していたのは助詞・助動詞誤り33%，続いてカタカナ語誤り11%，単語選択（類義語）の誤り10%であった．
今回の誤り傾向であるが，助詞誤りおよびカタカナ誤りは中国語母語話者に限らず広く外国人に共通して出現するものであると推測される．
助詞は日本語特有の文法であり，多くの非日本語母語話者にとっては習得が難しいものである．
そのため，中国語母語話者に限らず外国人の学習者作文の誤りに対する訂正対象を助詞とすることは，発生率から考えても効果的である．
助詞の種類によって誤り発生のしやすさは異なっているはずであり，全ての助詞が一律に誤りとはならない．
今回の作文データにおける助詞誤りについて，さらに詳細に内訳を分析をしたところ，まず，誤りタイプとしては置換誤りが74%，助詞の抜けが17%，余分な助詞の出現が9%であった．
特に置換誤りの発生が高い．
また余分な助詞の出現が9%と非常に低く，訂正のために助詞の削除操作が必要となるケースは少ないことがわかる．
個別の助詞誤り発生回数上位10件は表[REF_tbl-particle-errors]のとおりである．
このうち，「は→が」への置換訂正については，1文中に2回，「は／係助詞」が出現し，片方を「が／格助詞」に置換しなければならなかったものである（たとえば，「問題はあるときは．
．
．
」）．
「の」の助詞抜けとしては，「2つファイル」のように，数量表現に後続する名詞の直前の「の」が欠けている誤りがよく見られた．
また，余分な助詞「の」としては，「やったの人」「小さいの絵」など，連体修飾で使用された動詞や形容詞に後続して「の」が余分に存在している誤りが多い．
以上の分析から，本稿では，誤りの出現頻度の高い助詞誤りを訂正対象とした．
また，助詞の置換，挿入，削除が現れていることから，原文（入力文）を置換，挿入，削除操作することにより，誤り訂正を行う．
本章では，ベースとなる識別的系列変換を用いた誤り訂正方式について述べる．
本稿の誤り訂正は，学習者作文および修正文をあらかじめ形態素解析し，単語列から単語列へ変換することで行う．
本方式は，基本的には識別モデルを用いた句に基づく統計翻訳器と同等であるが，挿入，削除操作への拡張と，言語モデル確率を扱う拡張を行っている．
分類器を用いる誤り訂正方法と異なり，1文中の複数の誤りを一度に訂正し，助詞以外の誤りにも拡張が可能な方式である．
本稿では，音声認識結果を言語処理用単語列に変換する形態素変換器[CITE]をベースにし，以下の手順で入力文の誤りを訂正する．
まず，入力単語列でフレーズテーブルを検索し，入力側にマッチするフレーズを得る．
フレーズテーブルは，助詞誤りとその訂正候補を対にして格納したものである．
これは誤り訂正タスクにおけるConfusion Set [CITE]と同じもので，表[REF_tbl-particle-errors]をテーブル化したものである．
フレーズテーブルと照合することにより，すべての訂正候補が得られる．
また，無修正の場合を考慮し，入力単語を出力単語にコピーしたフレーズを作成し，両者をまとめてラティス構造にパックする（図[REF_fig-lattice]）．
これをフレーズラティスと呼ぶ．
フレーズラティスから，条件付き確率場(Conditional Random Fields; CRF) [CITE]に基づき，最尤フレーズ列を探索する．
本稿の誤り訂正では語順の変更を行わないため，探索にはViterbiアルゴリズムを用いる．
フレーズラティスには，非文法的系列（たとえば，図[REF_fig-lattice]では，格助詞「を」が連続する系列も候補として存在）も含まれるが，枝刈りなどは行わず，モデルに従い最尤探索を行う．
学習時には，学習者作文と修正文に対して，DPマッチによる単語アライメントを行い，正解のフレーズ列を作成する．
この正解から，助詞誤りだけを取得してフレーズテーブルを作成するほか，正解を教師データとしてCRFを学習する．
一般的に句に基づく翻訳器は置換操作のみで翻訳を行うが，本稿で実施する誤り訂正は，助詞の置換操作のほかに，挿入，削除操作も対象となる．
挿入操作は，空単語からある単語への置換，削除操作は，ある単語から空単語への置換とみなせるため，両者も基本的には置換操作と同等に扱い，モデルの学習・適用を行う．
しかし，挿入操作は，全単語間に挿入される可能性があるため，ラティス構築時にサイズが爆発するなど，非常に計算コストの高い操作である．
挿入箇所をある程度絞ることが望ましいため，本稿では，名詞直後に後続する助詞のみ，挿入を許可するという制約をかける．
挿入は1箇所1単語のみとする．
この制約により，一部訂正不可能な誤りも生じる（たとえば，格助詞「に」の直後に係助詞「は」を挿入し，「に」を「には」に訂正するのは不可能となる）．
なお，置換操作は，挿入操作と削除操作の連続でも表現できる．
本稿では，挿入と削除操作が連続していた場合は，置換操作になるように正解データを作成し，モデルを学習する．
誤り訂正時には，フレーズラティス内に置換操作の候補と，挿入と削除操作が連続する候補が混在するが，誤り訂正モデルに従い最尤探索すると，ほとんどすべての場合，置換操作が選ばれる．
本手法では2種類の素性を用いる．
一つは翻訳モデルに相当する入力と出力のフレーズ対応度を測るためのマッピング素性，もう一つは言語モデルに相当する出力単語列の日本語としてのもっともらしさを測るためのリンク素性である．
マッピング素性とリンク素性の概要を図[REF_fig-features]に，素性テンプレートの一覧を表[REF_tbl-templates]に示す．
固有表現抽出など，識別モデルを用いるタスクでは，タグを付与すべき単語のほかに，その周辺単語を素性として用いる場合が多く，今回も同様な考え方をする．
具体的には，当該フレーズの入力側前後2単語をウィンドウとして，1〜3-gramと当該フレーズの出力単語の対を，二値のマッピング素性として使用する．
リンク素性に関しては，次節で詳細に述べる．
誤り訂正タスクにおいては，「正しい日本語」を出力する必要があるため，リンク素性は重要であると考えられる．
この「正しい日本語」は，既存の日本語平文コーパスから容易に入手可能である．
そこで以下の2種類のリンク素性を併用し，識別学習を通じて全体最適化を行う．
識別モデルを用いる本稿の方式は，相互に依存する素性を混在できるという特徴を利用している．
n-gram二値素性：出力単語の1〜3-gramを二値素性として使用する．
最適化用の訓練コーパス（学習者作文・修正文などのペア文）からしか獲得できない．
個々のn-gramの素性重みは，マッピング素性を含む他の素性との兼ね合いを考慮しながら最適化されるため，きめ細かい最適化ができ，訓練コーパスにおける精度は高い．
言い換えると，未知テキスト中に訓練コーパスと同じパターンの誤りが出現した場合，非常に高い精度で訂正ができる．
言語モデル確率：出力単語列のn-gram確率（実際にはトライグラム確率）の対数値を実数素性として使用する．
素性重みは1つしか付与されないが，言語モデルは日本語平文コーパスから学習できるため，訓練コーパスに限らず，大量の文から構築できる．
訓練コーパスに出現した／しないにかかわらず，日本語としての適切さをスコアとして与えることができる．
識別学習における二値素性と実数素性の混在は，半教師あり学習における補助モデル[CITE]と同じ考え方であり，訓練コーパス上での精度を保ちながら，未知テキストに対して頑健な訂正が行えるという利点がある．
第[REF_sec-conversion]章で述べた誤り訂正器には，学習のため，翻訳における対訳文に相当する学習者作文・修正文ペアが必要である．
しかし，実際の誤り事例を大量に収集するのは困難であるため，自動生成した疑似誤り文を用いてペア文を拡張する．
本章では，まず疑似誤り文生成方法について説明し，ドメイン適応を利用した疑似誤り文の適用方式について説明する．
前述のとおり，学習者作文・日本語修正文ペアのうちの日本語修正文に関しては，日本語平文コーパスなどから文を適当に選択することにより，容易に入手できる．
よって，収集した文を，学習者作文のように誤らせることができれば，ペア文として扱うことができる．
本稿では，[CITE]と同様の生成方法を取る．
具体的には，フレーズテーブルには，すでに誤った助詞とその訂正候補が記録されているので，これを逆に適用し，訂正候補助詞が出現したら，正しい助詞を誤らせる．
誤りはある確率で発生させるが，発生確率には，実誤りコーパス（学習者作文と日本語修正文ペア）上での正解助詞[MATH]とその誤り助詞[MATH]の相対頻度を使用する．
すなわち，
ただし，[MATH]は誤り発生確率，[MATH]は，実誤りコーパス上での正解助詞[MATH]とその誤り助詞[MATH]の共起頻度，[MATH]は同コーパス上での正解助詞[MATH]の出現頻度である．
このように生成した疑似誤り文を訓練コーパスに加えることにより，誤り訂正モデルを学習する．
自動で作成した疑似誤り文の問題点は，実際の誤りの確率分布を反映している保証がない点である．
より正確に実誤りに近づけるため，本稿ではドメイン適応の技術を用いる．
すなわち疑似誤り文コーパスをソースドメイン，実際の学習者作文コーパスをターゲットドメインとみなし，ターゲットドメインに適応させた誤り訂正モデルを学習する．
本稿では，ドメイン適応法に[CITE]の素性空間拡張法(Feature Augmentation)を用いる．
これは，素性空間を拡張することによりドメイン適応を行うもので，ソースドメインに関するモデルを事前分布と考えることに相当する．
また，学習方法（学習器）を変更する必要がないという特徴がある．
素性空間拡張法を簡単に説明する．
素性選択によって構築された素性は，共通，ソース，ターゲットの素性空間に拡張して配備される．
この際，ソースドメインから作成された素性([MATH])は共通およびソースに，ターゲットドメインから作成された素性([MATH])は共通およびターゲットの素性空間に配備する．
つまり，素性空間が3倍に拡張される（図[REF_fig-augment]）．
パラメータ推定は，上記素性空間上で通常どおり推定される．
その結果，ソースドメイン，ターゲットドメインで共通に用いられる素性（つまり，ソース，ターゲットで矛盾しない素性）に関しては，共通空間の重みが大きくなり，両者で矛盾する素性に関しては，ソースまたはターゲット空間の素性が重くなる．
どちらか片方にしか出現しない素性については，共通空間とドメイン依存空間の素性が重くなる．
図[REF_fig-augment]には，素性空間拡張法の適用例も示した．
ここでは，格助詞「が」を「を」に置換するか，無修正にするかという問題に単純化する．
いま，ソースドメインデータ，ターゲットドメインデータから，以下の3種類の素性が得られたとする（表{[REF_tbl-templates]}の素性No. 11を想定）．
「機能:が:利用」は，ソースドメイン，ターゲットドメイン双方に現れ，どちらも「を」に訂正している．
「データ:が:変更」は，ソース，ターゲット双方に現れているが，ソースドメインでは無修正，ターゲットドメインでは「を」に置換されている．
「関数:が:実行」は，ソースドメインのみに現れている．
この素性空間上でパラメータ推定を行うと，「機能:が:利用」は，ドメイン間で矛盾しないので，共通空間の重みが特に大きくなる．
一方，「データ:が:変更」は，ソース・ターゲットで矛盾しているので，共通空間の重みが0になり，ソースまたはターゲット空間で，訂正先に依存した重みが重くなる．
また，「関数:が:実行」は，共通空間とソース空間の重みが大きくなっている．
誤り訂正時には，共通とターゲット空間の素性のみを利用してデコードが行われる．
ターゲットドメインに最適化されているため，実際の誤り出現分布に近くなる．
また，ターゲットドメインの訓練データに現れない素性に関しても，ソースドメインデータから学習された共通空間の素性が利用できるため，ターゲットドメインのみを利用するときより，未知の入力に頑健になる．
図[REF_fig-augment]の例では，ソースドメインのみに出現した「関数:が:実行」も利用して訂正ができる．
