日本語学習者の助詞誤り検出・訂正は従来より研究されてきた．
-0.5zw近年では，[CITE]が，最大エントロピー法(ME)による分類器を用いて，助詞（主に格助詞）が欠落した文からの復元を行っている．
この入力文は形態素・構文解析済みであり，基本的に誤り箇所が既に分かっているとき，挿入操作だけで修正を行う．
[CITE]は，形態素・構文解析済みの入力文（誤りを含む）に対して，周辺の形態素や係り先を素性として，SVMで助詞の誤用検出する方法を提案している．
ここでは，助詞の欠落も対象としている．
検出を行うのみで修正までは行わない．
英語の前置詞・冠詞誤り訂正では，[CITE]が，前置詞周辺単語や構文解析の主辞などを素性としたME分類器を用いて，前置詞の誤り訂正を行った．
[CITE]は前置詞と冠詞誤りを対象に，ME分類器による誤り検出，決定木による誤り訂正を行った．
また，[CITE]は平均化パーセプトロンに基づく分類器で前置詞の誤り訂正を行っている．
これらの研究は，いずれも誤りの種類を助詞や前置詞・冠詞に限定することで，分類器による誤り訂正を可能としている．
一方，[CITE]は，誤りを助詞に限定せず，すべての誤りを対象とした自動訂正法を提案した．
ここでは，対訳文に相当する学習者作文と日本人による修正文のペアを大量にSNSから収集し，句に基づく統計翻訳の仕組みを利用して訂正を行う．
誤りを含む入力の形態素解析は行わず，文字単位で翻訳を行う．
本稿で使用した系列変換は，基本的には統計翻訳と同等な手法である．
そのため，誤りの種類を助詞に限定する必要がなく，他の誤りにも拡張できる．
しかし，本稿の方式はあらかじめ学習者作文が単語に分割されていることを前提としている．
誤りを含む文を形態素解析，構文解析した場合の精度は，一般的には日本語母語話者が記述した文の解析精度より落ちると考えられるため，単語分割法も併せて検討する必要がある[CITE]．
母語話者の記述したテキスト（日本語修正文相当）のモデル化という観点で上記研究を俯瞰すると，[CITE]はn-gram二値素性として利用している．
[CITE]は，n-gram確率という形でモデル化している．
本稿では，識別モデルの枠組みで両者を併用し，マッピング素性を含んで全体最適化を行うことにより，再現率を向上することができた．
学習者作文の利用という観点で俯瞰すると，いずれの研究も，学習者の誤り傾向をモデルとして組み込むことにより，母語話者の記述したテキストのみを用いて誤り訂正を行う場合に比べ，訂正精度が向上したと報告している[CITE]．
本稿の方式は，マッピング素性という形で学習者の誤り傾向をモデル化しており，従来研究の成果を取り込んでいる．
学習者作文を模した擬似誤り文に関しては，[CITE]が提案を行っている．
そこでは，学習者の実誤りと同じ分布を持つ擬似誤り文を追加することにより，精度が向上したと報告している．
ただ，データ（論文では学習者の母語別）によって最適な擬似誤り生成方法が異なっており，擬似誤り生成を制御する必要がある．
本稿では，擬似誤りと実誤りのずれをドメイン適応技術を用いて修正することで安定した精度向上ができた．
さまざまな種類の誤りの同時訂正は，[CITE]も行い，前置詞・冠詞誤りだけでなく，スペルミス，句読点，名詞の数の誤りも含めて訂正を行っている．
誤りの種別ごとに分類器やルールを用いて訂正仮説を生成し，山登り的に書き換えを繰り返すことで1文中の複数の誤りを訂正する．
彼らは，複数の仮説を保持することで，山登り時に局所解に陥る可能性を軽減しているが，本稿の方式はすべての仮説をフレーズラティスに持ち，Viterbiアルゴリズムで最適な組み合わせを探索しているので，モデル上は最適な訂正結果であることが保証されている．
本タスクは，訂正すべき助詞に比べ訂正不要な助詞が圧倒的に多く，安易な再現率の向上は誤り訂正精度（相対向上数）の改善に直結しないと述べた．
これはデータ不平衡問題(Imbalanced Data Problem)と呼ばれ，機械学習を実タスクに適用するときの主要な問題の一つと認識されている（たとえば，サーベイ論文[CITE]を参照）．
この問題の解決方法には，少数派と多数派のデータを増減させることで平衡させる方法（サンプリング法）や，少数派の分類誤り（本タスクの場合，訂正誤り）と多数派の分類誤りに異なるコストを与えて学習する方法（ベイズリスク最小法）など，さまざまなものが提案されており，本タスクに適用できるか検討する必要がある．
なお，本稿で提案した疑似誤り文は，実誤りの分布を変えないようにデータを増やすのが目的であるので，少数派データを増やすover-sampling法とは異なる位置づけである．
日本語学習者の助詞誤り検出・訂正は従来より研究されてきた．
-0.5zw近年では，[CITE]が，最大エントロピー法(ME)による分類器を用いて，助詞（主に格助詞）が欠落した文からの復元を行っている．
この入力文は形態素・構文解析済みであり，基本的に誤り箇所が既に分かっているとき，挿入操作だけで修正を行う．
[CITE]は，形態素・構文解析済みの入力文（誤りを含む）に対して，周辺の形態素や係り先を素性として，SVMで助詞の誤用検出する方法を提案している．
ここでは，助詞の欠落も対象としている．
検出を行うのみで修正までは行わない．
英語の前置詞・冠詞誤り訂正では，[CITE]が，前置詞周辺単語や構文解析の主辞などを素性としたME分類器を用いて，前置詞の誤り訂正を行った．
[CITE]は前置詞と冠詞誤りを対象に，ME分類器による誤り検出，決定木による誤り訂正を行った．
また，[CITE]は平均化パーセプトロンに基づく分類器で前置詞の誤り訂正を行っている．
これらの研究は，いずれも誤りの種類を助詞や前置詞・冠詞に限定することで，分類器による誤り訂正を可能としている．
一方，[CITE]は，誤りを助詞に限定せず，すべての誤りを対象とした自動訂正法を提案した．
ここでは，対訳文に相当する学習者作文と日本人による修正文のペアを大量にSNSから収集し，句に基づく統計翻訳の仕組みを利用して訂正を行う．
誤りを含む入力の形態素解析は行わず，文字単位で翻訳を行う．
本稿で使用した系列変換は，基本的には統計翻訳と同等な手法である．
そのため，誤りの種類を助詞に限定する必要がなく，他の誤りにも拡張できる．
しかし，本稿の方式はあらかじめ学習者作文が単語に分割されていることを前提としている．
誤りを含む文を形態素解析，構文解析した場合の精度は，一般的には日本語母語話者が記述した文の解析精度より落ちると考えられるため，単語分割法も併せて検討する必要がある[CITE]．
母語話者の記述したテキスト（日本語修正文相当）のモデル化という観点で上記研究を俯瞰すると，[CITE]はn-gram二値素性として利用している．
[CITE]は，n-gram確率という形でモデル化している．
本稿では，識別モデルの枠組みで両者を併用し，マッピング素性を含んで全体最適化を行うことにより，再現率を向上することができた．
学習者作文の利用という観点で俯瞰すると，いずれの研究も，学習者の誤り傾向をモデルとして組み込むことにより，母語話者の記述したテキストのみを用いて誤り訂正を行う場合に比べ，訂正精度が向上したと報告している[CITE]．
本稿の方式は，マッピング素性という形で学習者の誤り傾向をモデル化しており，従来研究の成果を取り込んでいる．
学習者作文を模した擬似誤り文に関しては，[CITE]が提案を行っている．
そこでは，学習者の実誤りと同じ分布を持つ擬似誤り文を追加することにより，精度が向上したと報告している．
ただ，データ（論文では学習者の母語別）によって最適な擬似誤り生成方法が異なっており，擬似誤り生成を制御する必要がある．
本稿では，擬似誤りと実誤りのずれをドメイン適応技術を用いて修正することで安定した精度向上ができた．
さまざまな種類の誤りの同時訂正は，[CITE]も行い，前置詞・冠詞誤りだけでなく，スペルミス，句読点，名詞の数の誤りも含めて訂正を行っている．
誤りの種別ごとに分類器やルールを用いて訂正仮説を生成し，山登り的に書き換えを繰り返すことで1文中の複数の誤りを訂正する．
彼らは，複数の仮説を保持することで，山登り時に局所解に陥る可能性を軽減しているが，本稿の方式はすべての仮説をフレーズラティスに持ち，Viterbiアルゴリズムで最適な組み合わせを探索しているので，モデル上は最適な訂正結果であることが保証されている．
本タスクは，訂正すべき助詞に比べ訂正不要な助詞が圧倒的に多く，安易な再現率の向上は誤り訂正精度（相対向上数）の改善に直結しないと述べた．
これはデータ不平衡問題(Imbalanced Data Problem)と呼ばれ，機械学習を実タスクに適用するときの主要な問題の一つと認識されている（たとえば，サーベイ論文[CITE]を参照）．
この問題の解決方法には，少数派と多数派のデータを増減させることで平衡させる方法（サンプリング法）や，少数派の分類誤り（本タスクの場合，訂正誤り）と多数派の分類誤りに異なるコストを与えて学習する方法（ベイズリスク最小法）など，さまざまなものが提案されており，本タスクに適用できるか検討する必要がある．
なお，本稿で提案した疑似誤り文は，実誤りの分布を変えないようにデータを増やすのが目的であるので，少数派データを増やすover-sampling法とは異なる位置づけである．
