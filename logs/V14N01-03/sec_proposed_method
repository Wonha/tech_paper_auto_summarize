本稿で提案する意味役割推定モデルは，与えられた文と述語に対して取り得る全ての意味役割注釈パタンについての尤度を計算し，尤度が最も高い注釈パタンを出力するモデルである．
すなわち，入力文[MATH]と述語[MATH]が与えられた時の意味役割注釈パタン[MATH]の確率[MATH]を最大にする意味役割注釈パタン[MATH]が最終的な出力となる．
注釈パタン[MATH]はフレーム[MATH]，項候補集合[MATH]，項候補-意味役割対応関係[MATH]により一意に決定されるため，式([REF_eqn:rolelabeling0_proposal])右辺[MATH]を以下のように定義した．
本稿では式([REF_eqn:rolelabeling1_proposal])右辺を第1項からそれぞれ，対応付けモデル，項候補獲得モデル，フレーム選択モデルと呼ぶ．
図[REF_fig:flow]に，これらのモデルの概要を示す．
図[REF_fig:flow]中の各モデルについては以下で詳説する．
ただし，項候補獲得モデル中の項候補同定モデル，および対応付けモデル中の自項独立/他項依存意味役割同定モデルの詳細は[REF_sec:outline_proposal]節で述べる．
フレーム選択モデルは与えられた文と述語から，項に付けられる注釈となるべき意味役割が定義された意味フレームを獲得するモデルである．
我々はフレーム選択モデルを，[MATH]が[MATH]の見出し語に含まれる場合に[MATH]を，それ以外で[MATH]を返す関数[MATH]を用い，以下のように定義した．
フレーム選択モデルの例を図[REF_fig:frameselection]に示す．
[t]
{
{ccccc} \multicolumn{2}{r}{バッグ内の[MATH]現金は}{40mm} & \multicolumn{1}{l}{盗ま}{れて}{18mm} \noroleb{いたが，}{18mm} & \multicolumn{2}{l}{願書は}{15mm} \noroleb{無事．
}{15mm}
\multicolumn{5}{c}{[MATH]}
\hline
\multicolumn{5}{|c|}{フレーム選択モデル}
\hline
\multicolumn{5}{c}{[MATH]}
\multicolumn{5}{l}{Theftフレーム[MATH]}
[1mm]
}
項候補獲得モデルは与えられた文と述語およびフレームから，意味役割を注釈付けする項（断片）を獲得するモデルである．
項候補の獲得手法を以下に示す．
[MATH]を構文解析し，[MATH]と直接係り受け関係にある部分木の集合[MATH]を得る．
[MATH]の各要素[MATH]について，形態素ならびに文節の単位で前後に短縮伸長し，項候補の候補（断片候補）[MATH]を生成，断片候補集合[MATH]を得る（断片候補生成）．
[MATH]の各要素[MATH]に関し，[MATH]が[MATH]を越える要素を[MATH]として集め，断片候補集合[MATH]を得る．
尤度[MATH]は項候補同定モデル（[REF_sec:proposal_argument]節）により得られる．
[MATH]の各要素[MATH]について，([REF_enum:foo_cand_proposal])の尤度[MATH]が最大となる[MATH]を[MATH]とし，項候補集合[MATH]を得る．
以上より，我々は項候補獲得モデルを以下のように定義した．
項候補獲得モデルの例を図[REF_fig:candidating]に示す．
我々は，述語項構造における項が文節を基本に構成された語句であると仮定し，構文解析結果に基づいた項候補獲得手法を提案する．
一方，河原らの格フレーム辞書構築の取り組みは，項の意味が表層格で抽象化されて表現されることを根拠とする[CITE]．
また，Baldeweinらは構文情報を用いた項の抽象化手法を提案している[CITE]．
我々の仮定はそれらと同様，項が構文情報によって抽象化できることを前提としている．
本稿で提案した項候補獲得手法では，項候補となるための要件を過不足なく満たす最適な断片候補を獲得するため，述語と直接係り受け関係にある文節から複数の断片候補を生成し，それらを確率モデルを用いて順位付けする．
断片候補生成手法は以下の通りである．
述語と直接係り受け関係にある文節を獲得する
獲得した文節から，それが1つ以上の内容語を含むという前提の下，以下に適合する形態素の列を獲得する
その文節に係る全ての文節に含まれる形態素の列
その文節の先頭から連続する名詞形態素の列
獲得した各形態素列に対して，それが1つ以上の内容語を含むという前提の下，以下の各ル−ルに基づいて断片候補を生成する
[MATH]
文節数を減らさない範囲で先頭から形態素を1つずつ短縮
先頭から文節を1つずつ短縮
末尾文節の範囲で先頭から形態素を1つずつ短縮
[MATH]
文節数を減らさない範囲で末尾から形態素を1つずつ短縮
末尾品詞が「助詞-連体化」の場合に文節数を最大1増加させる範囲で末尾に形態素を1つずつ伸長（ただし，最初に伸長した形態素が名詞の場合は後続形態素を名詞に限定）
対応付けモデルは，与えられた文，述語，フレームならびに項候補から，項候補と意味役割の対応付けを行うモデルである．
項と意味役割の対応付け手法は以下の通りである．
項候補集合[MATH]の各要素[MATH]について，[MATH]に定義された意味役割[MATH]（[MATH]は[MATH]に定義された意味役割の集合）が対応付けられる確率[MATH]を算出する．
[MATH]は自項独立意味役割同定モデル（[REF_sec:proposal_srt_indep]節）により得られる．
[MATH]の各要素[MATH]について，([REF_enum:foo_corr_proposal])の尤度[MATH]を[MATH]とし，[MATH]について重複のないように[MATH]を集めたものを項候補-意味役割対応関係[MATH]とする．
[MATH]の各要素[MATH]について，([REF_enum:bar_corr_proposal])の尤度[MATH]の積が最大となる意味役割対応付け[MATH]を得る．
[MATH]の各要素[MATH]について，[MATH]を考慮した上で意味役割[MATH]が対応付けられる確率[MATH]を算出する．
[MATH]は他項依存意味役割同定モデル（[REF_sec:proposal_srt_dep]節）により得られる．
[MATH]の各要素[MATH]について，([REF_enum:buz_corr_proposal])の尤度[MATH]を[MATH]とし，[MATH]について重複のないように[MATH]を集めたものを[MATH]とする．
以上より，我々は対応付けモデルを以下のように定義した．
対応付けモデルの例を図[REF_fig:corresponding]に示す．
次に，[REF_sec:models_def_proposal]節で定義した意味役割推定モデルを構築する手法について述べる．
本稿で提案する手法は，大きく6つのステップで構成されている．
日本語フレームネットから，意味フレーム定義，意味役割定義，品詞定義，見出し語，ならびに意味役割注釈付き事例を抽出する．
フレーム意味論に反しない2つの仮定の下，抽出した事例から新しい事例を作成する．
以下の仮定は，いかなる事例に適用しても言語的に不自然にならないものとして設定したもので，我々はこれらの仮定を妥当なものと考える．
述語に直接係る主語句（ガ格を末尾に持つ文節の全部分木）を削除しても，他の項の意味役割は変化しない．
文の主辞となる述語の項は削除しても，他の全ての項の意味役割が変化しない解釈が可能．
事例から確率モデルを学習する．
意味役割推定モデルに基づくシステムを構築する．
日本語フレームネットに定義された見出し語が述語の文をコーパスから抽出する．
抽出した文の項の意味役割を推定する．
本手法では，[REF_sec:models_def_proposal]節で定義した意味役割推定モデルのうち，以下の3つのモデルを機械学習により獲得する．
項候補同定モデル（式([REF_eqn:candidating0_proposal])条件[MATH]):
項候補獲得モデルにおいて断片候補が項候補となるかどうかを判定する．
自項独立意味役割同定モデル（式([REF_eqn:corresponding0_proposal])右辺[MATH]):
対応付けモデルにおいて，ある項候補にある意味役割が割り当てられるかを，他項の意味役割を考慮せずに判定する．
他項依存意味役割同定モデル（式([REF_eqn:corresponding2_proposal])右辺[MATH]):
対応付けモデルにおいて，ある項候補にある意味役割が割り当てられるかを，他項の意味役割を考慮した上で判定する．
我々は機械学習に，最大エントロピー法とサポートベクタマシンを用いた．
最大エントロピー法の実装にはツールmaxentを用い，サポートベクタマシンの実装にはTinySVMを用いた．
サポートベクタマシンの出力は，シグモイド関数に代入することで確率値とみなした[CITE]．
なお，構文解析器にはCaboCha [CITE]を用いた．
以下に，各モデルの詳細を述べる．
項候補同定モデルは，断片候補[MATH]が断片すなわち項候補となるかを判定するモデルであり，項候補獲得モデルに定義されている．
項候補同定モデルが定義された式([REF_eqn:candidating0_proposal])には，断片候補が項候補となるための閾値[MATH]が定義されており，最大エントロピー法およびサポートベクタマシンの出力に対する正当性から，今回はそれを[MATH]とした．
学習に必要な正事例には日本語フレームネットから抽出した注釈付き事例を用い，負事例は抽出した事例と正事例を基に以下の2通りの方法を用いて準備した．
[MATH]
はじめに，正事例の正解項候補に対して[REF_sec:models_def_proposal]節・項候補獲得モデル・断片候補生成手法([REF_enum:extend_rule3_proposal])を適用した．
その結果得られた断片候補を不正解項候補とした．
[MATH]
まず，抽出事例で述語に指定されていない全ての動詞に対して，[REF_sec:models_def_proposal]節・項候補獲得モデル・断片候補生成手法([REF_enum:extend_rule1_proposal])〜([REF_enum:extend_rule3_proposal])を適用した．
その結果得られた断片候補のうち，指定述語に対して同様の手順を適用して得られた断片候補および正事例に含まれる正解項候補と範囲が重複しない断片候補を不正解項候補とした．
また，学習には以下の素性を用いた．
[MATH]
対象述語の原形や活用形と，機能語を構成する各形態素の原形や品詞を用いた．
[MATH]
固有表現，未知語，対象述語からの文節を単位とした相対距離，機能語列とそれを構成する各形態素の品詞を用いた．
また，NTT日本語語彙大系から検索した主辞の概念クラスも用いた．
加えて，断片候補の直前に連接する形態素の原形と品詞も利用した．
自項独立意味役割推定モデルは，ある項候補にある意味役割が注釈付けられるかを判定するモデルであり，対応付けモデルに定義されている．
対応付けモデルの定義式([REF_eqn:corresponding0_proposal]) ([REF_eqn:corresponding1_proposal])より明らかなように，本モデルは複数の意味役割候補から一つを選択する多値分類タスクと考えることができる．
我々は機械学習に最大エントロピー法とサポートベクタマシンを用いたが，このうちサポートベクタマシンでは，多値分類にone vs. rest法を用いた．
学習の素性には，項候補同定モデルの学習に用いた素性に加え，以下を利用した．
[MATH]
項候補同定モデルの学習のために対象断片候補から抽出した素性のうち，直前の形態素に関するものを除いた全ての素性を利用した．
加えて，項候補同定モデルが対象項候補に対して出力した値と，項候補を単位とした対象述語からの相対距離も併せて利用した．
[MATH]
項候補同定モデルが非対象項候補に対して出力した値を用いた．
他項依存意味役割同定モデルは，他項に注釈付けられた意味役割を考慮した上で，項候補にある意味役割が注釈付けされるかを判定するモデルであり，対応付けモデルに定義されている．
対応付けモデルの定義式([REF_eqn:corresponding2_proposal])ならびに意味役割推定モデルの定義式([REF_eqn:rolelabeling1_proposal])より明らかなように，本モデルも複数の意味役割候補から一つを選択する多値分類タスクと見なすことができ，自項独立意味役割同定モデル同様，サポートベクタマシンではone vs. rest法を適用した．
学習の素性には，自項独立意味役割同定モデルの学習に用いた素性に加え，以下を利用した．
[MATH]
自項独立意味役割同定モデルの出力が最も大きかった意味役割とその値を利用した．
[MATH]
自項独立意味役割同定モデルが各非対象項候補に対して出力した値が最も大きかった意味役割とその値，およびその意味役割と機能語の組み合わせ，その意味役割と項候補を単位とする対象述語からの相対距離との組み合わせを利用した．
本稿で提案する意味役割推定モデルは，与えられた文と述語に対して取り得る全ての意味役割注釈パタンについての尤度を計算し，尤度が最も高い注釈パタンを出力するモデルである．
すなわち，入力文[MATH]と述語[MATH]が与えられた時の意味役割注釈パタン[MATH]の確率[MATH]を最大にする意味役割注釈パタン[MATH]が最終的な出力となる．
注釈パタン[MATH]はフレーム[MATH]，項候補集合[MATH]，項候補-意味役割対応関係[MATH]により一意に決定されるため，式([REF_eqn:rolelabeling0_proposal])右辺[MATH]を以下のように定義した．
本稿では式([REF_eqn:rolelabeling1_proposal])右辺を第1項からそれぞれ，対応付けモデル，項候補獲得モデル，フレーム選択モデルと呼ぶ．
図[REF_fig:flow]に，これらのモデルの概要を示す．
図[REF_fig:flow]中の各モデルについては以下で詳説する．
ただし，項候補獲得モデル中の項候補同定モデル，および対応付けモデル中の自項独立/他項依存意味役割同定モデルの詳細は[REF_sec:outline_proposal]節で述べる．
フレーム選択モデルは与えられた文と述語から，項に付けられる注釈となるべき意味役割が定義された意味フレームを獲得するモデルである．
我々はフレーム選択モデルを，[MATH]が[MATH]の見出し語に含まれる場合に[MATH]を，それ以外で[MATH]を返す関数[MATH]を用い，以下のように定義した．
フレーム選択モデルの例を図[REF_fig:frameselection]に示す．
[t]
{
{ccccc} \multicolumn{2}{r}{バッグ内の[MATH]現金は}{40mm} & \multicolumn{1}{l}{盗ま}{れて}{18mm} \noroleb{いたが，}{18mm} & \multicolumn{2}{l}{願書は}{15mm} \noroleb{無事．
}{15mm}
\multicolumn{5}{c}{[MATH]}
\hline
\multicolumn{5}{|c|}{フレーム選択モデル}
\hline
\multicolumn{5}{c}{[MATH]}
\multicolumn{5}{l}{Theftフレーム[MATH]}
[1mm]
}
項候補獲得モデルは与えられた文と述語およびフレームから，意味役割を注釈付けする項（断片）を獲得するモデルである．
項候補の獲得手法を以下に示す．
[MATH]を構文解析し，[MATH]と直接係り受け関係にある部分木の集合[MATH]を得る．
[MATH]の各要素[MATH]について，形態素ならびに文節の単位で前後に短縮伸長し，項候補の候補（断片候補）[MATH]を生成，断片候補集合[MATH]を得る（断片候補生成）．
[MATH]の各要素[MATH]に関し，[MATH]が[MATH]を越える要素を[MATH]として集め，断片候補集合[MATH]を得る．
尤度[MATH]は項候補同定モデル（[REF_sec:proposal_argument]節）により得られる．
[MATH]の各要素[MATH]について，([REF_enum:foo_cand_proposal])の尤度[MATH]が最大となる[MATH]を[MATH]とし，項候補集合[MATH]を得る．
以上より，我々は項候補獲得モデルを以下のように定義した．
項候補獲得モデルの例を図[REF_fig:candidating]に示す．
我々は，述語項構造における項が文節を基本に構成された語句であると仮定し，構文解析結果に基づいた項候補獲得手法を提案する．
一方，河原らの格フレーム辞書構築の取り組みは，項の意味が表層格で抽象化されて表現されることを根拠とする[CITE]．
また，Baldeweinらは構文情報を用いた項の抽象化手法を提案している[CITE]．
我々の仮定はそれらと同様，項が構文情報によって抽象化できることを前提としている．
本稿で提案した項候補獲得手法では，項候補となるための要件を過不足なく満たす最適な断片候補を獲得するため，述語と直接係り受け関係にある文節から複数の断片候補を生成し，それらを確率モデルを用いて順位付けする．
断片候補生成手法は以下の通りである．
述語と直接係り受け関係にある文節を獲得する
獲得した文節から，それが1つ以上の内容語を含むという前提の下，以下に適合する形態素の列を獲得する
その文節に係る全ての文節に含まれる形態素の列
その文節の先頭から連続する名詞形態素の列
獲得した各形態素列に対して，それが1つ以上の内容語を含むという前提の下，以下の各ル−ルに基づいて断片候補を生成する
[MATH]
文節数を減らさない範囲で先頭から形態素を1つずつ短縮
先頭から文節を1つずつ短縮
末尾文節の範囲で先頭から形態素を1つずつ短縮
[MATH]
文節数を減らさない範囲で末尾から形態素を1つずつ短縮
末尾品詞が「助詞-連体化」の場合に文節数を最大1増加させる範囲で末尾に形態素を1つずつ伸長（ただし，最初に伸長した形態素が名詞の場合は後続形態素を名詞に限定）
対応付けモデルは，与えられた文，述語，フレームならびに項候補から，項候補と意味役割の対応付けを行うモデルである．
項と意味役割の対応付け手法は以下の通りである．
項候補集合[MATH]の各要素[MATH]について，[MATH]に定義された意味役割[MATH]（[MATH]は[MATH]に定義された意味役割の集合）が対応付けられる確率[MATH]を算出する．
[MATH]は自項独立意味役割同定モデル（[REF_sec:proposal_srt_indep]節）により得られる．
[MATH]の各要素[MATH]について，([REF_enum:foo_corr_proposal])の尤度[MATH]を[MATH]とし，[MATH]について重複のないように[MATH]を集めたものを項候補-意味役割対応関係[MATH]とする．
[MATH]の各要素[MATH]について，([REF_enum:bar_corr_proposal])の尤度[MATH]の積が最大となる意味役割対応付け[MATH]を得る．
[MATH]の各要素[MATH]について，[MATH]を考慮した上で意味役割[MATH]が対応付けられる確率[MATH]を算出する．
[MATH]は他項依存意味役割同定モデル（[REF_sec:proposal_srt_dep]節）により得られる．
[MATH]の各要素[MATH]について，([REF_enum:buz_corr_proposal])の尤度[MATH]を[MATH]とし，[MATH]について重複のないように[MATH]を集めたものを[MATH]とする．
以上より，我々は対応付けモデルを以下のように定義した．
対応付けモデルの例を図[REF_fig:corresponding]に示す．
次に，[REF_sec:models_def_proposal]節で定義した意味役割推定モデルを構築する手法について述べる．
本稿で提案する手法は，大きく6つのステップで構成されている．
日本語フレームネットから，意味フレーム定義，意味役割定義，品詞定義，見出し語，ならびに意味役割注釈付き事例を抽出する．
フレーム意味論に反しない2つの仮定の下，抽出した事例から新しい事例を作成する．
以下の仮定は，いかなる事例に適用しても言語的に不自然にならないものとして設定したもので，我々はこれらの仮定を妥当なものと考える．
述語に直接係る主語句（ガ格を末尾に持つ文節の全部分木）を削除しても，他の項の意味役割は変化しない．
文の主辞となる述語の項は削除しても，他の全ての項の意味役割が変化しない解釈が可能．
事例から確率モデルを学習する．
意味役割推定モデルに基づくシステムを構築する．
日本語フレームネットに定義された見出し語が述語の文をコーパスから抽出する．
抽出した文の項の意味役割を推定する．
本手法では，[REF_sec:models_def_proposal]節で定義した意味役割推定モデルのうち，以下の3つのモデルを機械学習により獲得する．
項候補同定モデル（式([REF_eqn:candidating0_proposal])条件[MATH]):
項候補獲得モデルにおいて断片候補が項候補となるかどうかを判定する．
自項独立意味役割同定モデル（式([REF_eqn:corresponding0_proposal])右辺[MATH]):
対応付けモデルにおいて，ある項候補にある意味役割が割り当てられるかを，他項の意味役割を考慮せずに判定する．
他項依存意味役割同定モデル（式([REF_eqn:corresponding2_proposal])右辺[MATH]):
対応付けモデルにおいて，ある項候補にある意味役割が割り当てられるかを，他項の意味役割を考慮した上で判定する．
我々は機械学習に，最大エントロピー法とサポートベクタマシンを用いた．
最大エントロピー法の実装にはツールmaxentを用い，サポートベクタマシンの実装にはTinySVMを用いた．
サポートベクタマシンの出力は，シグモイド関数に代入することで確率値とみなした[CITE]．
なお，構文解析器にはCaboCha [CITE]を用いた．
以下に，各モデルの詳細を述べる．
項候補同定モデルは，断片候補[MATH]が断片すなわち項候補となるかを判定するモデルであり，項候補獲得モデルに定義されている．
項候補同定モデルが定義された式([REF_eqn:candidating0_proposal])には，断片候補が項候補となるための閾値[MATH]が定義されており，最大エントロピー法およびサポートベクタマシンの出力に対する正当性から，今回はそれを[MATH]とした．
学習に必要な正事例には日本語フレームネットから抽出した注釈付き事例を用い，負事例は抽出した事例と正事例を基に以下の2通りの方法を用いて準備した．
[MATH]
はじめに，正事例の正解項候補に対して[REF_sec:models_def_proposal]節・項候補獲得モデル・断片候補生成手法([REF_enum:extend_rule3_proposal])を適用した．
その結果得られた断片候補を不正解項候補とした．
[MATH]
まず，抽出事例で述語に指定されていない全ての動詞に対して，[REF_sec:models_def_proposal]節・項候補獲得モデル・断片候補生成手法([REF_enum:extend_rule1_proposal])〜([REF_enum:extend_rule3_proposal])を適用した．
その結果得られた断片候補のうち，指定述語に対して同様の手順を適用して得られた断片候補および正事例に含まれる正解項候補と範囲が重複しない断片候補を不正解項候補とした．
また，学習には以下の素性を用いた．
[MATH]
対象述語の原形や活用形と，機能語を構成する各形態素の原形や品詞を用いた．
[MATH]
固有表現，未知語，対象述語からの文節を単位とした相対距離，機能語列とそれを構成する各形態素の品詞を用いた．
また，NTT日本語語彙大系から検索した主辞の概念クラスも用いた．
加えて，断片候補の直前に連接する形態素の原形と品詞も利用した．
自項独立意味役割推定モデルは，ある項候補にある意味役割が注釈付けられるかを判定するモデルであり，対応付けモデルに定義されている．
対応付けモデルの定義式([REF_eqn:corresponding0_proposal]) ([REF_eqn:corresponding1_proposal])より明らかなように，本モデルは複数の意味役割候補から一つを選択する多値分類タスクと考えることができる．
我々は機械学習に最大エントロピー法とサポートベクタマシンを用いたが，このうちサポートベクタマシンでは，多値分類にone vs. rest法を用いた．
学習の素性には，項候補同定モデルの学習に用いた素性に加え，以下を利用した．
[MATH]
項候補同定モデルの学習のために対象断片候補から抽出した素性のうち，直前の形態素に関するものを除いた全ての素性を利用した．
加えて，項候補同定モデルが対象項候補に対して出力した値と，項候補を単位とした対象述語からの相対距離も併せて利用した．
[MATH]
項候補同定モデルが非対象項候補に対して出力した値を用いた．
他項依存意味役割同定モデルは，他項に注釈付けられた意味役割を考慮した上で，項候補にある意味役割が注釈付けされるかを判定するモデルであり，対応付けモデルに定義されている．
対応付けモデルの定義式([REF_eqn:corresponding2_proposal])ならびに意味役割推定モデルの定義式([REF_eqn:rolelabeling1_proposal])より明らかなように，本モデルも複数の意味役割候補から一つを選択する多値分類タスクと見なすことができ，自項独立意味役割同定モデル同様，サポートベクタマシンではone vs. rest法を適用した．
学習の素性には，自項独立意味役割同定モデルの学習に用いた素性に加え，以下を利用した．
[MATH]
自項独立意味役割同定モデルの出力が最も大きかった意味役割とその値を利用した．
[MATH]
自項独立意味役割同定モデルが各非対象項候補に対して出力した値が最も大きかった意味役割とその値，およびその意味役割と機能語の組み合わせ，その意味役割と項候補を単位とする対象述語からの相対距離との組み合わせを利用した．
