定義した意味役割推定モデルの有効性を確認するために，獲得したモデルを用いて意味役割推定を行った．
評価に際し，モデルへの入出力にそれぞれ3通りの条件を設定した．
入力条件とその目的は以下の通りである．
文と述語[MATH]システム全体を評価
文と述語，正しい断片候補（項候補の候補）[MATH]項候補獲得モデルを評価
文と述語，正しい項候補[MATH]対応付けモデルを評価
また，出力条件は以下の通りである．
獲得した断片集合[MATH]についての正誤判定を行う．
獲得した項候補-意味役割対応関係[MATH]についての正誤判定を行う．
獲得した[MATH]のうちで，尤度[MATH]が[MATH]を越えるものを出力し正誤判定を行う．
出力条件([REF_enum:metrix5_experiment])は，出力条件([REF_enum:metrix4_experiment])において出力される意味役割注釈パタンのうち，この注釈パタンに含まれるものの意味役割が付与される確率が低い項候補については「項でない」とみなして出力することを意味する．
我々は，以上の9通りの組合せ（入力3条件[MATH]出力3条件）について，機械学習に用いた最大エントロピー法を用いた場合とサポートベクタマシンを用いた場合の2通りで，交差検定法により評価した．
評価実験の対象フレームを表[REF_tbl:domain_experiment]に，実験時に設定した各種パラメータを表[REF_tbl:param_experiment]に示す．
また，評価実験の結果を表[REF_tbl:result_all_experiment_me],[REF_tbl:result_all_experiment_svm]に示す．
評価実験の結果，本手法は(1)意味役割が付与されるべき項が分かっている文に対して精度77％，再現率68％，(2)意味役割が付与されるべき項がわかっていない文に対して精度63％，再現率43％の意味役割推定を実現した．
計490文という少ない注釈付き事例を用いて，大規模な学習事例を用いた英語の意味役割手法に迫る精度を得ることができており，本手法の有効性を示した．
また本手法は，図[REF_fig:samecase_differentrole_discussion]〜[REF_fig:samecase_differentrole_discussion3]のような，表層格では区別できない意味の区別を実現した．
なお，図[REF_fig:samecase_differentrole_discussion1]〜[REF_fig:samecase_differentrole_discussion3]は，同一の表層格を持つ項に対する本手法の意味役割推定を評価するために用意した入力に対する結果である．
[REF_sec:models_def_proposal]節で述べたように，項候補獲得モデルでは，日本語における深層的意味の保持単位が文節にあるとし，構文解析結果に基づいて項候補の獲得を試みた．
結果，精度73％，再現率61％の性能で項候補の獲得に成功した．
また本モデルは，構文解析誤りなどの理由から，述語と直接係り受け関係をもつ部分木が必ずしも項候補とならないことを考慮し，部分木が示す断片候補を短縮および伸長することで新たな断片候補を生成，それらの断片候補群から最適な断片候補を項候補とすることを戦略とした．
結果，図[REF_fig:syn_analyze_discussion0]のような構文解析結果を得た文について，図[REF_fig:candidating_discussion0]に示した項候補の獲得を実現した．
一方，本稿で提案した意味役割推定モデル全体の性能，特に再現率は，本項候補獲得モデルの性能に上限を狭められている．
そのため，項候補獲得モデルの改良により，全体の性能が向上すると考えられる．
以下では，項候補獲得モデルにおける失敗の原因と改善可能性を考察する．
断片候補生成手法の性能は，表[REF_tbl:result_all_experiment_me]の入力条件([REF_enum:metrix0_experiment])([REF_enum:metrix1_experiment])における出力条件([REF_enum:metrix3_experiment])の再現率（正解率）を比較することで推測できる．
具体的には，入力条件([REF_enum:metrix1_experiment])の正解率に対する入力条件([REF_enum:metrix0_experiment])の再現率の低下が，断片候補生成手法に起因した性能低下を表していると考えることができる．
[REF_sec:models_def_proposal]節で述べたように，本稿で提案する断片候補生成手法では，構文解析の結果から，述語文節と直接係り受け関係にある部分木を断片候補生成の基とし（以後，ベース断片候補と呼ぶ），それらを伸縮することで断片候補を生成する．
そのため，断片候補生成手法における性能は，以下の原因で低下する．
構文解析結果が述語と項の意味的な関係を反映していない場合
述語と直接係り受け関係にある部分木が項でない場合
これらの原因に起因する誤りは，表[REF_tbl:cand_discussion]に示す割合で現れた．
表[REF_tbl:cand_discussion]は原因([REF_enum:cand_foo_discussion])ならびに([REF_enum:cand_bar_discussion])の発生率を文単位で算出したものである．
表[REF_tbl:cand_discussion]からも明らかなように，65％の文では構文解析結果に基づく断片生成が適切であった．
しかしながら同時に，本断片候補生成手法が意味役割推定全体の性能の上限に影響していることも明らかとなった．
原因([REF_enum:cand_foo_discussion])による誤りの一つは，構文解析そのものの誤りに起因する．
本稿が提案する断片候補生成手法は，単一のベース断片候補を切断して複数の断片候補を生成することがない．
そのため，構文解析（文節区切りの同定）が誤った例では，適切な断片候補が生成されなかった．
原因([REF_enum:cand_foo_discussion])に起因する誤りには，意味の曖昧性のため，構文解析結果が構文的には正しくても，意味的には誤ってしまったものもある．
図[REF_fig:syn_analyze_discussion3]に示した文の構文解析では，``錨がぶつかるゴンという音がした直後，-0.5zw''が``なった''に係っている．
一方，日本語フレームネットにおいては，この従属節は図[REF_fig:candidating_discussion3]のように対象述語「入っ（て）」の項候補とされている．
すなわち，``錨がぶつかるゴンという音がした直後，-0.5zw''は``入っ（て）''に係っているとされている．
このように，意味を考慮しない構文解析では，文に意味的な曖昧性があり複数の係り先が考えられる場合に，係り受け関係の解析を誤ることがある．
この場合，本稿が提案する断片候補生成手法では適切なベース断片を生成することができず，結果として項候補の獲得に失敗した．
次に，原因([REF_enum:cand_bar_discussion])に起因する誤りについて述べる．
この誤りの代表は，複文における代名詞の省略もしくはゼロ代名詞に起因するものである．
特に，対象述語が後文に属する場合，その項は省略される傾向がある．
このような例においては，省略解析や照応解析を行わない本断片候補生成手法では，適切な断片候補を獲得できなかった．
原因([REF_enum:cand_bar_discussion])に起因する別の誤りには，並列の扱いに起因するものも存在した．
本稿で提案する断片候補生成手法は文節の同格を考慮せず，かつ，ベース断片候補が伸長されても別のベース断片候補と重複することはない．
そのため，対象述語に係っている同格の複数文節を，単一の断片候補として適切に扱うことができなかった．
以上より，本断片候補生成手法は，構文解析そのものを改良することにより性能が向上すると考えられる一方，構文解析結果に基づいて断片を生成する戦略そのものを再考することで，性能が向上する可能性があることが分かった．
加えて，省略解析[CITE]や，文節の並列の考慮などにより，性能が向上する余地があることも明らかとなった．
表[REF_tbl:result_all_experiment_me]の入力条件([REF_enum:metrix1_experiment])・出力条件([REF_enum:metrix3_experiment])の正解率78％は，[REF_sec:models_def_proposal]節で詳述した項候補同定モデル単独の性能を示している．
本手法において項候補同定モデルの性能に寄与する部分は，学習事例準備法，特に負事例の準備法と，学習に用いる素性の選択である．
項候補同定失敗の原因を素性空間で考えると，本来正解であるべき部分空間に負事例が配置されていることが推測される．
これはつまり，負事例の準備法に問題があることを示す．
[REF_sec:models_def_proposal]節・学習事例準備で述べた負事例の準備は，正解項候補の短縮伸長と，非対象述語項の抽出と短縮伸長の2通りの組み合わせで行われているが，これはそれぞれ，以下の2通りの不正解項候補を排除するために設定したものである．
「の機会を」などの切り分けが不適切な断片
対象述語の項ではない断片
このことから，項候補同定モデルが不正解とすべき事例で誤った素性の組み合わせを学習し，結果的に負事例が正解空間にはみ出す形になったと考えられる．
例えば，上述の不正解項候補において，素性値[MATH]が前者の組み合わせに，素性値[MATH]が後者の組み合わせに該当し，素性値[MATH]は双方において正解項候補に特有であるとする．
しかしながら，本稿で提案した項候補同定モデルは上述の2通りの不正解項候補を同時に学習するため，同モデルが推定する素性値[MATH]の不正解らしさが大きくなったと推測する．
つまり，上述の2つの目的に対処する唯一のモデルを学習するのではなく，それぞれの目的に特化した2つのモデルを学習し，意味役割推定に利用する必要があると考える．
次に，項候補同定モデルの学習に用いた素性の有効性を検証する．
素性の有効性は，特定の素性値を除いた残りの素性値でモデルを再学習し，その結果得られたモデルの性能の劣化度を利用するのが一般的である．
しかしながら，多くの素性値から学習したモデルの再学習にはコストがかかる．
また，本手法のように多くのモデルを単一の手法で学習する場合には，有効な素性値をモデル別に検証するのではなく，どのようなモデルにも有効な素性値を多く含む素性の検証を行うことが重要と考えられる．
そこで本稿では，素性の寄与度という新たな評価尺度を導入する．
寄与度の算出方法を図[REF_fig:contalgo]に示す．
図[REF_fig:contalgo]の算出法から明らかなように，寄与度は特定の素性値の有効性ではなく，複数の素性値からなる素性の有効性を表す．
寄与度とは，その素性がどの程度汎用的に有効であるかを表したものであり，寄与度[MATH]とはすなわち，その素性の特定の素性値が全体の30％のモデルで有効であることを示している．
加えて，特定のモデルにのみ有効な素性も同様に重要であることから，寄与度は数値そのものの比較と同時に，寄与度が[MATH]か否かも評価の対象となる．
表[REF_tbl:fenil_feature_discussion]は，サポートベクタマシンを用いて獲得した項候補同定モデルにおける各素性の寄与度である．
表[REF_tbl:fenil_feature_discussion]より，項候補同定モデルでは，項の直前形態素の情報の寄与が強いことが明らかとなった．
このことは，項候補同定モデルが不適切に切り分けられた断片の排除に特に有効に働いていることを示すものである．
また，項候補同定モデルでは，述語と項の位置関係の寄与度が大きいことが明らかとなった．
この素性は，対象の断片が述語の前にあるか後ろにあるかのみを反映するものであり，本来であれば述語項構造の判定に大きな影響は与えないと考えられる．
そこで，述語と断片の位置関係をより詳細に表す素性，例えば構文解析結果に基づく述語・断片間の経路情報などを代替素性として利用することが，性能向上につながると考えられる．
なお，ここで議論した表[REF_tbl:result_all_experiment_me]の入力条件([REF_enum:metrix1_experiment])・出力条件([REF_enum:metrix3_experiment])の正解率78％は「正解を正解と判定する割合」であり，「不正解を不正解と判定する割合」（以後これを偽陽性率と呼ぶ）は含まないため，正確にはこの数字だけで項候補同定モデルの評価をすることはできない．
例えば，正解率が100％に近付くように負事例準備法を調節することで入力条件([REF_enum:metrix1_experiment])における正解項候補の欠落が少なくなることから，対応付け部における性能の上限が上がり，全体の性能が向上して見えると考えられる．
しかし，同時に，意味役割推定モデル全体の評価となる入力条件([REF_enum:metrix0_experiment])での出力条件([REF_enum:metrix3_experiment])において偽陽性率が低くなることが予測され，結果的に誤った項候補が選択されると考えられる．
[REF_sec:models_def_proposal]節で述べたように，対応付けモデルは，与えられた文，述語，フレームおよび項候補から，項候補と意味役割の対応付けを行うモデルである．
結果，正解率72％の性能で，また，尤度が0.5以上のもののみを選択した場合は精度77％，再現率68％で意味役割の対応付けに成功した．
なお，尤度が0.5以上のもののみを選択することによる再現率の低下は最大エントロピー法で2ポイント，SVMで3ポイントに留まっており，精度はそれぞれ6ポイントおよび8ポイント上昇した．
機械学習の特徴を考慮することで，より正確な対応付けが可能となった．
表[REF_tbl:result_all_experiment_me]の入力条件([REF_enum:metrix2_experiment])・出力条件([REF_enum:metrix4_experiment])の正解率72％は，[REF_sec:models_def_proposal]節で述べた自項独立意味役割同定モデルと他項依存意味役割同定モデルの組み合わせの性能を示している．
本手法において，これらのモデルの性能に寄与する部分は，学習に用いる素性の選択である．
\newcounter{tablea}   \newcounter{tableb}  表は，サポートベクタマシンを用いて獲得した自項独立意味役割同定モデルの出力に関し，寄与が大きいと考えられる素性を示したものである．
また，表は，同じくサポートベクタマシンを用いて獲得した他項依存意味役割同定モデルの出力の寄与度を示したものである．
表中の数値は図[REF_fig:contalgo]で述べた手法により算出した．
表から，自項独立意味役割同定モデルでは，項の機能語だけでなく，項の主辞形態素の概念クラスが大きく寄与していることが明らかとなった．
このことは，本稿が提案した対応付けモデルが，項の機能語すなわち表層格では区別できない深層的意味に基づいて意味役割を同定していることを示すものである．
自項独立意味役割同定モデルでは，また，述語文節の機能語の寄与度が強いことが明らかとなった．
これは，態の変化による意味役割の変化を学習できたことを示唆している．
一方，表より，他項依存意味役割同定モデルでは，自項独立意味役割同定モデルによって推定した意味役割に加え，他項の情報が強く寄与していることが明らかとなった．
これは，本研究で提案した対応付けモデルに他項依存意味役割同定モデルを定義したことの有効性を示唆するものである．
また，自項独立意味役割同定モデルと同様に，項の機能語や項の主辞の概念クラス（0.11: 11位），述語文節（0.09: 13位）の寄与度も大きいことが分かった．
次に，[REF_sec:outline_proposal]節・ステップ([REF_enum:boost_proposal])で述べた事例自動作成について考察する．
作成した事例の数を表[REF_tbl:boost_result_discussion]に示す．
また，ステップ([REF_enum:boost_proposal])を実行せずに意味役割推定モデルを獲得，意味役割推定システムを構築した場合の評価実験の結果を表[REF_tbl:result_allnb_experiment_me], [REF_tbl:result_allnb_experiment_svm]に示す．
表[REF_tbl:result_all_experiment_me], [REF_tbl:result_all_experiment_svm]と表[REF_tbl:result_allnb_experiment_me], [REF_tbl:result_allnb_experiment_svm]の比較から，ステップ([REF_enum:boost_proposal])における事例自動生成が項候補獲得部・項候補同定モデルの偽陽性率の向上に貢献していることが明らかとなった．
すなわち，ステップ([REF_enum:boost_proposal])で自動生成された事例が，項候補同定モデルの学習事例，特に負事例の網羅性を向上させ，性能の良いモデルの学習に繋がったと考えられる．
このことからも，ステップ([REF_enum:boost_proposal])における事例自動生成の有効性が明らかとなった．
我々は，機械学習に最大エントロピー法とサポートベクタマシンの2つを用い，それぞれを用いて意味役割推定モデルを獲得した．
結果，意味役割を付与すべき項が分かっていない文に対して，最大エントロピー法を用いた場合は精度63％，再現率43％で意味役割付与を実現，サポートベクタマシンを用いた場合は精度65％，再現率38％で意味役割付与を実現した．
それらの数値を比較した結果として，本論文では，そこに有意な差は見られなかったと結論する．
というのも，最大エントロピー法，サポートベクタマシンの双方にチューニング可能なパラメータが多いほか，素性選択，学習事例準備など，多くのステップで最適解を求める余地が残っていると考えるためである．
一方，評価実験結果および事例自動生成検証結果を考察すると，最大エントロピー法に比べサポートベクタマシンは精度に焦点化しており，特に項候補同定モデルにおいて偽陽性率に関して優れていることが見てとれる．
言い換えれば，サポートベクタマシンは最大エントロピー法と比して，同モデル学習のために準備した負事例の特徴量をよく反映したと考えることができる．
我々は，最大エントロピー法とサポートベクタマシンの双方に，同一の負事例準備法を適用して項候補同定モデルを学習した．
しかしながら以上を考慮すると，採用する機械学習法に応じて負事例の準備の方法を変化させる必要があり，また，モデルの目的に応じて，最適な機械学習法を選択することが必要になると考える．
