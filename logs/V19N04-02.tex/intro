\section{はじめに}

近年，作文技術の習熟度を評定する目的で文章を自動的に評価する技術に対して，需要が高まっている．
大学入試や就職試験等の大規模な学力試験において課される小論文試験の採点や，
e-learning等の電子的な学習システムにおいて
学習者の作文技術についての能力を測るために出題される記述式テストの採点が，例として挙げられる．
このような，多数の文章を同一の基準で迅速に評価する必要があるタスクにおいて，
対象となる全ての文章を人手で評価することは，多くの場合困難を伴う．

第一に，評価に要する時間と労力が問題となる．
記述式回答の評価は，選択式回答の評価に比べて，
評価者が捉えるべき情報と考慮すべき基準が多く，
それらの情報や基準自体も複雑である．

第二に，評価基準の安定性が問題となる．
文章の良悪を決定する基準は，評価者個々において完全に固定的なものではない．
評価する順序による系列的効果や，
ある要素についての評価が他要素の特徴に歪められるハロー効果\cite{NisbettWilson1977}の影響も考えられる．
また，このような状況において他者による評価基準に自基準を合わせる場合，
少なくとも他者との基準の差異についての定量的な情報がない限り，
基準の統合は困難といえる．

これらの問題の存在は，
「個々の評価者が着目する言語的要素」や「評点決定に寄与する各要素の配分（重み）」に相違が生じる要因となり得る．
結果的に，それらの相違が評価者間での評点の差異として表れることも考えられる．

これらに対し，文章評価の自動化は，
評価の公平性を損なう要因となる問題の解消に役立つと考えられる．
また，評価者が着目する言語的要素やその配分の定量的な提示を行うことで，
正確かつ円滑な評価者間の基準統合が可能になると考えられる．

本稿では，単独の評価者により対象文章に与えられる総合的な評点と，
国語教育上扱われる言語的要素についての多種の特徴量から，
任意の試験設定における個人の評価者の文章評価モデルを推定する手法について述べる．
また，個人の評価者の評価モデルにおいて評点決定に寄与する要素毎の配分（重み）について，
他の評価者の評価モデルとの間で定量的に比較可能な形で提示する手法について述べる．
ただし，複数の評価者の評価モデルによる評価から最終的な評価判断を導き出すことについては扱わない．

提案手法は，文章を採点する行為を順序付き多クラス分類として捉え，
Support Vector Regression (SVR) \cite{SmolaSch1998}を用いた回帰手法により，
評価者が付けうる評点を予測する．
SVRの教師データには，表層や使用語彙，構文，文章構造などの特徴に関する様々な素性を用意する．
これらの素性には，日本の国語科教育において扱われる作文の良悪基準に関わる素性が多く含まれる．
なおかつ，全ての素性は，評価対象文章で議論されるトピック固有のものは含まない汎用的なものである．

本手法は，国語教育\footnote{
	本稿では便宜上，小学校，中学校，高等学校における作文教育を国語教育と呼ぶこととする．}
上扱われる言語的要素をSVRの素性に用いて文章評価をモデル化し，
SVRの回帰係数の差として評価者間での評価基準の個人差を明示できるという点に，新規性を持つ．
国語教育上扱われる要素に基づいて文章評価モデルを説明することができるため，
教育指導を行う立場にある評価者が，
普段の指導で参照する要素を介して容易に文章評価モデルを認識，比較することができる．

作文技術についてのあらゆる能力評価に対応可能であるよう，素性を網羅的に設定するが，
「文章を意味面で適切に記述する能力」の評価に関しては扱わない．
ここでいう意味面での適切さとは，文章中の文が示す個々の内容の正しさを指す．
例えば，「月は西から昇る」のような文が示す内容が正しいか正しくないかについての判断は，本研究では扱わない．



