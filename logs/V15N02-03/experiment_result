
正解のアラインメントが付与されている新聞記事の対訳コーパス[CITE]からランダムに500文を選び，これを用いて日英対訳文のアラインメント実験を行なった．
アラインメントの評価単位は，日本語は文字単位，英語は単語単位とした．
日本語の評価単位を単語単位としなかった理由は2つある．
1つは我々の出力と正解データとで形態素解析のずれがある場合があることである．
もう1つは，我々の出力も正解データもアラインメントの単位は句なのだが，そもそも何を句とするかの定義が定まっていないため，句の区切りにずれがあることである．
これらの理由から，評価を単純に，わかりやすくするために，日本語では文字単位で評価した．
なお我々の予備実験により，評価単位を文字単位としても大きな副作用はないことが示されている．
対訳辞書として，研究社の和英辞書（見出し語数36 K，抽出した対訳数214 K）と，同英和辞書（見出し語数50 K，抽出した対訳数303 K）を用いた．
評価は適合率，再現率，F値により算出し，さらにAER [CITE]も求めた．
なお，正解データにはSure([MATH])アラインメントのみが付与されており，Possible([MATH])アラインメントはない[CITE]．
実験結果を表[REF_tab:result_a]に示す．
``baseline''はすべての枝の距離を1とし，さらに整合性スコア[MATH]として実験したものである．
``uniform dist.''は枝の距離はすべて1だが，整合性スコアを[REF_function]章で定義した関数により計算した場合の結果である．
``proposed''は``uniform dist.''の枝の距離を係り受け距離に変更した結果である．
比較実験として，統計翻訳のフリーツールであり，その精度に定評のある``Moses'' [CITE]を利用したアラインメント実験も行なった．
トレーニングデータとして，毎日新聞4万対訳文と読売新聞25万文を利用し，日本語文については形態素解析器JUMANで形態素に分割した．
また[REF_alignment]章で述べた部分文字列アラインメントのみでのアラインメント精度を``sub-string''に示した．
ここでのトレーニングデータは，Mosesと同じものを用いた（ただし，日本語の形態素分割は行っていない）．
``manual''は，我々の出力を人手により修正したものであり，アラインメントの上限値と見ることができる．
上限値が100にならないのは，我々の出力と正解データとのアラインメントの単位にズレがあることや，正解データ自体に誤りが含まれていることがあるためである．
表[REF_tab:result_a]より，距離スコア関数を改善することによりF値で2.7ポイントの精度向上が見られる．
実際の言語現象を観測し，それを反映する関数の定義を用いることの妥当性と，その効果の高さがこの結果から示された．
係り受けスコアを用いることにより，さらに約1.5ポイント精度向上したが，距離スコア改善による向上に比べると差が小さく，係り受けスコアを用いることの利点はそれほどないように見える．
現在は係り受け距離は人手により設定されているが，この設定が実際の言語の特徴を十分に反映しているかどうかという点で疑問が残る．
今後係り受け距離を自動学習などにより適切に設定することにより，係り受け距離を利用する効果がより顕著に表れるものと思われる．
距離スコア関数の改善と，係り受けスコアの利用により，baselineより4.22ポイントの精度向上を達成した．
図[REF_fig:result_ex]に改善例を示す．
例では日本語の``司法''に対して，英語では``judicial''が二度出現しており，曖昧性が発生している．
baselineではこの曖昧性解消に失敗しており，アラインメントが不適切だが，proposedでは正しく曖昧性解消が行われ，正しいアラインメントを得ることができた．
しかしながら，日本語で``司法''という語が一度しか出てきていないため，正確には英語の``our judicial system''は未対応とするのが適切である．
このような省略は逆の場合を含め，しばしば起こることであるため，適切に扱う必要がある．
これについては今後検討する．
我々の提案手法では依存構造を用いており，その情報に強く頼っている部分が大きい．
このことは今まで述べたとおり非常に有効な手段であるが，一方で依存構造解析の失敗が容易にアラインメントの失敗につながってしまう．
日本語については形態素解析(JUMAN)の精度が99%，構文解析(KNP)の精度が90%であり，高精度ではあるが失敗も10%程度は含まれることになる．
英語ではこれよりさらに精度は低くなり，特に並列構造などでの解析失敗が目立つ．
このため，我々が提案する整合性尺度を利用して，依存構造木自体の修正を可能にする枠組を考案する必要がある．
これにより，アラインメントの精度向上が見込めるだけでなく，基礎技術である構文解析技術へのフィードバックを図ることも可能となる．
``Moses''の結果は我々の結果に比べてかなり低い．
これは[REF_Introduction]章で述べたように，統計的な手法が言語構造の異なる言語対に対してはあまり効果が発揮できないことの表れといえる．
日本語と英語では言語構造に大きな違いがあり，例えば日本語ではSOVの語順で文が構成されるが，英語ではSVOの語順で文が構成される．
このような言語対に対しては，我々の手法のように言語処理リソースを用いた深い文解析が必要であると言える．
``sub-string''の結果は``Moses''の結果とほぼ同じであるが，``sub-string''では形態素解析を行っていないという点を考慮すると，十分によい結果であると言える．
特に適合率を見るとMosesよりも良い結果であり，このことは我々のアラインメントで利用するときには有効である．
表[REF_tab:result_b]に，関連研究で示された，日英以外の言語対におけるアラインメント精度を示す．
HLT-NAACL 2003 [CITE]（英語—フランス語と英語—ロシア語）とACL 2005 [CITE]（英語—ロシア語）はそれぞれアラインメントに関するワークショップでの結果であり，それぞれのワークショップでの最も良い精度を記録した研究の値である．
[CITE]は英語と韓国語でのアラインメント精度の向上を目指したものである．
また最も基本的な統計的単語アラインメントツールであるGIZA++ [CITE]を用いてそれぞれの言語対でアラインメントした結果も示す．
すべての値はAERである．
表[REF_tab:result_b]より，英語—フランス語対でのアラインメントは最も容易であり，英語—韓国語で最も難しいといえる．
これは言語構造の違いが英仏では小さいが，英韓では大きいことからくると思われる．
韓国語は日本語に近いといわれており，日英と同様，アラインメントが難しい．
我々の日英アラインメントの結果をこれらの他言語対での結果と比較しても，十分高精度であると言える．
