



\documentstyle[epsf,jnlpbbl]{jnlp_j}

\setcounter{page}{3}
\setcounter{巻数}{2}
\setcounter{号数}{3}
\setcounter{年}{1995}
\setcounter{月}{7}
\受付{1995}{5}{6}
\再受付{1995}{7}{8}
\採録{1995}{9}{10}

\setcounter{secnumdepth}{2}

\title{文末から解析する統計的係り受け解析アルゴリズム}
\author{関根 聡\affiref{NYU} \and 内元 清貴\affiref{CRL} 
  \and 井佐原 均\affiref{CRL}}

\headauthor{関根 聡・内元 清貴・井佐原 均}
\headtitle{文末から解析する統計的係り受け解析アルゴリズム}

\affilabel{NYU}{ニューヨーク大学 コンピュータサイエンス学科}
{Computer Science Department, New York University}
\affilabel{CRL}{郵政省通信総合研究所}
{Communications Research Laboratory, Ministry of Posts and Telecommunications}

\jabstract{
係り受け解析は日本語文解析の基本的な方法として認識されている．
日本語の係り受けは，ほとんどが前方から後方であるため，
解析は文末から文頭の方向へ解析を進める事は効率的であり，
これまでもルールベースの解析手法ではいくつかの提案がある．
また，統計的文解析は英語，日本語等の言語を問わず数多くの提案があり，
その有効性が確認されている．
本論文では，上記の二つの特徴を兼ね備えた日本語文係り受け解析を
提案し，その実験結果を示し，有効性を実証する．
システムの精度は，正しい文節解析ができた所から開始した場合，
京大コーパスを使用した実験で係り受け正解率が87.2\%，
文正解率が40.8\%と高い精度を示している．
ビームサーチのビーム幅を調整した実験では，ビーム幅を小さくする
事による精度の劣化が認められなかった．
実際にビーム幅が1の際に得られた結果の95\%は
ビーム幅20の時の最良の結果と同一であった．
また，N--best文正解率を見た時には，Nが20の時には
78.5\%という非常に高い結果を示している．
解析速度は，解析アルゴリズムから推測される通り，
文節数の2乗に比例し，平均0.03秒(平均文節数10.0)，
最長文である41文節の文に対しては0.29秒で解析を行なった．
}

\jkeywords{係り受け解析，構文解析，統計的手法，最大エントロピー法}

\etitle{Statistical Dependency Analysis using Backward Beam Search}
\eauthor{Satoshi Sekine\affiref{NYU} \and Kiyotaka Uchimoto\affiref{CRL}
  \and Hitoshi Isahara\affiref{CRL}} 

\eabstract{
Dependency analysis is regarded as a standard method
of Japanese syntactic analysis.
As dependencies normally go from left to right,
it is effective to parse from right to left, 
as we can analyze predicates first.
There have been several proposals for such methods 
using rule based parsing.
In this paper, we will propose a Japanese dependency analysis
which combines right to left parsing and a statistical method.
It performs a beam search, an effective way of limiting the
search space for right to left parsing.
We get a dependency accuracy of 87.2\% and 
a sentence accuracy of 40.8\%
using the Kyoto University corpus.
Varying the beam search width,
we observed that the best performances were achieved when
the width is small.
Actually, 95\% of the sentence analyses obtained with
beam width=1 were the same as the best analyses with
beam width=20.
The N--best sentence accuracy for N=20 was 78.5\%.
The analysis speed was proportional to the square of 
the sentence length (number of segments), 
as predicted for the algorithm.
The average analysis time was 0.03 second (average sentence length
was 10.0) and it took 0.29 second to analyze
the longest sentence, which has 41 segments.
}

\ekeywords{dependency analysis, parser, statistical method, maximum entropy}


\begin{document}
\maketitle


\section{最大エントロピー法の利用}

最大エントロピー法(ME)は，トレーニングデータ中の素性の頻度等の
情報から特徴的な素性を学習し，その特徴を生かした確率的なモデルを作成する
方法である．
素性とは，我々の場合，二つの文節間の係り受けの確率を計算するための
情報であり，そこで使用される基本素性には表~\ref{素性}に挙げた種類の素性を
利用した．括弧内の数字は素性値の数である．
\begin{table}[tbh]
\begin{center}
\caption{素性}
\label{素性} 
\begin{tabular}{|l|l|}
\hline
前文節/後文節 & 主辞見出し(2204)，品詞(34)，活用情報(90)，\\
              & 語形情報(218)，助詞の細い情報(135)，      \\
              & 句読点，括弧の情報(31)                    \\
\hline
文節間情報    & 距離(3)，読点，括弧の有無(6)，「は」の有無(2)，\\
              & 前文節と同じ素性を持つ物の有無等(127) \\
              & 後文節と同じ素性を持つ物の有無等(220) \\
\hline
\end{tabular}
\end{center}
\end{table}
また，これらの素性を組合せた組合せの素性も利用した．
その数は約4万個である．
素性の詳細，および素性の選択による比較実験については
\cite{uchimoto:nlken98}を参照されたい．

そして，テストの際には，トレーニングデータを使用して学習されたモデルを基に
テスト文中に与えられた二つの文節の素性から
その二つの文節の係り受けの確率を計算する．
これまでの多くの先行研究と同様にすべての係り受けは独立であると仮定し，
一文全体の係り受け確率を，その文中にあるそれぞれの係り受けの確率の積で表す．
そして，一文全体の確率が最大となるような係り受け関係が正しい係り受け
関係であると仮定する．

\section{解析アルゴリズム}

この章では，解析アルゴリズムを紹介する．
まず，例を利用して，概略を説明し，その後フォーマルな形で
解析アルゴリズムを示す．
特徴は文末から文頭に向けての係り受け解析と
確率を利用したビームサーチにある．
例には以下の入力文を用いる．文節解析まで終っていると仮定しており，
文節の区切は''$|$''で示される．
説明図において，文節の係り先は，
それぞれの文節の下にある番号で示される．
\begin{verbatim}
-----------------------------------------------------------
<初期状態>
ID     1       2       3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
-----------------------------------------------------------
\end{verbatim}
\begin{flushleft}
\underline{解析手順}
\end{flushleft}
\begin{enumerate}
\item[(1)] {\bf 文末から二つ目の文節} \\
  文末の文節は係り先はなく，文末から二つ目の文節は必ず文末の
  文節にかかる．この結果は以下のようになる．
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文末から二つ目まで>
ID     1       2       3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補                                   6        -
-----------------------------------------------------------
\end{verbatim}
\begin{enumerate}
\item[(2)] {\bf 文末から三つ目の文節} \\
  この文節(「作り，」)は，係り先として二つの文節が考えられる．
  一つは「彼女に」であり，もう一つは「贈った」である．
  MEを利用して計算された確率を付与した二つの解析候補を
  作成する．(それぞれの確率は0.1，0.9としてあり，
  各候補の最後には，総合の確率(各係り受けの確率の積)を
  括弧の中に示す．)
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文末から三つ目まで>
ID     1        2      3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補1                          6       6        -    (0.9)
候補2                          5       6        -    (0.1)
-----------------------------------------------------------
\end{verbatim}
\begin{enumerate}
\item[(3)]  {\bf 文末から四つ目の文節} \\
  それぞれの候補に対して，「パイを」の文節の係り先を求める．
  候補1に対しては，非交差の条件から「パイを」の文節は「彼女に」
  の文節に係る事はありえない．したがって「パイを」が「作り，」と
  「贈った」のそれぞれに係る候補を作成する．
  候補2についても同様にする．
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文末から四つ目まで>
ID     1        2      3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補1                  4       6       6        -    (0.54)
候補2                  6       6       6        -    (0.36)
候補3                  4       5       6        -    (0.05)
候補4                  6       5       6        -    (0.04)
候補5                  5       5       6        -    (0.01)
-----------------------------------------------------------
\end{verbatim}
\begin{enumerate}
\item[]
  このように計算していくと，候補の数は文頭に行くにしたがって
  増えていく．しかし，
  解析途中の候補の数に上限を設けて，ビームサーチを行なえば，
  解析候補数の爆発は防げる．
  また，上記の例から直感的に分るように，
  その場合でも解析精度の悪化も少なく抑えられる．
  実際の実験で得られたビーム幅と精度のデータは次章で紹介する．
  例えば，この例でビーム幅を3とすると，候補4と候補5は
  この段階で捨てられ，以降の解析には使用されない．
\item[(4)] {\bf それ以降} \\
      上記で示したような解析を文頭まで繰り返す．
      例えば，ビーム幅を3とした場合の解析結果は以下のようになる．
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文頭まで>
ID     1        2      3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補1  6        4      4       6       6        -    (0.11)
候補2  4        4      6       6       6        -    (0.09)
候補3  6        4      6       5       6        -    (0.05)
-----------------------------------------------------------
\end{verbatim}

以下にフォーマルな解析アルゴリズムを示す．
\begin{verbatim}
----------------------------------------------------------------
Length: 入力文節長
Input[Length]: 入力文
N: ビーム幅
Cand[Length][N]: 解析結果候補 (各文節の係り先文節IDの配列で表される)
             例えばCand[1][1]={6,4,4,6,6,-}．この方法では，必要な
             メモリのサイズは文長とビーム幅の積以上になるが，簡単な
             変換で，上記のサイズに納める事ができる．

add(l,cand) : cand(解析結果候補)の確率がl番目の文節の解析結果候補の
             内のN番目のものより良い場合は，candをCand[l]の解析候補
             に加える．この際，N+1番目の候補になった物は捨てられる．
get(l)      : Cand[l]の候補群から候補を取り出す．候補がなければNULL
             を返す．
ins(i,cand) : iをcandの先頭に追加する．

procedure 係り受け解析 begin

  add(Length-1,{Length,-});

  for(i=Length-2;i>=1;i--) begin

    while((cand = get(i)) != NULL) begin

      for(j=i+1;j<=Length;j++) begin

        if(iからjへの係り受けがcandにおいて有効)

          add(i,ins(j,cand));

        endif
      end
    end
  end
end
----------------------------------------------------------------
\end{verbatim}
このアルゴリズムの解析時間オーダーは，文節数の2乗であり，
ビーム幅をNとすると，ビーム幅に対しNlog(N)であると推測される．

\section{まとめ}

本論文では文末から解析する統計的係り受け解析アルゴリズムを示した．
日本語の係り受けは，ほとんどが前方から後方であるという
特徴を生かし，解析は文末から文頭の方向へ解析を進めるという点と，
色々な提案によって有効性が示されている統計的文解析を利用するという
二つの特徴を兼ね備えた日本語文係り受け解析を提案した．
係り受けの正解率は，正しい文節解析ができた結果から開始した場合，
京大コーパスを使用した実験で係り受け正解率が87.2\%，
文正解率が40.8\%と高い精度を示している．
ビームサーチのビーム幅を調整した実験では，ビーム幅を小さくする
事による精度の劣化が認められなかった．
実際にビーム幅が1の際に得られた結果の95\%は
ビーム幅20の時の最良の結果と同一であった．
また，N--best文正解率を見た時には，Nが20の時には
78.5\%という非常に高い結果を示している．
解析速度は，解析アルゴリズムから推測される2乗程度であり，
平均0.03秒(平均文節数10.0)，
最長文である41文節の文に対しては0.29秒で解析を行なった．

また，他の手法との比較では，共通のベンチマークがない為，
直接的な比較はできなかったが，各手法と同程度か優れた結果が
得られたと判断した．
共通のベンチマークを作る事は，お互いのシステムの
特徴を直接的に比較し，技術の向上を計る為に有意義であると考えられる．
また，今回は，文節切りができている点から解析を開始したが，
そうでなく文からの解析を行なった場合には，評価の方法も
難しくなる．
特に文節切りが正解とシステムが出した結果とで異なる場合には
どのように判断したらよいかスタンダードな方法がない状態である．
協力しあってこのようなスタンダードを決める事は意味があると思われる．


\bibliographystyle{jnlpbbl}
\bibliography{jpaper}

\begin{biography}
\biotitle{略歴}
\bioauthor{関根 聡}{
1987年東京工業大学応用物理学科卒．同年松下電器東京研究所入社．
1990-1992年UMIST，CCL，Visiting Researcher．1992年MSc．
1994年からNew York University，Computer Science Department，
Assistant Research Scientist．1998年PhD．
同年からAssistant Research Professor．
自然言語処理の研究に従事．
情報処理学会，人工知能学会，言語処理学会，ACL会員．
}
\bioauthor{内元 清貴}{
1994年京都大学工学部電気工学第二学科卒業．
1996年同大学院修士課程修了．
同年郵政省通信総合研究所入所，郵政技官．
自然言語処理の研究に従事．
言語処理学会，情報処理学会，各会員．
}
\bioauthor{井佐原 均}{
1978年京都大学工学部電気工学第二学科卒業．1980年同大学院修士課程修了．
工学博士．同年通商産業省電子技術総合研究所入所．1995年郵政省通信総合研究所
関西支所知的機能研究室室長．自然言語処理，機械翻訳の研究に従事．
情報処理学会，言語処理学会，人工知能学会，日本認知科学会，各会員．
}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}

