
提案手法の有効性を確認するため，まず，再現率，すなわち対象の未知語のうち正しく解析できる語の割合の調査を行った．
すべての未知語をタグ付けした大規模なデータを作成するためには大きなコストが必要となることから，本研究では未知語のタイプごとに個別に対象の未知語を含むデータを作成し再現率の調査を行った．
未知語のタイプを限定することで，正規表現等により対象の未知語を含む可能性のある文を絞り込むことができ，効率的にデータを作成できるようになる．
具体的には，検索エンジン基盤TSUBAKI[CITE]で使用されているWebページから，各未知語タイプごとに正規表現を用いて未知語を含む文の候補を収集し，そこから未知語を100個含む文集合を作成し，再現率の評価を行った．
ただし，ここで使用した文集合には[REF_SEC::PRO]節で説明したルール・パターンの作成の際に参考にした文は含まれていない．
結果をUniDic[CITE]によるカバー率とともに表[REF_Table::Recall]に示す．
ここで，UniDicによるカバー率とは対象の未知語100個のうちUniDicに含まれている語の数を表している．
実際にUniDicを用いたシステムにおいて対象の未知語を正しく解析できるかどうかは考慮していないため，UniDicによるカバー率はUniDicを用いたシステムが達成できる再現率の上限とみなせる．
表[REF_Table::Recall]に示した結果から，すべての未知語タイプに対し提案手法は高い再現率を達成できることが確認できる．
連濁を除く未知語タイプにおいてはUniDicによるカバー率よりも高い再現率を達成していることから，考えうる多くの未知語を人手で登録するアプローチに比べ，既知語からの派生ルールと未知オノマトペ認識のためのパターンを用いる提案手法のアプローチは，低コストで多くの未知語に対応できると言える．
一方，連濁により濁音化した語については正しく認識できた語の数はUniDicでカバーされている語の数よりも少なかった．
たとえば以下の文に含まれている「がわら」は正しく認識することができなかった．
\ex{赤がわらの民家です。
}
これは連濁と関係ない表現を連濁により濁音化したものであると認識しないように，連濁により濁音化した形態素のノードに大きなコストを与えているためである．
たとえば以下のような文があった場合，連濁により濁音化した形態素のコストを元の形態素のコストと同程度に設定した場合は「でまわり」を「手回り」が濁音化したものと解析してしまうため，濁音化した形態素のノードには大きめのコストを与える必要がある．
\ex{笑顔でまわりの人たちを幸せにする。
}
続いて，実コーパスにおける再現率の評価を行うため，解析済みブログコーパス[CITE]を用いた評価を行った．
具体的には解析済みブログコーパスで1形態素としてタグ付けされている語のうち，2回以上出現し，かつ，JUMAN5.1の辞書に含まれていない230語を，村脇らによりコーパスから自動生成された辞書[CITE]でカバーされているもの，それ以外でWikipediaにエントリを持つもの，それ以外で提案手法によりカバーされるもの，その他の4つに分類した．
結果を表[REF_Table::Coverage]に示す．
村脇らによる辞書，および，Wikipediaのエントリでもカバーされない未知語のうち異なり数でおよそ30%，出現数でおよそ45%が提案手法により解析できており，提案手法による未知語処理が実コーパスに対しても有用であることが確認できる．
また，提案手法により解析できた未知語には，連濁による濁音化を除くすべての未知語タイプが含まれており，様々な未知語タイプが実コーパスにおいて出現することが確認できた．
本論文で導入したルール・パターンを用いることで新たに認識された未知語の精度，および，解析速度の変化を調べるため，これらのルール・パターンを用いないベースラインモデルと提案手法を用いたモデルを以下の7つの観点から比較することにより提案手法の評価を行った．
本節の実験ではJUMAN5.1をデフォルトのコスト設定のまま使用したものをベースラインモデルとした．
解析結果が変化した100箇所中，解析結果が改善した箇所の数：[MATH]
解析結果が変化した100箇所中，解析結果が悪化した箇所の数：[MATH]
10万文あたりの解析結果が変化した箇所の数：[MATH]
10万文あたりの解析結果が改善した箇所の推定数：[MATH]
10万文あたりの解析結果が悪化した箇所の推定数：[MATH]
形態素ラティスにおけるノードの増加率：[MATH]
解析速度の低下率：[MATH]
実験には検索エンジン基盤TSUBAKI[CITE]で使用されているWebページから収集した10万文を使用した．
これらの文は平仮名を1字以上含み，かつ，全体で20文字以上で構成される文であり，[REF_SEC::PRO]節で説明したルール・パターンの作成の際に参考にした文は含まれていない．
まず，[MATH]と[MATH]を算出するため，各ルール・パターンを用いた場合と用いなかった場合で解析結果が変化した箇所を100箇所抽出し，それらを改善，悪化，その他の3クラスに分類した．
この際，基本的に分割箇所が変化した場合は分割箇所の優劣を比較し，分割箇所に優劣がない場合で品詞が変化した場合はその品詞の優劣を比較した．
ただし，形態素区切りが改善した場合であっても，名詞であるべき品詞が副詞となっている場合など，明らかに正しい解析と言えない場合はその他に分類した．
たとえば「面白がれる」という表現は，JUMANでは子音動詞の可能形は可能動詞として登録されていることから，JUMANの辞書登録基準では1語となるべきである．
しかし，連濁ルールを用いなかった場合は下記の例([REF_EX::OMOSHIRO])aのように，連濁ルールを用いた場合は下記の例([REF_EX::OMOSHIRO])bのように，解析結果は異なるものの，いずれの場合も過分割されてしまうことから，このような場合はその他に分類した．
\ex
\ex面/白/が/れ/る\ex面/白/がれる
また，[MATH]，および，[MATH]は，10万文あたりの解析結果が変化した箇所の数[MATH]を用いて，それぞれ以下の式により算出した．
P^{*}_{100kS} & = D_{100kS} \times P_{100D}/100\notag
N^{*}_{100kS} & = D_{100kS} \times N_{100D}/100\notag
ここで，各未知語タイプごとに推定誤差は異なっていることに注意が必要である．
特に解析が悪化した箇所の数は少なことから[MATH]の推定誤差は大きいと考えられる．
しかしながら，各未知語タイプごとに大規模な評価を行うコストは大きいことから本論文では上記の式から算出された推定数に基づいて考察を行う．
解析精度の評価に加えて，最適解の探索時間に影響を与えると考えられることから形態素ラティスにおけるノードの増加率[MATH]，および，全体の解析速度への影響を調べるため速度の低下率[MATH]の計測も行った．
これらの評価結果を表[REF_Table::ResultAll]に示す．
表[REF_Table::ResultAll]に示す結果から提案手法を用いることで，ほとんど解析結果を悪化させることなく，また，解析速度を大きく下げることなく，多くの未知語を正しく処理できるようになることが確認できる．
具体的には，すべてのルール・パターンを用いることで10万文あたり4,500個以上の未知語処理が改善するのに対し，悪化する解析は80個程度であると推定でき，速度の低下率は6.2%であった．
速度の低下率に関してはベースラインとした形態素解析器の実装に大きく依存するため，具体的な数値に大きな意味はないと言えるものの，少なくとも提案手法は大幅な速度低下は引き起こさないと考えられる．
また，ノードの増加率に対し解析速度の低下率が大きいことから，速度低下は最適パスの探索ではなく，主に形態素ラティスの生成の時間の増加により引き起されていると考えられる．
以下ではルール・パターンごとの解析の変化について詳述する．
表[REF_Table::ResultAll]に示したとおり，連濁パターンを導入した場合，新たに正しく解析できるような表現がある一方で，解析結果が悪化する表現が長音文字や小書き文字の置換・挿入ルールと比べ多く存在する．
これは，長音文字や小書き文字を含む形態素はもともと非常に少ないのに対し，濁音を含む形態素は多く存在しているため，濁音が含まれているからといって連濁による濁音化であるケースが限定的であるためと考えられる．
表[REF_Table::Rendaku]に連濁ルールを導入することにより解析結果が変化した例を示す．
解析結果の変化を示した表において`/'は形態素区切りを，太字は解析結果が正解と一致していることを表す．
「はさみ」が濁音化した形態素「ばさみ」や「ためし」が濁音化した形態素「だめし」など正しく認識できるようになった表現がある一方で，本来，格助詞「が」と形容詞「ない」から構成される「がない」という文字列を「かない」が濁音化した表現であると誤って解析されてしまうような表現が8例存在した．
このような例を改善するためには，連濁化に関する静的な情報を活用して連濁処理の対象を制限することが考えられる．
たとえばUniDicには連濁によって濁音化する語の情報が登録されておりこれを利用することが考えられる．
長音文字を置換するルールを導入することで解析結果が変化した例を表[REF_Table::MacronR]に示す．
もともと正しく解析できていた表現がルールを導入することにより解析できなくなった例は存在せず，周辺の解析結果が悪化したものが「OKだよ〜ん」の1例のみ存在した．
この例ではいずれも形態素区切りは誤っているものの，ベースラインモデルでは「だ」を判定詞であると解析できていたものが，提案手法を用いた場合は普通名詞であると解析されたため，解析結果が悪化したと判定した．
小書き文字を置換するルールを導入することで解析結果が変化した例を表[REF_Table::KogakiR]に示す．
長音記号の場合と同様にもともと正しく解析できていた表現がルールを導入することにより解析できなくなった例は存在せず，周辺の解析結果が悪化したものが「ゆみぃの布団」の1例のみ存在した．
この例でベースラインモデルでは格助詞であると正しく解析できていた「の」が，「いの」という地名の一部であると解析されたため，解析結果が悪化したと判定した．
また，小書き文字を置換するルールを導入することで解析結果が改善した箇所の推定数は10万文あたり1,374箇所であり，全未知語タイプの中でもっとも多く，ほぼ悪影響もないことから，非常に有用なルールであると言える．
挿入されたと考えられる長音文字を削除するルールを導入することで解析結果が変化した例を表[REF_Table::MacronI]に示す．
長音文字の挿入に対処することで解析が悪化した例は存在せず，「苦〜い」や「ぜーんぶ」など多くの表現が正しく解析できるようになった．
長音文字を削除するルールを導入することで解析結果が改善した箇所の推定数は10万文あたり1,093箇所であり，小書き文字の置換ルールに次いで多かった．
解析結果が悪化した事例は確認できなかったことから，非常に有用性の高いルールであると言える．
挿入されたと考えられる小書き文字を削除するルールを導入することで解析結果が変化した例を表[REF_Table::KogakiI]に示す．
長音文字の挿入の場合と同様に小書き文字に対処することで解析が悪化した例は存在せず，「さぁん」や「でしたぁぁぁ」など小書き文字の挿入を含む表現が正しく解析できるようになった．
反復型オノマトペの認識パターンを導入することで解析結果が変化した例を表[REF_Table::OnoR]に示す．
解析結果に変化があった100箇所中，感動詞の反復である「あらあら」と「うんうん」の2例は誤ってオノマトペであると解析されたものであったが，この2例以外には解析が悪化した事例はなかった．
反復型オノマトペの認識パターンを導入することで解析結果が改善した箇所の推定数は10万文あたり860箇所であり，小書き文字の置換ルール，長音文字の削除ルールに次いで多かった．
非反復型オノマトペの認識パターンを導入することで解析結果が変化した例を表[REF_Table::OnoP]に示す．
解析結果が悪化した例は存在せず，「のっちょり」などのように本来オノマトペではない表現を誤ってオノマトペであると解析した例は存在したが，それらはいずれもベースライン手法でも正しく解析できない表現であった．
また，非反復型オノマトペの処理を行うことによる速度の低下は確認できなかった．
生成される形態素ラティスのノード数の増加率が0.008%にとどまっていることから，正しいオノマトペ以外にはほとんどパターンに該当する文字列が存在しなかったためであると考えられる．
