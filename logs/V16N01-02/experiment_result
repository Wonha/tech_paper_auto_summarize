2つの提案手法，つまり，
式([REF_式：n-gram確率の比])の値の推定を手法1で行う判別手法(Hypo1)，
式([REF_式：n-gram確率の比])の値の推定を手法2で行う判別手法(Hypo2)
を用いた母語話者性判別実験を行った．
また，
藤井らの手法で使用する言語モデルを[MATH]-gramに拡張した手法(Skew)，
青木らの手法(KL)
による母語話者性判別を行い，提案手法との比較を行った．
実験データは以下の2種類を用意した．
データ1
電気情報関係の国際会議で発表された英語科学技術論文．
内訳は，
英語圏（米国，英国，カナダ，オーストラリア）で開催された採択率50%未満の国際会議の論文で，第一著者が英語圏所属の非日本人名である論文602件，
東／東南アジアで開催された採択率50%以上の国際会議の論文で，第一著者が日本所属の日本人名の論文679件
である．
擬似的に，前者を母語話者文書集合，後者を非母語話者文書集合とした．
なお，母語話者文書集合／非母語話者文書集合における品詞列の出現頻度情報の信頼度がほぼ同一となるように，両文書集合中の延べ単語数（下記の前処理後の単語数）がほぼ同数になるように文書数を設定した．
データ2
電気情報関係の国際会議で発表された英語科学技術論文で，校正専門家（母語話者）が母語話者性を判定したもの60件（母語話者文書25件，非母語話者文書35件）．
これは，[CITE]で使用されている評価用論文と同一のものである．
なお，論文の収集に際しては，両文書集合に母語話者／非母語話者以外の特徴の差が現れないように注意を払った．
すなわち，複数の研究分野から論文を収集し，図表や数式，ヘッダやフッタなどの情報を削除するという前処理を行った．
単語列から品詞列への変換にはTree Taggerを用いた．
変換後の品詞異なり数は57であった（文頭，文末の特殊記号[MATH]，[MATH]を除く）．
データ1に付与された母語話者性（[MATH]/[MATH]の別）はかなり精度は高いものの，勿論誤りを含む．
そこで，参考としてデータ2をテストデータ（判別対象文書）とした実験（評価実験2）も行った．
データ数が少ないため，各手法に対して有意な差は期待できないが，データ1での結果と同様の傾向が見られるかどうかを調べた．
各手法の評価は，以下の2つの精度
Prec(N) &= \frac{母語話者文書で母語話者文書と判別された文書数} {母語話者文書と判別された文書数}
[4mm] Prec(\NN) &= \frac{非母語話者文書で非母語話者文書と判別された文書数} {非母語話者文書と判別された文書数}
のうち値の低い方（これをMinPrecと表記する）を用いて評価する．
これは，本手法の目的が，母語話者文書および非母語話者文書をともに高精度で収集することにあるからである．
以下のようにして，各手法の精度をデータ1を用いて10交差検定(10-fold cross validation)[CITE]で求める．
データ1の母語話者文書集合を[MATH]と10ブロックに分割する．
同様にデータ1の非母語話者文書集合を[MATH]と10ブロックに分割する．
各[MATH]に対して，以下を行う．
各[MATH]に対して，
[MATH]を除く8ブロックの母語話者文書を母語話者言語モデルの学習データ，[MATH]を除く8ブロックの非母語話者文書を非母語話者言語モデルの学習データとして，[MATH]の各文書の母語話者性を判別し，MinPrecが最大となるメタパラメタの値を求める．
上記で求めたメタパラメタの値（9個）の平均値をメタパラメタの値として設定し，[MATH]を除く9ブロックの母語話者文書を母語話者言語モデルの学習データ，[MATH]を除く9ブロックの非母語話者文書を非母語話者言語モデルの学習データとして，[MATH]の各文書の母語話者性を判別する．
上記(b)で求めた母語話者性判別結果より，精度を求める．
なお，各手法におけるメタパラメタは，手法Hypo1とHypo2では有意水準[MATH]，手法Skewでは式([REF_Skew:α])の[MATH]，手法KLでは式([REF_式：Sibun加算スムージング])の加算項[MATH]である．
上記(2)の(a)での各[MATH]に対するMinPrecが最大となるメタパラメタの値は，
\alpha &\in{0.01,\; 0.03,\; 0.05,\; 0.07,\; 0.09,\; 0.11}　(Hypo 1, 2)
\beta &\in{0.01,\; 0.02,\;\cdots,\;0.15}　(Skew)
\delta &\in{1\times10^{-7},\; 3\times10^{-7},\; 5\times10^{-7},\; 1\times10^{-6},\; 3\times10^{-6},\; \cdots,\; 5\times10^{-4}}　(KL)
の範囲で求めた．
以下のようにして，データ1を学習データ，データ2をテストデータとした場合の各手法の精度を求める．
データ1の母語話者文書集合を[MATH]と10ブロックに分割する．
同様にデータ1の非母語話者文書集合を[MATH]と10ブロックに分割する．
各[MATH]に対して，
[MATH]を除く9ブロックの母語話者文書を母語話者言語モデルの学習データ，[MATH]を除く9ブロックの非母語話者文書を非母語話者言語モデルの学習データとして，[MATH]の各文書の母語話者性を判別し，MinPrecが最大となるメタパラメタの値を求める．
上記で求めたメタパラメタの値（10個）の平均値をメタパラメタの値として設定し，データ1の全母語話者文書を母語話者言語モデルの学習データ，データ1の全非母語話者文書を非母語話者言語モデルの学習データとして，データ2の各文書の母語話者性を判別し，精度を求める．
上記(2)でのMinPrecが最大となるメタパラメタ値は前節と同様の範囲で求めた．
[MATH]なる品詞[MATH]-gramを言語モデルとした場合の2つの評価実験の結果を表[REF_実験結果]に示す．
表には，MinPrecだけでなく，参考のため，Prec(N)，Prec(NN)も挙げている．
また，『未定』の判定になった数を挙げている．
手法Skewのみ未定があるが，これは，条件部の品詞列の学習データにおける頻度が高い品詞[MATH]-gram分布が存在し，用いた計算機の精度では式([REF_Skew:α])の値が1となり，その結果[MATH]も[MATH]も[MATH]となってしまったことによる．
評価実験1では，各手法とも，[MATH]でMinPrecが最も高い．
手法Skewは，[MATH]の設定式([REF_Skew:α])が最適とは限らないことを述べたが，それでも，[MATH]の場合は[MATH]の場合より精度が1%向上しており，このことからも，条件部の長い品詞[MATH]-gramモデルを言語モデルとすることの有効性が分かる．
提案手法では，Hypo2の[MATH]の場合のMinPrecが最も高く，[MATH]である．
一方，従来手法では，Skewの[MATH]の場合のMinPrecが最も高く，[MATH]である．
2つの二項母集団の母比率の差の検定[CITE]を行うと，有意水準約8 %で有意差があることが示せ，AICに基づく2つの二項母集団の母比率の差の検定[CITE]でも有意差が示せる．
2つの提案手法Hypo1とHypo2の比較では，同一の[MATH]に対するMinPrecはHypo2の方が概ね高い．
特に，[MATH]ではその差は大きく，[MATH]-gram確率に関して，母語話者／非母語話者文書間で有意な差がない場合に，[MATH]なる[MATH]-gram確率を利用して式([REF_式：n-gram確率の比])を推定する効果が現れていることが分かる．
評価実験2でも，各手法とも[MATH]でMinPrecが最も高く，そのうち，Hypo2のMinPrecが最も高い．
また，Hypo1とHypo2における同一の[MATH]に対するMinPrecはHypo2の方が概ね高い．
評価実験2では使用したテスト文書数が少ないため，信頼性のある結果とは言えないが，このように評価実験1とある程度同様の傾向が現れていることが分かる．
