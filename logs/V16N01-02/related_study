関連研究
\label{節：関連研究}

文書の母語話者性の判別と関連の深い研究分野として，文書の記述言語を推定す
る言語識別がある．

Cavnar らは，出現頻度上位の文字列とその順位を言語および文書の特徴と考え
る言語識別を行っている\cite{cavnar}．
各言語 $L_i$ の学習データ文書中での 1〜5 の長さの文字列のうち出現頻度上
位 300 個の文字列とその順位を求めて，言語 $L_i$ における順位表を作成し
ておく．同様に，識別対象文書 $d$ に対しても順位表を作成する．$d$ の順位
表中の各文字列の順位と $L_i$ の順位表での順位との差の絶対値の和を
$d$ と $L_i$ の非類似度 $dissim(d,L_i)$ と考え，$dissim(d,L)$ が最小の
言語 $L$を $d$ の記述言語として識別する．これは，前節で述べた枠組みに
対して，$dissim(d,L_i)$ の逆数を尤度 $Lh(d,L_i)$ と考えたことに相当する．

また，前田らは，長さ2の文字列の出現頻度分布をユークリッド空間上の
ベクトル（頻度ベクトル）であると考え，識別対象文書 $d$ の頻度ベクトルと
各言語 $L_i$ の学習データ文書の頻度ベクトルとの余弦を，
$d$ と言語 $L_i$ の類似度 $sim(d,L_i)$ とする言語識別を行っている\cite{前田}．
これは，前節で述べた枠組みに対して，
$sim(d,L_i)$ を尤度 $Lh(d,L_i)$ と考えたことに相当する．

行野らは，長い文字列の頻度は統計的な揺らぎが大きいものの，言語を特定する
能力が高いと考え，1〜7 の長さの文字列を言語および文書の特徴と考える言語
識別の手法を提案している\cite{行野}．彼らの手法は，識別対象文書 $d$ に出
現する 1〜7 の長さの文字列集合と言語 $L_i$ の学習データに出現
する 1〜7 の長さの文
字列集合の積集合の大きさを $Lh(d,L_i)$ とする手法である．長い文字列を特徴
として使用した結果，類似言語間の識別や識別対象文書が極めて短い場合の識別
でも，Cavanr らの手法，前田らの手法に比べ高い識別精度を実現したと報告している．

Dunning は文字 $n$-gram モデルにより $P_{L_i}(d)$ を求め，
言語の事前確率を等確率($P(L_i)=P(L_j)$)と仮定して，ベイズ識別に
より，$d$ の属す言語の識別を行っている\cite{dunning}．
ただし，ゼロ頻度問題に対処するため，
加算スムージングによる $n$-gram 確率のスムージングを行っている．
$n=1\sim 5$ を試した結果，$n=2$ の場合，
つまり，bi-gram モデルの場合が最も識別精度が高かったと報告している．

Sibun らは，長さ $n$ の文字列の確率分布を言語および文書の特徴と考え（実
際には $n=1$ または $n=2$ を採用している），
確率分布間の相違尺度である KL-Divergence に基づいた言語識別手法を提案
している\cite{sibun}．
確率分布 $P$ と $Q$ の KL-Divergence（Kullback-Leibler 距離）
$D_{KL}(P||Q)$ は
\[
 D_{KL}(P||Q)=\sum_{x\in{\cal X}} P(x)\log \frac{P(x)}{Q(x)}
\]
で定義される\cite{確率的言語モデルテキスト}．Sibun らの手法は，
$D_{KL}(P_d||P_{L_i})$ が最小の $L_i$ を $d$ の記述言語として識別す
る手法である．ただし，
$P_d(\vec{a})$ は文書 $d$ における文字列 $\vec{a}$ の生起確率 ，
$P_{L_i}(\vec{a})$ は言語クラス $L_i$ における文字列 $\vec{a}$ の生起確
率である．
$P_d(\vec{a})$ は
\[
 P_d(\vec{a})=\gamma\cdot f_d(\vec{a})
 \qquad \text{ただし，}
 \gamma=\frac{1}
       {\sum_{\svec{a}\in A^n}f_d(\vec{a})}
\]
と推定されるので（$f_d(\vec{a})$ は $d$ での文字列 $\vec{a}$ の出現頻度，
$A$ は記号の全体集合，$A^n$ は可能な $n$ 長さの文字列
の全体の集合），言語 $L_i$ における文書 $d$ の生起確率 $P_{L_i}(d)$ を
\begin{equation}\label{式：文書の生起確率の大胆な近似}
 P_{L_i}(d)=\prod_{\svec{a}\in A^n} P_{L_i}(\vec{a})^{f_d(\vec{a})}
\end{equation}
と大胆に近似するならば，
\[
 D_{KL}(P_d||P_{L_i})
 = \sum_{\svec{a}\in A^n} P_d(\vec{a}) \log \frac{P_d(\vec{a})}
                                                   {P_{L_i}(\vec{a})}
 = -\gamma\cdot\log P_{L_i}(d)+
         \sum_{\svec{a}\in A^n} P_d(\vec{a}) \log P_d(\vec{a})
\]
となる．つまり，$D_{KL}(P_d||P_{L_i})$ が最小の $L_i$ を $d$ の記述
言語として識別する Sibun らの手法は，
式(\ref{式：文書の生起確率の大胆な近似})の近似を行った上で，
言語の事前確率を等確率と仮定して，ベイズ識別により，
$d$ の属す言語の識別を行うことと等価である．
なお，Sibun らもゼロ頻度問題に対処するために，$P_{L_i}(\vec{a})$ は
\begin{equation}\label{式：Sibun加算スムージング}
P_{L_i}(\vec{a})=\frac{f_{L_i}(\vec{a})+\delta}
                      {\sum_{\svec{a}\in A^n} \{f_{L_i}(\vec{a})+\delta\}}
\end{equation}
のように，加算スムージングによりスムージングしている
（$\delta$ は非負の定数）．

次に，本論文で扱う文書の母語話者性判別に関する従来研究について述べる．

Tomokiyo らは，長さ $n$ ($n=1,2,3$)の記号列（記号として
は，単語，品詞，および単語品詞混合の3種を試している）を言語および
文書の特徴と考え，文書（あるいは，文書を構成する単語をその品詞に置き換えた
もの，文書を構成する一部の単語を品詞に置き換えたもの）の生起確率を
式(\ref{式：文書の生起確率の大胆な近似})で近似し，ベイズ識別に基づく
母語話者／非母語話者クラスの判別を行っている\cite{Tomokiyo}．
しかし，彼らは，子
供用ニュース記事の音読による発話や観光などに関する自発的発話を，音声認
識器によりテキストにした文書，および，人手で書き起こした文書を対象として
いる．音読では読み間違いが非母語話者の大きな特徴であり，自発的発話では，
使用語彙が母語話者／非母語話者の間の大きな違いである．一方，我々は，論文
などのように十分推敲して作成されているフォーマルな文書を対象としており，
母語話者／非母語話者判別に有効な特徴量も異なってくるため，彼らの判別
実験結果と直接比較することはできない．

藤井らは，品詞 tri-gram モデルを言語モデルとし，ゼロ頻度問題に対処できる
Skew Divergence を用いて英文書の母語話者性の判別を行っている\cite{藤井}．
以下で定義される判別対象文書 $d$ と言語クラス $C$（$\in\{N,\NN\}$,
$N$: 母語話者言語クラス，$\NN$: 非母語話者言語クラス）との相違度
$ED(d\:;\:C)$ 
\[
   ED(d\:;\:C)=\sum_{\tuple{ab}\in H^2}
                  f_d(ab)D(P_d^\tuple{ab}\:||\:P_C^\tuple{ab})
\]
を求め，$ED(d\:;\:C)$ を最小にする $C(\in\{N,\NN\})$ を $d$ が属すクラ
スとして推定する．ただし，$H$ は品詞の全体集合，
$P_d^\tuple{ab}$ は文書 $d$ における条件を $ab$ とする品詞 tri-gram 
分布，$P_C^\tuple{ab}$ はクラス $C$ における条件を $ab$ とする品詞 tri-gram 
分布\footnote{
つまり，$P_d^\tuple{ab}(x)$ は文書 $d$ において，
品詞列 $ab$ の次に品詞 $x$ が生起する確率 $P_d(x|ab)$，
$P_C^\tuple{ab}(x)$ は言語クラス $C$ において，
品詞列 $ab$ の次に品詞 $x$ が生起する確率 $P_C(x|ab)$である．
}，$D$ は確率分布間の相違度である．確率分布間の相違度 $D$ として KL Divergence 
を用いた場合，$ED(d\:;\:C)$ を最小にする $C(\in\{N,\NN\})$ は，文書 $d$ 
の各単語をその品詞で置き換えた品詞列の生起確率を最大にする言語クラスであ
る．したがって藤井らの手法は，品詞 tri-gram モデルを言語モデル
とし，言語の事前確率を等確率と仮定して，Bayes 識別
に基づいて $d$ が属すクラスを判定する方法と本質的には同じである．
藤井らの手法の特徴は，分布間の相違度 $D$ として KL Divergenceを用
いるのではなく，以下で定義される Skew Divergence \cite{Lee} を用いている
点にある．
\[
 D_{skew}(p\:||\:q)
  =\sum_{x\in {\cal X}} p(x)\log\frac{p(x)}{\alpha\cdot q(x)+(1-\alpha)\cdot p(x)}
\]
Skew Divergence はゼロ頻度問題に弱い KL Divergence を改良したものである．
藤井らは，$\alpha$ を，分布 $q$（つまり，
$P_N^\tuple{ab}$，$P_{\NN}^\tuple{ab}$）の推定に用いた学習データのサイズに応じて，$ab$ 毎に
\begin{equation}\label{Skew:α}
\alpha(ab)=1-\exp\left( -\sqrt{\beta\cdot \min(f_N(ab),f_{\NN}(ab))} \right)
\end{equation}
と設定している．彼らは，Skew Divergence を用いることで，線
形補間を施した品詞 tri-gram 分布による KL Divergence を用いた手法
および多くの識別問題で高い精度を実現している Support Vector Machine を用
いた手法よりも有意に高い判別精度を実現できたと報告している．

英文書の母語話者性判別は，母語話者英語，非母語話者英語という類似した言語の
識別問題と捉えることもできる．
青木らは，文書を，それを構成する単語を品詞で置き換えた品詞列と見なし，
基本的には KL-Divergence を用いた Sibun らの言語識別手法に基づいて，
文書の母語話者性の判別を行っている\cite{青木}．
「長い文字列も言語特徴とすることで類似言語の識別精度が向上する」と
いう行野らの知見
からの予想通り，長い品詞列の頻度情報を利用した場合の判別精度が高く（
$n=6$ のときが最も精度が高い），藤井らの手法より高精度で母語話者性を判別
できたと報告している．

著者らは，青木らの主張と同じく，長い品詞列の頻度情報も利用すること
が文書の母語話者性判別に有効であると考えている．
藤井らの手法は言語モデルを $n>3$ の品詞 $n$-gram モデルとしてもそ
のまま適用できる．しかし，藤井らは，式 (\ref{Skew:α})を
\begin{itemize}
\item $\alpha$ は $f=\min(f_N(ab),f_{\NN}(ab))$ の単調増加関数，
\item $\lim_{f\rightarrow\infty} \alpha =1$，
      $\lim_{f\rightarrow 0} \alpha =0$
\end{itemize}
を満たす $\alpha$ の設定法の一例として用いたに過ぎず，$n$ を大きくした
場合に，式 (\ref{Skew:α}) で良いのかどうかは疑問である．さらに，
$n$ を大きくしたとき，式 (\ref{Skew:α})では高い精度が得られない
場合に，式 (\ref{Skew:α})に代えて，上記の性質を満たす
$f=\min(f_N(ab),f_{\NN}(ab))$ のどのような関数を $\alpha$ の
設定に用いればよいのかも明らかではない．
一方，青木らの手法は，統計的パターン認識の立場で見るならば，
近似式(\ref{式：文書の生起確率の大胆な近似})を仮定したベイズ識別による
判別法である．しかし，品詞 $n$-gram モデルに比べ，
式(\ref{式：文書の生起確率の大胆な近似})は，近似としては非常に粗い．

$n$が大きな品詞 $n$-gram モデルを言語モデルとして使用し，かつ，
ゼロ頻度問題およびスパースネスの問題を克服する新たな
母語話者性判別手法を次節で述べる．


