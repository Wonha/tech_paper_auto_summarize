本研究で扱う母語話者性の判別問題は，文書[MATH]が属すクラスの識別問題の一種である．
本節では，文書が属すクラスの識別の枠組みについて，その一般論を述べておく．
文書が属す可能性のあるクラスとして，[MATH]があるとする．
文書[MATH]がクラス[MATH]に属す文書である尤もらしさ（尤度）[MATH]を何らかの方法で設定し，[MATH]が最大の[MATH]，つまり，
を文書[MATH]が属すクラスとして識別する．
文書[MATH]のどのような構成要素（特徴）を用いて[MATH]をどのように定義するかにより，どのようなクラスの識別ができるか，および，その識別精度が異なって来る．
次節で述べる言語識別，本論文で扱う母語話者性の判別の他，ジャンルの識別，著者識別，さらに迷惑メールの判別(spam filter)もこの枠組みで議論することができる．
文書[MATH]の属すクラスが[MATH]である尤度[MATH]を[MATH]が与えられたときのクラス[MATH]の事後確率[MATH]とし，文書[MATH]の属すクラスを，
と推定することもできる．
これは，統計的パターン認識で用いられる事後確率最大化識別（ベイズ識別）[CITE]である．
文書[MATH]の生起確率を[MATH]，クラス[MATH]での[MATH]の生起確率（クラス[MATH]に属す文書が生起するときにその文書が[MATH]である条件付き確率）を[MATH]，クラス[MATH]に属す文書の生起確率（[MATH]の事前確率）を[MATH]とすると，上記の事後確率[MATH]は
と表せるので，式([REF_式：ベイズ識別1])は，
と等しい．
適当な統計的言語モデルを設定し，各クラス[MATH]の文書集合（[MATH]の学習データ）を用いて，[MATH]の言語モデルのパラメタを推定すれば，式([REF_式：ベイズ識別2])を用いて[MATH]が属すクラスの識別をすることができる．
代表的な統計的言語モデルとして，[MATH]-gramモデルがある．
一般に，ある時点で生起する事象の確率が，その直前の[MATH]個の時点で生起した事象だけの影響を受けるとき，これを[MATH]重マルコフ過程と呼び，[MATH]-gramモデルは，記号の生起を[MATH]重マルコフ過程で近似したモデルである[CITE]．
特に，[MATH]の場合をuni-gramモデル，[MATH]の場合をbi-gramモデル，[MATH]の場合をtri-gramモデルと呼ぶ．
[MATH]-gramモデルでは，記号列[MATH]の生起確率は，
で表される．
ただし，[MATH]のとき[MATH]であり，[MATH]は文頭を表す特殊記号である．
また，[MATH]であり，[MATH]は文末を表す特殊記号である．
記号としては，文字，単語，品詞などが考えられる．
本論文では，記号が文字であるものを文字[MATH]-gramモデル，記号が品詞であるものを品詞[MATH]-gramモデルと呼ぶことにする．
条件付き確率[MATH]は[MATH]-gram確率と呼ばれる．
本論文では，言語クラス[MATH]の[MATH]-gram確率を[MATH]と添え字を付けて表す．
学習データの生起確率を最大にするようにモデルのパラメタを推定する最尤推定[CITE]では，[MATH]は
すなわち，
と推定される．
[MATH]は言語クラス[MATH]の学習データにおける記号列[MATH]の出現頻度であり，[MATH]は記号の全体集合である．
しかし，[MATH]が大きい場合，[MATH]-gram確率を単純に式([REF_式：n-gram確率の最尤推定値])により推定すると，学習データ中に出現しない記号列[MATH]に対して，[MATH]を0と推定してしまうという大きな問題がある．
また，たとえ学習データ中に出現したとしても，条件部の記号列[MATH]の出現頻度が小さい場合は，統計的に信頼性のある確率値を推定するのが難しい．
前者はゼロ頻度問題，後者はスパースネスの問題と呼ばれている[CITE]．
したがって，これらの問題に対処するために，通常は[MATH]-gram確率のスムージングを行う．
代表的なスムージング手法としては，加算スムージング，線形補間などがある[CITE]．
一般に，線形補間の方が加算スムージングより精度が高いと言われている．
また，多くの識別問題で高い性能を実現している2クラスの識別器であるSupport Vector Machine[CITE]を使って，文書[MATH]の属すクラスを識別することもできる．
本論文で提案する母語話者性判別手法は，長い品詞列の頻度情報を利用することで，より高精度で判別を行うことをねらったもので，長い品詞列の頻度情報を使うことによる信頼性の低下を防ぐために仮説検定を利用しているのが大きな特徴である．
藤井らおよび青木らの研究と同じく，文書をそれを構成する単語を品詞で置き換えた品詞列とみなす．
品詞[MATH]-gramモデルを言語モデルとし，文書内の各文が独立に生起すると仮定すると，品詞列に変換した文書[MATH]のクラス[MATH]での生起確率[MATH]は，
と表せる．
ただし，[MATH]は文（品詞列）[MATH]の長さであり，[MATH]は[MATH]の[MATH]番目の品詞である．
また，[MATH]のとき[MATH]であり，[MATH]である（[REF_節：文書クラス識別の枠組み]節参照）．
Bayes識別に基づく文書[MATH]の母語話者性判別では，母語話者文書と非母語話者文書の事前確率を[MATH]とすると，
と判別することになる．
生起確率の比の対数を取り，文書（品詞列）の生起確率を式([REF_式：文書の生起確率])を用いて展開すると，
となる．
上式が正ならば[MATH]は母語話者文書，負ならば[MATH]は非母語話者文書と判別することになる．
より大きな[MATH]における品詞[MATH]-gramモデルは，母語話者英語と非母語話者英語における品詞列の生起確率の相違をより良く取り扱うことができると予想される．
しかし，現実的なサイズの学習データから最尤推定により求めた品詞[MATH]-gram確率による
では，この値が1から大きくずれる場合に，これが両言語の大きな相違を示しているのか，統計的な揺らぎに起因するものかが分からない（ゼロ頻度問題，スパースネスの問題）．
そこで，式([REF_式：n-gram確率の比])を仮説検定に基づいた以下に述べる2種類の手法により控えめに（最尤推定値を用いた場合の比より1に近い値として）推定し，これを用いて式([REF_判別式])の計算を行い母語話者性の判別を行う．
手法1では，式([REF_式：n-gram確率の比])の値を以下のようにして推定する．
ただし，[MATH]を[MATH]の最尤推定値とする．
[MATH]の場合
なる有意水準[MATH]の検定において，帰無仮説を棄却できる最大の[MATH]を求め，[MATH]ならば[MATH]-gram確率の比([REF_式：n-gram確率の比])を[MATH]と推定し，[MATH]（つまり，[MATH]が[MATH]より有意に大きいと言えない）ならば1と推定する．
[MATH]を言語クラス[MATH] ([MATH])のモデルの学習データにおける品詞列[MATH]の出現頻度とすると，上記の[MATH]は，
x &= f_N(a_{i-n+1}\cdots a_{i-2} a_{i-1} a_i), & y &= f_(a_{i-n+1}\cdots a_{i-2} a_{i-1} a_i),
m &= f_N(a_{i-n+1}\cdots a_{i-2} a_{i-1}), & n &= f_(a_{i-n+1}\cdots a_{i-2} a_{i-1})
として，付録[REF_付録：estimateMu]の[MATH]で求めることができる．
[MATH]の場合
なる有意水準[MATH]の検定において，帰無仮説を棄却できる最大の[MATH]を求め，[MATH]ならば[MATH]-gram確率の比([REF_式：n-gram確率の比])を[MATH]と推定し，[MATH]（つまり，[MATH]が[MATH]より有意に小さいと言えない）ならば1と推定する．
このような[MATH]は，[MATH], [MATH], [MATH], [MATH]を前述(A)のように定めると，[MATH]として求めることができる．
[MATH]の場合[MATH]-gram確率の比([REF_式：n-gram確率の比])を1と推定する．
つまり，頻度情報の統計的揺らぎを考慮し，[MATH]の信頼度で，[MATH]-gram確率の比([REF_式：n-gram確率の比])を控えめに（最尤推定値を用いた場合の比より1に近い値として）推定する．
一方の[MATH]-gram確率が他方より有意に大きいと言えない場合，両[MATH]-gram確率に大きな違いはないということで，この[MATH]-gram確率の比を1と推定し，母語話者性判別に影響しないようにする．
表[REF_表：n-gram確率の比の推定例]に[MATH]-gram確率の比の推定例を示す（有意水準[MATH]）．
例(a)は頻度が小さいため有意水準0.05で一方の[MATH]-gram確率が他方の[MATH]-gram確率より大きいと判断できない場合で，比を1と推定している．
例(b)〜(e)は最尤推定値を用いた場合より1に近い値を推定している（つまり，スパースネスの問題に対処できている）．
例(f)(g)は，最尤推定値を用いると[MATH]-gram確率の比がそれぞれ[MATH]，[MATH]となってしまう場合であるが，有意水準0.05での推定では0より大きな有限の値となっており，母語話者性の判別に決定的な影響を与えることを避けている（つまり，ゼロ頻度問題にも対処できている）．
手法2は，手法1を拡張し，[MATH]-gram確率の比([REF_式：n-gram確率の比])の推定において，有意水準[MATH]では両言語モデルにおける[MATH]-gram確率の一方が他方より有意に大きいと判断できない場合に，[MATH]の[MATH]-gram確率の比の推定値を用いるものである．
[MATH]
以下の3つの場合に応じて，
を推定する．
[MATH]の場合
なる有意水準[MATH]の検定において，帰無仮説を棄却できる最大の[MATH]を求め，[MATH]ならば[MATH]-gram確率の比([REF_式：n-gram確率の比（手法2）])を[MATH]と推定し，[MATH]ならば1と推定する．
[MATH]の場合
なる有意水準[MATH]の検定において，帰無仮説を棄却できる最大の[MATH]を求め，[MATH]ならば[MATH]-gram確率の比([REF_式：n-gram確率の比（手法2）])を[MATH]と推定し，[MATH]ならば1と推定する．
[MATH]の場合[MATH]-gram確率の比([REF_式：n-gram確率の比（手法2）])を1と推定する．
推定した[MATH]-gram確率の比([REF_式：n-gram確率の比（手法2）])が1で，かつ，[MATH]ならば，[MATH]として([REF_手法2繰り返し])へ．
そうでないならば，この推定値を式([REF_式：n-gram確率の比])の推定値とする．
