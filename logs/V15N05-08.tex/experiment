\section{評価実験}

\subsection{設定}
\label{sec:experimental_settings}

我々はトーナメントモデル，CCアルゴリズム\shortcite{Kudo:2002}，SRアルゴリズム\shortcite{Sassano:2004}，
CLEアルゴリズム\shortcite{McDonald:2005b}をSVMを用いて実装し，
係り受け正解率と文正解率を京大コーパスVersion 4.0を用いて評価した．
係り受け正解率とは係り先文節を正しく同定できた文節の割合であり，
文正解率とは文中の全ての文節の係り先を正しく同定できた文の割合である．
係り受け正解率は各文の末尾の文節（係り先を持たない）を除いて計算する\footnote{
	多くの先行研究で用いられている基準である．}．
また，一文節からなる文は本実験では一切使用しておらず，
以下の文数も一文節からなる文を除いた数である．

1月1日〜1月8日分の記事（7,587文）を訓練データとし，
1月9日分（1,213文），1月10日分（1,479文），1月15日分（1,179文）の記事をそれぞれテストデータとした．
二値分類器としてはTinySVM\footnote{
	http:\slash\slash{}chasen.org\slash\~{}taku\slash{}software\slash{}TinySVM\slash}を用いた．以下のすべての実験・手法において，多くの先行研究と同じく三次の多項式カーネルを使用し，誤分類のコストは1.0とした．
すべての実験はDual Core Xeon 3GHz x 2のLinux上で行った．


\subsection{使用した素性}

使用した素性を表\ref{tbl_features}に示す．
文節の主辞とは，文節の形態素のうち品詞が特殊・助詞・接尾辞以外の形
態素のうち最も右側のもの，語形とは品詞が特殊以外の
形態素のうち最も右側のものである．
また，文節の子文節とは，その文節に係っている文節のこととする．
なお，トーナメントモデルは同時に候補を二つ見るため，候補に関する素性は
それぞれの候補について別々に作成する．
標準素性と追加素性は颯々野\shortcite{Sassano:2004}の用いたのとほぼ同じものを使用した．
格助詞素性は，ある格要素がすでに埋まっているかどうかを認識させ，
「複数のヲ格が単一の文節に係ることはない」といった現象を
学習させることを意図したものである．

ある動的素性が使用できるかは解析アルゴリズムに依存する．
たとえば表\ref{tbl_features}の素性の中では格助詞素性のみが動的素性であるが，この格助詞素性は
トーナメントモデルにおいて文末から文頭に向かって係り先を決定していく解析アルゴリズムでは
「候補の全ての子文節」とは候補の子文節のうち係り元より右側にあるものに限られる．
SRアルゴリズムでも同様に，係り元より右側にあるものに限られる．
CCアルゴリズムでは片側に限られるということはないものの，候補から遠い子文節については未解析である
場合がある．
またCLEアルゴリズムではすべての係り関係を独立と考える都合上，動的素性は使用できない．


\begin{table}[b]
\caption{使用した素性}
\begin{center}
\input{08table03.txt}
\end{center}
\label{tbl_features}
\end{table}



\subsection{解析精度}
\label{sec:exp_acc}

\begin{table}[b]
\caption{訓練データ（7,587文）による係り受け正解率／文正解率[\%]}
\label{tbl_accuracy}
\begin{center}
\input{08table04.txt}
\end{center}
\end{table} 

解析精度を表\ref{tbl_accuracy}に示す．
係り受け正解率に関するマクネマー検定($p < 0.01$)によると，
トーナメントモデルは，素性セット：全素性，テストデータ：1月10日分のSRアルゴリズム($p = 0.083$)および
CCアルゴリズム($p = 0.099$)以外の全ての条件で他の手法より優位であった．
テストデータ：1月9日分に対して報告されている最高の係り受け正解率は
颯々野\shortcite{Sassano:2004}の89.56\%であるが\footnote{
	この結果は京大コーパスVersion 4.0ではなくVersion 2.0を用いた実験の結果である．
	また，用いた素性も我々のものとは異なる．}，
トーナメントモデルはこの係り受け正解率を上回っている．
ただし，颯々野の実験の出力が手元にないためにマクネマー検定の代わりに
符号検定($p < 0.01$)を行ったところ，この差は有意ではなかった($p = 0.097$)．



追加素性と格助詞素性の有無による精度の差に注目すると，
トーナメントモデルは他のモデルより精度差が小さいことが分かる．
このことは単に「元の精度が高い方が大幅な精度向上が難しい」と解釈できるが，
「トーナメントモデルは他の手法よりモデル自身で周辺情報を多くとらえられている」とも解釈できる．
なお，素性の追加による係り受け正解率の向上に関しては，テストデータ：1月9日分のトーナメントモデルのみ有意ではなかった($p = 0.25$)．
また結果からは，同じ素性を用いたときSRアルゴリズムとCCアルゴリズムの精度がほぼ同じということも分かる．
だがこの結果は両アルゴリズムの能力が同程度ということを示しているわけではなく，
解析順が違えば使用できる動的素性も異なるため，各アルゴリズムに最適な素性を使ったときの
能力には差が出る可能性がある．

 
\subsection{解析時間と訓練事例の規模}

各方式において全素性を使用し，テストデータ：1月9日分全体を解析するのに要した時間と，
訓練事例の規模を表\ref{tbl_speed}に示す．
ステップ数とは，SVM classifyの実行回数である．


\begin{table}[b]
\caption{解析時間と訓練事例の規模}
\begin{center}
\input{08table05.txt}
\end{center}
\label{tbl_speed}
\end{table}

時間計算量はトーナメントモデルとCCアルゴリズムが$O(n^2)$，
SRアルゴリズムが$O(n)$である．
結果からはSRアルゴリズムが最も高速でCCアルゴリズムもそれに準ずる速度，
トーナメントモデルはSRアルゴリズムの4倍以上の時間がかかっていることがわかる．
ステップ数でみるとトーナメントモデルはSRアルゴリズムの1.7倍程度であるのに
解析時間では4倍以上の差が開く理由は，トーナメントモデルは訓練事例数の規模が大きく
SVMモデルが巨大になるためアクションの決定に時間がかかるからである．


\subsection{解析順等の精度への影響}

\ref{sec:parsing_algorithm}節において，トーナメントモデルには係り先の同定順，トーナメントの組み方，
非交差制約の考慮に関して自由度があると述べた．
そこで，これらの自由度および動的素性である格助詞素性の有無に関して実験を行った．
その解析精度を表\ref{tbl:variation}に示す．
なお，唯一の動的素性である格助詞素性を使用せず非交差制約も仮定しない場合，各係り元文節の係り先の同定は独立となるので，同定順は解析結果に影響を与えない．
精度の変化は多くの場合0.1\%程度と小さいが，係り受け正解率に関しては一貫して格助詞素性あり，同定順：右から左，
トーナメント：右から左，非交差制約：ありという設定が最もよい．
また，格助詞素性を使用することでほとんどの場合精度が向上しているが，向上幅はそれほど大きくない．

\begin{table}[b]
\caption{解析順等を変化させたときの係り受け正解率／文正解率[\%]}
\label{tbl:variation}
\begin{center}
\input{08table06.txt}
\end{center}
\end{table}

なお，動的素性である格助詞素性を使用しているため，トーナメントの組み方と非交差制約の考慮の有無を
変更する場合には同一のモデルを共用できるが，同定順の変更はモデルの再学習を必要とする．
なぜなら，解析時に有効な係り先候補の子文節は，同定順が左から右の場合には係り元より左にあって候補に
係っている文節に限られ，同定順が右から左の場合は係り元より右にある子文節に限られるので，
訓練事例生成時には格助詞素性における子文節をそのように制限する必要があるからである．





\subsection{相対モデルとの比較}

我々は相対モデルを実装していないため，京大コーパスVersion 3.0を使い，
工藤ら\shortcite{Kudo:2005j}と実験設定を合わせた実験を行った．
ただし素性は統一していない．
訓練データは1月1日〜1月11日分の記事と1月〜8月分の社説（24,263文），
テストデータは1月14日〜1月17日分の記事と10〜12月分の社説（9,287文）である．
工藤ら\shortcite{Kudo:2005j}は誤分類のコストをディベロップメントデータを用いて調整しているが，
本実験ではしておらずすべての実験・手法において1.0に固定した．
また，本実験の解析順等は\ref{sec:exp_acc}節の実験と同じく，同定順：右から左，トーナメント：左から右，非交差制約：ありとした．
係り受け正解率の計算法は上の実験と同じだが，文正解率は工藤ら\shortcite{Kudo:2005j}の基準に合わせ，
一文節からなる文であっても計算に含めた．

\begin{table}[t]
\caption{工藤ら(2005)との比較実験の係り受け正解率／文正解率[\%] }
\begin{center}
\input{08table07.txt}
\end{center}
\label{tbl_accuracy_kudo05}
\end{table} 

結果を表\ref{tbl_accuracy_kudo05}に示す．
工藤ら\shortcite{Kudo:2005j}の実験と本実験では使用した素性が異なるので直接的な比較はできないが，
唯一両方の素性で実験されているCCアルゴリズムの結果を比較すると
我々の素性の方が優れているように見える．
係り受け正解率に関するマクネマー検定($p < 0.01$)によると，トーナメントモデルはSRアルゴリズムおよび
CCアルゴリズムに対して優位である．
相対モデルに関しては出力が手元にないのでマクネマー検定は行えないが，
係り受け正解率に関する符号検定($p < 0.01$)によるとトーナメントモデルは
相対モデル\shortcite{Kudo:2005j}より優位であった．
一方，トーナメントモデルは「組み合わせ」モデル\shortcite{Kudo:2005j}を係り受け正解率において
上回っているものの，符号検定によるとその差は有意ではなかった($p = 0.014$)\footnote{
	「組み合わせ」モデルとは，CCアルゴリズムが近距離の係り受け関係に，
	相対モデルが遠距離の係り受け関係に強いことに着目し，係り関係の距離に基づいて両手法を
	使い分けるモデルである．
	距離の閾値はディベロップメントセットを用いて3と決めている．
	しかしながらトーナメントモデルの解析精度はCCアルゴリズムと比較して近距離・遠距離ともに上回っているため，
	このようなアドホックな組み合わせは不要と思われる．}．



ただし，工藤ら\shortcite{Kudo:2005j}の実験で用いているlog-linearモデルはSVMに比べて訓練時間が短いが，
精度の面では不利といえる．というのは，SVMは多項式カーネルによって組み合わせ素性が
自動的に考慮されるが，log-linearモデルは明示的に組み合わせ素性を導入する必要があるからである．
 



