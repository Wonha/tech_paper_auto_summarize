最大エントロピー法の利用

最大エントロピー法(ME)は，トレーニングデータ中の素性の頻度等の
情報から特徴的な素性を学習し，その特徴を生かした確率的なモデルを作成する
方法である．
素性とは，我々の場合，二つの文節間の係り受けの確率を計算するための
情報であり，そこで使用される基本素性には表~\ref{素性}に挙げた種類の素性を
利用した．括弧内の数字は素性値の数である．
\begin{table}[tbh]
\begin{center}
\caption{素性}
\label{素性} 
\begin{tabular}{|l|l|}
\hline
前文節/後文節 & 主辞見出し(2204)，品詞(34)，活用情報(90)，\\
              & 語形情報(218)，助詞の細い情報(135)，      \\
              & 句読点，括弧の情報(31)                    \\
\hline
文節間情報    & 距離(3)，読点，括弧の有無(6)，「は」の有無(2)，\\
              & 前文節と同じ素性を持つ物の有無等(127) \\
              & 後文節と同じ素性を持つ物の有無等(220) \\
\hline
\end{tabular}
\end{center}
\end{table}
また，これらの素性を組合せた組合せの素性も利用した．
その数は約4万個である．
素性の詳細，および素性の選択による比較実験については
\cite{uchimoto:nlken98}を参照されたい．

そして，テストの際には，トレーニングデータを使用して学習されたモデルを基に
テスト文中に与えられた二つの文節の素性から
その二つの文節の係り受けの確率を計算する．
これまでの多くの先行研究と同様にすべての係り受けは独立であると仮定し，
一文全体の係り受け確率を，その文中にあるそれぞれの係り受けの確率の積で表す．
そして，一文全体の確率が最大となるような係り受け関係が正しい係り受け
関係であると仮定する．

解析アルゴリズム

この章では，解析アルゴリズムを紹介する．
まず，例を利用して，概略を説明し，その後フォーマルな形で
解析アルゴリズムを示す．
特徴は文末から文頭に向けての係り受け解析と
確率を利用したビームサーチにある．
例には以下の入力文を用いる．文節解析まで終っていると仮定しており，
文節の区切は''$|$''で示される．
説明図において，文節の係り先は，
それぞれの文節の下にある番号で示される．
\begin{verbatim}
-----------------------------------------------------------
<初期状態>
ID     1       2       3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
-----------------------------------------------------------
\end{verbatim}
\begin{flushleft}
\underline{解析手順}
\end{flushleft}
\begin{enumerate}
\item[(1)] {\bf 文末から二つ目の文節} \\
  文末の文節は係り先はなく，文末から二つ目の文節は必ず文末の
  文節にかかる．この結果は以下のようになる．
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文末から二つ目まで>
ID     1       2       3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補                                   6        -
-----------------------------------------------------------
\end{verbatim}
\begin{enumerate}
\item[(2)] {\bf 文末から三つ目の文節} \\
  この文節(「作り，」)は，係り先として二つの文節が考えられる．
  一つは「彼女に」であり，もう一つは「贈った」である．
  MEを利用して計算された確率を付与した二つの解析候補を
  作成する．(それぞれの確率は0.1，0.9としてあり，
  各候補の最後には，総合の確率(各係り受けの確率の積)を
  括弧の中に示す．)
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文末から三つ目まで>
ID     1        2      3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補1                          6       6        -    (0.9)
候補2                          5       6        -    (0.1)
-----------------------------------------------------------
\end{verbatim}
\begin{enumerate}
\item[(3)]  {\bf 文末から四つ目の文節} \\
  それぞれの候補に対して，「パイを」の文節の係り先を求める．
  候補1に対しては，非交差の条件から「パイを」の文節は「彼女に」
  の文節に係る事はありえない．したがって「パイを」が「作り，」と
  「贈った」のそれぞれに係る候補を作成する．
  候補2についても同様にする．
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文末から四つ目まで>
ID     1        2      3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補1                  4       6       6        -    (0.54)
候補2                  6       6       6        -    (0.36)
候補3                  4       5       6        -    (0.05)
候補4                  6       5       6        -    (0.04)
候補5                  5       5       6        -    (0.01)
-----------------------------------------------------------
\end{verbatim}
\begin{enumerate}
\item[]
  このように計算していくと，候補の数は文頭に行くにしたがって
  増えていく．しかし，
  解析途中の候補の数に上限を設けて，ビームサーチを行なえば，
  解析候補数の爆発は防げる．
  また，上記の例から直感的に分るように，
  その場合でも解析精度の悪化も少なく抑えられる．
  実際の実験で得られたビーム幅と精度のデータは次章で紹介する．
  例えば，この例でビーム幅を3とすると，候補4と候補5は
  この段階で捨てられ，以降の解析には使用されない．
\item[(4)] {\bf それ以降} \\
      上記で示したような解析を文頭まで繰り返す．
      例えば，ビーム幅を3とした場合の解析結果は以下のようになる．
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文頭まで>
ID     1        2      3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補1  6        4      4       6       6        -    (0.11)
候補2  4        4      6       6       6        -    (0.09)
候補3  6        4      6       5       6        -    (0.05)
-----------------------------------------------------------
\end{verbatim}

以下にフォーマルな解析アルゴリズムを示す．
\begin{verbatim}
----------------------------------------------------------------
Length: 入力文節長
Input[Length]: 入力文
N: ビーム幅
Cand[Length][N]: 解析結果候補 (各文節の係り先文節IDの配列で表される)
             例えばCand[1][1]={6,4,4,6,6,-}．この方法では，必要な
             メモリのサイズは文長とビーム幅の積以上になるが，簡単な
             変換で，上記のサイズに納める事ができる．

add(l,cand) : cand(解析結果候補)の確率がl番目の文節の解析結果候補の
             内のN番目のものより良い場合は，candをCand[l]の解析候補
             に加える．この際，N+1番目の候補になった物は捨てられる．
get(l)      : Cand[l]の候補群から候補を取り出す．候補がなければNULL
             を返す．
ins(i,cand) : iをcandの先頭に追加する．

procedure 係り受け解析 begin

  add(Length-1,{Length,-});

  for(i=Length-2;i>=1;i--) begin

    while((cand = get(i)) != NULL) begin

      for(j=i+1;j<=Length;j++) begin

        if(iからjへの係り受けがcandにおいて有効)

          add(i,ins(j,cand));

        endif
      end
    end
  end
end
----------------------------------------------------------------
\end{verbatim}
このアルゴリズムの解析時間オーダーは，文節数の2乗であり，
ビーム幅をNとすると，ビーム幅に対しNlog(N)であると推測される．

