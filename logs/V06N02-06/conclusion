本研究では，毎日新聞記事データベースを用いた過去の記事による言語モデルのタスクへの適応化と抽出した定型表現を用い，N-gram言語モデルを構築する方法を検討した．
まず言語モデルのタスクへの適応化については，実験の結果，6カ月前の数日間の記事より直前の数日間の記事で適応化した方がパープレキシティが小さくなった．
このことは言語モデルがジャンルだけでなく時間にも依存するものであることを示すものである．
ただ，適応化サンプルの量を多くするほどパープレキシティが小さくなる傾向があり，N-gramベースでの言語モデルを少量サンプルで適応化させることは限界があると考えられる．
次に定型表現を抽出し，これを用いたN-gram言語モデルを構築した．
定型表現を用いた言語モデルを作成することで，bigramモデルに関しては，テストデータに対し約3割程度パープレキシティを低く押えるとこができ，言語モデルの有効性を示すことができた．
しかし，trigramではトレーニングデータの量が不十分だったため，トレーニングデータでは効果があったがテストデータに対しては効果が得られなかった．
トレーニングデータの量をもっと増やし，本方法の有効性を調べる必要がある．
また，本研究では言語モデルの有効性をパープレキシティで評価したが，実際の音声認識で確認する必要がある[CITE]．
なお，NHKのニュース原稿に対する経時変化の適応化や定型表現の導入による言語モデルに関しては文献[CITE]を参照されたい．
