================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[2638] 最後に新聞テキストには，使用頻度の高い(特殊)表現や，固定的な言い回しなどの表現(以下，定型表現と呼ぶ)が多いことに注目し，複数形態素から成る定型表現を抽出し，これを1形態素として捉えた上で，N-gram言語モデルを構築する方法を検討し，有用性を示す．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[2323] 評価実験の結果，長さ2および3以下である定型表現を1形態素化してbigram, trigram言語モデルを作成することで，bigramに関しては，エントロピーが小さくなり，言語モデルとして有効であることを示す．

================================================================
[section type  : experiment_result]
[section title : 言語モデルの評価基準]
================================================================
[2119] 本研究では大規模コーパスが利用可能な新聞の読み上げ音声の認識のための精度の良い言語モデルの構築を実験的に検討した．
-----------------------------------------------------
  [subsection title : エントロピーとパープレキシティ]
-----------------------------------------------------
  [1800] エントロピーとパープレキシティは共に，対象とする文集合の複雑さを定量的に示す指標で，その文集合が複雑なほど，それぞれの値は大きくなる．
-----------------------------------------------------
  [subsection title : 補正パープレキシティ]
-----------------------------------------------------
  [1599] そこで評価テキスト中に出現した未知語の種類[MATH]と，未知語の出現回数[MATH]を用いてパープレキシティを補正する[CITE]．

================================================================
[section type  : proposed_method]
[section title : 言語モデルの適応化]
================================================================
[2119] 本研究では大規模コーパスが利用可能な新聞の読み上げ音声の認識のための精度の良い言語モデルの構築を実験的に検討した．
-----------------------------------------------------
  [subsection title : 面種別での学習と評価]
-----------------------------------------------------
  [2584] 全面種で学習した言語モデルと面種別で学習した言語モデルをテストデータの(補正)パープレキシティで比較すると，形態素数5000のbigramでの比較とは逆に，面種別で学習した言語モデルより全面種で学習した言語モデルの方が，(補正)パープレキシティが小さく，面種別で学習した言語モデルを使用するより，全面種で学習した言語モデルを使用する方がよいという結論が得られた．
-----------------------------------------------------
  [subsection title : 適応化法]
-----------------------------------------------------
  [2003] 実験手順としては，{[MATH]}1形態素数20000の標準言語モデル(trigram)を構築し，{[MATH]}2標準言語モデルを事前モデルとして，面種別の適応化サンプルでターゲットタスクの言語モデルをMAP推定し，{[MATH]}3テストデータのパープレキシティを求める．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [1935] 通常，直前の数百単語をキャッシュとして用いて適応化する方法が効果があると言われているが[CITE]，これよりも大量の直前データを用いる方が効果があるということである[CITE]．
-----------------------------------------------------
  [subsection title : 固有名詞の適応化]
-----------------------------------------------------
  [1814] 追加する固有名詞の数を制限しない場合は，適応化サンプルが多いほどカバー率が高くなるのは当然だが，固有名詞の数を制限した場合でも，10日間より30日間の適応化サンプルを用いた方が，カバー率は少し高くなる．

================================================================
[section type  : proposed_method]
[section title : 定型表現]
================================================================
[2357] 新聞テキスト文には，定型表現が多いことに着目し，これらの高頻出定型表現を1形態素として捉えた上で，言語モデルを構築すれば，より精度の良いモデルが出来ると考られる．
-----------------------------------------------------
  [subsection title : 標準言語モデル]
-----------------------------------------------------
  [1780] 標準言語モデルは，表[REF_base]に示した全面種の学習用データから作成した表[REF_tbl:pp_bi_20k]のモデルを用いる．
-----------------------------------------------------
  [subsection title : 定型表現を用いた言語モデル]
-----------------------------------------------------
  [2044] 登録されなかった定型表現が多数あるので，これは未知語の数を増やすだけなので図[REF_bun]のようにもとの形態素に分解しておく．
-----------------------------------------------------
  [subsection title : 評価実験]
-----------------------------------------------------
  [2302] 同じパラメータ数(bigram)でもパープレキシティが小さいモデルが構築できたことは，これを大語彙連続音声認識の第1パスに使用すると認識率の向上に繋がると考えられる．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[2138] 本研究では，毎日新聞記事データベースを用いた過去の記事による言語モデルのタスクへの適応化と抽出した定型表現を用い，N-gram言語モデルを構築する方法を検討した．

