 
 まずタスクについて注目する．
 言語モデルをN-gram\mbox{ベースで構築する場合(ルールベースで}記述するのとは異
 なり)，大量の学習データが必要となる．最近では各種データベースが幅広く
 構築され，言語モデルの作成に新聞記事などの大規模なデータベー
 スを利用した研究が行なわれている \cite{test6}．
 しかし N-gram はタスクに依存するので
 タスクに関する大量のデータベースを用いて構築される必要がある．
 例えば，観光案内対話タスクを想定し，既存の大量の言語データに
 特定タスクの言語データを少量混合することによって，
 N-gram言語モデルの性能の改善が行なわれている \cite{test7}．
 また，複数のトピックに関する言語モデルの線形補間で適応化する方法が
 試みられている\cite{test8}．
 本研究ではタスクへの適応化のために，同一ジャンルの過去の
 記事を用いる方法とその有効性を示す．

 次に言語モデルの経時変化について注目する．例えば新聞記事などでは話題が経
 時的に変化し，新しい固有名詞が短期的に集中的に出現する場合が多い．
 以前の研究では、\mbox{直前の数百単}\mbox{語による言語モデルの適応化(キャッシュ法)が試}
 みられ\cite{test20}，\mbox{小さいタスクでは}その有効性が示されてはいるが，本論文
 では直前の数万〜数十万語に拡大する．つまり
 ，直前の数日間〜数週間の記事内容で言語モデルを適応化する方法
 を検討し，その有効性を示す．

 
 最後に認識単位に注目する．
 音声認識において，\mbox{認識単位が短い場合認識誤りを生じやすく，}
 付属語において 
 その影響は大きいと考えられ，小林らは，付属語列を新たな認識単位とした場\mbox{合
 の効果の検証をしている\cite{test9}}．
 \mbox{また高木らは，高頻度の付属語連鎖，}関連率の高い複合名詞などを新しい認識単
 位とし，\mbox{これらを語彙に加えることによる言語モデ}ルの性能に与える影響を検討
 している\cite{test10}．
 なお，連続する単語クラスを連結して一つの単語クラスとする方法や句を一つの単
 位とする方法は以前から試みられているが，いずれも適用されたデータベースの
 規模が小さい\cite{test11,test12}．
 同じような効果を狙った方法として，N-gramのNを可変にする方法も試みられて
 いる\cite{test8}．なお，定型表現の抽出に関する研究は，テキスト処理分野で
 は多くが試みられている(例えば，新納,井佐原 1995; 北,小倉,森本,矢野 1995)．
score of this paragraph is 4
