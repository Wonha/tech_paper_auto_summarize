================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:2, score:0.24704] まずN-gram言語モデルはタスクに依存するので，タスクに関する大量のデータベースを用いて構築される必要があることに注目し，共通の大量データベースによる言語モデルをもとに，同一ジャンルの過去の記事を用いるタスク適応化の方法とその有効性を示す．
[i:3, score:0.24974] 次に，新聞記事は話題が経時的に変化するので，数日間〜数週間の直前の記事内容で言語モデルの適応化を行なう方法とその有効性を示す．
[i:4, score:0.29279] 最後に新聞テキストには，使用頻度の高い(特殊)表現や，固定的な言い回しなどの表現(以下，定型表現と呼ぶ)が多いことに注目し，複数形態素から成る定型表現を抽出し，これを1形態素として捉えた上で，N-gram言語モデルを構築する方法を検討し，有用性を示す．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:10, score:0.26181] そこで，大語彙連続音声認識では，第1パス目はN=2のbigramモデルで複数候補の認識結果を出力し，N=3のtrigramで後処理を行なう方法が一般的である．
[i:32, score:0.24653] 次に，これらの(複数形態素から成る)定型表現を1形態素として捉えた上で，N-gram言語モデルを構築する方法を検討する．
[i:33, score:0.34036] 評価実験の結果，長さ2および3以下である定型表現を1形態素化してbigram, trigram言語モデルを作成することで，bigramに関しては，エントロピーが小さくなり，言語モデルとして有効であることを示す．

================================================================
[section type  : experiment_result]
[section title : 言語モデルの評価基準]
================================================================
[i:35, score:0.00000] 
-----------------------------------------------------
  [subsection title : エントロピーとパープレキシティ]
-----------------------------------------------------
  [i:lead, score:0.22832] 言語モデルの評価基準として，エントロピーとパープレキシティを用いる．
.....
  [i:36, score:0.22832] 言語モデルの評価基準として，エントロピーとパープレキシティを用いる．
  [i:37, score:0.19695] エントロピーとパープレキシティは共に，対象とする文集合の複雑さを定量的に示す指標で，その文集合が複雑なほど，それぞれの値は大きくなる．
  [i:52, score:0.19502] そこで，本論文では文字単位のエントロピー(パープレキシティ)の指標も用いる．
-----------------------------------------------------
  [subsection title : 補正パープレキシティ]
-----------------------------------------------------
  [i:lead, score:0.11278] 本研究で使用したCMU SLM toolkit[CITE]では語彙に含まれないものは全て一つの未知語のカテゴリにまとめられ，語彙に含まれる形態素と等価に未知語のカテゴリは扱われる．
.....
  [i:54, score:0.23961] そのため語彙サイズのセットが小さい程(カバー率が小さい程)，パープレキシティは小さくなるということになり好ましくない．
  [i:55, score:0.22877] そこで評価テキスト中に出現した未知語の種類[MATH]と，未知語の出現回数[MATH]を用いてパープレキシティを補正する[CITE]．
  [i:56, score:0.19627] 補正パープレキシティは

================================================================
[section type  : proposed_method]
[section title : 言語モデルの適応化]
================================================================
[i:62, score:0.00000] 
-----------------------------------------------------
  [subsection title : 面種別での学習と評価]
-----------------------------------------------------
  [i:lead, score:0.12409] タスク依存の言語モデルを構築する場合，ターゲットとするタスクに関するデータのみを用いて学習する方がよいと考えられる[CITE]．
.....
  [i:86, score:0.57173] なお，テストデータの補正パープレキシティに関しては，形態素数20000のtrigramでは面種別で学習するより全面種で学習する方が補正パープレキシティが小さくなる．
  [i:95, score:0.61399] 形態素数20000のtrigramに関しては，トレーニングデータとテストデータの(補正)パープレキシティの比較によって，面種別での学習のみならず全面種での学習でもトレーニングデータ量の不足が起きていることが分かる．
  [i:96, score:0.55903] 全面種で学習した言語モデルと面種別で学習した言語モデルをテストデータの(補正)パープレキシティで比較すると，形態素数5000のbigramでの比較とは逆に，面種別で学習した言語モデルより全面種で学習した言語モデルの方が，(補正)パープレキシティが小さく，面種別で学習した言語モデルを使用するより，全面種で学習した言語モデルを使用する方がよいという結論が得られた．
-----------------------------------------------------
  [subsection title : 適応化法]
-----------------------------------------------------
  [i:lead, score:0.10140] 新聞記事では数日間に渡って関連のある記事が載っていることがある．
.....
  [i:103, score:0.21407] そこで記事の評価時に，過去の数日間の記事で言語モデルを適応化しておけば，適応前より精度のよい言語モデルが出来ると考えられる．
  [i:109, score:0.34595] 標準言語モデルでは，新聞記事の全面種に対応する学習サンプルで出現頻度の高い形態素20000に限定した．
  [i:112, score:0.60524] 実験手順としては，{[MATH]}1形態素数20000の標準言語モデル(trigram)を構築し，{[MATH]}2標準言語モデルを事前モデルとして，面種別の適応化サンプルでターゲットタスクの言語モデルをMAP推定し，{[MATH]}3テストデータのパープレキシティを求める．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, score:0.08878] 実験結果を表[REF_tbl:MAP_pp_20k],[REF_tbl:MAP_app_20k]に示す．
.....
  [i:118, score:0.32584] 5日より14日間の適応化サンプルの方がパープレキシティが小さくなること
  [i:119, score:0.35318] 6カ月前の数日間より直前の数日間の記事での適応化の方がパープレキシティが小さくなること
  [i:124, score:0.38483] 国際面とスポーツ面で適応化サンプルの期間を5,14日,1,2,3,6カ月にして求めたパープレキシティと補正パープレキシティを図[REF_fig:pp2]に示す．
-----------------------------------------------------
  [subsection title : 固有名詞の適応化]
-----------------------------------------------------
  [i:lead, score:0.10420] 前述したように，新聞記事では数日間に渡って関連のある記事が載っていることが多い．
.....
  [i:136, score:0.23700] 基本語彙に数日間〜数週間の適応化サンプル中に出現した固有名詞を高出現頻度順に追加し，固有名詞のカバー率を求める．
  [i:145, score:0.24142] このことは，基本語彙に登録されなかった単語(未知語)において，固有名詞の占める割合が低いことを示している(5000語彙に対しては約20%，20000語彙に対しては約25%)．
  [i:150, score:0.25128] 但し，面種別で学習すれば，20000〜30000形態素でも十分である(表2,3参照)．

================================================================
[section type  : proposed_method]
[section title : 定型表現]
================================================================
[i:151, score:0.23715] 新聞テキスト文には，定型表現が多いことに着目し，これらの高頻出定型表現を1形態素として捉えた上で，言語モデルを構築すれば，より精度の良いモデルが出来ると考られる．
[i:152, score:0.13711] 今回の実験では，定型表現を抽出するアルゴリズムとして，池原らの提案した方法[CITE]を用いる．
[i:155, score:0.16629] この方法では，最長一致の文字列抽出(ある文字列が抽出されたとき，その文字列に含まれる部分文字列は統計量を求める際にはこの部分文字列を定型表現とはカウントしない)を条件とし，任意の長さ以上，任意の使用頻度以上の表現を，もれなく自動的に抽出する．
-----------------------------------------------------
  [subsection title : 標準言語モデル]
-----------------------------------------------------
  [i:lead, score:0.25910] 標準言語モデルは，表[REF_base]に示した全面種の学習用データから作成した表[REF_tbl:pp_bi_20k]のモデルを用いる．
.....
  [i:158, score:0.25910] 標準言語モデルは，表[REF_base]に示した全面種の学習用データから作成した表[REF_tbl:pp_bi_20k]のモデルを用いる．
  [i:159, score:0.19725] まず，RWC[CITE]の毎日新聞形態素解析結果を用いて，出現頻度が上位20000番目までの形態素を語彙として辞書に登録した．
  [i:160, score:0.10530] 言語モデルの構築には，CMU SLM Toolkit Ver.1を用いた．
-----------------------------------------------------
  [subsection title : 定型表現を用いた言語モデル]
-----------------------------------------------------
  [i:lead, score:0.17784] 定型表現を用いた言語モデル構築のための手順を以下に示す．
.....
  [i:167, score:0.23148] トレーニングデータから出現頻度の多い順に20000を求め，語彙サイズ20000の辞書を作成する．
  [i:168, score:0.30833] このとき，上位20000の辞書に登録された定型表現は2連結で9430個，3連結で9357個(このうち2連語が7010，3連語が2347)である．
  [i:176, score:0.41515] CMU SLM Toolkitを用いてトレーニングデータから，語彙サイズ20000の辞書を作成し，bigram,trigram言語モデルを構築する．
-----------------------------------------------------
  [subsection title : 評価実験]
-----------------------------------------------------
  [i:lead, score:0.20966] 評価を行なう時，注意しなければならないことは，いずれの比較対象に対しても同じ定義の1形態素あたりのパープレキシティを求めないといけないということである．
.....
  [i:193, score:0.40933] 次に，標準言語モデルを作成した時の語彙サイズ20000の辞書に，2および3連結の定型表現をそれぞれ高出現頻度順で上位2000個,5000個分を追加した場合の辞書で言語モデルを構築した．
  [i:197, score:0.36466] bigramでは定型表現を用いることにより，補正パープレキシティも大幅に減少している．
  [i:198, score:0.36904] また，定型表現5000個追加のものの方が，定型表現2000個追加のものと比べて，語彙サイズが大きいのにも関わらず，パープレキシティが減少している．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[i:207, score:0.40876] まず言語モデルのタスクへの適応化については，実験の結果，6カ月前の数日間の記事より直前の数日間の記事で適応化した方がパープレキシティが小さくなった．
[i:209, score:0.36603] ただ，適応化サンプルの量を多くするほどパープレキシティが小さくなる傾向があり，N-gramベースでの言語モデルを少量サンプルで適応化させることは限界があると考えられる．
[i:211, score:0.41717] 定型表現を用いた言語モデルを作成することで，bigramモデルに関しては，テストデータに対し約3割程度パープレキシティを低く押えるとこができ，言語モデルの有効性を示すことができた．

