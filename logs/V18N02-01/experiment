評価
\label{section:評価}

提案手法の評価のために，学習コーパスの作成の方法と言語モデルの単位が異なる仮名漢字変換
を構築し，テストコーパスに対する変換精度を測定した．この節では，その結果を提示し提案手
法の評価を行う．



\subsection{実験条件}

実験に用いたコーパスの諸元を\tabref{table:corpus}に掲げる．学習コーパスは，$L$と$R$の
2種類である．学習コーパス$L$は，現代日本語書き言葉均衡コーパス2009年モニター版
\cite{Balanced.Corpus.of.Contemporary.Written.Japanese}と日常会話の辞書の例文と新聞記
事からなり，人手による単語分割と入力記号付与がなされている．学習コーパス$R$は新聞記事
からなり，単語境界や入力記号などの付加情報はない．単語境界や入力記号の推定は，京都テ
キスト解析ツールキットKyTea \cite{点推定と能動学習を用いた自動単語分割器の分野適応}
\footnote{Version 0.1.0, http://www.phontron.com/kytea/（2010年10月）．}によって行っ
た．テストコーパス$T$は，学習コーパス$R$と同じ新聞の別の記事であり，変換精度の計算の
ために入力記号が付与されてある．

\begin{table}[tb]
\caption{コーパス}
\input{01table01.txt}
  \label{table:corpus}
\vspace{1\baselineskip}
\end{table}


\subsection{評価基準}

\begin{figure}[tb]
\begin{center}
\includegraphics{18-2ia1f3.eps}
\end{center}
  \caption{評価基準}
  \label{figure:criteria}
\end{figure}

仮名漢字変換の評価基準は，各入力文の一括変換結果と正解との最長共通部分列(LCS;
longest common subsequence) \cite{文字列中のパターン照合のためのアルゴリズム}の文字数
に基づく再現率と適合率である（\figref{figure:criteria}参照）．正解コーパスに含まれる文
字数を$N_{COR}$とし，一括変換の結果に含まれる文字数を$N_{SYS}$とし，これらの最長共通
部分列の文字数を$N_{LCS}$とすると，再現率は$N_{LCS}/N_{COR}$と定義され，適合率は
$N_{LCS}/N_{SYS}$と定義される．\figref{figure:criteria}の例では，これらは以下のように
なる．
\begin{description}
\item[\ 再現率：] $N_{LCS}/N_{COR} =  5/8$
\item[\ 適合率：] $N_{LCS}/N_{SYS} = 5/11$
\end{description}
これらに加えて，文正解率も計算した．これは，変換結果が文全体に渡って一致している文の
割合を表す．



\subsection{評価}

学習コーパスの作成の方法と言語モデルの単位による仮名漢字変換精度の差を調べるために，
以下の3通りの方法で作成された学習コーパスのそれぞれから，単語を言語モデルの単位とする
仮名漢字変換（\equref{eqnarray:KKConv1}参照）と単語と入力記号列の組を言語モデルの単位と
する仮名漢字変換（\equref{eqnarray:KKConv3}参照）を作成した．言語モデルはすべて2-gramモデ
ルである\footnote{音声認識で一般的な3-gramモデルを用いなかったのは，仮名漢字変換の先
行研究\cite{確率的モデルによる仮名漢字変換}とその実用化の例\cite{Google.IME}が2-gram
モデルを用いていること，仮名漢字変換での入力記号列は比較的短い傾向があり（第1著者の場
合約2.2単語分）長い履歴が実際にはほとんど有効ではないこと，3-gramモデルは必要となる記
憶域が増大し処理速度が低下するなど実用化に向かないことである．}．
\par
\KKC{DD}:　決定的に単語分割し，決定的に入力記号列を付与する．\par
\KKC{DS}:　決定的に単語分割し，確率的に入力記号列を付与する．\par
\KKC{SS}:　確率的に単語分割し，確率的に入力記号列を付与する．\par
\noindent
ここで，「確率的」は擬似確率的単語分割および疑似確率的入力記号付与を意味し，全て倍率
は1とした．

文献\cite{擬似確率的単語分割コーパスによる言語モデルの改良}では，1,890,041文字の生コー
パスに対して1〜256の倍率による擬似確率的単語分割コーパスを評価している．その結果，倍
率が8〜32程度で確率的単語分割コーパスと同程度の性能となっている．前後数単語の単語分割
の可能性は16〜32通り程度（その出現にも偏りがある）なので高頻度の単語（候補）の高頻度の文
脈はある程度大きいコーパスであれば，倍率が1の擬似確率的単語分割コーパスでも十分に真の
分布に近い推定値が得られると考えられる．本実験での生コーパスの文字数は，この文献での
実験の約27.9倍であり，ある程度の頻度の組の列$\Bdma{u}$の出現頻度
（\subref{subsec:pseudo}の$F$）は約27.9倍となっていることが期待される．したがって，倍率
（第3.5項の$N$）が1であっても，上述の文献における実験での倍率27.9に相当し，確率的タグ付与
コーパス($N \rightarrow \infty$)に近い性能が期待される．

3つの学習コーパスの作成の方法と2つの言語モデルの単位のすべての組み合わせによる仮名漢
字変換の精度を\tabref{table:result}に示す．表中のIDの最初の2文字は学習コーパスの作成
の方法を表し，次の1文字は言語モデルの単位を表す．文献\Cite{確率的モデルによる仮名漢字
変換} は，単語と品詞の組を言語モデルの単位とし，生コーパスの形態素解析結果を学習コー
パスに利用していないが，生コーパスの利用による精度向上は広く一般に知られているので，
単語を言語モデルの単位とし，生コーパスの決定的な単語分割と入力記号列付与結果を利用す
る\KKC{DDw}が既存手法に対応するとし，これをベースラインとする．

\begin{table}[t]
\caption{仮名漢字変換の精度 2-gram}
\input{01table02.txt}
\label{table:result}
\end{table}

まず，\tabref{table:result}中の\KKC{DDw}と\KKC{DSw}と\KKC{SSw}の比較についてである．
これらは，すべて単語を言語モデルの単位とする．自動分割と入力記号付与の両方を決定的に
行った結果から言語モデルを推定するベースライン\KKC{DDw}に対して，入力記号付与を確率的
に行う\KKC{DSw}はより高い変換精度となっている．これにより，入力記号付与を確率的に行う
ことが有効であることが分かる．\KKC{DDw}と\KKC{DSw}の言語モデルは共通で，違いは仮名漢
字モデルのみである．このことから，入力記号付与を確率的に行うことで，仮名漢字モデルが
より適切に推定できることが分かる．さらに，単語分割も確率的に行う\KKC{SSw}の精度は，入
力記号付与のみを確率的に行う\KKC{DSw}よりも高くなっている．このことから，確率的入力記
号付与は，確率的単語分割\cite{擬似確率的単語分割コーパスによる言語モデルの改良}と協調
して精度向上に寄与することがわかる．

次に，\tabref{table:result}中の\KKC{DDu}と\KKC{DSu}と\KKC{SSu}の比較についてである．こ
れらは，すべて単語と入力記号列の組を言語モデルの単位とする．この場合も，確率的に入力記
号を付与することで精度が向上し，単語分割も確率的に行うことでさらに精度が向上しているこ
とが分かる．

さらに，言語モデルの単位の差異についてである．\tabref{table:result}から，\KKC{DDw}と
\KKC{DDu}，\KKC{DSw}と\KKC{DSu}，\KKC{SSw}と\KKC{SSu}のいずれの組の比較においても，言
語モデルの単位を単語から単語と入力記号列の組に変更することで変換精度が向上しているこ
とが分かる．

\begin{figure}[tb]
\begin{center}
\includegraphics{18-2ia1f4.eps}
\end{center}
  \caption{疑似確率的単語分割と疑似タグ付与の合計の倍率($m^{2}$)と仮名漢字変換精度の関係}
  \label{figure:graph}
\end{figure}

最後に，提案手法\KKC{SSu}における倍率と精度の関係についてである．これを調べるために，
$m$倍の疑似確率的単語分割の各結果に対する$m$倍の疑似確率的タグ付与の結果（合計$m^2$,
$m \in \{1,\,2,\,4\}$）を用いた場合の精度を計算した．\figref{figure:graph}は，倍率と精
度の関係である（$m = 1$は，\tabref{table:result}の\KKC{SSu}と同じ）．この結果から，倍率
を上げることで，少しではあるが精度が向上することがわかる．一方で，それぞれの場合の語
彙（表記と読みの組）のサイズは順に，123,078組，181,800組，295,801組であり，単語分割とタ
グ付与を決定的に行う\KKC{DDu}の99,210組との差は，倍率が大きくなるに従って非常に大きく
なる．\figref{figure:graph}から精度の差は大きくないので，倍率は$1^2$か$2^2$程度が現実
的であろう．

以上のことから，仮名漢字変換の言語モデルを単語から単語と入力記号列の組とし，入力記号
を確率的に付与したコーパスからこれを推定することが有効であると言える．さらに，確率的
単語分割と組み合わせることでさらなる精度向上が実現できると結論できる．

