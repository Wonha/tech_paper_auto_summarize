================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:2, score:0.41013] 精度の高い読み推定ツールは存在しないため，結果として，言語モデルの単位を単語（と品詞の組）とし，仮名漢字モデルを比較的小さい読み付与済みコーパスから推定したり，単語の発音の確率を推定せずに一定値としている．
[i:7, score:0.42751] これらの提案を採用するか否かに応じて複数の仮名漢字変換器を構築し，テストコーパスにおける変換精度を比較した結果，単語と読みの組を言語モデルの単位とし，そのパラメータを確率的に単語分割し，さらに確率的読みを付与したコーパスから推定することで最も高い変換精度となることが分かった．
[i:8, score:0.28294] したがって，本論文で提案する単語と読みの組を単位とする言語モデルと，確率的タグ付与コーパスの概念は有用であると結論できる．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:16, score:0.30562] 仮名漢字モデルや発音辞書における確率の推定には，実際の使用における単語の読みの頻度を計数する必要がある．
[i:18, score:0.37296] したがって，仮名漢字モデルを比較的小さい読み付与済みコーパスから推定したり[CITE]，後処理によって，一部の高頻度語にのみ文脈に応じた発音を付与し，他の単語に関しては，各発音の確率を推定せずに一定値としている[CITE]のが現状である．
[i:37, score:0.39025] 実験では，タグとして入力記号列を採用し，単語と入力記号列の組を単位とする言語モデルを用いる仮名漢字変換器を構築し，単語を単位とする言語モデルを用いる場合や，決定的な単語分割や入力記号付与などの既存手法に対する提案手法の優位性を示す．

================================================================
[section type  : proposed_method]
[section title : 統計的仮名漢字変換]
================================================================
[i:38, score:0.24026] 統計的手法による仮名漢字変換[CITE]は，キーボードから直接入力可能な入力記号[MATH]の正閉包[MATH]を入力として，日本語の文字[MATH]の正閉包である変換候補[MATH]を確率値[MATH]の降順に提示する．
[i:39, score:0.28284] 文献\Cite{確率的モデルによる仮名漢字変換}では文を単語列[MATH]とみなし，これを単語[MATH]を単位とする言語モデルと仮名漢字モデルに分解して実現する方法を提案している．
[i:40, score:0.15247] 本節では，まずこれについて説明し，次に単語と読みを組とする言語モデルによる方法を提案し定式化する．
-----------------------------------------------------
  [subsection title : 従来手法]
-----------------------------------------------------
  [i:lead, score:0.27292] 文献\Cite{確率的モデルによる仮名漢字変換}では，変換候補を[MATH]で順序付けすることを提案しており，これを次の式が示すように，単語を単位とする言語モデルと仮名漢字モデルに分解する．
.....
  [i:41, score:0.27292] 文献\Cite{確率的モデルによる仮名漢字変換}では，変換候補を[MATH]で順序付けすることを提案しており，これを次の式が示すように，単語を単位とする言語モデルと仮名漢字モデルに分解する．
  [i:54, score:0.42674] \equref{eqnarray:KKConv1}の[MATH]は，単語単位の仮名漢字モデルであり，パラメータは，単語に分割されかつ各単語に入力記号列が付与されたコーパスから以下の式を用いて最尤推定する．
  [i:55, score:0.33464] \equref{eqnarray:KKConv1}から分かるように，単語単位の仮名漢字モデルでは，単語と入力記号列との対応関係が各単語において独立であると仮定している．
-----------------------------------------------------
  [subsection title : 提案手法]
-----------------------------------------------------
  [i:lead, score:0.19078] 本論文では，言語モデルの単位を単語と入力記号列の組[MATH]とすることを提案する．
.....
  [i:79, score:0.21451] \figref{figure:LMB}が示すように，この学習コーパスには自動単語分割・読み付与の結果を用いることができる．
  [i:80, score:0.25846] さらに自動単語分割器や読み付与の学習に用いたタグ付きコーパスが利用可能な場合にはこれを加えることもできる（\figref{figure:LMB}の点線）．
  [i:81, score:0.22308] 単語を単位とする従来手法と同程度の信頼性となるパラメータを推定するために，従来手法においてパラメータ推定に用いられる単語に分割されたコーパスと同程度の量の単語に分割されかつ入力記号列が付与されたコーパスが必要である．

================================================================
[section type  : proposed_method]
[section title : 仮名漢字変換のための言語資源とその処理]
================================================================
[i:85, score:0.27111] 仮名漢字変換や音声認識のための言語モデルは，単語分割済みコーパスと生コーパスの自動単語分割結果から構築される．
[i:86, score:0.00371] この節では，まずこの過程を概説する．
[i:87, score:0.28082] 次に，前節で提案したモデルのパラメータをより正確に推定するために，単語に入力記号列や発音などのタグを確率的に付与することを提案する．
-----------------------------------------------------
  [subsection title : コーパス]
-----------------------------------------------------
  [i:lead, score:0.24349] 仮名漢字変換や音声認識のための単語を単位とする言語モデル作成においては，これらを適用する分野のコーパスが必須である．
.....
  [i:88, score:0.24349] 仮名漢字変換や音声認識のための単語を単位とする言語モデル作成においては，これらを適用する分野のコーパスが必須である．
  [i:89, score:0.25187] 一般に，コーパスには単語境界情報がないので，自動単語分割器[CITE]や形態素解析器[CITE]を用いて文を言語モデルの単位に分割し，その結果に対して単語[MATH]-gram頻度を計数する（\figref{figure:LMA}参照）\inhibitglue．
  [i:91, score:0.15423] その場合には，これら自然言語処理システムの学習コーパスも言語モデルの学習コーパスに加えることができる（\figref{figure:LMA}の点線）が，実際には，これら自然言語処理システムはツールとして配布され，辞書追加程度の適応しかなされず，自然言語処理システムの学習コーパスが言語モデルの学習に利用されることは少ない．
-----------------------------------------------------
  [subsection title : 形態素解析と自動単語分割]
-----------------------------------------------------
  [i:lead, score:0.02664] 形態素解析は，日本語の自然言語処理の第一段階として研究され，ルールに基づく方法が一定の成果を上げた[CITE]．
.....
  [i:96, score:0.17646] このような背景から，仮名漢字変換や音声認識のための言語モデル作成のために，形態素解析が用いられている．
  [i:105, score:0.22203] この手法では，自動単語分割器によって各文字の間に単語境界がある確率を付与し，その確率を参照して計算される単語[MATH]-gramの期待頻度を用いて言語モデルが構築される．
  [i:106, score:0.22855] 実用上は，モンテカルロシミュレーションのように，各文字間に対して都度発生させた乱数と単語境界確率の比較結果から単語境界か否かを決定することで得られる擬似確率的単語分割コーパスから従来法と同様に言語モデルが構築される[CITE]．
-----------------------------------------------------
  [subsection title : 自動読み推定]
-----------------------------------------------------
  [i:lead, score:0.29459] 前節で，仮名漢字変換のための言語モデルの単位として単語と入力記号列の組を用いることを提案した．
.....
  [i:107, score:0.29459] 前節で，仮名漢字変換のための言語モデルの単位として単語と入力記号列の組を用いることを提案した．
  [i:114, score:0.40429] 前節で提案した単語と入力記号列の組を単位とする言語モデルの構築においては，コーパスを単語に分割し，文脈に応じた読みを付与することができるKyTea（京都テキスト解析ツールキット）[CITE]を用いて適応対象の分野のテキストを自動的に単語と入力記号列の組の列に変換する（\figref{figure:LMB}参照）．
  [i:115, score:0.25355] その結果から\equref{equation:UM}を用いて単語と入力記号列の組の[MATH]-gram確率を推定する．
-----------------------------------------------------
  [subsection title : 確率的タグ付与]
-----------------------------------------------------
  [i:lead, score:0.14838] 自動読み推定の結果は，形態素解析や自動単語分割等の自動処理の場合と同様に，一定量の誤りを含む．
.....
  [i:118, score:0.27360] 学習コーパスに含まれる読み推定誤りは，言語モデルや仮名漢字モデル，あるいは発音辞書に悪影響を及ぼす．
  [i:134, score:0.27932] 仮名漢字変換のための言語モデル構築では，タグとして単語に対応する入力記号列を用いる．
  [i:135, score:0.25823] 確率的入力記号列付与のためのモデルは，単語ごとに入力記号列が付与されたコーパスからロジスティック回帰などの点予測器を推定しておくことで実現できる．
-----------------------------------------------------
  [subsection title : 擬似確率的タグ付与]
-----------------------------------------------------
  [i:lead, score:0.23188] 確率的単語分割の場合と同様に，確率的タグ付与コーパスに対する単語とタグの組の列の頻度の計算は，決定的タグ付与コーパスに対する頻度計算と比べてはるかに多い計算を要する．
.....
  [i:136, score:0.23188] 確率的単語分割の場合と同様に，確率的タグ付与コーパスに対する単語とタグの組の列の頻度の計算は，決定的タグ付与コーパスに対する頻度計算と比べてはるかに多い計算を要する．
  [i:141, score:0.22997] 擬似確率的タグ付与コーパスは，各単語に対して都度発生させた乱数とタグの確率の比較結果から当該単語のタグを唯一に決定することで得られる単語とタグの組の列である．
  [i:147, score:0.21840] 擬似確率的タグ付与コーパスにおける単語とタグの組の[MATH]-gram頻度の計算はこの特殊な場合である．

================================================================
[section type  : experiment_result]
[section title : 評価]
================================================================
[i:151, score:0.00859] この節では，その結果を提示し提案手法の評価を行う．
-----------------------------------------------------
  [subsection title : 実験条件]
-----------------------------------------------------
  [i:lead, score:0.05047] 実験に用いたコーパスの諸元を\tabref{table:corpus}に掲げる．
.....
  [i:154, score:0.18679] 学習コーパス[MATH]は，現代日本語書き言葉均衡コーパス2009年モニター版[CITE]と日常会話の辞書の例文と新聞記事からなり，人手による単語分割と入力記号付与がなされている．
  [i:156, score:0.14557] 単語境界や入力記号の推定は，京都テキスト解析ツールキットKyTea [CITE]によって行った．
  [i:157, score:0.14508] テストコーパス[MATH]は，学習コーパス[MATH]と同じ新聞の別の記事であり，変換精度の計算のために入力記号が付与されてある．
-----------------------------------------------------
  [subsection title : 評価基準]
-----------------------------------------------------
  [i:lead, score:0.22635] 仮名漢字変換の評価基準は，各入力文の一括変換結果と正解との最長共通部分列(LCS; longest common subsequence) [CITE]の文字数に基づく再現率と適合率である（\figref{figure:criteria}参照）．
.....
  [i:158, score:0.22635] 仮名漢字変換の評価基準は，各入力文の一括変換結果と正解との最長共通部分列(LCS; longest common subsequence) [CITE]の文字数に基づく再現率と適合率である（\figref{figure:criteria}参照）．
  [i:159, score:0.07854] 正解コーパスに含まれる文字数を[MATH]とし，一括変換の結果に含まれる文字数を[MATH]とし，これらの最長共通部分列の文字数を[MATH]とすると，再現率は[MATH]と定義され，適合率は[MATH]と定義される．
  [i:160, score:0.04952] \figref{figure:criteria}の例では，これらは以下のようになる．
-----------------------------------------------------
  [subsection title : 評価]
-----------------------------------------------------
  [i:lead, score:0.41023] 学習コーパスの作成の方法と言語モデルの単位による仮名漢字変換精度の差を調べるために，以下の3通りの方法で作成された学習コーパスのそれぞれから，単語を言語モデルの単位とする仮名漢字変換（\equref{eqnarray:KKConv1}参照）と単語と入力記号列の組を言語モデルの単位とする仮名漢字変換（\equref{eqnarray:KKConv3}参照）を作成した．
.....
  [i:165, score:0.41023] 学習コーパスの作成の方法と言語モデルの単位による仮名漢字変換精度の差を調べるために，以下の3通りの方法で作成された学習コーパスのそれぞれから，単語を言語モデルの単位とする仮名漢字変換（\equref{eqnarray:KKConv1}参照）と単語と入力記号列の組を言語モデルの単位とする仮名漢字変換（\equref{eqnarray:KKConv3}参照）を作成した．
  [i:178, score:0.53336] 文献\Cite{確率的モデルによる仮名漢字変換}は，単語と品詞の組を言語モデルの単位とし，生コーパスの形態素解析結果を学習コーパスに利用していないが，生コーパスの利用による精度向上は広く一般に知られているので，単語を言語モデルの単位とし，生コーパスの決定的な単語分割と入力記号列付与結果を利用する\KKC{DDw}が既存手法に対応するとし，これをベースラインとする．
  [i:191, score:0.39105] \tabref{table:result}から，\KKC{DDw}と\KKC{DDu}，\KKC{DSw}と\KKC{DSu}，\KKC{SSw}と\KKC{SSu}のいずれの組の比較においても，言語モデルの単位を単語から単語と入力記号列の組に変更することで変換精度が向上していることが分かる．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:202, score:0.39186] さらに，単語分割済みコーパスから自動読み推定を用いて表記と読みの組を単位とする確率的言語モデルを推定し，仮名漢字変換に用いることを提案した．
[i:203, score:0.38170] 実験では，単語分割や読み推定が決定的にあるいは確率的に行われているコーパスから，単語を単位とする言語モデルと，単語と読みの組を単位とする言語モデルを推定し，仮名漢字器を構築した．
[i:204, score:0.41467] これら複数の仮名漢字器の変換精度を比較した結果，単語と読みの組を言語モデルの単位とし，そのパラメータを確率的に単語分割されかつ確率的に読み付与されたコーパスから推定することで最も高い変換精度となることが分かった．

================================================================
[section type  : proposed_method]
[section title : 自動読み推定]
================================================================
[i:207, score:0.18515] 本論文で用いた自動読み推定[CITE]は，コーパスに基づく方法であり，単語に分割された文を入力とし，単語毎に独立に以下の分類に基づいて読み推定が行われる．
[i:219, score:0.18158] 学習コーパスとして33,147文（899,025単語，1,292,249文字）を用い，テストコーパスとして同一分野の3,681文（98,634単語，141,655文字）を用いた場合の読み推定精度を測定した．
[i:221, score:0.24445] その結果，一般的な手法である単語と読みを組とする3-gramモデル\Cite{N-gramモデルを用いた音声合成のための読み及びアクセントの同時推定}の適合率と再現率はそれぞれ99.07%と99.12%であり，本論文で用いた自動読み推定の適合率と再現率はそれぞれ99.19%と99.26%であった．

