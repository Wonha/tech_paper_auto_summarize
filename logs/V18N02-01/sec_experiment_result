提案手法の評価のために，学習コーパスの作成の方法と言語モデルの単位が異なる仮名漢字変換を構築し，テストコーパスに対する変換精度を測定した．
この節では，その結果を提示し提案手法の評価を行う．
実験に用いたコーパスの諸元を\tabref{table:corpus}に掲げる．
学習コーパスは，[MATH]と[MATH]の2種類である．
学習コーパス[MATH]は，現代日本語書き言葉均衡コーパス2009年モニター版[CITE]と日常会話の辞書の例文と新聞記事からなり，人手による単語分割と入力記号付与がなされている．
学習コーパス[MATH]は新聞記事からなり，単語境界や入力記号などの付加情報はない．
単語境界や入力記号の推定は，京都テキスト解析ツールキットKyTea [CITE]によって行った．
テストコーパス[MATH]は，学習コーパス[MATH]と同じ新聞の別の記事であり，変換精度の計算のために入力記号が付与されてある．
仮名漢字変換の評価基準は，各入力文の一括変換結果と正解との最長共通部分列(LCS; longest common subsequence) [CITE]の文字数に基づく再現率と適合率である（\figref{figure:criteria}参照）．
正解コーパスに含まれる文字数を[MATH]とし，一括変換の結果に含まれる文字数を[MATH]とし，これらの最長共通部分列の文字数を[MATH]とすると，再現率は[MATH]と定義され，適合率は[MATH]と定義される．
\figref{figure:criteria}の例では，これらは以下のようになる．
[MATH]
[MATH]
これらに加えて，文正解率も計算した．
これは，変換結果が文全体に渡って一致している文の割合を表す．
学習コーパスの作成の方法と言語モデルの単位による仮名漢字変換精度の差を調べるために，以下の3通りの方法で作成された学習コーパスのそれぞれから，単語を言語モデルの単位とする仮名漢字変換（\equref{eqnarray:KKConv1}参照）と単語と入力記号列の組を言語モデルの単位とする仮名漢字変換（\equref{eqnarray:KKConv3}参照）を作成した．
言語モデルはすべて2-gramモデルである．
\KKC{DD}:決定的に単語分割し，決定的に入力記号列を付与する．
\KKC{DS}:決定的に単語分割し，確率的に入力記号列を付与する．
\KKC{SS}:確率的に単語分割し，確率的に入力記号列を付与する．
ここで，「確率的」は擬似確率的単語分割および疑似確率的入力記号付与を意味し，全て倍率は1とした．
文献[CITE]では，1,890,041文字の生コーパスに対して1〜256の倍率による擬似確率的単語分割コーパスを評価している．
その結果，倍率が8〜32程度で確率的単語分割コーパスと同程度の性能となっている．
前後数単語の単語分割の可能性は16〜32通り程度（その出現にも偏りがある）なので高頻度の単語（候補）の高頻度の文脈はある程度大きいコーパスであれば，倍率が1の擬似確率的単語分割コーパスでも十分に真の分布に近い推定値が得られると考えられる．
本実験での生コーパスの文字数は，この文献での実験の約27.9倍であり，ある程度の頻度の組の列[MATH]の出現頻度（\subref{subsec:pseudo}の[MATH]）は約27.9倍となっていることが期待される．
したがって，倍率（第3.5項の[MATH]）が1であっても，上述の文献における実験での倍率27.9に相当し，確率的タグ付与コーパス([MATH])に近い性能が期待される．
3つの学習コーパスの作成の方法と2つの言語モデルの単位のすべての組み合わせによる仮名漢字変換の精度を\tabref{table:result}に示す．
表中のIDの最初の2文字は学習コーパスの作成の方法を表し，次の1文字は言語モデルの単位を表す．
文献\Cite{確率的モデルによる仮名漢字変換}は，単語と品詞の組を言語モデルの単位とし，生コーパスの形態素解析結果を学習コーパスに利用していないが，生コーパスの利用による精度向上は広く一般に知られているので，単語を言語モデルの単位とし，生コーパスの決定的な単語分割と入力記号列付与結果を利用する\KKC{DDw}が既存手法に対応するとし，これをベースラインとする．
まず，\tabref{table:result}中の\KKC{DDw}と\KKC{DSw}と\KKC{SSw}の比較についてである．
これらは，すべて単語を言語モデルの単位とする．
自動分割と入力記号付与の両方を決定的に行った結果から言語モデルを推定するベースライン\KKC{DDw}に対して，入力記号付与を確率的に行う\KKC{DSw}はより高い変換精度となっている．
これにより，入力記号付与を確率的に行うことが有効であることが分かる．
\KKC{DDw}と\KKC{DSw}の言語モデルは共通で，違いは仮名漢字モデルのみである．
このことから，入力記号付与を確率的に行うことで，仮名漢字モデルがより適切に推定できることが分かる．
さらに，単語分割も確率的に行う\KKC{SSw}の精度は，入力記号付与のみを確率的に行う\KKC{DSw}よりも高くなっている．
このことから，確率的入力記号付与は，確率的単語分割[CITE]と協調して精度向上に寄与することがわかる．
次に，\tabref{table:result}中の\KKC{DDu}と\KKC{DSu}と\KKC{SSu}の比較についてである．
これらは，すべて単語と入力記号列の組を言語モデルの単位とする．
この場合も，確率的に入力記号を付与することで精度が向上し，単語分割も確率的に行うことでさらに精度が向上していることが分かる．
さらに，言語モデルの単位の差異についてである．
\tabref{table:result}から，\KKC{DDw}と\KKC{DDu}，\KKC{DSw}と\KKC{DSu}，\KKC{SSw}と\KKC{SSu}のいずれの組の比較においても，言語モデルの単位を単語から単語と入力記号列の組に変更することで変換精度が向上していることが分かる．
最後に，提案手法\KKC{SSu}における倍率と精度の関係についてである．
これを調べるために，[MATH]倍の疑似確率的単語分割の各結果に対する[MATH]倍の疑似確率的タグ付与の結果（合計[MATH], [MATH]）を用いた場合の精度を計算した．
\figref{figure:graph}は，倍率と精度の関係である（[MATH]は，\tabref{table:result}の\KKC{SSu}と同じ）．
この結果から，倍率を上げることで，少しではあるが精度が向上することがわかる．
一方で，それぞれの場合の語彙（表記と読みの組）のサイズは順に，123,078組，181,800組，295,801組であり，単語分割とタグ付与を決定的に行う\KKC{DDu}の99,210組との差は，倍率が大きくなるに従って非常に大きくなる．
\figref{figure:graph}から精度の差は大きくないので，倍率は[MATH]か[MATH]程度が現実的であろう．
以上のことから，仮名漢字変換の言語モデルを単語から単語と入力記号列の組とし，入力記号を確率的に付与したコーパスからこれを推定することが有効であると言える．
さらに，確率的単語分割と組み合わせることでさらなる精度向上が実現できると結論できる．
