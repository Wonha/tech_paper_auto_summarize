確率的言語モデルは，統計的手法による仮名漢字変換[CITE] [CITE] [CITE]や音声認識[CITE] [CITE]などに広く用いられている．
確率的言語モデルは，ある単語列がある言語でどの程度自然であるかを出現確率としてモデル化する．
仮名漢字変換においては，確率的言語モデルに加えて，仮名漢字モデルが用いられる．
仮名漢字モデルは，入力記号列と単語の対応を記述する．
音声認識では，仮名漢字モデルの代わりに，発音と単語の対応を記述する発音辞書と音響モデルが用いられる．
確率的言語モデルの推定のためには，システムを適応する分野の大量のテキストが必要で，その文は単語に分割されている必要がある．
このため，日本語を対象とする場合には，自動単語分割や形態素解析が必要であるが，ある程度汎用性のあるツールが公開されており，辞書の追加などで一般的な分野の言語モデルが構築可能となっている．
仮名漢字モデルや発音辞書における確率の推定には，実際の使用における単語の読みの頻度を計数する必要がある．
しかしながら，読み推定をある程度の汎用性と精度で行うツールは存在しない．
したがって，仮名漢字モデルを比較的小さい読み付与済みコーパスから推定したり[CITE]，後処理によって，一部の高頻度語にのみ文脈に応じた発音を付与し，他の単語に関しては，各発音の確率を推定せずに一定値としている[CITE]のが現状である．
一方で，単語（表記）を言語モデルの単位とすることには弊害がある．
例えば，「…するや，…した」という発声が，「…する夜，…した」と書き起こされることがある．
この書き起こし結果の「夜」は，この文脈では必ず「よる」と発音されるので，「夜」と書き起こすのは不適切である．
この問題は，単語を言語モデルの単位とする仮名漢字変換においても同様に起こる．
これは，単語の読みの確率を文脈と独立であると仮定して推定（あるいは一定値に固定）していることに起因する．
このような問題を解決するために，本論文では，まず，すべての単語を読みで細分化し，単語と読みの組を単位とする言語モデルを利用することを提案する．
仮名漢字変換や音声認識において，単語と品詞の組を言語モデルの単位とすることや，一部の高頻度語を読みで細分化することが行われている[CITE] [CITE]．
提案手法は，品詞ではなく読みですべての単語を細分化することとみなすこともできるので，提案手法は既存手法から容易に類推可能であろう．
しかしながら，提案手法を実現するためには，文脈に応じた正確な読みを様々な分野のテキストに対してある程度の精度で推定できる必要がある．
このため，提案手法を実現したという報告はない．
単語を単位とする言語モデルのパラメータは，自動単語分割の結果から推定される．
自動単語分割の精度は十分高いとはいえ，一定の割合の誤りは避けられない．
この問題による悪影響を避けるために，確率的単語分割[CITE]という考えが提案されている．
この方法では，各文字の間に単語境界が存在する確率を付与し，その確率を参照して計算される単語[MATH]-gramの期待頻度を用いて言語モデルを構築する．
計算コストの削減のために，実際には，各文字間に対してその都度発生させた乱数と単語境界確率の比較結果から単語境界か否かを決定することで得られる擬似確率的単語分割コーパスから従来法と同様に言語モデルが構築される[CITE]．
単語と読みの組を単位とする言語モデルのパラメータは，自動単語分割および自動読み推定の結果から推定される．
自動単語分割と同様に，自動読み推定の精度は十分高いとしても，一定の割合の誤りは避けられず，言語モデルのパラメータ推定に悪影響がある．
これを回避するために，確率的タグ付与とその近似である擬似確率的タグ付与を提案する．
実験では，タグとして入力記号列を採用し，単語と入力記号列の組を単位とする言語モデルを用いる仮名漢字変換器を構築し，単語を単位とする言語モデルを用いる場合や，決定的な単語分割や入力記号付与などの既存手法に対する提案手法の優位性を示す．
