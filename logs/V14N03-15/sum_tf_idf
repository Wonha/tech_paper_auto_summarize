================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.74320] 本論文では，Web上の評判情報を有益に活用するために，レビューなどの評価文書をポジティブ（おすすめ）とネガティブ（おすすめしない）という極性値に分類する手法を提案する．
[i:3, score:0.58753] 全体評判情報の極性値は評価文書の極性値と一致すると考えられるため，まず全体評判情報を用いて評価文書を分類し，全体評判情報がない場合は部分評判情報を用いて分類する．
[i:6, score:0.58465] ここでは，評価文書の極性値とその中の部分評判情報の極性値が異なる場合にその部分評判情報は信頼性が高いと評価する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:15, score:0.60309] また，評判情報を含む評価文書を，ポジティヴ（おすすめ）とネガティヴ（おすすめしない）という2つの極性値に分類し，その結果をユーザに提示する．
[i:30, score:0.60620] そこで本論文では，評判情報を全体評判情報と部分評判情報という2つのレベルに分け，その極性値を基に評価文書を分類する手法を提案する．
[i:37, score:0.60349] 信頼性を評価する手法は多くのことが考えられるが，ここではその1つとして，評価文書の極値と異なる極性値を持つ部分評判情報は信頼性の高い情報と捉えることを提案する．

================================================================
[section type  : proposed_method]
[section title : 評判情報]
================================================================
[i:47, score:0.43755] また，全体評判情報と部分評判情報という評判情報の2つのレベルに関して述べる．
-----------------------------------------------------
  [subsection title : 評判情報と評価文書]
-----------------------------------------------------
  [i:lead, score:0.21234] Web上ではブログや掲示板あるいはレビュー等で映画の感想やある製品に関する評価が多く存在する．
.....
  [i:65, score:0.55376] また，（映画，映像，きれい）のようなすべての属性がある場合でも，映像に関する評判情報であるため，部分評判情報と捉える．
  [i:66, score:0.58623] 全体評判情報は対象全般に関する評価であるため，その極性値は評価文書の極性値と一致すると考えられる．
  [i:67, score:0.58709] 一方，部分評判情報は一属性に関する評価であるため，その極性値は評価文書の極性値と一致するとは限らない．

================================================================
[section type  : experiment_result]
[section title : 評価文書の分類]
================================================================
[i:73, score:0.28885] ここでは，評価文書をポジティブとネガティブに分類する手法を説明する．
[i:74, score:0.09878] まず，本手法での基本モデルとして用いるナイーブベイズ(NB)モデルついて述べる[CITE]．
[i:75, score:0.50509] 次に，2つのレベルの評判情報を用いた評価文書の分類手法を提案する．
-----------------------------------------------------
  [subsection title : ナイーブベイズモデル]
-----------------------------------------------------
  [i:lead, score:0.10636] 文書分類では単語の順序は必ずしも必要ではなく，文書中にどのような単語がどのような頻度で出現するかの情報で十分な場合が多い．
.....
  [i:84, score:0.15643] NBでは，あるトピック[MATH]を持つ文書[MATH]の各単語[MATH]の生起を統計的に独立と仮定しているため，独立性の定義から次の式が成り立つ，
  [i:89, score:0.15602] これがBOWモデルに基づく，文書のNBモデルである．
  [i:97, score:0.35082] NBモデルを用いて文書をポジティブとネガティブの2つのクラス[MATH]に分類する．
-----------------------------------------------------
  [subsection title : NB分類器の作成]
-----------------------------------------------------
  [i:lead, score:0.10607] 単語素性のNB分類器は次の手順で作られる．
.....
  [i:109, score:0.26122] そこで，評価対象を特徴づける対象名や属性名（映画ならば“映画”や“映像”など）と助詞—連体化や助詞—並立助詞，つまり“の”や“と”で繋がる名詞を[MATH]から抽出し，評価表現ではない可能性が高いので評価表現候補からは除外する（図[REF_fig:3.3]）．
  [i:113, score:0.24258] TF-IDFは単語を得点づけするアルゴリズムで，ポジティブである評価文書だけに頻出するような単語はTF-IDF値が大きくなる．
  [i:114, score:0.57641] 逆に，ポジティブにもネガティブにも出現するような評判情報はTF-IDF値が押さえられる．
-----------------------------------------------------
  [subsection title : 評価文書分類の提案モデル]
-----------------------------------------------------
  [i:lead, score:0.11297] ここでは，評価文書を分類するための提案モデルについて述べる．
.....
  [i:130, score:0.64514] なぜならば，全体評判情報の極性値は評価文書の極性値とほぼ一致するため，これを重視すると，この評価文書の極性値はポジティブであると予想されるからである．
  [i:131, score:0.56367] しかし，評判情報の単純な多数決ではこの評価文書はネガティブに分類される．
  [i:140, score:0.58684] 全体評判情報の極性値は評価文書の極性値とほぼ一致するため，評価文書を全体評判情報の極性値に基づき分類する．
-----------------------------------------------------
  [subsection title : 2つのレベルを考慮した評価文書の分類手法]
-----------------------------------------------------
  [i:lead, score:0.43487] 全体評判情報の分類器の作成手順を以下に示す．
.....
  [i:144, score:0.43487] 全体評判情報の分類器の作成手順を以下に示す．
  [i:149, score:0.15472] 単語素性に基づくNB分類器の評価候補単語リストの作成と同様に行う．
  [i:150, score:0.45599] [MATH]から対象候補と評価表現候補の組み合わせとのマッチングによる全体評判情報候補を作成

================================================================
[section type  : experiment_result]
[section title : 評価情報の信頼性評価]
================================================================
[i:169, score:0.63993] 前者のように，ポジティブな極性値を持つ評価文書において，ポジティブな部分評判情報はあまり情報としての価値はない．
[i:171, score:0.71843] しかし，後者は映画そのものはネガティブと捉えているが，映像に関してはポジティブに評価しているため，客観的でフェアな評判情報と考えられる．
[i:172, score:0.62946] このように，評価文書の極性値とは逆の評価を持つ部分評判情報は，他のものよりもフェアであると考えられる．
-----------------------------------------------------
  [subsection title : フェアな評判情報の抽出]
-----------------------------------------------------
  [i:lead, score:0.48565] 本節では，フェアな評判情報の抽出法について述べる．
.....
  [i:188, score:0.48565] 本節では，フェアな評判情報の抽出法について述べる．
  [i:189, score:0.55879] フェアな評判情報を抽出するためには，評価文書の分類と，それに含まれている評判情報の抽出およびその分類が必要である．
  [i:203, score:0.49271] このように作成された評判情報辞書を用いることで，分類対象の評価文書から評判情報を抜き出す．
-----------------------------------------------------
  [subsection title : フェアな評判情報の利用]
-----------------------------------------------------
  [i:lead, score:0.48817] 本手法によって得られた部分評判情報を評価対象毎，カテゴリ毎，ラベル（PpやNn）毎にカウントすることによって，表[REF_class]のような分類結果が得られる．
.....
  [i:204, score:0.48817] 本手法によって得られた部分評判情報を評価対象毎，カテゴリ毎，ラベル（PpやNn）毎にカウントすることによって，表[REF_class]のような分類結果が得られる．
  [i:207, score:0.42584] この表をユーザに提示することで評判情報が評価できる．
  [i:209, score:0.65956] しかし，フェアな評判情報であるPnとNpを考慮することで，カテゴリ1はポジティブが優勢であり，カテゴリ2はネガティブが優勢であると判断できる．

================================================================
[section type  : experiment_result]
[section title : 評価実験]
================================================================
[i:211, score:0.50068] また，抽出されたフェアな評判情報の有用性について評価する．
-----------------------------------------------------
  [subsection title : 実験設定]
-----------------------------------------------------
  [i:lead, score:0.03516] 実験に用いたデータはポータルサイト``Yahoo Japan''の``Yahoo Movie''から収集した．
.....
  [i:222, score:0.42758] また，評判情報に関する語は自立語に絞られるため，両手法共に素性には自立語のみを利用した．
  [i:224, score:0.52399] 全体評判情報の最初の対象候補単語リストとしては，映画，作品，ムービーを用いた．
  [i:225, score:0.53929] 部分評判情報の最初の候補単語リストは，映像，CG，画面，音楽，ミュージック，曲，演出，ステージング，脚色，配役，キャスティング，キャスト，物語，ストーリー，話を用いた．
-----------------------------------------------------
  [subsection title : 全体評判情報による分類評価]
-----------------------------------------------------
  [i:lead, score:0.50584] ここでは，全体評判情報が実際に評価文書分類に有用であるかの評価のために，全体評判情報を人手で抽出し，全体評判情報と評価文書の評価がどの程度一致するかを調べた．
.....
  [i:231, score:0.62830] 500のレビューを人手で評価した結果，全体評判情報は178のレビューに含まれており，そのうち162のレビューでは全体評判情報と評価文書の極性値が一致した．
  [i:233, score:0.51569] したがって，全体評判情報によって逆の極性値を取るものはなかった．
  [i:236, score:0.55672] 更に，提案手法において全体評判情報がNBよりも高い精度で抽出できれば評価文書の分類精度が向上することが予測される．
-----------------------------------------------------
  [subsection title : 評価文書分類の実験結果]
-----------------------------------------------------
  [i:lead, score:0.10883] 評価文書分類の実験結果を表[REF_result]に示す．
.....
  [i:251, score:0.69128] このレビューでは，「とても面白かった」という全体評判情報によってポジティブな投稿であると本手法では判定しているが，NBモデルでは，それ以外の単語も考慮しているため，この影響でネガティブに分類された．
  [i:263, score:0.52718] これらの全体評判情報は極性値を決定するものではないが，分布の偏りによってはこのように全体評判情報の候補となる．
  [i:266, score:0.51744] ``「最高の映画」なんて書いている人がいるけど''のように逆の見地をとる投稿者の評判情報部分を引用していることがある．
-----------------------------------------------------
  [subsection title : フェアな評判情報の評価]
-----------------------------------------------------
  [i:lead, score:0.49406] ここでは，フェアな評判情報を評価する．
.....
  [i:269, score:0.59348] 映画の評判を多数決を用いて評価した場合とフェアな評判情報のみを用いて多数決を用いて評価した場合を比較し，どちらが世間的な評価に近いかを確認する．
  [i:280, score:0.58577] しかし，フェアな評判情報であるPnとNpを比較すると61対72となりネガティブの方が多くなる．
  [i:283, score:0.52372] このようにフェアな評判情報を用いることで，世間的な評価を抽出できる可能性を示唆した．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:285, score:0.50761] 本論文では，評判情報の2つのレベルを考慮した評価文書の分類手法を提案した．
[i:288, score:0.58981] また，評価文書の極性値と評判情報の極性値を利用することで，信頼性の高い情報を抽出するための一手法を提案した．
[i:289, score:0.64411] 評価文書の極性値とその中の評判情報の極値が異なる場合，その評判情報をフェアな評判情報であるとし，信頼性の高い情報とした．

