ここでは，評価文書をポジティブとネガティブに分類する手法を説明する．
まず，本手法での基本モデルとして用いるナイーブベイズ(NB)モデルついて述べる[CITE]．
次に，2つのレベルの評判情報を用いた評価文書の分類手法を提案する．
文書分類では単語の順序は必ずしも必要ではなく，文書中にどのような単語がどのような頻度で出現するかの情報で十分な場合が多い．
そこで，単語の順序を無視し，文書を単語の集合として捉えるBOW (bag-of--words)モデルが用いられる．
BOWモデルでは，1つの文書は形態素解析によって抜き出された単語リスト[MATH]と表現され，単語リスト[MATH]は文書と同一視される．
[MATH]は文書に含まれる単語で，各々は異なる単語とは限らない．
この考えに基づき，分類する文書（実際には単語リスト）を[MATH]とし，分類するための手がかりとなる学習コーパス（N個の学習用文書）[MATH]から形態素解析等の処理によって得られる単語リストを単語集合Wとする．
単語集合は[MATH]と表現する．
[MATH]は第[MATH]番目の単語でVは単語の総数を表す．
NBモデルではBOWモデルに従う．
NBでは，あるトピック[MATH]を持つ文書[MATH]の各単語[MATH]の生起を統計的に独立と仮定しているため，独立性の定義から次の式が成り立つ，
これはあるクラスを与えたときに文書[MATH]が生成される確率は，[MATH]の生成確率である[MATH]の乗算で算出できることを意味する．
次に単語頻度ベクトル[MATH]を導入する．
[MATH]は[MATH]が文書[MATH]に出現する回数を表す．
単語[MATH]ごとに整理すると，[MATH]が成り立つため，[MATH]式(1)は次のようになる．
これがBOWモデルに基づく，文書のNBモデルである．
[MATH]は未知のパラメータであるために学習する必要がある．
本研究では，NBのパラメータ学習に，事後分布最大化学習（MAP学習）を用いる．
MAP学習では，与えられた学習用コーパス[MATH]に対して，[MATH]の事後分布[MATH]を最大化するパラメータを最適としている．
MAP学習による[MATH]の推定値は次の式で表現できる．
ここで，[MATH]は[MATH]が[MATH]中に出現する頻度ベクトルである．
推定パラメータ[MATH]は一種の平滑化（スムージング）パラメータである．
[MATH]はW中の全ての単語が[MATH]中に出現する総回数に対する，[MATH]が[MATH]中に出現する数の割合となっている（図[REF_fig:3.2]）．
NBモデルを用いて文書をポジティブとネガティブの2つのクラス[MATH]に分類する．
各クラス毎に学習データ[MATH]から式(3)を利用して[MATH]が得られる．
クラスが未知の文書[MATH]に対して，クラス事後確率[MATH]を最大化するクラス[MATH]がベイズ誤り確率最小化の観点で最適なクラス分類となる．
ここで，[MATH]なので，[MATH]の最大化となる．
単語素性のNB分類器は次の手順で作られる．
学習データから評価表現候補単語リストの作成
NBモデルの作成
学習データ[MATH]には，極性値がラベル付けされたレビュー集合を用いる．
[MATH]から，評価表現の単語リストを抽出する．
このとき，評価表現候補は，形容詞—自立，動詞—自立，名詞—形容動詞語幹，名詞—サ変接続，副詞—一般，副詞—助詞類接続という品詞で絞り込んだ単語集合を抽出する．
これは評価表現をこれらの品詞にほぼ限定できるためである．
この段階では明らかに評価表現でない名詞を多く含んでいる．
そこで，評価対象を特徴づける対象名や属性名（映画ならば“映画”や“映像”など）と助詞—連体化や助詞—並立助詞，つまり“の”や“と”で繋がる名詞を[MATH]から抽出し，評価表現ではない可能性が高いので評価表現候補からは除外する（図[REF_fig:3.3]）．
また，明らかに評価表現にならない動詞も候補から外す．
これには“する”などのstop-wordと呼ばれるものが含まれる．
次に，評価表現候補をTF-IDFで得点づけする．
TF-IDFは単語を得点づけするアルゴリズムで，ポジティブである評価文書だけに頻出するような単語はTF-IDF値が大きくなる．
逆に，ポジティブにもネガティブにも出現するような評判情報はTF-IDF値が押さえられる．
この段階で，ポジティブとネガティブそれぞれに対して特徴的な語が数値として得られる（表[REF_fig:3.4]）．
ポジティブ，ネガティブそれぞれに特徴的な語を数値順でソートしたものの中で上位の単語だけを用いる．
これは，あまり数値が低いものは特徴的な単語でない可能性があるためである．
また，候補数に差があると，分類に偏りが出易くなるので，ポジティブとネガティブ，それぞれの候補数を合わせる．
本研究では，ポジティブとネガティブで候補数が少ない方の数に合わせた．
このようにして単語集合[MATH]が完成する．
さらに単語集合Wの[MATH]中における頻度ベクトル[MATH]を作成し，式(3)に基づき[MATH]と[MATH]を作成する．
ここでは，評価文書を分類するための提案モデルについて述べる．
NBモデルによる分類には，分類対象を評価文書にした場合には以下のような問題点がある．
問題点の1つは係り受けを扱えないことである．
例えば，「車がはやい」と「電池切れがはやい」のように，評価表現だけでなく，対象と評価表現，あるいは属性と評価表現の組でなければ，ポジティブとネガティブに正確に分類できない．
このため，係り受けを扱うことで分類精度が高められると期待できる．
もう1つの問題点は，全体評判情報と部分評判情報を同等に扱っていることである．
単なる多数決ではなく，レベルの違いを利用した分類手法が必要である．
例えば，（映画，[MATH],おもしろい）が1回，（[MATH],映像，荒い）が2回出現するような評価文書は一般的にはポジティブに分類される．
なぜならば，全体評判情報の極性値は評価文書の極性値とほぼ一致するため，これを重視すると，この評価文書の極性値はポジティブであると予想されるからである．
しかし，評判情報の単純な多数決ではこの評価文書はネガティブに分類される．
したがって，全体評判情報を重視すれば，評価文書の分類精度は向上すると期待できる．
評価文書を分類するための提案モデルには次の2つの新しい点がある．
全体評判情報と部分評判情報に分けて文書分類すること
係り受けの関係を扱うこと
提案モデルでは，次の2つの分類器を作成する．
1つは全体評判情報の分類器，もう1つはNB分類器である．
最初に全体評判情報分類器で分類を試みる．
この分類器では全体評判情報を抽出し，その極性値を求める．
全体評判情報の極性値は評価文書の極性値とほぼ一致するため，評価文書を全体評判情報の極性値に基づき分類する．
全体評判情報を含まない評価文書はこの分類噐では分類不可能であるため，このような評価文書は，単語素性のNB分類器を用いて分類する．
この手順により本手法では優先的に全体評判情報を用いて評価文書を分類する．
実際に全体評判情報として使われる素性は評判情報の3つ組の種類のうち（対象，[MATH],評価表現）となる．
全体評判情報の分類器の作成手順を以下に示す．
学習データ[MATH]から対象候補単語リストの作成
対象候補単語はその対象の特徴的な言葉に限定し，人手で設定する．
例えば，映画ならば``映画''，``作品''を用いる．
[MATH]から評価表現候補単語リストの作成
単語素性に基づくNB分類器の評価候補単語リストの作成と同様に行う．
[MATH]から対象候補と評価表現候補の組み合わせとのマッチングによる全体評判情報候補を作成
[MATH]から係り受けの関係にある2文節をすべて抽出し，対象候補と評価表現候補の組み合わせとマッチングしていく．
このようにして抜き出されたものを同じ組み合わせであるもの毎に集めて単語集合Wと単語集合の頻度ベクトルXを得る（図[REF_fig:3.5]）．
NBモデルの作成
[MATH]と[MATH]と式(3)から[MATH]と[MATH]を作成する．
ここでは，評価情報の信頼性を評価する一手法について述べる．
評判情報は主観的な意見であるために，その客観性は乏しく信頼性は低いという問題点がある．
このような信頼性の低い情報の中から比較的信頼性の高い情報を抽出できれば有益な情報となる．
人間は主に2つの信頼性評価方法を用いていると考えられる．
1つは，サイト名などの情報発信者や組織名などの情報を用いる方法である．
このような情報を元に情報の信頼性を評価する研究[CITE]があるが，サイトの信頼性が低いからといって全ての評判情報の信頼性が低いわけではない．
また，投稿者情報を用いることは匿名性の高さのために困難であることが多い．
もう1つの信頼性評価手法は，複数の情報の整合性から評価するものである．
これを利用した研究は単純に多数決をとることで客観性を与えるということ[CITE]しかなされていない．
本論文では，信頼性評価の一要素として評価文書と評判情報の極性値に基づく手法を提案する．
ここでは，評価文書の極性値とその中の部分評判情報の極性値が異なる場合にその部分評判情報は信頼性が高いと評価する．
例えば，「すごく面白い映画だった．
映像も素晴らしかった」と「はっきりいって最低の映画でした．
でも映像だけは良かったです」という評価文書について考える．
前者のように，ポジティブな極性値を持つ評価文書において，ポジティブな部分評判情報はあまり情報としての価値はない．
悪意のある見方をすれば，前者の評判情報は映画の宣伝とも捉えられる．
しかし，後者は映画そのものはネガティブと捉えているが，映像に関してはポジティブに評価しているため，客観的でフェアな評判情報と考えられる．
このように，評価文書の極性値とは逆の評価を持つ部分評判情報は，他のものよりもフェアであると考えられる．
この理由は以下の通りである．
対象全般に対する評価と属性に対する評価が同じになることが一般的であるが，あえて異なる極性値を持つ評価情報を書き込むことは情報としての価値が高い．
対象に関してポジティブな面とネガティブな面の両方が評価できているため，客観性が高い．
宣伝や熱狂的なファン，アンチファンの投稿は信頼性が低いが，このような情報を排除できる．
本論文では，このような情報をフェアな評判情報と呼ぶ．
このフェアな評判情報を抽出するためには，評価文書と評判情報の極性値も調べることが必要である．
つまり，評価文書を分類するタスクと，評価文書から評判情報を抜き出した後，各評判情報を分類するタスクの2つのタスクが必要である（図[REF_fig:3.1]）．
この2つのタスクの結果，部分評判情報は以下の4種類に分類される．
評価文書としてはポジティブ，部分評判情報としてはポジティブなもの(Pp)
評価文書としてはポジティブ，部分評判情報としてはネガティブなもの(Pn)
評価文書としてはネガティブ，部分評判情報としてはポジティブなもの(Np)
評価文書としてはネガティブ，部分評判情報としてはネガティブなもの(Nn)
フェアな評判情報はPnとNpということになる．
本論文では，このように評価文書を分類し，その中の評判情報を分類することでフェアな評判情報とそれ以外の評判情報を区別する．
このようにしてフェアな評判情報を抽出する．
本節では，フェアな評判情報の抽出法について述べる．
フェアな評判情報を抽出するためには，評価文書の分類と，それに含まれている評判情報の抽出およびその分類が必要である．
評価文書の分類に関しては，前章で提案した手法を用いる．
以下では評判情報の抽出とその分類について述べる[CITE]．
このタスクにおける評判情報とは部分評判情報を指すため，（[MATH],属性，評価表現）を抽出し，分類するタスクである．
このタスクのために，まず，評判情報辞書を作成する．
基本的な考え方は辞書にマッチする評判情報候補は評判情報であるというものである．
この手法を用いる理由は，既存の研究では様々な条件付けで評判情報候補を絞ることはできても，それが実際に評判情報であるかという分類は難しいとされているためである．
辞書の作成には，まず学習データ[MATH]から属性候補と評価表現候補を抽出することから始める．
属性候補に関しては，初期値として属性であると考えられる単語を10程度与える．
学習データ[MATH]中でそれらと助詞—連体化や助詞—並立助詞，つまり「の」や「と」で繋がる名詞を抽出する．
このように抜き出された名詞は，対象の属性である可能性が高いため初期値にこれを加え属性候補とする．
評価表現候補は，形容詞—自立，動詞—自立，名詞—形容動詞語幹，名詞—サ変接続，副詞—一般，副詞—助詞類接続という品詞で絞り込めるため，これらの品詞を候補とする．
このように抽出された属性候補と評価集合の全組み合わせに対して手動でポジティブとネガティブをラベル付けして，正事例として辞書に加える．
評価表現でないと判断した組み合わせは負事例として学習していく．
このように作成された評判情報辞書を用いることで，分類対象の評価文書から評判情報を抜き出す．
本手法によって得られた部分評判情報を評価対象毎，カテゴリ毎，ラベル（PpやNn）毎にカウントすることによって，表[REF_class]のような分類結果が得られる．
カテゴリとは属性のグループであり，映画のカテゴリでは映像・音楽・ストーリなどである．
このカテゴリと属性を一対多で対応させることで，カテゴリ毎，ラベル毎に集計する．
この表をユーザに提示することで評判情報が評価できる．
例えば，この表でのカテゴリ1，カテゴリ2はともに単なるポジティブとネガティブの多数決をとると，それぞれ100対100と145対145で同じとなる．
しかし，フェアな評判情報であるPnとNpを考慮することで，カテゴリ1はポジティブが優勢であり，カテゴリ2はネガティブが優勢であると判断できる．
評価文書分類においてNBモデルと提案手法の比較実験を行った．
また，抽出されたフェアな評判情報の有用性について評価する．
実験に用いたデータはポータルサイト``Yahoo Japan''の``Yahoo Movie''から収集した．
収集したデータは，最近公開されたメジャーな10タイトルにおいてそれぞれ最新の1000レビューを収集したものであり，合計10000レビューである．
これらのタイトルを選択したのは，レビュー数が十分であることと，実際に本手法を用いる際には比較的新しい情報を対象とすることが多いと考えたためである．
``Yahoo Movie''のレビューには，投稿者によって点数が5段階で付与されている．
本実験では得点が5点あるいは4点のレビューをポジティブとし，2点あるいは1点のものをネガティブとした．
3点または“得点なし”は中立とした．
表[REF_train]にデータの詳細な内訳を示す．
10回交差検定でNBモデルと提案手法の結果を比較した．
データの中から，1000レビュー，つまり1タイトル毎に評価データとし，残りのデータである9000レビューを訓練データとした．
比較の指標には精度と再現率を用いた．
また，評判情報に関する語は自立語に絞られるため，両手法共に素性には自立語のみを利用した．
また，否定語である“ない”に関しては，“自立語—ない”の形で扱っている．
全体評判情報の最初の対象候補単語リストとしては，映画，作品，ムービーを用いた．
部分評判情報の最初の候補単語リストは，映像，CG，画面，音楽，ミュージック，曲，演出，ステージング，脚色，配役，キャスティング，キャスト，物語，ストーリー，話を用いた．
ここでは，全体評判情報が実際に評価文書分類に有用であるかの評価のために，全体評判情報を人手で抽出し，全体評判情報と評価文書の評価がどの程度一致するかを調べた．
ここでの人手による全体評判情報の抽出は，「良かった」，「最悪」などの一単語で明確に評価が分かるものに限定し，「ちょっと．
．
．
」，「心に残る」などの分かりにくい表現は抽出に用いなかった．
500のレビューを人手で評価した結果，全体評判情報は178のレビューに含まれており，そのうち162のレビューでは全体評判情報と評価文書の極性値が一致した．
また，一致しなかった16のレビューに関しても，評価文書の評価値はすべて3点となっており，中立の評価となった．
したがって，全体評判情報によって逆の極性値を取るものはなかった．
全体評判情報が含まれている文書は全体の1/3以上であり，全体評判情報が一般的な情報であることがわかった．
以上のことから，全体評判情報が評価文書分類に有用であることが示唆された．
更に，提案手法において全体評判情報がNBよりも高い精度で抽出できれば評価文書の分類精度が向上することが予測される．
評価文書分類の実験結果を表[REF_result]に示す．
値は10回交差検定の平均値である．
P精度，P再現率とは，それぞれポジティブな評価文書に対する精度，再現率を表しており，N精度，N再現率，全体精度，全体再現率はそれぞれネガティブな評価文書と全評価文書に対する精度と再現率を表す．
人間がこの分類を行った場合，9割強の精度で分類できるが，完全には分類できないと思われる．
この理由は内容に関して述べているだけで評価につながる表現がないレビューやポジティブとネガティブの両方の評価が書いてあるが，結局全体としてどちらに評価したのかがわからない場合が挙げられる．
実験結果としては，提案モデルがNBモデルをすべての精度，再現率において上回った．
これは全体評判情報を用いて分類したためと考えられる．
本手法の方が正確に分類した例として「先日，見てきました．
とても面白かったです．
ですが，レンのお腹…．
あれはないかと…．
ちょっと失笑してしまいました．
もう少し役作りして欲しかったです．
」というレビューがある．
このレビューでは，「とても面白かった」という全体評判情報によってポジティブな投稿であると本手法では判定しているが，NBモデルでは，それ以外の単語も考慮しているため，この影響でネガティブに分類された．
しかしながら，全体の精度と再現率に関してはNBモデルと提案手法のt検定による有意差はなかった．
この原因は，明らかに全体情報でない候補に対して強い特徴づけをしていることが主として挙げられる．
本手法による全体評判情報の抽出精度は82%であり，全体評判情報をさらに高い精度で抽出する必要がある．
全体評判情報の抽出精度を上げるには辞書の拡充があげられるが，人手によるコストが大きくなる．
また，ネガティブな評価文書に関する性能の低さは，ポジティブと比べて，学習データが少ないことが原因として考えられる．
これは，学習データ数を揃えることで解決できそうであるが，ネガティブな評価文書数は表[REF_train]からもわかるように少なく，揃えることが容易ではない．
また，日本人の特徴である“否定的な事ははっきり言わない”ということを考えると，数を揃えるだけでは対処できない場合もある．
例えば「ちょっと…」のような表現がある．
分類誤りは，Yahooの得点とは逆の内容を書いている，ということを除けば以下のような例がある．
全体評判情報の候補リストに誤っているものが含まれている場合
例えば，（映画，[MATH],聞く）（映画，[MATH],感じる）などがネガティブな候補として上位となった．
これらの全体評判情報は極性値を決定するものではないが，分布の偏りによってはこのように全体評判情報の候補となる．
このリストを基に分類器を作成するため，分類精度を下げることになった．
他人のレビューを引用して否定している場合
``「最高の映画」なんて書いている人がいるけど''のように逆の見地をとる投稿者の評判情報部分を引用していることがある．
この問題に対処するためには，引用部分を見分ける必要がある．
ここでは，フェアな評判情報を評価する．
映画の評判を多数決を用いて評価した場合とフェアな評判情報のみを用いて多数決を用いて評価した場合を比較し，どちらが世間的な評価に近いかを確認する．
世間的な評価を完全に把握することは困難であるが，ここでは著者の1名が多くのレビューを読むことで世間的な評価を判断した．
実際のデータに対して本手法を適用し，評判情報を分類した．
評価データとしてどのように世間的に評価されているかがよく知られているため，``NANA''と``オペラ座の怪人''の2つの映画のレビューを用いた．
表[REF_result2]，表[REF_result3]にその分類結果を示す．
表中の数値はデータ中に含まれていたそれぞれのカテゴリの評判情報の数である．
NANAの分類結果を見てみると，音楽カテゴリにおいてPnに対してNpが多く，ポジティブである可能性が高いと考えられる．
オペラ座の怪人の音楽カテゴリにおいても同様のことが言える．
実際にこの両作品に関しては音楽的な評価が高かったと考えられるため，世間的な評価と一致している．
しかし，これらの結果は単純な多数決でも同様の結果が得られる．
NANAのストーリに注目すると，単純な多数決をとった場合，224対114となりポジティブの方が多い．
しかし，フェアな評判情報であるPnとNpを比較すると61対72となりネガティブの方が多くなる．
NANAのストーリは世間的には原作とのギャップから評価が低かったことを考えると，ネガティブとする方が妥当である．
これはフェアな評判情報のみを用いた場合と一致している．
このようにフェアな評判情報を用いることで，世間的な評価を抽出できる可能性を示唆した．
このように評判情報の分類結果を用いることで，評判情報の多様な解析が可能となる．
ここでは，評価文書をポジティブとネガティブに分類する手法を説明する．
まず，本手法での基本モデルとして用いるナイーブベイズ(NB)モデルついて述べる[CITE]．
次に，2つのレベルの評判情報を用いた評価文書の分類手法を提案する．
文書分類では単語の順序は必ずしも必要ではなく，文書中にどのような単語がどのような頻度で出現するかの情報で十分な場合が多い．
そこで，単語の順序を無視し，文書を単語の集合として捉えるBOW (bag-of--words)モデルが用いられる．
BOWモデルでは，1つの文書は形態素解析によって抜き出された単語リスト[MATH]と表現され，単語リスト[MATH]は文書と同一視される．
[MATH]は文書に含まれる単語で，各々は異なる単語とは限らない．
この考えに基づき，分類する文書（実際には単語リスト）を[MATH]とし，分類するための手がかりとなる学習コーパス（N個の学習用文書）[MATH]から形態素解析等の処理によって得られる単語リストを単語集合Wとする．
単語集合は[MATH]と表現する．
[MATH]は第[MATH]番目の単語でVは単語の総数を表す．
NBモデルではBOWモデルに従う．
NBでは，あるトピック[MATH]を持つ文書[MATH]の各単語[MATH]の生起を統計的に独立と仮定しているため，独立性の定義から次の式が成り立つ，
これはあるクラスを与えたときに文書[MATH]が生成される確率は，[MATH]の生成確率である[MATH]の乗算で算出できることを意味する．
次に単語頻度ベクトル[MATH]を導入する．
[MATH]は[MATH]が文書[MATH]に出現する回数を表す．
単語[MATH]ごとに整理すると，[MATH]が成り立つため，[MATH]式(1)は次のようになる．
これがBOWモデルに基づく，文書のNBモデルである．
[MATH]は未知のパラメータであるために学習する必要がある．
本研究では，NBのパラメータ学習に，事後分布最大化学習（MAP学習）を用いる．
MAP学習では，与えられた学習用コーパス[MATH]に対して，[MATH]の事後分布[MATH]を最大化するパラメータを最適としている．
MAP学習による[MATH]の推定値は次の式で表現できる．
ここで，[MATH]は[MATH]が[MATH]中に出現する頻度ベクトルである．
推定パラメータ[MATH]は一種の平滑化（スムージング）パラメータである．
[MATH]はW中の全ての単語が[MATH]中に出現する総回数に対する，[MATH]が[MATH]中に出現する数の割合となっている（図[REF_fig:3.2]）．
NBモデルを用いて文書をポジティブとネガティブの2つのクラス[MATH]に分類する．
各クラス毎に学習データ[MATH]から式(3)を利用して[MATH]が得られる．
クラスが未知の文書[MATH]に対して，クラス事後確率[MATH]を最大化するクラス[MATH]がベイズ誤り確率最小化の観点で最適なクラス分類となる．
ここで，[MATH]なので，[MATH]の最大化となる．
単語素性のNB分類器は次の手順で作られる．
学習データから評価表現候補単語リストの作成
NBモデルの作成
学習データ[MATH]には，極性値がラベル付けされたレビュー集合を用いる．
[MATH]から，評価表現の単語リストを抽出する．
このとき，評価表現候補は，形容詞—自立，動詞—自立，名詞—形容動詞語幹，名詞—サ変接続，副詞—一般，副詞—助詞類接続という品詞で絞り込んだ単語集合を抽出する．
これは評価表現をこれらの品詞にほぼ限定できるためである．
この段階では明らかに評価表現でない名詞を多く含んでいる．
そこで，評価対象を特徴づける対象名や属性名（映画ならば“映画”や“映像”など）と助詞—連体化や助詞—並立助詞，つまり“の”や“と”で繋がる名詞を[MATH]から抽出し，評価表現ではない可能性が高いので評価表現候補からは除外する（図[REF_fig:3.3]）．
また，明らかに評価表現にならない動詞も候補から外す．
これには“する”などのstop-wordと呼ばれるものが含まれる．
次に，評価表現候補をTF-IDFで得点づけする．
TF-IDFは単語を得点づけするアルゴリズムで，ポジティブである評価文書だけに頻出するような単語はTF-IDF値が大きくなる．
逆に，ポジティブにもネガティブにも出現するような評判情報はTF-IDF値が押さえられる．
この段階で，ポジティブとネガティブそれぞれに対して特徴的な語が数値として得られる（表[REF_fig:3.4]）．
ポジティブ，ネガティブそれぞれに特徴的な語を数値順でソートしたものの中で上位の単語だけを用いる．
これは，あまり数値が低いものは特徴的な単語でない可能性があるためである．
また，候補数に差があると，分類に偏りが出易くなるので，ポジティブとネガティブ，それぞれの候補数を合わせる．
本研究では，ポジティブとネガティブで候補数が少ない方の数に合わせた．
このようにして単語集合[MATH]が完成する．
さらに単語集合Wの[MATH]中における頻度ベクトル[MATH]を作成し，式(3)に基づき[MATH]と[MATH]を作成する．
ここでは，評価文書を分類するための提案モデルについて述べる．
NBモデルによる分類には，分類対象を評価文書にした場合には以下のような問題点がある．
問題点の1つは係り受けを扱えないことである．
例えば，「車がはやい」と「電池切れがはやい」のように，評価表現だけでなく，対象と評価表現，あるいは属性と評価表現の組でなければ，ポジティブとネガティブに正確に分類できない．
このため，係り受けを扱うことで分類精度が高められると期待できる．
もう1つの問題点は，全体評判情報と部分評判情報を同等に扱っていることである．
単なる多数決ではなく，レベルの違いを利用した分類手法が必要である．
例えば，（映画，[MATH],おもしろい）が1回，（[MATH],映像，荒い）が2回出現するような評価文書は一般的にはポジティブに分類される．
なぜならば，全体評判情報の極性値は評価文書の極性値とほぼ一致するため，これを重視すると，この評価文書の極性値はポジティブであると予想されるからである．
しかし，評判情報の単純な多数決ではこの評価文書はネガティブに分類される．
したがって，全体評判情報を重視すれば，評価文書の分類精度は向上すると期待できる．
評価文書を分類するための提案モデルには次の2つの新しい点がある．
全体評判情報と部分評判情報に分けて文書分類すること
係り受けの関係を扱うこと
提案モデルでは，次の2つの分類器を作成する．
1つは全体評判情報の分類器，もう1つはNB分類器である．
最初に全体評判情報分類器で分類を試みる．
この分類器では全体評判情報を抽出し，その極性値を求める．
全体評判情報の極性値は評価文書の極性値とほぼ一致するため，評価文書を全体評判情報の極性値に基づき分類する．
全体評判情報を含まない評価文書はこの分類噐では分類不可能であるため，このような評価文書は，単語素性のNB分類器を用いて分類する．
この手順により本手法では優先的に全体評判情報を用いて評価文書を分類する．
実際に全体評判情報として使われる素性は評判情報の3つ組の種類のうち（対象，[MATH],評価表現）となる．
全体評判情報の分類器の作成手順を以下に示す．
学習データ[MATH]から対象候補単語リストの作成
対象候補単語はその対象の特徴的な言葉に限定し，人手で設定する．
例えば，映画ならば``映画''，``作品''を用いる．
[MATH]から評価表現候補単語リストの作成
単語素性に基づくNB分類器の評価候補単語リストの作成と同様に行う．
[MATH]から対象候補と評価表現候補の組み合わせとのマッチングによる全体評判情報候補を作成
[MATH]から係り受けの関係にある2文節をすべて抽出し，対象候補と評価表現候補の組み合わせとマッチングしていく．
このようにして抜き出されたものを同じ組み合わせであるもの毎に集めて単語集合Wと単語集合の頻度ベクトルXを得る（図[REF_fig:3.5]）．
NBモデルの作成
[MATH]と[MATH]と式(3)から[MATH]と[MATH]を作成する．
ここでは，評価情報の信頼性を評価する一手法について述べる．
評判情報は主観的な意見であるために，その客観性は乏しく信頼性は低いという問題点がある．
このような信頼性の低い情報の中から比較的信頼性の高い情報を抽出できれば有益な情報となる．
人間は主に2つの信頼性評価方法を用いていると考えられる．
1つは，サイト名などの情報発信者や組織名などの情報を用いる方法である．
このような情報を元に情報の信頼性を評価する研究[CITE]があるが，サイトの信頼性が低いからといって全ての評判情報の信頼性が低いわけではない．
また，投稿者情報を用いることは匿名性の高さのために困難であることが多い．
もう1つの信頼性評価手法は，複数の情報の整合性から評価するものである．
これを利用した研究は単純に多数決をとることで客観性を与えるということ[CITE]しかなされていない．
本論文では，信頼性評価の一要素として評価文書と評判情報の極性値に基づく手法を提案する．
ここでは，評価文書の極性値とその中の部分評判情報の極性値が異なる場合にその部分評判情報は信頼性が高いと評価する．
例えば，「すごく面白い映画だった．
映像も素晴らしかった」と「はっきりいって最低の映画でした．
でも映像だけは良かったです」という評価文書について考える．
前者のように，ポジティブな極性値を持つ評価文書において，ポジティブな部分評判情報はあまり情報としての価値はない．
悪意のある見方をすれば，前者の評判情報は映画の宣伝とも捉えられる．
しかし，後者は映画そのものはネガティブと捉えているが，映像に関してはポジティブに評価しているため，客観的でフェアな評判情報と考えられる．
このように，評価文書の極性値とは逆の評価を持つ部分評判情報は，他のものよりもフェアであると考えられる．
この理由は以下の通りである．
対象全般に対する評価と属性に対する評価が同じになることが一般的であるが，あえて異なる極性値を持つ評価情報を書き込むことは情報としての価値が高い．
対象に関してポジティブな面とネガティブな面の両方が評価できているため，客観性が高い．
宣伝や熱狂的なファン，アンチファンの投稿は信頼性が低いが，このような情報を排除できる．
本論文では，このような情報をフェアな評判情報と呼ぶ．
このフェアな評判情報を抽出するためには，評価文書と評判情報の極性値も調べることが必要である．
つまり，評価文書を分類するタスクと，評価文書から評判情報を抜き出した後，各評判情報を分類するタスクの2つのタスクが必要である（図[REF_fig:3.1]）．
この2つのタスクの結果，部分評判情報は以下の4種類に分類される．
評価文書としてはポジティブ，部分評判情報としてはポジティブなもの(Pp)
評価文書としてはポジティブ，部分評判情報としてはネガティブなもの(Pn)
評価文書としてはネガティブ，部分評判情報としてはポジティブなもの(Np)
評価文書としてはネガティブ，部分評判情報としてはネガティブなもの(Nn)
フェアな評判情報はPnとNpということになる．
本論文では，このように評価文書を分類し，その中の評判情報を分類することでフェアな評判情報とそれ以外の評判情報を区別する．
このようにしてフェアな評判情報を抽出する．
本節では，フェアな評判情報の抽出法について述べる．
フェアな評判情報を抽出するためには，評価文書の分類と，それに含まれている評判情報の抽出およびその分類が必要である．
評価文書の分類に関しては，前章で提案した手法を用いる．
以下では評判情報の抽出とその分類について述べる[CITE]．
このタスクにおける評判情報とは部分評判情報を指すため，（[MATH],属性，評価表現）を抽出し，分類するタスクである．
このタスクのために，まず，評判情報辞書を作成する．
基本的な考え方は辞書にマッチする評判情報候補は評判情報であるというものである．
この手法を用いる理由は，既存の研究では様々な条件付けで評判情報候補を絞ることはできても，それが実際に評判情報であるかという分類は難しいとされているためである．
辞書の作成には，まず学習データ[MATH]から属性候補と評価表現候補を抽出することから始める．
属性候補に関しては，初期値として属性であると考えられる単語を10程度与える．
学習データ[MATH]中でそれらと助詞—連体化や助詞—並立助詞，つまり「の」や「と」で繋がる名詞を抽出する．
このように抜き出された名詞は，対象の属性である可能性が高いため初期値にこれを加え属性候補とする．
評価表現候補は，形容詞—自立，動詞—自立，名詞—形容動詞語幹，名詞—サ変接続，副詞—一般，副詞—助詞類接続という品詞で絞り込めるため，これらの品詞を候補とする．
このように抽出された属性候補と評価集合の全組み合わせに対して手動でポジティブとネガティブをラベル付けして，正事例として辞書に加える．
評価表現でないと判断した組み合わせは負事例として学習していく．
このように作成された評判情報辞書を用いることで，分類対象の評価文書から評判情報を抜き出す．
本手法によって得られた部分評判情報を評価対象毎，カテゴリ毎，ラベル（PpやNn）毎にカウントすることによって，表[REF_class]のような分類結果が得られる．
カテゴリとは属性のグループであり，映画のカテゴリでは映像・音楽・ストーリなどである．
このカテゴリと属性を一対多で対応させることで，カテゴリ毎，ラベル毎に集計する．
この表をユーザに提示することで評判情報が評価できる．
例えば，この表でのカテゴリ1，カテゴリ2はともに単なるポジティブとネガティブの多数決をとると，それぞれ100対100と145対145で同じとなる．
しかし，フェアな評判情報であるPnとNpを考慮することで，カテゴリ1はポジティブが優勢であり，カテゴリ2はネガティブが優勢であると判断できる．
評価文書分類においてNBモデルと提案手法の比較実験を行った．
また，抽出されたフェアな評判情報の有用性について評価する．
実験に用いたデータはポータルサイト``Yahoo Japan''の``Yahoo Movie''から収集した．
収集したデータは，最近公開されたメジャーな10タイトルにおいてそれぞれ最新の1000レビューを収集したものであり，合計10000レビューである．
これらのタイトルを選択したのは，レビュー数が十分であることと，実際に本手法を用いる際には比較的新しい情報を対象とすることが多いと考えたためである．
``Yahoo Movie''のレビューには，投稿者によって点数が5段階で付与されている．
本実験では得点が5点あるいは4点のレビューをポジティブとし，2点あるいは1点のものをネガティブとした．
3点または“得点なし”は中立とした．
表[REF_train]にデータの詳細な内訳を示す．
10回交差検定でNBモデルと提案手法の結果を比較した．
データの中から，1000レビュー，つまり1タイトル毎に評価データとし，残りのデータである9000レビューを訓練データとした．
比較の指標には精度と再現率を用いた．
また，評判情報に関する語は自立語に絞られるため，両手法共に素性には自立語のみを利用した．
また，否定語である“ない”に関しては，“自立語—ない”の形で扱っている．
全体評判情報の最初の対象候補単語リストとしては，映画，作品，ムービーを用いた．
部分評判情報の最初の候補単語リストは，映像，CG，画面，音楽，ミュージック，曲，演出，ステージング，脚色，配役，キャスティング，キャスト，物語，ストーリー，話を用いた．
ここでは，全体評判情報が実際に評価文書分類に有用であるかの評価のために，全体評判情報を人手で抽出し，全体評判情報と評価文書の評価がどの程度一致するかを調べた．
ここでの人手による全体評判情報の抽出は，「良かった」，「最悪」などの一単語で明確に評価が分かるものに限定し，「ちょっと．
．
．
」，「心に残る」などの分かりにくい表現は抽出に用いなかった．
500のレビューを人手で評価した結果，全体評判情報は178のレビューに含まれており，そのうち162のレビューでは全体評判情報と評価文書の極性値が一致した．
また，一致しなかった16のレビューに関しても，評価文書の評価値はすべて3点となっており，中立の評価となった．
したがって，全体評判情報によって逆の極性値を取るものはなかった．
全体評判情報が含まれている文書は全体の1/3以上であり，全体評判情報が一般的な情報であることがわかった．
以上のことから，全体評判情報が評価文書分類に有用であることが示唆された．
更に，提案手法において全体評判情報がNBよりも高い精度で抽出できれば評価文書の分類精度が向上することが予測される．
評価文書分類の実験結果を表[REF_result]に示す．
値は10回交差検定の平均値である．
P精度，P再現率とは，それぞれポジティブな評価文書に対する精度，再現率を表しており，N精度，N再現率，全体精度，全体再現率はそれぞれネガティブな評価文書と全評価文書に対する精度と再現率を表す．
人間がこの分類を行った場合，9割強の精度で分類できるが，完全には分類できないと思われる．
この理由は内容に関して述べているだけで評価につながる表現がないレビューやポジティブとネガティブの両方の評価が書いてあるが，結局全体としてどちらに評価したのかがわからない場合が挙げられる．
実験結果としては，提案モデルがNBモデルをすべての精度，再現率において上回った．
これは全体評判情報を用いて分類したためと考えられる．
本手法の方が正確に分類した例として「先日，見てきました．
とても面白かったです．
ですが，レンのお腹…．
あれはないかと…．
ちょっと失笑してしまいました．
もう少し役作りして欲しかったです．
」というレビューがある．
このレビューでは，「とても面白かった」という全体評判情報によってポジティブな投稿であると本手法では判定しているが，NBモデルでは，それ以外の単語も考慮しているため，この影響でネガティブに分類された．
しかしながら，全体の精度と再現率に関してはNBモデルと提案手法のt検定による有意差はなかった．
この原因は，明らかに全体情報でない候補に対して強い特徴づけをしていることが主として挙げられる．
本手法による全体評判情報の抽出精度は82%であり，全体評判情報をさらに高い精度で抽出する必要がある．
全体評判情報の抽出精度を上げるには辞書の拡充があげられるが，人手によるコストが大きくなる．
また，ネガティブな評価文書に関する性能の低さは，ポジティブと比べて，学習データが少ないことが原因として考えられる．
これは，学習データ数を揃えることで解決できそうであるが，ネガティブな評価文書数は表[REF_train]からもわかるように少なく，揃えることが容易ではない．
また，日本人の特徴である“否定的な事ははっきり言わない”ということを考えると，数を揃えるだけでは対処できない場合もある．
例えば「ちょっと…」のような表現がある．
分類誤りは，Yahooの得点とは逆の内容を書いている，ということを除けば以下のような例がある．
全体評判情報の候補リストに誤っているものが含まれている場合
例えば，（映画，[MATH],聞く）（映画，[MATH],感じる）などがネガティブな候補として上位となった．
これらの全体評判情報は極性値を決定するものではないが，分布の偏りによってはこのように全体評判情報の候補となる．
このリストを基に分類器を作成するため，分類精度を下げることになった．
他人のレビューを引用して否定している場合
``「最高の映画」なんて書いている人がいるけど''のように逆の見地をとる投稿者の評判情報部分を引用していることがある．
この問題に対処するためには，引用部分を見分ける必要がある．
ここでは，フェアな評判情報を評価する．
映画の評判を多数決を用いて評価した場合とフェアな評判情報のみを用いて多数決を用いて評価した場合を比較し，どちらが世間的な評価に近いかを確認する．
世間的な評価を完全に把握することは困難であるが，ここでは著者の1名が多くのレビューを読むことで世間的な評価を判断した．
実際のデータに対して本手法を適用し，評判情報を分類した．
評価データとしてどのように世間的に評価されているかがよく知られているため，``NANA''と``オペラ座の怪人''の2つの映画のレビューを用いた．
表[REF_result2]，表[REF_result3]にその分類結果を示す．
表中の数値はデータ中に含まれていたそれぞれのカテゴリの評判情報の数である．
NANAの分類結果を見てみると，音楽カテゴリにおいてPnに対してNpが多く，ポジティブである可能性が高いと考えられる．
オペラ座の怪人の音楽カテゴリにおいても同様のことが言える．
実際にこの両作品に関しては音楽的な評価が高かったと考えられるため，世間的な評価と一致している．
しかし，これらの結果は単純な多数決でも同様の結果が得られる．
NANAのストーリに注目すると，単純な多数決をとった場合，224対114となりポジティブの方が多い．
しかし，フェアな評判情報であるPnとNpを比較すると61対72となりネガティブの方が多くなる．
NANAのストーリは世間的には原作とのギャップから評価が低かったことを考えると，ネガティブとする方が妥当である．
これはフェアな評判情報のみを用いた場合と一致している．
このようにフェアな評判情報を用いることで，世間的な評価を抽出できる可能性を示唆した．
このように評判情報の分類結果を用いることで，評判情報の多様な解析が可能となる．
