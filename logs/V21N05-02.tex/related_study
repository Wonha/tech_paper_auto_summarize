関連研究


自然言語処理における領域適応は，帰納学習手法を利用する全てのタスクで生じる問題であるために，
その研究は多岐にわたる．
利用手法をおおまかに分類すると，ターゲット領域のラベル付きデータを利用するかしないかで分類できる．
利用する場合を教師付き領域適応手法，利用しない場合を教師なし領域適応手法と呼ぶ．
提案手法は教師なし領域適応手法の範疇に入るので，
ここでは教師なし領域適応手法を中心に関連研究を述べる．

領域適応の問題は，一般の教師付き学習手法における訓練事例のスパース性の問題だと
捉えることもできる．そのためターゲット領域のデータにラベルを付与しないという条件では，
半教師付き学習\cite{chapelle2006semi}が教師なし領域適応手法として使えることは明らかである．
ただし半教師付き学習では大量のラベルなしデータを必要とする．
半教師付き学習を WSD に利用する場合，対象単語毎に用例を集める必要があり，
しかもターゲット領域のコーパスは新規であることが多いため，
対象単語毎の用例を大量に集めることは困難である．
このため WSD の領域適応の場合，半教師付き学習を利用しようとすれば，
Transductive 学習\cite{joachims1999transductive}に近い形となるが，
ソース領域とターゲット領域が異なる領域適応の形に 
Transductive 学習が利用できるかどうかは明らかではない．

WSD の領域適応をタスクとした教師なし領域適応の研究としては，
論文\cite{shinnou-gengo-13}の研究がある．そこでの基本的なアイデアは WSD で使うシソーラスを
ターゲット領域のコーパスから構築することであるが，
WSD で使うシソーラスが分野依存になっているかどうかは明らかではない\cite{shinnou-jws5}
\footnote{この論文\cite{shinnou-gengo-13}は本論文と同じタスクに対して，一部同じデータを用いた
実験結果を示しているため，考察において提案手法との比較を行う．}．
また Chan はターゲット領域上の語義分布を EM アルゴリズムで推定している
\cite{chan2005word,chan2006estimating}．
これも教師なし領域適応手法であるが，本論文で扱う領域適応では
語義分布の違いは顕著ではなく，効果が期待できない．

本論文は，WSD の領域適応では共変量シフトの仮定が成立していると考え，
共変量シフト下の学習を利用する．共変量シフト下の学習を領域適応に応用した研究としては
Jiang の研究\cite{jiang2007instance}と齋木の研究\cite{saiki-2008-03-27}がある．
Jiang は確率密度比を手動で調整し，モデルにはロジステック回帰を用いている．
また齋木は$P_S({\bm x})$と$P_T({\bm x})$を unigram でモデル化することで確率密度比を推定し，
モデルには最大エントロピー法を用いている．
ただしどちらの研究もタスクは WSD ではない．しかもターゲット領域の
ラベル付きデータを利用しているために，教師なし領域適応手法でもない．
また新納は WSD の領域適応に共変量シフト下の学習を用いているが\cite{shinnou-gengo-14}，
そこではDaum{\'e} が提案した素性空間拡張法 (Feature Augmentation)\cite{daume0}を
組み合わせて利用しているために，これも教師なし領域適応手法ではない．

一方，共変量シフト下の学習は，事例への重み付き学習の一種である．
Jiang は識別精度を悪化させるようなデータを
Misleading データとして訓練データから取り除いて学習することを試みた\cite{jiang2007instance}．
これは Misleading データの重みを 0 にした学習と見なせるため，この手法も重み付き学習手法と見なせる．
吉田はソース領域内の訓練データ${\bm x}$がターゲット領域から見て外れ値と見なせた場合，
${\bm x}$をMisleading と判定し，それらを訓練データから取り除いて学習している\cite{yoshida}．
これは WSD の教師なし領域適応手法であるが，
Misleading データの検出は困難であり，精度の改善には至っていない．
また WSD の領域適応をタスクとした古宮の手法\cite{komiya-nenji2013}も重み付き学習と見なせる．
そこでは複数のソース領域のコーパスを用意し，そこから訓練事例をランダムに選択し，
選択された訓練データセットの中で，ターゲット領域のテストデータを識別するのに
最も適した訓練データセットを選ぶ．これは全ソース領域のコーパスの訓練データから
選択された訓練データの重みを 1，それ以外を重み 0 としていることを意味する．
ただし複数のソース領域のコーパスから対象単語のラベル付き訓練データを集めるのは
実際は困難である．また古宮は上記の研究以外にも 
WSD の領域適応の研究\cite{komiya3,komiya2,komiya-nlp2012}を行っているが，
これらは教師付き学習手法となっている．


