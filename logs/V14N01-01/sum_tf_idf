================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.09770] 日本語係り受け解析を行なう新しいアルゴリズムを述べる．
[i:1, score:0.13593] このアルゴリズムによれば，トップレベルの精度を落とすことなく線形時間で係り受け解析が行なえる．
[i:4, score:0.11353] 改良された係り関係のモデルと提案手法を組み合わせると，京大コーパスVersion 2に対して従来手法よりもよい精度が得られた．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:9, score:0.12311] 本研究の目的は，日本語の係り受け解析(依存構造解析)を行なう効率のよいアルゴリズムを提案し，その効率の良さを理論的，実験的の両面から示すことである．
[i:10, score:0.11882] 本論文では，日本語係り受け解析の線形時間アルゴリズムを示す．
[i:17, score:0.10162] 次に，第5節で，二つの文節の依存関係を推定するための改良したモデルを述べる．

================================================================
[section type  : proposed_method]
[section title : 日本語文の解析]
================================================================
[i:20, score:0.02107] 本節では，日本語の構文的特徴と典型的な日本語文の解析の手順について整理する．
-----------------------------------------------------
  [subsection title : 日本語の構文的特徴]
-----------------------------------------------------
  [i:lead, score:0.00791] 日本語は基本的にはSOV言語である．
.....
  [i:29, score:0.10995] 文節をこのように定義することによって，ドイツ語のような屈折言語において文中の語の文法的役割を分析するときと似た手法を日本語文を分析するときにも使うことができる．
  [i:34, score:0.11260] この2例文で，最も右の文節「あげた」(動詞の語幹と，過去や完了を表すマーカで構成されている)は文の末尾に置かれていることに注意されたい．
  [i:37, score:0.14541] \TermHead{}となる文節は，必ず係り元の文節の右側に位置する．
-----------------------------------------------------
  [subsection title : 日本語文解析の典型的な手順]
-----------------------------------------------------
  [i:lead, score:0.01740] 日本語には前節のような特徴があるので，日本語文の解析では次のような手順が非常に一般的である:
.....
  [i:42, score:0.07414] それらを文節にまとめ上げる
  [i:43, score:0.12663] 文節間の係り関係を解析する
  [i:45, score:0.08017] 我々は(3)における係り受け解析に焦点を置く．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:56, score:0.16645] Sekineら[CITE]は最大エントロピー法(Maximum Entropy Modeling; ME)を係り受けの確率の推定に使い，後方ビームサーチ(文末から文頭に向かうビームサーチ)で最もよい解析結果を見つける．
[i:64, score:0.18765] このアルゴリズムは，考慮する係り先の文節数を制限することでしらみつぶしに探索することを避け，[MATH]の時間計算量となっている．
[i:67, score:0.21792] 2文節間の係り受けの確率を用いない別の興味深い手法は，KudoとMatsumoto [CITE]によるCascaded Chunking Modelである．

================================================================
[section type  : proposed_method]
[section title : アルゴリズム]
================================================================
[i:74, score:0.07045] 解析時のアルゴリズム，その時間計算量，学習時のアルゴリズムを順に述べ，最後に提案アルゴリズムの特徴のまとめと関連研究との理論的な比較を述べる．
-----------------------------------------------------
  [subsection title : 文を解析するアルゴリズム]
-----------------------------------------------------
  [i:lead, score:0.14597] 我々の提案する係り受け解析のアルゴリズムの擬似コードを図 [REF_code:analysis]に示す．
.....
  [i:95, score:0.23329] 2回目のiterationでは，1をスタックから降ろし，1番目の文節と2番目の文節(あの)の係り関係をチェックする．
  [i:97, score:0.23202] 3回目のiterationでは，2をスタックから降ろし，2番目の文節と3番目の文節(本を)の係り関係をチェックする．
  [i:101, score:0.21032] 次に，1をスタックから降ろし，1番目の文節と3番目の文節の係り関係をチェックする．
-----------------------------------------------------
  [subsection title : 時間計算量]
-----------------------------------------------------
  [i:lead, score:0.09755] 一見したところ，提案したアルゴリズムの時間計算量の上限は，2重ループを含むため[MATH]と思える．
.....
  [i:115, score:0.09755] 一見したところ，提案したアルゴリズムの時間計算量の上限は，2重ループを含むため[MATH]と思える．
  [i:117, score:0.14322] 時間計算量の上限が[MATH]であることを，図[REF_code:analysis]におけるwhileループの条件部が何回実行されるかを考えることによって示す．
  [i:126, score:0.13379] 文節[MATH]それぞれについて，outdep[[MATH]] [MATH]は必ず一度だけ実行される．
-----------------------------------------------------
  [subsection title : 訓練事例を作り出すアルゴリズム]
-----------------------------------------------------
  [i:lead, score:0.08485] 前節のアルゴリズムで用いる分類器のための訓練事例を作り出すには，図[REF_code:generate]に示すアルゴリズムを使う．
.....
  [i:132, score:0.08485] 前節のアルゴリズムで用いる分類器のための訓練事例を作り出すには，図[REF_code:generate]に示すアルゴリズムを使う．
  [i:133, score:0.07156] 図[REF_code:analysis]にある解析用のアルゴリズムと殆ど同じである．
  [i:134, score:0.14577] 違いは，indep[ ]を使ってestimate_dependency()が正しい係り関係の判定を返す点と，outdep[ ]に係り先のIDを格納する必要がない点である．
-----------------------------------------------------
  [subsection title : 特徴のまとめと関連研究との理論的な比較]
-----------------------------------------------------
  [i:lead, score:0.03688] 我々の提案アルゴリズムは次のような特徴を持つ:
.....
  [i:152, score:0.10661] 彼のアルゴリズムも，スタックを用いており，時間計算量の上限も[MATH]である．
  [i:153, score:0.12502] ただし，我々のアルゴリズムが日本語を対象とし，係り先が必ず右にあることを前提にしているのに対し，Nivreのアルゴリズムは依存関係の向きはどちらでもよい．
  [i:159, score:0.11260] これらの簡潔さの理由は，日本語が制約C2 (第[REF_sec:prop]節参照)を仮定できること，文脈自由文法の解析ではなく，係り受け関係のみの解析であることの二つによる．

================================================================
[section type  : proposed_method]
[section title : 係り関係を推定するためのモデル]
================================================================
[i:160, score:0.18338] 2文節間の係り関係を推定するために，2文節に関係する形態的，文法的情報を素性のベクタとして表現し，それを入力として分類器に係るか否かを判断させる．
[i:167, score:0.18765] 実際には2文節間の係り関係の推定の処理は，図[REF_code:analysis]のestimate_dependency()の中で行なう．
[i:168, score:0.14952] 推定しようとする2文節の形態的，文法的情報を素性のベクタとして表現し，SVMsに係るか否かを判定させることになる．
-----------------------------------------------------
  [subsection title : 標準素性]
-----------------------------------------------------
  [i:lead, score:0.03899] ここで「標準素性」といっているものは，[CITE]でほぼ共通に使われている素性セットを指す．
.....
  [i:177, score:0.10488] ここで主辞とは，概ね文節内の最も右の内容語に相当する．
  [i:179, score:0.10821] 語形とは，概ね文節内の最も右の機能語に相当する．
  [i:181, score:0.09671] これらに加えて，2文節間のギャップに関する素性も用いた．
-----------------------------------------------------
  [subsection title : 注目文節の前後の文節]
-----------------------------------------------------
  [i:lead, score:0.13568] 注目している係り元文節，係り先文節の前後の文節も有用である．
.....
  [i:185, score:0.17139] 第[MATH]番目の文節が係り元文節で，第[MATH]番目の文節が係り先文節の候補だとする．
  [i:187, score:0.17173] 我々のアルゴリズムでは，[MATH]を満たし[MATH]番目の文節が[MATH]番目の文節に係るかチェックしているとき，[MATH]番目の文節は必ず[MATH]番目の文節に係っていることに注意されたい．
  [i:189, score:0.17198] なお，[MATH]番目の文節が[MATH]番目の文節に係るかどうかはoutdep[ ]を見れば簡単にチェックできる．
-----------------------------------------------------
  [subsection title : 文節内の追加素性]
-----------------------------------------------------
  [i:lead, score:0.12448] 「標準素性」では，文節内に二つ以上の機能語を含むとき格助詞の情報を見落とすことがある．
.....
  [i:198, score:0.13699] それは，係り先候補の文節の最も左の語の情報である．
  [i:199, score:0.14284] この語は係り元の文節の最も右の語と慣用表現のような強い相関関係を持つことも多い．
  [i:200, score:0.16429] これに加えて，係り先候補文節の直後の文節の表層形も素性として使う．
-----------------------------------------------------
  [subsection title : 並列句のための素性]
-----------------------------------------------------
  [i:lead, score:0.02726] 並列構造を正しく認識することは，長い文を正しく解析する際に最も難しいことの一つである．
.....
  [i:206, score:0.11976] 注目している文節がキー文節(distinctive key bunsetsu) [CITE]であるとき，この二つの素性は使われる．
  [i:207, score:0.16114] 一つ目の素性は，係り元文節がキー文節であるときアクティブになるものである．
  [i:208, score:0.18900] もう一つの素性は，係り元文節がキー文節で，その係り元文節と係り先候補の文節の主辞表層形が一致していればアクティブになるものである．

================================================================
[section type  : experiment_result]
[section title : 実験と考察]
================================================================
[i:210, score:0.11344] 提案アルゴリズムを利用したパーザをC++で実装し，その時間計算量の振る舞いや解析精度を実験的に評価した．
-----------------------------------------------------
  [subsection title : コーパス]
-----------------------------------------------------
  [i:lead, score:0.07317] 提案アルゴリズムを評価するために，京大コーパスVersion 2 [CITE]を使った．
.....
  [i:211, score:0.07317] 提案アルゴリズムを評価するために，京大コーパスVersion 2 [CITE]を使った．
  [i:212, score:0.02845] 新聞記事の1月1日から1月8日分(7,958文)を訓練事例とし，1月9日分(1,246文)をテスト事例とした．
  [i:213, score:0.00970] 1月10日分を開発用に用いた．
-----------------------------------------------------
  [subsection title : SVM の設定]
-----------------------------------------------------
  [i:lead, score:0.03432] 独自にC++で実装したSVMsのツールを用いた．
.....
  [i:215, score:0.03432] 独自にC++で実装したSVMsのツールを用いた．
  [i:216, score:0.03023] カーネルとして，3次の多項式カーネルを用いた．
  [i:217, score:0.00672] 特に記述がない限り誤分類のコストは1に設定した．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, score:0.08317] 解析精度テスト事例に対する我々のパーザの性能を表[REF_tbl:acc]に示す．
.....
  [i:220, score:0.15953] 係り受け正解率とは，正しく解析された係り受けの割合であり(他の多くの文献と同様，文末の一文節を除く)，文正解率とは，全ての係り関係が正しく解析された文の割合である．
  [i:222, score:0.14402] 実際，この係り受け正解率は動的素性を用いないときのCascaded Chunking Model [CITE]とほぼ同じである．
  [i:223, score:0.16218] 第[REF_sec:models]節で述べた全ての素性を用いた場合，我々のパーザは89.56%の係り受け正解率を得た．
-----------------------------------------------------
  [subsection title : 関連研究との比較]
-----------------------------------------------------
  [i:lead, score:0.08623] 我々のパーザと関連研究におけるパーザとを時間計算量と精度の点から比較する．
.....
  [i:252, score:0.22375] 文献[CITE]では，「相対モデル」のパーザは，京大コーパスVersion 3.0に対して，係り受け正解率91.37%を得，Cascaded Chunking Modelは91.23%を得たと報告されている．
  [i:253, score:0.16851] 我々のパーザは，京大コーパスVersion 2において，Cascaded Chunking Modelの精度を0.27ポイント上回っていることを考えると，我々のパーザと「相対モデル」パーザとの差も大きなものではないと判断できる．
  [i:256, score:0.19870] 係り元の文節の語形の情報と，係り先候補(5つまで)の主辞の情報から，係り先を一つに決める決定的有限状態変換器を用いている．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:260, score:0.13183] 我々は線形時間で処理を行なう日本語係り受け解析のアルゴリズムを提案した．
[i:263, score:0.14649] 精度の差は従来研究で報告されているものと大きくないため，精度面からの優位性は結論できないが，本研究で(1)提案アルゴリズムが理論的にも実験的にも時間計算量の上限が[MATH]で抑えられていることと，(2)時間計算量を抑え，左から右へ一度しかスキャンしないにも関わらずトップレベルの精度が得られることの二つを示せた意義は大きいと考える．
[i:264, score:0.17310] 後方の文節を直接考慮しない提案アルゴリズムに一定の限界があることは明らかであるが，係り先として考慮する文節の数を増やしても精度が向上するとは限らず，その解決は単純ではない．

