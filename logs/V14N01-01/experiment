実験と考察
提案アルゴリズムを利用したパーザを C++ で実装し，その時間計算量の振る
舞いや解析精度を実験的に評価した．
\subsection{コーパス}
提案アルゴリズムを評価するために，京大コーパス 
Version 2 \cite{Kurohashi1998} を使った．
新聞記事の1月1日から1月8日分 (7,958 文) を訓練事例とし，1月9日分 (1,246 文) を
テスト事例とした．
1月10日分を開発用に用いた．
これらの記事の使い方は \cite{Uchimoto1999,Sekine2000Backward,Kudo2002} と
同じである．

\subsection{SVM の設定}
独自に C++ で実装した SVMs のツールを用いた．
カーネルとして，3 次の多項式カーネルを用いた．
特に記述がない限り誤分類のコストは 1 に設定した．

\subsection{実験結果}\label{subsec:results}

\begin{table}[b]
\caption{テスト事例に対する精度}
\label{tbl:acc}
\begin{center}
\begin{tabular}{lcc} \hline\hline
         & 係り受け正解率 (\%) & 文正解率 (\%) \\ \hline
標準素性 & 88.72        & 45.88 \\
全て     & 89.56 & 48.35 \\
前後文節素性 (5.2~節) なし & 88.91 & 46.33 \\
文節内追加素性 (5.3~節) なし  & 89.19 & 47.05 \\
並列句素性 (5.4~節) なし & 89.41 & 47.86 \\
\hline
\end{tabular}
\end{center}
\end{table}

{\bf 解析精度}\hspace{0.4em}
テスト事例に対する我々のパーザの性能を表~\ref{tbl:acc} に示す．
従来研究との比較のために，性能評価には京大コーパスで標準的に使われる
尺度である係り受け正解率と文正解率の二つを用いる．
係り受け正解率とは，正しく解析された係り受けの割合であり
(他の多くの文献と同様，文末の一文節を除く)，
文正解率とは，全ての係り関係が正しく解析された文の割合である．


「標準素性」を用いた場合の精度は比較的よい．
実際，この係り受け正解率は動的素性を用いないときの Cascaded Chunking
Model \cite{Kudo2002} とほぼ同じである．
第~\ref{sec:models} 節で述べた全ての素性を用いた場合，
我々のパーザは 89.56\% の係り受け正解率を得た．
これは京大コーパス Version 2 に対して公表されている精度の中で最もよい
ものである．

\begin{figure}[t]
\begin{center}
    \includegraphics[scale=1.2]{speed-j02.eps}
\end{center}
\caption{一文あたりの処理時間}
\label{speed}
\end{figure}

{\bf 時間計算量の漸近的な振る舞い}\hspace{0.4em}
図~\ref{speed} に，我々のパーザのテスト事例に対する実行時間を示す．これは
ワークステーション (Ultra SPARC II 450 MHz, 1GB メモリ) を用いて計測した．
図~\ref{speed} より実行時間の上限が文の長さに比例しているのが分かる．
これは，第~\ref{subsec:time} 節で行なった理論的な分析と一致している．

この実験結果を見て，確かに従来研究よりも時間計算量の上限は
低く抑えられているが，我々のパーザの実際の処理時間はそれほど速くない
と思われるかもしれない．
パーザのこの遅さの主たる原因は，SVMs におけるカーネル評価での
膨大な計算のせいである．
我々の実験では，SVM の分類器は 4 万個以上のサポートベクタを持っている．
それゆえ，係り関係を判定するたびに膨大な内積計算が必要となる．
幸い，この問題に対する解決策は既に Kudo と Matsumoto \shortcite{Kudo2003} に
よって与えられている．
彼らは高次の多項式カーネルを線形カーネルに変換する手法を提案し，
変換された線形カーネルでは，精度を保ったまま元の多項式カーネルよりも
およそ 30 から 300 倍高速だったと報告している．
彼らの手法を我々のパーザに適用すれば，処理時間も十分高速化されるだろう．

彼らの手法を用いればどのくらい我々のパーザの速度が改善されるか
粗く見積もるために，線形カーネルを用い，同じテスト事例に対してパーザを
走らせてみた．
図~\ref{speed:lin} に，線形カーネルを用いたパーザの処理時間を示す．なお
計測には多項式カーネルを用いた場合と同じマシンを使った．
3次の多項式カーネルを使う場合に比べて相当に高速である．
非常に長い文であっても 0.02 秒以内で
解析が行なえている．
加えて，このパーザのスピードばかりでなく精度も我々が期待した以上だった．
係り受け正解率は 87.36\%，文正解率は 40.60\% に達した．
これらの精度は，素性の組合せを人手で選択して追加している
パーザ \cite{Uchimoto1999} よりもわずかに良い．

\begin{figure}[t]
\begin{center}
    \includegraphics[scale=1.2]{speed-lin-j02.eps}
\end{center}
\caption{線形カーネルを使った場合の一文あたりの処理時間．
誤分類のコストは 0.0056．}\label{speed:lin}
\end{figure}


\subsection{関連研究との比較}\label{sec:relatedwork}

我々のパーザと関連研究におけるパーザとを時間計算量と精度の点から比較する．
比較のサマリを表~\ref{tbl:comp} に示す．
我々のアルゴリズムと SVMs と組み合わせたものが時間計算量の点から
優れた性質を持ち，加えてトップレベルの精度が得られている．

    \begin{table}[t]
\caption{関連研究との性能の比較． KM02 = Kudo and Matsumoto 2002, KM00 = Kudo and Matsumoto 
\hspace*{27pt}2000, USI99 = Uchimoto et al. 1999, and Seki00 = Sekine 2000. 提案アルゴリズムを Stack
\hspace*{27pt}Dependency Analysis と記述．}
\label{tbl:comp}
\begin{center}
\begin{tabular}{l|l|c|c} \hline\hline
 & アルゴリズム/モデル & \multicolumn{1}{c|}{時間計算量}
   & 係り受け正解率 (\%) \\
\hline
本論文 & Stack Dependency Analysis (SVMs) & $n$ & 89.56 \\
           & Stack Dependency Analysis (linear SVMs) & $n$ & 87.36 \\ \hline
KM02 & Cascaded Chunking Model (SVMs) & $n^2$ & 89.29 \\
KM00 & 後方ビームサーチ (SVMs) & $n^2$ & 89.09 \\
USI99 & 後方ビームサーチ (ME) & $n^2$ & 87.14 \\
Seki00 & 決定的有限状態変換器 & $n$ & 77.97 \\ \hline
\end{tabular}
\end{center}
    \end{table}

文献 \cite{Kudo2002} との比較は，第~\ref{comp:theory} 
の記述にゆずる．
Uchimoto ら \shortcite{Uchimoto1999} は最大エントロピー法と
後方ビームサーチを用いている．
文献 \cite{Sekine2000Backward} によれば，解析時間は $n^{2}$ に比例する
とのことである．
これに対し，我々のパーザは線形時間で文を解析し，精度もよい．
工藤と松本 \cite{Kudo2005} の「相対モデル」のパーザ\footnote{
京大コーパス Version 2 に対する精度が不明なため，表~\ref{tbl:comp} に
はあげていない．}も，後方ビームサーチを用いているので，時間計算量という
点では Uchimoto らのパーザと同様である．
文献 \cite{Kudo2005} では，「相対モデル」のパーザは，京大コーパス 
Version 3.0 に対して，係り受け正解率 91.37\% を得，
Cascaded Chunking Model は 91.23\% を得たと報告されている．
我々のパーザは，京大コーパス Version 2 において，Cascaded Chunking
Model の精度を 0.27 ポイント上回っていることを考えると，我々のパーザと
「相対モデル」パーザとの差も大きなものではないと判断できる\footnote{
「相対モデル」が Cascaded Chunking Model よりも，長距離の文節間の係
り受け F 値が上回っている \cite{Kudo2005} ことは注目に値する．
我々の提案手法も Cascaded Chunking Model と同様，直後に係りやすいという性質
を利用しているため，「相対モデル」のほうが提案手法よりも長距離の文節間
の係り受け F 値がよい可能性が高い．
}．
また，我々と同様 Sekine \shortcite{Sekine2000Japanese} も線形時間で
処理が進む非常に高速なパーザを提案している．
彼の手法は，後方から係り先を決定していく．
係り元の文節の語形の情報と，係り先候補 (5つまで) の主辞の情報から，係
り先を一つに決める決定的有限状態変換器を用いている．
係り元の語形や5つの係り先候補の主辞の情報を細かく区別すると，
状態 (state) の数が多くなりすぎ，大量のメモリを消費するため，係り元の語形の状
態を40に，係り先の主辞の状態を18に限定している．
品詞や活用形の情報のみ利用している．
このため，精度が大きく犠牲になっている．

