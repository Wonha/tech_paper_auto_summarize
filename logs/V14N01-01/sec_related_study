ここでは，主に時間計算量に重点を置いて関連研究を述べる．
日本語はもちろん英語でも依存構造解析(dependency analysis)は研究されている[CITE]．
これらの論文の解析アルゴリズムでは，[MATH]の時間がかかる．
ここで[MATH]は単語数である[MATH]．
日本語の係り受け解析では，文中の二つの文節の係り受けの確率を使うことが非常に多かった．
Harunoら[CITE]は，決定木を用いて係り受けの確率を推定した．
FujioとMatsumoto [CITE]はCollinsのモデル[CITE]の修正版を日本語の係り受け解析に適用した．
Harunoらと，FujioとMatsumotoの両グループともCYK法を用いている．
これは[MATH]の時間がかかる．
ここで[MATH]は文の長さ，つまり文節数を表している．
Sekineら[CITE]は最大エントロピー法(Maximum Entropy Modeling; ME)を係り受けの確率の推定に使い，後方ビームサーチ(文末から文頭に向かうビームサーチ)で最もよい解析結果を見つける．
このビームサーチのアルゴリズムは[MATH]の時間がかかる．
KudoとMatsumoto [CITE]らも同じ後方ビームサーチをMEではなくサポートベクタマシン(SVMs)とともに用いている．
二つの文節間の係り受けの確率を使わない統計的手法も少ないながらある．
一つはSekineの決定的有限状態変換器を用いる手法[CITE]である．
Sekineは，\TermHead{}の場所の97%は文中の五つの候補でカバーされると報告している．
似た現象はMaruyamaとOgino [CITE]も観測している．
これらの調査にもとづき，Sekineは，決定的有限状態変換器を用いる効率のよい解析アルゴリズムを提案している．
このアルゴリズムは，考慮する係り先の文節数を制限することでしらみつぶしに探索することを避け，[MATH]の時間計算量となっている．
しかしながら，彼のパーザは京大コーパスに対して77.97%の係り受け正解率(定義は第[REF_subsec:results]節で述べる)しか得られていない．
これは，89%を超える現在の最高精度よりもかなり低い．
2文節間の係り受けの確率を用いない別の興味深い手法は，KudoとMatsumoto [CITE]によるCascaded Chunking Modelである．
このモデルは[CITE]のアイデアにもとづく．
彼らはこのモデルとSVMsを用いて，89.29%を得ている．
彼らの手法では，解析時に評価される係り関係の数はCYK法や後方ビームサーチよりも相当少ないが，それでも時間計算量の上限は[MATH]である．
以上見たように，高い精度を保ちつつ線形時間の処理を保証して，どのように日本語係り受け解析を行なうかは，まだ解決されていない問題である．
以下に記述するアルゴリズムがこの問題に対する答えとなろう．
ここでは，主に時間計算量に重点を置いて関連研究を述べる．
日本語はもちろん英語でも依存構造解析(dependency analysis)は研究されている[CITE]．
これらの論文の解析アルゴリズムでは，[MATH]の時間がかかる．
ここで[MATH]は単語数である[MATH]．
日本語の係り受け解析では，文中の二つの文節の係り受けの確率を使うことが非常に多かった．
Harunoら[CITE]は，決定木を用いて係り受けの確率を推定した．
FujioとMatsumoto [CITE]はCollinsのモデル[CITE]の修正版を日本語の係り受け解析に適用した．
Harunoらと，FujioとMatsumotoの両グループともCYK法を用いている．
これは[MATH]の時間がかかる．
ここで[MATH]は文の長さ，つまり文節数を表している．
Sekineら[CITE]は最大エントロピー法(Maximum Entropy Modeling; ME)を係り受けの確率の推定に使い，後方ビームサーチ(文末から文頭に向かうビームサーチ)で最もよい解析結果を見つける．
このビームサーチのアルゴリズムは[MATH]の時間がかかる．
KudoとMatsumoto [CITE]らも同じ後方ビームサーチをMEではなくサポートベクタマシン(SVMs)とともに用いている．
二つの文節間の係り受けの確率を使わない統計的手法も少ないながらある．
一つはSekineの決定的有限状態変換器を用いる手法[CITE]である．
Sekineは，\TermHead{}の場所の97%は文中の五つの候補でカバーされると報告している．
似た現象はMaruyamaとOgino [CITE]も観測している．
これらの調査にもとづき，Sekineは，決定的有限状態変換器を用いる効率のよい解析アルゴリズムを提案している．
このアルゴリズムは，考慮する係り先の文節数を制限することでしらみつぶしに探索することを避け，[MATH]の時間計算量となっている．
しかしながら，彼のパーザは京大コーパスに対して77.97%の係り受け正解率(定義は第[REF_subsec:results]節で述べる)しか得られていない．
これは，89%を超える現在の最高精度よりもかなり低い．
2文節間の係り受けの確率を用いない別の興味深い手法は，KudoとMatsumoto [CITE]によるCascaded Chunking Modelである．
このモデルは[CITE]のアイデアにもとづく．
彼らはこのモデルとSVMsを用いて，89.29%を得ている．
彼らの手法では，解析時に評価される係り関係の数はCYK法や後方ビームサーチよりも相当少ないが，それでも時間計算量の上限は[MATH]である．
以上見たように，高い精度を保ちつつ線形時間の処理を保証して，どのように日本語係り受け解析を行なうかは，まだ解決されていない問題である．
以下に記述するアルゴリズムがこの問題に対する答えとなろう．
