前節で述べた方法の有効性を確かめるため，以下の点を明らかにするための実験を行った．
外部辞書による解析精度の向上
形態素クラスタリングによる解析精度の向上
以下では，まず形態素解析精度の評価基準について述べ，実験の条件を明確にし，上述の実験の結果を提示し評価する．
また，文法の専門家による形態素解析器との解析精度の比較を行なった結果について述べる．
なお以下では，「クラス[MATH]-gramモデル」などの言語モデルを表す表現を，文脈から明らかな場合には，その言語モデルに基づく形態素解析器を表すためにも用いる．
我々が用いた評価基準は，[CITE]で用いられた再現率と適合率であり，次のように定義される．
EDRコーパスに含まれる形態素数を[MATH]，解析結果に含まれる形態素数を[MATH]，分割と品詞の両方が一致した形態素数を[MATH]とすると，再現率は[MATH]と定義され，適合率は[MATH]と定義される．
例として，コーパスの内容と解析結果が以下のような場合を考える．
この場合，分割と品詞の両方が一致した形態素は「は(助詞)」と「な(形容詞)」と「い(形容詞語尾)」であるので，[MATH]となる．
また，コーパスには6つの形態素が含まれ，解析結果には5つの形態素が含まれているので，[MATH]である．
よって，再現率は[MATH]となり，適合率は[MATH]となる．
実験にはEDRコーパス[CITE]を用いた．
まず，これを10個に分割し，この内の9個を学習コーパスとし，残りの1個をテストコーパスとした．
前章で述べたように，クラス関数の推定では，この9個の学習コーパスのうちの8つから[MATH]-gramモデルを推定し，残りの1つのコーパスに対してクロスエントロピーを求めるということを9通り行なって得られる平均クロスエントロピーを評価規準とする．
それぞれのコーパスに含まれる文と形態素と文字の数(のべ)は表[REF_table:corpus]の通りである．
既知形態素は，2個以上の学習コーパスに現れる59,956個の形態素とした．
形態素bi-gramモデルは，これらに対応する状態の他に，各品詞の未知語に対応する状態(15個)と文区切り(文末と文頭)に対応する状態を持つ．
同様に，クラスbi-gramモデルは，既知形態素をクラスタリングすることで得られるクラスに対応する状態と，各品詞の未知語に対応する状態と文区切りに対応する状態を持つ．
形態素bi-gramモデルとクラスbi-gramモデルを比較するために，これらを同じ学習コーパスから構成し，同じテストコーパスに対してパープレキシティや形態素解析の精度を計算した．
それぞれの言語モデルの構成の手順は以下の通りである．
形態素bi-gramモデル
削除補間により式([REF_equation:m-inter])の補間の係数を推定
すべての学習コーパスを対象に形態素bi-gramと形態素uni-gramを計数
クラスbi-gramモデル
削除補間により式([REF_equation:m-inter])の補間の係数を推定
前章で述べた方法([MATH])でクラス関数を推定
削除補間により式([REF_equation:c-inter])の補間の係数を推定
すべての学習コーパスを対象にクラスbi-gramとクラスuni-gramを計数
未知語モデルは共通であり，各品詞(15個)に対して形態素bi-gramモデルと同様の手順で構成される．
本実験では行なっていないが，文字に対するクラスタリングを行ない，これをクラスbi-gramモデルとすることも可能である．
外部辞書の形態素集合は，EDR日本語単語辞書[CITE]の見出し語から既知形態素を除いた形態素集合と学習コーパスには出現するが既知形態素とならなかった形態素集合(分割された学習コーパスの1個にのみ現れた形態素)の和集合とした．
品詞毎の形態素数とクラスタリングの結果得られたクラスの数を表[REF_table:cluster]に掲げた．
平均要素数は，形態素数をクラス数で割った値である．
この値は，内容語において高く，機能語において低いことが観測される．
このことから，品詞[MATH]-gramモデルにおいては機能語を一般化し過ぎており，形態素[MATH]-gramモデルにおいては内容語を特殊化し過ぎているということが分かる．
なお，対象となる59,956の形態素をクラスタリングするのに要した時間は，SPARC Station 20 (150MHz)で約4日であった．
図[REF_figure:result]は，形態素クラスタリングの結果を用いたクラスbi-gramモデルの，外部辞書を持つ場合と持たない場合の，クロスエントロピーと形態素解析の精度である．
このグラフから次のようなことが分かる．
まず，学習コーパスの大きさと解析精度の関係であるが，解析精度は，コーパスの大きさに対して単調に増加している．
しかし，コーパスがある程度大きくなるとこの増加量は小さくなっている．
このことは，さらなる精度向上を達成するためには，学習コーパスを増やすという単純な方法は，コーパスの作成コストを考えると，得策ではないということを意味する．
次に，外部辞書を付加することによる解析精度の向上であるが，クロスエントロピーの減少から予測される通り，外部辞書を付加することにより解析精度が向上した．
グラフから分かるように，学習コーパスの大きさが小さい方が，外部辞書を付加することによる効果が大きい．
この理由は，学習コーパスが大きくなると，外部辞書の元となる辞書などに記述されている形態素の大部分が学習コーパスに含まれることになり，テストコーパスに含まれる未知形態素の割合が減少することであると考えられる．
この議論から，確率的形態素解析器を用いて学習コーパスと異なる分野の文を解析する場合には，未知形態素となるであろうその分野特有の用語(表記と品詞)を収集しておき，これを外部辞書として付加することでかなりの精度の向上が望めると考えられる．
分野特有の用語の収集方法としては，その分野の専門用語辞書などを直接用いることや，その分野の大量の文例から[MATH]-gram統計を用いて抽出し品詞を推定すること[CITE]などが考えられる．
表[REF_table:result]は，外部辞書を備えない場合と備えた場合の，形態素bi-gramモデルとクラスbi-gramモデルによるクロスエントロピーと形態素解析の精度である．
また，先行研究との比較のため，外部辞書を備えていない場合の品詞tri-gramモデルによるクロスエントロピーも表中に記載している．
この結果から，外部辞書の有無に関わらず，我々が提案する方法によって得られる単語のクラス分類を用いることで，形態素解析の精度が再現率と適合率の双方で向上していることが分かる．
これは，クロスエントロピーの減少から予測される通りの結果である．
このように，確率モデルを用いた言語の解析では，クロスエントロピーが減少するようにモデルを改善することで，自然に形態素解析などの解析精度が向上することが見込まれる．
ただし，このクロスエントロピーと解析精度の関係は，単調であることが解析的に導出できるような確固たる関係ではないことに注意しなければならない．
クロスエントロピーと解析精度の関係が逆になっている例(上述の関係の反例)として，表[REF_table:result]の中の「形態素bi-gram+外部辞書」と「クラスbi-gram」のエントロピーと適合率が挙げられる．
文献[CITE]では，品詞tri-gramモデルを用いた形態素解析をについて述べている．
この文献では，我々が今回用いた評価規準と全く同じ評価規準ではなく，単語分割のみや読みも含めた再現率と適合率を報告している．
このような評価の一つとして72,000文で学習した品詞tri-gramモデルの単語分割の精度として90.6%の再現率と91.7%の適合率を報告している．
このモデルとの比較を可能にするために，約47,000の学習コーパスで学習した「クラスbi-gram+外部辞書」の単語分割の精度を計算した．
この結果，再現率は94.8%であり，適合率は94.9%であり，学習コーパスが少し小さいにもかかわらず品詞tri-gramモデルの結果を双方で上回っている．
解析精度に関しては全ての条件が同じというわけではないので単純な比較は適切ではないが，この結果は，本手法の優位性を実験的に示すと考えられる．
また，クロスエントロピー(表[REF_table:result]参照)の差は十分有意であると考えられるので，この点からも本手法の形態素解析の精度という点での優位性が十分予測される．
しかし，より長い文脈から次の品詞を予測しているという品詞tri-gramモデルの良い点も無視できない．
この点を採り入れて，形態素tri-gramモデルに対して形態素クラスタリングを実行し，その結果を用いてクラスtri-gramモデルを構築すれば，クロスエントロピーがさらに下がり，形態素解析の精度も上がると考えられる．
ただし，実用とするためには，遷移表や解探索のための表が大きくなることによる記憶域の増大と可能な組合せの増加による解探索に必要な時間が増加するという問題にも注意を払う必要がある．
我々は，上述の実験に加えて，文法の専門家による形態素解析器と確率的形態素解析器を解析精度という点で比較するという実験を行なった．
この際に最大の問題となるのは評価基準である．
確率的形態素解析器の解析精度の比較は容易に行なえる．
つまり，我々が上述した実験で行なったように，同一の学習コーパスと同一のテストコーパスを用いた解析結果の再現率と適合率を比較すればよい．
これは英文における単語の品詞推定の精度の比較にも用いられる標準的な方法である(英語では単語区切りに曖昧性がないので再現率と適合率は同じ値になる)．
しかし，文法の専門家による形態素解析器の解析精度の比較は一般に容易ではない．
これは，それぞれの文法の専門家によって形態素の定義(品詞体系や単語区切り)に違いがあり，正解となるべき形態素解析結果を共有できないことに起因する．
その結果，形態素解析器の評価としては，あるいくつかの文の解析結果を文法の専門家も含めた形態素解析器の製作者が観察することで計算される値が用いられる．
また，テストは最後に一回だけ行なわれるのではなく，テストの結果を見て形態素解析器を修正するということもあり，完全なオープンテストになっていないこともある．
このようなテストの結果得られる精度は，客観性に欠けるので，おおよその目安としてのみ意味があり，複数の形態素解析器の比較に用いることはできない．
この問題は，文法の専門家による形態素解析器と確率的形態素解析器の解析精度の比較を行なう際にも現れる．
上述の問題を解決する方法として，同じ文法基準(品詞体系や単語区切)を持つ形態素解析済みコーパスと文法の専門家による形態素解析器を用いることが考えられる．
これが，本研究で我々が選択した解決方法である．
具体的には，京都大学で開発された文法の専門家による形態素解析器JUMAN [CITE]とその解析結果を人手で修正したコーパス[CITE]を用いた．
つまり，コーパスを学習コーパスとテストコーパスに分割し(表[REF_table:corpus-juman])，学習コーパスから構成した確率的形態素解析器(外部辞書を備えたクラスbi-gramモデル)とJUMANを用いてテストコーパスを解析した結果を，テストコーパスにあらかじめ付与されている正解と比較して，それぞれの再現率と適合率を計算した．
なお，外部辞書の形態素集合は，学習コーパスには出現するが既知形態素とならなかった形態素集合である．
表[REF_table:result-juman]はこの結果である．
この表から，テストコーパスにおいては，確率的形態素解析器の誤りが文法の専門家による形態素解析器の誤りに対して25%程度少ないことが分かる．
この実験で使用した解析済みコーパスがJUMANの出力の訂正であることや，コーパスの訂正の過程で訂正結果を参考にしてJUMANを改良していることを考えると学習コーパスでの比較が適切かも知れない．
この場合は，確率的形態素解析器の解析精度は表[REF_table:result-juman]に示されるように圧倒的に良い．
未知語モデルを文字クラスタリングしたクラス[MATH]-gramモデルとすることや，外部辞書の源としてJUMANの辞書や別のコーパスをJUMANで解析した結果から得られる学習コーパスに現れない高頻度の形態素を用いることで，確率的形態素解析器の精度はさらに向上すると考えられる．
本実験で比較の対象とした文法の専門家による形態素解析器は，初版の完成から10年弱の期間を経ており，この間に莫大な人的資源を投入し様々な改良が施されている．
一方，我々の確率的形態素解析器がパラメータ推定に用いた学習コーパスは8,584文であり，これを作成する費用はそれほど高くはない．
これは，確率的形態素解析器が，文法の専門家による形態素解析器に対して優位である点の一つである．
現状での学習コーパスの大きさは[MATH]文字と比較的小規模であり，図[REF_figure:result]のEDRコーパスにおける学習コーパスの大きさと解析精度の関係から，コーパスを増量し確率言語モデルを再学習するということを繰り返すことで，この品詞体系でのより高精度の形態素解析器が容易に実現できると予測される．
これと並行して確率言語モデルの改善を行なうことも重要である．
以下に，より良い確率的形態素解析器を実現するための指針をまとめる．
解析済みコーパスの保守と増量
人手による修正を受けた解析済みコーパスにも誤りはあり，さらなる修正が必要である．
確率的形態素解析器の出力との比較は，これらの誤りを指摘する上で有効であろう．
すでに指摘したように，学習コーパスは多ければ多いほど良い．
新たな文に正解を付加するときには，人手による修正を受けたコーパスを全て用いて，最も良い言語モデルを学習し，その結果得られる確率的形態素解析器による解析結果を修正することで，人手による修正のコストを最小限に抑える必要がある．
形態素解析器の出力を用いた研究や開発の過程で，品詞体系の変更が要求されることがある．
例えば，京都大学テキストコーパス[CITE]では，「みんな/名詞」と「みんな/副詞」を区別していない．
このような区別が必要になれば，まず解析済みコーパスの一部をこの区別を加えて修正し，これと残りのコーパスで問題となる形態素が出現しないコーパスから形態素解析器を学習し，問題となる形態素が出現する文を曖昧な部分以外を固定して解析し直すことで，人手による修正のコストを最小限に抑えることができる．
確率的言語モデルの改良
確率言語モデルの改善方法は，本論文で提案した形態素クラスタリング以外にも提案されてる．
これらは，未知語モデルにも適用できる．
[MATH]-gramモデルでの単語予測は固定長の文脈を条件部にもつが，これを先行する単語に応じて変化させる[CITE] [CITE]．
直前のいくつかの単語の分布(キャッシュ)を用いて[MATH]-gramモデルのパラメータを動的に変化させる[CITE]．
複数のクラス[MATH]-gramモデルを補間したモデルを用いる[CITE]．
これらの改良をうまく組み合わせることで言語モデルの予測力が向上し，結果としてより高い精度の形態素解析器が実現できる．
解探索のアルゴリズムやデータ構造の改良
これによる解析速度や記憶容量の改良は，解析精度の向上にはつながらないが，実用とする上で重要である．
解探索のアルゴリズムやデータ構造は，モデルのクラスに依存する点に注意しなければならない．
これらの改善は独立に行なえるので，組織的な取り組みが可能になる．
このように，高い精度を実現するための方法論が確立していることが確率的手法の最大の利点であろう．
