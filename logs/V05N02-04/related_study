 上述の問題を解決する方法として，同じ文法基準(品詞体系や単語区切)を持つ形態素解析済み
 コーパスと文法の専門家による形態素解析器を用いることが考えられる．これが，本研究で我
 々が選択した解決方法である．具体的には，京都大学で開発された文法の専門家による形態素
 解析器JUMAN \cite{日本語形態素解析システムjuman使用説明書.version.3.2}とその解析結果
 を人手で修正したコーパス\cite{京都大学テキストコーパス・プロジェクト}を用いた．つま
 り，コーパスを学習コーパスとテストコーパスに分割し(表\ref{table:corpus-juman})，学習
 コーパスから構成した確率的形態素解析器(外部辞書を備えたクラスbi-gramモデル)とJUMANを
 用いてテストコーパスを解析した結果を，テストコーパスにあらかじめ付与されている正解と
 比較して，それぞれの再現率と適合率を計算した．なお，外部辞書の形態素集合は，学習コー
 パスには出現するが既知形態素とならなかった形態素集合である．表
 \ref{table:result-juman}はこの結果である．この表から，テストコーパスにおいては，確率
 的形態素解析器の誤りが文法の専門家による形態素解析器の誤りに対して25\%程度少ないこと
 が分かる．この実験で使用した解析済みコーパスがJUMANの出力の訂正であることや，コーパ
 スの訂正の過程で訂正結果を参考にしてJUMANを改良していることを考えると学習コーパスで
 の比較が適切かも知れない．この場合は，確率的形態素解析器の解析精度は表
 \ref{table:result-juman}に示されるように圧倒的に良い．未知語モデルを文字クラスタリン
 グしたクラス$n$-gramモデルとすることや，外部辞書の源としてJUMANの辞書や別のコーパス
 をJUMANで解析した結果から得られる学習コーパスに現れない高頻度の形態素を用いることで
 ，確率的形態素解析器の精度はさらに向上すると考えられる．

 \input{table:corpus-juman}
 \input{table:result-juman}

 本実験で比較の対象とした文法の専門家による形態素解析器は，初版の完成から10年弱の期間
 を経ており，この間に莫大な人的資源を投入し様々な改良が施されている．一方，我々の確率
 的形態素解析器がパラメータ推定に用いた学習コーパスは8,584文であり，これを作成する費
 用はそれほど高くはない．これは，確率的形態素解析器が，文法の専門家による形態素解析器
 に対して優位である点の一つである．現状での学習コーパスの大きさは$10^{5.56}$文字と比
 較的小規模であり，図\ref{figure:result}のEDRコーパスにおける学習コーパスの大きさと解
 析精度の関係から，コーパスを増量し確率言語モデルを再学習するということを繰り返すこと
 で，この品詞体系でのより高精度の形態素解析器が容易に実現できると予測される．これと並
 行して確率言語モデルの改善を行なうことも重要である．以下に，より良い確率的形態素解析
 器を実現するための指針をまとめる．
 \begin{itemize}
 \item 解析済みコーパスの保守と増量
   \begin{description}
   \item[コーパスの修正] \ \\
     人手による修正を受けた解析済みコーパスにも誤りはあり，さらなる修正が必要である．
     確率的形態素解析器の出力との比較は，これらの誤りを指摘する上で有効であろう．
   \item[コーパスの増量] \ \\
     すでに指摘したように，学習コーパスは多ければ多いほど良い．新たな文に正解を付加す
     るときには，人手による修正を受けたコーパスを全て用いて，最も良い言語モデルを学習
     し，その結果得られる確率的形態素解析器による解析結果を修正することで，人手による
     修正のコストを最小限に抑える必要がある．
   \item[品詞体系の変更] \ \\
     形態素解析器の出力を用いた研究や開発の過程で，品詞体系の変更が要求されることがあ
     る．例えば，京都大学テキストコーパス\cite{京都大学テキストコーパス・プロジェクト}
     では，「みんな/名詞」と「みんな/副詞」を区別していない．このような区別が必要にな
     れば，まず解析済みコーパスの一部をこの区別を加えて修正し，これと残りのコーパスで
     問題となる形態素が出現しないコーパスから形態素解析器を学習し，問題となる形態素が
     出現する文を曖昧な部分以外を固定して解析し直すことで，人手による修正のコストを最
     小限に抑えることができる．
   \end{description}
 \item 確率的言語モデルの改良 \\
   確率言語モデルの改善方法は，本論文で提案した形態素クラスタリング以外にも提案されて
   る．これらは，未知語モデルにも適用できる．
   \begin{description}
   \item[可変記憶長マルコフモデル] \ \\
     $n$-gramモデルでの単語予測は固定長の文脈を条件部にもつが，これを先行する単語に応
     じて変化させる\cite{Part.of.Speech.Tagging.Using.a.Variable.Memory.Markov.Model}
     \cite{文脈木を利用した形態素解析}．
   \item[キャッシュモデル] \ \\
     直前のいくつかの単語の分布(キャッシュ)を用いて$n$-gramモデルのパラメータを動的に
     変化させる\cite{A.Cache-Based.Natural.Language.Model.for.Speech.Recognition}．
   \item[複数のモデルの補間] \ \\
     複数のクラス$n$-gramモデルを補間したモデルを用いる
     \cite{Improving.Statistical.Language.Model.Performance.with.Automatically.Generated.Word.Hierarchies}
     ．
   \end{description}
   これらの改良をうまく組み合わせることで言語モデルの予測力が向上し，結果としてより高
   い精度の形態素解析器が実現できる．
 \item 解探索のアルゴリズムやデータ構造の改良 \\
   これによる解析速度や記憶容量の改良は，解析精度の向上にはつながらないが，実用とする
   上で重要である．解探索のアルゴリズムやデータ構造は，モデルのクラスに依存する点に注
   意しなければならない．
 \end{itemize}
 これらの改善は独立に行なえるので，組織的な取り組みが可能になる．このように，高い精度
 を実現するための方法論が確立していることが確率的手法の最大の利点であろう．
score of this paragraph is 5
