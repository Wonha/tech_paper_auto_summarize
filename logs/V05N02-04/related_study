本実験で比較の対象とした文法の専門家による形態素解析器は，初版の完成から10年弱の期間
を経ており，この間に莫大な人的資源を投入し様々な改良が施されている．一方，我々の確率
的形態素解析器がパラメータ推定に用いた学習コーパスは8,584文であり，これを作成する費
用はそれほど高くはない．これは，確率的形態素解析器が，文法の専門家による形態素解析器
に対して優位である点の一つである．現状での学習コーパスの大きさは$10^{5.56}$文字と比
較的小規模であり，図\ref{figure:result}のEDRコーパスにおける学習コーパスの大きさと解
析精度の関係から，コーパスを増量し確率言語モデルを再学習するということを繰り返すこと
で，この品詞体系でのより高精度の形態素解析器が容易に実現できると予測される．これと並
行して確率言語モデルの改善を行なうことも重要である．以下に，より良い確率的形態素解析
器を実現するための指針をまとめる．
\begin{itemize}
\item 解析済みコーパスの保守と増量
  \begin{description}
  \item[コーパスの修正] \ \\
    人手による修正を受けた解析済みコーパスにも誤りはあり，さらなる修正が必要である．
    確率的形態素解析器の出力との比較は，これらの誤りを指摘する上で有効であろう．
  \item[コーパスの増量] \ \\
    すでに指摘したように，学習コーパスは多ければ多いほど良い．新たな文に正解を付加す
    るときには，人手による修正を受けたコーパスを全て用いて，最も良い言語モデルを学習
    し，その結果得られる確率的形態素解析器による解析結果を修正することで，人手による
    修正のコストを最小限に抑える必要がある．
  \item[品詞体系の変更] \ \\
    形態素解析器の出力を用いた研究や開発の過程で，品詞体系の変更が要求されることがあ
    る．例えば，京都大学テキストコーパス\cite{京都大学テキストコーパス・プロジェクト}
    では，「みんな/名詞」と「みんな/副詞」を区別していない．このような区別が必要にな
    れば，まず解析済みコーパスの一部をこの区別を加えて修正し，これと残りのコーパスで
    問題となる形態素が出現しないコーパスから形態素解析器を学習し，問題となる形態素が
    出現する文を曖昧な部分以外を固定して解析し直すことで，人手による修正のコストを最
    小限に抑えることができる．
  \end{description}
\item 確率的言語モデルの改良 \\
  確率言語モデルの改善方法は，本論文で提案した形態素クラスタリング以外にも提案されて
  る．これらは，未知語モデルにも適用できる．
  \begin{description}
  \item[可変記憶長マルコフモデル] \ \\
    $n$-gramモデルでの単語予測は固定長の文脈を条件部にもつが，これを先行する単語に応
    じて変化させる\cite{Part.of.Speech.Tagging.Using.a.Variable.Memory.Markov.Model}
    \cite{文脈木を利用した形態素解析}．
  \item[キャッシュモデル] \ \\
    直前のいくつかの単語の分布(キャッシュ)を用いて$n$-gramモデルのパラメータを動的に
    変化させる\cite{A.Cache-Based.Natural.Language.Model.for.Speech.Recognition}．
  \item[複数のモデルの補間] \ \\
    複数のクラス$n$-gramモデルを補間したモデルを用いる
    \cite{Improving.Statistical.Language.Model.Performance.with.Automatically.Generated.Word.Hierarchies}
    ．
  \end{description}
  これらの改良をうまく組み合わせることで言語モデルの予測力が向上し，結果としてより高
  い精度の形態素解析器が実現できる．
\item 解探索のアルゴリズムやデータ構造の改良 \\
  これによる解析速度や記憶容量の改良は，解析精度の向上にはつながらないが，実用とする
  上で重要である．解探索のアルゴリズムやデータ構造は，モデルのクラスに依存する点に注
  意しなければならない．
\end{itemize}
これらの改善は独立に行なえるので，組織的な取り組みが可能になる．このように，高い精度
を実現するための方法論が確立していることが確率的手法の最大の利点であろう．
score of this paragraph is 5
