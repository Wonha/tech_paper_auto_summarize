日本語に対する形態素解析とは，日本語の文(文字列)を入力とし，これを表記と品詞の直積として定義される形態素に分割する処理である．
この節では，これを実現する手法の一つとしての確率的形態素解析とその基礎となる確率言語モデルと解の探索方法について述べる．
日本語の形態素解析は，日本語のアルファベット[MATH]のクリーネ閉包に属する文[MATH]を入力として，これを表記[MATH]と品詞[MATH]の直積として定義される形態素[MATH]の列[MATH]に分解して出力することと定義できる．
このとき，出力される形態素列の表記の連接は，入力のアルファベット列に等しくなければならない．
つまり，入力のアルファベット列(長さ[MATH])を[MATH]とし，出力の形態素列(要素数[MATH])を[MATH]とすると以下の式が成り立つ必要がある．
ただし，[MATH]は形態素[MATH]の表記を表し，[MATH]は形態素の連接[MATH]の表記の連接を表わすものとする．
一般に，これを満たす解は一意ではない．
形態素解析の問題は，可能な解の中から人間の判断(正解)に最も近いと推測される形態素列(単語分割と品詞割り当て)を選択し出力することである．
この選択の基準としては，文法の専門家が自身の言語直観を頼りにした規則に基づく方法と大量の正解例(形態素解析済みコーパス)からの推定を規準にする方法がある．
以下では，後者の一つである確率的形態素解析について説明する．
確率的形態素解析器は，品詞という概念を内包する確率的言語モデルを基にして，与えられた文字列[MATH]に対する確率最大の形態素列[MATH]を計算し出力する．
これは，以下の式で表される．
この式の最後の[MATH]が品詞という概念を内包する確率的言語モデルである．
このような確率的言語モデルには様々なものが考えられる．
これらの良否の尺度としては，クロスエントロピーが一般的である．
これは，確率的言語モデルを[MATH]とし，テストコーパスを[MATH]とすると以下の式で与えられる．
ただし，[MATH]は文[MATH]の長さ(文字数)を表わす．
この値は，コーパス[MATH]をモデル[MATH]で符合化した時の文字あたりの平均符合長の下限であり，[MATH]として無作為に抽出された十分多数の文を選択すれば，複数のモデルの良否を比較するための尺度となる．
定義から明らかなように，この値がより小さいほうがより良い言語モデルである．
クロスエントロピーの意味で良い言語モデルを用いる方が形態素解析の精度が良いと考えられる．
確率的言語モデル[MATH]は，形態素を一つずつ予測することを仮定すると，以下のように書き換えられる．
ここで[MATH]は，文末に対応する特別な記号である．
これを導入することによって，すべての可能な形態素列に対する確率の和が1となることが保証される[CITE]．
式([REF_eqnarray:P(m)])は，ある時点[MATH]での形態素[MATH]の出現確率は最初の時点から時点[MATH]までの全ての形態素に依存することを表しているが，実装の簡便さなどを考慮して，時点[MATH]から時点[MATH]までの連続する[MATH]個の形態素の履歴にのみ依存する[MATH]重マルコフ過程であると仮定する．
この仮定は，以下の式で表される近似である．
ここで[MATH]は，文頭に対応する特別な記号である．
これを導入することによって式が簡便になる．
一般に，確率[MATH]の値はコーパスから最尤推定することで得られる．
これは，[MATH]を形態素列[MATH]のコーパスにおける頻度として，以下の式で与えられる．
このように，このモデルは連続する[MATH]個の形態素列の頻度に基づいているので，形態素[MATH]-gramモデルと呼ばれる．
形態素[MATH]-gramモデルにおいて場合に問題となるのは，状態に対応する形態素(既知形態素)の選択である．
一般的には，頻度の高い形態素を既知形態素とすることで高い予測力が実現できる．
しかし，どのような形態素の集合を選択したとしても，テストコーパスに出現する可能性のあるすべての形態素が既知形態素であることは望めない．
このため，未知形態素の扱いが避けられない問題となる．
この問題に対処するため，未知形態素に対応する特別な記号を用意し，既知の形態素以外はこの記号から次節で述べる未知語モデルにより与えられる確率で生成されることとする．
未知形態素に対応する特別な記号は，かならずしも唯一である必要はなく，品詞などの情報を用いて区別される複数の記号であっても良い．
我々の目的は形態素解析であるから未知形態素であっても品詞の推定が可能でなければならない．
よって，各品詞に対して未知形態素に対応する記号を設ける．
以上に述べた形態素[MATH]-gramモデル[MATH]による，形態素列の出現確率は以下の式で表される．
ただし[MATH]は既知形態素の集合を表わし，[MATH]は[MATH]の品詞を表わす．
また，[MATH]は品詞[MATH]に属する未知形態素に対応する特別な記号である．
この式の中の[MATH]は，次項で述べる未知語モデルであり，品詞が[MATH]であることを条件として，引数で与えられる文字列の生成確率を値とする．
確率値の最尤推定においては，まず既知形態素集合を定義し，学習コーパスの未知形態素を未知形態素に対応する特別な記号に置き換えて頻度を計数する．
未知語モデルは，表記から確率値への写像として定義され，既知形態素以外のあらゆる形態素の表記を0より大きい確率で生成し，この確率をすべての表記に渡って合計すると1以下になる必要がある．
このような条件を満たすモデルの一つとして，文字[MATH]-gramモデルがある．
日本語の表記に用いられる文字は有限と考えられるので，形態素[MATH]-gramモデルのときの未知形態素のような問題は起こらない．
しかし，形態素[MATH]-gramモデルの場合と同様に，文字を既知文字と未知文字に分類し，未知文字はこれを表わす特別な記号から生成されるものとすることもできる．
文字の使用頻度には大きな偏りがあることが予測されるので，これらを一つのグループとみなすことで，モデルが改善されると考えられる．
文字集合は有限であるから，未知形態素モデルの場合と異なり，各未知文字の生成確率を等確率とすることができる．
このようにして構成される未知語モデルは以下の式で表わされる．
ただし[MATH]は品詞が[MATH]である未知語モデルの既知文字の集合を表わし，[MATH]は品詞[MATH]の未知語モデルの未知文字に対応する特別な記号である．
また，[MATH]としている．
この式の中の[MATH]は，語頭に対応する便宜的な記号である．
また，[MATH]は，語末に対応する特別な記号であり，形態素に対するモデルの場合と同様に，すべての可能な文字列に対する確率の和が1となるために導入されている．
以上で説明した未知語モデルは，未知文字を等確率で生成するモジュールを「未知文字モデル」と考えると，形態素[MATH]-gramモデルと相似の構造である．
文字[MATH]-gramモデルの確率値は，形態素[MATH]-gramモデルの場合と同様に，既知文字を定義した後，未知形態素の実例における文字列の頻度から推定される．
上述したように，形態素[MATH]-gramモデルのパラメータ推定には，出現頻度を基にした最尤推定が用いられる．
しかし，対象とする事象の頻度が低い場合には，推定値の信頼性は低くなるという問題がある．
この問題に対処する方法として，補間と呼ばれる方法が用いられる[CITE]．
これは，次の式で表されるように，より信頼性が高いことが期待される，より低次のマルコフモデルの遷移確率を一定の割合で足し合わせるという操作を施すことを言う．
係数[MATH]の値は，確率値[MATH]の推定に用いられるコーパスとは別に用意された比較的小さいコーパスを用いて最尤推定される．
この方法では，確率値の推定に用いることができるコーパスの大きさが小さくなり，推定値の信頼性が少しではあるが低下するという問題がある．
これに対処する方法として削除補間[CITE]と呼ばれる方法がある．
これは，パラメータ推定のためのコーパスを[MATH]個に分割し，[MATH]個の部分で確率値を推定し，残りの部分で補間の係数を推定するということを全ての組合せ([MATH]通り)に渡って行ない，その平均値をとるという方法である．
形態素[MATH]-gramモデルによる形態素解析器は，入力として文字列[MATH]を受けとり，式([REF_equation:morph_n-gram1])([REF_equation:morph_n-gram2]) ([REF_equation:ukwmodel1])([REF_equation:ukwmodel2])([REF_equation:m-inter])を用いて計算される確率が最大の形態素列[MATH]を式([REF_equation:condition])で表わされる条件の下で計算し出力する．
解の探索には動的計画法を用いることができ，入力の文字数[MATH]に対して計算時間のオーダーが[MATH]となるアルゴリズムが提案されている[CITE] [CITE]．
この章では，確率的形態素解析の精度を向上させる方法として，未知語モデルに外部辞書を付加する方法を提案する．
これは，確率的言語モデルの予測力を改善する方法であり，確率的形態素解析の精度向上を直接の目的としているわけではないが，確率的言語モデルの予測力の改善は，結果としてそれに基づく確率的形態素解析器の解析精度を向上させる．
また，予測力の高い未知語モデルを推定するための未知形態素の実例の収集方法についても述べる．
前章で述べた未知語モデル[MATH]は，未知形態素だけでなく既知形態素の表記も0より大きい確率で生成する可能性がある．
この場合には，以下の式が示すように，未知形態素の生成確率の合計は1未満となる．
以下の説明では品詞[MATH]を省略してある．
また，形態素の集合を表わす記号[MATH]をその表記の集合を表わすとしている．
これは，言語モデルとしての条件を満たしてはいるが，クロスエントロピーという点で改善の余地がある．
つまり，既知形態素の生成確率を何らかの方法で未知形態素に分配することで，未知形態素の生成確率が大きくなり，テストコーパスにそのような未知形態素が出現した場合に，テストコーパスの出現確率が大きくなる．
既知形態素の生成確率の分配には，様々な方法が考えられるが，以下の式が表すように，すべての未知形態素にその生成確率に比例して分配する方法が一般的であろう．
これに対して我々は，辞書の見出し語などとして与えられる形態素の部分集合に等しく配分することを提案する．
つまり，ある形態素の集合が与えられたとして，ここから既知形態素を除いた集合を[MATH] ([MATH])として，この要素の生成確率を文字[MATH]-gramモデルによる確率と既知形態素の生成確率の合計を[MATH]の要素数で割った値の和とする．
これは，既知形態素の生成確率を，学習コーパスには現れないが辞書などから形態素であると考えられる文字列に優先的に分配し，それらの生成確率を相対的に高くすることを意味する．
このような文字列の集合を外部辞書と呼ぶ．
形態素解析が目的なので，外部辞書には文字列のほかにその品詞が記述されている必要がある．
この方法により，確率言語モデルの枠内で，コーパスから推定された確率言語モデルに辞書などの異なる情報源の情報を付加できる．
以上に述べた外部辞書を備えた未知語モデル[MATH]による文字列[MATH]の出現確率は以下の式で表される．
これを式([REF_equation:ukwmodel0])の代わりに用いる未知語モデルを外部辞書を備えた未知語モデルと呼ぶ．
文字[MATH]-gramモデルの確率値は，形態素[MATH]-gramモデルの場合と同様に，アルファベットを定義してから，未知形態素の実例における文字列の頻度から推定される．
未知形態素の実例の収集の方法としては，学習コーパスに含まれるすべての形態素とすることや，学習コーパスにおける頻度が1である形態素とする[CITE]などが考えられる．
我々は，削除補間法を応用した以下の方法を提案する．
学習コーパスを[MATH]個の部分コーパスに分割し，[MATH]番目の部分コーパスの未知形態素の実例を，[MATH]番目の部分コーパス以外を学習コーパスとし[MATH]番目の部分コーパスをテストコーパスと見た場合の未知形態素とする．
我々が提案する方法は，削除補間法を応用して，実際のテストコーパスにおける未知形態素と類似した実例を得ているので，他の方法よりも優れていると予測される．
実際に，予備実験としてこれらの方法を実装し，予測力という規準で比較した．
その結果，我々が提案する方法が最良であった．
したがって，実験にはこの方法を用いた．
この章では，形態素[MATH]-gramモデルの一般化の一つであるクラス[MATH]-gramモデルを説明し，文献(提出中)を応用して形態素解析のためのクラスを自動的に学習する方法を提案する．
前章と同様に，確率的言語モデルの予測力の改善を目的としているが，学習されたクラス[MATH]-gramモデルに基づく確率的形態素解析器の解析精度は，形態素[MATH]-gramモデルや人間の言語直観による品詞をクラスとした場合の品詞[MATH]-gramモデルに基づく確率的形態素解析器の解析精度より高くなると考えられる．
クラス[MATH]-gramモデル[CITE]では，あらかじめ形態素をクラスと呼ばれるグループに分類しておき，先行するクラスの列を直前の事象とみなして分類する．
このモデルでは，次の形態素を直接予測するのではなく，次のクラスを予測した上で次の形態素を予測する．
以下の式で，[MATH]は既知形態素に対応するクラスであり，これを品詞とすれば，品詞[MATH]-gramモデルとなる．
この式の中の[MATH]は，文頭に対応する特別な記号である．
これを導入することによって式が簡便になる．
また，[MATH]は，語末に対応する特別な記号であり，これを導入することによって，すべての可能な文字列に対する確率の和が1となる[CITE]．
形態素に基づくモデルの場合と同様に，確率[MATH]の値および，確率[MATH]の値は，コーパスから最尤推定することで得られる．
この式において，クラスを品詞とすれば品詞[MATH]-gramモデルが得られ，形態素からクラスへの写像が全単射であれば，形態素[MATH]-gramモデルと等価になることが分かる．
また，これをマルコフモデルと考えると，状態はクラスに対応する．
形態素[MATH]-gramモデルと同様に，データスパースネスの問題に対処する方法として，補間を用いることができる[CITE]．
これは，以下のように式([REF_equation:m-inter])において形態素[MATH]をクラス[MATH]と読み変えれることで容易に得られる．
確率言語モデルの形態素クラスタリングの課題は，クロスエントロピーが最も低くなる形態素とクラス(図[REF_figure:concept]の中の[MATH])の対応関係を算出することである．
このようなクラスを用いて構築されたクラス[MATH]-gramモデルに基づく確率的形態素解析器の解析精度は，品詞[MATH]-gramモデルや形態素[MATH]-gramモデルに基づく確率的形態素解析器の解析精度よりも高くなることが期待される．
従って，形態素クラスタリングの目的関数は，削除補間を応用することでクロスエントロピーを模擬すると考えられる以下のような値とした．
ここで，[MATH]は[MATH]番目以外の[MATH]の部分コーパスから推定された確率言語モデルであり，[MATH]は[MATH]番目の部分コーパス(文の列)を表す．
ここで問題としているのは，確率的言語モデルとしてクラス[MATH]-gramモデルを用いた場合の形態素のクラスタリングである．
この場合，コーパスは一定であり，確率的言語モデル[MATH]は形態素とクラスの関係[MATH]にのみ依存する．
従って，上式の平均クロスエントロピーは，形態素とクラスの関係の関数とみなすことができる．
この値がより小さいほうが，未知のコーパスに対してより良い言語モデルであることが予測される．
よって，クラスタリングの目的は，式([REF_equation:criterion])で定義される平均クロスエントロピーを最小化する形態素とクラスの関係を求めることである．
形態素とクラスの対応関係としては，ある形態素が一定の確率で複数のクラスに属するという確率的な関係も考えられるが，解空間が広大になるので，本研究では形態素は唯一のクラスに属することを仮定した．
よって，クラスの集合は形態素の集合の直和分割となる．
形態素とクラスの対応関係[MATH]は，[MATH]をそれぞれ形態素の集合とクラスの集合とすると，関数[MATH]を用いて表すことができ，この関数は以下の条件を満たす．
解探索のアルゴリズム中で用いるために，形態素とクラスの対応関係に対して，以下の関数を定義する．
[MATH]
[MATH]は，形態素とクラスの関係[MATH]に対して形態素[MATH]をクラス[MATH]に移動した結果得られる形態素とクラスの関係を返す．
クラスタリングの解空間はあらゆる可能な形態素とクラスの対応関係である．
しかし，この数はある程度の大きさの語彙数に対しては非常に大きいため，これら全てに対して平均クロスエントロピーを計算し，これを最小化するクラス関係を選択するということは，計算量という観点から不可能である．
平均クロスエントロピーの値はクラス関係の一部分の変更が全体に影響するという性質をもっているので，分割統治法や動的計画法を用いることもできない．
以上のことから，我々は最適解を求めることを諦め，貪欲アルゴリズムを用いることにした．
このアルゴリズムは以下の通りである(図[REF_figure:clustering]参照)．
なお，[MATH]は式([REF_equation:criterion])で与えられる平均クロスエントロピーでり，[MATH]や[MATH]は形態素[MATH]やクラス[MATH]の品詞を表わす．
同一の品詞である形態素に対してのみ併合を試みるので，結果としてどのクラスも同一の品詞の形態素のみを要素に持つことに注意しなければならない．
計算量は，二番目のforeachでの繰り返しの回数は単語数[MATH]に比例し，argminでの繰り返しの回数はクラス数[MATH]に比例するので，全体で[MATH]である．
クラス数[MATH]は，全ての単語が独立したクラスに分けられる場合に最大([MATH])となり，全ての単語が同一のクラスとなる場合に最小([MATH])となる．
従って，初期化における全体の計算量は，最良の場合が[MATH]であり，最悪の場合が[MATH]である．
ただし，単語の並べ替えや一番目のforeachの計算量は係数が非常に小さいと考えられるので，考慮に入れていない．
次節で述べる実験の結果では，頻度の高い形態素を対象とする段階では多くの形態素がクラスに併合されずクラス数は形態素数に比例し最悪の場合に近い挙動を示したが，頻度の低い形態素を対象とする段階ではほとんどの形態素がクラスに併合されてクラス数はほとんど一定となり最良の場合に近い挙動を示した．
頻度の低い形態素が多数を占めるので，計算量は実際にはかなり線形に近いと考えられる．
頻度の高い形態素から移動を試みることとしているのは，頻度の高い形態素の移動のほうがパープレキシティに与える影響が大きいと考えられるので，早い段階での移動が後の移動によって影響されにくく，収束がより速くなると考えたためである．
上述のアルゴリズムによって得られたクラス分類からさらに探索を進めてより良いクラス分類が得られるかを試みることができる．
このアルゴリズムとして，さらに形態素の移動を試みること[CITE]やクラスの併合を試みること[CITE]が考えられる．
我々は，これらのアルゴリズムを小さなコーパスに対する予備実験で適用してみたが，必要となる計算時間が膨大である割にはクロスエントロピーの改善が小さかった．
よって，次章では，上述のアルゴリズムによる実験結果について述べる．
日本語に対する形態素解析とは，日本語の文(文字列)を入力とし，これを表記と品詞の直積として定義される形態素に分割する処理である．
この節では，これを実現する手法の一つとしての確率的形態素解析とその基礎となる確率言語モデルと解の探索方法について述べる．
日本語の形態素解析は，日本語のアルファベット[MATH]のクリーネ閉包に属する文[MATH]を入力として，これを表記[MATH]と品詞[MATH]の直積として定義される形態素[MATH]の列[MATH]に分解して出力することと定義できる．
このとき，出力される形態素列の表記の連接は，入力のアルファベット列に等しくなければならない．
つまり，入力のアルファベット列(長さ[MATH])を[MATH]とし，出力の形態素列(要素数[MATH])を[MATH]とすると以下の式が成り立つ必要がある．
ただし，[MATH]は形態素[MATH]の表記を表し，[MATH]は形態素の連接[MATH]の表記の連接を表わすものとする．
一般に，これを満たす解は一意ではない．
形態素解析の問題は，可能な解の中から人間の判断(正解)に最も近いと推測される形態素列(単語分割と品詞割り当て)を選択し出力することである．
この選択の基準としては，文法の専門家が自身の言語直観を頼りにした規則に基づく方法と大量の正解例(形態素解析済みコーパス)からの推定を規準にする方法がある．
以下では，後者の一つである確率的形態素解析について説明する．
確率的形態素解析器は，品詞という概念を内包する確率的言語モデルを基にして，与えられた文字列[MATH]に対する確率最大の形態素列[MATH]を計算し出力する．
これは，以下の式で表される．
この式の最後の[MATH]が品詞という概念を内包する確率的言語モデルである．
このような確率的言語モデルには様々なものが考えられる．
これらの良否の尺度としては，クロスエントロピーが一般的である．
これは，確率的言語モデルを[MATH]とし，テストコーパスを[MATH]とすると以下の式で与えられる．
ただし，[MATH]は文[MATH]の長さ(文字数)を表わす．
この値は，コーパス[MATH]をモデル[MATH]で符合化した時の文字あたりの平均符合長の下限であり，[MATH]として無作為に抽出された十分多数の文を選択すれば，複数のモデルの良否を比較するための尺度となる．
定義から明らかなように，この値がより小さいほうがより良い言語モデルである．
クロスエントロピーの意味で良い言語モデルを用いる方が形態素解析の精度が良いと考えられる．
確率的言語モデル[MATH]は，形態素を一つずつ予測することを仮定すると，以下のように書き換えられる．
ここで[MATH]は，文末に対応する特別な記号である．
これを導入することによって，すべての可能な形態素列に対する確率の和が1となることが保証される[CITE]．
式([REF_eqnarray:P(m)])は，ある時点[MATH]での形態素[MATH]の出現確率は最初の時点から時点[MATH]までの全ての形態素に依存することを表しているが，実装の簡便さなどを考慮して，時点[MATH]から時点[MATH]までの連続する[MATH]個の形態素の履歴にのみ依存する[MATH]重マルコフ過程であると仮定する．
この仮定は，以下の式で表される近似である．
ここで[MATH]は，文頭に対応する特別な記号である．
これを導入することによって式が簡便になる．
一般に，確率[MATH]の値はコーパスから最尤推定することで得られる．
これは，[MATH]を形態素列[MATH]のコーパスにおける頻度として，以下の式で与えられる．
このように，このモデルは連続する[MATH]個の形態素列の頻度に基づいているので，形態素[MATH]-gramモデルと呼ばれる．
形態素[MATH]-gramモデルにおいて場合に問題となるのは，状態に対応する形態素(既知形態素)の選択である．
一般的には，頻度の高い形態素を既知形態素とすることで高い予測力が実現できる．
しかし，どのような形態素の集合を選択したとしても，テストコーパスに出現する可能性のあるすべての形態素が既知形態素であることは望めない．
このため，未知形態素の扱いが避けられない問題となる．
この問題に対処するため，未知形態素に対応する特別な記号を用意し，既知の形態素以外はこの記号から次節で述べる未知語モデルにより与えられる確率で生成されることとする．
未知形態素に対応する特別な記号は，かならずしも唯一である必要はなく，品詞などの情報を用いて区別される複数の記号であっても良い．
我々の目的は形態素解析であるから未知形態素であっても品詞の推定が可能でなければならない．
よって，各品詞に対して未知形態素に対応する記号を設ける．
以上に述べた形態素[MATH]-gramモデル[MATH]による，形態素列の出現確率は以下の式で表される．
ただし[MATH]は既知形態素の集合を表わし，[MATH]は[MATH]の品詞を表わす．
また，[MATH]は品詞[MATH]に属する未知形態素に対応する特別な記号である．
この式の中の[MATH]は，次項で述べる未知語モデルであり，品詞が[MATH]であることを条件として，引数で与えられる文字列の生成確率を値とする．
確率値の最尤推定においては，まず既知形態素集合を定義し，学習コーパスの未知形態素を未知形態素に対応する特別な記号に置き換えて頻度を計数する．
未知語モデルは，表記から確率値への写像として定義され，既知形態素以外のあらゆる形態素の表記を0より大きい確率で生成し，この確率をすべての表記に渡って合計すると1以下になる必要がある．
このような条件を満たすモデルの一つとして，文字[MATH]-gramモデルがある．
日本語の表記に用いられる文字は有限と考えられるので，形態素[MATH]-gramモデルのときの未知形態素のような問題は起こらない．
しかし，形態素[MATH]-gramモデルの場合と同様に，文字を既知文字と未知文字に分類し，未知文字はこれを表わす特別な記号から生成されるものとすることもできる．
文字の使用頻度には大きな偏りがあることが予測されるので，これらを一つのグループとみなすことで，モデルが改善されると考えられる．
文字集合は有限であるから，未知形態素モデルの場合と異なり，各未知文字の生成確率を等確率とすることができる．
このようにして構成される未知語モデルは以下の式で表わされる．
ただし[MATH]は品詞が[MATH]である未知語モデルの既知文字の集合を表わし，[MATH]は品詞[MATH]の未知語モデルの未知文字に対応する特別な記号である．
また，[MATH]としている．
この式の中の[MATH]は，語頭に対応する便宜的な記号である．
また，[MATH]は，語末に対応する特別な記号であり，形態素に対するモデルの場合と同様に，すべての可能な文字列に対する確率の和が1となるために導入されている．
以上で説明した未知語モデルは，未知文字を等確率で生成するモジュールを「未知文字モデル」と考えると，形態素[MATH]-gramモデルと相似の構造である．
文字[MATH]-gramモデルの確率値は，形態素[MATH]-gramモデルの場合と同様に，既知文字を定義した後，未知形態素の実例における文字列の頻度から推定される．
上述したように，形態素[MATH]-gramモデルのパラメータ推定には，出現頻度を基にした最尤推定が用いられる．
しかし，対象とする事象の頻度が低い場合には，推定値の信頼性は低くなるという問題がある．
この問題に対処する方法として，補間と呼ばれる方法が用いられる[CITE]．
これは，次の式で表されるように，より信頼性が高いことが期待される，より低次のマルコフモデルの遷移確率を一定の割合で足し合わせるという操作を施すことを言う．
係数[MATH]の値は，確率値[MATH]の推定に用いられるコーパスとは別に用意された比較的小さいコーパスを用いて最尤推定される．
この方法では，確率値の推定に用いることができるコーパスの大きさが小さくなり，推定値の信頼性が少しではあるが低下するという問題がある．
これに対処する方法として削除補間[CITE]と呼ばれる方法がある．
これは，パラメータ推定のためのコーパスを[MATH]個に分割し，[MATH]個の部分で確率値を推定し，残りの部分で補間の係数を推定するということを全ての組合せ([MATH]通り)に渡って行ない，その平均値をとるという方法である．
形態素[MATH]-gramモデルによる形態素解析器は，入力として文字列[MATH]を受けとり，式([REF_equation:morph_n-gram1])([REF_equation:morph_n-gram2]) ([REF_equation:ukwmodel1])([REF_equation:ukwmodel2])([REF_equation:m-inter])を用いて計算される確率が最大の形態素列[MATH]を式([REF_equation:condition])で表わされる条件の下で計算し出力する．
解の探索には動的計画法を用いることができ，入力の文字数[MATH]に対して計算時間のオーダーが[MATH]となるアルゴリズムが提案されている[CITE] [CITE]．
この章では，確率的形態素解析の精度を向上させる方法として，未知語モデルに外部辞書を付加する方法を提案する．
これは，確率的言語モデルの予測力を改善する方法であり，確率的形態素解析の精度向上を直接の目的としているわけではないが，確率的言語モデルの予測力の改善は，結果としてそれに基づく確率的形態素解析器の解析精度を向上させる．
また，予測力の高い未知語モデルを推定するための未知形態素の実例の収集方法についても述べる．
前章で述べた未知語モデル[MATH]は，未知形態素だけでなく既知形態素の表記も0より大きい確率で生成する可能性がある．
この場合には，以下の式が示すように，未知形態素の生成確率の合計は1未満となる．
以下の説明では品詞[MATH]を省略してある．
また，形態素の集合を表わす記号[MATH]をその表記の集合を表わすとしている．
これは，言語モデルとしての条件を満たしてはいるが，クロスエントロピーという点で改善の余地がある．
つまり，既知形態素の生成確率を何らかの方法で未知形態素に分配することで，未知形態素の生成確率が大きくなり，テストコーパスにそのような未知形態素が出現した場合に，テストコーパスの出現確率が大きくなる．
既知形態素の生成確率の分配には，様々な方法が考えられるが，以下の式が表すように，すべての未知形態素にその生成確率に比例して分配する方法が一般的であろう．
これに対して我々は，辞書の見出し語などとして与えられる形態素の部分集合に等しく配分することを提案する．
つまり，ある形態素の集合が与えられたとして，ここから既知形態素を除いた集合を[MATH] ([MATH])として，この要素の生成確率を文字[MATH]-gramモデルによる確率と既知形態素の生成確率の合計を[MATH]の要素数で割った値の和とする．
これは，既知形態素の生成確率を，学習コーパスには現れないが辞書などから形態素であると考えられる文字列に優先的に分配し，それらの生成確率を相対的に高くすることを意味する．
このような文字列の集合を外部辞書と呼ぶ．
形態素解析が目的なので，外部辞書には文字列のほかにその品詞が記述されている必要がある．
この方法により，確率言語モデルの枠内で，コーパスから推定された確率言語モデルに辞書などの異なる情報源の情報を付加できる．
以上に述べた外部辞書を備えた未知語モデル[MATH]による文字列[MATH]の出現確率は以下の式で表される．
これを式([REF_equation:ukwmodel0])の代わりに用いる未知語モデルを外部辞書を備えた未知語モデルと呼ぶ．
文字[MATH]-gramモデルの確率値は，形態素[MATH]-gramモデルの場合と同様に，アルファベットを定義してから，未知形態素の実例における文字列の頻度から推定される．
未知形態素の実例の収集の方法としては，学習コーパスに含まれるすべての形態素とすることや，学習コーパスにおける頻度が1である形態素とする[CITE]などが考えられる．
我々は，削除補間法を応用した以下の方法を提案する．
学習コーパスを[MATH]個の部分コーパスに分割し，[MATH]番目の部分コーパスの未知形態素の実例を，[MATH]番目の部分コーパス以外を学習コーパスとし[MATH]番目の部分コーパスをテストコーパスと見た場合の未知形態素とする．
我々が提案する方法は，削除補間法を応用して，実際のテストコーパスにおける未知形態素と類似した実例を得ているので，他の方法よりも優れていると予測される．
実際に，予備実験としてこれらの方法を実装し，予測力という規準で比較した．
その結果，我々が提案する方法が最良であった．
したがって，実験にはこの方法を用いた．
この章では，形態素[MATH]-gramモデルの一般化の一つであるクラス[MATH]-gramモデルを説明し，文献(提出中)を応用して形態素解析のためのクラスを自動的に学習する方法を提案する．
前章と同様に，確率的言語モデルの予測力の改善を目的としているが，学習されたクラス[MATH]-gramモデルに基づく確率的形態素解析器の解析精度は，形態素[MATH]-gramモデルや人間の言語直観による品詞をクラスとした場合の品詞[MATH]-gramモデルに基づく確率的形態素解析器の解析精度より高くなると考えられる．
クラス[MATH]-gramモデル[CITE]では，あらかじめ形態素をクラスと呼ばれるグループに分類しておき，先行するクラスの列を直前の事象とみなして分類する．
このモデルでは，次の形態素を直接予測するのではなく，次のクラスを予測した上で次の形態素を予測する．
以下の式で，[MATH]は既知形態素に対応するクラスであり，これを品詞とすれば，品詞[MATH]-gramモデルとなる．
この式の中の[MATH]は，文頭に対応する特別な記号である．
これを導入することによって式が簡便になる．
また，[MATH]は，語末に対応する特別な記号であり，これを導入することによって，すべての可能な文字列に対する確率の和が1となる[CITE]．
形態素に基づくモデルの場合と同様に，確率[MATH]の値および，確率[MATH]の値は，コーパスから最尤推定することで得られる．
この式において，クラスを品詞とすれば品詞[MATH]-gramモデルが得られ，形態素からクラスへの写像が全単射であれば，形態素[MATH]-gramモデルと等価になることが分かる．
また，これをマルコフモデルと考えると，状態はクラスに対応する．
形態素[MATH]-gramモデルと同様に，データスパースネスの問題に対処する方法として，補間を用いることができる[CITE]．
これは，以下のように式([REF_equation:m-inter])において形態素[MATH]をクラス[MATH]と読み変えれることで容易に得られる．
確率言語モデルの形態素クラスタリングの課題は，クロスエントロピーが最も低くなる形態素とクラス(図[REF_figure:concept]の中の[MATH])の対応関係を算出することである．
このようなクラスを用いて構築されたクラス[MATH]-gramモデルに基づく確率的形態素解析器の解析精度は，品詞[MATH]-gramモデルや形態素[MATH]-gramモデルに基づく確率的形態素解析器の解析精度よりも高くなることが期待される．
従って，形態素クラスタリングの目的関数は，削除補間を応用することでクロスエントロピーを模擬すると考えられる以下のような値とした．
ここで，[MATH]は[MATH]番目以外の[MATH]の部分コーパスから推定された確率言語モデルであり，[MATH]は[MATH]番目の部分コーパス(文の列)を表す．
ここで問題としているのは，確率的言語モデルとしてクラス[MATH]-gramモデルを用いた場合の形態素のクラスタリングである．
この場合，コーパスは一定であり，確率的言語モデル[MATH]は形態素とクラスの関係[MATH]にのみ依存する．
従って，上式の平均クロスエントロピーは，形態素とクラスの関係の関数とみなすことができる．
この値がより小さいほうが，未知のコーパスに対してより良い言語モデルであることが予測される．
よって，クラスタリングの目的は，式([REF_equation:criterion])で定義される平均クロスエントロピーを最小化する形態素とクラスの関係を求めることである．
形態素とクラスの対応関係としては，ある形態素が一定の確率で複数のクラスに属するという確率的な関係も考えられるが，解空間が広大になるので，本研究では形態素は唯一のクラスに属することを仮定した．
よって，クラスの集合は形態素の集合の直和分割となる．
形態素とクラスの対応関係[MATH]は，[MATH]をそれぞれ形態素の集合とクラスの集合とすると，関数[MATH]を用いて表すことができ，この関数は以下の条件を満たす．
解探索のアルゴリズム中で用いるために，形態素とクラスの対応関係に対して，以下の関数を定義する．
[MATH]
[MATH]は，形態素とクラスの関係[MATH]に対して形態素[MATH]をクラス[MATH]に移動した結果得られる形態素とクラスの関係を返す．
クラスタリングの解空間はあらゆる可能な形態素とクラスの対応関係である．
しかし，この数はある程度の大きさの語彙数に対しては非常に大きいため，これら全てに対して平均クロスエントロピーを計算し，これを最小化するクラス関係を選択するということは，計算量という観点から不可能である．
平均クロスエントロピーの値はクラス関係の一部分の変更が全体に影響するという性質をもっているので，分割統治法や動的計画法を用いることもできない．
以上のことから，我々は最適解を求めることを諦め，貪欲アルゴリズムを用いることにした．
このアルゴリズムは以下の通りである(図[REF_figure:clustering]参照)．
なお，[MATH]は式([REF_equation:criterion])で与えられる平均クロスエントロピーでり，[MATH]や[MATH]は形態素[MATH]やクラス[MATH]の品詞を表わす．
同一の品詞である形態素に対してのみ併合を試みるので，結果としてどのクラスも同一の品詞の形態素のみを要素に持つことに注意しなければならない．
計算量は，二番目のforeachでの繰り返しの回数は単語数[MATH]に比例し，argminでの繰り返しの回数はクラス数[MATH]に比例するので，全体で[MATH]である．
クラス数[MATH]は，全ての単語が独立したクラスに分けられる場合に最大([MATH])となり，全ての単語が同一のクラスとなる場合に最小([MATH])となる．
従って，初期化における全体の計算量は，最良の場合が[MATH]であり，最悪の場合が[MATH]である．
ただし，単語の並べ替えや一番目のforeachの計算量は係数が非常に小さいと考えられるので，考慮に入れていない．
次節で述べる実験の結果では，頻度の高い形態素を対象とする段階では多くの形態素がクラスに併合されずクラス数は形態素数に比例し最悪の場合に近い挙動を示したが，頻度の低い形態素を対象とする段階ではほとんどの形態素がクラスに併合されてクラス数はほとんど一定となり最良の場合に近い挙動を示した．
頻度の低い形態素が多数を占めるので，計算量は実際にはかなり線形に近いと考えられる．
頻度の高い形態素から移動を試みることとしているのは，頻度の高い形態素の移動のほうがパープレキシティに与える影響が大きいと考えられるので，早い段階での移動が後の移動によって影響されにくく，収束がより速くなると考えたためである．
上述のアルゴリズムによって得られたクラス分類からさらに探索を進めてより良いクラス分類が得られるかを試みることができる．
このアルゴリズムとして，さらに形態素の移動を試みること[CITE]やクラスの併合を試みること[CITE]が考えられる．
我々は，これらのアルゴリズムを小さなコーパスに対する予備実験で適用してみたが，必要となる計算時間が膨大である割にはクロスエントロピーの改善が小さかった．
よって，次章では，上述のアルゴリズムによる実験結果について述べる．
