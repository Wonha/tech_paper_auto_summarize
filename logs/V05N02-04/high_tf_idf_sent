================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.30041] 本論文では，形態素クラスタリングと未知語モデルの改良による確率的形態素解析器の精度向上を提案する．
[i:1, score:0.36417] 形態素クラスタリングとしては，形態素[MATH]-gramモデルをクロスエントロピーを基準としてクラス[MATH]-gramモデルに改良する方法を提案する．
[i:3, score:0.31477] bi-gramモデルを実装しEDRコーパスを用いて実験を行なった結果，形態素解析の精度の向上が観測された．

================================================================
[section type  : intro]
[section title : まえがき]
================================================================
[i:21, score:0.32868] 我々は，この問題に対処するために，予測力を最大にするという観点よって算出したクラスと呼ばれる単語のグループを一つの状態に対応させ，基礎となる確率言語モデルを改良し，結果として形態素解析の精度を向上する方法を提案する．
[i:24, score:0.33267] これらに対して，文献(提出中)では削除補間[CITE]を応用したクラスタリング規準とそれを用いたクラスタリングアルゴリズムを提案し，クラス[MATH]-gramモデルの予測力が有意に向上したことを報告している．
[i:25, score:0.37072] 本論文では，この方法を応用することで得られるクラス[MATH]-gramモデルを基礎にした確率的形態素解析器による解析精度の向上について報告する．

================================================================
[section type  : proposed_method]
[section title : 確率的形態素解析]
================================================================
[i:29, score:0.20120] この節では，これを実現する手法の一つとしての確率的形態素解析とその基礎となる確率言語モデルと解の探索方法について述べる．
-----------------------------------------------------
  [subsection title : 形態素解析の問題の定義]
-----------------------------------------------------
  [i:lead, score:0.15447] 日本語の形態素解析は，日本語のアルファベット[MATH]のクリーネ閉包に属する文[MATH]を入力として，これを表記[MATH]と品詞[MATH]の直積として定義される形態素[MATH]の列[MATH]に分解して出力することと定義できる．
.....
  [i:30, score:0.15447] 日本語の形態素解析は，日本語のアルファベット[MATH]のクリーネ閉包に属する文[MATH]を入力として，これを表記[MATH]と品詞[MATH]の直積として定義される形態素[MATH]の列[MATH]に分解して出力することと定義できる．
  [i:35, score:0.14287] 形態素解析の問題は，可能な解の中から人間の判断(正解)に最も近いと推測される形態素列(単語分割と品詞割り当て)を選択し出力することである．
  [i:36, score:0.21018] この選択の基準としては，文法の専門家が自身の言語直観を頼りにした規則に基づく方法と大量の正解例(形態素解析済みコーパス)からの推定を規準にする方法がある．
-----------------------------------------------------
  [subsection title : 確率的形態素解析]
-----------------------------------------------------
  [i:lead, score:0.26635] 確率的形態素解析器は，品詞という概念を内包する確率的言語モデルを基にして，与えられた文字列[MATH]に対する確率最大の形態素列[MATH]を計算し出力する．
.....
  [i:74, score:0.31832] しかし，形態素[MATH]-gramモデルの場合と同様に，文字を既知文字と未知文字に分類し，未知文字はこれを表わす特別な記号から生成されるものとすることもできる．
  [i:83, score:0.35763] 文字[MATH]-gramモデルの確率値は，形態素[MATH]-gramモデルの場合と同様に，既知文字を定義した後，未知形態素の実例における文字列の頻度から推定される．
  [i:92, score:0.40470] 形態素[MATH]-gramモデルによる形態素解析器は，入力として文字列[MATH]を受けとり，式([REF_equation:morph_n-gram1])([REF_equation:morph_n-gram2]) ([REF_equation:ukwmodel1])([REF_equation:ukwmodel2])([REF_equation:m-inter])を用いて計算される確率が最大の形態素列[MATH]を式([REF_equation:condition])で表わされる条件の下で計算し出力する．

================================================================
[section type  : proposed_method]
[section title : 未知語モデルの改良]
================================================================
[i:94, score:0.28389] この章では，確率的形態素解析の精度を向上させる方法として，未知語モデルに外部辞書を付加する方法を提案する．
[i:95, score:0.26984] これは，確率的言語モデルの予測力を改善する方法であり，確率的形態素解析の精度向上を直接の目的としているわけではないが，確率的言語モデルの予測力の改善は，結果としてそれに基づく確率的形態素解析器の解析精度を向上させる．
[i:96, score:0.21301] また，予測力の高い未知語モデルを推定するための未知形態素の実例の収集方法についても述べる．
-----------------------------------------------------
  [subsection title : 外部辞書の付加]
-----------------------------------------------------
  [i:lead, score:0.25084] 前章で述べた未知語モデル[MATH]は，未知形態素だけでなく既知形態素の表記も0より大きい確率で生成する可能性がある．
.....
  [i:97, score:0.25084] 前章で述べた未知語モデル[MATH]は，未知形態素だけでなく既知形態素の表記も0より大きい確率で生成する可能性がある．
  [i:102, score:0.23663] つまり，既知形態素の生成確率を何らかの方法で未知形態素に分配することで，未知形態素の生成確率が大きくなり，テストコーパスにそのような未知形態素が出現した場合に，テストコーパスの出現確率が大きくなる．
  [i:105, score:0.31156] つまり，ある形態素の集合が与えられたとして，ここから既知形態素を除いた集合を[MATH] ([MATH])として，この要素の生成確率を文字[MATH]-gramモデルによる確率と既知形態素の生成確率の合計を[MATH]の要素数で割った値の和とする．
-----------------------------------------------------
  [subsection title : 未知形態素の実例の収集方法]
-----------------------------------------------------
  [i:lead, score:0.33742] 文字[MATH]-gramモデルの確率値は，形態素[MATH]-gramモデルの場合と同様に，アルファベットを定義してから，未知形態素の実例における文字列の頻度から推定される．
.....
  [i:112, score:0.33742] 文字[MATH]-gramモデルの確率値は，形態素[MATH]-gramモデルの場合と同様に，アルファベットを定義してから，未知形態素の実例における文字列の頻度から推定される．
  [i:115, score:0.18910] 学習コーパスを[MATH]個の部分コーパスに分割し，[MATH]番目の部分コーパスの未知形態素の実例を，[MATH]番目の部分コーパス以外を学習コーパスとし[MATH]番目の部分コーパスをテストコーパスと見た場合の未知形態素とする．
  [i:116, score:0.22852] 我々が提案する方法は，削除補間法を応用して，実際のテストコーパスにおける未知形態素と類似した実例を得ているので，他の方法よりも優れていると予測される．

================================================================
[section type  : proposed_method]
[section title : 形態素クラスタリング]
================================================================
[i:121, score:0.43629] 前章と同様に，確率的言語モデルの予測力の改善を目的としているが，学習されたクラス[MATH]-gramモデルに基づく確率的形態素解析器の解析精度は，形態素[MATH]-gramモデルや人間の言語直観による品詞をクラスとした場合の品詞[MATH]-gramモデルに基づく確率的形態素解析器の解析精度より高くなると考えられる．
-----------------------------------------------------
  [subsection title : クラス$n$-gramモデル]
-----------------------------------------------------
  [i:lead, score:0.28241] クラス[MATH]-gramモデル[CITE]では，あらかじめ形態素をクラスと呼ばれるグループに分類しておき，先行するクラスの列を直前の事象とみなして分類する．
.....
  [i:122, score:0.28241] クラス[MATH]-gramモデル[CITE]では，あらかじめ形態素をクラスと呼ばれるグループに分類しておき，先行するクラスの列を直前の事象とみなして分類する．
  [i:124, score:0.31694] 以下の式で，[MATH]は既知形態素に対応するクラスであり，これを品詞とすれば，品詞[MATH]-gramモデルとなる．
  [i:129, score:0.30062] この式において，クラスを品詞とすれば品詞[MATH]-gramモデルが得られ，形態素からクラスへの写像が全単射であれば，形態素[MATH]-gramモデルと等価になることが分かる．
-----------------------------------------------------
  [subsection title : 形態素クラスタリング]
-----------------------------------------------------
  [i:lead, score:0.33330] 確率言語モデルの形態素クラスタリングの課題は，クロスエントロピーが最も低くなる形態素とクラス(図[REF_figure:concept]の中の[MATH])の対応関係を算出することである．
.....
  [i:133, score:0.33330] 確率言語モデルの形態素クラスタリングの課題は，クロスエントロピーが最も低くなる形態素とクラス(図[REF_figure:concept]の中の[MATH])の対応関係を算出することである．
  [i:134, score:0.37836] このようなクラスを用いて構築されたクラス[MATH]-gramモデルに基づく確率的形態素解析器の解析精度は，品詞[MATH]-gramモデルや形態素[MATH]-gramモデルに基づく確率的形態素解析器の解析精度よりも高くなることが期待される．
  [i:137, score:0.32756] ここで問題としているのは，確率的言語モデルとしてクラス[MATH]-gramモデルを用いた場合の形態素のクラスタリングである．

================================================================
[section type  : experiment_result]
[section title : 実験結果とその評価]
================================================================
[i:168, score:0.12385] 形態素クラスタリングによる解析精度の向上
[i:170, score:0.17921] また，文法の専門家による形態素解析器との解析精度の比較を行なった結果について述べる．
[i:171, score:0.31513] なお以下では，「クラス[MATH]-gramモデル」などの言語モデルを表す表現を，文脈から明らかな場合には，その言語モデルに基づく形態素解析器を表すためにも用いる．
-----------------------------------------------------
  [subsection title : 評価基準]
-----------------------------------------------------
  [i:lead, score:0.02849] 我々が用いた評価基準は，[CITE]で用いられた再現率と適合率であり，次のように定義される．
.....
  [i:173, score:0.17013] EDRコーパスに含まれる形態素数を[MATH]，解析結果に含まれる形態素数を[MATH]，分割と品詞の両方が一致した形態素数を[MATH]とすると，再現率は[MATH]と定義され，適合率は[MATH]と定義される．
  [i:175, score:0.10764] この場合，分割と品詞の両方が一致した形態素は「は(助詞)」と「な(形容詞)」と「い(形容詞語尾)」であるので，[MATH]となる．
  [i:176, score:0.11806] また，コーパスには6つの形態素が含まれ，解析結果には5つの形態素が含まれているので，[MATH]である．
-----------------------------------------------------
  [subsection title : 実験の条件]
-----------------------------------------------------
  [i:lead, score:0.03941] 実験にはEDRコーパス[CITE]を用いた．
.....
  [i:180, score:0.35876] 前章で述べたように，クラス関数の推定では，この9個の学習コーパスのうちの8つから[MATH]-gramモデルを推定し，残りの1つのコーパスに対してクロスエントロピーを求めるということを9通り行なって得られる平均クロスエントロピーを評価規準とする．
  [i:184, score:0.41026] 同様に，クラスbi-gramモデルは，既知形態素をクラスタリングすることで得られるクラスに対応する状態と，各品詞の未知語に対応する状態と文区切りに対応する状態を持つ．
  [i:185, score:0.36515] 形態素bi-gramモデルとクラスbi-gramモデルを比較するために，これらを同じ学習コーパスから構成し，同じテストコーパスに対してパープレキシティや形態素解析の精度を計算した．
-----------------------------------------------------
  [subsection title : 外部辞書と形態素クラスタリングによる精度向上の評価]
-----------------------------------------------------
  [i:lead, score:0.45345] 図[REF_figure:result]は，形態素クラスタリングの結果を用いたクラスbi-gramモデルの，外部辞書を持つ場合と持たない場合の，クロスエントロピーと形態素解析の精度である．
.....
  [i:203, score:0.45345] 図[REF_figure:result]は，形態素クラスタリングの結果を用いたクラスbi-gramモデルの，外部辞書を持つ場合と持たない場合の，クロスエントロピーと形態素解析の精度である．
  [i:213, score:0.43927] 表[REF_table:result]は，外部辞書を備えない場合と備えた場合の，形態素bi-gramモデルとクラスbi-gramモデルによるクロスエントロピーと形態素解析の精度である．
  [i:219, score:0.41283] クロスエントロピーと解析精度の関係が逆になっている例(上述の関係の反例)として，表[REF_table:result]の中の「形態素bi-gram+外部辞書」と「クラスbi-gram」のエントロピーと適合率が挙げられる．
-----------------------------------------------------
  [subsection title : 文法の専門家による形態素解析器との比較]
-----------------------------------------------------
  [i:lead, score:0.23948] 我々は，上述の実験に加えて，文法の専門家による形態素解析器と確率的形態素解析器を解析精度という点で比較するという実験を行なった．
.....
  [i:244, score:0.50746] つまり，コーパスを学習コーパスとテストコーパスに分割し(表[REF_table:corpus-juman])，学習コーパスから構成した確率的形態素解析器(外部辞書を備えたクラスbi-gramモデル)とJUMANを用いてテストコーパスを解析した結果を，テストコーパスにあらかじめ付与されている正解と比較して，それぞれの再現率と適合率を計算した．
  [i:250, score:0.51061] 未知語モデルを文字クラスタリングしたクラス[MATH]-gramモデルとすることや，外部辞書の源としてJUMANの辞書や別のコーパスをJUMANで解析した結果から得られる学習コーパスに現れない高頻度の形態素を用いることで，確率的形態素解析器の精度はさらに向上すると考えられる．
  [i:254, score:0.36016] 現状での学習コーパスの大きさは[MATH]文字と比較的小規模であり，図[REF_figure:result]のEDRコーパスにおける学習コーパスの大きさと解析精度の関係から，コーパスを増量し確率言語モデルを再学習するということを繰り返すことで，この品詞体系でのより高精度の形態素解析器が容易に実現できると予測される．

================================================================
[section type  : conclusion]
[section title : むすび]
================================================================
[i:278, score:0.36417] 形態素クラスタリングとしては，形態素[MATH]-gramモデルをクロスエントロピーを基準としてクラス[MATH]-gramモデルに改良する方法を提案した．
[i:279, score:0.31477] bi-gramモデルを実装しEDRコーパスを用いて実験を行なった結果，形態素解析の精度の向上が観測された．
[i:283, score:0.29849] 両方の改良を行なったモデルによる形態素解析実験の結果の精度は，先行研究として報告されている品詞tri-gramモデルの精度を上回った．

