NMF と初期値の問題


\subsection{NMF とその特徴}

NMF は\( m \times n \)の索引語文書行列\( X \)を，\( m \times k \)の行列\( U \)と
\( n \times k \)の行列\( V \)の転置行列\( V^{T} \)の積に分解する\cite{nmf}．
ただし\( k \)はクラスタ数である．
\[
X = U V^{T}   
\]

NMF はクラスタに対応したトピックの次元を\( k \)個想定し，その基底ベクトルの線形和によって，
文書ベクトル及び索引語ベクトルを表現することに対応する．
つまり基底ベクトルの係数が，そのトピックとの関連度を表しているので，
行列\( V \)自体がクラスタリング結果と見なせる．
具体的には，\( i \)番目の文書\( d_i \)は，
行列\( X \)の第\( i \)列のベクトルで表現され，
その次元圧縮された結果が，行列\( V \)の第\( i \)行のベクトルとなる．
このとき，\( V \)の第\( i \)行のベクトルは
\[
(v_{i1}, v_{i2}, \cdots, v_{ik})
\]
と表せ，文書\( d_i \)のクラスタの番号は
\[
\arg \max_{j \in 1:k} v_{ij}
\]
となる．

\subsection{NMF のアルゴリズム}

与えられた索引語文書行列\( X \)から，\( U \)と\( V \)は
以下の繰り返しで得ることができる\cite{lee00algorithms}． 
\begin{gather}
  \label{eq:1}
 u'_{ij} \leftarrow u_{ij} \frac{(XV)_{ij}}{(UV^{T}V)_{ij}}   \\
  \label{eq:2}
 v'_{ij} \leftarrow v_{ij} \frac{(X^{T}U)_{ij}}{(VU^{T}U)_{ij}} 
\end{gather}

ここで \( u_{ij} \)と\( v_{ij} \)はそれぞれ\( U \)と\( V \)の\( i \)行\( j \)列の
要素を表す．また \( (X)_{ij} \) により行列\( X \)の\( i \)行\( j \)列の要素を表す．
上記の式により，現在の\( U \)と\( V \)から，\( u'_{ij} \)と\( v'_{ij} \) が得られる，
つまり新たな\( U' \)と\( V' \)が得られるので，それを\( U \)と\( V \)と見なして，
上記の式を繰り返し適用する．

また各繰り返しの後に\( U \)を以下のように正規化する．
\begin{equation}
 u'_{ij} \leftarrow \frac{u_{ij}}{\sqrt{\sum_{i} u_{ij}^2}} 
\end{equation}

繰り返しの終了は，繰り返しの最大回数を決めておくか，
\( UV^{T} \)と\( X \)との距離\( J \)の変化量から判定する．
\begin{equation}
  \label{eq:3}
J = || X - UV^{T} ||_{F}           
\end{equation}

\( J \)の値は NMF の分解の精度を表現している．NMF ではこの分解の精度が
クラスタリングの目的関数となっており，この分解の精度が高い，つまり\( J \)の値が
小さいほど，良好なクラスタリングであると推定する．

また\( || \cdot ||_{F} \)は Frobenius ノルムを表し，\( m \times n \) の行列\( A \)の
Frobenius ノルムは以下で定義される．
\[
|| A ||_{F} = \sqrt{\sum_{i = 1}^{m} \sum_{j = 1}^{n} {a_{ij}}^2}
\]


\subsection{NMF の解の多様性}

通常，行列\( V \)と\( U \)の初期値にはランダムな値を与える．
しかし\mbox{式\ref{eq:1}と\ref{eq:2}}による繰り返しは局所最適解にしか収束しないために，
\( V \)と\( U \)の初期値の与え方によって，最終的に得られる\( V \)と\( U \)は大きく異なり，
結果としてクラスタリングの精度も大きく異なる．

例えば，\mbox{図\ref{tr45a}}は本論文の実験で用いた文書データセット tr45 に対して，
NMF によるクラスタリングの実験を20回行った結果である．
ただし各実験での NMF の初期値にはランダムな値を与えており，
各実験の初期値は異なる．
\mbox{図\ref{tr45a}}の横軸は実験の番号を示し，縦軸はクラスタリングの精度を表している．
\mbox{図\ref{tr45a}}から初期値によって得られる精度が大きく異なることが確認できる．

\begin{figure}[t]
\begin{center}
\includegraphics{14-5ia4f1.eps}
\caption{初期値とクラスタリングの精度}\label{tr45a}
\end{center}
\end{figure}

つまり，NMF は初期値によって得られるクラスタリング結果が異なる．
通常は適当な初期値を与える実験を複数回行い，
それらから得た複数個の解の中で\( X \)の分解の精度が最も高いものを選ぶ．
しかし分解の精度は，直接的にはクラスタリングの精度を意味していないため，
最も精度の高いクラスタリング結果を選択できる保証がない．

ここでは複数個のクラスタリング結果から1つを選択するのではなく，
それらをアンサンブルするアンサンブルクラスタリングを試みる．


アンサンブルクラスタリング


\subsection{ハイパーグラフによるデータの再表現}

本手法のアンサンブルクラスタリングでは，NMF の初期値を様々に変化させて，
複数個のクラスタリング結果を生成する．次に複数個得られたクラスタリング結果から
各データに対するベクトル表現を新たに作成し，その新たにベクトル表現されたデータに
対してクラスタリングを行うことで，アンサンブルクラスタリングを実現する．

ここでは複数個得られたクラスタリング結果からデータに対する新たなベクトル表現を
作る方法を説明する．基本的には論文\cite{strehl02}で提案された
ハイパーグラフを用いる．

クラスタの数が\( k \)個であり，得られているクラスタリング結果が\( m \)種類の場合，
各データは\( k m \)次元のベクトルで表現される．
データ\( d \)の\( k (i - 1) + c \)次元の値は，
\( i \)番目のクラスタリング結果として，データ\( d \)が
クラスタ番号\( c \)のクラスタに属していれば 1 を，属していなければ 0 を与える．
この結果，データ\( d \)の\( k m \)次元のベクトル表現が得られる．

例を示す．\( k = 3\)，\( m = 4\)とする．またデータは\( \{ d_1,d_2, \cdots, d_7 \} \) の
7つとする．4種類のクラスタリング結果が以下のようになっていたとする．

第1のクラスタリング結果：
\[
\{ d_1,d_2,d_5 \}, \{ d_3,d_4 \}, \{ d_6,d_7 \}
\]
この結果から目的の行列の1列目から3列目が得られる．
\[
                        \begin{array}{c}
                                 d_1\\
                                 d_2\\
                                 d_3\\
                                 d_4\\
                                 d_5\\
                                 d_6\\
                                 d_7\\
                        \end{array}
\left[
                        \begin{array}{rrr}
                                 1& 0& 0\\
                                 1& 0& 0\\
                                 0& 1& 0\\
                                 0& 1& 0\\
                                 1& 0& 0\\
                                 0& 0& 1\\
                                 0& 0& 1
                        \end{array}
\right]
\]

第2のクラスタリング結果：
\[
\{ d_1,d_5 \}, \{ d_2,d_3 \}, \{ d_4,d_6,d_7 \}
\]
この結果から目的の行列の4列目から6列目が得られる．
\[
                        \begin{array}{c}
                                 d_1\\
                                 d_2\\
                                 d_3\\
                                 d_4\\
                                 d_5\\
                                 d_6\\
                                 d_7\\
                        \end{array}
\left[
                        \begin{array}{rrr}
                                 1& 0& 0\\
                                 0& 1& 0\\
                                 0& 1& 0\\
                                 0& 0& 1\\
                                 1& 0& 0\\
                                 0& 0& 1\\
                                 0& 0& 1
                        \end{array}
\right]
\]


第3のクラスタリング結果：
\[
\{ d_2,d_5 \}, \{ d_1, d_4 \}, \{ d_3, d_6,d_7 \}
\]
この結果から目的の行列の7列目から9列目が得られる．
\[
                        \begin{array}{c}
                                 d_1\\
                                 d_2\\
                                 d_3\\
                                 d_4\\
                                 d_5\\
                                 d_6\\
                                 d_7\\
                        \end{array}
\left[
                        \begin{array}{rrr}
                                 0& 1& 0\\
                                 1& 0& 0\\
                                 0& 0& 1\\
                                 0& 1& 0\\
                                 1& 0& 0\\
                                 0& 0& 1\\
                                 0& 0& 1
                        \end{array}
\right]
\]


第4のクラスタリング結果：
\[
\{ d_1,d_5,d_7 \}, \{ d_3,d_4 \}, \{ d_2, d_6 \}
\]
この結果から目的の行列の10列目から12列目が得られる．
\[
                        \begin{array}{c}
                                 d_1\\
                                 d_2\\
                                 d_3\\
                                 d_4\\
                                 d_5\\
                                 d_6\\
                                 d_7\\
                        \end{array}
\left[
                        \begin{array}{rrr}
                                 1& 0& 0\\
                                 0& 0& 1\\
                                 0& 1& 0\\
                                 0& 1& 0\\
                                 1& 0& 0\\
                                 0& 0& 1\\
                                 1& 0& 0
                        \end{array}
\right]
\]

以上の4つの行列を結合させ，以下の\( 7 \times 12 \)の行列を得る．
これがハイパーグラフである．このハイパーグラフにおける行ベクトルが，
各データ（本論文の場合，文書）の新たなベクトル表現に対応している．
このベクトルの類似度に基づいて，データをクラスタリングする．
\[
                        \begin{array}{c}
                                 d_1\\
                                 d_2\\
                                 d_3\\
                                 d_4\\
                                 d_5\\
                                 d_6\\
                                 d_7\\
                        \end{array}
\left[
                        \begin{array}{rrrrrrrrrrrr}
 1& 0& 0 &  1& 0& 0 & 0& 1& 0 & 1& 0& 0 \\
 1& 0& 0 &  0& 1& 0 & 1& 0& 0 & 0& 0& 1 \\
 0& 1& 0 &  0& 1& 0 & 0& 0& 1 & 0& 1& 0 \\
 0& 1& 0 &  0& 0& 1 & 0& 1& 0 & 0& 1& 0 \\
 1& 0& 0 &  1& 0& 0 & 1& 0& 0 & 1& 0& 0 \\
 0& 0& 1 &  0& 0& 1 & 0& 0& 1 & 0& 0& 1 \\
 0& 0& 1 &  0& 0& 1 & 0& 0& 1 & 1& 0& 0
                        \end{array}
\right]
\]

\subsection{重み付きハイパーグラフ}

ハイパーグラフが表す行列の各要素の値は 0 か 1 のバイナリ値である．
しかし値の意味を考えれば，その次元に対応する
あるクラスタリング結果のあるクラスタに属する度合いと捉えられる．
そのため 0 か 1 のバイナリ値ではなく，非負の実数値を与える方が適切である．

しかも NMF の場合，各クラスタリング結果では各クラスタに属する度合いに
対応する値が行列\( V \)に記載されている．
そこでここではハイパーグラフの要素が 1 である部分を，
行列\( V \)の値から得ることで，非負の実数値を与えることにした．
このようにして作成したハイパーグラフを，ここでは重み付きハイパーグラフと呼ぶ．

\mbox{図\ref{ensemble}}に重み付きハイパーグラフの作成例を示す．これは先の
第1のクラスタリング結果に対応する部分である．
\( d_1 \) から \( d_7 \)の7個の文書データセットを
NMF により3グループにクラスタリングする．結果は行列\( V \)で表される．
次に行列\( V \)を正規化する．\( V \)の各行に注目し，最大値の部分を 1に，それ以外を
0 に変換したものが通常のハイパーグラフである．
\( V \)の各行に注目し，最大値の部分はそのままに，それ以外を
0 に変換したものが本論文で提案する重み付きハイパーグラフである．

\begin{figure}[tbp]
\begin{center}
\includegraphics{14-5ia4f2.eps}
\caption{行列 V から作られる重み付きハイパーグラフ}\label{ensemble}
\end{center}
\end{figure}



