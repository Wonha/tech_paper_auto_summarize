本論文では，与えられた表現が比喩であるかを判断する基準として，「クローズアップされる特徴がいかに明確か」という点と，「与えられた表現がどの程度新鮮か」という点が重要であることに着目する．
比喩表現の理解とは，概念が持つ，ある特徴を強調することによって，新たな理解を促すものであるから，強調される特徴が明確でなければならない．
``顕現性落差"は，クローズアップされる特徴を抽出し，それらの特徴がいかに明確であるかをはかる尺度である．
また，比喩表現として対比される概念が新鮮であることは，その表現に強い印象を与え，理解を促すことになる．
``意外性"は，対比される概念の組み合わせの新鮮さをはかる尺度である．
このような，二つの尺度を設定することで，その表現の比喩らしさ，すなわち，比喩性を検出できると考えられる．
以下，``顕現性落差''および``意外性''について，比喩性との関係を説明し，両尺度が，比喩性検出にどのように利用できるかについて述べる．
Ortny[CITE]は，比較される概念間の共有特徴が少ない場合でも，それらの類似性が認識されて比喩性が理解される点や，類似性の非対称性に着目し，相互作用モデルを示した．
例えば，``卵のような車''という比喩の場合，たとえる言葉(source概念)``卵''とたとえられる言葉(target概念)``車''の共有特徴[MATH]は，``車''においては顕著な特徴ではないが，``卵''においては，これらの共有特徴は非常に顕著な特徴(顕現特徴)である．
したがって，``車''に対して，``卵''のイメージを重ね合わせることによって，``車''における[MATH]などの特徴を同時に強調し，その結果，``顕現性落差''が生じて，比喩性が検出される．
``顕現性落差''からは，類似性の非対称性が生じるので，同じ概念を比較した場合でも，``車のような卵''という表現からは，比喩性は検出されにくい．
また，source概念が顕著な特徴を持っていたとしても，対比される概念間に共有特徴が認められない場合は，``顕現性落差''が生じないため，比喩性は認識されない．
例えば，``谷底のような車''という表現では，``谷底''と``車''の間には共有特徴が見つけられないので，``顕現性落差''は生じず，比喩性も生じない．
``自動車のような車''では，組み合わせ概念が類似概念であるため，両者の顕現特徴もほとんど共通である．
この場合も，``顕現性落差''は生じにくく，比喩性もあらわれにくいと考えられる．
さらに，比喩とは，意表を突いた言葉(ここでは単語)の組合せによって，伝えたい内容をより鮮明にしたり，強調する働きを持つ．
例えば，``スポーツカーのような車''という比喩の場合，``スポーツカー''と``車''の共有特徴([MATH])={速い，格好いい，燃費が悪い…}は，``車''においては顕著な特徴ではないが，``スポーツカー''において非常に顕著である．
したがって，``車''に対して，``スポーツカー''のイメージを重ね合わせることによって，``車''における{速い，恰好いい，…}などの特徴を同時に強調するが，比喩性は認識されにくい．
この理由は，両概念が上位下位関係を持つために，重複する特徴が多く，かつ，ありふれた組み合わせであるために，表現の新鮮さに欠けるからと考えられる．
本論文では，このような単語間の組合せの新鮮さの度合を``意外性''として扱う．
一般に，同一話題中に頻出する単語対は，たとえ2章の``顕現性落差''の条件を満たしていても，``意外性''が低い．
その結果，比喩としての「新しさ」や「意外さ」が認識されず，比喩性を高める要因とはならない．
反対に，めったに同一話題中に現れない単語対は``意外性''が高く，「新鮮」で「意外」であると認識され，比喩性を高める要因となる．
上記の見地から，``顕現性落差''が大きく，かつ``意外性''も大きい概念対ほど，特徴が明確であり，表現も新鮮に受け取られ，比喩性も大きくなると考えられる．
この考え方と，概念対(比喩・例示・無意味)の区別を対応付けると，表[REF_tbl:relation]のような関係が仮定できる．
概念対において，``顕現性落差''によって，無意味な概念対(無関係対)と意味のある概念対(比喩関係対・例示関係対)が区別でき，``意外性''によって，例示関係対と非例示の概念対(比喩関係対・無関係対)が区別できる．
よって，両者を統合的に利用することで，比喩関係にある概念対が区別できる．
2章で述べたような共有特徴の顕現性落差を扱うために，属性値集合を用いた，確率的な概念記述を用いる．
確率的な概念記述モデルでは，概念は属性値とその生起確率の集合として記述される[CITE]．
概念[MATH]が属性値[MATH]をもち，その生起確率が[MATH]であるとき，[MATH]は以下のように，確率的な属性値集合として記述できる(式([REF_exp:collection]))．
このとき，概念の顕現性は，これらの属性値集合の冗長度(ばらつき具合)から予測可能である．
([REF_exp:collection])で示した概念[MATH]が，[MATH]種類の属性値から成る属性値集合として記述される場合，その冗長度[MATH]は，式([REF_exp:info])を用いて定量化できる[CITE]．
ところで，比喩表現の顕現特徴は，比較される概念間の共有特徴から選ばれるが，同時に，source概念の顕現特徴になっているはずである．
よって，source概念の属性値集合から主要な属性値を取り出し，それらと，target概念の属性値との間で共有できるものを取り出すことで，顕現性落差を考えるためにクローズアップされる共有属性値集合が取り出される．
取り出された共有属性値集合について，source概念とtarget概念の各々における生起確率を用いて冗長度を計算することで，顕現性落差が予測できる．
したがって，source概念[MATH]が，降順で整列した[MATH]個の属性値から成る属性値集合で記述される場合を考えると，まず，生起確率上位から，閾値[MATH]までの範囲内に存在する[MATH]個の属性値([MATH])を，その概念の主要な属性値集合とみなして取り出し(式([REF_exp:set]))，
次に，取り出した属性値集合[MATH]と，target概念[MATH]との間で共有される属性値を探し，それらを，各々の概念における相対頻度の値とともに取り出す．
([REF_exp:set])に関して，source概念[MATH]の主要な属性値集合[MATH]と，target概念[MATH]の間で共有される属性値集合は，[MATH]，[MATH]であり，それらの主要な共有属性値集合(属性値数[MATH]個，[MATH]個)は，式([REF_exp:set1]),([REF_exp:set2])のように表せる．
さらに，それぞれの共有属性値集合の冗長度，[MATH]，[MATH]は，式([REF_exp:var1])，([REF_exp:var2])のように計算できる．
ここで，上記の手順で求められた冗長度は，単に属性値のばらつき具合を示しているにすぎない．
そのため，source概念における共有属性値集合の冗長度が，target概念のそれより小さい(ばらついている)場合でも，共有属性値の生起確率が概念記述全体に対して占める割合が大きいと，顕現特徴となる場合があり，冗長度の差のみでは，顕現性落差を正確に反映できない．
そこで，顕現性落差を反映させるために，対象となる属性値がどの程度主要であるかによって冗長度に重み付けをする．
例えば，図[REF_fig:rep-kage]では，属性値[MATH]の生起確率は，概念[MATH]において[MATH]であり，概念[MATH]において[MATH]である．
この場合，属性値[MATH]は，概念[MATH]において最も主要な属性値であるが，概念[MATH]においてはそれほど主要ではないといえる．
このように，ある属性値集合における属性値が，集合全体に対して，どの程度主要であるかということは，その属性値が集合内において保持する生起確率から把握できる．
主要な属性値を用いた冗長度と，主要でない属性値を用いた冗長度を比較した場合，前者が主要であることが，顕現性の強調に影響すると考えられる．
よって，各々の冗長度に対して，対象となった共有属性値集合の生起確率の総和を乗じて重み付けをし，比較した結果を顕現性落差として判断する(式([REF_exp:dif]))．
比較した結果が正の場合，顕現性落差は比喩性を上げるように働き，負の場合は比喩性を下げるように働く，または生じないとみなす．
以下に，顕現性落差の計算手法についての具体例を示す．
``子供のような顔''という比喩表現に関して，二つの構成概念，[MATH]と[MATH]が図[REF_fig:rep-kage]のように，記述されている．
仮に，主要な属性値集合を決める閾値[MATH]を0.5とした場合，source概念[MATH]における上位の属性値集合[MATH]は，[MATH] (合計0.505)となる．
さらに，[MATH]と[MATH]の共有属性値として，[MATH]が得られるので，クローズアップされる属性値集合は以下のように表せ，
それぞれの冗長度は次のように計算できる．
共有属性値の生起確率の総和によって重み付けをして，両者を比較すると，
[MATH]という``顕現性落差''が得られ，この概念対は，[MATH]という属性値に関して，比喩性を高めるようにはたらくと判断する．
本節では，顕現性落差の定量化に用いる知識ベースの構築について述べる．
前節で説明した顕現性落差を定量化するためには，対象となる単語を表現できる属性値集合に関する知識ベースが必要である．
知識ベース構築において，従来のように被験者を用いた心理学的実験に基づいた場合，妥当性の高い知識は期待できるが，同手法によって，数万，数十万と，知識を大規模化することは，極めて困難である．
コンピュータを用いた汎用的な比喩性判定を考えた場合，大規模な知識ベースを効率良く構築することも非常に重要である．
よって，大規模コーパスを利用した統計的なアプローチも有効な手段の一つである．
そこで，我々は，従来の心理学的実験手法を用いず，統計的手法を用いて，テキストコーパスから大規模な知識を自動的に抽出し，知識ベースを構築する．
具体的には，対象とするテキストコーパスを形態素解析し，得られた結果から，``修飾語−名詞''の共起関係とその共起頻度を抽出する．
抽出された共起情報は，確率的プロトタイプモデルに基づいて，知識ベース化する．
例文(1)第一日目には，赤い花が一本売れた[CITE]．
例文(2)二人は白い花のイバラの影から出て，水蓮の咲いている小さい沼の方へ歩いて行きます[CITE]．
例えば，例文(1)を形態素解析した結果から，共起関係``花−赤い''が抽出される．
この関係を共起頻度とともに，``[MATH] ''のように記録する．
同様に，例文(2)を処理すると，共起関係``花−白い''と``沼−小さい''が抽出できる．
その結果，知識は，``[MATH]''に更新される．
上記の方法に従って，1年分の新聞記事コーパス[CITE]から知識ベースを構築した．
知識ベース構築に際して，知識を抽出する共起範囲は1文とした．
知識として抽出された共起ペアは79,712組，属性値集合は27,958組であった．
属性値集合あたりの属性値数は1〜339，平均は2.5であった．
表[REF_tbl:nov-ex0]に知識ベースの例を示す．
``山：高い''，``海：青い''，``学生：若い''，など，概念の顕現特徴を示す属性値が概ね上位に位置した．
下位の順位においても，``山：険しい''，``海：暗い，神秘的だ''，``学生：無気力だ，忙しい''，のように，概念の特徴として連想可能な属性値を見ることができる．
構築した知識ベースから，ランダムに100組を抜きだし，人手による大まかな評価を行った.
評価は，(A)見出しの属性値として連想し易い，(B)見出しの属性値として連想することが可能，(C)見出しの属性値として連想不可能，の三段階に分類することで行った．
その結果，(A)が85組，(B)が15組，(C)が5組となった．
したがって，抽出した属性値のうち，85%程度は顕現特徴として理解でき，95%程度は連想可能なものであると考えられる．
上の評価結果は，個々の属性値が妥当かどうかを測るものであり，評価後の数値がそのまま属性値集合の妥当性を示すものではないが，大規模な知識を，概ね直観に合うレベルで抽出することができたといえる．
一方で，以下に述べるような，方式限界の存在も明らかになった．
属性値の中には，ほとんどの概念と頻繁に共起するために，概念の特徴を示す属性値とはならないケースが見られた．
``よい''や``いい''がその一例である．
これらの語は，概念によっては，その特徴を反映していない場合も多く，属性値集合のノイズとなってしまうことがわかった．
他にも，``夢''の属性値の例があげられる．
文献[CITE]に記載されている``夢''の語義文を参考にして属性値を考えると，``はかない''，``非現実的だ''，``実現困難だ''，``理想的だ''が得られる．
上記手法によって構築された知識ベース(表[REF_tbl:nov-ex0])の``夢''の属性値集合をみると，``はかない''以外の属性値が抽出されていないことがわかる．
これは，コーパス中において，``非現実的な''，``実現困難な''，``理想的な''などは，非制限的な属性であり，``夢''の属性値としては一般的過ぎるために，修飾語として出現しにくいためと考えられる．
上で述べたような問題点は，以降で扱う，比喩性判定の過程に影響を与えることが予想されるが，本論文では，これを本構築手法の限界と考えている．
以上の見地から，本手法によって構築される知識ベースは，強調されやすい属性値の集合によって表現される，確率的な概念記述であるといえ，概念の顕現特徴やそれらの集合を近似することは可能である．
したがって，比喩性の判定という目的においては，十分利用可能である．
構築した知識ベースを用いて，単語間の顕現性落差を計算した例を表[REF_tbl:gap-ex]に示す．
[MATH]の項の単語対は，前述のコーパスから，``[MATH]''というパターンで現れる表現の構成単語である．
表[REF_tbl:gap-ex]から，顕現性落差が大きい単語対は，比喩または例示の組み合わせが多く，顕現性落差が小さい単語対は，例示や無意味単語対が多いことがわかる．
2章で述べたように，比喩表現の``意外性''とは，構成概念の組み合わせの新鮮さである．
単語同士の組み合わせがいかに新鮮かを決める要因として，それらの単語が，日常的に用いられる文章中でどれほど頻繁に共起するか，という点があげられる．
よって，テキストデータ中の単語の共起情報に基づく意味距離を利用すれば，単語組み合わせの``意外性''を定量化できるはずである．
大規模なテキストデータから，単語の共起頻度を用いて単語間の意味距離を定量化する手法は，これまでにも数多く提案されている[CITE]．
本論文では，計算対象となる頻度が小さい場合でも，比較的信頼できる結果が得られるdice係数を利用する．
dice係数は，本来，単語間の意味距離を示す値であるため，単語間の結び付きが強い程値が小さな値をとる．
これは，``意外性''の定義とは反対の概念であるため，dice係数の逆数を``意外性''の値として用いることにする．
したがって，あるテキスト中において出現する二つの単語[MATH]，[MATH]が，それぞれ，[MATH]，[MATH]の頻度で出現しており，そのうち両者が共起する頻度が[MATH]である場合，``意外性''[MATH]は，式([REF_exp:novelty])で表される．
この計算方法では，dice係数の値が0となる場合，すなわち，対象とする単語間の共起頻度が0の場合は値が得られない．
共起頻度が得られないということは，単語の抽出元であるコーパス中からは，意外性を判断するための基本情報が得られなかったと判断できる．
したがって，単語間の共起頻度が0であった場合は，判定不能として扱う．
この場合，顕現性落差の計算が可能であったとしても，比喩性の判定は不能となる．
以下，意外性の計算手法について，具体例を示す．
``山のような書類''という比喩表現に関して考える．
ある新聞記事[CITE]では，二つの単語``山''および``書類''の頻度はそれぞれ，2695，1033であり，両者の共起頻度が4である．
このとき``意外性''は，
となる．
同様に，``文書のような書類''という表現の場合，二つの単語``文書''および``書類''の頻度はそれぞれ，1898，1633，両者の共起頻度が20なので，``意外性''は，
となり，``山，書類''と比較して意外性が小さいことがわかる．
顕現性落差同様，テキストコーパスから，統計的手法を用いて大規模な知識を取り出し，意外性の定量化に用いる知識ベースを構築する．
具体的には，対象とするテキストを形態素解析[CITE]し，得られたその処理結果から，全ての名詞とその出現頻度，および，1文をスコープとした場合の名詞共起とその共起頻度を抽出して構築する．
例文(2)には5つの名詞``二人''，``花''，``イバラ''，``影''，``水蓮''，``沼''が存在する．
共起範囲を一文として各名詞のペア組合せを考えると，14組の名詞ペアが考えられる．
このとき，各名詞の出現頻度と共起頻度，それらに基づいて名詞間の意味距離が計算できる．
以上の結果を知識ベースとして，[MATH]のように記録する．
表[REF_tbl:nov-ex]に，単語間の意外性の例を示す．
これらは，1年分の新聞記事コーパス[CITE]を利用して構築した知識ベースを用いて，計算した結果である．
知識ベース構築のための共起範囲は1文とし，共起頻度5以上のものを対象とした．
[MATH]の項の単語対は，前述のコーパスから，``[MATH]''というパターンで現れる表現の構成単語である．
表[REF_tbl:nov-ex]から，意外性が高い単語対は比喩または無関係の組み合わせが多く，意外性が下位のものは例示の組み合わせが多いことがわかる．
本論文では，与えられた表現が比喩であるかを判断する基準として，「クローズアップされる特徴がいかに明確か」という点と，「与えられた表現がどの程度新鮮か」という点が重要であることに着目する．
比喩表現の理解とは，概念が持つ，ある特徴を強調することによって，新たな理解を促すものであるから，強調される特徴が明確でなければならない．
``顕現性落差"は，クローズアップされる特徴を抽出し，それらの特徴がいかに明確であるかをはかる尺度である．
また，比喩表現として対比される概念が新鮮であることは，その表現に強い印象を与え，理解を促すことになる．
``意外性"は，対比される概念の組み合わせの新鮮さをはかる尺度である．
このような，二つの尺度を設定することで，その表現の比喩らしさ，すなわち，比喩性を検出できると考えられる．
以下，``顕現性落差''および``意外性''について，比喩性との関係を説明し，両尺度が，比喩性検出にどのように利用できるかについて述べる．
Ortny[CITE]は，比較される概念間の共有特徴が少ない場合でも，それらの類似性が認識されて比喩性が理解される点や，類似性の非対称性に着目し，相互作用モデルを示した．
例えば，``卵のような車''という比喩の場合，たとえる言葉(source概念)``卵''とたとえられる言葉(target概念)``車''の共有特徴[MATH]は，``車''においては顕著な特徴ではないが，``卵''においては，これらの共有特徴は非常に顕著な特徴(顕現特徴)である．
したがって，``車''に対して，``卵''のイメージを重ね合わせることによって，``車''における[MATH]などの特徴を同時に強調し，その結果，``顕現性落差''が生じて，比喩性が検出される．
``顕現性落差''からは，類似性の非対称性が生じるので，同じ概念を比較した場合でも，``車のような卵''という表現からは，比喩性は検出されにくい．
また，source概念が顕著な特徴を持っていたとしても，対比される概念間に共有特徴が認められない場合は，``顕現性落差''が生じないため，比喩性は認識されない．
例えば，``谷底のような車''という表現では，``谷底''と``車''の間には共有特徴が見つけられないので，``顕現性落差''は生じず，比喩性も生じない．
``自動車のような車''では，組み合わせ概念が類似概念であるため，両者の顕現特徴もほとんど共通である．
この場合も，``顕現性落差''は生じにくく，比喩性もあらわれにくいと考えられる．
さらに，比喩とは，意表を突いた言葉(ここでは単語)の組合せによって，伝えたい内容をより鮮明にしたり，強調する働きを持つ．
例えば，``スポーツカーのような車''という比喩の場合，``スポーツカー''と``車''の共有特徴([MATH])={速い，格好いい，燃費が悪い…}は，``車''においては顕著な特徴ではないが，``スポーツカー''において非常に顕著である．
したがって，``車''に対して，``スポーツカー''のイメージを重ね合わせることによって，``車''における{速い，恰好いい，…}などの特徴を同時に強調するが，比喩性は認識されにくい．
この理由は，両概念が上位下位関係を持つために，重複する特徴が多く，かつ，ありふれた組み合わせであるために，表現の新鮮さに欠けるからと考えられる．
本論文では，このような単語間の組合せの新鮮さの度合を``意外性''として扱う．
一般に，同一話題中に頻出する単語対は，たとえ2章の``顕現性落差''の条件を満たしていても，``意外性''が低い．
その結果，比喩としての「新しさ」や「意外さ」が認識されず，比喩性を高める要因とはならない．
反対に，めったに同一話題中に現れない単語対は``意外性''が高く，「新鮮」で「意外」であると認識され，比喩性を高める要因となる．
上記の見地から，``顕現性落差''が大きく，かつ``意外性''も大きい概念対ほど，特徴が明確であり，表現も新鮮に受け取られ，比喩性も大きくなると考えられる．
この考え方と，概念対(比喩・例示・無意味)の区別を対応付けると，表[REF_tbl:relation]のような関係が仮定できる．
概念対において，``顕現性落差''によって，無意味な概念対(無関係対)と意味のある概念対(比喩関係対・例示関係対)が区別でき，``意外性''によって，例示関係対と非例示の概念対(比喩関係対・無関係対)が区別できる．
よって，両者を統合的に利用することで，比喩関係にある概念対が区別できる．
2章で述べたような共有特徴の顕現性落差を扱うために，属性値集合を用いた，確率的な概念記述を用いる．
確率的な概念記述モデルでは，概念は属性値とその生起確率の集合として記述される[CITE]．
概念[MATH]が属性値[MATH]をもち，その生起確率が[MATH]であるとき，[MATH]は以下のように，確率的な属性値集合として記述できる(式([REF_exp:collection]))．
このとき，概念の顕現性は，これらの属性値集合の冗長度(ばらつき具合)から予測可能である．
([REF_exp:collection])で示した概念[MATH]が，[MATH]種類の属性値から成る属性値集合として記述される場合，その冗長度[MATH]は，式([REF_exp:info])を用いて定量化できる[CITE]．
ところで，比喩表現の顕現特徴は，比較される概念間の共有特徴から選ばれるが，同時に，source概念の顕現特徴になっているはずである．
よって，source概念の属性値集合から主要な属性値を取り出し，それらと，target概念の属性値との間で共有できるものを取り出すことで，顕現性落差を考えるためにクローズアップされる共有属性値集合が取り出される．
取り出された共有属性値集合について，source概念とtarget概念の各々における生起確率を用いて冗長度を計算することで，顕現性落差が予測できる．
したがって，source概念[MATH]が，降順で整列した[MATH]個の属性値から成る属性値集合で記述される場合を考えると，まず，生起確率上位から，閾値[MATH]までの範囲内に存在する[MATH]個の属性値([MATH])を，その概念の主要な属性値集合とみなして取り出し(式([REF_exp:set]))，
次に，取り出した属性値集合[MATH]と，target概念[MATH]との間で共有される属性値を探し，それらを，各々の概念における相対頻度の値とともに取り出す．
([REF_exp:set])に関して，source概念[MATH]の主要な属性値集合[MATH]と，target概念[MATH]の間で共有される属性値集合は，[MATH]，[MATH]であり，それらの主要な共有属性値集合(属性値数[MATH]個，[MATH]個)は，式([REF_exp:set1]),([REF_exp:set2])のように表せる．
さらに，それぞれの共有属性値集合の冗長度，[MATH]，[MATH]は，式([REF_exp:var1])，([REF_exp:var2])のように計算できる．
ここで，上記の手順で求められた冗長度は，単に属性値のばらつき具合を示しているにすぎない．
そのため，source概念における共有属性値集合の冗長度が，target概念のそれより小さい(ばらついている)場合でも，共有属性値の生起確率が概念記述全体に対して占める割合が大きいと，顕現特徴となる場合があり，冗長度の差のみでは，顕現性落差を正確に反映できない．
そこで，顕現性落差を反映させるために，対象となる属性値がどの程度主要であるかによって冗長度に重み付けをする．
例えば，図[REF_fig:rep-kage]では，属性値[MATH]の生起確率は，概念[MATH]において[MATH]であり，概念[MATH]において[MATH]である．
この場合，属性値[MATH]は，概念[MATH]において最も主要な属性値であるが，概念[MATH]においてはそれほど主要ではないといえる．
このように，ある属性値集合における属性値が，集合全体に対して，どの程度主要であるかということは，その属性値が集合内において保持する生起確率から把握できる．
主要な属性値を用いた冗長度と，主要でない属性値を用いた冗長度を比較した場合，前者が主要であることが，顕現性の強調に影響すると考えられる．
よって，各々の冗長度に対して，対象となった共有属性値集合の生起確率の総和を乗じて重み付けをし，比較した結果を顕現性落差として判断する(式([REF_exp:dif]))．
比較した結果が正の場合，顕現性落差は比喩性を上げるように働き，負の場合は比喩性を下げるように働く，または生じないとみなす．
以下に，顕現性落差の計算手法についての具体例を示す．
``子供のような顔''という比喩表現に関して，二つの構成概念，[MATH]と[MATH]が図[REF_fig:rep-kage]のように，記述されている．
仮に，主要な属性値集合を決める閾値[MATH]を0.5とした場合，source概念[MATH]における上位の属性値集合[MATH]は，[MATH] (合計0.505)となる．
さらに，[MATH]と[MATH]の共有属性値として，[MATH]が得られるので，クローズアップされる属性値集合は以下のように表せ，
それぞれの冗長度は次のように計算できる．
共有属性値の生起確率の総和によって重み付けをして，両者を比較すると，
[MATH]という``顕現性落差''が得られ，この概念対は，[MATH]という属性値に関して，比喩性を高めるようにはたらくと判断する．
本節では，顕現性落差の定量化に用いる知識ベースの構築について述べる．
前節で説明した顕現性落差を定量化するためには，対象となる単語を表現できる属性値集合に関する知識ベースが必要である．
知識ベース構築において，従来のように被験者を用いた心理学的実験に基づいた場合，妥当性の高い知識は期待できるが，同手法によって，数万，数十万と，知識を大規模化することは，極めて困難である．
コンピュータを用いた汎用的な比喩性判定を考えた場合，大規模な知識ベースを効率良く構築することも非常に重要である．
よって，大規模コーパスを利用した統計的なアプローチも有効な手段の一つである．
そこで，我々は，従来の心理学的実験手法を用いず，統計的手法を用いて，テキストコーパスから大規模な知識を自動的に抽出し，知識ベースを構築する．
具体的には，対象とするテキストコーパスを形態素解析し，得られた結果から，``修飾語−名詞''の共起関係とその共起頻度を抽出する．
抽出された共起情報は，確率的プロトタイプモデルに基づいて，知識ベース化する．
例文(1)第一日目には，赤い花が一本売れた[CITE]．
例文(2)二人は白い花のイバラの影から出て，水蓮の咲いている小さい沼の方へ歩いて行きます[CITE]．
例えば，例文(1)を形態素解析した結果から，共起関係``花−赤い''が抽出される．
この関係を共起頻度とともに，``[MATH] ''のように記録する．
同様に，例文(2)を処理すると，共起関係``花−白い''と``沼−小さい''が抽出できる．
その結果，知識は，``[MATH]''に更新される．
上記の方法に従って，1年分の新聞記事コーパス[CITE]から知識ベースを構築した．
知識ベース構築に際して，知識を抽出する共起範囲は1文とした．
知識として抽出された共起ペアは79,712組，属性値集合は27,958組であった．
属性値集合あたりの属性値数は1〜339，平均は2.5であった．
表[REF_tbl:nov-ex0]に知識ベースの例を示す．
``山：高い''，``海：青い''，``学生：若い''，など，概念の顕現特徴を示す属性値が概ね上位に位置した．
下位の順位においても，``山：険しい''，``海：暗い，神秘的だ''，``学生：無気力だ，忙しい''，のように，概念の特徴として連想可能な属性値を見ることができる．
構築した知識ベースから，ランダムに100組を抜きだし，人手による大まかな評価を行った.
評価は，(A)見出しの属性値として連想し易い，(B)見出しの属性値として連想することが可能，(C)見出しの属性値として連想不可能，の三段階に分類することで行った．
その結果，(A)が85組，(B)が15組，(C)が5組となった．
したがって，抽出した属性値のうち，85%程度は顕現特徴として理解でき，95%程度は連想可能なものであると考えられる．
上の評価結果は，個々の属性値が妥当かどうかを測るものであり，評価後の数値がそのまま属性値集合の妥当性を示すものではないが，大規模な知識を，概ね直観に合うレベルで抽出することができたといえる．
一方で，以下に述べるような，方式限界の存在も明らかになった．
属性値の中には，ほとんどの概念と頻繁に共起するために，概念の特徴を示す属性値とはならないケースが見られた．
``よい''や``いい''がその一例である．
これらの語は，概念によっては，その特徴を反映していない場合も多く，属性値集合のノイズとなってしまうことがわかった．
他にも，``夢''の属性値の例があげられる．
文献[CITE]に記載されている``夢''の語義文を参考にして属性値を考えると，``はかない''，``非現実的だ''，``実現困難だ''，``理想的だ''が得られる．
上記手法によって構築された知識ベース(表[REF_tbl:nov-ex0])の``夢''の属性値集合をみると，``はかない''以外の属性値が抽出されていないことがわかる．
これは，コーパス中において，``非現実的な''，``実現困難な''，``理想的な''などは，非制限的な属性であり，``夢''の属性値としては一般的過ぎるために，修飾語として出現しにくいためと考えられる．
上で述べたような問題点は，以降で扱う，比喩性判定の過程に影響を与えることが予想されるが，本論文では，これを本構築手法の限界と考えている．
以上の見地から，本手法によって構築される知識ベースは，強調されやすい属性値の集合によって表現される，確率的な概念記述であるといえ，概念の顕現特徴やそれらの集合を近似することは可能である．
したがって，比喩性の判定という目的においては，十分利用可能である．
構築した知識ベースを用いて，単語間の顕現性落差を計算した例を表[REF_tbl:gap-ex]に示す．
[MATH]の項の単語対は，前述のコーパスから，``[MATH]''というパターンで現れる表現の構成単語である．
表[REF_tbl:gap-ex]から，顕現性落差が大きい単語対は，比喩または例示の組み合わせが多く，顕現性落差が小さい単語対は，例示や無意味単語対が多いことがわかる．
2章で述べたように，比喩表現の``意外性''とは，構成概念の組み合わせの新鮮さである．
単語同士の組み合わせがいかに新鮮かを決める要因として，それらの単語が，日常的に用いられる文章中でどれほど頻繁に共起するか，という点があげられる．
よって，テキストデータ中の単語の共起情報に基づく意味距離を利用すれば，単語組み合わせの``意外性''を定量化できるはずである．
大規模なテキストデータから，単語の共起頻度を用いて単語間の意味距離を定量化する手法は，これまでにも数多く提案されている[CITE]．
本論文では，計算対象となる頻度が小さい場合でも，比較的信頼できる結果が得られるdice係数を利用する．
dice係数は，本来，単語間の意味距離を示す値であるため，単語間の結び付きが強い程値が小さな値をとる．
これは，``意外性''の定義とは反対の概念であるため，dice係数の逆数を``意外性''の値として用いることにする．
したがって，あるテキスト中において出現する二つの単語[MATH]，[MATH]が，それぞれ，[MATH]，[MATH]の頻度で出現しており，そのうち両者が共起する頻度が[MATH]である場合，``意外性''[MATH]は，式([REF_exp:novelty])で表される．
この計算方法では，dice係数の値が0となる場合，すなわち，対象とする単語間の共起頻度が0の場合は値が得られない．
共起頻度が得られないということは，単語の抽出元であるコーパス中からは，意外性を判断するための基本情報が得られなかったと判断できる．
したがって，単語間の共起頻度が0であった場合は，判定不能として扱う．
この場合，顕現性落差の計算が可能であったとしても，比喩性の判定は不能となる．
以下，意外性の計算手法について，具体例を示す．
``山のような書類''という比喩表現に関して考える．
ある新聞記事[CITE]では，二つの単語``山''および``書類''の頻度はそれぞれ，2695，1033であり，両者の共起頻度が4である．
このとき``意外性''は，
となる．
同様に，``文書のような書類''という表現の場合，二つの単語``文書''および``書類''の頻度はそれぞれ，1898，1633，両者の共起頻度が20なので，``意外性''は，
となり，``山，書類''と比較して意外性が小さいことがわかる．
顕現性落差同様，テキストコーパスから，統計的手法を用いて大規模な知識を取り出し，意外性の定量化に用いる知識ベースを構築する．
具体的には，対象とするテキストを形態素解析[CITE]し，得られたその処理結果から，全ての名詞とその出現頻度，および，1文をスコープとした場合の名詞共起とその共起頻度を抽出して構築する．
例文(2)には5つの名詞``二人''，``花''，``イバラ''，``影''，``水蓮''，``沼''が存在する．
共起範囲を一文として各名詞のペア組合せを考えると，14組の名詞ペアが考えられる．
このとき，各名詞の出現頻度と共起頻度，それらに基づいて名詞間の意味距離が計算できる．
以上の結果を知識ベースとして，[MATH]のように記録する．
表[REF_tbl:nov-ex]に，単語間の意外性の例を示す．
これらは，1年分の新聞記事コーパス[CITE]を利用して構築した知識ベースを用いて，計算した結果である．
知識ベース構築のための共起範囲は1文とし，共起頻度5以上のものを対象とした．
[MATH]の項の単語対は，前述のコーパスから，``[MATH]''というパターンで現れる表現の構成単語である．
表[REF_tbl:nov-ex]から，意外性が高い単語対は比喩または無関係の組み合わせが多く，意外性が下位のものは例示の組み合わせが多いことがわかる．
