単語境界確率の推定方法の評価として，言語モデルの適応の実験を行なった．
まず，適応対象文野の大きな生コーパスに既存手法と提案手法のそれぞれで単語境界確率を付与した．
次に，その結果得られる確率的単語分割コーパスから単語2-gramモデルを推定し，これを一般分野の単語分割済みコーパスから推定された単語2-gramモデルと補間した．
最後に，適応分野のテストコーパスに対して，予測力と仮名漢字変換[CITE]の精度の評価を行なった．
後者は，理想的な音響モデルを用いた場合の音声認識と考えることも可能である．
この節では，実験の結果を提示し，評価を行なう．
実験に用いたコーパスは，「現代日本語書き言葉均衡コーパス」モニター公開データ（2008年度版）中の人手による単語分割の修正がなされている文（一般コーパス）と医療文書からなる適応対象のコーパスである．
一般コーパスの各文は正しく単語に分割され，各単語に入力記号列（読み）が付与されている．
これを10個に分割し，この内の9個を学習コーパスとし，残りの1個をテストコーパスとした（\tabref{table:corpus}参照）．
自動単語分割器や単語境界確率の推定のための最大エントロピーモデルはこの学習コーパスから構築される．
一方，適応対象のコーパスは大量にあるが，単語境界情報を持たない．
この内の7,000文に入力記号列（読み）を付与しテストコーパスとし，残りを確率的単語分割コーパスとして言語モデルの学習に用いた（\tabref{table:raw-corpus}参照）．
テストコーパスの内の1,000文には，単語境界情報も付与し，言語モデルの予測力の評価に用いた．
確率的言語モデルの予測力の評価に用いた基準は，テストコーパスにおける単語あたりのパープレキシティである．
まず，テストコーパス[MATH]に対して未知語の予測も含む文字単位のエントロピー[MATH]を以下の式で計算する[CITE]．
ここで，[MATH]は単語[MATH]-gramモデルによる単語列[MATH]の生成確率を，[MATH]はテストコーパス[MATH]の文字数を表す．
次に，単語単位のパープレキシティを以下の式で計算する．
ここで[MATH]は平均単語長（文字数）である．
これらの計算に際しては，単語境界情報が付与された1,000文を用いた．
仮名漢字変換の評価基準は，文字誤り率である．
文字誤り率は[MATH]と定義される．
ここで，[MATH]は正解に含まれる文字数であり，[MATH]は各文を一括変換することで得られる最尤解と正解との最長共通部分列(LCS; Longest Common Subsequence) [CITE]の文字数である．
単語境界確率の推定方法の差異を調べるために，以下の2つの確率的単語分割コーパスを作成しそれらから推定された単語2-gramモデルの能力を調べた．
従来手法
各単語境界確率は，単語2-gramモデルに基づく自動単語分割器の判断に応じて[MATH]又は[MATH]とする．
ここで，[MATH]は一般分野のテストコーパスにおける単語境界推定精度である（\subref{subsection:EM}参照）．
提案手法
各単語境界確率は，最大エントロピーモデルを用いて文脈に応じて推定される（\subref{subsection:ME}参照）．
適応対象分野のテストコーパスにおける予測力と文字誤り率を\tabref{table:result1}に示す．
この結果から，本論文で提案する最大エントロピー法による単語境界確率の推定方法により約11%のパープレキシティの削減が実現されている．
この結果から，最大エントロピー法により推定された単語境界確率を持つ確率的単語分割コーパスを用いることで適応対象分野における単語2-gram確率がより正確に推定されていることがわかる．
応用の仮名漢字変換においても，文字正解率の比較から，提案手法により，従来手法の文字誤りの約3.1%が削減さた．
検定の結果，有意水準5%で有意差があるとの結果であった．
この点からも言語モデルが改善されていることが確認される．
従来手法の文字正解率は97.51%と高いので，提案手法により実現された誤りの削減は十分有意義であろう．
本論文のもう一つの論点は，単語分割済みコーパスによる確率的単語分割コーパスの近似である．
この評価として，3種類の大きさ(1/1, 1/2, 1/4)の適応分野の疑似確率的単語分割コーパスから推定した言語モデルのテストコーパスに対するパープレキシティと文字正解率を複数の倍率([MATH])に対して計算した．
\tabref{table:result2}〜\tabref{table:result4}はその結果である．
まず，自動分割の結果を決定的単語分割コーパスとして用いる場合についてである．
これと，確率的単語分割コーパスとして用いる場合との比較では，文献[CITE]の報告と同じように確率的単語分割により予測力が向上し，文献[CITE]の報告と同じように仮名漢字変換の文字正解率も向上している．
さらに，本論文で提案する倍率が1の疑似確率的単語分割は，決定的単語分割に対して，予測力と文字正解率の双方において優れていることが分る．
倍率が1の疑似確率的単語分割と決定的単語分割の唯一の違いは，自動単語分割の際に単語境界確率を0.5と比較するか，0から1の乱数と比較するかであり，モデル構築の計算コストはほとんど同じである．
にもかかわらず，予測力と文字正解率の双方が向上している点は注目に値するであろう．
次に，確率的単語分割と疑似確率的単語分割の比較について述べる．
倍率が1の場合は，予測力や文字正解率は，確率的単語分割コーパスから推定された言語モデルに対して少し低く，倍率を上げることによりこれらは確率的単語分割コーパスによる結果に近づいていくことがわかる．
これは，疑似確率的単語分割がモンテカルロ法による数値演算の一種になっていることを考えれば当然の結果である．
このことから，ある程度の倍率の疑似確率的単語分割コーパスは，確率的単語分割コーパスのよい近似となっているといえる．
適応分野のコーパスの大きさに係わらず，倍率が256の場合の疑似確率的単語分割による結果は，確率的単語分割の結果とほぼ同じといえる．
最後に，確率的単語分割と疑似確率的単語分割の計算コストの比較について述べる．
確率的単語分割の語彙サイズは，適応対象の学習コーパスにおける期待頻度が0より大きい16文字以下の部分文字列と一般コーパスの語彙の合計9,383,985語であった．
この語彙に対する単語2-gram頻度をハッシュ(Berkeley DB 4.6.21)を用いてファイルに出力すると10.0 GBとなった．
これをRAMディスク上で計算するのに61147.45秒（約17時間）を要した．
同じ計算機で，16倍の疑似確率的単語分割コーパスから単語2-gram頻度をRAMディスク上で計算すると，語彙サイズが46,777語であり，単語2-gram頻度のファイルサイズは9.98 MBであり，計算時間は1009.95秒（約17分）と約61分の1となった．
疑似確率的単語分割コーパスを用いた場合には，倍率が256の場合でも20.2 MBと，ファイルサイズが大きくないので，現在の多くの計算機で主記憶上で計算が可能である（主記憶上での計算時間は303.29秒）．
これに対して，確率的単語分割コーパスからの推定では，一部の計算機においてのみ主記憶上での計算が可能である．
さらに，実験で用いた適応対象の分野のコーパスは44,915文と決して大きくはなく，適応分野によっては1桁か2桁ほど大きい学習コーパスが利用できることも十分考えられる．
この場合には，確率的単語分割では2次記憶（RAMディスクかハードディスク）上での計算が避けられず，モデル作成にかかる計算時間の違いは非常に大きくなる．
したがって，本論文で提案する疑似確率的単語分割は，この点から有用であると考えられる．
疑似確率的単語分割において，どの程度の倍率がよいかは要求する精度と利用可能な計算機資源との兼ね合いである．
例えば倍率が16の場合は，単語に分割された718,640文から言語モデルを推定することになる．
モデル構築に要する計算時間は，決定的単語分割の場合の16倍程度であり，現在の計算機はこの大きさのコーパスを処理する能力が十分ある．
したがって，疑似確率的単語分割により，単語3-gramモデルや可変長記憶マルコフモデル，あるいは言語モデルのための単語クラスタリングなどさらなる言語モデルの改善を容易に試みることが可能となる．
