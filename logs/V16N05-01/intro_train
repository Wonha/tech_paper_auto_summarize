0 一般的 な 分野 において 精度 の 高い 単語分割済みコーパス が 利用可能 に なっ て き た 現在言語モデル の 課題 は 言語モデル を 利用 する 分野 へ の 適応 すなわち 適応対象分野 に 特有 の 単語 や 表現 の 統計的振る舞い を 的確 に 捉える こと に 移っ て き て いる 
0 この 際 の 標準的 な 方法 で は 適応対象 の コーパス を 自動的 に 単語分割 し 単語MATHgram頻度 など が 計数 さ れる 
0 この 際 に 用い られる 自動単語分割器 は 一般分野 の 単語分割済みコーパス から 構築 さ れ て おり 分割誤り の 混入 が 避け られ ない 
0 特に 適切 に 単語分割 さ れる 必要 が ある 適応対象分野 に 特有 の 単語 や 表現 や その 近辺 において 誤る 傾向 が あり 単語MATHgram頻度 など の 信頼性 を 著しく 損なう 結果 と なる 
0 上述 の 単語分割誤り の 問題 に 対処 する ため確率的単語分割コーパス という 概念 が 提案 さ れ て いる 
1 この 枠組 で は 適応対象 の 生 コーパス は 各 文字 の 間 に 単語境界 が 存在 する 確率 が 付与 さ れ た 確率的単語分割コーパス と みなさ れ 単語MATHgram確率 が 計算 さ れる 
0 従来 の 決定的 に 自動単語分割 さ れ た 結果 を 用いる より 予測力 の 高い 言語モデル が 構築 できる こと が 確認 さ れ て いる 
0 また 仮名漢字変換CITE や 音声認識CITE において も 従来手法 に対する 優位性 が 示さ れ て いる 
0 確率的単語分割コーパス の 初期 の 論文 で は 単語境界確率 は 自動分割 により 単語境界 と 推定 さ れ た 箇所 で 単語分割 の 精度MATH 例えば 095 と し そう で ない 箇所 で MATH と する 単純 な 方法 により 与え られ て いる 
0 実際 に は 単語境界 が 存在 する と 推定 さ れる 確率 は 文脈 に 応じ て 幅広い 値 を 取る と 考え られる 
0 例えば 学習コーパス から は どちら と も 判断 でき ない 箇所 で は 12 に 近い 値 と なる べき で ある が 既存手法 で は 1 に 近い MATH か 0 に 近い MATH と する 他 ない 
0 この 問題 に 加え て 既存 の 決定的 に 単語分割 する 手法 より も 計算コスト計算時間記憶領域 が 高い こと が 挙げ られる 
0 その 要因 は 2 つ ある 
0 1 つ 目 は 期待頻度 の 計算 に 要する 演算 の 種類 と 回数 で ある 
0 通常 の 手法 で は 学習コーパス は 単語 に 分割 さ れ て おり これ を 先頭 から 単語毎 に 順に 読み込ん で 単語辞書 を 検索 し て 番号 に 変換 し 対応 する 単語MATHgram頻度 を インクリメント する 
0 単語辞書 の 検索 は 辞書 を オートマトン に し て おく こと で コーパス の 読み込み と 比較 し て 僅か な オーバーヘッド で 行える 
0 これ に対して 確率的単語分割コーパス において は 全て の 連続 する MATH個 の 部分文字列MATH文字 に対して MATH回 の 浮動小数点数 の 積 を 実行 し て 期待頻度 を 計算 し さらに 1回 の 加算 を 実行 する 必要 が ある 
0 2 つ 目 の 要因 は 学習コーパス の ほとんど 全て の 部分文字列 が 単語候補 に なる ため語彙サイズ が 非常 に 大きく なる こと で ある 
0 この 結果単語MATHgram の 頻度 や 確率 の 記憶領域 が 膨大 と なり 個人向け の 計算機 で は 動作 し なく なる など の 重大 な 制限 が 発生 する 
0 例えば 本 論文 で 実験 に 用い た 44915文 の 学習コーパス に 出現 する 句読点 を 含ま ない 16文字以下 の 部分文字列 は 9379799種類 あっ た 
0 この うち期待頻度 が 0 より 大きい 部分文字列 と 既存 の 語彙 を 加え て 重複 を 除い た 結果 を 語彙 と する と その サイズ は 9383985語 と なり この 語彙 に対する 単語2gram頻度 の ハッシュ による 記憶容量 は 100GB と なっ た 
0 この よう な 時間的 あるいは 空間的 な 計算コスト により 確率的単語分割コーパス から の 言語モデル構築 は 実用性 が 高い と は 言え ない 
0 この こと に 加え て 単語クラスタリングCITE や 文脈 に 応じ た 参照履歴 の 伸長CITE など の すでに 提案 さ れ て いる 様々 な 言語モデル の 改良 を 試みる こと が 困難 に なっ て いる 
1 本 論文 で は まず 確率的単語分割コーパス における 新しい 単語境界確率 の 推定方法 を 提案 する 
1 さらに 確率的単語分割コーパス を 通常 の 決定的 に 単語 に 分割 さ れ た コーパス により 模擬 する 方法 を 提案 する 
1 最後 に 実験 の 結果言語モデル の 能力 を 下げる こと なく 確率的単語分割コーパス の 利用 において 必要 と なる 計算コスト が 大幅 に 削減可能 で ある こと を 示す 
