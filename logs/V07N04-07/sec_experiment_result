実験には，池原らによって編集された機械翻訳機能試験文集[CITE]の2868文を用いた．
まず，試験文集に合わせた準備を全く行なわない完全ブラインドテストを行ない，その評価結果に基づいて辞書と規則を修正した後，ウィンドウテストを行なった．
試験文集だけに合わせた修正は極力避け，一般性のある修正を行なうように努めた．
翻訳品質の評価，辞書と規則の修正，試験のサイクルは四回繰り返した．
評価および修正はすべて一名で行なった．
完全ブラインドテストの結果の評価から第四回目のウィンドウテストの結果の評価までに要した期間は，およそ六ヶ月であった．
翻訳品質評価の基準は，訳文が1)文法的か，2)わかりやすいか，3)原文の意味と一致するか，4)利用者の役に立つかという観点から表[REF_tab:eval_criterion]のように設定した．
この評価基準において，4点以上を合格とし，それ未満を不合格とする．
完全ブラインドテストと四回目のウィンドウテストでの評価点の分布を表[REF_tab:experiment_result1]に示す．
合格した文の数は，完全ブラインドテストでは全体の46.4%にあたる1332文，ウィンドウテストでは2096文(73.1%)であった．
評価点の平均は，完全ブラインドテストでは2.7点で合格点に達しなかったが，ウィンドウテストでは4.2点と合格点を上回った．
各評価点を与えられた文の数が完全ブラインドテストとウィンドウテストでどのように変化したかを見ると，合格領域の6点ないし4点となる文数はいずれも増加し，不合格領域の3点ないし[MATH]点となる文数はいずれも減少している．
特に，何も出力されないために0点となる文数の減少が著しい．
これは主に，完全ブラインドテストでは入力文全体を覆う構文木が生成できず何も出力されなかった文に対して，ウィンドウテストでは全体の構文木が生成できるようになったことによる．
各文の評価値が完全ブラインドテストとウィンドウテストでどのように変化したかの分布を表[REF_tab:experiment_result2]に示す．
表[REF_tab:experiment_result2]によれば，評価点が向上した文数(表の左下隅の領域)は1186文(41.4%)であり，そのうち不合格から合格へ改善された文数は835文である．
逆に，評価値が低下した文数(表の右上隅の領域)は204文(7.1%)であり，そのうち合格から不合格へ悪化した文数は71文である．
また，両テストで評価点に変化がなかった文数(表の対角線上)は1478文(51.5%)である．
この結果から，辞書と規則の修正による悪影響を比較的小さく抑えつつ，翻訳品質の改善が実現できているといえる．
完全ブラインドテストとウィンドウテストでの翻訳例を付録の表[REF_tab:trans_example]に示す．
