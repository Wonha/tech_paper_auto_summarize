    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\usepackage{lingexample}
\usepackage{bm}
\newcommand{\argmax}{}
\newcommand{\w}{}
\newcommand{\x}{}
\newcommand{\y}{}
\newcommand{\e}{}
\newcommand{\f}{}
\renewcommand{\Phi}{}
\newcommand{\what}{}
\newcommand{\score}{}

\Volume{19}
\Number{2}
\Month{July}
\Year{2012}

\received{2011}{6}{17}
\revised{2011}{10}{10}
\rerevised{2011}{12}{27}
\accepted{2012}{1}{11}

\setcounter{page}{65}

\jtitle{言い換えと逆翻字を用いた片仮名複合名詞の分割}
\jauthor{鍜治　伸裕\affiref{Author_1} \and 喜連川　優\affiref{Author_1}}
\jabstract{
日本語を含めた多くの言語において，複合名詞内部の単語境界は空白で分かち書
きされない．こうした複合名詞を構成語列へと分割する処理は，多くの自然言語
処理の応用において重要な基礎技術となる．日本語の場合，片仮名語は生産性が
高く未知語が多いことから，特に片仮名複合名詞の扱いが技術的な問題となる．
この問題の解決を図るため，本論文は片仮名複合名詞の言い換えと逆翻字を分
割処理に利用する方法を提案する．実験では，言い換えと逆翻字をラベルなしテ
キストから抽出し，その情報を利用することによって，分割精度が統計的に有意
に向上することを確認した．
}
\jkeywords{言い換え，逆翻字，片仮名語，複合名詞分割，単語分割}

\etitle{Splitting Katakana Noun Compounds\\ by Paraphrasing and Back-transliteration}
\eauthor{Nobuhiro Kaji\affiref{Author_1} \and Masaru Kitsuregawa\affiref{Author_1}} 
\eabstract{
	Word boundaries within noun compounds are not marked by white
	spaces in a number of languages including Japanese, and it is
	beneficial for various NLP applications to split such noun
	compounds. In the case of Japanese, noun compounds made up of
	katakana words are particularly difficult to split, because
	katakana words are highly productive and are often
	out-of-vocabulary. To overcome this difficulty, we propose using
	paraphrases and back-transliteration of katakana noun compounds
	for splitting them. Experiments demonstrated that splitting
	accuracy is improved with a statistical significance by extracting
	both paraphrases and back-transliterations from unlabeled
	textual	data, and then using that information for constructing
	splitting models.
}
\ekeywords{paraphrasing, back-transliteration, katakana words, noun compound splitting, word segmentation}

\headauthor{鍜治，喜連川}
\headtitle{言い換えと逆翻字を用いた片仮名複合名詞の分割}

\affilabel{Author_1}{東京大学生産技術研究所}{IIS, the University of Tokyo}



\begin{document}
\maketitle


\section{教師あり学習に基づく手法} \label{sec:approach}

本論文では，片仮名複合名詞$x$が入力として与えられたとき，それを
構成語列$\y=(y_1,y_2\dots y_{|\y|})$へと分割する問題を取り扱う．ここでは，
出力$\y$が1語（すなわち$|\y|=1$）である場合もありうることに注意をされたい．

1節においても議論したように，片仮名名詞は英語の翻字が多く，提案する素性
の1つもその性質を利用したものとなっているため，以下では入力される片仮名
語は英語の翻字であると仮定する．この仮定が実テキストにおいてどの程度成立
しているのかを検証することは難しいが，例えばウェブ検索エンジンのクエリに
おいては，片仮名のクエリの約87\%は翻字であることが報告されている
\cite{Brill01}．このデータから上記の仮定にはある程度の妥当性があることが
推測され，実テキストを処理する際にも提案手法の効果を期待することができる．

\begin{table}[b]
   \caption{実験で使用した素性テンプレート}
   \label{tab:feature}
\input{02table01.txt}
\vspace{-0.5\Cvs}
\end{table}

我々は片仮名複合名詞の分割処理を「片仮名複合名詞$x$に対する構成語列$\y$
を予測する構造予測問題」と捉えて，これを以下のような線形モデルを用いて解
く．
\[
 \y^{*}=\argmax_{\y\in\mathcal{Y}(x)}\w\cdot{\bm\phi}(\y)
\]
ここで$\mathcal{Y}(x)$は入力$x$に対する全分割候補の集合を表す．
${\bm\phi}(\y)$は分割候補$\y$の素性ベクトル表現，$\w$は訓練事例から推定
される重みベクトルである．

表\ref{tab:feature}に我々が実験で用いた素性テンプレートを示す．テンプレー
ト1からは，ある構成語$1$-gramが出現したか否かを示す2値素性が，訓練事例に
出現した全ての構成語$1$-gramについて生成される．テンプレート2は同様の
$2$-gram素性である．テンプレート3からは，構成語の文字数(1, 2, 3,
4, $\geq$5)を示す2値素性が5種類生成される．テンプレート4は構成語$y$が外
部辞書
\footnote{外部辞書としてはNAIST-jdic ver.~0.6.0を用いた．}に登録されてい
るか否かを表す2値素性であり，構成語$y$が外部辞書に登録されていれば1を返
す2値素性が1つ生成される．テンプレート5から7は，片仮名複合名詞の言い換え
と逆翻字を用いたものであり，\ref{sec:para}節と\ref{sec:trans}節において
詳しく説明する．以下の議論では，テンプレート1から4によって生成される素性
を基本素性，テンプレート5から生成される素性を言い換え素性，テンプレート6
と7から生成される素性を逆翻字素性と呼んで互いに区別をする．

重みベクトル$\w$は任意の学習アルゴリズムを用いて最適化することが可能であ
るが，ここでは計算効率を考慮して平均化パーセプトロン\cite{Freund99}を用
いた．平均化パーセプトロンはオンライン学習アルゴリズムの一種であり，高速
に学習を行うことができると同時に，多くのタスクにおいてSVMなどのバッチ学
習アルゴリズムと比較しても遜色のない精度を達成できることが知られている．
パーセプトロンの訓練時およびテスト時には$\y^{*}$を求める操作が必要となる
が，セミマルコフモデルにおいて用いられるのと同様の動的計画法によって効率
的に実行可能である．


\section{言い換え素性} \label{sec:para}

本節では，片仮名複合名詞の言い換え表現を，教師あり学習の素性として使う方
法について述べる（表\ref{tab:feature}におけるテンプレート5に対応する）．

\subsection{複合名詞の言い換え}

一般的に，複合名詞は様々な形へと言い換えることが可能であるが，そうした言
い換え表現の中には，元の複合名詞の単語境界を認識する手がかりとなるものが
存在する．以下に具体例を示す．

\begin{lingexample}
 \head{アンチョビパスタ}{ex:anchovy}
 \sent{アンチョビ・パスタ\\[3pt]}
 \sent{アンチョビのパスタ}
\end{lingexample}

\noindent
(\ref{ex:anchovy}b)は，複合名詞(\ref{ex:anchovy}a)の構成語間に中黒を挿入
することによって生成された言い換え表現である．同様に(\ref{ex:anchovy}c)
は助詞「の」を挿入することによって生成された言い換え表現である．もしラベ
ルなしテキストにおいて(\ref{ex:anchovy}b)や(\ref{ex:anchovy}c)のような言
い換え表現を観測することができれば，このことは複合名詞
(\ref{ex:anchovy}a)を「アンチョビ」と「パスタ」に正しく分割するための手
がかりとなることが考えられる．

\subsection{言い換え規則}

このような言い換えを利用して片仮名複合名詞の分割処理を行うため，複合名詞
の言い換え規則を7つ作成した（表\ref{tab:para}）．言い換え規則の作成にあたっ
ては，Kageuraら\citeyear{Kageura04}の研究を参考にしながら，分割処理に有
用と思われるものを人手で選定した．作成した言い換え規則は全て
$X_1X_2\rightarrow X_1MX_2$という形式をしており（$X_1$と$X_2$は名詞，$M$
は助詞などの機能語），左辺が言い換え前の複合名詞，右辺が言い換え後の表現
に対応している．

\begin{table}[b]
\caption{作成した言い換え規則の一覧とその適用例．$X_1$と$X_2$は名詞を表す}
\label{tab:para}
\input{02table02.txt}
\end{table}



\subsection{言い換え頻度に基づく素性}

これらの規則を用いて，次のように新しい素性を定義する．まず前処理として，
以下のような正規表現を用いることにより，片仮名複合名詞の言い換え表現の出
現頻度をラベルなしテキストから求める．
\begin{quote}
 (katakana)+\;・\;(katakana)+ \\
 (katakana)+\;の\;(katakana)+ \\
 (katakana)+\;する\;(katakana)+ \\
 (katakana)+\;した\;(katakana)+ \\
 (katakana)+\;な\;(katakana)+ \\
 (katakana)+\;的\;(katakana)+ \\
 (katakana)+\;的な\;(katakana)+ 
\end{quote}
ただし(katakana)は片仮名1文字にマッチする特殊文字である．
また$+$は文字の繰り返しを表す量指定子であり，最長一致が適用されるものと
する．

このような正規表現を用いることによって，単語分割処理を行わずに言い換え表
現を抽出することができるのは，表\ref{tab:para}のような片仮名複合語の言い
換え表現に対象を限定しているためである．上記の正規表現にマッチするテキス
トは，必ず前後が片仮名以外の文字（漢字や平仮名）に囲まれていることになる．
そのような文字種の変わり目には，単語境界が存在する場合が多いため，このよ
うな単純な文字列処理であっても言い換え表現を抽出することが可能になってい
る．

分割処理時に分割候補$\y$が提示された際には，構成語 2-gram に対する言い換え
素性{\sc Para} ($y_{i-1}$, $y_{i}$)の値を次のように定義する．まず
$X_1=y_{i-1}$，$X_2=y_i$と代入することにより，表\ref{tab:para}の規則から
言い換え表現を生成する．そして，生成された7つの言い換え表現の頻度の和を
$F$としたとき，その対数$\log(F+1)$を素性値として用いる．

ここでは素性値の計算に非常に単純な方法を用いているため，$X_1$や$X_2$に名
詞ではなく，名詞連続が代入された場合であっても，素性が発火してしまうとい
うことがある．また逆に，正解となる構成語よりも小さな単位の文字列が代入さ
れた場合であっても，同様に素性が発火してしまうことがあり，精度に悪影響を
及ぼす可能性がある．しかし，このような手法であっても実験において分割精度
の向上を十分確認することができたため，シンプルさを重視して現在のような手
法とした．


素性値として頻度ではなく対数頻度を用いているのはスケーリングのためである．
予備的な実験においては，頻度をそのまま素性値として用いることも行ったが，
対数頻度を用いた場合の方が高い精度が得られた．なお，$\log F$ではなく
$\log(F+1)$としているのは，$F$ = 1 であった場合に素性値が0となるのを防ぐ
ためである．



\section{逆翻字素性} \label{sec:trans}

\begin{table}[b]
 \caption{単語対応付き翻字対の例．下線部に付与された数字は単語の対応を表
 す}
 \label{tab:trans}
\input{02table03.txt}
\end{table}

片仮名語の多くは英語を翻字したものであり，元となる英語表現が存在する．以
下では，そのような英語表現のことを{\bf 原語}と呼び，片仮名語と原語の対の
ことを{\bf 翻字対}と呼ぶこととする．我々は，片仮名語が原語の発音情報をお
およそ保持しているという特性を利用することによって，単語単位での対応関係
が付与された翻字対（{\bf 単語対応付き翻字対}）をラベルなしテキストから自動
抽出する（表\ref{tab:trans}）．そして，得られた単語対応付き翻字対に基づい
て，分割結果$\y$に出現する単語$n$-gramが，英単語$n$-gramと対応付け可能で
あるかを示す2値素性を用いる（表\ref{tab:feature}におけるテンプレート6と7
に対応する）．以下本節では，テキストから単語対応付き翻字対を自動抽出する
方法について説明する．
  
\subsection{括弧表現}

日本語においては，括弧表現を使って片仮名語の原語がテキスト中に挿入される
場合がある．

\begin{lingexample}
 \head{アメリカで\underline{ジャンクフード} (junk food)と言えば...}{ex:junk}
 \sent{トラックバック\underline{スパム} (spam)を撃退するため...}{}
\end{lingexample}

\noindent
いずれの例文においても，下線を引いた片仮名語に対して，その原語が括弧を使っ
て併記されている．我々はこのような括弧表現を利用することにより，単語対応
付き翻字対の自動抽出を行う．

こうした括弧表現から単語対応付き翻字対の抽出を行うためには，少なくとも以
下の3つのことが技術的な問題となる
\begin{description}
 \item[問題A]
	    片仮名語の直後に出現する括弧表現が必ずしもその原語であるとは
	    限らないため，原語が記述されている括弧表現とそうでない括弧表
	    現を区別する必要がある．
 \item[問題B]
	    翻字対の関係にある片仮名語の開始位置を決定しなくてはならない．
	    例えば(\ref{ex:junk}b)においては，原語「spam」の翻字は「トラッ
	    クバックスパム」ではなく「スパム」である．
 \item[問題C]
	    片仮名語と原語の単語対応を求めるためには，片仮名語を分かち書
	    きしなくてはならない．例えば(\ref{ex:junk}a)から表
	    \ref{tab:trans}のような単語対応付き翻字対を獲得するためには，
	    片仮名列「ジャンクフード」を「ジャンク」と「フード」に分割す
	    ることが必要である．
\end{description}


\subsection{発音の類似性の利用}

これまでにも，前述のような括弧表現から翻字対を自動抽出する研究は数多く存
在するが，問題Cに対する本質的な解決策はいまだ提案されていない．これまで
の研究においては，基本的に既存の単語分割器を用いることによって片仮名語の
分割が行われている\cite{Cao07,Wu09}．しかし，\ref{sec:prev}節において議
論を行ったように，片仮名語の分かち書きを行うことは現在のところ技術的に困
難であり，このようなアプローチは望ましくない．

我々は上記の3つの問題を解決するため，片仮名語と原語の発音の類似性を利用
することを提案する．以下の議論では，説明のために，まず問題Cだけを議論の
対象とする．具体例として，片仮名語「ジャンクフード」と原語「junk food」
に対して，それらの発音の類似性に基づき以下のような部分文字列の対応関係が
得られたとする．

\begin{lingexample}
 \head{[ジャン]$_1$[ク]$_2$[フー]$_3$[ド]$_4$}{ex:junk2}
 \sent{[jun]$_1$[k]$_2$ [foo]$_3$[d]$_4$}
\end{lingexample} 

\noindent
ここでは，括弧で囲まれて同じ番号を添えられている部分文字列が，互いに対応
関係にあるものとする．括弧表現内の英語は空白を使って分かち書きされている
ため，上記のような部分文字列の対応関係を利用すれば，片仮名語と英単語が1
対1に対応するように片仮名列を分かち書きすることができる．また，その過程
において，単語間の対応関係も明らかにすることができる．

残る問題Aおよび問題Bに対しても，発音の類似性に基づいて同様に解決を図るこ
とが可能である．以下の例において，下線が引かれた片仮名語と括弧内の英語表現が翻字対であ
るか否かを判定することを考える．

\begin{lingexample}
 \head{検索\underline{エンジン} (Google)を使って...}{ex:google}
 \sent{\underline{トラックバックスパム} (spam)を撃退する...}{}
\end{lingexample}

\noindent
このように，括弧内に原語ではない表現が出現したり，片仮名語の開始位置が正
しく認識されなかった場合には，片仮名列とアルファベット列の発音の類似度が
低くなることが期待できるため，フィルタリングできると考えられる．単語対応
付き翻字対の具体的な抽出手順については，\ref{sec:extraction}節において説
明を行う．



\subsection{発音モデル} \label{sec:phonetic_model}

片仮名語と原語における部分文字列の対応関係の発見には，Jiampojamarnら
\citeyear{Jiampojamarn07}が提案した生成モデルを用いる．$f$と$e$をそ
れぞれ片仮名列とアルファベット列とし，これらの間の対応関係を見つけること
を考える．ただし，原語には空白が存在する可能性があるが，空白に対応する片
仮名文字列は存在しないことから，部分文字列の対応を求めるときにはアルファ
ベット列から空白を取り除いておく．例えば「ジャンクフード」と「junk food」
の部分文字列対応を求める場合には「$f=\text{ジャンクフード}$」「$e=\text{junkfood}$」と
する．ここで，$\mathcal{A}$をそれらの間の部分文字列の対応とする．具体的
には，$\mathcal{A}$は対応付けられている部分文字列の組($f_i$, $e_i$)の集合で
あり，$f=f_1f_2\dots f_{|\mathcal{A}|}$および$e=e_1e_2\dots
e_{|\mathcal{A}|}$となる．この部分文字列対応$\mathcal{A}$の確率を以下の
ように定義する．
\[
 \log p(f,e,\mathcal{A})=\sum_{(f_i,e_i)\in\mathcal{A}}\log p(f_{i},e_{i})
\]
一般に$\mathcal{A}$は観測することができないため隠れ変数として扱い，モデ
ルのパラメータは翻字対$(f,e)$の集合からEMアルゴリズムを用いて推定する．
詳細は文献\cite{Jiampojamarn07}を参照されたい．表\ref{tab:alignment}に
「ジャンクフード」と「junkfood」に対する部分文字列対応$\mathcal{A}$の具
体例，および実験において計算された確率値を示す．

この確率モデルを用いて，与えられた$(f,e)$に対する部分文字列の対応を次の
ように決定する．
\[
\mathcal{A}^{*}=\argmax_{\mathcal{A}}\log p(f,e,\mathcal{A})
\]
このとき$\mathcal{A}^{*}$の中の部分文字列$e_i$が空白をまたいでしまうと
（ジャンクフードの例であれば$e_i=\text{kfoo}$などとなった場合），
$\mathcal{A}^{*}$を使って片仮名列$f$を分かち書きすることができなくなって
しまう．そこで，アルファベット列$e$が空白を含んでいた場合は，前述のとお
り空白を取り除いて確率値の計算を行うが，空白の存在した箇所は記憶しておき，
部分文字列$e_i$が空白をまたがないという制約を加えて$\argmax$の計算を行う．

\begin{table}[t]
\hangcaption{片仮名列「$f=\text{ジャンクフード}$」とアルファベット列
   「$e=\text{junkfood}$」に対する部分文字列対応$\mathcal{A}$の具体例
   ($|\mathcal{A}|=4$)}
\label{tab:alignment}
\input{02table04.txt}
\end{table}


\subsection{単語対応付き翻字対の抽出} \label{sec:extraction}

この発音モデルを用いて，以下のような手順で単語対応付き翻字対の抽出を行う．
\begin{description}
 \item[手順1]
	    括弧内に出現するアルファベット列$e$と，その直前に出現する片
	    仮名列$f$を抽出し，それらの組$(f,e)$を翻字対の候補とする．た
	    だしアルファベット列は全て小文字に正規化する．
 \item[手順2]
	    翻字対候補$(f,e)$に対するスコアを以下のように定義し，それが
	    閾値$\theta$を越えたものを正しい翻字対と判定する．
	    \[
	    \frac{1}{N}\log p(f,e,\mathcal{A}^{*})
	    \]
	    式中の$N$は$e$に含まれる単語数であり，$\frac{1}{N}$という項
	    は単語数が多い場合にスコアが過剰に小さくなるのを防ぐために導
	    入している．ここでスコアが閾値を下回っていた場合には，片仮名
	    語の開始位置を正しく判定できていない可能性がある．そこで，片
	    仮名列$f$の最左文字を1文字ずつ削除していき，閾値を上回るもの
	    が見つかればそれを翻字対と判定し，次の翻字対候補の処理に移る．	    
	    
 \item[手順3]
	    得られた翻字対$(f,e)$に対して，部分文字列対応
	    $\mathcal{A}^{*}$に基づいて片仮名列$f$を分かち書きし，単語の
	    対応関係を求める．これにより，単語対応付き翻字対のリストを得
	    ることができる．
\end{description}

\noindent
ただし，手順2においては，表記揺れやタイポなどの要因により，1つの片仮名列
に対して複数の逆翻字が見つかる可能性がある．その場合は，各片仮名列$f$に
対して，最もスコアの高い翻字対$(f,e)$のみを保持して，それ以外のものは使
用しない．


\end{document}
