自然言語処理における領域適応は，帰納学習手法を利用する全てのタスクで生じる問題であるために，その研究は多岐にわたる．
利用手法をおおまかに分類すると，ターゲット領域のラベル付きデータを利用するかしないかで分類できる．
利用する場合を教師付き領域適応手法，利用しない場合を教師なし領域適応手法と呼ぶ．
本稿における手法は教師付き領域適応手法の範疇に入るので，ここでは提案手法に関連する教師付き領域適応手法の従来研究を述べる．
教師付き領域適応手法においては，一般に，ターゲット領域の知識は使えるだけ使えばよいはずなので，ポイントはソース領域の知識の利用方法にある．
ソース領域とターゲット領域間の距離が離れすぎている場合，ソース領域の知識を使いすぎると分類器の精度が悪化する現象がおこる．
これは負の転移[CITE]と呼ばれている．
負の転移を避けるには，本質的に，ソース領域とターゲット領域間の距離を測り，その距離を利用してソース領域の知識の利用を制御する形となる．
Aschは品詞タグ付けをタスクとして領域間の類似性を測り，その類似度から領域適応を行った際に精度がどの程度悪くなるかを予測できることを示した[CITE]．
張本は構文解析をタスクとしてターゲット領域を変化させたときの精度低下の要因を調査し，そこから新たな領域間の類似性の尺度を提案している[CITE]．
Plankは構文解析をタスクとして領域間の類似性を測ることで，ターゲット領域を解析するのに最も適したソース領域を選んでいる[CITE]．
Ponomareva [CITE]やRemus [CITE]は感情極性分類をタスクとして領域間の類似度を学習中のパラメータに利用した．
これらの研究はタスク毎に類似性を測るが，WSDがタスクの場合，領域間の類似性はWSDの対象単語に依存していると考えられる．
古宮は対象単語毎に領域間の距離を含めた性質によって適用する学習手法を変化させている[CITE]．
上記した古宮の一連の研究は広い意味でアンサンブル学習の一種である．
そこでアンサンブルされる各要素となる学習手法をみるとソース領域のデータとターゲット領域のデータへの各重みが異なるだけである．
つまり領域適応においてはソース領域のデータとターゲット領域のデータへの各重みを調整して，学習手法を適用するというアプローチが有力である．
Jiang [CITE]は[MATH]と[MATH]との差が極端に大きいデータを``misleading''データとして訓練データから取り除いて学習することを試みた．
これは``misleading''データの重みを0にした学習と見なせるため，この手法も重み付けの手法と見なせる．
本稿で利用する共変量シフト下での学習もこの範疇の手法といえる．
素性空間拡張法[CITE]も重み付け手法である．
ただしデータではなくデータ中の素性に重みをつける．
そこではソース領域の訓練データのベクトル[MATH]を[MATH]と連結した3倍の長さのベクトルに直し，ターゲット領域の訓練データのベクトル[MATH]を[MATH]と連結した3倍の長さのベクトルに直す．
ここで[MATH]は[MATH]や[MATH]と同じ次元数であり，しかもすべての次元の値が0であるようなベクトルである．
この3倍にしたベクトルを用いて，通常の分類問題として解く．
この手法は非常に簡易でありながら，効果が高い手法として知られている．
この拡張手法はソース領域とターゲット領域に共通している特徴が重なることで，結果として共通している特徴の重みがつくことで領域適応に効果が出ると考えられる．
また領域適応の問題を共変量シフト下の学習を用いて解決する研究としては，Jiangの研究[CITE]と齋木の研究[CITE]がある．
Jiangは確率密度比を手動で調整し，モデルにはロジステック回帰を用いている．
また齋木は[MATH]をunigramでモデル化することで確率密度比を推定し，モデルには最大エントロピー法のモデルを用いている．
ただしどちらの研究もタスクはWSDではない．
また共変量シフト下では[MATH]を仮定するが，[MATH]を仮定するアプローチもある．
この場合，ベイズの定理から
\arg\max_{c \in C} P_T (c|\boldsymbol{x}) & = \arg\max_{c \in C} P_T(c) P_T(\boldsymbol{x}|c)
& = \arg\max_{c \in C} P_T(c) P_S(\boldsymbol{x}|c)
となるので領域適応の問題は[MATH]の推定に帰着できる．
実際，Chanらは[MATH]と[MATH]の違いの影響は非常に小さいと考え，[MATH]を仮定し，[MATH]をEMアルゴリズムで推定することでWSDの領域適応を行っている[CITE]．
更に新納らは[MATH]の仮定があったとしても，コーパスのスパース性から単純に[MATH]を[MATH]で置き換えることはできないと考え，[MATH]の推定の問題と[MATH]の推定の問題を個別に対処することを提案している[CITE]．
自然言語処理における領域適応は，帰納学習手法を利用する全てのタスクで生じる問題であるために，その研究は多岐にわたる．
利用手法をおおまかに分類すると，ターゲット領域のラベル付きデータを利用するかしないかで分類できる．
利用する場合を教師付き領域適応手法，利用しない場合を教師なし領域適応手法と呼ぶ．
本稿における手法は教師付き領域適応手法の範疇に入るので，ここでは提案手法に関連する教師付き領域適応手法の従来研究を述べる．
教師付き領域適応手法においては，一般に，ターゲット領域の知識は使えるだけ使えばよいはずなので，ポイントはソース領域の知識の利用方法にある．
ソース領域とターゲット領域間の距離が離れすぎている場合，ソース領域の知識を使いすぎると分類器の精度が悪化する現象がおこる．
これは負の転移[CITE]と呼ばれている．
負の転移を避けるには，本質的に，ソース領域とターゲット領域間の距離を測り，その距離を利用してソース領域の知識の利用を制御する形となる．
Aschは品詞タグ付けをタスクとして領域間の類似性を測り，その類似度から領域適応を行った際に精度がどの程度悪くなるかを予測できることを示した[CITE]．
張本は構文解析をタスクとしてターゲット領域を変化させたときの精度低下の要因を調査し，そこから新たな領域間の類似性の尺度を提案している[CITE]．
Plankは構文解析をタスクとして領域間の類似性を測ることで，ターゲット領域を解析するのに最も適したソース領域を選んでいる[CITE]．
Ponomareva [CITE]やRemus [CITE]は感情極性分類をタスクとして領域間の類似度を学習中のパラメータに利用した．
これらの研究はタスク毎に類似性を測るが，WSDがタスクの場合，領域間の類似性はWSDの対象単語に依存していると考えられる．
古宮は対象単語毎に領域間の距離を含めた性質によって適用する学習手法を変化させている[CITE]．
上記した古宮の一連の研究は広い意味でアンサンブル学習の一種である．
そこでアンサンブルされる各要素となる学習手法をみるとソース領域のデータとターゲット領域のデータへの各重みが異なるだけである．
つまり領域適応においてはソース領域のデータとターゲット領域のデータへの各重みを調整して，学習手法を適用するというアプローチが有力である．
Jiang [CITE]は[MATH]と[MATH]との差が極端に大きいデータを``misleading''データとして訓練データから取り除いて学習することを試みた．
これは``misleading''データの重みを0にした学習と見なせるため，この手法も重み付けの手法と見なせる．
本稿で利用する共変量シフト下での学習もこの範疇の手法といえる．
素性空間拡張法[CITE]も重み付け手法である．
ただしデータではなくデータ中の素性に重みをつける．
そこではソース領域の訓練データのベクトル[MATH]を[MATH]と連結した3倍の長さのベクトルに直し，ターゲット領域の訓練データのベクトル[MATH]を[MATH]と連結した3倍の長さのベクトルに直す．
ここで[MATH]は[MATH]や[MATH]と同じ次元数であり，しかもすべての次元の値が0であるようなベクトルである．
この3倍にしたベクトルを用いて，通常の分類問題として解く．
この手法は非常に簡易でありながら，効果が高い手法として知られている．
この拡張手法はソース領域とターゲット領域に共通している特徴が重なることで，結果として共通している特徴の重みがつくことで領域適応に効果が出ると考えられる．
また領域適応の問題を共変量シフト下の学習を用いて解決する研究としては，Jiangの研究[CITE]と齋木の研究[CITE]がある．
Jiangは確率密度比を手動で調整し，モデルにはロジステック回帰を用いている．
また齋木は[MATH]をunigramでモデル化することで確率密度比を推定し，モデルには最大エントロピー法のモデルを用いている．
ただしどちらの研究もタスクはWSDではない．
また共変量シフト下では[MATH]を仮定するが，[MATH]を仮定するアプローチもある．
この場合，ベイズの定理から
\arg\max_{c \in C} P_T (c|\boldsymbol{x}) & = \arg\max_{c \in C} P_T(c) P_T(\boldsymbol{x}|c)
& = \arg\max_{c \in C} P_T(c) P_S(\boldsymbol{x}|c)
となるので領域適応の問題は[MATH]の推定に帰着できる．
実際，Chanらは[MATH]と[MATH]の違いの影響は非常に小さいと考え，[MATH]を仮定し，[MATH]をEMアルゴリズムで推定することでWSDの領域適応を行っている[CITE]．
更に新納らは[MATH]の仮定があったとしても，コーパスのスパース性から単純に[MATH]を[MATH]で置き換えることはできないと考え，[MATH]の推定の問題と[MATH]の推定の問題を個別に対処することを提案している[CITE]．
