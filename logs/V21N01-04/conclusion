考察

\subsection{負の転移の有無}

WSD の領域適応では，対象単語毎に領域適応の問題が生じている．
実験では領域の組み合わせで 6通り，対象単語が 16単語あるので，
合計 96 ($= 6 \times 16$) 通りの領域適応の問題を扱ったことになる．
ここでは各領域適応の問題に対して負の転移が生じているかどうかを調べ，
それぞれのケースに分けて，各手法の正解率を調べた．

\begin{table}[b]
\caption{負の転移が生じていない領域適応}
\label{tab:funoteni}
\input{04table03.txt}
\end{table}

まず負の転移が生じているかどうかの判定には，
先の実験でより得られた
\verb|T-Only|，\verb|S-Only| 及び
\verb|S+T| の正解率を利用する．もしも正解率で以下の関係が成立しているなら，
負の転移が生じていないと考えられる．
\begin{center}
\verb|T-Only, S-Only  <  S+T| 
\end{center}
結果を\mbox{表\ref{tab:funoteni}}に示す．チェックがつけられた箇所が
負の転移が生じていない領域適応の問題である．96種類の領域適応の問題の中で
44種類において負の転移が生じていない．


次に負の転移が生じているかいないかのケースに分けて，各手法の平均正解率を調べた．
結果を\mbox{表\ref{tab:funoteni2}}に示す．

\begin{table}[t]
\caption{負の転移と各手法の平均正解率}
\label{tab:funoteni2}
\input{04table04.txt}
\end{table}

\mbox{表\ref{tab:funoteni2}}において領域適応に対処する 3 手法（Daum{\'e}，Cov-Shift，提案手法）を見ると，
提案手法は負の転移の有無に関わらず Cov-Shift よりも
高い正解率であり，提案手法は Cov-Shift の改良になっていることがわかる．
更に負の転移が生じていないケースでは Cov-Shift は Daum{\'e} よりも正解率が高く，
このケースでは素性に重みをつけるよりも事例に重みをつける方が
効果があることがわかる．
ただし負の転移が生じるケースでは，提案手法は Daum{\'e} よりも正解率が若干低い．
つまり提案手法を Daum{\'e} の手法の改良と見た場合，
負の転移が生じるケースでは正解率の低下を抑え，
その代わりに負の転移が生じないケースで正解率を高めることで，
全体的な正解率を改善する手法と見なせる．

また領域適応に対処しない 3 手法 (S-Only, T-Only, S+T)
も含めて比較すると，負の転移が生じるケースでは領域適応に対処する 3 手法（Daum{\'e}，Cov-Shift，提案手法）
の正解率はかなり悪い．
つまり WSD の領域適応では負の転移を検出することで大きな改善が期待できる．
共変量シフト下の学習では，負の転移が生じているケースに対しては，
ソース領域のデータに 0 に近い重みを与えられればよいはずである．
より正確な確率密度比の推定法を利用することで，
このような重み付けが可能だと考える．この点は今後の課題である．


\subsection{確率密度比の調整}

確率密度比を精度良く推定することは困難な問題である．
そのために求まった確率密度比を調整することも行われている．
杉山は
確率密度比\( r \)に\( p \) (\(0 < p < 1\)) 乗した\( r^p \)を重みにすることを
提案している\cite{sugiyama-2006-09-05}．
また Yamada は relative density ratio として確率密度比を
以下の形で求めることを提案してる\cite{yamada2011relative}．
\[
\frac{P_T(\boldsymbol{x})}{\alpha P_T(\boldsymbol{x}) + (1-\alpha)P_S(\boldsymbol{x})}
\]

ここでは\( r^{0.5} \)の重みと\( \alpha = 0.5 \)の relative density ratio を試した．
結果を\mbox{表\ref{tab:mitudohi-hikaku}}に示す．
\mbox{表\ref{tab:mitudohi-hikaku}}における提案手法と Cov-Shift は
\mbox{表\ref{tab:resultall}}における提案手法と Cov-Shift と同じものである．
\( r^{0.5}\)が \mbox{Cov-Shift} の重み\( r \)を 0.5 乗したものであり，
RDR が\( \alpha = 0.5 \)の relative density ratio である．

\mbox{表\ref{tab:mitudohi-hikaku}}をみると，
\( r^{0.5}\)や relative density ratio の調整は一部有効な問題もあったが，
全体として見ると，効果はあまりない．
これも本来の確率密度値\( P_S(\boldsymbol{x}) \)や\( P_T(\boldsymbol{x}) \)の推定が簡易すぎるために
生じていると考える．

\begin{table}[b]
\caption{確率密度比の調整による平均正解率}
\label{tab:mitudohi-hikaku}
\input{04table05.txt}
\end{table}

確率密度比を確率統計的により精緻に求めていくことは重要である．
ただし確率密度比は事例の重み，つまり事例の重要度を意味している．
事例の重要度という自然言語処理的な観点から WSD の領域適応に特化した
重みの設定も可能である．


\subsection{ SVM の利用}

本稿では学習アルゴリズムとして最大エントロピー法を用いた．
共変量シフトの解法として，重み付き対数尤度を最大化する形では，
\( P_T(c|\boldsymbol{x}) \)をモデル化するアプローチに限られる．
しかし共変量シフト下の学習では
確率密度比を重みにして期待損失を最小化すれば良いので，
損失関数ベースの学習手法が利用できる．
例えばヒンジ損失関数に密度比で重みづけすることで共変量シフト下の学習に
SVM を利用できる\cite{sugiyama-book}．
ただし SVM 自体の実装が容易ではないために簡単に試すことはできない．

\begin{table}[b]
\caption{SVM による平均正解率}
\label{tab:result-svm}
\input{04table06.txt}
\end{table}

ここでは共変量シフト下の学習に SVM を用いるのではなく，
素性空間拡張法により拡張されたデータに対して，SVM を利用してみる．
実行にはツールの libsvm\footnote{http://www.csie.ntu.edu.tw/\~{}cjlin/libsvm/}を用いた．
またそこで利用したカーネルは線形カーネルである．
実験結果を\mbox{表\ref{tab:result-svm}}に示す．

提案手法が本稿での提案手法での平均正解率であり，
D3-ME が素性空間拡張法と最大エントロピー法を利用した場合の平均正解率である．
つまり提案手法とD3-MEは，\mbox{表\ref{tab:resultall}}での提案手法と
Daum{\'e} に対応する．
そしてD3-SVM が素性空間拡張法と SVM を利用した場合の平均正解率である．
提案手法は D3-SVM よりもわずかに高い正解率となっているが，
その差は小さく識別能力については，提案手法と D3-SVM は同程度と言える．
また D3-SVM は  D3-ME よりも正解率が高い．
つまり最大エントロピー法ではなく，SVM を利用する方が正解率が高くなると予想できる．
このことから共変量シフト下の学習に SVM を利用すれば，
改善が可能であると考えられる．これは今後の課題である．


\subsection{教師なし手法への適用}

共変量シフト下での学習では訓練データの中にターゲット領域のデータが
含まれる必要はない．ターゲット領域の訓練データを含めなければ，
教師なし領域適応手法となるはずである．
この点を確認した実験を行った．
実験結果を\mbox{表\ref{tab:unsuper}}に示す．
表の S-Only の列はソース領域の訓練データだけで学習した結果である．
これは\mbox{表\ref{tab:resultall}}の S-Only に対応する．
W-S-Only はソース領域の訓練データのみを使った共変量シフト下での学習手法である．
また参考までに提案手法の結果も記している．

\begin{table}[b]
\caption{重み付き教師なし学習による平均正解率}
\label{tab:unsuper}
\input{04table07.txt}
\end{table}

確率密度比を用いる W-S-Only ではソース領域の
データへの重みが小さくなりがちである．
ここでの実験では重みが 0.01 未満の場合はそのデータを省いて学習させている．
そのために W-S-Only では極端にラベル付きデータが減少するケースがあった．
結果として精度が低くなってしまったと考えられる．
また多くの単語で正解率の低下が起こっていた．
この原因としては，重みのあるデータの欠如だと考える．
例えば，語義\( c_1 \)のデータ\( x_1 \)の重みが\( 0.01 \)，
語義\( c_2 \)のデータ\( x_2 \)の重みが\( 0.02 \)である場合，
どちらの重みも「小さく」，その差はほぼ等しいと見なして\( P(c_1) = P(c_2) = 0.5 \)と考えるのが妥当であるが，
「小さい」という点を考えないと\( P(c_1) = 1/3\), \(P(c_2) = 2/3 \)となってしまう．
「小さい」という点を考えるためには比較となるある程度「大きな」データが必要である．
例えば，上記の設定の上で語義\( c_1 \)のデータ\( x_3 \)の重みが 1 などという
データが存在すれば，\( P(c_1) = 101/103\), \(P(c_2) = 2/103 \)となり，
これは妥当である．つまり重みが低いデータが多数を占めるような場合，
信頼性のある推定が行えない．ある程度，重みのあるデータが必要だと思われる．
このため共変量シフト下での学習を教師なしの枠組みに単純に利用することは難しい．
教師なしの枠組みへの利用方法の検討は今後の課題である．


おわりに

本稿では WSD の領域適応の問題
が共変量シフトの問題と見なせることを示した．そして，共変量シフトの
標準的な解法である確率密度比を重みにしたパラメータ学習により，
WSD の領域適応の解決が図れることを示した．
また素性空間拡張法により拡張されたデータに対して，共変量シフトの
解法を行う手法を提案した．

BCCWJ コーパスの3つ領域 OC （Yahoo! 知恵袋），PB （書籍）及び PN （新聞）を選び，
SemEval-2 の日本語 WSD タスクのデータを利用して，
上記領域にある程度の頻度がある多義語 16単語を対象に，WSD の領域適応の実験を行った．
実験の結果，提案手法は Daum{\'e} の手法と同等以上の正解率を出した．

共変量シフトの解法では確率密度比の算出が鍵となるが，ここでは Naive
Bayes で利用されるモデルを利用した簡易な算出法を試みた．
このような簡易な算出法であっても
WSD の領域適応に共変量シフトの解法を利用する効果が高いことが示された．

より正確な確率密度比の推定法を利用したり，
最大エントロピー法に代えてSVM を利用するなどの工夫で更なる改善が可能である．
また教師なし領域適応へも応用可能である．
WSD の領域適応に共変量シフトの解法を利用することは有望であると考えられる．

\acknowledgment

Classias の作者である岡崎直観氏に，Classias の事例の重み付け方法について教えていただきました．
また本稿の査読者殿には有益なコメントいただきました．感謝いたします．


\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Chan \BBA\ Ng}{Chan \BBA\ Ng}{2005}]{chan2005word}
Chan, Y.~S.\BBACOMMA\ \BBA\ Ng, H.~T. \BBOP 2005\BBCP.
\newblock \BBOQ Word Sense Disambiguation with Distribution Estimation.\BBCQ\
\newblock In {\Bem Proceedings of IJCAI-2005}, \mbox{\BPGS\ 1010--1015}.

\bibitem[\protect\BCAY{Chan \BBA\ Ng}{Chan \BBA\ Ng}{2006}]{chan2006estimating}
Chan, Y.~S.\BBACOMMA\ \BBA\ Ng, H.~T. \BBOP 2006\BBCP.
\newblock \BBOQ Estimating class priors in domain adaptation for word sense
  disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of COLING-ACL-2006}, \mbox{\BPGS\ 89--96}.

\bibitem[\protect\BCAY{Daum\'{e}}{Daum\'{e}}{2007}]{daume0}
Daum\'{e}, H.~I. \BBOP 2007\BBCP.
\newblock \BBOQ Frustratingly Easy Domain Adaptation.\BBCQ\
\newblock In {\Bem Proceedings of ACL-2007}, \mbox{\BPGS\ 256--263}.

\bibitem[\protect\BCAY{張本\JBA 宮尾\JBA 辻井}{張本 \Jetal }{2010}]{harimoto}
張本佳子\JBA 宮尾祐介\JBA 辻井潤一 \BBOP 2010\BBCP.
\newblock
  構文解析の分野適応における精度低下要因の分析及び分野間距離の測定手法.\
\newblock \Jem{言語処理学会第16回年次大会}, \mbox{\BPGS\ 27--30}.

\bibitem[\protect\BCAY{Jiang \BBA\ Zhai}{Jiang \BBA\
  Zhai}{2007}]{jiang2007instance}
Jiang, J.\BBACOMMA\ \BBA\ Zhai, C. \BBOP 2007\BBCP.
\newblock \BBOQ Instance weighting for domain adaptation in NLP.\BBCQ\
\newblock In {\Bem Proceedings of ACL-2007}, \mbox{\BPGS\ 264--271}.

\bibitem[\protect\BCAY{神嶌}{神嶌}{2010}]{kamishima}
神嶌敏弘 \BBOP 2010\BBCP.
\newblock 転移学習.\
\newblock \Jem{人工知能学会誌}, {\Bbf 25}  (4), \mbox{\BPGS\ 572--580}.

\bibitem[\protect\BCAY{古宮\JBA 奥村}{古宮\JBA 奥村}{2012}]{komiya-nlp2012}
古宮嘉那子\JBA 奥村学 \BBOP 2012\BBCP.
\newblock 語義曖昧性解消のための領域適応手法の決定木学習による自動選択.\
\newblock \Jem{自然言語処理}, {\Bbf 19}  (3), \mbox{\BPGS\ 143--166}.

\bibitem[\protect\BCAY{Komiya \BBA\ Okumura}{Komiya \BBA\
  Okumura}{2011}]{komiya3}
Komiya, K.\BBACOMMA\ \BBA\ Okumura, M. \BBOP 2011\BBCP.
\newblock \BBOQ Automatic Determination of a Domain Adaptation Method for Word
  Sense Disambiguation using Decision Tree Learning.\BBCQ\
\newblock In {\Bem Proceedings of IJCNLP-2011}, \mbox{\BPGS\ 1107--1115}.

\bibitem[\protect\BCAY{Komiya \BBA\ Okumura}{Komiya \BBA\
  Okumura}{2012}]{komiya2}
Komiya, K.\BBACOMMA\ \BBA\ Okumura, M. \BBOP 2012\BBCP.
\newblock \BBOQ Automatic Domain Adaptation for Word Sense Disambiguation Based
  on Comparison of Multiple Classifiers.\BBCQ\
\newblock In {\Bem Proceedings of PACLIC-2012}, \mbox{\BPGS\ 75--85}.

\bibitem[\protect\BCAY{Maekawa}{Maekawa}{2007}]{bccwj}
Maekawa, K. \BBOP 2007\BBCP.
\newblock \BBOQ Design of a Balanced Corpus of Contemporary Written
  Japanese.\BBCQ\
\newblock In {\Bem Symposium on Large-Scale Knowledge Resources (LKR2007)},
  \mbox{\BPGS\ 55--58}.

\bibitem[\protect\BCAY{Okazaki}{Okazaki}{2009}]{Classias}
Okazaki, N. \BBOP 2009\BBCP.
\newblock \BBOQ Classias: a collection of machine-learning algorithms for
  classification.\BBCQ\ \texttt{http://www.chokkan.org/software/classias/}.

\bibitem[\protect\BCAY{Okumura, Shirai, Komiya, \BBA\ Yokono}{Okumura
  et~al.}{2010}]{semeval-2010}
Okumura, M., Shirai, K., Komiya, K., \BBA\ Yokono, H. \BBOP 2010\BBCP.
\newblock \BBOQ SemEval-2010 Task: Japanese WSD.\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Workshop on Semantic
  Evaluation}, \mbox{\BPGS\ 69--74}.

\bibitem[\protect\BCAY{Plank \BBA\ van Noord}{Plank \BBA\ van
  Noord}{2011}]{plank}
Plank, B.\BBACOMMA\ \BBA\ van Noord, G. \BBOP 2011\BBCP.
\newblock \BBOQ Effective measures of domain similarity for parsing.\BBCQ\
\newblock In {\Bem Proceedings of ACL-2011}, \mbox{\BPGS\ 1566--1576}.

\bibitem[\protect\BCAY{Ponomareva \BBA\ Thelwall}{Ponomareva \BBA\
  Thelwall}{2012}]{ponomareva}
Ponomareva, N.\BBACOMMA\ \BBA\ Thelwall, M. \BBOP 2012\BBCP.
\newblock \BBOQ Which resource is best for cross-domain sentiment
  analysis?\BBCQ\
\newblock In {\Bem Proceedings of CICLing-2012}, \mbox{\BPGS\ 488--499}.

\bibitem[\protect\BCAY{Remus}{Remus}{2012}]{rem2012}
Remus, R. \BBOP 2012\BBCP.
\newblock \BBOQ Domain Adaptation Using Domain Similarity- and Domain
  Complexity-based Instance Selection for Cross-domain Sentiment
  Analysis.\BBCQ\
\newblock In {\Bem Proceedings of the 2012 IEEE 12th International Conference
  on Data Mining Workshops (ICDMW 2012) Workshop on Sentiment Elicitation from
  Natural Text for Information Retrieval and Extraction (SENTIRE)},
  \mbox{\BPGS\ 717--723}.

\bibitem[\protect\BCAY{Rosenstein, Marx, Kaelbling, \BBA\
  Dietterich}{Rosenstein et~al.}{2005}]{rosenstein2005transfer}
Rosenstein, M.~T., Marx, Z., Kaelbling, L.~P., \BBA\ Dietterich, T.~G. \BBOP
  2005\BBCP.
\newblock \BBOQ To transfer or not to transfer.\BBCQ\
\newblock In {\Bem Proceedings of the NIPS 2005 Workshop on Inductive Transfer:
  10 Years Later}.

\bibitem[\protect\BCAY{齋木\JBA 高村\JBA 奥村}{齋木 \Jetal
  }{2008}]{saiki-2008-03-27}
齋木陽介\JBA 高村大也\JBA 奥村学 \BBOP 2008\BBCP.
\newblock 文の感情極性判定における事例重み付けによるドメイン適応.\
\newblock \Jem{情報処理学会第184回自然言語処理研究会}, \mbox{\BPGS\ 61--67}.

\bibitem[\protect\BCAY{Shimodaira}{Shimodaira}{2000}]{shimodaira2000improving}
Shimodaira, H. \BBOP 2000\BBCP.
\newblock \BBOQ Improving predictive inference under covariate shift by
  weighting the log-likelihood function.\BBCQ\
\newblock {\Bem Journal of statistical planning and inference}, {\Bbf 90}  (2),
  \mbox{\BPGS\ 227--244}.

\bibitem[\protect\BCAY{新納\JBA 佐々木}{新納\JBA
  佐々木}{2013}]{shinnou-gengo-13}
新納浩幸\JBA 佐々木稔 \BBOP 2013\BBCP.
\newblock k近傍法とトピックモデルを利用した語義曖昧性解消の領域適応.\
\newblock \Jem{自然言語処理}, {\Bbf 20}  (5), \mbox{\BPGS\ 707--726}.

\bibitem[\protect\BCAY{Sogaard}{Sogaard}{2013}]{da-book}
Sogaard, A. \BBOP 2013\BBCP.
\newblock {\Bem Semi-Supervised Learning and Domain Adaptation in Natural
  Language Processing}.
\newblock Morgan \& Claypool.

\bibitem[\protect\BCAY{杉山}{杉山}{2006}]{sugiyama-2006-09-05}
杉山将 \BBOP 2006\BBCP.
\newblock 共変量シフト下での教師付き学習.\
\newblock \Jem{日本神経回路学会誌}, {\Bbf 13}  (3), \mbox{\BPGS\ 111--118}.

\bibitem[\protect\BCAY{杉山}{杉山}{2010}]{sugiyama-2010}
杉山将 \BBOP 2010\BBCP.
\newblock 密度比に基づく機械学習の新たなアプローチ.\
\newblock \Jem{統計数理}, {\Bbf 58}  (2), \mbox{\BPGS\ 141--155}.

\bibitem[\protect\BCAY{Sugiyama \BBA\ Kawanabe}{Sugiyama \BBA\
  Kawanabe}{2011}]{sugiyama-book}
Sugiyama, M.\BBACOMMA\ \BBA\ Kawanabe, M. \BBOP 2011\BBCP.
\newblock {\Bem Machine Learning in Non-Stationary Environments: Introduction
  to Covariate Shift Adaptation}.
\newblock MIT Press.

\bibitem[\protect\BCAY{高村}{高村}{2010}]{takamura}
高村大也 \BBOP 2010\BBCP.
\newblock \Jem{言語処理のための機械学習入門}.
\newblock コロナ社.

\bibitem[\protect\BCAY{Van~Asch \BBA\ Daelemans}{Van~Asch \BBA\
  Daelemans}{2010}]{vanasch}
Van~Asch, V.\BBACOMMA\ \BBA\ Daelemans, W. \BBOP 2010\BBCP.
\newblock \BBOQ Using domain similarity for performance estimation.\BBCQ\
\newblock In {\Bem Proceedings of the 2010 Workshop on Domain Adaptation for
  Natural Language Processing}, \mbox{\BPGS\ 31--36}.

\bibitem[\protect\BCAY{Yamada, Suzuki, Kanamori, Hachiya, \BBA\
  Sugiyama}{Yamada et~al.}{2011}]{yamada2011relative}
Yamada, M., Suzuki, T., Kanamori, T., Hachiya, H., \BBA\ Sugiyama, M. \BBOP
  2011\BBCP.
\newblock \BBOQ Relative density-ratio estimation for robust distribution
  comparison.\BBCQ\
\newblock {\Bem Neural Computation}, {\Bbf 25}  (5), \mbox{\BPGS\ 1370--1370}.

\end{thebibliography}


\begin{biography}

\bioauthor{新納　浩幸}{
1985年東京工業大学理学部情報科学科卒業．
1987年同大学大学院理工学研究科情報科学専攻修士課程修了．
同年富士ゼロックス，翌年松下電器を経て，
1993年4月茨城大学工学部システム工学科助手．
1997年10月同学科講師，2001年4月同学科助教授，
現在，茨城大学工学部情報工学科准教授．博士（工学）．
機械学習や統計的手法による自然言語処理の研究に従事．
言語処理学会，情報処理学会，人工知能学会 各会員．
}
\bioauthor{佐々木　稔}{
1996年徳島大学工学部知能情報工学科卒業．
2001年同大学大学院博士後期課程修了．博士（工学）．
2001年12月茨城大学工学部情報工学科助手．
現在，茨城大学工学部情報工学科講師．
機械学習や統計的手法による情報検索，自然言語処理等に関する研究に従事．
言語処理学会，情報処理学会 各会員．
}

\end{biography}

\biodate




