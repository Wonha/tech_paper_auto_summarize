================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.68528] 本稿では語義曖昧性解消(Word Sense Disambiguation, WSD)の領域適応が共変量シフトの問題と見なせることを示し，共変量シフトの解法である確率密度比を重みにしたパラメータ学習により，WSDの領域適応の解決を図る．
[i:1, score:0.48559] 共変量シフトの解法では確率密度比の算出が鍵となるが，ここではNaive Bayesで利用されるモデルを利用した簡易な算出法を試みた．
[i:9, score:0.55012] WSDの領域適応に共変量シフトの解法を利用することは有望であると考えられる．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:10, score:0.55983] 本稿では語義曖昧性解消(Word Sense Disambiguation, WSD)をタスクとした領域適応の問題が共変量シフトの問題と見なせることを示す．
[i:11, score:0.65477] そして共変量シフトの解法である確率密度比を重みにしたパラメータ学習により，WSDの領域適応の解決を図る．
[i:34, score:0.55634] 本稿ではWSDの領域適応の問題を共変量シフトの問題として捉え，共変量シフトの解法を利用してWSDの領域適応を解決することを試みる．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:69, score:0.35963] つまり領域適応においてはソース領域のデータとターゲット領域のデータへの各重みを調整して，学習手法を適用するというアプローチが有力である．
[i:79, score:0.34940] この拡張手法はソース領域とターゲット領域に共通している特徴が重なることで，結果として共通している特徴の重みがつくことで領域適応に効果が出ると考えられる．
[i:80, score:0.48614] また領域適応の問題を共変量シフト下の学習を用いて解決する研究としては，Jiangの研究[CITE]と齋木の研究[CITE]がある．

================================================================
[section type  : proposed_method]
[section title : 期待損失最小化からみた共変量シフト]
================================================================
[i:93, score:0.28668] [MATH]をターゲット領域上の分布とすれば，領域適応の問題における期待損失[MATH]は以下で表せる．
[i:95, score:0.27466] ここで共変量シフトの仮定から
[i:98, score:0.31388] となるので，期待損失最小化の観点から考えると，共変量シフトの問題は以下の式[MATH]を最小にする[MATH]を求めればよいことがわかる．

================================================================
[section type  : proposed_method]
[section title : 重み付き対数尤度の最大化]
================================================================
[i:101, score:0.48855] つまり，分類問題の解決に[MATH]のモデルを導入するアプローチを取る場合，共変量シフト下での学習では，確率密度比を重みとした以下に示す重み付き対数尤度[MATH]を最大化するパラメータ[MATH]を求める形となる．
[i:107, score:0.32940] 共変量シフト下ではない通常のケースでは，重みパラメータは最尤法から求める．
[i:111, score:0.32119] 共変量シフト下の学習では式([REF_eq:2])の[MATH]を最大にする[MATH]を求める．

================================================================
[section type  : proposed_method]
[section title : 確率密度比の算出]
================================================================
[i:118, score:0.41563] 共変量シフト下の学習では確率密度比の算出が鍵である．
[i:122, score:0.47504] 本稿の目的はこのような簡易な手法による確率密度比の算出法であっても，WSDの領域適応の有力な解法になることを示すことである．
[i:131, score:0.30902] 以上より，ソース領域[MATH]の用例[MATH]に対して，確率密度比[MATH]が計算できる．

================================================================
[section type  : proposed_method]
[section title : 提案手法]
================================================================
[i:137, score:0.32094] つまり拡張されたデータに対して，共変量シフト下の学習も可能である．
[i:138, score:0.36783] 本稿では，素性空間拡張法により拡張されたデータに対して，4章で説明した共変量シフト下の学習を行うことを提案手法する．
[i:140, score:0.31978] 素性空間拡張法により，ソース領域の訓練データ[MATH]は[MATH]という3倍の長さのベクトルに拡張され，ターゲット領域の訓練データ[MATH]は[MATH]という3倍の長さのベクトルに拡張される．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[i:159, score:0.30725] 単語[MATH]についてソース領域[MATH]からターゲット領域[MATH]への領域適応の実験について説明する．
[i:168, score:0.78011] (1)ソース領域のラベル付きデータのみを用いる手法（ターゲット領域の15個のラベル付きデータの重みを0とする手法）(S-Only)，(2)ターゲット領域からランダムに取り出した15個のラベル付きデータのみを用いる手法（ソース領域のラベル付きデータの重みを0とする手法）(T-Only)，(3)ソース領域のラベル付きデータとターゲット領域の15個のラベル付きデータを用いる手法(S+T)，(4) Daum{e}の手法(Daum{e})，(5)本稿で示した簡易手法により算出した確率密度比を用いた共変量シフトによる手法(Cov-Shift)，(6)素性空間拡張法から得られた訓練データに対して，本稿で示した簡易手法により算出した確率密度比を用いた共変量シフトによる手法（提案手法）の計6種類である．
[i:174, score:0.40552] ただし提案手法はDaum{e}よりも高い正解率であり，共変量シフトによる解法の効果が確認できる．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[i:175, score:0.00000] 
-----------------------------------------------------
  [subsection title : 負の転移の有無]
-----------------------------------------------------
  [i:lead, score:0.29207] WSDの領域適応では，対象単語毎に領域適応の問題が生じている．
.....
  [i:187, score:0.43903] 表[REF_tab:funoteni2]において領域適応に対処する3手法（Daum{e}，Cov-Shift，提案手法）を見ると，提案手法は負の転移の有無に関わらずCov-Shiftよりも高い正解率であり，提案手法はCov-Shiftの改良になっていることがわかる．
  [i:191, score:0.48442] また領域適応に対処しない3手法(S-Only, T-Only, S+T)も含めて比較すると，負の転移が生じるケースでは領域適応に対処する3手法（Daum{e}，Cov-Shift，提案手法）の正解率はかなり悪い．
  [i:193, score:0.54370] 共変量シフト下の学習では，負の転移が生じているケースに対しては，ソース領域のデータに0に近い重みを与えられればよいはずである．
-----------------------------------------------------
  [subsection title : 確率密度比の調整]
-----------------------------------------------------
  [i:lead, score:0.13247] 確率密度比を精度良く推定することは困難な問題である．
.....
  [i:198, score:0.16722] 杉山は確率密度比[MATH]に[MATH]([MATH])乗した[MATH]を重みにすることを提案している[CITE]．
  [i:199, score:0.17126] またYamadaはrelative density ratioとして確率密度比を以下の形で求めることを提案してる[CITE]．
  [i:208, score:0.31237] 事例の重要度という自然言語処理的な観点からWSDの領域適応に特化した重みの設定も可能である．
-----------------------------------------------------
  [subsection title :  SVM の利用]
-----------------------------------------------------
  [i:lead, score:0.04600] 本稿では学習アルゴリズムとして最大エントロピー法を用いた．
.....
  [i:210, score:0.39337] 共変量シフトの解法として，重み付き対数尤度を最大化する形では，[MATH]をモデル化するアプローチに限られる．
  [i:211, score:0.45461] しかし共変量シフト下の学習では確率密度比を重みにして期待損失を最小化すれば良いので，損失関数ベースの学習手法が利用できる．
  [i:212, score:0.44846] 例えばヒンジ損失関数に密度比で重みづけすることで共変量シフト下の学習にSVMを利用できる[CITE]．
-----------------------------------------------------
  [subsection title : 教師なし手法への適用]
-----------------------------------------------------
  [i:lead, score:0.46936] 共変量シフト下での学習では訓練データの中にターゲット領域のデータが含まれる必要はない．
.....
  [i:226, score:0.46936] 共変量シフト下での学習では訓練データの中にターゲット領域のデータが含まれる必要はない．
  [i:232, score:0.52297] W-S-Onlyはソース領域の訓練データのみを使った共変量シフト下での学習手法である．
  [i:234, score:0.38120] 確率密度比を用いるW-S-Onlyではソース領域のデータへの重みが小さくなりがちである．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:248, score:0.65607] そして，共変量シフトの標準的な解法である確率密度比を重みにしたパラメータ学習により，WSDの領域適応の解決が図れることを示した．
[i:253, score:0.58074] このような簡易な算出法であってもWSDの領域適応に共変量シフトの解法を利用する効果が高いことが示された．
[i:256, score:0.55012] WSDの領域適応に共変量シフトの解法を利用することは有望であると考えられる．

