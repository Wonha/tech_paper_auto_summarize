楽天データ公開より配布されている商品データから，論文[CITE]を参考に，ワイン，シャンプー，プリンターインク，Tシャツ，キャットフードカテゴリに登録されている商品ページを無作為に20件ずつ，計100件抽出した．
そして，抽出したページをブロック要素タグ，記号を手がかりに文に分割した．
カテゴリ毎に分析対象とした属性を表[REF_attributes]に示す．
これらの属性は論文[CITE]で抽出対象とされたものに以下の修正を加えたものである．
同じ意味を表す属性名を人手で統合した．
誤った属性を人手で削除した．
ブランド名，商品名，メーカー名などの重要な属性が抽出対象となっていなかったので，これらを分析対象として加えた．
続いて，各商品ページのタイトル，商品説明文，販売方法別説明文に含まれる属性値を1名の作業者によりアノテーションした．
アノテーション時には，後述する[REF_dictbuild]節の方法で作成した属性-属性値のリストを提示し，これらと類似する表現をアノテーションするよう依頼した．
また．
アノテーションにあたり作業者に以下の点を指示した．
属性値を[MATH]，任意の語を[MATH]とした時，表現「[MATH]の[MATH]」が属性値として見なせる場合，[MATH]もまた属性値として見なせる場合であっても「[MATH]の[MATH]」を1つの属性値としてアノテーションする．
例えば「フランスのブルゴーニュ産ワインです」という文があった場合，「フランス」，「ブルゴーニュ産」をそれぞれアノテーションするのではなく，「フランスのブルゴーニュ産」をアノテーションする．
記号を挟んで属性値が列挙されている場合は別々にアノテーションする．
例えば，「フランス・ブルゴーニュ産ワインです」という文があった場合，記号「・」で区切り，「フランス」，「ブルゴーニュ産」をそれぞれアノテーションする．
ただし固有名詞（e.g.,「カベルネ・ソーヴィニョン」），数値（e.g.,「3,000 ml」），サイズ（e.g.,「[MATH] cm」），数値の範囲（e.g.,「10〜15cm」）の場合は例外とし，記号があっても区切らない．
括弧の直前，中にある表現が共に属性値と見なせる場合は別々にアノテーションする．
例えば「ブルゴーニュ（フランス）のワインです．
」の場合，「ブルゴーニュ」，「フランス」を個別にアノテーションする．
一方，「シャルドネ（100%）」の場合は，「シャルドネ（100%）」をアノテーションする．
以上の作業により得られた分析対象データの規模を表[REF_attributes]の文数および属性値数列に示す．
カテゴリ毎に文数およびアノテーションされた属性値数に差があることがわかる．
本節では商品の属性値を商品説明文から抽出するシステムについて述べる．
本研究で用いる情報抽出システムは，オンラインショッピングサイト上の商品データの特徴を考慮したものであるため，まず商品データの特徴について整理する．
オンラインショッピングサイト上の商品データの特徴として以下の点が挙げられる．
商品カテゴリ数が多い．
一部の商品ページには表や箇条書きなどの形式で整理された属性情報が含まれている．
一般にオンラインショッピングサイトの商品カテゴリ数は多く，例えば，今回分析対象とした楽天では4万以上のカテゴリが存在する．
そのため，それぞれのカテゴリにおいて学習データを準備することはとてもコストの高い作業となるため現実的ではない．
その一方で，一部の商品ページにおいては，図[REF_semi-structured-data]に挙げたように商品の属性情報が表や箇条書きなどを使って整理されている場合がある．
これら半構造化データはショッピングサイトに出店している店舗ごとにその形式が異なるものの，いくつかのパターンを用いれば，そこから属性-属性値情報をある程度の精度で抽出することができる．
例えば，Shinzatoら[CITE]は簡単な正規表現パターンを適用することで，ワインとシャンプーカテゴリに対して70%程度の精度で属性-属性値辞書が構築できたと報告している．
タスクに内在する研究課題を明らかにするためには，少なくとも2つの方法が考えられる．
1つは複数のシステムを同じデータで実行し，多くのシステムがエラーとなる事例の分析を通してタスクの研究課題を明らかにする方法である．
もう1つはシステムがシンプルでどのような動きになっているかをグラスボックス的に分析できるものを実行し，その結果を基に課題を明らかにする方法である．
今回の商品属性値抽出タスクは，標準的なタグ付きコーパスや属性値抽出のためのソフトウェア等が公開されているわけではないため，多くのシステムを実行させることは現実的ではない．
そこで，今回のエラー分析は2つ目の方法により行った．
具体的には，商品ページに含まれる半構造化データから属性-属性値辞書を自動構築し，この辞書を使った辞書マッチによって商品ページのタイトル，商品説明文，販売方法別説明文から属性値を抽出する．
この辞書マッチに基づくシステムは，辞書に属性値が登録されているか否かで属性値の抽出を行うためエラーの原因の特定が容易である．
このような単純なシステムのエラー分析を行うことで，このタスクに含まれるエラーのタイプおよびその割合が明らかとなり，この結果は複雑なシステムを実装する際も，その素性の設計や重みの調整などに役立つと考えられる．
近年，図[REF_flow-of-ds]に示すようなDistant supervisionに基づく情報抽出手法が多く提案されている[CITE]．
これらはFreebaseやWikipediaのInfoboxなどの人手で整備された辞書を活用してテキストデータに対し自動でアノテーションし，これを訓練データとして抽出規則を学習する．
本手法でFreebaseやWikiepdiaのInfoboxを用いない理由は，これら辞書にはオンラインショッピングで有用となる商品の属性-属性値が記述されていない商品カテゴリが多く，教師データを自動構築する際の辞書データとしては利用できないためである．
本手法は単純なものであるが，これはDistant supervisionにおける初期タグ付きデータ作成部分に相当する（図[REF_flow-of-ds]の破線の部分）．
多くの手法では，この後，固有表現抽出と組み合わせたフィルタリングや，統計量を用いたフィルタリング等の処理を行ってタグ付きコーパスからFalse-positive，False-negativeを減らすように工夫している[CITE]．
そのため，本研究で得られたエラー分析の結果は商品の属性値抽出のみならず，Distant supervisionに基づく一般の情報抽出タスクにおいても，どのようなエラーについて後続のフィルタリング処理で考慮しないといけないのかを示唆する有用な知見になると考えられる．
以下，属性-属性値辞書の構築方法，および辞書に基づく属性値抽出方法について述べる．
属性-属性値辞書の構築はShinzatoらの手法[CITE]に基づいて行った．
この手法は「属性-属性値の抽出」，「同じ意味を持つ属性の集約」の2つの処理からなる．
属性-属性値の抽出前述したように一部の商品ページには表や箇条書きなどの半構造化データが含まれており，辞書の構築にはこれらのデータを利用する．
まずドメイン特有の属性を得るため，正規表現パターン[MATH]TH.*?[MATH].
+?[MATH]/TH[MATH]を使って表のヘッダーから属性を獲得する（[MATH]TH[MATH]は表のヘッダーを表すHTMLタグ）．
獲得された属性のうち「保存方法」「その他」「商品説明」「広告文責」「特徴」「仕様」は適切な属性と見なせないため除く．
続いて属性-属性値の組を抽出するため，以下の正規表現パターンを商品ページに適用し，[ANY]にマッチした表現を[ATTR]に対応する属性の値として抽出する．
[MATH]T(H[MATH]D).
*?[MATH][ATTR][MATH]/T(H[MATH]D)[MATH]TD.*?[MATH][ANY][MATH]/TD[MATH]
[P][ATTR][S][ANY][P]
[P][ATTR][ANY][P]
[ATTR][S][ANY][ATTR][S]
ここで[ATTR]は事前に獲得しておいた属性を表す文字列，[ANY]は任意の文字列，[P]は○，●，◎，□，■，・，☆，★，【，＜，［のいずれかの文字，[S]は：，／，】，＞，］のいずれかの文字を表す．
なおP4において，[ANY]は最初に出現した[ATTR]の値とする．
抽出された属性-属性値の組に対して，それらを表や箇条書きなどの形式で記述した店舗の異なり数を計数する．
この店舗の異なり数を以降では店舗頻度と呼ぶ．
この店舗頻度が高いほど抽出された属性-属性値が正しい関係にあることが報告されており[CITE]，次節で述べる属性値抽出システムでは，店舗頻度を用いて属性値の曖昧性解消を行っている．
同じ意味を持つ属性の集約前述の方法で抽出した属性-属性値には属性の表記に揺れがある．
これは商品データを店舗が記述するための標準的な方法（規則）がないためである．
例えば，「イタリア」「フランス」はワインカテゴリにおいて「生産地」であるが，店舗[MATH]は「生産地」，店舗[MATH]は「生産国」として記述することがある．
そこでShinzatoらは「属性[MATH]が同一の半構造化データに出現しておらず，[MATH]が店舗頻度の高い同一の属性値をとる場合，[MATH]は同義である」という仮説を用いて表記の揺れた属性の認識・集約を行っている．
具体的には，まず，店舗頻度が[MATH]を超える属性-属性値を対象に，同じ属性値を持つ属性のベクトル([MATH], [MATH])を生成する．
そして，属性[MATH], [MATH]が同一の半構造化データに含まれているかどうかチェックし，含まれていなければそれらを同義語と見なす．
[MATH]は[MATH]で求まる値であり，[MATH]は対象カテゴリにおいて半構造化データを提供している店舗数を表す．
[MATH]は店舗頻度の閾値を決定するパラメータであり，本手法では経験的に100としている．
この処理により，例えばワインカテゴリであれば[MATH]=(生産国,生産地), [MATH]=(ぶどう品種,品種)が得られる．
得られた属性のベクトルの集合({[MATH]})を[MATH]で表す．
続いて，属性ベクトルの集合[MATH]の中で類似度の高い属性のベクトル同士をマージする．
例えば，(地域,生産国,生産地)は，(地域,生産国)，(生産国,生産地)をマージすることで得られる．
ベクトル間の類似度はコサイン尺度で求め，マージ処理は類似度の最大値が0.5を下回るまで繰り返し行う．
この閾値0.5は経験的に決定した．
以上の操作を楽天市場のワイン，シャンプー，プリンターインク，Tシャツ，キャットフードカテゴリに登録されている商品データに対して適用した．
獲得された属性-属性値をカテゴリ毎に400件無作為に抽出し，正しい関係になっているかどうかを1人の被験者により評価した．
獲得された属性-属性値の数，および正解率を表[REF_dicteval]に示す．
Tシャツカテゴリで極端に低い精度(43.5%)が得られたが，それ以外はShinzatoらの報告と同程度，もしくはより高い精度が達成できていることがわかる．
最後にワインカテゴリに対して獲得された属性-属性値の例を表[REF_dict]に示す．
括弧（[ ]）内の数字は店舗頻度を表す．
まず入力文を形態素解析し，属性-属性値辞書中の属性値と最長一致した形態素列を対応する属性の値として抽出する．
この時，抽出された属性値からさらに別の属性値を取ることは考えない．
また，誤抽出の影響を少なくするため属性値が数値のみからなる場合は抽出しなかった．
形態素解析器にはJUMAN 7.01を用いた．
一部の表現は複数の属性の値となることがあるため抽出時に曖昧性を解消する必要がある．
例えば「55cm」はTシャツカテゴリの属性「身幅」，「着丈」のどちらの値にもなりえる．
本システムでは店舗頻度が高いほど自動抽出された属性-属性値の信頼性が高いことに注目し，複数の属性が考えられる場合は店舗頻度の高い属性の値として抽出した．
先程の例の場合，(身幅，55cm)の店舗頻度は35，(着丈，55cm)の店舗頻度は7であるため，Tシャツカテゴリでは，表現「55cm」は「身幅」の属性値として常に抽出される．
[REF_corpus]節で述べたデータに対し属性値の抽出を行った時のTrue-positive/False-positive/False-negativeの事例数および精度(Prec.)と再現率(Recall)を表[REF_tpfpfn]に示す．
5カテゴリ中3カテゴリでは，辞書の正解率は80%に近かったにも関わらず，それらを用いて行った自動抽出の精度は50%程度であることがわかる．
以下では，まず，False-positive，False-negativeの事例について分析し，各エラーを除くためにどのような処理・データが必要となるかを検討する．
[REF_chiken]節では，エラー分析を通して得られた知見のうち，Distant supervisionに基づく一般の情報抽出タスクにおいても有用なものについて考える．
False-positiveとなった1,057事例について，以下の項目を順次チェックすることで分類を試みた．
誤った属性-属性値に基づいて属性値が抽出されている
属性値を抽出するべき商品ページでない
商品と関係ないパッセージから属性値が抽出されている
分類の結果を表[REF_checkitems]に示す．
表より誤った辞書エントリに起因する誤抽出が多いことがわかる．
各チェック項目の詳細については[REF_check1]節，[REF_check2]節，[REF_check3]節で述べる．
チェック項目(1)，(2)，(3)をパスした抽出結果は，適切な商品ページの適切なパッセージから適切な属性-属性値に基づいて抽出されたものであるにも関わらず誤抽出と判断されたものである．
そこで，残った事例を調査し，何が原因なのかを検討した．
この結果については[REF_check4]節で述べる．
属性値の抽出は商品ページの半構造化データより構築した辞書に基づいて行っている．
辞書は自動構築しているため，誤った属性-属性値の組も含まれている．
そこでまず，誤った属性-属性値に基づいて抽出された結果であるかどうかを確認した．
この項目に該当する事例数は712であり，False-positive事例の67.4%に相当する．
自明ではあるが，高い精度で辞書を構築することが，辞書ベースの情報抽出システムにおいて重要であることがわかる．
この項目に該当する事例を減らすためには辞書構築の方法を見直す必要がある．
今回は表・箇条書きデータに注目して辞書を構築しているため，辞書構築の精度を改善するためには，商品ページ中のこれら半構造化データの解析をより正確に行う必要があるだろう．
また，表・箇条書き以外の手がかり（例えば語彙統語パターン）を取り入れることも辞書構築の精度向上に有効であると考えられる．
次に人手でチェックするなどして属性-属性値辞書に含まれる誤ったエントリを削除した場合，辞書マッチに基づく抽出システムの精度がどの程度改善されるのかについて確認する．
誤った属性-属性値に基づいて抽出されてしまった事例を除いた後，再度計算したカテゴリ毎の精度を表[REF_estprec]に示す．
表[REF_tpfpfn]および表[REF_estprec]を比べると，平均で精度が45.2%から71.6%に改善されていることがわかる．
この結果から，エントリが全て正しい辞書を用いたとしても3割程度は誤抽出となることがわかる．
楽天では商品ページを商品カテゴリに登録する作業は店舗によって行われており，そこには誤りが含まれている．
そこで誤って分析対象カテゴリに登録された商品ページかどうかを確認した．
誤ったカテゴリに登録されている商品ページは今回のデータセット中に4件あり，そこに含まれるFalse-positive事例数は53件(5.0%)であった．
このような誤りを除くためには，与えられた商品ページが商品カテゴリに該当するものであるかどうかを判定する処理が必要である．
例えば，村上ら[CITE]は辞書に基づく方法で商品ページが正しい商品カテゴリに登録されているかを判定する手法を提案している．
このような手法を用いることで，この項目に該当する事例を減らすことができると考えられる．
商品ページには当該ページで販売している商品以外のことについて記述されることも多い．
例えば，商品ページ閲覧者を店舗サイト内で回遊させるために，当該ページで販売されている商品以外の商品の広告を掲載していたり，検索結果に頻繁に表示されるようキーワードスタッフィングが行われている商品ページがある．
そこで3番目の項目として，当該ページにて販売されている商品に関係ないパッセージから属性値抽出が行われたかどうかを確認した．
結果，99件(9.4%)の事例がこの項目に該当した．
このうち90件は以下のような他の商品へのナビゲーションであった（括弧内はカテゴリ名）．
その他のシャンパン[MATH]＆スパーク＆ワイン関連はコチラをクリック♪※順次追加中！（ワイン）
ミルボン[MATH]一覧はこちら（シャンプー）
色違い”ナチュラル[MATH]”’’ＴＨＥＲＥＡＲＥＷＡＶＥＳＮＡＴ’’クルーネックＴシャツ（Tシャツ）
《チャオ缶国産[MATH]》（キャットフード）
他の商品ページへのリンクが埋め込まれているかどうかの確認や，他の商品へのナビゲーションは複数の商品ページに対して設置されることが多いため，商品ページのテンプレートを認識した結果を利用することで，このような事例は減らせるのではないかと考えられる．
残りの9件はキーワードスタッフィングが行われた領域から抽出されたものであった．
前処理としてキーワードスタッフィングが行われているかどうかを判定することで，これらの事例を削除することが期待できる．
ここまでの項目をパスした抽出結果は，適切な商品ページの適切なパッセージから適切な属性-属性値に基づいて抽出されたものであるが誤抽出となった事例である．
このような誤りは193件(18.2%)あり，これら事例を重複を考慮して分類すると表[REF_error_type_fp]のようになった．
以下エラータイプ毎に事例を列挙するとともに，エラーを除くために必要となる処理・データについて検討する．
人手アノテーションと部分一致人手アノテーションと部分一致している事例が84件あった．
このうち以下の例のように正解とみなしても問題ない事例が37件あった（太字が人手アノテーション，下線が自動抽出結果）．
ドメーヌ・レ・グリフェはボジョレーの南[MATH]に位置する歴史あるドメーヌです。
国内製[MATH]ヘアケア品
薄手のコットン素材[MATH]で着心地抜群。
表記Ｌ[MATH]
これらは「どのような表現を属性値として抽出するか」という属性値の定義と関係している．
定義は抽出結果を利用するアプリケーションに依存する部分であり，アプリケーションによっては上に挙げた抽出結果でも問題ない場合がある．
そのため，これらはFalse-positiveであるが，ほぼ正解と見なしても問題ないと考えられる．
残りの47件中41件はシャンプーの成分に関するものであり，以下の例のように人手アノテーションと部分一致しているものの，これが抽出されても意味をなさないものであった．
２−アルキル−Ｎ−カルボキシメチルヒドロキシエチルイミダゾリニウムベタイン、ラウロイルメチル−Β−アラニン[MATH]ＮＡ液、ヤシ油脂肪酸アミドプロピルベタイン液
このような事例は属性-属性値辞書のカバレージを改善することで減らせると考えられる．
他のエンティティの部分文字列からの抽出次に多かった誤りは他のエンティティの部分文字列から抽出している事例であり40件あった．
これらはエンティティのタイプから組織名やイベント名，型番，ブランド名などの固有表現，ドメイン固有の用語，一般的な名詞句に分類できた．
固有表現の一部から抽出されていた例を示す（太字が固有表現相当の表現）．
フランス[MATH]革命の戦いの舞台にもなった歴史あるシャトー。
また、フランスで最も古いＡＯＣ、ブランケット・ド・リムー[MATH]を産出します。
醸造方法もシャトー・マルゴー[MATH]と同じ手法をとって、セカンドながらも品質は他の特級シャトーに匹敵するほどです。
２０１１年度のトロフィー・リヨン・ボジョレー[MATH]・ヌーヴォーコンクールでは見事金賞を受賞！
１円３個までリピート歓迎ＣＡＮＯＮ（キヤノン）対応の純正互換インクカートリッジＢＣＩ−６ＰＭ（残量表示機能付）（関連商品ＢＣＩ−６ＢＫ[MATH]ＢＣＩ−６ＣＢＣＩ−６ＭＢＣＩ−６ＹＢＣＩ−６ＰＣＢＣＩ−６ＰＭＢＣＩ−６ＲＢＣＩ−６Ｇ）
アメリカンイーグル（ＡＭＥＲＩＣＡＮＥＡＧＬＥ）は、ＡＢＥＲＣＲＯＭＢＩＥ[MATH]＆ＦＩＴＣＨ（アバクロンビー＆フィッチ）と並んで人気のカジュアルブランドで、北米では８００店舗の直営店を持っています。
ブラック[MATH]メタルページ正規ライセンスＴシャツ販売
このような事例は全部で25件あり，前処理として固有表現認識を行い，固有表現の一部からは属性値を抽出しない，等のルールを適用することで事例を減らすことができると考えられる．
ただ，ブランド名等は従来の固有表現タイプではカバーされていないため，従来にはないタイプの固有表現の認識技術が求められる．
次にドメイン固有の用語から抽出していた例を示す．
ボジョレー[MATH]・ヌーヴォー２０１３年（新酒）！
パーマ・デジパー（デジタルパーマ）・縮毛矯正ストレートパーマエアウエーブ・水[MATH]パーマ・フィルムパーマなどパーマのウエーブを長持ちさせたい方に。
このような例は全部で12件であった．
固有表現の場合と同様に，ドメイン毎に専門性の高い用語を抽出するなどし，用語の部分文字列からは属性値を抽出しないなどのルールを設ける必要があると考えられる．
最後に名詞句の一部から抽出されていた事例を示す．
このような事例は以下の3件であった．
２位にルイ・ロデレール・ブリュット、７位にテタンジュ・ブリュットなど大手のシャンパン[MATH]ハウスも名を連ねています。
ジョエル・ファルメ氏が引き継いだころは、栽培した葡萄をシャンパン[MATH]メーカーに売っていましたが、現在は、葡萄の栽培・醸造・瓶詰めまで行うＲＭ（レコルタン・マニピュラン）です。
アメリカ[MATH]各種機関で厳しい環境基準をクリアした分解作用で汚れだけを分解してくれるから髪や頭皮を傷めません。
これらを除くためには名詞句の構造を解析し，主辞以外の部分からは属性値を抽出しない，等の処理が考えられる．
当該商品の属性値の説明とは関係ない記述からの抽出このような事例は37件あった．
以下に例を示す．
スペイン[MATH]のロマネ・コンティで知られるヴェガ・シシリア社がハンガリーで造るワイン。
米国ではアメリカンイーグル、アバクロ、ＧＡＰ[MATH]（ギャップ）は３大アメカジブランドとして、３つとも同じくらいの知名度となっています。
Ｍ，Ｌモデル着用サイズ：Ｍ（モデル身長：１７０ＣＭ，体重：５８ＫＧ，ウエスト：７２ＣＭ，ヒップ：９０ＣＭ，胸囲：８８ＣＭ，肩幅：４４ＣＭ[MATH]，首周り：３７ＣＭ）
成猫体重１ＫＧ[MATH]当り１日約１．
４袋を目安として、１日の給与量を２回以上に分けて与えてください。
レビューで５％[MATH]ＯＦＦクーポン！
上の例からわかるように，ワインはワイナリーに関する記述から，Tシャツはブランドの説明およびモデルの体型に関する記述から，キャットフードはその利用方法やクーポンに関する記述から誤った情報が抽出されている．
このような誤抽出を除くためには，商品ページ内の各文が何について言及しているのかといった文中の主題を認識する必要がある．
属性値の多義性に起因する誤抽出このような事例は33件あった．
この中で最も多かったタイプはサイズに関する属性値であり，16件であった．
以下に例を示す．
着丈５９ＣＭ、身幅４２ＣＭ[MATH]、袖幅１７ＣＭ
５４．
５ＣＭ[MATH]
1つ目の例のように，サイズに関する情報は属性名とともに属性値が記述されることがあるため，属性名に相当する表現と属性値がどのくらい離れた場所に記述されているか，という指標を考慮することで誤りを減らせる可能性がある．
2つ目の例は表のセルに記述されたものであった．
そのため，表形式で記述されたデータの理解も重要な処理と考えられる．
次に多かったタイプは割合に関する表現であった．
このタイプの事例は9件であった．
以下にその例を示す．
ピノノワール７０％、ピノムニエ２０％[MATH]、シャルドネ１０％
粗たん白質：４．
０％以上[MATH]、粗脂肪：０．
１％以上、粗繊維：０．
１％以下、粗灰分：１．
０％以下、水分：９４．
０％以下、エネルギー：約１５ＫＣＡＬ／袋
０．
０５％以上[MATH]
1つ目の例のように混合比が素材と一緒に併記されることがある．
そのため，素材に相当する表現の間に挟まれる割合表現を抽出対象としないことでエラーを減らせると考えられる．
サイズ同様，割合についても2つ目の例のように属性名にあたる表現と併記されることがあるため，属性名との距離を考慮することである程度事例数を減らすことが期待できる．
また割合も表形式のデータで記述されることがあるため，表データの理解は重要であろう．
以下は本来であれば，ワインの属性「タイプ」の値として抽出されるべきであるが，地名として抽出されてしまった例である．
ＮＹタイムズで、ベストシャンパーニュ[MATH]（４０ドル以下）に選ばれました。
モエ・シャンドン・ドンペリニヨンの最高級品、通称「ドンペリ・ゴールド」最高の葡萄を熟成させ生産量が極めて少なく本場フランスと日本でしか手に入れることのできない究極の「幻のシャンパーニュ[MATH]」と呼ばれています。
このような地名に関係した誤りは3件あり，サイズ，割合表現についで多かった．
最初の例は「40ドル以下」，次の例は「幻の」や「フランスと日本でしか手に入れることのできない」という表現から「シャンパーニュ」が「地名」ではなく「タイプ」の意味で使われていることがわかる．
このことから，属性値の周辺の語彙を見ることで多義性解消を行う従来手法で解決できそうである．
しかし従来手法は機械学習に基づくものが多く，教師データを曖昧性のある属性値ごとに作成するのは膨大なコストがかかる．
そのため，教師なし学習に基づく解消方法が求められる．
メトニミーに起因する誤抽出このタイプに該当する事例は5件あり，すべて「ボジョレー」に関するものであった．
以下に例を示す．
本物のボジョレー[MATH]の味わいを感じさせてくれる、自然派！
ボジョレー[MATH]に求める要素をすべて備えていると言っても過言ではありません。
「ボジョレー」はワインの産地の1つであるが，ここでは産地としてではなく，「ボジョレー産のワイン」という意味で用いられている．
上の例は「の味わい」という表現に注目することで「産地」でないことがわかる．
その一方で下の例は文単体では「産地」という理解も可能である．
しかしながら，当該文の直前の文が「彼らのスタイルは飲み心地が良く、フルーティで果実味が豊か。
」であることを考えると「産地」ではないことがわかる．
このタイプのエラー事例を減らすには，ある表現がメトニミーなのかどうかを判定する処理が必要であり，さらに2つ目の例のように一文中の情報では判定できない事例もあるため，文を跨いだ解析が求められる．
形態素解析器の過分割による誤抽出形態素解析器により過分割されたために誤って抽出された事例が1件あった．
以下に示す．
トカイ・フルミント・ドライ・マンデュラス[MATH]［２００６］（オレムス）
マンデュラス(mandulas)とはハンガリー語でアーモンドを意味する語である．
形態素解析器の辞書にマンデュラスが登録されていなかったため，過分割されてしまい誤った属性値が抽出されていた．
しかしながら，マンデュラスのような語が形態素解析器の辞書にあらかじめ登録されていることは期待できないため，あるドメインに関するテキスト集合から自動的に語彙を獲得し，形態素解析器の辞書を動的に拡充する手法（例えば，村脇らの手法[CITE]）が必要であると考えられる．
商品ページ内の誤った情報からの抽出誤った情報が商品ページに記述されており，そこから誤った属性値が抽出されている事例が1件あった．
以下に示す．
アリミノミントシャンプーフローズンクール２２０ＭＬ[MATH]
商品タイトルには1000mlと記述されており，商品画像も1000mlのものであったことから220mlは誤りであることがわかった．
このように抽出元となるテキストの信頼度や，画像データなどのテキスト以外の情報を考慮することも精度の向上に必要である．
False-negativeに該当する事例は全部で831件あった．
分析にあたり，まず，キャットフードカテゴリについては全18件，キャットフード以外のカテゴリからは無作為に50件ずつ選び出した．
そして，以下の条件のいずれかに一致する事例を削除して残った188件について分析を行った．
誤ったカテゴリに登録された商品ページ．
人手アノテーションと部分一致し，かつ正解と見なしても問題ないもの．
分析の結果，False-negative事例は(1)異表記すら辞書に含まれていない，(2)異表記は辞書に含まれている，(3)抽出手法の問題の3種類に分類できた．
本節では各タイプについて述べる．
当該表現だけでなく，その異表記すら辞書に含まれていない事例が100件(53.2%)あった．
表[REF_fn_type]に異表記が辞書に含まれていない属性値のタイプと例を示す．
組織名，地名，割合表現，人名など既存の固有表現のタイプが見てとれる．
そのため，固有表現のタイプと属性の間に変換ルールを設けることで，辞書に含まれていない属性値についても固有表現認識技術を用いることで抽出できる可能性がある．
しかしながら，この操作によってFalse-positiveの数が増えてしまう可能性があることに留意する必要がある．
属性値自身は辞書に含まれていないが，その異表記が辞書に含まれている事例は69件(36.7%)あった．
異表記のタイプ，各タイプの数および例を表[REF_variation]に示す．
空白，中黒，ハイフンの有無や入れ替わり，長音とハイフンの入れ替わり，接辞の有無，翻字の違い，小数点の扱い，送り仮名の有無など，テキスト中と辞書中の表現の柔軟なマッチングを行うことで改善できる事例が多いことがわかる．
その一方で，略語，翻訳，言い換えなど事前の知識獲得処理を必要とする事例も見られる．
辞書に正しい属性-属性値の組が登録されているにも関わらず[REF_system]節で述べた手法の問題により抽出されなかった事例が19件(10.1%)あった．
この中で最も多かったタイプは数値単体からなる属性値であった（13件）．
誤抽出の影響を減らすため数値のみの属性値は抽出しないようにしたことが原因である．
数値に関する抽出手法を洗練することで，このタイプの誤りは減らせると考えられる．
残り6件のうち3件は，辞書エントリとテキストの最長一致による属性値抽出方法が問題となっていた．
具体的には，正解の属性値（例えば，(メーカー，デミコスメティクス)）よりも文字列長の長い誤った属性値（例えば，(メーカー，日華化学株式会社デミコスメティクス)）が先に抽出されてしまい，正しい属性値が抽出されなくなっていた．
文字列長だけではなく，属性-属性値としての正しさも考慮に入れて抽出を行うことで改善できる可能性がある．
残りの3件は属性値に多義性がある場合であった．
属性値抽出を行う際，店舗頻度をもとに多義性解消を行っているが，この処理が誤っていた．
そのため，店舗頻度だけでなく，前後の文脈を考慮するなどして多義性解消を行う必要があると考えられる．
一般にDistant supervisionに基づく情報抽出手法では，FreebaseやWikipediaのInfoboxなどの人手で整備された辞書に登録されているエンティティ（もしくはエンティティの組）がテキストに出現している際，エンティティに紐づいている辞書内の情報（例えば，エンティティのタイプやエンティティ間の関係）を当該テキストに付与することで教師データを自動的に作成する．
例えばDistant supervisionの考え方を一般的な関係抽出タスクに初めて用いたMintzら[CITE]の手法では，まず固有表現抽出器をテキストに対して適用し，任意の文[MATH]に固有表現[MATH]，[MATH]が含まれ，かつFreebaseに[MATH]というレコードが登録されている時，文[MATH]を関係[MATH]の学習データとして利用する．
Distant supervisionに基づく方法で教師データを作成する際，エンティティの誤認識が問題となる．
どのような誤認識のタイプがあるのか，という点で4.1.4節で述べた以下のエラーカテゴリはDistant supervisionに基づく一般の情報抽出においても有用な知見になると考えられる．
他のエンティティの部分文字列からの抽出
形態素解析器の過分割による誤抽出
属性値の多義性に起因する誤抽出
メトニミーに起因する誤抽出
「他のエンティティの部分文字列からの抽出」に関しては，固有表現の認識を事前に行うことで，ある程度の誤認識は減らせるかもしれない．
しかしながら，4.1.4節で述べたように，従来の固有表現抽出で定義されたタイプ以外の表現の認識も求められることから，依然としてこの問題点は考慮する必要がある．
「形態素解析器の過分割による誤抽出」についても，固有表現の認識に失敗する可能性があるため，タグ付け対象となるテキストのドメインに特化した表現の自動獲得手法が求められる．
関係抽出では「文に2つのエンティティが含まれている」という条件が各エンティティの多義性解消の手がかりになると考えられるが，この条件だけで全ての多義性を解消できるとは考えにくい．
また，固有表現抽出のような1つエンティティを対象としたタスクの場合は上述の条件が適用できない．
そのため，「エンティティがどの意味で用いられているのか」を認識することが一般の情報抽出においても重要である．
このことから，「属性値の多義性に起因する誤抽出」および「メトニミーに起因する誤抽出」で列挙した事例については，商品属性値抽出タスクに限らず，一般の情報抽出においても考慮する必要があるだろう．
エンティティの誤認識以外には，エンティティが出現しているにも関わらず認識されないFalse-negativeの問題がある．
この問題のうち，異表記が辞書に含まれているエンティティについては[REF_containedSpellingVariation]節で得られた結果が役立つと考えられる．
この結果は，辞書中とテキスト中の表現のマッチングを行う際，どのような「ずれ」について考慮しなければならないか，を検討する1つの知見になりえる．
楽天データ公開より配布されている商品データから，論文[CITE]を参考に，ワイン，シャンプー，プリンターインク，Tシャツ，キャットフードカテゴリに登録されている商品ページを無作為に20件ずつ，計100件抽出した．
そして，抽出したページをブロック要素タグ，記号を手がかりに文に分割した．
カテゴリ毎に分析対象とした属性を表[REF_attributes]に示す．
これらの属性は論文[CITE]で抽出対象とされたものに以下の修正を加えたものである．
同じ意味を表す属性名を人手で統合した．
誤った属性を人手で削除した．
ブランド名，商品名，メーカー名などの重要な属性が抽出対象となっていなかったので，これらを分析対象として加えた．
続いて，各商品ページのタイトル，商品説明文，販売方法別説明文に含まれる属性値を1名の作業者によりアノテーションした．
アノテーション時には，後述する[REF_dictbuild]節の方法で作成した属性-属性値のリストを提示し，これらと類似する表現をアノテーションするよう依頼した．
また．
アノテーションにあたり作業者に以下の点を指示した．
属性値を[MATH]，任意の語を[MATH]とした時，表現「[MATH]の[MATH]」が属性値として見なせる場合，[MATH]もまた属性値として見なせる場合であっても「[MATH]の[MATH]」を1つの属性値としてアノテーションする．
例えば「フランスのブルゴーニュ産ワインです」という文があった場合，「フランス」，「ブルゴーニュ産」をそれぞれアノテーションするのではなく，「フランスのブルゴーニュ産」をアノテーションする．
記号を挟んで属性値が列挙されている場合は別々にアノテーションする．
例えば，「フランス・ブルゴーニュ産ワインです」という文があった場合，記号「・」で区切り，「フランス」，「ブルゴーニュ産」をそれぞれアノテーションする．
ただし固有名詞（e.g.,「カベルネ・ソーヴィニョン」），数値（e.g.,「3,000 ml」），サイズ（e.g.,「[MATH] cm」），数値の範囲（e.g.,「10〜15cm」）の場合は例外とし，記号があっても区切らない．
括弧の直前，中にある表現が共に属性値と見なせる場合は別々にアノテーションする．
例えば「ブルゴーニュ（フランス）のワインです．
」の場合，「ブルゴーニュ」，「フランス」を個別にアノテーションする．
一方，「シャルドネ（100%）」の場合は，「シャルドネ（100%）」をアノテーションする．
以上の作業により得られた分析対象データの規模を表[REF_attributes]の文数および属性値数列に示す．
カテゴリ毎に文数およびアノテーションされた属性値数に差があることがわかる．
本節では商品の属性値を商品説明文から抽出するシステムについて述べる．
本研究で用いる情報抽出システムは，オンラインショッピングサイト上の商品データの特徴を考慮したものであるため，まず商品データの特徴について整理する．
オンラインショッピングサイト上の商品データの特徴として以下の点が挙げられる．
商品カテゴリ数が多い．
一部の商品ページには表や箇条書きなどの形式で整理された属性情報が含まれている．
一般にオンラインショッピングサイトの商品カテゴリ数は多く，例えば，今回分析対象とした楽天では4万以上のカテゴリが存在する．
そのため，それぞれのカテゴリにおいて学習データを準備することはとてもコストの高い作業となるため現実的ではない．
その一方で，一部の商品ページにおいては，図[REF_semi-structured-data]に挙げたように商品の属性情報が表や箇条書きなどを使って整理されている場合がある．
これら半構造化データはショッピングサイトに出店している店舗ごとにその形式が異なるものの，いくつかのパターンを用いれば，そこから属性-属性値情報をある程度の精度で抽出することができる．
例えば，Shinzatoら[CITE]は簡単な正規表現パターンを適用することで，ワインとシャンプーカテゴリに対して70%程度の精度で属性-属性値辞書が構築できたと報告している．
タスクに内在する研究課題を明らかにするためには，少なくとも2つの方法が考えられる．
1つは複数のシステムを同じデータで実行し，多くのシステムがエラーとなる事例の分析を通してタスクの研究課題を明らかにする方法である．
もう1つはシステムがシンプルでどのような動きになっているかをグラスボックス的に分析できるものを実行し，その結果を基に課題を明らかにする方法である．
今回の商品属性値抽出タスクは，標準的なタグ付きコーパスや属性値抽出のためのソフトウェア等が公開されているわけではないため，多くのシステムを実行させることは現実的ではない．
そこで，今回のエラー分析は2つ目の方法により行った．
具体的には，商品ページに含まれる半構造化データから属性-属性値辞書を自動構築し，この辞書を使った辞書マッチによって商品ページのタイトル，商品説明文，販売方法別説明文から属性値を抽出する．
この辞書マッチに基づくシステムは，辞書に属性値が登録されているか否かで属性値の抽出を行うためエラーの原因の特定が容易である．
このような単純なシステムのエラー分析を行うことで，このタスクに含まれるエラーのタイプおよびその割合が明らかとなり，この結果は複雑なシステムを実装する際も，その素性の設計や重みの調整などに役立つと考えられる．
近年，図[REF_flow-of-ds]に示すようなDistant supervisionに基づく情報抽出手法が多く提案されている[CITE]．
これらはFreebaseやWikipediaのInfoboxなどの人手で整備された辞書を活用してテキストデータに対し自動でアノテーションし，これを訓練データとして抽出規則を学習する．
本手法でFreebaseやWikiepdiaのInfoboxを用いない理由は，これら辞書にはオンラインショッピングで有用となる商品の属性-属性値が記述されていない商品カテゴリが多く，教師データを自動構築する際の辞書データとしては利用できないためである．
本手法は単純なものであるが，これはDistant supervisionにおける初期タグ付きデータ作成部分に相当する（図[REF_flow-of-ds]の破線の部分）．
多くの手法では，この後，固有表現抽出と組み合わせたフィルタリングや，統計量を用いたフィルタリング等の処理を行ってタグ付きコーパスからFalse-positive，False-negativeを減らすように工夫している[CITE]．
そのため，本研究で得られたエラー分析の結果は商品の属性値抽出のみならず，Distant supervisionに基づく一般の情報抽出タスクにおいても，どのようなエラーについて後続のフィルタリング処理で考慮しないといけないのかを示唆する有用な知見になると考えられる．
以下，属性-属性値辞書の構築方法，および辞書に基づく属性値抽出方法について述べる．
属性-属性値辞書の構築はShinzatoらの手法[CITE]に基づいて行った．
この手法は「属性-属性値の抽出」，「同じ意味を持つ属性の集約」の2つの処理からなる．
属性-属性値の抽出前述したように一部の商品ページには表や箇条書きなどの半構造化データが含まれており，辞書の構築にはこれらのデータを利用する．
まずドメイン特有の属性を得るため，正規表現パターン[MATH]TH.*?[MATH].
+?[MATH]/TH[MATH]を使って表のヘッダーから属性を獲得する（[MATH]TH[MATH]は表のヘッダーを表すHTMLタグ）．
獲得された属性のうち「保存方法」「その他」「商品説明」「広告文責」「特徴」「仕様」は適切な属性と見なせないため除く．
続いて属性-属性値の組を抽出するため，以下の正規表現パターンを商品ページに適用し，[ANY]にマッチした表現を[ATTR]に対応する属性の値として抽出する．
[MATH]T(H[MATH]D).
*?[MATH][ATTR][MATH]/T(H[MATH]D)[MATH]TD.*?[MATH][ANY][MATH]/TD[MATH]
[P][ATTR][S][ANY][P]
[P][ATTR][ANY][P]
[ATTR][S][ANY][ATTR][S]
ここで[ATTR]は事前に獲得しておいた属性を表す文字列，[ANY]は任意の文字列，[P]は○，●，◎，□，■，・，☆，★，【，＜，［のいずれかの文字，[S]は：，／，】，＞，］のいずれかの文字を表す．
なおP4において，[ANY]は最初に出現した[ATTR]の値とする．
抽出された属性-属性値の組に対して，それらを表や箇条書きなどの形式で記述した店舗の異なり数を計数する．
この店舗の異なり数を以降では店舗頻度と呼ぶ．
この店舗頻度が高いほど抽出された属性-属性値が正しい関係にあることが報告されており[CITE]，次節で述べる属性値抽出システムでは，店舗頻度を用いて属性値の曖昧性解消を行っている．
同じ意味を持つ属性の集約前述の方法で抽出した属性-属性値には属性の表記に揺れがある．
これは商品データを店舗が記述するための標準的な方法（規則）がないためである．
例えば，「イタリア」「フランス」はワインカテゴリにおいて「生産地」であるが，店舗[MATH]は「生産地」，店舗[MATH]は「生産国」として記述することがある．
そこでShinzatoらは「属性[MATH]が同一の半構造化データに出現しておらず，[MATH]が店舗頻度の高い同一の属性値をとる場合，[MATH]は同義である」という仮説を用いて表記の揺れた属性の認識・集約を行っている．
具体的には，まず，店舗頻度が[MATH]を超える属性-属性値を対象に，同じ属性値を持つ属性のベクトル([MATH], [MATH])を生成する．
そして，属性[MATH], [MATH]が同一の半構造化データに含まれているかどうかチェックし，含まれていなければそれらを同義語と見なす．
[MATH]は[MATH]で求まる値であり，[MATH]は対象カテゴリにおいて半構造化データを提供している店舗数を表す．
[MATH]は店舗頻度の閾値を決定するパラメータであり，本手法では経験的に100としている．
この処理により，例えばワインカテゴリであれば[MATH]=(生産国,生産地), [MATH]=(ぶどう品種,品種)が得られる．
得られた属性のベクトルの集合({[MATH]})を[MATH]で表す．
続いて，属性ベクトルの集合[MATH]の中で類似度の高い属性のベクトル同士をマージする．
例えば，(地域,生産国,生産地)は，(地域,生産国)，(生産国,生産地)をマージすることで得られる．
ベクトル間の類似度はコサイン尺度で求め，マージ処理は類似度の最大値が0.5を下回るまで繰り返し行う．
この閾値0.5は経験的に決定した．
以上の操作を楽天市場のワイン，シャンプー，プリンターインク，Tシャツ，キャットフードカテゴリに登録されている商品データに対して適用した．
獲得された属性-属性値をカテゴリ毎に400件無作為に抽出し，正しい関係になっているかどうかを1人の被験者により評価した．
獲得された属性-属性値の数，および正解率を表[REF_dicteval]に示す．
Tシャツカテゴリで極端に低い精度(43.5%)が得られたが，それ以外はShinzatoらの報告と同程度，もしくはより高い精度が達成できていることがわかる．
最後にワインカテゴリに対して獲得された属性-属性値の例を表[REF_dict]に示す．
括弧（[ ]）内の数字は店舗頻度を表す．
まず入力文を形態素解析し，属性-属性値辞書中の属性値と最長一致した形態素列を対応する属性の値として抽出する．
この時，抽出された属性値からさらに別の属性値を取ることは考えない．
また，誤抽出の影響を少なくするため属性値が数値のみからなる場合は抽出しなかった．
形態素解析器にはJUMAN 7.01を用いた．
一部の表現は複数の属性の値となることがあるため抽出時に曖昧性を解消する必要がある．
例えば「55cm」はTシャツカテゴリの属性「身幅」，「着丈」のどちらの値にもなりえる．
本システムでは店舗頻度が高いほど自動抽出された属性-属性値の信頼性が高いことに注目し，複数の属性が考えられる場合は店舗頻度の高い属性の値として抽出した．
先程の例の場合，(身幅，55cm)の店舗頻度は35，(着丈，55cm)の店舗頻度は7であるため，Tシャツカテゴリでは，表現「55cm」は「身幅」の属性値として常に抽出される．
[REF_corpus]節で述べたデータに対し属性値の抽出を行った時のTrue-positive/False-positive/False-negativeの事例数および精度(Prec.)と再現率(Recall)を表[REF_tpfpfn]に示す．
5カテゴリ中3カテゴリでは，辞書の正解率は80%に近かったにも関わらず，それらを用いて行った自動抽出の精度は50%程度であることがわかる．
以下では，まず，False-positive，False-negativeの事例について分析し，各エラーを除くためにどのような処理・データが必要となるかを検討する．
[REF_chiken]節では，エラー分析を通して得られた知見のうち，Distant supervisionに基づく一般の情報抽出タスクにおいても有用なものについて考える．
False-positiveとなった1,057事例について，以下の項目を順次チェックすることで分類を試みた．
誤った属性-属性値に基づいて属性値が抽出されている
属性値を抽出するべき商品ページでない
商品と関係ないパッセージから属性値が抽出されている
分類の結果を表[REF_checkitems]に示す．
表より誤った辞書エントリに起因する誤抽出が多いことがわかる．
各チェック項目の詳細については[REF_check1]節，[REF_check2]節，[REF_check3]節で述べる．
チェック項目(1)，(2)，(3)をパスした抽出結果は，適切な商品ページの適切なパッセージから適切な属性-属性値に基づいて抽出されたものであるにも関わらず誤抽出と判断されたものである．
そこで，残った事例を調査し，何が原因なのかを検討した．
この結果については[REF_check4]節で述べる．
属性値の抽出は商品ページの半構造化データより構築した辞書に基づいて行っている．
辞書は自動構築しているため，誤った属性-属性値の組も含まれている．
そこでまず，誤った属性-属性値に基づいて抽出された結果であるかどうかを確認した．
この項目に該当する事例数は712であり，False-positive事例の67.4%に相当する．
自明ではあるが，高い精度で辞書を構築することが，辞書ベースの情報抽出システムにおいて重要であることがわかる．
この項目に該当する事例を減らすためには辞書構築の方法を見直す必要がある．
今回は表・箇条書きデータに注目して辞書を構築しているため，辞書構築の精度を改善するためには，商品ページ中のこれら半構造化データの解析をより正確に行う必要があるだろう．
また，表・箇条書き以外の手がかり（例えば語彙統語パターン）を取り入れることも辞書構築の精度向上に有効であると考えられる．
次に人手でチェックするなどして属性-属性値辞書に含まれる誤ったエントリを削除した場合，辞書マッチに基づく抽出システムの精度がどの程度改善されるのかについて確認する．
誤った属性-属性値に基づいて抽出されてしまった事例を除いた後，再度計算したカテゴリ毎の精度を表[REF_estprec]に示す．
表[REF_tpfpfn]および表[REF_estprec]を比べると，平均で精度が45.2%から71.6%に改善されていることがわかる．
この結果から，エントリが全て正しい辞書を用いたとしても3割程度は誤抽出となることがわかる．
楽天では商品ページを商品カテゴリに登録する作業は店舗によって行われており，そこには誤りが含まれている．
そこで誤って分析対象カテゴリに登録された商品ページかどうかを確認した．
誤ったカテゴリに登録されている商品ページは今回のデータセット中に4件あり，そこに含まれるFalse-positive事例数は53件(5.0%)であった．
このような誤りを除くためには，与えられた商品ページが商品カテゴリに該当するものであるかどうかを判定する処理が必要である．
例えば，村上ら[CITE]は辞書に基づく方法で商品ページが正しい商品カテゴリに登録されているかを判定する手法を提案している．
このような手法を用いることで，この項目に該当する事例を減らすことができると考えられる．
商品ページには当該ページで販売している商品以外のことについて記述されることも多い．
例えば，商品ページ閲覧者を店舗サイト内で回遊させるために，当該ページで販売されている商品以外の商品の広告を掲載していたり，検索結果に頻繁に表示されるようキーワードスタッフィングが行われている商品ページがある．
そこで3番目の項目として，当該ページにて販売されている商品に関係ないパッセージから属性値抽出が行われたかどうかを確認した．
結果，99件(9.4%)の事例がこの項目に該当した．
このうち90件は以下のような他の商品へのナビゲーションであった（括弧内はカテゴリ名）．
その他のシャンパン[MATH]＆スパーク＆ワイン関連はコチラをクリック♪※順次追加中！（ワイン）
ミルボン[MATH]一覧はこちら（シャンプー）
色違い”ナチュラル[MATH]”’’ＴＨＥＲＥＡＲＥＷＡＶＥＳＮＡＴ’’クルーネックＴシャツ（Tシャツ）
《チャオ缶国産[MATH]》（キャットフード）
他の商品ページへのリンクが埋め込まれているかどうかの確認や，他の商品へのナビゲーションは複数の商品ページに対して設置されることが多いため，商品ページのテンプレートを認識した結果を利用することで，このような事例は減らせるのではないかと考えられる．
残りの9件はキーワードスタッフィングが行われた領域から抽出されたものであった．
前処理としてキーワードスタッフィングが行われているかどうかを判定することで，これらの事例を削除することが期待できる．
ここまでの項目をパスした抽出結果は，適切な商品ページの適切なパッセージから適切な属性-属性値に基づいて抽出されたものであるが誤抽出となった事例である．
このような誤りは193件(18.2%)あり，これら事例を重複を考慮して分類すると表[REF_error_type_fp]のようになった．
以下エラータイプ毎に事例を列挙するとともに，エラーを除くために必要となる処理・データについて検討する．
人手アノテーションと部分一致人手アノテーションと部分一致している事例が84件あった．
このうち以下の例のように正解とみなしても問題ない事例が37件あった（太字が人手アノテーション，下線が自動抽出結果）．
ドメーヌ・レ・グリフェはボジョレーの南[MATH]に位置する歴史あるドメーヌです。
国内製[MATH]ヘアケア品
薄手のコットン素材[MATH]で着心地抜群。
表記Ｌ[MATH]
これらは「どのような表現を属性値として抽出するか」という属性値の定義と関係している．
定義は抽出結果を利用するアプリケーションに依存する部分であり，アプリケーションによっては上に挙げた抽出結果でも問題ない場合がある．
そのため，これらはFalse-positiveであるが，ほぼ正解と見なしても問題ないと考えられる．
残りの47件中41件はシャンプーの成分に関するものであり，以下の例のように人手アノテーションと部分一致しているものの，これが抽出されても意味をなさないものであった．
２−アルキル−Ｎ−カルボキシメチルヒドロキシエチルイミダゾリニウムベタイン、ラウロイルメチル−Β−アラニン[MATH]ＮＡ液、ヤシ油脂肪酸アミドプロピルベタイン液
このような事例は属性-属性値辞書のカバレージを改善することで減らせると考えられる．
他のエンティティの部分文字列からの抽出次に多かった誤りは他のエンティティの部分文字列から抽出している事例であり40件あった．
これらはエンティティのタイプから組織名やイベント名，型番，ブランド名などの固有表現，ドメイン固有の用語，一般的な名詞句に分類できた．
固有表現の一部から抽出されていた例を示す（太字が固有表現相当の表現）．
フランス[MATH]革命の戦いの舞台にもなった歴史あるシャトー。
また、フランスで最も古いＡＯＣ、ブランケット・ド・リムー[MATH]を産出します。
醸造方法もシャトー・マルゴー[MATH]と同じ手法をとって、セカンドながらも品質は他の特級シャトーに匹敵するほどです。
２０１１年度のトロフィー・リヨン・ボジョレー[MATH]・ヌーヴォーコンクールでは見事金賞を受賞！
１円３個までリピート歓迎ＣＡＮＯＮ（キヤノン）対応の純正互換インクカートリッジＢＣＩ−６ＰＭ（残量表示機能付）（関連商品ＢＣＩ−６ＢＫ[MATH]ＢＣＩ−６ＣＢＣＩ−６ＭＢＣＩ−６ＹＢＣＩ−６ＰＣＢＣＩ−６ＰＭＢＣＩ−６ＲＢＣＩ−６Ｇ）
アメリカンイーグル（ＡＭＥＲＩＣＡＮＥＡＧＬＥ）は、ＡＢＥＲＣＲＯＭＢＩＥ[MATH]＆ＦＩＴＣＨ（アバクロンビー＆フィッチ）と並んで人気のカジュアルブランドで、北米では８００店舗の直営店を持っています。
ブラック[MATH]メタルページ正規ライセンスＴシャツ販売
このような事例は全部で25件あり，前処理として固有表現認識を行い，固有表現の一部からは属性値を抽出しない，等のルールを適用することで事例を減らすことができると考えられる．
ただ，ブランド名等は従来の固有表現タイプではカバーされていないため，従来にはないタイプの固有表現の認識技術が求められる．
次にドメイン固有の用語から抽出していた例を示す．
ボジョレー[MATH]・ヌーヴォー２０１３年（新酒）！
パーマ・デジパー（デジタルパーマ）・縮毛矯正ストレートパーマエアウエーブ・水[MATH]パーマ・フィルムパーマなどパーマのウエーブを長持ちさせたい方に。
このような例は全部で12件であった．
固有表現の場合と同様に，ドメイン毎に専門性の高い用語を抽出するなどし，用語の部分文字列からは属性値を抽出しないなどのルールを設ける必要があると考えられる．
最後に名詞句の一部から抽出されていた事例を示す．
このような事例は以下の3件であった．
２位にルイ・ロデレール・ブリュット、７位にテタンジュ・ブリュットなど大手のシャンパン[MATH]ハウスも名を連ねています。
ジョエル・ファルメ氏が引き継いだころは、栽培した葡萄をシャンパン[MATH]メーカーに売っていましたが、現在は、葡萄の栽培・醸造・瓶詰めまで行うＲＭ（レコルタン・マニピュラン）です。
アメリカ[MATH]各種機関で厳しい環境基準をクリアした分解作用で汚れだけを分解してくれるから髪や頭皮を傷めません。
これらを除くためには名詞句の構造を解析し，主辞以外の部分からは属性値を抽出しない，等の処理が考えられる．
当該商品の属性値の説明とは関係ない記述からの抽出このような事例は37件あった．
以下に例を示す．
スペイン[MATH]のロマネ・コンティで知られるヴェガ・シシリア社がハンガリーで造るワイン。
米国ではアメリカンイーグル、アバクロ、ＧＡＰ[MATH]（ギャップ）は３大アメカジブランドとして、３つとも同じくらいの知名度となっています。
Ｍ，Ｌモデル着用サイズ：Ｍ（モデル身長：１７０ＣＭ，体重：５８ＫＧ，ウエスト：７２ＣＭ，ヒップ：９０ＣＭ，胸囲：８８ＣＭ，肩幅：４４ＣＭ[MATH]，首周り：３７ＣＭ）
成猫体重１ＫＧ[MATH]当り１日約１．
４袋を目安として、１日の給与量を２回以上に分けて与えてください。
レビューで５％[MATH]ＯＦＦクーポン！
上の例からわかるように，ワインはワイナリーに関する記述から，Tシャツはブランドの説明およびモデルの体型に関する記述から，キャットフードはその利用方法やクーポンに関する記述から誤った情報が抽出されている．
このような誤抽出を除くためには，商品ページ内の各文が何について言及しているのかといった文中の主題を認識する必要がある．
属性値の多義性に起因する誤抽出このような事例は33件あった．
この中で最も多かったタイプはサイズに関する属性値であり，16件であった．
以下に例を示す．
着丈５９ＣＭ、身幅４２ＣＭ[MATH]、袖幅１７ＣＭ
５４．
５ＣＭ[MATH]
1つ目の例のように，サイズに関する情報は属性名とともに属性値が記述されることがあるため，属性名に相当する表現と属性値がどのくらい離れた場所に記述されているか，という指標を考慮することで誤りを減らせる可能性がある．
2つ目の例は表のセルに記述されたものであった．
そのため，表形式で記述されたデータの理解も重要な処理と考えられる．
次に多かったタイプは割合に関する表現であった．
このタイプの事例は9件であった．
以下にその例を示す．
ピノノワール７０％、ピノムニエ２０％[MATH]、シャルドネ１０％
粗たん白質：４．
０％以上[MATH]、粗脂肪：０．
１％以上、粗繊維：０．
１％以下、粗灰分：１．
０％以下、水分：９４．
０％以下、エネルギー：約１５ＫＣＡＬ／袋
０．
０５％以上[MATH]
1つ目の例のように混合比が素材と一緒に併記されることがある．
そのため，素材に相当する表現の間に挟まれる割合表現を抽出対象としないことでエラーを減らせると考えられる．
サイズ同様，割合についても2つ目の例のように属性名にあたる表現と併記されることがあるため，属性名との距離を考慮することである程度事例数を減らすことが期待できる．
また割合も表形式のデータで記述されることがあるため，表データの理解は重要であろう．
以下は本来であれば，ワインの属性「タイプ」の値として抽出されるべきであるが，地名として抽出されてしまった例である．
ＮＹタイムズで、ベストシャンパーニュ[MATH]（４０ドル以下）に選ばれました。
モエ・シャンドン・ドンペリニヨンの最高級品、通称「ドンペリ・ゴールド」最高の葡萄を熟成させ生産量が極めて少なく本場フランスと日本でしか手に入れることのできない究極の「幻のシャンパーニュ[MATH]」と呼ばれています。
このような地名に関係した誤りは3件あり，サイズ，割合表現についで多かった．
最初の例は「40ドル以下」，次の例は「幻の」や「フランスと日本でしか手に入れることのできない」という表現から「シャンパーニュ」が「地名」ではなく「タイプ」の意味で使われていることがわかる．
このことから，属性値の周辺の語彙を見ることで多義性解消を行う従来手法で解決できそうである．
しかし従来手法は機械学習に基づくものが多く，教師データを曖昧性のある属性値ごとに作成するのは膨大なコストがかかる．
そのため，教師なし学習に基づく解消方法が求められる．
メトニミーに起因する誤抽出このタイプに該当する事例は5件あり，すべて「ボジョレー」に関するものであった．
以下に例を示す．
本物のボジョレー[MATH]の味わいを感じさせてくれる、自然派！
ボジョレー[MATH]に求める要素をすべて備えていると言っても過言ではありません。
「ボジョレー」はワインの産地の1つであるが，ここでは産地としてではなく，「ボジョレー産のワイン」という意味で用いられている．
上の例は「の味わい」という表現に注目することで「産地」でないことがわかる．
その一方で下の例は文単体では「産地」という理解も可能である．
しかしながら，当該文の直前の文が「彼らのスタイルは飲み心地が良く、フルーティで果実味が豊か。
」であることを考えると「産地」ではないことがわかる．
このタイプのエラー事例を減らすには，ある表現がメトニミーなのかどうかを判定する処理が必要であり，さらに2つ目の例のように一文中の情報では判定できない事例もあるため，文を跨いだ解析が求められる．
形態素解析器の過分割による誤抽出形態素解析器により過分割されたために誤って抽出された事例が1件あった．
以下に示す．
トカイ・フルミント・ドライ・マンデュラス[MATH]［２００６］（オレムス）
マンデュラス(mandulas)とはハンガリー語でアーモンドを意味する語である．
形態素解析器の辞書にマンデュラスが登録されていなかったため，過分割されてしまい誤った属性値が抽出されていた．
しかしながら，マンデュラスのような語が形態素解析器の辞書にあらかじめ登録されていることは期待できないため，あるドメインに関するテキスト集合から自動的に語彙を獲得し，形態素解析器の辞書を動的に拡充する手法（例えば，村脇らの手法[CITE]）が必要であると考えられる．
商品ページ内の誤った情報からの抽出誤った情報が商品ページに記述されており，そこから誤った属性値が抽出されている事例が1件あった．
以下に示す．
アリミノミントシャンプーフローズンクール２２０ＭＬ[MATH]
商品タイトルには1000mlと記述されており，商品画像も1000mlのものであったことから220mlは誤りであることがわかった．
このように抽出元となるテキストの信頼度や，画像データなどのテキスト以外の情報を考慮することも精度の向上に必要である．
False-negativeに該当する事例は全部で831件あった．
分析にあたり，まず，キャットフードカテゴリについては全18件，キャットフード以外のカテゴリからは無作為に50件ずつ選び出した．
そして，以下の条件のいずれかに一致する事例を削除して残った188件について分析を行った．
誤ったカテゴリに登録された商品ページ．
人手アノテーションと部分一致し，かつ正解と見なしても問題ないもの．
分析の結果，False-negative事例は(1)異表記すら辞書に含まれていない，(2)異表記は辞書に含まれている，(3)抽出手法の問題の3種類に分類できた．
本節では各タイプについて述べる．
当該表現だけでなく，その異表記すら辞書に含まれていない事例が100件(53.2%)あった．
表[REF_fn_type]に異表記が辞書に含まれていない属性値のタイプと例を示す．
組織名，地名，割合表現，人名など既存の固有表現のタイプが見てとれる．
そのため，固有表現のタイプと属性の間に変換ルールを設けることで，辞書に含まれていない属性値についても固有表現認識技術を用いることで抽出できる可能性がある．
しかしながら，この操作によってFalse-positiveの数が増えてしまう可能性があることに留意する必要がある．
属性値自身は辞書に含まれていないが，その異表記が辞書に含まれている事例は69件(36.7%)あった．
異表記のタイプ，各タイプの数および例を表[REF_variation]に示す．
空白，中黒，ハイフンの有無や入れ替わり，長音とハイフンの入れ替わり，接辞の有無，翻字の違い，小数点の扱い，送り仮名の有無など，テキスト中と辞書中の表現の柔軟なマッチングを行うことで改善できる事例が多いことがわかる．
その一方で，略語，翻訳，言い換えなど事前の知識獲得処理を必要とする事例も見られる．
辞書に正しい属性-属性値の組が登録されているにも関わらず[REF_system]節で述べた手法の問題により抽出されなかった事例が19件(10.1%)あった．
この中で最も多かったタイプは数値単体からなる属性値であった（13件）．
誤抽出の影響を減らすため数値のみの属性値は抽出しないようにしたことが原因である．
数値に関する抽出手法を洗練することで，このタイプの誤りは減らせると考えられる．
残り6件のうち3件は，辞書エントリとテキストの最長一致による属性値抽出方法が問題となっていた．
具体的には，正解の属性値（例えば，(メーカー，デミコスメティクス)）よりも文字列長の長い誤った属性値（例えば，(メーカー，日華化学株式会社デミコスメティクス)）が先に抽出されてしまい，正しい属性値が抽出されなくなっていた．
文字列長だけではなく，属性-属性値としての正しさも考慮に入れて抽出を行うことで改善できる可能性がある．
残りの3件は属性値に多義性がある場合であった．
属性値抽出を行う際，店舗頻度をもとに多義性解消を行っているが，この処理が誤っていた．
そのため，店舗頻度だけでなく，前後の文脈を考慮するなどして多義性解消を行う必要があると考えられる．
一般にDistant supervisionに基づく情報抽出手法では，FreebaseやWikipediaのInfoboxなどの人手で整備された辞書に登録されているエンティティ（もしくはエンティティの組）がテキストに出現している際，エンティティに紐づいている辞書内の情報（例えば，エンティティのタイプやエンティティ間の関係）を当該テキストに付与することで教師データを自動的に作成する．
例えばDistant supervisionの考え方を一般的な関係抽出タスクに初めて用いたMintzら[CITE]の手法では，まず固有表現抽出器をテキストに対して適用し，任意の文[MATH]に固有表現[MATH]，[MATH]が含まれ，かつFreebaseに[MATH]というレコードが登録されている時，文[MATH]を関係[MATH]の学習データとして利用する．
Distant supervisionに基づく方法で教師データを作成する際，エンティティの誤認識が問題となる．
どのような誤認識のタイプがあるのか，という点で4.1.4節で述べた以下のエラーカテゴリはDistant supervisionに基づく一般の情報抽出においても有用な知見になると考えられる．
他のエンティティの部分文字列からの抽出
形態素解析器の過分割による誤抽出
属性値の多義性に起因する誤抽出
メトニミーに起因する誤抽出
「他のエンティティの部分文字列からの抽出」に関しては，固有表現の認識を事前に行うことで，ある程度の誤認識は減らせるかもしれない．
しかしながら，4.1.4節で述べたように，従来の固有表現抽出で定義されたタイプ以外の表現の認識も求められることから，依然としてこの問題点は考慮する必要がある．
「形態素解析器の過分割による誤抽出」についても，固有表現の認識に失敗する可能性があるため，タグ付け対象となるテキストのドメインに特化した表現の自動獲得手法が求められる．
関係抽出では「文に2つのエンティティが含まれている」という条件が各エンティティの多義性解消の手がかりになると考えられるが，この条件だけで全ての多義性を解消できるとは考えにくい．
また，固有表現抽出のような1つエンティティを対象としたタスクの場合は上述の条件が適用できない．
そのため，「エンティティがどの意味で用いられているのか」を認識することが一般の情報抽出においても重要である．
このことから，「属性値の多義性に起因する誤抽出」および「メトニミーに起因する誤抽出」で列挙した事例については，商品属性値抽出タスクに限らず，一般の情報抽出においても考慮する必要があるだろう．
エンティティの誤認識以外には，エンティティが出現しているにも関わらず認識されないFalse-negativeの問題がある．
この問題のうち，異表記が辞書に含まれているエンティティについては[REF_containedSpellingVariation]節で得られた結果が役立つと考えられる．
この結果は，辞書中とテキスト中の表現のマッチングを行う際，どのような「ずれ」について考慮しなければならないか，を検討する1つの知見になりえる．
