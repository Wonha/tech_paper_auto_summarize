固有表現抽出とは，テキストに含まれる人名，地名，組織名などの固有表現を抽出するタスクである．
本稿では，表[REF_tbl-irex-tags]に示すとおり，IREX [CITE]で定義される8種の固有表現を抽出対象とし，IOB2方式[CITE]に基づいて17種類のタグを使用する．
例えば，``東京/都/に''という文は次のようにタグ付けされる：
``東京/B-[MATH]LOC[MATH]都/I-[MATH]LOC[MATH]に/O''
このタスクは単語列[MATH]に対して固有表現の種類を表す固有表現タグ列[MATH]を付与する系列ラベリング問題として考えることができる．
近年，系列ラベリング問題ではCRF[CITE]などの識別モデルが成功を収めている．
本稿ではlinear-chain CRFを利用し，固有表現タグ列の事後確率を以下の式で算出する．
P(T|W) & = \frac{1}{Z(W)} \exp\left_{i=1}^{n} \left( \sum_{a} \lambda_{a} \cdot f_{a}(t_i,w_i) + \sum_{b} \lambda_{b} \cdot f_{b}(t_{i-1},t_{i}) \right) \right
Z(W) & = \sum_{T} \exp\left_{i=1}^{n} \left( \sum_{a} \lambda_{a} \cdot f_{a}(t_i,w_i) + \sum_{b} \lambda_{b} \cdot f_{b}(t_{i-1},t_{i}) \right) \right
[MATH]と[MATH]は位置[MATH]に置ける単語（周辺単語を含む）と固有表現タグ，[MATH]，[MATH]は当該単語及び固有表現タグがある条件を満たす時に1となる素性関数である．
[MATH]，[MATH]は素性関数の重みであり，正解データから推定される．
[MATH]は正規化項である．
([REF_eqn-sentence-prob])式を最大化するタグ列が最尤タグ列であり，Viterbiアルゴリズムを利用して求められる．

([REF_eqn-sentence-prob])式から，文全体の事後確率をタグ列全体の信頼度として利用することは自然であり，従来の能動学習では，通常，文全体の事後確率からデータ選択のための信頼度を算出していた．
本稿では，文ではなくタグ単位の事後確率に着目し，この値をタグ自体の信頼度とみなす．
そしてタグ信頼度の値を利用して解析誤りであるタグを自動的に判定する．
図[REF_fig-confidence-measure]はタグ信頼度計算の模式図である．
単語[MATH]のタグ候補[MATH]についての信頼度は，次式のように計算される．
ここで[MATH]はタグ候補[MATH]を通る全てのタグ列の事後確率を総和したものであり，周辺確率(marginal probability)とも呼ばれる．
なお，[MATH]は表[REF_tbl-irex-tags]に示す固有表現タグの全種類に対応するものであり，本稿では[MATH]である．
タグ候補の信頼度は，前向きおよび後向きアルゴリズム[CITE]により以下のように効率的に算出することができる．
ここで
\alpha_{i,j} & = \sum_{k} \left_{i-1,k} \cdot\exp\left( \sum_{a} \lambda_{a} \cdot f_{a}(t_i,w_i) + \sum_{b} \lambda_{b} \cdot f_{b}(t_{i-1},t_{i}) \right) \right
\beta_{i,j} & = \sum_{k} \left_{i+1,k} \cdot\exp\left( \sum_{a} \lambda_{a} \cdot f_{a}(t_{i+1},w_{i+1}) + \sum_{b} \lambda_{b} \cdot f_{b}(t_{i},t_{i+1}) \right) \right
\alpha_{0,j} & = 1
\beta_{n+1,j} & = 1
以上のようにして，文中の各単語に付与されうる全てのタグに関して信頼度が得られる．
リジェクターは，タグ信頼度を参照し，システム出力の解析誤りを自動で検出する．
各単語において，デコーダが出力した最尤タグ[MATH]と信頼度1位タグ[MATH]を参照し，以下のような手順で各固有表現タグが正解か不正解かを判定する．
なお，最尤タグ[MATH]は，([REF_eqn-sentence-prob])式を最大化するタグであり，信頼度1位タグ[MATH]は([REF_eqn-tag-prob])式を最大化するタグである．
最尤タグ[MATH]が信頼度1位タグ[MATH]と不一致ならば，最尤タグ[MATH]を解析誤りとしてリジェクトする
{[[REF_step-reject1]]}でアクセプトされた場合，信頼度1位タグ[MATH]の信頼度[MATH]が閾値[MATH]以下ならば最尤タグ[MATH]を解析誤りとしてリジェクトする
それ以外であれば最尤タグ[MATH]を正解としてアクセプトする
閾値が高ければリジェクトされるタグ数が増え，人手のチェック・修正コストが増加する．
実際の運用では，開発データにてリジェクト・アクセプトの判定誤り率が最小となるような閾値を設定すればよい．
このようにして，タグ信頼度を利用することにより，タグを単位として解析誤りを検出することが可能となる．
タグ単位での誤り検出は能動学習のデータセレクションに有効である．
もし，文中にリジェクトタグが1つでも含まれれば，その文は，現在のモデル（ベースモデル）が確信を持って解析できない，何か新しい事象が存在していることを意味する．
すなわち，このような文を優先的にモデル学習の対象とすることで高い学習効果を期待できる．
そこでここでの能動学習では，文中にリジェクトタグを含むか否かに基づいたデータセレクションを採用する．
また，選別された文について，全てのタグを人手でチェック・修正する必要は無く，リジェクトされたタグのみを対象としてチェック・修正すればよい．
図[REF_fig-active-learning]は本稿で提案する能動学習のスキームを示したものである．
固有表現抽出デコーダでは，初期正解データから学習したベースモデルに基づいて最尤タグが出力される．
続いて[REF_sec-confidence-measure]章で示した手順で最尤タグの解析誤りを検出する．
このステップでは，同じベースモデルを利用してタグ信頼度を計算し，その結果を参照してリジェクターで誤り検出を実行する．
データセレクションにて少なくとも1つ以上のリジェクトタグを含む文のみを選別し，検出された誤りタグ（リジェクトタグ）のみを人手でチェック・修正する．
最終的に，人手修正済みデータを初期正解データに追加し，モデルを再学習して更新する．
今回，本稿で提案する能動学習の効果を学習コストの面から評価した．
実験用にブログデータ（45,694文）をWebから収集し，表[REF_tbl-al-corpus]に示すとおり4つのセグメントに分割した．
全データに対して予め人手で正解となる固有表現タグを付与したが，追加平文データに関しては，これらの正解タグは隠しておき，プレーンテキストとして扱う．
そして人手修正を模する際にこの正解タグの情報を利用する．
開発データは[REF_sec-rejector]節で述べたリジェクター判定に利用する閾値を最適化する際に利用した．
学習コストは人手でタグをチェック・修正した単語の割合(WCR: Word Check Rate)とみなした．
WCRは，追加平文データに含まれる総単語数に対するチェックされた単語数の割合であり，次式で表される．
本方式は，リジェクターの閾値に依存して，検出されるリジェクトタグ数が変化するため，閾値を0.1から1.0の範囲で0.1ずつ段階的に変更し，リジェクトタグを含む文のみをデータセレクションで選別して，誤り検出済みデータとした．
それぞれの閾値で得られた誤り検出済みデータのうち，リジェクトタグだけを予め付与していた正解タグと変換した．
この手順は，人手修正を模したものである．
修正後のデータを初期正解データに追加し，ベースモデルを再学習する．
この能動学習と比較するため，タグ単位ではなく文単位の信頼度に基づくデータセレクションによる能動学習と比較した．
文全体の事後確率を信頼度とみなし，低信頼度の文を優先的に選択する能動学習である．
本稿で提案するタグ単位の信頼度に基づく能動学習と異なり，文単位の信頼度の能動学習では，選択された文は全ての単語についてタグのチェックが必要であるとみなされる．
以上，2つの能動学習について，再学習したモデルの精度と学習コスト(WCR)の関係を評価した．
モデルの精度は評価データにおけるF値を利用した．
図[REF_fig-learning-curve]に提案手法でのタグ単位のデータセレクションによる能動学習と，文単位のデータセレクションによる能動学習での学習曲線を示す．
再学習後のモデルの精度がF値で0.76となるために，文単位での能動学習では全データの60%を人手でチェックするコストが必要だが，タグ単位での能動学習では，わずか20%で済む．
言い換えると，タグ単位の能動学習は従来の文単位の能動学習と比較して学習コストを1/3に低減したことを意味する．
また，図[REF_fig-learning-curve]に，追加平文データのタグをまったく修正しないで，モデルを再学習して測定した精度も併せて示す．
ベースモデルではF値0.612であったものが，タグ修正なしの追加平文データをすべて加えた場合はF値0.602に若干低下した．
タグ修正なしデータには誤りタグが多く残存しており，そのためF値が低下したと考えられる．
このように，ベースモデルによるデコード結果を単純に加えただけでは，学習データ量が増えても精度向上には寄与せず，悪化する場合もある．
更にタグ単位の能動学習の効果を調べるために，リジェクトタグに対して実施されたタグ修正の内容を以下の4タイプに分類して内訳を分析した．
No Change:リジェクトタグが修正不要
OtoBI:リジェクトタグがOタグであり，B-又はI-タグに置換
BItoO:リジェクトタグがB-又はI-タグであり，Oタグに置換
BItoBI:リジェクトタグがB-又はI-タグであり，別のB-又はI-タグに置換
表[REF_tbl-rejected-tags]はリジェクター閾値が0.5の時のリジェクトタグについて，上記4タイプの分類の分布を示している．
この閾値は開発データで，リジェクターの判定誤り率が最低となる値である．
表からわかるとおり，No Changeタイプの割合が最も多い．
これはリジェクターが本来修正の必要の無いタグまで過剰にリジェクトしていることを意味する．
この結果は，更新するモデルの精度そのものには悪影響を及ぼさないが，学習コストの面では無駄が含まれていることを示している．
続いてOtoBIタイプが2番目に割合が多く，全体の1/3を占める．
実質的な変化のなかったNo Changeタイプを除き，何かしらの修正が加わった3つのタイプ(OtoBI，BItoO，BItoBI)だけを考慮すると，OtoBIタイプは全修正の約60%を占める．
つまり，ベースモデルでは固有表現として認識できなかったものが，固有表現に修正されたケースが最も多い．
このことは，誤り検出済みデータ中には，初期正解データにはない，新しい固有表現が多く含まれていることを示唆している．
[REF_sec-active-learning]章で述べた通り，実際の修正では約60%がOタグをB-またはI-タグに変更する必要がある．
この事実は固有表現抽出タスクの特徴に由来するものと推察される．
つまり，固有表現抽出タスクでは，全コーパスの殆どはOタグで占められている．
実際，[REF_sec-active-learning]章で我々が整備した追加平文データにおいても，91%がOタグであった．
そのため固有表現の新語が文中に出現すると，ベースモデルではOタグが付与されてしまうことが多い．
このようにOタグが支配的であるという傾向があるならば，OタグではないB-またはI-タグの候補の可能性を考慮することが必要である．
即ち，Oタグがリジェクトされたときに，次に信頼度の高いタグは何かを調べることは意味があると考えられる．
そこで，閾値0.5の時のタグ信頼度が上位2位までのタグについて，その精度を分析したものを表[REF_tbl-second-accuracy]に示す．
信頼度1位のタグ（1位タグ）がアクセプトとされた時，その精度は94%と高い．
一方，1位タグがリジェクトされた時，1位タグの精度はわずか43%であった．
しかし，信頼度2位のタグ（2位タグ）の精度は29%であり，1位タグと2位タグをどちらも考慮すると，いずれかに正解タグが存在する可能性が72%まで高まる．
このことから，上位2位のタグまでを考慮することにより，システム出力のリジェクト箇所を自動的に修正できる可能性があることがわかる．
図[REF_fig-tag-graph]に，閾値0.5で1位タグがリジェクトされる場合は2位タグまで考慮するときのタグの状況を示す．
以後，本稿ではこのラティス構造をタググラフと呼ぶ．
``3丁目の夕日''という映画タイトル（固有物名ART）を1位タグだけでは正しく固有表現として認識できていない．
しかし，2位タグまで考慮すると，正しいタグ列が存在していることがわかる．
もしこの正解のタグ列を自動的にシステムが発見できれば，この正しいタグ列情報を人手修正した正解データと同等のものとして利用できる．
以上の考察をふまえ，新しい学習スキームである半自動自己更新型固有表現抽出(UpdateNER)を提案する．
これは，予め用意する固有表現リストをシードとし，そのシードを利用してタググラフから正解のタグ列を発見する方式であり，シードを利用して新しいインスタンスを取得するブートストラップ型の学習に類似している．
図[REF_fig-update-ner]にUpdateNERの概要を示す．
リジェクターでは，タグ信頼度に基づいてリジェクト／アクセプト判定をした後，適宜2位までのタグを考慮したタググラフを出力する．
ここでリジェクターは[REF_sec-active-learning]章で述べた処理手続きを以下のように変更して動作する．
1位タグの信頼度スコア[MATH]が閾値以上であれば，1位タグ[MATH]のみをアクセプトする．
それ以外は[[REF_step-second-accept]]の処理へ進む
[MATH]が閾値より小さければ，1位タグ[MATH]と更に2位タグ[MATH]をアクセプトする
後続のデータセレクションでは，2位までのタグ候補を有するタググラフ構造を持つ文を抽出する．
そして，コンテキスト抽出にて以下の手順で正解タグ列が存在するかを調べ，該当するタグ列が存在すればそのタグ列を抽出する．
タググラフ内で最長となる固有表現が成立するタグ列を選択する
該固有表現が別途準備するシードリストである固有表現リストに存在していれば文全体のタグ列を正解タグ列として抽出する
ステップ[[REF_step-longest-match]]では，タググラフの中から最も有望と思われるタグ列を選ぶことを意図して，最長となる固有表現が成立するルートを選択する．
例えば，図[REF_fig-tag-graph]で示すタググラフの場合，``3''，``丁目''，``の''，``夕日''の4単語が2位タグまでの候補を有しているため，16通りのタグ列が存在する．
例えば，``B I I I''，``B I I O''，``B I O O''，``O O O I''，``O O O O''などである．
しかし，ここでは``B I I I''のタグ列で最長の固有表現（``3丁目の夕日''で固有物名ART）が構成できるため，このタグ列を選択する．
他の部分文字列からなる固有表現，例えば，``3''，``3丁目''，``3丁目の''でいずれも固有物名ARTとなるようなタグ列は全て無視される．
ステップ[[REF_step-seed-comparison]]では，ステップ[[REF_step-longest-match]]で選択した有望なタグ列が本当に正解であるとみなしてよいかを判定する．
タグ列の確からしさを判定するための手がかりが必要となるので，ここではシードとなる固有表現リストを準備し，表記と対応する固有表現タイプを記載しておく．
このリストは，人手で必要な固有表現を登録しても良いし，辞書のような外部DBを利用して自動的に構築しても良い．
もし同じ固有表現がステップ[[REF_step-longest-match]]で選択されたタグ列および固有表現リストに存在していれば，このタグ列は正解であると判断されて正解データとして抽出される．
そして，このようにして抽出されたデータを初期正解データに追加し，モデルを再学習する．
以上のようにUpdateNERでは，シードを与えるだけで学習データの収集・構築を実行できるため，日々増大する固有表現にモデルを追随させることが可能となる枠組みを備えている．
UpdateNERで1週間分のブログテキストからどの程度効果的にモデル更新ができるか評価した．
表[REF_tbl-update-corpus]に実験でのデータ内訳を示す．
モデルの性能評価を行う評価データは2006年12月のブログを利用する．
また，ベースモデルの学習に利用する初期正解データは評価データより半年以上古いものである．
そのため，評価データにはベースモデルでは未知の固有表現が存在することが予想される．
評価データと同時期の2006年12月から1週間分のブログを収集して追加平文データとし，ここからシードを使ってブートストラップ的に正解データを収集する．
なお，評価データのうち，追加平文データと重複するものは予め削除してある．
リジェクターの閾値を0.5に設定し，追加平文データから2位までのタググラフを含む文を選別した．
シードとなる固有表現リストは日本語Wikipediaのエントリから自動的に収集した．
Wikipediaには，世間で注目される人や固有物が次々とエントリに登場するため，話題語や新語を獲得する上では貴重な言語資源であると言える．
本実験では，Wikipediaの記事タイトルを表記とし，固有表現タイプは各記事のカテゴリー情報から予め設定したルールにより自動的に推定した．
最終的に104,296エントリの固有表現リストを得た．
UpdateNERではこのシードを利用して，ブログ記事からシードの固有表現を含むタグ列を自動的に探索する．
もし同じ固有表現を発見したら，そのタグ列を正解データとして抽出する．
このようにして自動修正したデータを初期正解データに追加し，モデルの再学習を行う．
なお，タググラフ探索時には，5.1節で述べた最長固有表現列を採用したが，異なるタイプの固有表現列に展開可能な場合は，複数の候補を別の文として扱い，追加データとした．
今回，比較のために，シードそのものの効果を調査した．
ここでは，シードと同じ単語列を文中に発見したら必ず固有表現と認識するような固有表現抽出システムを想定する．
なお他の単語列の部分はベースモデルに基づいて確率的に固有表現を抽出する．
このシステムは，ベースモデルの他に，ユーザが固有表現として認識したいリストをユーザ辞書（シード）として装備したシステムと捉えることができるため，以後，ユーザ辞書システム(user dic.)と呼ぶ．
更新後のモデルの精度を再現率(rec.)と適合率(prec.)で評価した．
実験の結果，のべ2,100文が追加データとして抽出された．
このデータのうち，6,125タグが誤りと推定されたリジェクトタグで，その中で2,038個は信頼度2位のタグが採用された．
タググラフ付きデータが73,563文あったことを考えると，得られた文数は少ない．
表[REF_tbl-update-results]に，人名(PSN)，地名(LOC)，組織名(ORG)，固有物名(ART)での解析精度について，ベースモデル，ユーザ辞書システム(user dic.)，UpdateNERの結果をそれぞれ示す．
シードをユーザ辞書として扱う場合，再現率は向上するが，適合率は殆ど変化しないか，むしろARTでは0.667から0.620へと低下している．
これはユーザ辞書を単に追加するだけでは固有表現抽出システムの性能を向上するには十分ではないことを示唆している．
ユーザ辞書の枠組みでは，周囲のコンテキストを利用せず単に同一の単語列（表記）を発見すれば一意に固有表現と認定してしまうため，過剰に固有表現を抽出する危険があるからである．
一方，UpdateNERでは再現率と適合率ともに向上している．
例えば，ARTでは再現率が0.321から0.370，適合率が0.667から0.698へと向上している．
この結果から，シードに存在する固有表現だけでなく，その固有表現の周囲の文全体のタグ列の情報がモデルの再学習には必須であると解釈できる．
UpdateNERでは，シードの固有表現が出現する文全体でのタグ列，即ち，固有表現とそのコンテキストのうち，有望で確からしいものを自動的に発見して抽出すると言う点で優れている．
シードを準備するには多少の人手コストが必要ではあるが，そのコストは正解データそのものを作成するコストと比較すれば極めて小さい．
そのため，このUpdateNERの学習スキームは，実際に固有表現抽出システムを運用する場面においては学習コストを抑える1つの有望な手法であると考える．
表[REF_tbl-update-results]で示す通り，ユーザ辞書システムもUpdateNERもORGに対しては効果が見られなかった．
これはシードに含まれる固有表現の分布によるものと考えられる．
Wikipediaから自動作成したシードでは，PSNの固有表現が74%と最も多かった．
一方ORGはわずか11%しか存在せず，UpdateNERではORGについての正解データを抽出する機会が十分になかったものと考えられる．
また，同じ表記でもORGとPSNの曖昧性が生じるケースはもともと多いため，PSNが支配的なシードを利用したUpdateNERではORGをPSNに過剰に学習してしまっている可能性もある．
今後，シードの分布とその学習効果への影響は検討を進めたい．
なお，UpdateNERでは，初期正解データへの追加データには誤りが含まれる可能性があることを指摘しておく．
実験では，追加したデータにどの程度の誤りが含まれていたかは調査できていない．
ただし，第[REF_sec-active-learning]章の実験では誤りタグを含むデータを追加して再学習することは精度を若干低下させることが示されていることと，本実験において精度の低下があまり見られないことを考え合わせると，本手法で追加するデータには，モデルの性能に悪影響を与えるような誤りはほとんど含まれないと推察される．
従来の機械学習の手法と比較して，UpdateNERの一番の特徴は1位タグが信頼できない時に2位タグまで考慮する点にある．
これにより特に固有表現抽出タスクのようにベースモデルではOタグであると認識されたとき，次点の候補が何であるかを考慮することが可能となった．
しかしUpdateNERには，2つの大きな制約がある．
1つは2位タグまでに正解が存在しなければ自動的に正解データとして抽出することができない，という点である．
もう1つはその固有表現がシードにも存在していなければならない，という点である．
これらの2つの制約があるため，UpdateNERが自動的に収集・修正できる正解データの範囲は狭いと考えられる．
この弱点を克服するには，実運用にてUpdateNERとタグ単位でのデータセレクションによる能動学習を組み合わせる手法が有望であると考えている．
能動学習の場合，2位までに正解が存在しなければならないという制約はないため，単純に解析誤りを人手で優先的に修正して学習対象とすることが可能である．
即ち，能動学習ではベースモデルが解析誤りをするデータ全般を学習対象とすることとなり，その学習範囲はUpdateNERよりも広い．
そのため，能動学習ではベースモデルの精度を底上げするような学習に向いていると考えられる．
一方，UpdateNERは日々増大する膨大なテキストから半自動で正解データを収集できるという利点があり，新語への追随学習には向いていると言える．
そこで，例えば，短期的にはUpdateNERで毎週モデルの新語追随学習を実行し，中期的には1ヵ月或いは半年といった間隔で能動学習を行ってベースモデルの底上げをする，というような運用形態が考えられる．
今後，実際のシステム運用上での本手法の効果について，評価を実施したい．
