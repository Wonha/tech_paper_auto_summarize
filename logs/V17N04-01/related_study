関連研究
\label{sec-related-works}

能動学習は固有表現抽出タスクへの適応
\cite{shen-EtAl:2004:ACL,laws-schutze:2008:PAPERS}に限らず，様々な自然
言語処理タスクへの適応が研究されており，品詞タグ付け
\cite{argamonengelson99committeebased}，テキスト分類
\cite{Lewis94heterogeneousuncertainty}，構文解析
\cite{Hwa:ActiveLearning2000}，単語選択での曖昧性解消
\cite{banko_ACL_2001}など数多くの関連研究がある．いずれの場合も信頼度
や情報量といった何かしらの指標に基づいて学習効果の高いデータを選択する
ことが重要であり，その指標の算出やデータセレクションの単位は基本的に文，
もしくは一定の語数以上の単語列であった．今回我々が提案する能動学習では，
モデル出力の信頼度を指標とするが，その算出単位は文単位ではなく，タグ単
位である点が従来研究とは異なる．更にデータセレクションも文単位ではなく，
タグ単位でリジェクト／アクセプトを決定し，リジェクトタグのみを修正箇所
対象として絞っているため，更なる学習コストの削減に繋がった．なお，
\cite{tomanek-hahn:2009:ACLIJCNLP}では，本稿と同様にタグ単位の信頼度に
基づいた能動学習を英語の固有表現抽出タスクで評価しており，本稿と同程度
のコスト削減効果を報告している．今回，我々は更にタグ単位の信頼度を利用
して半自動で誤り修正を行うUpdateNERの提案および評価を実施した点が新し
い．

一方，特に機械学習の分野において，正解データだけでなく膨大な量のプレー
ンテキストを利用する半教師あり学習の研究も進められている．自然言語処理
タスクでは，語義曖昧性解消\cite{Yarowsky:WSD1995}，テキスト分類
\cite{Fujino:SemiSupervised2008}，チャンキング・固有表現抽出
\cite{suzuki-isozaki:2008:ACLMain}などへも適応されている．特に近年は，
Giga Word単位のプレーンテキストも入手可能になってきたため，このデータ
を正解データと組み合わせてモデル学習することにより従来技術の性能限界を
超える可能性が示唆されている．ただし，今回我々がターゲットとしているの
は，日々語彙や話題の変化が激しいブログなどのCGMドメインにおいて，モデ
ルを低コストで再学習するタスクであり，このような状況を反映するような
Giga Word単位のプレーンテキストを入手するのは困難であると考えられる．
そのため，膨大な量のプレーンテキストを利用する半教師あり学習をそのまま
適応することは現実的ではない．

プレーンテキストを利用するという点で半教師あり学習と類似する手法にブー
トストラップ学習の研究がある
\cite{Etzioni2005,pantel-pennacchiotti:2006:COLACL}．これは，少量のシー
ドを準備して，シードと同じカテゴリに属する新しいインスタンスをプレーン
テキストから自動獲得する学習法である．本稿のUpdateNERはシードを準備す
るだけで，データセレクションとその修正・抽出までを自動的に実行するブー
トストラップ学習とみなすことができる．しかし，従来のブートストラップは
新しいインスタンスを獲得して辞書（シソーラス）を構築することを目的とし
ているのに対し，本手法では，固有表現単体ではなく，固有表現を含むタグ列，
即ちコンテキスト全体を獲得している点が異なる．モデルの再学習のためには
固有表現辞書だけではなく，固有表現を含むコンテキストそのものが必要であ
る．UpdateNERではブートストラップ学習を適用して最終的には教師あり学習
の枠組みでモデル更新を実現するという点が新しい．この学習コストはシード
を準備する部分のみのため，能動学習と比較しても極めて低く抑えられるとい
う利点もあり，本手法は有効である．

