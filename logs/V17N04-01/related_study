能動学習は固有表現抽出タスクへの適応[CITE]に限らず，様々な自然言語処理タスクへの適応が研究されており，品詞タグ付け[CITE]，テキスト分類[CITE]，構文解析[CITE]，単語選択での曖昧性解消[CITE]など数多くの関連研究がある．
いずれの場合も信頼度や情報量といった何かしらの指標に基づいて学習効果の高いデータを選択することが重要であり，その指標の算出やデータセレクションの単位は基本的に文，もしくは一定の語数以上の単語列であった．
今回我々が提案する能動学習では，モデル出力の信頼度を指標とするが，その算出単位は文単位ではなく，タグ単位である点が従来研究とは異なる．
更にデータセレクションも文単位ではなく，タグ単位でリジェクト／アクセプトを決定し，リジェクトタグのみを修正箇所対象として絞っているため，更なる学習コストの削減に繋がった．
なお，[CITE]では，本稿と同様にタグ単位の信頼度に基づいた能動学習を英語の固有表現抽出タスクで評価しており，本稿と同程度のコスト削減効果を報告している．
今回，我々は更にタグ単位の信頼度を利用して半自動で誤り修正を行うUpdateNERの提案および評価を実施した点が新しい．
一方，特に機械学習の分野において，正解データだけでなく膨大な量のプレーンテキストを利用する半教師あり学習の研究も進められている．
自然言語処理タスクでは，語義曖昧性解消[CITE]，テキスト分類[CITE]，チャンキング・固有表現抽出[CITE]などへも適応されている．
特に近年は，Giga Word単位のプレーンテキストも入手可能になってきたため，このデータを正解データと組み合わせてモデル学習することにより従来技術の性能限界を超える可能性が示唆されている．
ただし，今回我々がターゲットとしているのは，日々語彙や話題の変化が激しいブログなどのCGMドメインにおいて，モデルを低コストで再学習するタスクであり，このような状況を反映するようなGiga Word単位のプレーンテキストを入手するのは困難であると考えられる．
そのため，膨大な量のプレーンテキストを利用する半教師あり学習をそのまま適応することは現実的ではない．
プレーンテキストを利用するという点で半教師あり学習と類似する手法にブートストラップ学習の研究がある[CITE]．
これは，少量のシードを準備して，シードと同じカテゴリに属する新しいインスタンスをプレーンテキストから自動獲得する学習法である．
本稿のUpdateNERはシードを準備するだけで，データセレクションとその修正・抽出までを自動的に実行するブートストラップ学習とみなすことができる．
しかし，従来のブートストラップは新しいインスタンスを獲得して辞書（シソーラス）を構築することを目的としているのに対し，本手法では，固有表現単体ではなく，固有表現を含むタグ列，即ちコンテキスト全体を獲得している点が異なる．
モデルの再学習のためには固有表現辞書だけではなく，固有表現を含むコンテキストそのものが必要である．
UpdateNERではブートストラップ学習を適用して最終的には教師あり学習の枠組みでモデル更新を実現するという点が新しい．
この学習コストはシードを準備する部分のみのため，能動学習と比較しても極めて低く抑えられるという利点もあり，本手法は有効である．
