================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.29205] 本論文では，日本語文字のクラス分類により得られた文字クラスモデルを用いる新しい単語分割手法を提案する．
[i:3, score:0.31804] したがって，文字クラスモデルを単語分割へ適用した場合，文字モデルよりもさらに頑健な未知語モデルとして機能することが期待できる．
[i:6, score:0.38877] ATR対話データベースを用いて評価実験を行った結果，文字クラスモデルを用いた提案手法の単語分割精度は文字モデルによる精度より高く，特に，文字クラスを予測単位とする可変長[MATH]-gramクラスモデルではオープンテストにおいて再現率96.38%，適合率96.23%の高精度を達成した．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:26, score:0.31758] したがって，より頑健なモデルである文字クラスモデルを単語分割へ適用した場合，未知語に対する頑健性がさらに向上すると考えられる．
[i:27, score:0.40470] 文字とクラスの対応関係を得るためのクラスタリング処理には，クロス・バリデーション法(cross-validation)の適用により求められる平均クロス・エントロピーを言語モデルの評価基準としたクラスタリング法[CITE]を用いる．
[i:28, score:0.32321] 平均クロス・エントロピーを評価基準として求められた単語bigramクラスモデルは，単語bigramモデルよりも予測力という点において優れていることが実験的に示されている[CITE]．

================================================================
[section type  : proposed_method]
[section title : 文字モデルに基づく単語分割法]
================================================================
[i:43, score:0.26715] 単語境界位置の付与された学習データから文字trigramモデルの確率値を推定し，これを用いて単語分割を行う．
[i:58, score:0.22644] 文字trigramモデルを言語モデルとして用いた場合，以上の単語分割モデルにより，入力文に対して最適な単語分割を求めることができる．
[i:61, score:0.33195] もし文字trigramモデルによる単語分割モデルと同様に，文字位置[MATH]の直前が単語境界である(状態1)か否(状態0)かの2つの仮定に対する各々の最尤解のみに関して解探索を行うならば，その探索空間は，図[REF_Fig:viterbi]に示す探索空間と同じとなる．

================================================================
[section type  : proposed_method]
[section title : 日本語文字のクラスタリング]
================================================================
-----------------------------------------------------
  [subsection title : 文字 $n$-gram クラスモデル]
-----------------------------------------------------
  [i:lead, score:0.20498] [MATH]-gramモデルに，クラスという概念を導入したモデルを[MATH]-gramクラスモデル([MATH]-gram class model)と呼ぶ[CITE]．
.....
  [i:63, score:0.36250] ここで，クラスとは[MATH]-gramモデルの予測単位とする文字(あるいは単語)の集合を何らかの基準でクラスタリング(クラス分類)したものを指す．
  [i:65, score:0.30126] 文字クラス数は文字数に比べると少ないものとなるので，文字[MATH]-gramモデルよりも文字[MATH]-gramクラスモデルの方が推定すべきパラメータ数が少ないという利点がある．
  [i:67, score:0.31341] このため，文字[MATH]-gramクラスモデルは，文字[MATH]-gramモデルよりも必要な学習データ量が少なく，たとえ小さな学習データからでも，より信頼性のある確率値を推定することが容易となる．
-----------------------------------------------------
  [subsection title : 文字クラスタリング法]
-----------------------------------------------------
  [i:lead, score:0.11816] クラス分類法には様々なものが提案されている[CITE]．
.....
  [i:78, score:0.36420] 優れた文字クラスモデルを獲得するためには，モデルの予測力を向上させる(すなわちクロス・エントロピーの値を小さくする)文字とクラスの対応関係を発見する必要がある．
  [i:81, score:0.39525] したがって，学習データのエントロピーを評価基準としてクラスタリングの解探索を行う限り，どのような文字の組合せに対しても複数の文字を同一視することで必ず情報の損失が生じるため，文字モデルよりもエントロピーの値が小さい文字クラスモデルは解空間に存在しないこととなる．
  [i:82, score:0.35560] 以上のように，学習データのエントロピーは，クラスタリングの評価基準としては不適切なものであり，得られた文字クラスモデルが文字モデルより優れた言語モデルであることが期待できないという重大な問題が生じる．

================================================================
[section type  : proposed_method]
[section title : 文字クラスモデルに基づく単語分割法]
================================================================
[i:130, score:0.33905] したがって，文字trigramクラスモデルによる単語分割モデルでは，以下のようにクラス連鎖の確率のみを用いて簡単に計算することができる．
[i:132, score:0.32340] 上記の単語分割モデルをみれば分かるように，文字クラスモデルを用いた場合は，文字クラスの連鎖により単語境界を予測するという問題に置き換わる．
[i:133, score:0.38443] 文字trigramクラスモデルを用いた場合も，[MATH]となる状態遷移系列をビタビ・アルゴリズムを用いて求めることで，入力文に対する最適な単語分割を得ることができる(図[REF_Fig:viterbi]参照)．

================================================================
[section type  : experiment_result]
[section title : 評価実験]
================================================================
[i:136, score:0.05555] それぞれのデータの文数，単語数，文字数を表[REF_Tab:datasize]に示す．
-----------------------------------------------------
  [subsection title : 文字クラスモデルのクロス・エントロピー評価]
-----------------------------------------------------
  [i:lead, score:0.28081] 前節の単語分割モデルで用いる文字クラスモデルを作成する．
.....
  [i:138, score:0.36500] したがって，文字trigramクラスモデルや可変長[MATH]-gramクラスモデルの予測力を改善するような文字クラスを求める必要がある．
  [i:156, score:0.36552] 実験により得られた，文字bigramモデルと文字bigramクラスモデルのクロス・エントロピーを表[REF_Tab:CrossEntropy]に示す．
  [i:157, score:0.35792] 本実験において，文字クラスモデルのクロス・エントロピーは文字モデルのものよりも小さく，より予測力の高い言語モデルの獲得に成功している．
-----------------------------------------------------
  [subsection title : 単語分割精度の比較評価]
-----------------------------------------------------
  [i:lead, score:0.38949] 文字クラスタリング実験により得られたクラス関数[MATH]を用いることで，文字trigramクラスモデルや可変長[MATH]-gramクラスモデルを構築することができる．
.....
  [i:167, score:0.38949] 文字クラスタリング実験により得られたクラス関数[MATH]を用いることで，文字trigramクラスモデルや可変長[MATH]-gramクラスモデルを構築することができる．
  [i:168, score:0.38255] ここで，文字クラスタリングでは字種別にグループ化を行ったので，単語分割に用いる文字クラスモデルを作成するときに，クラス関数[MATH]を用いる字種を限定してみることについても試みることとした．
  [i:177, score:0.35397] モデル3, 4, 5は字種クラス(字種全体を一つのクラスとする)を予測単位とすることを試みたモデルであり，それらの中のモデル4とモデル5では文字クラスタリングの結果得られるクラス関数[MATH]を用いる文字を限定している．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:195, score:0.44140] ADDコーパスを用いた評価実験で，クロス・エントロピー評価によるクロス・バリデーション法を適用した文字クラスタリングを行い，モデルのパラメータ数を減少させた上で，優れた予測力を持つ頑健な文字クラスモデルを獲得できることを示した．
[i:196, score:0.32856] また，提案した単語分割モデルにおいて，文字モデルを用いた場合と，文字クラスモデルを用いた場合の単語分割精度の比較を行い，文字クラスモデルによる単語分割モデルの方が未知語を含むデータに対する解析力が優れていることを示した．
[i:198, score:0.34933] また，より多くの文字種を含む大規模コーパスでの文字クラスモデルのクロス・エントロピーおよびパラメータ数の減少度を計測し，その有効性を確認することを予定している．

