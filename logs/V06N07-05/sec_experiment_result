以上で提案した手法を評価するために，ATR対話データベースを用いた評価実験を行った．
それぞれのデータの文数，単語数，文字数を表[REF_Tab:datasize]に示す．
前節の単語分割モデルで用いる文字クラスモデルを作成する．
したがって，文字trigramクラスモデルや可変長[MATH]-gramクラスモデルの予測力を改善するような文字クラスを求める必要がある．
しかし，文字クラスタリング・アルゴリズムの評価基準である平均クロス・エントロピーの計算を考えると，高次のモデルでは，必要な記憶容量と計算時間が大きな問題となる．
そこで，本実験では，クロス・エントロピーの計算は，低次のbigram確率によって計算した．
bigramモデルであれば，高速なクラスタリング処理が可能である．
もし日本語における文字分類の最適解に近い解を得ることができれば，得られたクラス関数[MATH]はどのような次数のモデルに対してもある程度有効であると考えられる．
また，本論文では，日本語文字が明らかに字種によって分類できることから，クラスタリング処理において，字種により規制を設けることを考えた．
たとえば，漢字は漢字同士でグループ化するというように考えることで，文字とクラスの対応関係の変更を考える場合に必要な計算量を少なくすることができる．
これにより，漢字の場合は[MATH]関数の移動先クラスとして漢字のクラスのみを考えることとなり，ひらがなの場合はひらがなのクラスのみとなる．
以上の条件により，文字クラスタリングを行うために，学習データを9個のデータ[MATH]に分割した．
ここで，1個のデータにしか出現しない文字は未知文字とし，字種ごとに未知文字クラスを用意した．
これは，クロス・バリデーション法による平均クロス・エントロピーの計算(9回の評価)において未知文字であった文字をそのまま学習データ全体における未知文字の実例の収集に用いることを意味する．
したがって，クラスタリングの対象となる文字は，2個以上のデータに出現する文字となる．
また，単語分割に用いる言語モデルを獲得することを念頭におくため，単語間に単語境界記号を挿入した分かち書きデータを用いた．
単語境界記号自体はクラスタリングの対象ではないが，その存在により，クロス・エントロピー評価では単語境界(単語間のスペース)まで考慮するようになる．
本実験において，評価データ中の未知文字(クラスタリング対象文字以外)は字種ごとに異なる特別な記号に置き換えてクロス・エントロピーの計算を行った．
未知文字の扱いは文字モデルと文字クラスモデルで共通であるので，未知文字の確率はモデルの比較においては問題とならない．
重要なことは，クラスタリング対象文字のグループ化によって，モデルの予測力がどのように変化するかである．
以上の点から，モデルの状態は，既知文字すべて(もしくは文字クラスすべて)，未知文字クラス(字種ごと)，単語境界，文区切りの各々に対応することとなる．
実験により得られた，文字bigramモデルと文字bigramクラスモデルのクロス・エントロピーを表[REF_Tab:CrossEntropy]に示す．
本実験において，文字クラスモデルのクロス・エントロピーは文字モデルのものよりも小さく，より予測力の高い言語モデルの獲得に成功している．
また，表[REF_Tab:CharClassParameters]に，クラスタリング対象文字数とそれらをクラスタリングした後の文字クラス数を示す．
学習データ中には，1357種類の文字が含まれていたが，約200種類の低頻度文字が未知文字として取り扱われた．
実験の結果，クラス当たりの平均要素(文字)数は1.36文字であり，最大のクラスの所属文字数は12文字であった．
文字クラスタリング実験により得られたクラス関数[MATH]が返す文字集合(文字クラス)を，図[REF_Fig:ExampleCharClass]にいくつか示す．
必ずしもすべての文字クラスが言語直観から納得がいくものではないが，いくつかのノイズと思われる文字を除けば，(特に出現位置の類似という点で)ある程度良い解が得られていることが分かる．
不自然な印象を受ける文字のグループが存在するのは，あくまでbigramクラスモデルの改善における準最適解を求めているからであると考えられる．
本実験では，各文字クラスに属する文字数は少なく，文字クラスタリングによって，それほど極端にパラメータ数が減少するということにはならなかった．
この原因は，今回用いたコーパスの規模が小さく，学習データに含まれる文字の種類が少なかったためであると考えられる．
より多くの文字種をクラスタリングの対象とすれば，モデルのパラメータ数の減少度はさらに大きくなるであろう．
文字クラスタリング実験により得られたクラス関数[MATH]を用いることで，文字trigramクラスモデルや可変長[MATH]-gramクラスモデルを構築することができる．
ここで，文字クラスタリングでは字種別にグループ化を行ったので，単語分割に用いる文字クラスモデルを作成するときに，クラス関数[MATH]を用いる字種を限定してみることについても試みることとした．
もしあまり有効でない文字のグループ化が行われている字種があれば，それらの文字はクラス関数[MATH]を用いず，文字を予測単位として処理すれば，より性能の良いモデルが得られる可能性がある．
また，本論文で提案した文字クラスモデルに基づく単語分割モデルは非常に簡単な構造となっており，いかにクラス連鎖により単語境界の生起を把握するかが単語分割精度の鍵となる．
ここで，字種変化によるヒューリスティクスを考慮した場合，カタカナ，数字，英字はその字種同士の文字間では分かち書きされる可能性がほとんどないと考えられる．
単語分割を行う場合，これらの文字は単にカタカナか数字か英字であるという情報のみでモデル化したほうが良い結果が得られる可能性がある．
そこで，それらの字種に関しては字種全体を一つのクラスとみなして同一視することについても検討することとした．
以上の点から，文字クラスモデルと文字モデルの比較において，表[REF_Tab:ClusteringCondition]の5つのモデルを考え，単語分割実験を行った．
表中には，字種ごとに何を予測単位としてモデル化を行うかを示している．
モデル1は文字モデルであり，モデル2は文字クラスタリングの結果に何も手を加えずに，すべての文字でクラス関数[MATH]を用いた文字クラスモデルである．
モデル3, 4, 5は字種クラス(字種全体を一つのクラスとする)を予測単位とすることを試みたモデルであり，それらの中のモデル4とモデル5では文字クラスタリングの結果得られるクラス関数[MATH]を用いる文字を限定している．
表[REF_Tab:PerformanceTrigram]に，文字trigramモデルと文字trigramクラスモデルに基づく単語分割モデルによる単語分割精度を示す．
単語分割の性能は，再現率(recall)と適合率(precision)により評価する[CITE]．
ここで，Stdをコーパス中の単語数，Sysを本手法で分割された単語数，Mを照合した単語数とすると，再現率は[MATH]，適合率は[MATH]で表される．
本実験では，バックオフ・スムージング[CITE]付きのtrigram確率値を計算した．
表[REF_Tab:PerformanceTrigram]のモデル1とモデル2は文字trigramモデルと文字trigramクラスモデルの精度であるが，オープンテストにおいて文字クラスモデルの精度が上回る結果となっている．
また，モデル1とモデル3およびモデル2とモデル4のオープンテストの結果を比較することで，カタカナ，数字，英字を各々一つのクラスとしたほうが未知語を含むデータに対して，精度が向上していることが分かる．
したがって，字種単位でのグループ化の有効な字種の存在が確認できた．
全体として，オープンテストでは，漢字に関して文字クラスを用いたモデル5の場合が最も高精度であった．
本実験結果より，文字クラスタリングの動機であった漢字のクラスタリングには特に良い解が得られていることが分かる．
また，可変長[MATH]-gramモデル[CITE]と可変長[MATH]-gramクラスモデルの比較に関する単語分割実験も行ったが，trigram同様，クラスモデルの方が高精度であった．
本実験において，可変長[MATH]-gramクラスモデルによる探索空間はtrigramによる場合と同じものとした．
文献[CITE]において，trigramモデルによる探索空間と同じ場合に最も高い精度を達成している可変長[MATH]-gramモデルを用いた場合の結果を表[REF_Tab:PerformancePPMBackOff]に示す．
実験結果から，可変長[MATH]-gramクラスモデルはtrigramクラスモデルよりもさらに高い単語分割精度を達成できることが分かる．
学習データと評価データの組を変更して，可変長[MATH]-gramクラスモデルによる単語分割の再評価を行ったところ，オープンテストで96%〜98%以上のかなりの高精度を達成することを確認した．
パラメータ数の少ない文字クラスモデルでは，本論文で用いたような比較的小規模の学習データからでも信頼のおける確率値を得ることが容易となり，有効な未知語モデルとして機能できることが結論できる．
