日本語や中国語等においては，単語間に空白を入れる習慣がないため，これらの言語の計算機処理では，まず文を単語列に分割する処理が必要となる．
単語分割は日本語処理における最も基本的かつ重要な技術であり，精度・速度ともに高い水準の性能が要求される．
単語分割と品詞付けから成る日本語形態素解析法の多くは，単語辞書の登録語との照合を行い，複数の形態素解析候補がある場合はヒューリスティクス(heuristics)を用いて候補間の順位付けを行うというものである．
しかし，実際に，辞書中にすべての単語を網羅するのは不可能であるため，未知語(辞書未登録語)という重大な問題が生ずる．
また，ヒューリスティクスでは扱うことのできない例外的な言語現象の存在や，例外現象に対処するための規則の複雑化が問題となる．
その結果，一部の規則修正が全体に与える影響を人間が把握することが困難になり，規則の保守・管理に大きな労力を必要とすることとなる．
一方，英語の品詞付けでは，タグ付きコーパスを用いた確率的手法が確立されている[CITE]．
言語表現の出現頻度に基づく確率的言語モデルを用いる方法には，対象領域のテキストからモデルのパラメータを学習する方法が存在するという大きな利点があり，タグ付きコーパスが整備されている領域では，実験的に最も高い精度が報告されている．
英語の正書法は単語間で分かち書きするため，これらの手法は，単語モデル(word-based model)を用いている．
英語の品詞付けは，日本語の単語分割と技術的に似ているため，英語の品詞付け手法の多くは日本語の単語分割にも適用可能となる．
しかし，単語モデルを日本語に適用するためには，いくつかの問題がある．
日本語では，未知語の存在が単語の同定に影響を与える上，分割が曖昧で，異なる長さの多くの分割候補があり，それらの候補を比較する必要がある[CITE]．
このため，単語モデルを用いるためには，分割候補の確率を正規化する必要が生じる．
以上の点から，我々は文字モデル(character-based model)に基づく単語分割法を提案した[CITE]．
文字モデルは，未知語モデルとしても機能するために，学習データに含まれていない単語に対しても対応が可能である．
本論文では，より頑健な単語分割モデルを構築するために，日本語文字のクラスタリング(グループ化)を行うことを考える．
日本語漢字は表意文字であり，一文字が何らかの意味を担っている．
したがって，何らかの基準によりいくつかのグループ(クラス)に分類することが可能である．
文献[CITE]で示されている文字モデルの利点に加え，文字クラスモデルでは，文字モデルよりもさらにモデルのパラメータ数を少なくすることができるという大きな利点がある．
したがって，より頑健なモデルである文字クラスモデルを単語分割へ適用した場合，未知語に対する頑健性がさらに向上すると考えられる．
文字とクラスの対応関係を得るためのクラスタリング処理には，クロス・バリデーション法(cross-validation)の適用により求められる平均クロス・エントロピーを言語モデルの評価基準としたクラスタリング法[CITE]を用いる．
平均クロス・エントロピーを評価基準として求められた単語bigramクラスモデルは，単語bigramモデルよりも予測力という点において優れていることが実験的に示されている[CITE]．
本論文では，この方法を日本語文字のクラスタリングに適用し，文字クラスモデルを構築する．
以下，本論文では，文字クラスモデルに基づく新しい単語分割手法を提案する．
まず，基本となる文字モデルに基づく単語分割モデルについて簡単に説明する．
さらに，類似した文字を自動的にグループ化するクラス分類法について説明し，文字クラスモデルに基づいた単語分割モデルを提案する．
ADD(ATR Dialogue Database)コーパスを用いた評価実験において，文字モデルを用いた場合と，文字クラスモデルを用いた場合の単語分割精度を比較し，提案した手法の評価を行う．
日本語や中国語等においては，単語間に空白を入れる習慣がないため，これらの言語の計算機処理では，まず文を単語列に分割する処理が必要となる．
単語分割は日本語処理における最も基本的かつ重要な技術であり，精度・速度ともに高い水準の性能が要求される．
単語分割と品詞付けから成る日本語形態素解析法の多くは，単語辞書の登録語との照合を行い，複数の形態素解析候補がある場合はヒューリスティクス(heuristics)を用いて候補間の順位付けを行うというものである．
しかし，実際に，辞書中にすべての単語を網羅するのは不可能であるため，未知語(辞書未登録語)という重大な問題が生ずる．
また，ヒューリスティクスでは扱うことのできない例外的な言語現象の存在や，例外現象に対処するための規則の複雑化が問題となる．
その結果，一部の規則修正が全体に与える影響を人間が把握することが困難になり，規則の保守・管理に大きな労力を必要とすることとなる．
一方，英語の品詞付けでは，タグ付きコーパスを用いた確率的手法が確立されている[CITE]．
言語表現の出現頻度に基づく確率的言語モデルを用いる方法には，対象領域のテキストからモデルのパラメータを学習する方法が存在するという大きな利点があり，タグ付きコーパスが整備されている領域では，実験的に最も高い精度が報告されている．
英語の正書法は単語間で分かち書きするため，これらの手法は，単語モデル(word-based model)を用いている．
英語の品詞付けは，日本語の単語分割と技術的に似ているため，英語の品詞付け手法の多くは日本語の単語分割にも適用可能となる．
しかし，単語モデルを日本語に適用するためには，いくつかの問題がある．
日本語では，未知語の存在が単語の同定に影響を与える上，分割が曖昧で，異なる長さの多くの分割候補があり，それらの候補を比較する必要がある[CITE]．
このため，単語モデルを用いるためには，分割候補の確率を正規化する必要が生じる．
以上の点から，我々は文字モデル(character-based model)に基づく単語分割法を提案した[CITE]．
文字モデルは，未知語モデルとしても機能するために，学習データに含まれていない単語に対しても対応が可能である．
本論文では，より頑健な単語分割モデルを構築するために，日本語文字のクラスタリング(グループ化)を行うことを考える．
日本語漢字は表意文字であり，一文字が何らかの意味を担っている．
したがって，何らかの基準によりいくつかのグループ(クラス)に分類することが可能である．
文献[CITE]で示されている文字モデルの利点に加え，文字クラスモデルでは，文字モデルよりもさらにモデルのパラメータ数を少なくすることができるという大きな利点がある．
したがって，より頑健なモデルである文字クラスモデルを単語分割へ適用した場合，未知語に対する頑健性がさらに向上すると考えられる．
文字とクラスの対応関係を得るためのクラスタリング処理には，クロス・バリデーション法(cross-validation)の適用により求められる平均クロス・エントロピーを言語モデルの評価基準としたクラスタリング法[CITE]を用いる．
平均クロス・エントロピーを評価基準として求められた単語bigramクラスモデルは，単語bigramモデルよりも予測力という点において優れていることが実験的に示されている[CITE]．
本論文では，この方法を日本語文字のクラスタリングに適用し，文字クラスモデルを構築する．
以下，本論文では，文字クラスモデルに基づく新しい単語分割手法を提案する．
まず，基本となる文字モデルに基づく単語分割モデルについて簡単に説明する．
さらに，類似した文字を自動的にグループ化するクラス分類法について説明し，文字クラスモデルに基づいた単語分割モデルを提案する．
ADD(ATR Dialogue Database)コーパスを用いた評価実験において，文字モデルを用いた場合と，文字クラスモデルを用いた場合の単語分割精度を比較し，提案した手法の評価を行う．
