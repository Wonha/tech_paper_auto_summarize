また，可変長[MATH]-gramモデル[CITE]と可変長[MATH]-gramクラスモデルの比較に関する単語分割実験も行ったが，trigram同様，クラスモデルの方が高精度であった．本実験において，可変長[MATH]-gramクラスモデルによる探索空間はtrigramによる場合と同じものとした．文献[CITE]において，trigramモデルによる探索空間と同じ場合に最も高い精度を達成している可変長[MATH]-gramモデルを用いた場合の結果を表[REF_Tab:PerformancePPMBackOff]に示す．実験結果から，可変長[MATH]-gramクラスモデルはtrigramクラスモデルよりもさらに高い単語分割精度を達成できることが分かる．学習データと評価データの組を変更して，可変長[MATH]-gramクラスモデルによる単語分割の再評価を行ったところ，オープンテストで96%〜98%以上のかなりの高精度を達成することを確認した．パラメータ数の少ない文字クラスモデルでは，本論文で用いたような比較的小規模の学習データからでも信頼のおける確率値を得ることが容易となり，有効な未知語モデルとして機能できることが結論できる．



本論文では，日本語のような単語間で分かち書きをしない言語のための新しい単語分割モデルを提案した．入力文に対して最適な単語分割を見つけるために，本手法は文字クラスモデルを言語モデルとして用いる．ADDコーパスを用いた評価実験で，クロス・エントロピー評価によるクロス・バリデーション法を適用した文字クラスタリングを行い，モデルのパラメータ数を減少させた上で，優れた予測力を持つ頑健な文字クラスモデルを獲得できることを示した．また，提案した単語分割モデルにおいて，文字モデルを用いた場合と，文字クラスモデルを用いた場合の単語分割精度の比較を行い，文字クラスモデルによる単語分割モデルの方が未知語を含むデータに対する解析力が優れていることを示した．

paragraph score: 1.05087967955107
