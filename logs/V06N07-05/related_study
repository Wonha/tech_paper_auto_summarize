 
 \section{はじめに}

 日本語や中国語等においては，単語間に空白を入れる習慣がないため，
 これらの言語の計算機処理では，まず文を単語列に分割する処理が必要となる．
 単語分割は日本語処理における最も基本的かつ重要な技術であり，
 精度・速度ともに高い水準の性能が要求される．
 単語分割と品詞付けから成る日本語形態素解析法の多くは，
 単語辞書の登録語との照合を行い，複数の形態素解析候補がある場合は
 ヒューリスティクス (heuristics) を用いて
 候補間の順位付けを行うというものである．
 しかし，実際に，辞書中にすべての単語を網羅するのは不可能であるため，
 未知語 (辞書未登録語) という重大な問題が生ずる．
 また，ヒューリスティクスでは扱うことのできない例外的な言語現象の存在や，
 例外現象に対処するための規則の複雑化が問題となる．
 その結果，一部の規則修正が全体に与える影響を人間が把握することが
 困難になり，規則の保守・管理に大きな労力を必要とすることとなる．

 一方，英語の品詞付けでは，タグ付きコーパスを用いた確率的手法が
 確立されている\cite{Church88,Cutting92,Charniak93}．
 言語表現の出現頻度に基づく確率的言語モデルを用いる方法には，
 対象領域のテキストからモデルのパラメータを学習する方法が存在する
 という大きな利点があり，タグ付きコーパスが整備されている領域では，
 実験的に最も高い精度が報告されている．
 英語の正書法は単語間で分かち書きするため，これらの手法は，
 単語モデル (word-based model) を用いている．
 英語の品詞付けは，日本語の単語分割と技術的に似ているため，
 英語の品詞付け手法の多くは日本語の単語分割にも適用可能となる．
 しかし，単語モデルを日本語に適用するためには，いくつかの問題がある．
 日本語では，未知語の存在が単語の同定に影響を与える上，
 分割が曖昧で，異なる長さの多くの分割候補があり，それらの
 候補を比較する必要がある\cite{Yamamoto97}．
 このため，単語モデルを用いるためには，
 分割候補の確率を正規化する必要が生じる．
score of this paragraph is 2
