    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.1}
\usepackage{amsmath}
\usepackage[dvips]{graphicx}
\usepackage{hangcaption_jnlp}

\Volume{15}
\Number{2}
\Month{Apr.}
\Year{2008}
\received{2007}{6}{10}
\revised{2007}{11}{20}
\accepted{2007}{12}{23}

\setcounter{page}{3}

\jtitle{複数の分類スコアを用いたクラス所属確率の推定}
\jauthor{高橋　和子\affiref{KEIAI} \and 高村　大也\affiref{PRECISION} 
	\and 奥村　　学\affiref{PRECISION}}
\jabstract{
文書分類の多くのアプリケーションにおいて，分類器が出力するクラスに確信度すなわちクラス所属確率を付与することは有用で，正確な推定値が必要とされる．これまでに提案された推定方法はいずれも 2 値分類を想定し，推定したいクラスの分類スコア（分類器が出力するスコア）のみを用いている. しかし，文書分類では多値分類が適用されることが多く，その場合は，予測されるクラスはクラスごとに出力された分類スコアの絶対的な大きさではなく相対的な大きさにより決定される. 
したがって，クラス所属確率は，推定したいクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられるため，推定したいクラス以外の分類スコアも用いて推定する必要があると思われる．本稿は，多値分類における任意のクラスについてのクラス所属確率を，複数の分類スコア，特に推定したいクラスと第 1 位のクラスの分類スコアを用いて，ロジスティック回帰により高精度に推定する方法を提案する．提案手法を多値分類に拡張したサポートベクターマシンに適用し，性質の異なる 2 つのデータセットを用いて実験した結果，有効性が示された. また，本稿では，クラス所属確率を推定する別の方法として，各分類スコアを軸として等間隔に区切ってセルを作成する「正解率表」を利用する方法も提案したが，この方法においても複数の分類スコアを用いることは有効であった．提案手法は，分類スコアの組み合わせや分類器の変更に対しても容易に対応できる.
}
\jkeywords{クラス所属確率，ロジスティック回帰，複数の分類スコア，多値分類，\\
	文書分類，正解率表，平滑化}

\etitle{Estimation of Class Membership Probabilities by Using Multiple Classification Scores}
\eauthor{Kazuko Takahashi\affiref{KEIAI}
	\and Hiroya Takamura\affiref{PRECISION} 
	\and Manabu Okumura\affiref{PRECISION}} 
\eabstract{
We propose a method for estimating class membership probabilities of a predicted class in multiclass classification, using scores outputted by a classifier (classification scores), not only for the predicted class but also for other classes in a document classification. Class membership probabilities are important in many applications of document classification, in which multiclass classification is often applied. As a method for estimating class membership probabilities by using multiple scores, we propose two kinds of methods. One is generating an accuracy table with smoothing methods such as the moving average or a moving average with coverage, which indirectly estimates class membership probabilities by referring the accuracy table. The other is applying a logistic regression estimated parameters beforehand, which directly estimate these probabilities. Through experiments on two different datasets with both Support Vector Machines and Naive Bayes classifiers, we show that the use of multiple classification scores is much effective in both methods. We also show that the proposed smoothing method for the accuracy table works quite well, and that the method applying a logistic regression is more stable. Moreover, the estimated class membership probabilities by the proposed method are useful in the detection of the misclassified samples. 
}
\ekeywords{Class membership probability, Logistic regression, 
	Multiple classificaion scores, Multiclass classification, Document classification, 
	Accuracy table, Smoothing}

\headauthor{高橋，高村，奥村}
\headtitle{複数の分類スコアを用いたクラス所属確率の推定}

\affilabel{KEIAI}{敬愛大学国際学部}{Faculty of International Studies, Keiai University}
\affilabel{PRECISION}{東京工業大学精密工学研究所}{Precision and Intelligence Laboratory, Tokyo Institute of Technology}



\begin{document}
\maketitle


\section{序論}\label{sec:hajime}

自然言語処理においては，タグ付けや文書分類をはじめとするさまざまな分類タスクにおいて，分類器が出力するクラスに確信度すなわちクラス所属確率を付与することは有用である．
例えば，自動分類システムがより大きなシステムの一部を構成し，自動分類結果が別のシステムに自動入力されるような場合に，クラス所属確率は重要な役割を果たす．
この例として，ブログ記事に対してさまざまな観点から付けられたタグ（複数）をユーザに表示するシステムにおいて，タグを自動的に付与する際に，クラス所属確率が閾値より低いタグについては排除することが有効な場合がある~\cite{Ohkura06}.  同様に，手書き文字認識システムによる分類結果が，言語モデルのようなドメイン知識を組み込んだシステムの入力である場合も，クラス所属確率が用いられている~\cite{Zadrozny02}. 
また，自動的にタグ付けされた事例のうち誤分類されたものを人手により訂正したい場合に，すべての事例をチェックするのは大きなコストがかかるが，
クラス所属確率が低いものほど不正解である可能性が高いと仮定し，
クラス所属確率が閾値を下回る事例のみを訂正することにすれば，効率的な作業が行える．
さらに，自動分類結果が人間の意思決定を支援する場合においては，クラス所属確率は判断の根拠を与える．
例えば，高橋らは，
社会調査において自由回答で収集される職業データを該当する職業コードに自動分類し~\cite{Takahashi05a,Takahashi05c}, 
上位 5 位までに予測されたクラスを候補として画面に提示するシステム（NANACO システム）を開発した~\cite{Takahashi05b}.  
NANACO システムは，我が国の主要な社会調査である JGSS（Japanese General Social Surveys; 日本版総合的社会調査）\kern-0.5zw\footnote{
	\texttt{http://jgss.daishodai.ac.jp/}. JGSS プロジェクトは，シカゴ大学 NORC 
	(the National Opinion Research Center) における GSS プロジェクトの日本版であり，
	国際比較分析を可能にするために，日本の社会や態度，行動に関する調査項目を有する．
} や，
SSM 調査（Social Stratification and Social Mobility Survey; 
社会階層と社会移動調査）\kern-0.5zw\footnote{
	\texttt{http://www.sal.tohoku.ac.jp/coe/ssm/index.html}.  1995 年から 10 年ごとに
	実施されている「仕事と暮らしに関する」全国調査である．
} などに利用されているが，
システムを利用したコーダから，
提示された各クラスについてどの程度確からしいかを示すクラス所属確率を付与してほしいという要望が出されている\footnote{
	NANACO システムが適用されるたびに，コーダによるシステム評価を行っている．
}．
最後に，クラス所属確率は EM アルゴリズムにおいても有用である．
例えば，語の曖昧性解消において，あるドメインで訓練された分類器を，別のドメインのコーパス用に調整するために用いられた EM アルゴリズムにおいて，クラス所属確率は精度の向上に役立つことが報告されている~\cite{Chan06}.  

事例 $x$ があるクラス $c$ に所属するクラス所属確率 $P$ は，2 値分類，多値分類のいずれにおいても $P(x \in{c}|x)$ で表される\footnote{
	クラス所属確率 $P$ の別の定義として，
	$P(\overrightarrow{\rm X}_{i},X_{i}\in{C_{j}}|\overrightarrow{\rm V}_{j},T_{j},S,I)$ 
	で表される場合もある．
	ただし，$\overrightarrow{\rm X}_{i}$ は事例 $X_{i}$ を記述する属性のベクトル，
	$C_{j}$ はクラス $j$, $\overrightarrow{\rm V}_{j}$ は確率密度関数を具体化する
	パラメータ集合，
	$T_{j}$ は確率密度関数の数式，$S$ は許容される確率密度関数 
	$\overrightarrow{\rm V}_{j}$, $T$ の空間，$I$ は明確には表現されない暗黙の情報を
	表す~\cite{Cheeseman96}.
}．
このようなクラス所属確率の意味からは，1 つの事例が複数のクラスに所属するマルチラベル分類の可能性があってもよく~\cite{erosheva05}, 
またある事例の全クラスに対するクラス所属確率の推定値の総和が $1$ 
である必要もない~\cite{Canters02}\footnote{
	さらに，Carreiras (2005) らにおいては，$n$ 個の分類器のバギングにより生成された分類器に
	おいて，クラス所属確率の推定値として，それぞれのクラスごとに各分類器におけるクラス
	所属確率の推定値の平均をそのまま用いている~\cite{Carreiras05}.
}. 
しかし，もし，シングルラベル分類で，全クラスに対するクラス所属確率の推定値を求めることができれば，その総和が $1$ になるように正規化することが可能である．このようなクラス所属確率は「正規化されたクラス所属確率」とよばれ~\cite{Cheeseman96}, 
事後確率と考えることができる．
対象とする分類問題をシングルラベルとして扱う場合，本来は正規化されたクラス所属確率を用いる必要があると考えられる．しかし，本稿においては，事例が注目するクラスに所属するか否かという問題に対する関心により，それぞれのクラスを独立に扱うため，一部の実験を除き基本的には正規化されたクラス所属確率を用いない．
実際には，
今回の実験では，正規化を行わないクラス所属確率の推定値の総和の平均はほぼ 1 に等しく，
また限定された実験の結果ではあるが\footnote{
	3.2.2 節および 4.2.2 節において報告を行う．
}，
本稿における提案手法に関しては，正規化を行わない場合は正規化された場合とほぼ同様かやや劣る結果であるため，本稿における結論は，正規化されたクラス所属確率を用いた場合には，さらなる説得性をもつと考えられる\footnote{
	この理由は，既存の方法に関しては，正規化を行う場合の方が正規化を行わない
	場合より結果が悪いためである．ただし，一般化するにはさらなる実験が必要である．
}．

クラス所属確率の推定は，分類器が出力するスコア（分類スコア）に基づいて行われる．非常に単純には，例えばナイーブベイズ分類器や決定木では分類スコアが $[0,1]$ の値をとるために，
分類スコアをそのまま用いることができる． 
また，サポートベクターマシン (SVM) のように分類スコアが $[0,1]$ の値をとらない場合でも，
最大値や最小値を利用して確率値に変換することは容易である\footnote{
	例えば分類スコアが $f$ の場合，$(f-min)/(max-min)$~\cite{Mizil05} または 
	$(f+max)/2*max$~\cite{Zadrozny02} により $[0,1]$ の値に変換することが可能である．
	ここで，$max$, $min$ はそれぞれ分類スコアの最大値，最小値を表す．
}. 
しかし，このようにして得られた推定値は実際の値から乖離することが多い．
この理由は，例えば，ナイーブベイズ分類器が出力する確率値は，0 または 1 に近い極端な値をとることが多いために，この値をそのままクラス所属確率とすると不正確になるためである\footnote{
	Zadrozny らによれば，ナイーブベイズ分類器が出力する確率は，
	その大小関係を用いた事例のランキングをうまく行うことはできる．
}~\cite{Zadrozny02}. 
また，決定木においては，少なくとも，ナイーブベイズ分類器の場合と同様の確率値の偏りおよび，
リーフに関連する訓練事例数が少ない場合に分散が大きいという 2 つの問題\footnote{
	度数が少ないことによる信頼性の低さが原因である．
}があるが，刈り込みによっても確率値の改善は期待できないため，クラス所属確率の推定値としては使えない~\cite{Zadrozny01b}.   
SVM においても，分類スコアとして用いられる分離平面からの距離が，事例がクラスに所属する程度に正確には比例しない~\cite{Zadrozny02} ために，
単純な変換では正確な値を推定しにくい．
したがって，クラス所属確率の正確な値を推定する方法についての研究が必要である.


\begin{table}[b]
\begin{center}
\caption{ビニングによる方法において参照される正解率の例}
\raisebox{1zw}[0pt][0pt]{（ナイーブベイズ分類器を利用しビンが 3 個の場合）}
\par
\label{bining1}
\input{01table01.txt}
\end{center}
\end{table}

これまでにいくつかの方法が提案されているが，代表的なものに，
Platt の方法~\cite{Platt99} や Zadrozny らにより提案された方法~\cite{Zadrozny01a,Zadrozny01b,Zadrozny02,Zadrozny05} がある． 
Platt の方法では，SVM における分離平面からの距離を分類スコアとし，
この値をシグモイド関数を利用して $[0,1]$ 区間の値に変換してクラス所属確率値の推定値とする（図~\ref{Platt} における実線）．
例えば，訓練事例により図~\ref{Platt} の実線で表されるような変換式が得られている場合に，ある事例の分類スコアが 1.5 であれば，この事例のクラス所属確率は 0.9 であると計算される．
しかし，Platt の方法では分類器やデータセットによってはうまく推定できない場合があるとして~\cite{Bennett00,Zadrozny01b}, 
Zadrozny らは決定木やナイーブベイズ分類器に対していくつかの方法を提案した~\cite{Zadrozny01a,Zadrozny01b}. 
このうち，
ナイーブベイズ分類器に適用した「ビニングによる方法」は注目に値する．
ビニングによる方法は，
訓練事例を分類スコアの順にソートして等サンプルごとに「ビン」にまとめ，各ビンごとに正解率を計算しておいたものをクラス所属確率として利用する（表~\ref{bining1} を参照のこと．表の上段の数値（斜体）は各ビンにおける分類スコアの範囲，下段の数値は各ビンの正解率を表す）． 
すなわち，評価事例の分類スコアから該当するビンを参照し，そのビンの正解率を評価事例のクラス所属確率の推定値とする．
例えば，訓練事例により表~\ref{bining1} が作成されている場合に，未知の事例の分類スコアが 0.6 であれば，この事例のクラス所属確率は 0.46 であると推定される．
Zadrozny らは，ビニングによる方法には最適なビンの個数を決定するのが困難であるという問題があるとして，
次に Isotonic 回帰による方法を提案した~\cite{Zadrozny02}. 
Isotonic 回帰による方法もビニングによる方法と同様に，訓練事例を分類スコアの順にソートすることが前提条件であるが，
ビンとしてまとめずに事例ごとに確率（正解の場合 1, 不正解の場合 0）を付ける点が異なる．
確率値は初期値 1 または 0 で開始されるが，分類スコアと単調関係を保つようになるまで修正が繰り返され，最終的に定まった値を正解率とする（表~\ref{Isotonic1} を参照のこと．表の上段の数値（斜体）は各事例の分類スコア，下段の数値は各事例の正解率を表す）．
評価事例のクラス所属確率は，評価事例の分類スコアと等しい分類スコアをもつ事例の正解率を参照し，この値を推定値とする．
例えば，訓練事例により表~\ref{Isotonic1} が作成されている場合に，未知の事例の分類スコアが 0.8 であれば，この事例のクラス所属確率は 0.5 であると推定される.

\begin{table}[b]
\begin{center}
\caption{Isotonic 回帰による方法において参照される正解率の例（SVM を利用し事例数が 10 の場合）}
\label{Isotonic1}
\input{01table02.txt}
\end{center}
\end{table}

これまでに提案された方法\footnote{
	これらの方法についての詳しい解説はこの後 2 節で行う．
}はいずれも 2 値分類を想定しているために，
クラス所属確率の推定には推定したいクラスの分類スコアのみを用いる．
したがって，文書分類でしばしば用いられる多値分類に対しても，分類スコアを単独に用いて推定する 2 値分類に分解する方法が検討された~\cite{Zadrozny02,Zadrozny05}.  
すなわち，
多値分類をいったん 2 値分類の組に分解し，それぞれの組で 2 値分類として推定したクラス所属確率の値を最後に統合（調整）する．
多値分類を 2 値分類に分解するには，all-pairs (one-versus-one) および one-against-all (one-versus-rest) の 2 つの方法があるが，
Zadrozny らは，
分解する方法そのものに精度の違いがないことを実験により示した上で，
実験においてはいずれの場合も one-against-all を用いた．
各組の 2 値分類における推定値を統合する方法としては，
one-against-all により分解した各組（クラスの数と等しい）において推定した値の合計が 1 になるようにそれぞれの推定値を正規化する方法がよい結果を示したことを報告した\footnote{
	Zadrozny らが推定値を統合する方法として提案した他の方法については，
	2.3 節で述べる．
}~\cite{Zadrozny02}. 
また，Zadrozny らによる最新の統合方法はさらに単純で，
one-against-all により分解した 2 値分類の各組において推定したクラス所属確率をそのままそのクラスについての推定値とする\footnote{
	ただし，この推定は（$\text{分類クラスの数}-{1}$）個に対して行い，
	残りの 1 クラスについては，これらの推定値を合計したものを 1 から
	引いた値を推定値とする．
}~\cite{Zadrozny05}. 
多値分類についての推定方法については Zadrozny らの研究以外になく，
例えば，Caruana らによるクラス所属確率の推定方法の比較~\cite{Mizil05} においても，2 値分類を対象としており，多値分類に対しては，Zadrozny らの文献~\cite{Zadrozny02} の紹介にとどまっている．

しかし，多値分類は 2 値分類の場合と異なり，予測されるクラスは分類スコアの絶対的な大きさではなく相対的な大きさにより決定されるために，クラス所属確率は推定したいクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられる．したがって，多値分類においては，推定したいクラス以外のクラスの分類スコアも用いることが有効であると思われる．

本稿は，多値分類における任意のクラスについてのクラス所属確率を，複数の分類スコア，特に推定したいクラスと第 1 位のクラスの分類スコアを用いて，ロジスティック回帰により高精度に推定する方法を提案する．
本稿ではまた，複数の分類スコアを用いてクラス所属確率を推定する別の方法として，「正解率表」（表~\ref{accuracy_table1} を参照のこと．表の最左列と最上段の数値（斜体）はそれぞれ第 1 位と第 2 位に予測されたクラスに対する分類スコアの範囲，それ以外の数値は、第 1 位のクラスについての正解率を表す．）を利用する方法も提案する．
正解率表を利用する方法とは，各分類スコアのなす空間を等区間（例えば 0.5）に区切って
「セル」\footnote{
	正解率表は多次元を想定するために，
	ビンではなくセルの語を用いることにする．
}を作成し，各セルについて正解率を計算した表を用意して参照する方法である．
例えば，「正解率表」を利用する方法において，
訓練事例により表~\ref{accuracy_table1} が作成されている場合，未知の事例において第 1 位に予測されたクラスの分類スコアが 0.8, 第 2 位に予測されたクラスの分類スコアが $-0.6$ であれば，この事例の第 1 位のクラスに対するクラス所属確率は 0.67 であると推定される．
しかし，もし第 2 位に予測されたクラスの分類スコアが $-0.2$ または 0.3 であれば，第 1 位のクラスについてのクラス所属確率の推定値は，それぞれ 0.53 または 0.38 のようにより小さな値になる．
このように，提案手法は既存の方法と異なり，推定したいクラス所属確率に関連すると思われる別のクラス（例えば第 2 位のクラス）の分類スコアを直接利用することで，より正確な推定を行うことが可能になる．


\begin{table}[b]
\begin{center}
\hangcaption{複数の分類スコアを用いた正解率表の例（SVM を利用し，第 1 位と第 2 位のクラスの分類スコアを用いた場合）}
\label{accuracy_table1}
\input{01table03.txt}
\end{center}
\end{table}

以下，次節で関連研究について述べた後，
3 節では，まず第 1 位に予測されたクラスのクラス所属確率を複数の分類スコアを用いて推定する方法を提案し，実験を行う．
4 節では 3 節で得られた結論を第 2 位以下の任意のクラスに対して拡張する方法を提案し，実験を行う．
最後にまとめと今後の課題について述べる．

\section{第 1 位のクラスについてのクラス所属確率推定}

本稿においても，Zadrozny らと同様に，多値分類においては，分類器は各々の予測クラスに対して分類スコアを 1 つずつ出力すると仮定する．
例えば，$k$ 値分類の場合は分類スコアを $k$ 個出力するものとする．
このとき，第 1 位に予測されるクラスはすべての分類スコアの中で最大の分類スコアをもつクラスで，分類スコアの絶対的な大きさではなく分類スコア間の相対的な大きさにより決定される．
したがって，例えば第 1 位の分類スコアが大きな値であっても，第 2 位の分類スコアも同じ程度に大きな値の場合には第 1 位のクラスが不正解であったり，
逆に，第 1 位の分類スコアがたとえ小さな値であっても，第 2 位の分類スコアがさらに小さな値の場合には第 1 位のクラスが正解であるケースも観察される．
以上より，多値分類において第 1 位のクラスのクラス所属確率は，第 1 位のクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられるために，正確な推定値を得るためには，第 1 位のクラス以外の分類スコアも考慮に入れた複数の分類スコアを用いる必要があると思われる．

ここで，
既存のビニングによる方法や Isotonic 回帰による方法は，
いずれも前提条件として，事例を分類スコアの順にソートする必要があるために，
複数の分類スコアを用いることが困難である．
したがって，複数の分類スコアを扱える方法を検討する必要がある．
本稿は，パラメトリックな方法として Platt の方法を，またノンパラメトリックな方法として Zadorzny らのビニングによる方法をそれぞれ参考にしながら，複数の分類スコアを有効に用いる方法を検討する．
その際，対象とするクラスを，クラス所属確率の必要性が最も高い第 1 位に予測されたクラスと，それ以外のクラス（第 2 位以下に予測されたクラス）の 2 つの場合に分けて検討することにする．

以下では，まず，本節において，第 1 位の予測クラスについてクラス所属確率の推定方法を検討し，有効な方法を提案する．
次に，4 節で，本節において提案された推定方法を第 2 位以下の任意のクラスに対して拡張する方法を提案する．

\subsection{提案手法}\label{method}

本稿では，第 1 位のクラス所属確率を複数の分類スコアを用いて推定することを提案する．
クラス所属確率を推定する方法としては，
ロジスティック回帰により直接推定する方法と，
正解率表を利用して間接推定する方法の 2 つを提案する．

\subsubsection{ロジスティック回帰による方法}

第 1 位のクラスから第 $r$ 位のクラスまで $r$ 個の分類スコアを用いる場合，
ロジスティック回帰による方法は（1）式により直接，クラス所属確率を推定する．
用いる分類スコアの数に制限はない．
\begin{equation}
P_{Log}( f_{1},\cdots , f_{r} ) = \frac{1}{1+\exp (\sum_{i=1}^r A_{i}f_{i}+B)},
\end{equation}
ここで，
$f_{i}$ は第 $i$ 位の分類スコアを表す．
このとき，
パラメータ $A_{i}$ ($\forall i$) および $B$ は訓練事例を用い，
最尤法によりあらかじめ推定しておく必要がある．

ロジスティック回帰による方法の手順を次に示す．
\vspace{0.5\baselineskip}
\begin{description}
\item[STEP 1]
ロジスティック回帰式におけるパラメータの推定

\item[STEP 2]
クラス所属確率の推定
\end{description}
\vspace{0.5\baselineskip}
\noindent
{\bf STEP 1}
\par
全訓練事例を，パラメータを推定するための訓練事例と評価事例に分割し，
各評価事例についての分類スコアと正解の状態（正解か不正解か）のペアデータから，パラメータ $A_{i}$ と $B$ の最尤推定を行う．
このとき，訓練事例と評価事例の分割は交差検定による．
\vspace{1\baselineskip}\par
\noindent
{\bf STEP 2}

未知の事例に対するクラス所属確率の推定は，未知の事例において用いるクラスの分類スコア $f_{i}$ をロジスティック回帰式（（1）式）に代入し，クラス所属確率を直接推定する．


\subsubsection{正解率表を利用する方法}

本稿においては，正解率表とは，各分類スコアを軸として等区間に区切ってセルを作成し，各セルについて正解率（＝セル内の正解事例数／セル内の全事例数）を計算した表をいう（表 3 参照のこと）．
正解率表は用いる分類スコアの数により次元が決まる．
すなわち，$k$ 個の分類スコアを用いる場合には $k$ 次元の正解率表になる．
例えば，分類スコアを 1 つしか利用しない場合は等幅の区切りをもつ線分，
2 個利用する場合は同様の長方形，
3 個利用する場合は同様の直方体となる．

正解率表を利用する方法の手順を次に示す．\\

\begin{description}
\item[STEP 1]
正解率表のためのセルの作成と正解率の計算 

\item[STEP 2]
正解率の平滑化

\item[STEP 3]
クラス所属確率の推定
\end{description}

\vspace{1\baselineskip}
\noindent
{\bf STEP 1}

まず，正解率表を作成するためには，
事例ごとに分類スコアと正誤状況のペアデータが必要である．
これは，ロジスティック回帰による方法と全く同様に，全訓練事例を交差検定により，正解率表作成のための訓練事例と評価事例に分割して学習を行って得ることができる．
次に，用いる分類スコアを軸とし，各軸とも等間隔（例えば，SVM の場合には 0.1 など）に区切ってセルを作成し，各セルごとに該当する事例をまとめて正解率を計算する．
例えば，第 1 位のクラスと第 2 位のクラスの分類スコアの 2 つを用いて区間幅 0.1 とする場合，縦横ともに 0.1 間隔で区切られたセルをもつ長方形の正解率表となるが，
訓練事例中の各評価事例における 2 つのクラスの分類スコアから，どのセルに属するかが決まる．
すべての訓練事例の所属先セルが決定された時点で，
各セルごとに所属する事例数と正解の事例数により正解率が計算できる．

提案手法は，ビニングによる方法や Isotonic 回帰による方法のように，事例を分類スコア順にソートしておく必要がないために，
利用する分類スコアの数（次元）が複数であっても正解率表の作成を行うことが可能である．ただし，実際には，正解率表の次元が上がるに連れてセル数の爆発が起こるというノンパラメトリックな方法に特有の問題があるために，分類スコアの数を無制限に大きくすることはできない．
また，訓練事例数に比較してセル数が多すぎる場合や，区間幅の決め方（セルの作り方）によっては，セルに含まれる事例数がゼロになる（ゼロ頻度問題）可能性があり，
正解率が計算できないという問題もある．
さらに，
セルに属する事例数が等しくない可能性があるために，
正解率における信頼性に違いが生じるという問題もある．
ゼロ頻度問題や信頼性の問題については，STEP 2 で対応する．
\vspace{1\baselineskip}\par
\noindent
{\bf STEP2}

正解率表の精度を高めるために，STEP 1 で計算された正解率に対して平滑化を行う．
まず，ゼロ頻度問題に対応する手法とし，
ラプラス法やリッドストーン法がある~\cite{Kita99_j}. 
分類スコア $f$ が与えられたとき，
ラプラス法 $P_{Lap}(f)$ およびリッドストーン法 $P_{Lid}(f)$ により平滑化された正解率は，
次式により計算される: 
\begin{equation}
P_{LapLid}(f)=\frac{N_{p}(c(f))+\delta} {N(c(f))+2\delta}.
\end{equation} 
ただし，
 $c(f)$ は平滑化を行うセル，
$N(c(f))$ は平滑化を行うセル中の訓練事例の数，
$N_{p}(c(f))$ は平滑化を行うセル中の正しく分類された訓練事例の数を表す.
また，$\delta$ は擬似的に加える数\footnote{
	本稿では，$\delta$ の最適な値を実験により決定する．
}であり，$\delta=1$ の場合がラプラス法である．

ここで，正解率表におけるセルの位置と正解率の関係を観察すると，
各セルとも正解率は周囲のセルの正解率と値が類似しており，
各軸ごとに分類スコアの変化に伴う正解率の状況は，
ほぼ単調な関係がみられる．
例えば，
第 1 位の分類スコアは正解率と正の相関があり，
第 2 位の分類スコアでは正解率と負の相関が観察される．
したがって，平滑化を行うセルに対して，
そのセルの周囲に位置するセルの情報も用いることが有効であると考えられる．
このような平滑化を可能にする手法としては，
移動平均法やメディアン法~\cite{Agui91_j} がある．
分類スコア $f$ が与えられたとき，
移動平均法 $P_{MA}(f)$ およびメディアン法 $P_{Median}(f)$ により平滑化された正解率は，
次式により計算される:
\begin{align}
 P_{\mathit{MA}}(f) & = \frac{\frac{N_p(c(f))}{N(c(f))} + \sum_{s\in Nb(c(f))}
	 \frac{N_p(s)}{N(s)}}{n},\\
 P_{\mathit{Median}}(f) & = \mathit{median}_{s\in Nb(c(f))} \Bigg( \frac{N_p(c(f))}{N(c(f))} , 
	\frac{N_p(s)}{N(s)} \Biggr).
\end{align}
ただし，
$Nb(c(f))$ は平滑化を行うセル $c(f)$ の周囲に位置するセル，
$n$ は $|Nb(c(f))|+1$ を表す．

さらに，
セルごとに正解率の信頼性が異なる問題を解決する方法としては，
各セルのカバレッジを重み付けとして調整する方法が考えられる．
移動平均法にカバレッジによる重み付けを行う方法 $P_{MA\_cov}$ により平滑化された正解率は，
次式により計算される: 
\begin{equation}
P_{\mathit{MA}\_cov}(f)=\frac{\frac{N_p(c(f))}{N(c(f))}C(c(f))
 + \sum_{s\in Nb(c(f))} \frac{N_p(s)}{N(s)}C(s)}{C(c(f))+\sum_{s\in Nb(c(f))}C(s)}.
\end{equation}
ただし，
 $C(c(f))$ は各セルのカバレッジで，
セル $c(f)$ における事例数をすべての事例数で割った数を表す．

周囲の情報も利用した平滑化手法においては，どこまでの範囲を周囲とするかという問題があるが，
今回は，最も単純に，平滑化を行うセルに隣接するセルまでとする．
例えば，
分類スコアを 1 つ利用する場合には平滑化を行うセルを含めて計 3 個，
分類スコアを 2 個利用する場合には，平滑化を行うセルを中心に斜めに位置するセルも含め計 9 個のセルを用いる\footnote{
	ただし，端や端の列（行）に位置するセルで用いられるセルは，この数より少ない．
}. \\\\ 
{\bf STEP3}
 
未知の事例に対するクラス所属確率の推定は，
未知の事例において用いる分類スコアにより正解率表の中から該当するセルを見つけ，そのセルの正解率を推定値とする．

\subsection{実験}

実験の目的は，
多値分類における第 1 位のクラスのクラス所属確率について有効な推定方法を調査し，複数の分類スコアを用いることが有効であることを示すこと（実験 1），
および実験 1 で最も有効であった方法の性能を評価すること（実験 2）である．

\subsubsection{実験設定} 
\noindent{\bf 分類器}

分類器は SVM を用いたが，提案手法の汎用性を調査するため，一部の実験についてはナイーブベイズ分類器も用いた．
SVM を選択した理由は，
SVM は文書分類においてきわめて高い分類性能を示す分類器として認識され~\cite{Joachims98,Dumais_et_al98,Taira00,Sebastiani02}, 
適用される場合が多いために，
分類器を特定しても有用性が高いと思われたためである．
ただし，SVM は本来は 2 値分類器であるために，
one-versus-rest 法~\cite{kressel99} により多値分類器に拡張した\footnote{
	\texttt{http://chasen.org/\textasciitilde taku/software/TinySVM/}
}. 
高橋ら (2005a) および Takahashi et al. (2005) にしたがって，SVM におけるカーネル関数は線形カーネルを用いた．
\vspace{1\baselineskip}\par
\noindent
{\bf データセット} 

データセットは，日本語の調査データである JGSS データセット
\pagebreak
および Zadrozny らの実験~\cite{Zadrozny02} において用いられた英文のネットニュース記事である UseNet news articles (20 Newsgroups) データセットの 2 つを用いた．

JGSS データセットは，
2000 年から 2003 年までの 4 年間に毎年実施された調査により収集されたデータのうちの職業データ（サンプル数 23,838）で，
自由回答である「仕事の内容」「従業先事業の種類」の他に，
選択回答である「従業上の地位」「役職」「従業先事業の規模」など複数の回答群から構成されている． すべての職業データに 195 個ある職業コードのいずれか 1 つのコードが付与されており\footnote{
	過去のデータには人手による職業コーディングが行われて職業コードが付与されている．
}，本稿ではこの職業コードを正解とした．
例えば，次のような職業データには正解として職業コード「563」が付与されている．
    \vspace{0.5\baselineskip}\par
\begin{tabular}{lll}
「仕事の内容」&：&配車等を手配（自由回答）\\
「従業先事業の種類」&：&荷物をつみおろす業務他（自由回答）\\  
「従業上の地位」&：&2　常時雇用の一般従事者（選択肢）\\
「役職」&：&1　役職なし（選択肢）\\
「従業先事業の規模」&：&8　500〜999 人（選択肢）
\end{tabular}
    \vspace{0.5\baselineskip}

JGSS データセットにおいては，
先に開発した自動コーディングシステム~\cite{Takahashi05a} の設定を踏襲し，
「仕事の内容」と「従業先事業の種類」に出現する単語 unigram および「従業上の地位」と「役職」を表す選択肢を素性として用いた．
訓練事例と評価事例の分割は，実際の職業コーディングの状況に似せて，
すでに正解が付けられた過去のデータを訓練事例とし，
これからコーディングを行う予定のデータを評価事例とした．
今回は，
訓練事例として 2000 年から 2002 年までの 3 年間分のデータ（20,066 サンプル），
評価事例として 2003 年のデータ（3,772 サンプル）に分割した．
さらに，訓練事例は正解率表を作成するため，5 分割交差検定により訓練事例と評価事例に分割した．
すなわち，
正解率表を作成するために，データを変えて訓練事例 16,053 サンプル，
評価事例 4,013 サンプルに分割し，計 5 回の学習を行った．

20 Newsgroups データセット（サンプル数 18,828）は，さまざまな UseNet のディスカッショングループに対応する 20 個のカテゴリのいずれかに分類されており，本稿ではこれを正解とした．
用いた素性は，ネットニュース記事に出現する単語 unigram で，JGSS データセットにおける自由回答の場合と同様である．
20 Newsgroups データセットでは，訓練事例と評価事例の分割は 5 分割交差検定により行った．
すなわち，
データを変えて，例えば，訓練事例 15,063 サンプル，評価事例 3,765 サンプルとし，計 5 回の学習を行った．
正解率表の作成は，
JGSS データセットの場合と全く同様に，全訓練事例を 5 分割交差検定により，訓練事例（例えば 12,053 サンプル）と評価事例（例えば 3,013 サンプル）に分割し計 5 回の学習を行った．
    \clearpage
\noindent
{\bf セルの区間幅}

最適なセルの区間幅は自動的に決めることができないために，
実験を行って決める必要がある．
今回は，区間幅を 0.05, 0.1, 0.2, 0.3, 0.5 の 5 通りに設定した．
このとき，1 つの正解率表においては，どの次元の軸も同一の区間幅で区切った．
第 1 位のクラスの分類スコア軸における区間幅とセルの数との関係は，
表~\ref{cell_interval} に示す通りであった．


\begin{table}[t]
\begin{center}
\caption{SVM におけるセルの区間幅と個数の関係 }
\label{cell_interval}
\input{01table04.txt}
\end{center}
\end{table}


\vspace{1\baselineskip}
\noindent
{\bf 評価尺度}

実験 1 では，各手法の評価を行うために，Zadrozny ら~\cite{Zadrozny05} にしたがい，次式で計算されるクロスエントロピーを用いた．
\begin{equation}
 H(y,p) = \frac{1}{N}\sum_{i=1}^N\{-y_{i}\log(p_{i}) - (1-y_{i})\log(1-p_{i})\}, 
\end{equation}
ただし，
$N$ は評価事例数，
$p_{i}$ は $i$ 番目の事例におけるクラス所属確率の推定値，
$y_{i}$ は $i$ 番目の事例における正誤状況で，正解の場合は $1$, 不正解の場合は $0$ を表す．
クロスエントロピーの値が小さいほどよい手法であるとする．

実験 2 では，提案手法の評価を行うために，Caruana ら~\cite{Caruana04,Mizil05} にしたがい，予測値がどの程度実測値と重なるかを表す信頼度曲線を用いた．
予測値と実測値が重なる程度が高いほどよい手法であるとする．
また，Zadrozny ら~\cite{Zadrozny05} にしたがい，ROC (receiver operating characteristic) 曲線に基づいて計算される AUC (Area Under the Curve) を用いた評価も行った．
AUC の値が大きいほどよい手法であるとする．
提案手法の性能評価としては，誤分類検出能力により従来の検出手法との比較を行った．
誤分類検出能力は，誤分類の事例を対象となる事例数のカバレッジが低い時点で多く検出できるほどよい手法であるとする．

\subsubsection{実験 1：有効な方法の調査}

\noindent{\bf セルの作成法}

実験 1 を行う前の予備実験として，正解率表におけるセルの作成法について，
分類スコアを等間隔に区切る方法（提案手法）を各ビンの事例数を等しくする方法（Zadorozny らによるビニングの方法）と比較し，
提案手法の有効性を確認した．
ここでは，
Zadorozny らによるビニングの方法との比較を可能にするために，
提案手法においても用いる分類スコアを第 1 位のクラスに対するもののみとし，正解率の平滑化を行わない値を用いた．
ここで，提案手法における定義域は $[-\infty,+\infty]$ であるが，今回用いたデータセットにおける第 1 位のクラスの分類スコアの範囲は，分類器が SVM の場合，JGSS データセットでは $[-0.99,5.48]$, 20 Newsgroups データセットでは $[-2.92,19.636]$ であった．

表~\ref{equal} は，
2 つの方法により作成されたセルからなる正解率表の有効性を，
データセットや分類器を変えてクロスエントロピーにより比較した結果である．
表中，等間隔は我々の提案する方法（セルの区間幅を等間隔にする方法），
等事例は Zadrozny らの提案する方法（セルに含まれる事例数を等しくする方法）を表す．
表の値は，等間隔の方法では区間幅を 0.1 から 0.5 まで 4 通り，
等事例の方法においても，この区間幅に対応させてセルの個数を 30 個から 7 個まで 4 通りに変化させた中のそれぞれ最もよかった場合の値である\footnote{
	セル個数 30, 16 に対応するセルの区間幅はそれぞれ 0.1, 0.2 である
	（表~\ref{cell_interval} 参照のこと）．
}．
太字の数字は，2 つの方法のうちよい方の値を示す．

\begin{table}[b]
\begin{center}
\caption{セルの作成法別クロスエントロピー}
\label{equal}
\input{01table05.txt}
\end{center}
\end{table}

表~\ref{equal} において，
セルを等間隔に区切る方法は，
ナイーブベイズ分類器ではセルに含まれる事例を等しくする方法にやや劣るものの，
SVM ではどちらのデータセットでも大きく上回る結果を示した．
この傾向は，
最もよかった値同士の比較だけではなく，セルの区間幅（セルの個数）が異なっても全く同様であった．
この理由としては，一般に，データを各区間の度数が等しくなるように分割する方法は各区間幅が等しくなるように分割する方法より推定効率が高いことが知られているが，一方で，密度関数推定の観点から大きなバイアスを引き起こす可能性があることが指摘されており~\cite{Kogure05},  
今回用いたデータセットの分類スコアの分布において，特に SVM を適用した場合にこのバイアス問題が生じたのではないかと考えられる．
その結果，
セルを等事例で区切る方法において作成された正解率表は，セルに属する事例の分類スコアと正解率の関係を適切に反映したものにならなかったのではないかと思われる．
表~\ref{equal} より，
「分類スコアを等間隔に区切ってセルを作成する方法」により正解率表を作成する方法が有効であることが確認できたため，
以下の実験では，セルの作成は分類スコアを等間隔に区切る方法を用いた．

なお，今回，等事例に区切る方法において最もよかったのは，セルの個数が 12 個または 7 個の場合であったが，
Zadrozny らのビニングによる方法においてもビンの個数が 10 個の場合が最もよかったとの報告があり~\cite{Zadrozny02}, 
第 1 位のクラスの分類スコアのみを用いる場合には，分類器やデータセットが異なっていても最適なセルの個数が類似していることは興味深い．
    \vspace{1\baselineskip}\par
    \noindent
{\bf クロスエントロピーによる評価}

表~\ref{loglikelihoodJGSS} は，
SVM を適用し JGSS データセットを用いた場合のクロスエントロピーの値を，
用いた分類スコア別，クラス所属確率を推定する方法別にまとめたものである．
表において，
重み付け移動平均法はカバレッジを重みとする移動平均法を表す．
リッドストーン法においては最もよい場合の値を示す．
表の縦方向はセルの区間幅を 0.05 から 0.5 まで 5 通りに変化させたことを示しており，
各区間幅の上段は利用した分類スコアが第 1 位のクラスのみの場合，
下段は利用した分類スコアが第 1 位と第 2 位のクラスの場合の結果を示す．
表中の記号「---」は クロスエントロピーが計算できなかったセルがあったことを示す\footnote{
	セル内の事例数が 0 であったり，正解の場合に確率値が 0 であった場合に生じた．
}．
また，太字の数字は，表中のすべての値の中で最もよい値であることを示す．

\begin{table}[b]
\begin{center}
\hangcaption{用いた分類スコア別 SVM におけるクロスエントロピー（JGSS データセット）．正解率表を利用する方法（上）およびロジスティック回帰による方法（下）}
\label{loglikelihoodJGSS}
\input{01table06.txt}
\end{center}
\end{table}

表では省略したが，正解率表を利用する方法において，第 1 位から第 3 位まで 3 つのクラスの分類スコアを用いた場合のクロスエントロピーは，
いずれも第 1 位のクラスのみの場合よりははるかによく第 1 位と第 2 位のクラスの場合よりやや悪かった．
なお，1 節で述べた 2 種類の単純な変換~\cite{Mizil05,Zadrozny02} によるクロスエントロピーは，
Nicllescu-Mizil らによる変換では 1.4563 であり，Zadrozny らによる変換では 0.8332 であった．

同様に，
SVM を適用し 20 Newsgroups データセットを用いた結果を表~\ref{loglikelihoodNS} に示す．
表の形式や記号の意味などは表~\ref{loglikelihoodJGSS} と同様である．
ここでも，正解率表を利用する方法においては，第 1 位から第 3 位まで 3 つのクラスの分類スコアを用いた場合のクロスエントロピーは JGSS データセットを用いた場合と全く同様で，いずれも第 1 位のクラスのみの場合よりははるかによく，第 1 位と第 2 位のクラスの場合よりやや悪かった．
なお，1 節で述べた単純な変換によるクロスエントロピーは，Nicllescu-Mizil らによる変換では計算できず，Zadrozny らによる変換では 0.9199 であった．




\begin{table}[b]
\begin{center}
\hangcaption{用いた分類スコア別 SVM におけるクロスエントロピー（20 Newsgroups データセット）．正解率表を利用する方法（上）およびロジスティック回帰による方法（下）}
\label{loglikelihoodNS}
\input{01table07.txt}
\end{center}
\end{table}

表~\ref{loglikelihoodJGSS} および表~\ref{loglikelihoodNS} より，次のことが明らかになった．
まず，SVM を適用した場合は，クラス所属確率を推定する方法やデータセットに関係なく，
第 1 位のクラスの分類スコアのみ用いるより他のクラスの分類スコアも含めた複数の分類スコアを用いることが有効であった．
分類スコアの有効な組み合わせ方については，ロジスティック回帰による方法と正解率表を利用する方法で異なっており，
ロジスティック回帰による方法は，第 1 位のクラスから第 3 位のクラスまで 3 つの分類スコアを用いた場合，
正解率表を利用する方法は，第 1 位のクラスと第 2 位のクラスの 2 つの分類スコアを用いた場合が最もよかった．
ただし，いずれの方法においても，分類スコアの組み合わせ方の違いによる差は小さかった．
 
次に，ロジスティック回帰による方法も含めてすべての場合の中で最もよい結果を示したのは，最適な正解率表を利用した場合，すなわち「第 1 位と第 2 位のクラスの分類スコアを用いてカバレッジを重みとする移動平均法による平滑化を行った正解率表を利用する方法」（セルの区間幅 0.1）であった．
ただし，正解率表を利用する方法は，セルの区間幅の決め方により結果に大きな差があった．
特にセルの区間幅を非常に小さく（0.05）設定した場合は，複数の分類スコアを用いることは有効ではなかった．
この理由は，
セルの個数が増えることにより各セルごとに含まれる事例数が少なくなり，場合によっては事例が存在しないセルが出現したために，正解率における信頼性が低くなったことが原因であると考えられる．
正解率表を利用する方法においてはロジスティック回帰による方法と異なり，分類スコアを 3 つ用いた方が 2 つ用いた場合より結果が悪かった理由も，同様であると考えられる．
今回は，最適なセルの区間幅は，どちらのデータセットにおいても 0.1 であった．
これに対して，ロジスティック回帰による方法は，どちらのデータセットにおいても安定してよい結果を示した\footnote{
	なお，第 2 位以下のクラスについて，注目するクラスのスコアのみを用いて推定した場合における
	全クラスの総和は，平均 1.0035, 標準偏差 0.1625 であり，4.2.2 節で提案するように
	注目するクラスと第 1 位のクラスのスコアを用いて推定した場合における全クラスの総和は，
	平均 0.9998, 標準偏差 0.0478 であった．
	これらの値から，正規化されたクラス所属確率を計算して用いた場合のクロスエントロピーは，
	第 1 位のスコアしか用いない場合は 0.4449 で表~\ref{loglikelihoodNS} における
	すべてのケースの中で最も悪く，
	第 1 位\&第 2 位のスコアを用いた場合は 0.3634 で正規化しない場合よりややよかった．
	一方，JGSS データセットの場合は，クラスの総数が約 200 個と多いため第 20 位までのクラス
	に対する推定値の総和の計算を試みた．その結果，注目するクラスのスコアのみを用いた場合は，
	平均 0.9217, 標準偏差 0.2711 で，注目するクラスと第 1 位のクラスのスコアを用いた場合の
	総和は，平均 0.9039, 標準偏差 0.1141 であった．
}．

さらに，正解率表における平滑化の手法は，いずれもデータセットに関係なく有効であった．
特に，平滑化を行うセルの周囲にあるセルの情報も利用する方法である（カバレッジを重みとする）移動平均法は，セルの区間幅が適切であった場合によい結果を示した．
注目するセルの情報のみで平滑化を行うラプラス法やリッドストーン法は，クロスエントロピーにおいては大きな効果はなかったが，ゼロ頻度問題に対応できる点で評価できる．

ここで，正解率表を利用する方法における結論をより一般化させるために，分類器をナイーブベイズ分類器に変え，20 Newsgroups データセットによる実験を行った\footnote{
	ただし，正解率の信頼性が低下することが明らかな場合，すなわち 分類スコアを第 3 位のクラス
	まで用いた場合やセルの個数が 60 個の場合についての実験は行わなかった．
	また，表~\ref{loglikelihoodJGSS} および表~\ref{loglikelihoodNS} に示すように，
	周囲の情報を用いない平滑化手法の 2 つの手法は違いがみられなかったため，
	ラプラス法のみを用いた．
}．
結果は表~\ref{loglikelihoodNS_NB} に示すように，
SVM の場合と同様に，
第 1 位のクラスの分類スコアのみを用いた場合より，第 2 位のクラスまで 2 つの分類スコアを用いた場合の方がよかった．
また，平滑化手法は有効で，特にセルの区間幅が適切な場合に移動平均法はよい結果を示した．
ナイーブベイズ分類器において最もよかったのはセルの個数が 30 個の場合であり，これは SVM において最もよかったセルの区間幅 0.1 の場合に該当する．

\begin{table}[t]
\begin{center}
\hangcaption{用いた分類スコア別ナイーブベイズ分類器におけるクロスエントロピー（20 Newsgroups データセット）}
\label{loglikelihoodNS_NB}
\input{01table08.txt}
\end{center}
\end{table}

以上より，
多値分類における第 1 位のクラスのクラス所属確率の推定は，複数の分類スコアを用いることが有効であった．
特に，最適な正解率表である「第 1 位と第 2 位のクラスの分類スコアを用いて（カバレッジによる重み付き）移動平均法による平滑化を行い，セルの区間幅を 0.1（セルの個数 30 個）に設定した正解率表」を利用する方法は最も有効であった．
ただし，正解率表を利用する方法は設定されたセルの区間幅により結果が不安定であるという問題があったのに対して，ロジスティック回帰による方法は安定してよい結果を示した．
また，今回は，正解率表を利用する方法における最適な正解率表がデータセットや分類器に関係なく一致したが，
この結果をさらに一般化するには，データセットや分類器をより多様なものに変えた実験を行って確認する必要がある．  
したがって，現時点では，正解率表を利用する方法は，データセットや分類器が異なる場合に最適な正解率表を決定するための実験を行う必要があり，手間がかかるという欠点があるといえる\footnote{
	今回は，$\delta$ を最適にしたリッドストーン法のラプラス法に対する優位性が
	認められなかったが，
	この点についても一般化するためにはさらなる実験が必要である．
}．

\subsubsection{実験 2：提案手法の評価}

ここでは，SVM を適用して，実験 1 において最適であった方法（以後，提案手法とよぶ）の評価を行った．\\\\
\noindent{\bf 信頼度曲線および ROC 曲線}

信頼度曲線は，予測値（推定値）（$X$ 軸）と実際の値（$Y$ 軸）の関係をプロットしたもので，
予測値と実際の値が等しい場合には対角線上にプロットされ，
対角線から離れるほど予測の精度が悪いことを示す．
ここでは，提案手法を，分類スコアを 1 つ用いた方法のうち，平滑化を行わない正解率表を利用する方法（以後，平滑化を行わない方法とよぶ）
およびシグモイド関数による方法と比較した．
このとき，平滑化を行わない方法は，等事例ではなく等間隔に区切ったビニングによる方法であると考えることができ，シグモイド関数による方法は Platt の方法を簡略化したものであると考えられる．
今回は，予測値を 0.1 ずつ区切り 10 区間を作成し，予測値と真の値としていずれも区間内（例えば，$[0,0.1]$）に含まれる事例の平均を用いた．
JGSS データセットによる結果を図~\ref{reliability_JGSS} に，20 Newsgroups データセットによる結果を図~\ref{reliability_20ng} に示す．
図~\ref{reliability_JGSS} および図~\ref{reliability_20ng} において，
提案手法はどちらのデータセットにおいても対角線の近くにプロットされており，クラス所属確率を全体的にうまく推定することがわかった．

\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f4.eps}
\hangcaption{JGSS データセットにおける信頼度曲線．左から順に提案手法，平滑化を行わない方法，シグモイド関数による方法の結果を示す．}
\label{reliability_JGSS}
\end{center}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f5.eps}
\hangcaption{20 Newsgroups データセットにおける信頼度曲線．左から順に提案手法，平滑化を行わない方法，シグモイド関数による方法の結果を示す．}
\label{reliability_20ng}
\end{center}
\end{figure}

ROC 曲線は，$X$ 軸が FPF（False Positive Fraction; 偽陽性率），$Y$ 軸が TPF（True Positive Fraction; 真陽性率）を表す座標上に，正解率の程度により分類された各グループごとの FPF と TPF の値をプロットしたものである．
ここで，FPF＝注目するグループ内の不正解事例数／全不正解事例数，TPF＝注目するグループ内の正解事例数／全正解事例数である．
今回は，正解率を 10 点刻みに分類して FPF と TPF の値を求めた．
すなわち，最上位のグループ（正解率が 91\%〜100\% の範囲にある事例）から始めて，上限を固定し下限を 10\% ずつ下げたグループ（例えば 2 番目のグループは，正解率の範囲が 81\%〜100\% である事例の集合）を計 10 個作成し，各グループにおける FPF と TPF を計算した．
ROC 曲線においては，ROC 曲線が左上方に位置するほど正確な推定が行われていることを示すが，
より正確には，ROC 曲線の下方にある領域である AUC (Area Under the Curve) を計算し，その値が大きいほどよい手法であるとされる．
図~\ref{ROC_JGSS_20ns} に，JGSS データセットおよび 20 Newsgroups データセットによる提案手法，平滑化を行わない方法，シグモイド関数による方法における ROC 曲線を示す．
また，3 つの手法における AUC の値を表~\ref{AUC_rank1} に示す．
図~\ref{ROC_JGSS_20ns} および表~\ref{AUC_rank1} より明らかなように，提案手法はいずれのデータセットにおいても他の 2 つの方法より正確な推定を行えることがわかった．

\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f6.eps}
\hangcaption{クラス所属確率の推定方法別 ROC 曲線（JGSS データセット（左）および 20 Newsgroups データセット（右））}
\label{ROC_JGSS_20ns}
\end{center}
\end{figure}
\begin{table}[b]
\begin{center}
\caption{クラス所属確率の推定方法別 AUC (Area Under the Curve)}
\label{AUC_rank1}
\input{01table09.txt}
\end{center}
\end{table}



\vspace{1\baselineskip}
\noindent
{\bf 誤分類検出能力} 

事例をクラス所属確率の推定値の小さい順に並べたとき，
カバレッジの値が小さいときにできるだけ多くの誤分類事例が検出されることが望ましい．
カバレッジをこのように考えた場合に，各カバレッジごとにどのくらい誤分類された事例を検出できるかを，本稿では誤分類検出能力とよぶ．
提案手法の誤分類検出能力を，
JGSS データセットおよび 20 Newsgroups データセットを用いて評価した．
評価の方法は，
提案手法によるクラス所属確率の推定値を値の小さい順に事例を並べ，
カバレッジを 10\% ずつ増やしてできた区間ごとに，誤分類された事例数を調査した．
比較のため，既存の手法である Schohn により提案された単純な方法~\cite{Schohn00} による結果も示した．
単純な方法では，
分類スコアの値の小さい順に並べ，同様にカバレッジを 10\% ずつ増やしてできた区間ごとに，
誤分類された事例数を調査した．
それぞれのデータセットによる結果を図~\ref{Lap-RawJGSS_ns} に示す．
 
図~\ref{Lap-RawJGSS_ns} において，
提案手法はどちらのデータセットにおいても常に単純な方法を上回った．
特に，20 Newsgroups データセットにおいては，
カバレッジが小さい場合に大きく上回る点が評価できる．
その理由は，我々が実際に人手により分類誤りを検出する必要がある場合，
チェックをするデータセットの量はできる限り少量の方が作業が楽であるからである．
JGSS データセットでは，全体の 40\% をチェックすれば誤分類事例の 80\% を検出することができるが，
20 Newsgroups データセットで同じ量をチェックすると，誤分類事例の 90\% を検出できる．
両者のデータセットにおける傾向の違いを説明する理由は明確ではないが，
JGSS データセットには非常に短く有効な素性が少ししか含まれない事例が多いため，
正確な推定を行うために十分な情報がないことが原因であると考えられる\footnote{
	表~\ref{equal}，表~\ref{loglikelihoodJGSS}, 表~\ref{loglikelihoodNS} における
	クロスエントロピーの値からも，JGSS データセットの方が推定が困難な
	タスクであることが予想される．
}．

\begin{figure}[t]
\begin{center}
\includegraphics{15-2ia1f7.eps}
\hangcaption{SVM における提案手法の誤分類検出能力（JGSS データセット（左）および 20 Newsgroups データセット（右））}
\label{Lap-RawJGSS_ns}
\end{center}
\end{figure}

以上をまとめると，
多値分類において第 1 位に予測されたクラスのクラス所属確率の推定は，
複数の分類スコアを用いることが有効であることがわかった．
特に，第 1 位と第 2 位に予測されたクラスの分類スコアを用いて作成した最適な正解率表を利用する方法が最もよい結果を示した．
ここで，最適な正解率表とは，
セルの区間幅を 0.1（セルの個数が 30）として作成した正解率表を（カバレッジによる重み付き）移動平均法による平滑化を行ったものである．
ただし，正解率表を利用する方法は正解率表の作成法により結果が不安定であるという欠点があった．
この点において，ロジスティック回帰による方法は安定してよい結果を示した．
また，ロジスティック回帰による方法は，最適な正解率表を見つけるために実験を重ねる手間が不要であるという利点もある．

\section{第 2 位以下の任意のクラスについてのクラス所属確率推定}\

3 節で，多値分類における第 1 位の予測クラスについてのクラス所属確率は，
複数の分類スコアを用いた推定が有効であることが明らかになった．
本節では，3 節で得られた結論を第 2 位以下の任意のクラスに対して拡張する方法を検討する．
この場合，どのクラスの分類スコアを組み合わせることが有効であるかを検討することが重要である．

\subsection{提案手法}

本稿では，多値分類における第 2 位以下の任意のクラスについてのクラス所属確率を高精度に推定するために，
推定したいクラス（第 $k$ 位のクラス）と第 1 位のクラスの分類スコアを用いてロジスティック回帰により推定する方法を提案する．
すなわち，次式\footnote{
	3 節で示した（1）式を第 1 位と第 $k$ 位のクラスのみ用いるように修正したものである．
}によりクラス所属確率の推定を行うことを提案する．
\begin{equation}
 P_{Log}( f_{1},f_{k}) = \frac{1}{1+\exp (A_{1}f_{1}+A_{k}f_{k}+B)}.
\end{equation}
ここで，
$f_{k}$ は第 $k$ 位の分類スコアを表す．
このとき，
パラメータ $A_{1}$, $A_{k}$ および $B$ は訓練事例を用い，
最尤法によりあらかじめ推定しておく必要がある.

ここで，
推定したいクラスの他に用いるクラスとして第 1 位のクラスを選択した理由は，
3 節でも述べたように，
多値分類においては，第 1 位のクラスの分類スコアが最も大きく，
どのクラスの分類スコアも第 1 位のクラスの分類スコアの値以上にはならないため，
推定したいクラスの分類スコアの値を第 1 位のクラスの分類スコアとの相対的な関係で捉えることが有効であると考えたためである．
これを実現するための方法はいくつか存在するが\footnote{
	例えば，2 つのスコア間の差や相関係数などが考えられる．
}，ここでは，3 節と同様に最も単純に第 1 位のクラスの分類スコアをそのまま用いることにした．
また，クラス所属確率の推定方法については，第 2 位以下のクラスにおいては，
第 1 位のクラスよりも分類スコアの傾向をさらに把握しにくくなるために，
最適な正解率表を作成することが困難であると考えられる．
したがって，第 1 位のクラスの場合において安定した結果を示したロジスティック回帰による方法の方が有効であると考えた．この 2 つの仮定を以下の実験により確認する．

\subsection{実験}

実験の目的は，
多値分類における第 2 位以下の任意のクラスのクラス所属確率の推定に用いる分類スコアは，提案手法による組み合わせ方が最も有効であることを示すこと（実験 1），
および第 2 位以下のクラスにおいては，ロジスティック回帰による方法が正解率表を利用する方法より有効であることを示すこと（実験 2）である．

実験設定は 3 節と同様で，分類器は SVM を適用した．実験 1 では第 2 位から
第 20 位までのクラス\footnote{
	JGSS データセットにおいては 10\%, 20 Newsgroups データセットにおいてはすべてのクラスを
	カバーする．
}，実験 2 では第 2 位から第 5 位までのクラスについて調査した．


\subsubsection{実験 1：分類スコアの有効な組み合わせ方}

\noindent{\bf 分類スコアの候補}

実験 1 を行う前の予備実験として，推定したいクラスのクラス所属確率と関連の深いクラスを発見するために，
第 2 位以下のすべてのクラスについて，注目するクラスの正誤状況（正解の場合 1，不正解の場合 0）と全クラスの分類スコアとの相関関係を調査した．
これは，注目するクラスの正誤状況と相関係数の絶対値が大きい分類スコアのクラスほど注目するクラスとの関連が強いと仮定したためである．
したがって，相関係数の絶対値の大きな分類スコアが多い順位のクラスを候補として用いることを検討した．

JGSS データセットと 20 Newsgroups データセットを用いて第 2 位から第 20 位のクラスにおいて，各クラスごとに関連の強かったクラスを表~\ref{correlation} にまとめる．
表~\ref{correlation} より，注目するクラス（推定したいクラス）自身より第 1 位のクラスの方が多かったため，
用いるクラスの候補として第 1 位のクラスを候補とした．
また，注目するクラスの直前や直後のクラスも候補とした．

\begin{table}[b]
\begin{center}
\caption{注目するクラスの正誤状況と関連の強いクラス}
\label{correlation}
\input{01table10.txt}
\end{center}
\end{table}

次に，これらの 3 つのクラスの分類スコアを推定したいクラスとそれぞれ単純に組み合わせた場合におけるクロスエントロピーを， JGSS データセットと 20 newsgroups データセットを用いて調査した．
その結果，どちらのデータセットにおいても，
第 1 位のクラスの分類スコアを組み合わせた場合以外は有効性が認められなかったため，実験 1 では，複数の分類スコアとして次の 3 つの組み合わせ方を考え，「推定したいクラスの分類スコアのみを用いる」場合と比較を行った（（　）内は用いる分類スコアの数を表す）．
このとき，分類スコアを 3 個以上用いた場合のクラス所属確率の推定には，3 節で述べた（1）式を適宜修正した式を用いた．
\begin{itemize}
\item ［提案手法］「推定したいクラスと第 1 位のクラスの分類スコア」（2 個） 

\item 「第 1 位のクラスから推定したいクラス（第 $k$ 位のクラス）までのすべてのクラスの分類スコア」（$k$ 個）

\item 「推定したいクラスとその直前および直後のクラスの分類スコア」（3 個）
\end{itemize}


\vspace{1\baselineskip}
\noindent
{\bf 提案手法の有効性}

図~\ref{rank2-12_JGSS_20ns} は，
JGSS データセットと 20 Newsgroups データセットにより，用いた分類スコアの組み合わせを変えた場合のクロスエントロピーを，推定したいクラスの順位別（$X$ 軸）に示したものである．
ただし，どちらのデータセットにおいても，13 位以下のクラスにおいては 12 位と同様の傾向であったために省略した．

\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f8.eps}
\caption{分類スコアの組み合わせ方別クロスエントロピー}
\label{rank2-12_JGSS_20ns}
\end{center}
\end{figure}



図~\ref{rank2-12_JGSS_20ns} から明らかなように，どちらのデータセットにおいても，推定したいクラスが上位の場合には，推定したいクラスの分類スコアのみを用いるより，クラスの組み合わせ方に関係なく複数の分類スコアを用いた方がよかった．
特に提案手法である「推定したいクラスと第 1 位のクラスの分類スコア」を用いた場合は，どの順位においても最もよかった．
ただし，推定したいクラスの順位が下がるにつれて，どの方法もクロスエントロピーの値が小さくなり，方法間の違いの差がみられなくなった．
この理由は，クラスの順位が下がるにつれてどの方法であってもクラス所属確率の推定値が小さくなり，また予測されたクラスも不正解である場合が多くなるために\footnote{
	例えば，JGSS データセットにおいて第 2 位から第 5 位に予測されたクラスの正解率は，
	それぞれ 7.7\%, 2.2\%, 0.9\%, 0.6\% であり，20 newsgroups データセットにおいては
	それぞれ 6.4\%, 2.3\%, 1.2\%, 0.8\% であった．
}，クロスエントロピーも小さくなったためだと考えられる．

次に，提案手法を含めた 4 つの方法における ROC 曲線を，第 2 位のクラスと第 3 位のクラスに注目した場合についてそれぞれ図~\ref{ROC2} および図~\ref{ROC3} に示す\footnote{
	第 4 位以下のクラスについては，いずれのデータセットにおいても第 3 位の場合と
	同様の傾向であったために省略した．
}．
ただし，第 2 位のクラスにおいては，
「第 1 位から推定したいクラスまでのすべてのクラスの分類スコアを用いる方法」は提案手法と同じ方法であるために，図~\ref{ROC2} では省略した．
また，図~9，図~10 における AUC を表~\ref{AUC_rank23} に示す．
表中，太字の数字は，各ケースにおいて最もよい値であることを示す．
図~\ref{ROC2}, 図~\ref{ROC3}, 表~\ref{AUC_rank23} より，注目するクラスやデータセットが異なっても，
複数の分類スコアを用いる方法は，注目するクラスの分類スコアだけを用いる方法よりよかった．
AUC による評価において最もよかった方法は，
JGSS データセットの場合は提案手法であり，
20 Newsgroups データセットの場合は，注目するクラスと直前および直後のクラスの分類スコアを用いる方法（第 2 位のクラスの場合）や，第 1 位から推定したいクラスまでのすべてのクラスの分類スコアを用いる方法（第 3 位のクラスの場合）であった．
ただし，提案手法は 20 Newsgroups データセットの場合も安定してよかった．

\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f9.eps}
\hangcaption{第 2 位のクラスについての分類スコアの組み合わせ方別 ROC 曲線（JGSS データセット（左）および 20 Newsgroups データセット（右））}
\label{ROC2}
\end{center}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f10.eps}
\hangcaption{第 3 位のクラスについての分類スコアの組み合わせ方別 ROC 曲線（JGSS データセット（左）および 20 Newsgroups データセット（右））}
\label{ROC3}
\end{center}
\end{figure}

以上より，第 2 位以下の任意のクラスについてのクラス所属確率を推定する場合も，複数の分類スコアを用いることは有効であり，特に推定したいクラスと第 1 位のクラスの分類スコアを用いる方法は有効であることが示された．

最後に，ロジスティック回帰式におけるパラメータを最尤推定するために用いる訓練事例数を変化させたときのクロスエントロピーを調査した．
図~\ref{JGSS_train_size} は，JGSS データセットにより，推定したいクラスの分類スコアのみ用いる方法と提案手法を比較したものである．
$X$ 軸は訓練事例数を表しており，右端はこれまでの実験において訓練事例として用いられてきた 20,066 サンプルの場合，左端は 1,000 サンプルにまで減らした場合を表す．
図~\ref{JGSS_train_size} より，まず，
訓練事例の数に関係なく提案手法が有効であることがわかった．
また，訓練事例が 1,000 サンプルと比較的少ない場合でも，ロジスティック回帰による方法は安定してよい結果を示すこともわかった．

\begin{table}[t]
\begin{center}
\caption{分類スコアを利用したクラス別 AUC}
\label{AUC_rank23}
\input{01table11.txt}
\end{center}
\end{table}
\begin{figure}[t]
  \begin{center}
\includegraphics{15-2ia1f11.eps}
\hangcaption{パラメータ推定に用いる訓練事例数の変化によるクロスエントロピー（ロジスティック回帰による方法）}
\label{JGSS_train_size}
  \end{center}
\end{figure}



\subsubsection{実験 2：ロジスティック回帰による方法の有効性}

ここでは，
提案手法による分類スコアの組み合わせにおいて，ロジスティック回帰による方法を最適な正解率表を利用する方法と比較した．
このとき，
最適な正解率表としては次の 2 つを検討した．
1 つは第 1 位のクラスについて推定する場合に
最も有効であった正解率表（セルの区間幅を 0.1 に設定）で，
推定したいクラスごとに新たな正解率表を作成する手間を省略する目的で用いた．
もう 1 つは，第 2 位以下の各クラスにおける分類スコアのとる値の状況に合わせて，セルの区間幅を適宜（例えば 0.2 など）変えたもので，「正解率表（改良版）」とよぶことにする．
いずれの正解率表も，
3 節で最も有効であった平滑化手法すなわちカバレッジを重みとする移動平均法による平滑化を行った．



\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f12.eps}
\caption{クラス所属確率の推定方法別クロスエントロピー}
\label{JGSS_20ns_seikai_hikaku}
\end{center}
\end{figure}


図~\ref{JGSS_20ns_seikai_hikaku} に，ロジスティック回帰による方法と正解率表を利用する方法におけるクロスエントロピーを示す．
図~\ref{JGSS_20ns_seikai_hikaku} より，
注目するクラスが第 2 位から第 5 位までの場合の平均において，ロジスティック回帰による方法が最も有効であることが示された\footnote{
	なお，20 Newsgroups データセットを用いた場合，ロジスティック回帰による方法において
	正規化されたクラス所属確率を用いた場合の第 2 位から第 5 位までのクロスエントロピーと
	その平均はそれぞれ 0.2386, 0.1246, 0.0694, 0.0483, 0.1202 で，正規化しない場合の値
	（0.2450, 0.1161, 0.0697, 0.0556, 0.1216）とほぼ同様であった．
}．
正解率表（改良版）を利用する方法は，JGSS データセットにおいて第 2 位のクラスに注目する場合や，20 Newsgroups データセットにおいて第 3 位のクラスに注目する場合のみ，
ロジスティック回帰による方法よりわずかによい結果であったが，
注目するクラスに対して毎回，最適な正解率表を作成する手間がかかるという欠点がある． 
3 つの方法における ROC 曲線の例として，JGSS データセットを用いて第 2 位のクラスに注目する場合を図~\ref{ROC_JGSS_seikai_hikaku} に示す．
このとき，3 つの方法における AUC は，それぞれロジスティック回帰による方法（0.7443），第 1 位のクラスに対する最適な正解率表を利用する方法（0.7260），正解率表（改良版）を利用する方法（0.7449）で，JGSS データセットにおいて第 2 位のクラスを推定する場合に限り，正解率表（改良版）を利用する方法がロジスティック回帰による方法をやや上回った．

\begin{figure}[t]
  \begin{center}
\includegraphics{15-2ia1f13.eps}
  \caption{クラス所属確率の推定方法別 ROC 曲線（JGSS データセットにおける第 2 位のクラス）}
  \label{ROC_JGSS_seikai_hikaku}
 \end{center}
\end{figure}


今回，第 6 位以下のクラスについては比較実験を行っていないが，
先に述べたように，下位のクラスになるにしたがって最適な正解率表の作成は困難になることが予想されるため，第 6 位以下のクラスにおいてもロジスティック回帰による方法が有効であると考えられる．


以上より，第 2 位以下の任意のクラスにおいても，
ロジスティック回帰による方法の方が正解率表を利用する方法より有効であると判断できた．

\end{document}
