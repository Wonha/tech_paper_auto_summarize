ここではテキスト分類における特徴選択の先行研究として，Zhangらが提案した方法について詳しく説明する．
テキスト分類に用いる機械学習アルゴリズムの多くは，学習の際のデータ表現に文書ベクトルを用いるが，通常このベクトルの値として，以下のtf値，df値を元に計算したtfidfと呼ばれる値が使用される．
tf(t, d):文字列tが文書dに出現する頻度
df(t, D):コーパスD中で文字列tが出現する文書数
tfidf(t, d): tfidf(t, d) = tf(t, d) [MATH] log([MATH]D[MATH]/df(t, D))
-0.5zw（[MATH]D[MATH]はコーパスDの文書数を表す）
Zhangらは，膨大な部分文字列を削り込むために出現分布が同一または類似している文字列をまとめ，上で述べた値に違いのあるものをなるべく特徴として選択するというアプローチを採用した．
ここで，出現分布が同一または類似している文字列とは，ある文字列のコーパス中におけるすべての出現場所をリストにしたとき，そのリストが別の文字列が持つ出現場所リストと等しいまたは類似している文字列のことを指す．
出現分布が同一な文字列はtf値とdf値について同じ値を持つため，学習において区別する必要はなく，ひとつの特徴としてまとめてしまう．
具体的な手続きとしては，出現場所のリストが等しい文字列のうち，最も文字列長が短い文字列のみを代表文字列として選択する．
また，出現場所のリストが厳密に等しくなくても類似していれば，そのような文字列のtf値，df値にも大きな違いは生じないため，これらの文字列をひとつの特徴にまとめても分類結果に余り影響を与えることなく，特徴集合を減らすことができると考えられる．
ただし出現場所の類似性の判定には基準が必要なので，Zhangらは類似した文字列を取り除くための条件を以下のようにした．
コーパス中である文字列の次に現れる文字の種類がb種類未満の文字列は特徴集合から取り除く．
ある文字列(S[MATH])が現れたとき，この文字列から始まる文字列(S[MATH])が出現する条件付確率P(S[MATH] S[MATH]がp以上であるならば，後者の文字列を特徴集合から取り除く．
ある文字列(S[MATH])が現れたとき，この文字列で終わる文字列(S[MATH])が出現する条件付確率P(S[MATH]S[MATH]がq以上であるならば，特徴集合から後者の文字列を取り除く．
また，コーパス中で出現頻度が極端に多い文字列，少ない文字列は分類に寄与しないと考え，最小頻度l未満の文字列，最大頻度h以上の文字列は特徴集合から除く．
以上の処理により，特徴集合の大きさを，全部分文字列を特徴集合とした場合に比べ大幅に小さくすることができる．
これらの処理を行うには5つのパラメータl, h, b, pおよびqを決定する必要があるが，これらは学習文書における交差検定法によって推定する．
Zhangらは以上の処理をsuffix treeを用いて効率的に行う方法を提案し，英語，中国語およびギリシャ語のコーパスを用いてテキスト分類の実験を行ったところ，これまでに提案されてきた主な文字列ベースのテキスト分類手法，例えば，言語モデルを利用した生成アプローチ(Peng 2004)やstring kernelを利用した識別アプローチ(Lodhi 2001)などの方法よりも優れた性能を示したと報告している．

本研究では，出現分布が同一または類似した文字列をまとめることに加え，ある文書に偏って出現する文字列をテキスト分類の重要な特徴として残すことを考え，Zhangらが用いた手法の条件(1), (2), (3)の代わりに反復度と呼ばれる統計量を用いることによって文字列を選択する方法を提案する．
反復度adapt(t, D)は，語tが出現した文書のうち，2回以上繰り返し出現している文書の割合を示す統計量で以下のように定義される．
ここで，df[MATH](t, D)はコーパスD中の文書で，文字列tが2回以上出現する文書数を表す．
表1は，ある英文中における反復度の変化の様子を示したものである．
ただし，「{_}」は空白を表す．
この例では，「natural{_}gas{_}」に1文字追加して「natural{_}gas{_}s」となったときに反復度が急激に減少している様子が示されている．
表1に見られるように，反復度はある境界を境にそれまでほぼ一定だった値が急激に減少する統計量であり，df / [MATH]D[MATH]で計算される出現確率とは異なり，意味的に一塊の語の境界で減少することが多いことから，キーワードの自動抽出(Takeda and Umemura 2002)などに利用されている．
表1の例においても，「natural{_}gas{_}」で語が区切られることは，その意味を考えると妥当であるといえる．
提案する方法では，出現分布が等しい文字列をその代表文字列だけにまとめることはZhangらと同じであるが，2章で説明した(1), (2), (3)の条件の代わりに，以下の条件を用いる．
反復度が最小反復度a未満の文字列は特徴集合から取り除く
Zhangらの(1), (2), (3)の条件を用いていないため，出現分布が類似していてもひとつにまとめず別の特徴として扱う．
ただし，出現分布が等しい文字列はひとつの特徴にまとめるため，表1のような1文字ずつ増加させたような文字列が必ず選ばれるわけではなく，単語中の語幹や連語単位の文字列などを特徴集合に含めることができる(平田他2007)．
表1の例では，「nat」と「natu」の2つ，「natural{_}」，「natural{_}g」，「natural{_}ga」の3つは出現場所のリストが等しく，統計量も同じなので，それぞれ「nat」と「natural{_}」だけを特徴として選択する．
また，「natural{_}gas」のような連語も特徴として選択される．
提案手法では，最小頻度l，最大頻度hといったパラメータに加え，最小反復度aを決定する必要があるが，本研究ではZhangらと同じく交差検定法によって推定する．
交差検定法とは，未知のデータに対するモデルのパラメータを推定する方法のひとつである．
本研究で用いる4分割交差検定法は，学習文書を4つのブロックに分割し，それぞれのブロックをテスト文書とし，テストに使用していない残りのブロックを学習文書に使用する．
この4回のテキスト分類において最も分類性能が良くなるパラメータを最適なパラメータとして推定する．
以上のように，パラメータの推定のテスト文書に学習文書とは別の文書を使用し，元の学習文書のすべての文書を順にテスト文書として使用することで，過学習を防ぐパラメータを決定することができ，学習における汎化性能の向上が期待される．
