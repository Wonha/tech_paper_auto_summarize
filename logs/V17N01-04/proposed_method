Zhangらの特徴選択方法

ここではテキスト分類における特徴選択の先行研究として，Zhangらが提案した方法について詳しく説明する．

テキスト分類に用いる機械学習アルゴリズムの多くは，学習の際のデータ表現に文書ベクトルを用いるが，通常このベクトルの値として，以下のtf値，df値を元に計算したtfidfと呼ばれる値が使用される．

\begin{itemize}
\item tf(t, d): 文字列tが文書dに出現する頻度
\item df(t, D): コーパスD中で文字列tが出現する文書数
\item tfidf(t, d): tfidf(t, d) = tf(t, d) $\cdot$ log($\vert $D$\vert $/df(t, D)) \\
{\kern-0.5zw}（$\vert $D$\vert $はコーパスDの文書数を表す）
\end{itemize}

Zhangらは，膨大な部分文字列を削り込むために出現分布が同一または類似している文字列をまとめ，上で述べた値に違いのあるものをなるべく特徴として選択するというアプローチを採用した．ここで，出現分布が同一または類似している文字列とは，ある文字列のコーパス中におけるすべての出現場所をリストにしたとき，そのリストが別の文字列が持つ出現場所リストと等しいまたは類似している文字列のことを指す．

出現分布が同一な文字列はtf値とdf値について同じ値を持つため，学習において区別する必要はなく，ひとつの特徴としてまとめてしまう．具体的な手続きとしては，出現場所のリストが等しい文字列のうち，最も文字列長が短い文字列のみを代表文字列として選択する．また，出現場所のリストが厳密に等しくなくても類似していれば，そのような文字列のtf値，df値にも大きな違いは生じないため，これらの文字列をひとつの特徴にまとめても分類結果に余り影響を与えることなく，特徴集合を減らすことができると考えられる．

ただし出現場所の類似性の判定には基準が必要なので，Zhangらは類似した文字列を取り除くための条件を以下のようにした．

\begin{enumerate}
\item コーパス中である文字列の次に現れる文字の種類がb種類未満の文字列は特徴集合から取り除く．
\item ある文字列 (S$_{1}$) が現れたとき，この文字列から始まる文字列 (S$_{2}$) が出現する条件付確率P(S$_{2}\vert $ S$_{1})$がp以上であるならば，後者の文字列を特徴集合から取り除く．
\item ある文字列(S$_{3}$) が現れたとき，この文字列で終わる文字列 (S$_{4}$) が出現する条件付確率P(S$_{4}\vert $S$_{3})$がq以上であるならば，特徴集合から後者の文字列を取り除く．
\end{enumerate}

また，コーパス中で出現頻度が極端に多い文字列，少ない文字列は分類に寄与しないと考え，最小頻度l未満の文字列，最大頻度h以上の文字列は特徴集合から除く．

以上の処理により，特徴集合の大きさを，全部分文字列を特徴集合とした場合に比べ大幅に小さくすることができる．これらの処理を行うには5つのパラメータl, 
h, b, 
pおよびqを決定する必要があるが，これらは学習文書における交差検定法によって推定する．Zhangらは以上の処理をsuffix 
treeを用いて効率的に行う方法を提案し，英語，中国語およびギリシャ語のコーパスを用いてテキスト分類の実験を行ったところ，これまでに提案されてきた主な文字列ベースのテキスト分類手法，例えば，言語モデルを利用した生成アプローチ(Peng 2004)やstring kernel を利用した識別アプローチ(Lodhi 2001)などの方法よりも優れた性能を示したと報告している．



提案手法


\subsection{反復度による特徴量抽出}

本研究では，出現分布が同一または類似した文字列をまとめることに加え，ある文書に偏って出現する文字列をテキスト分類の重要な特徴として残すことを考え，Zhang 
らが用いた手法の条件 (1), (2), (3)の代わりに反復度と呼ばれる統計量を用いることによって文字列を選択する方法を提案する．

反復度 adapt(t, D)は，語tが出現した文書のうち，2回以上繰り返し出現している文書の割合を示す統計量で以下のように定義される．
\[
 \text{adapt} (t,D) = \frac{\text{df}_{2}(t,D)}{\text{df}(t,D)}
\]

ここで，df$_{2}$(t, D)はコーパスD中の文書で，文字列tが2 
回以上出現する文書数を表す．



表 1は，ある英文中における反復度の変化の様子を示したものである．ただし，「{\_}」は空白を表す．この例では，「natural{\_}gas{\_}」に1文字追加して「natural{\_}gas{\_}s」となったときに反復度が急激に減少している様子が示されている．表 
1に見られるように，反復度はある境界を境にそれまでほぼ一定だった値が急激に減少する統計量であり，df 
/ $\vert $D$\vert 
$で計算される出現確率とは異なり，意味的に一塊の語の境界で減少することが多いことから，キーワードの自動抽出(Takeda and Umemura 2002)などに利用されている．表 
1の例においても，「natural{\_}gas{\_}」で語が区切られることは，その意味を考えると妥当であるといえる．提案する方法では，出現分布が等しい文字列をその代表文字列だけにまとめることはZhangらと同じであるが，2章で説明した (1), (2), (3)の条件の代わりに，以下の条件を用いる．

\begin{itemize}
\item 反復度が最小反復度a未満の文字列は特徴集合から取り除く
\end{itemize}

\begin{table}[t]
\caption{語の境界における反復度の変化}
\input{05table01.txt}
\end{table}


Zhangらの (1), (2), (3) の条件を用いていないため，出現分布が類似していてもひとつにまとめず別の特徴として扱う．ただし，出現分布が等しい文字列はひとつの特徴にまとめるため，表 
1のような1文字ずつ増加させたような文字列が必ず選ばれるわけではなく，単語中の語幹や連語単位の文字列などを特徴集合に含めることができる(平田 他 2007)．表1の例では，「nat」と「natu」の 2 
つ，「natural{\_}」，「natural{\_}g」，「natural{\_}ga」の3つは出現場所のリストが等しく，統計量も同じなので，それぞれ「nat」と「natural{\_}」だけを特徴として選択する．また，「natural{\_}gas」のような連語も特徴として選択される．


\subsection{交差検定法によるパラメータの設定}

提案手法では，最小頻度l，最大頻度h といったパラメータに加え，最小反復度a 
を決定する必要があるが，本研究ではZhangらと同じく交差検定法によって推定する．交差検定法とは，未知のデータに対するモデルのパラメータを推定する方法のひとつである．本研究で用いる4分割交差検定法は，学習文書を4つのブロックに分割し，それぞれのブロックをテスト文書とし，テストに使用していない残りのブロックを学習文書に使用する．この4回のテキスト分類において最も分類性能が良くなるパラメータを最適なパラメータとして推定する．以上のように，パラメータの推定のテスト文書に学習文書とは別の文書を使用し，元の学習文書のすべての文書を順にテスト文書として使用することで，過学習を防ぐパラメータを決定することができ，学習における汎化性能の向上が期待される．



考察


\subsection{ニュースのトピック分類}

まず，文字列に対する2つの特徴選択方法，提案手法である反復度による方法とベースラインである条件付確率による方法を比較する．4.1節の実験において，学習文書とテスト文書に同じ文書集合を用いてみると，F値のマクロ平均は，反復度を用いた方法では92.87{\%}，条件付確率を用いた方法では95.17{\%}となり，条件付確率による特徴集合の方が全体的にF値が高くなる．学習文書とテスト文書に異なる文書集合を用いる本来の評価では，4.1節で説明したように反復度による特徴集合の方がF値が高いことから，条件付確率を用いた特徴集合では，反復度を用いた場合に比べ，過学習してしまう傾向があると考えられる． 

ここで，各手法で選択された文字列を比較すると，共通して選択されたのは1,400文字列で，特徴集合全体に比べて小さい．2つの手法で選択される文字列の差を直感的に理解しやすい例をこの文字列から一つ示す．トピックのひとつであるshipに注目し，このトピックに含まれる学習文書を見るとトピック名である「ship」という単語が含まれていることがわかった．それぞれの手法で選択された文字列のうちこの単語に関連する文字列を表 
6に示す．

\begin{table}[b]
\caption{特徴文字列}
\input{05table06.txt}
\end{table}

条件付確率による特徴選択に比べて，反復度による特徴選択では，直前に現れる単語の最後の1文字加えた文字列や統計的には類似している文字列が追加で選択されている．これらのうち共通していない2文字列を特徴集合から取り除いて実験を行ったところ，shipの分類結果が75.68{\%}から73.10{\%}に減少した．これは，shipに含まれる文書中の「foreign 
ships」や「own 
shipping」のような文字列の特徴をテキスト分類に使用したためだと考えられる．連語そのものを検出しているとはいえないが，連語の情報を利用できていることが示唆される．

また，単語を特徴集合とする方法に比べ，提案手法は同等の性能を示したものの有意差は認められなかった．しかしながら，提案手法は区切り文字のないデータにおいて，単語抽出を行うための事前処理が必要なく，また上記の連語などのような情報を損なうことのないといった利点がある．


\subsection{Spam分類}

実験結果から，部分文字列を特徴集合とする2つの方法を比較すると，反復度で特徴選択した場合の方が，分類結果が良いことがわかる．そこで，ここでは両者の特徴集合を比較し，どのような文字列によりこの差が生まれたのかについて考察する．

この考察のために，4.2.1節で生成した20の文書セットの内の一つに相当する別の文書セット1個を生成した．これ一つについて分類を行い，反復度と条件付確率それぞれによる特徴集合を取り出す．さらに反復度について，特徴集合のうちサポートベクトルとして使用された文字列を抽出する．この分類実験の結果として表 
7に示すデータが得られた．


\begin{table}[b]
\begin{minipage}[t]{105pt}
\caption{手法ごとのF値}
\input{05table07.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{280pt}
\caption{文字列集合の記号との対応と大きさ}
\input{05table08.txt}
\end{minipage}
\end{table}

このとき，各手法のパラメータは次のように設定した．

\begin{itemize}
\item 反復度：l=80, h=8000, a=0.3
\item 条件付確率：l=80, h=8000, b=8, p=0.8, q=0.8
\end{itemize}

ここで，表 
8のように記号を定義する．ISはASにあってCSにはない文字列の集合であるため，この文字列の中に条件付確率を用いた場合に比べて分類結果を改善する原因となった文字列が含まれていると考えられる．ISがどれほど分類に寄与しているかと，たとえばどのような文字列が寄与しているかを調べるため以下の2つの実験（[実験1]，[実験2]）を行い，その結果を用いて考察する．

\noindent
\textbf{[実験1]}

ここでは，$\text{AS}-\text{IS}$ を特徴集合として分類を行う．この分類の結果として表 
9の実験1-aに示されるF値を得た．結果を見ると，反復度で特徴抽出した場合よりも7.00{\%}，条件付確率で特徴抽出した場合よりも2.00{\%}だけF値が下がっていることがわかる．このことから，ISの文字列はF値を7.00{\%}上昇させることがわかる．また，このときのF値がCSで分類したときよりも下がっていることから，反復度では捉えることができなかったが条件付確率では捉えることができた分類に役立つ文字列があったことがわかる．ただし，ISのうち実際に分類に使われるものは 
IS$\cap $SV（大きさは1628）であるから，IS$\cap 
$SVをASから取り除いた場合とISを取り除いた場合の結果は同じである．

\noindent
\textbf{[実験2]}

 実験1からIS$\cap 
$SVが分類結果を改善しているということがわかった．ここでは，実際にどのような文字列が分類に寄与しているのかについて調べる．

まず，考察のために作成した文書セットの分類において反復度が選んだ特徴集合 (AS) の内サポートベクトルとして用いられた部分文字列 (SV) の重みw$_{j}$（4.1節参照）を計算する．そして，w$_{j}$が大きいほど分類に寄与していると考え，その上位50の文字列をとりだす．その集合とISの積をとり，それをASから取り除いて分類を行う．この結果として表 
9の実験2-aに示されるF値を得た．この結果を見ると，反復度で特徴抽出した場合よりも2.50{\%}だけF値が下がっていることがわかる．この50個の文字列を調べると，message{\_}idという文字列の一部と推測できる部分文字列12個が含まれていることが分かった．これはたとえば表 
10に示されるような文字列である．ここで「 {\_} 」は空白を意味することとする．

\begin{table}[b]
\hfill\begin{minipage}[t]{100pt}
\caption{条件ごとのF値}
\input{05table09.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{210pt}
\caption{見つかったmessage{\_}idの部分文字列の一部}
\input{05table10.txt}
\end{minipage}
\hfill
\end{table}


ただし，この12個の部分文字列はすべてCSに含まれていないことが分かった．これらをASから取り除いて分類するとF値は表 
9の実験2-bに示される値となった．このように，これを除去することで F 値が下がるという結果から，明らかにこれらの部分文字列は分類に役立っていることがわかる．

SV全体からmessage{\_}idの部分文字列を探したところ26個見つかり，ISとの積をとると16個の文字列が得られた．この16個の文字列をASから取り除き分類するとF値は表 
9の実験2-cに示される値となった．この結果からも，message{\_}idの部分文字列群は役立っていることが示唆される．ここで，CSにも含まれている10個のmessage{\_}idの部分文字列を除去した場合，F値は変化しなかった．よって，CSに含まれない16個の部分文字列はCSに含まれる10個の部分文字列をカバーするといえる．

 このmessage{\_}idという文字列がコーパスのSpam, Hamメールのうちどれぐらい含まれるのかを調べたところ，Spamメールの約81.9{\%}，Hamメールの約99.9{\%}にこれが含まれていることがわかった．よってこれが含まれていないとほぼSpamと断定できる文字列であるということがわかり，これは分類に有用であるということは直感的に理解できる．

message{\_}idという文字列の一部がCSにも含まれており（26個中10個），CSに含まれない16個の部分文字列をASから取り除き分類すると分類結果が悪くなることは先に述べた．ではなぜ10個の文字列はCSに含まれない16個をカバーできなかったのか，それらの文字列の違いについてここでは考える．考察のために，表 
11に反復度，条件付確率それぞれの手法が捉えたmessage{\_}idの部分文字列を示す．

\begin{table}[t]
\caption{反復度と条件付確率の特徴集合の比較}
\input{05table11.txt}
\end{table}

表 11を見ると，条件付確率の手法を用いたほうは一見しただけでは何の部分文字列かわからないほど短い文字列である．これは別の意図しない文字列に対しても分類結果が引きずられやすい，つまり文字列message{\_}idを意図してmeを選択してもmemberやmeatなどの別の文字の部分文字列と解釈される可能性があるということである．それに対して反復度で抽出した部分文字列は短い文字列もあるが，かなり長い文字列も捉えており，age{\_}iなど間に空白が挟まった形も捉えているため，不特定多数の文字列の一部となりえない特定のものをさす文字列の部分文字列であるといえる．このような何を指しているのかわかりやすいある程度長い部分文字列と，間に空白を挟んだ単語と単語を結ぶような形の部分文字列が分類結果を改善していると考えられる．


