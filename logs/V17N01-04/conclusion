考察


\subsection{ニュースのトピック分類}

まず，文字列に対する2つの特徴選択方法，提案手法である反復度による方法とベースラインである条件付確率による方法を比較する．4.1節の実験において，学習文書とテスト文書に同じ文書集合を用いてみると，F値のマクロ平均は，反復度を用いた方法では92.87{\%}，条件付確率を用いた方法では95.17{\%}となり，条件付確率による特徴集合の方が全体的にF値が高くなる．学習文書とテスト文書に異なる文書集合を用いる本来の評価では，4.1節で説明したように反復度による特徴集合の方がF値が高いことから，条件付確率を用いた特徴集合では，反復度を用いた場合に比べ，過学習してしまう傾向があると考えられる． 

ここで，各手法で選択された文字列を比較すると，共通して選択されたのは1,400文字列で，特徴集合全体に比べて小さい．2つの手法で選択される文字列の差を直感的に理解しやすい例をこの文字列から一つ示す．トピックのひとつであるshipに注目し，このトピックに含まれる学習文書を見るとトピック名である「ship」という単語が含まれていることがわかった．それぞれの手法で選択された文字列のうちこの単語に関連する文字列を表 
6に示す．

\begin{table}[b]
\caption{特徴文字列}
\input{05table06.txt}
\end{table}

条件付確率による特徴選択に比べて，反復度による特徴選択では，直前に現れる単語の最後の1文字加えた文字列や統計的には類似している文字列が追加で選択されている．これらのうち共通していない2文字列を特徴集合から取り除いて実験を行ったところ，shipの分類結果が75.68{\%}から73.10{\%}に減少した．これは，shipに含まれる文書中の「foreign 
ships」や「own 
shipping」のような文字列の特徴をテキスト分類に使用したためだと考えられる．連語そのものを検出しているとはいえないが，連語の情報を利用できていることが示唆される．

また，単語を特徴集合とする方法に比べ，提案手法は同等の性能を示したものの有意差は認められなかった．しかしながら，提案手法は区切り文字のないデータにおいて，単語抽出を行うための事前処理が必要なく，また上記の連語などのような情報を損なうことのないといった利点がある．


\subsection{Spam分類}

実験結果から，部分文字列を特徴集合とする2つの方法を比較すると，反復度で特徴選択した場合の方が，分類結果が良いことがわかる．そこで，ここでは両者の特徴集合を比較し，どのような文字列によりこの差が生まれたのかについて考察する．

この考察のために，4.2.1節で生成した20の文書セットの内の一つに相当する別の文書セット1個を生成した．これ一つについて分類を行い，反復度と条件付確率それぞれによる特徴集合を取り出す．さらに反復度について，特徴集合のうちサポートベクトルとして使用された文字列を抽出する．この分類実験の結果として表 
7に示すデータが得られた．


\begin{table}[b]
\begin{minipage}[t]{105pt}
\caption{手法ごとのF値}
\input{05table07.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{280pt}
\caption{文字列集合の記号との対応と大きさ}
\input{05table08.txt}
\end{minipage}
\end{table}

このとき，各手法のパラメータは次のように設定した．

\begin{itemize}
\item 反復度：l=80, h=8000, a=0.3
\item 条件付確率：l=80, h=8000, b=8, p=0.8, q=0.8
\end{itemize}

ここで，表 
8のように記号を定義する．ISはASにあってCSにはない文字列の集合であるため，この文字列の中に条件付確率を用いた場合に比べて分類結果を改善する原因となった文字列が含まれていると考えられる．ISがどれほど分類に寄与しているかと，たとえばどのような文字列が寄与しているかを調べるため以下の2つの実験（[実験1]，[実験2]）を行い，その結果を用いて考察する．

\noindent
\textbf{[実験1]}

ここでは，$\text{AS}-\text{IS}$ を特徴集合として分類を行う．この分類の結果として表 
9の実験1-aに示されるF値を得た．結果を見ると，反復度で特徴抽出した場合よりも7.00{\%}，条件付確率で特徴抽出した場合よりも2.00{\%}だけF値が下がっていることがわかる．このことから，ISの文字列はF値を7.00{\%}上昇させることがわかる．また，このときのF値がCSで分類したときよりも下がっていることから，反復度では捉えることができなかったが条件付確率では捉えることができた分類に役立つ文字列があったことがわかる．ただし，ISのうち実際に分類に使われるものは 
IS$\cap $SV（大きさは1628）であるから，IS$\cap 
$SVをASから取り除いた場合とISを取り除いた場合の結果は同じである．

\noindent
\textbf{[実験2]}

 実験1からIS$\cap 
$SVが分類結果を改善しているということがわかった．ここでは，実際にどのような文字列が分類に寄与しているのかについて調べる．

まず，考察のために作成した文書セットの分類において反復度が選んだ特徴集合 (AS) の内サポートベクトルとして用いられた部分文字列 (SV) の重みw$_{j}$（4.1節参照）を計算する．そして，w$_{j}$が大きいほど分類に寄与していると考え，その上位50の文字列をとりだす．その集合とISの積をとり，それをASから取り除いて分類を行う．この結果として表 
9の実験2-aに示されるF値を得た．この結果を見ると，反復度で特徴抽出した場合よりも2.50{\%}だけF値が下がっていることがわかる．この50個の文字列を調べると，message{\_}idという文字列の一部と推測できる部分文字列12個が含まれていることが分かった．これはたとえば表 
10に示されるような文字列である．ここで「 {\_} 」は空白を意味することとする．

\begin{table}[b]
\hfill\begin{minipage}[t]{100pt}
\caption{条件ごとのF値}
\input{05table09.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{210pt}
\caption{見つかったmessage{\_}idの部分文字列の一部}
\input{05table10.txt}
\end{minipage}
\hfill
\end{table}


ただし，この12個の部分文字列はすべてCSに含まれていないことが分かった．これらをASから取り除いて分類するとF値は表 
9の実験2-bに示される値となった．このように，これを除去することで F 値が下がるという結果から，明らかにこれらの部分文字列は分類に役立っていることがわかる．

SV全体からmessage{\_}idの部分文字列を探したところ26個見つかり，ISとの積をとると16個の文字列が得られた．この16個の文字列をASから取り除き分類するとF値は表 
9の実験2-cに示される値となった．この結果からも，message{\_}idの部分文字列群は役立っていることが示唆される．ここで，CSにも含まれている10個のmessage{\_}idの部分文字列を除去した場合，F値は変化しなかった．よって，CSに含まれない16個の部分文字列はCSに含まれる10個の部分文字列をカバーするといえる．

 このmessage{\_}idという文字列がコーパスのSpam, Hamメールのうちどれぐらい含まれるのかを調べたところ，Spamメールの約81.9{\%}，Hamメールの約99.9{\%}にこれが含まれていることがわかった．よってこれが含まれていないとほぼSpamと断定できる文字列であるということがわかり，これは分類に有用であるということは直感的に理解できる．

message{\_}idという文字列の一部がCSにも含まれており（26個中10個），CSに含まれない16個の部分文字列をASから取り除き分類すると分類結果が悪くなることは先に述べた．ではなぜ10個の文字列はCSに含まれない16個をカバーできなかったのか，それらの文字列の違いについてここでは考える．考察のために，表 
11に反復度，条件付確率それぞれの手法が捉えたmessage{\_}idの部分文字列を示す．

\begin{table}[t]
\caption{反復度と条件付確率の特徴集合の比較}
\input{05table11.txt}
\end{table}

表 11を見ると，条件付確率の手法を用いたほうは一見しただけでは何の部分文字列かわからないほど短い文字列である．これは別の意図しない文字列に対しても分類結果が引きずられやすい，つまり文字列message{\_}idを意図してmeを選択してもmemberやmeatなどの別の文字の部分文字列と解釈される可能性があるということである．それに対して反復度で抽出した部分文字列は短い文字列もあるが，かなり長い文字列も捉えており，age{\_}iなど間に空白が挟まった形も捉えているため，不特定多数の文字列の一部となりえない特定のものをさす文字列の部分文字列であるといえる．このような何を指しているのかわかりやすいある程度長い部分文字列と，間に空白を挟んだ単語と単語を結ぶような形の部分文字列が分類結果を改善していると考えられる．


まとめ

文字列によるテキスト分類において，条件付確率を用いて文書の特徴集合を選択する代わりに，反復度を用いて特徴選択を行い，ニュース記事のコーパスであるReuters-21578，20newsgroupsと，スパムメールのコーパスであるTREC 
2006 Spam 
Corpusのテキスト分類の結果の比較を行った．反復度によって特徴選択した特徴集合を用いると条件付確率による特徴集合を用いた場合に比べて，ニュース記事の分類では平均79.65{\%}から平均83.39{\%}と，平均3.74{\%}だけテキスト分類の結果を改善することを報告し，スパムメールの分類では分類結果を平均90.23{\%}から平均93.15{\%}と平均2.93{\%}だけ結果を改善することを報告した．このとき，その両方の実験において，提案する反復度を用いる手法と条件付確率を用いるZhangら手法の間に有意差があることを確認した．

また，本実験では提案手法である反復度を用いて特徴集合を選択する方法と単語を特徴集合とする方法との比較についてもZhangらの手法との比較と同様にして行った．Reuters-21578，20newsgroupsを用いたニュース記事の分類においては両手法の間に有意差は確認できなかった．しかし，TREC 
2006 Spam 
Corpusを用いたスパムメールの分類においては，反復度による特徴抽出法を用いると，単語を特徴集合とする場合に比べて分類結果を，平均92.11{\%}から平均93.15{\%}と平均1.04{\%}だけ改善するということを報告した．そして，このとき危険率1{\%}の検定を行い両手法の間に有意差があるということを確認した．この結果の一つの要因として，反復度を用いて抽出される部分文字列に，条件付き確率を用いる手法で抽出される部分文字列に比べて別の部分文字列と解釈されにくい部分文字列や，単語による方法では抽出できない単語と単語を結ぶような文字列が含まれていると言うことが考えられる．よって，本研究は意味ある結果となったといえる．


\acknowledgment

この研究は，住友電工情報システムとの共同研究の成果です．データの解析には，戦略的情報通信開発推進制度(SCOPE)の課題「実空間情報処理のためのインターユビキタスネットワークの研究」の成果の分析技術を利用しました．

また，多くの有益なご指摘を頂いた査読者の方々に感謝致します．


\bibliographystyle{jnlpbbl_1.4}
\begin{thebibliography}{}


\item
Manning, C. and Schutze H. (1999). ``Foundations of Statistical Natural 
Language Processing.'' MIT Press, Cambridge.

\item
Zhang, D. and Lee, W. S. (2006). ``Extracting Key-Substing-Group Features for 
Text Classification.'' In \textit{Proceedings of the 12th ACM SIGKDD international 
Conference on Knowledge Discovery and Data Mining}, pp.~474--483.

\item
Peng, F., Shuurmans D., and Wang, S. (2004). ``Augmenting Naive Bayes text 
classifier with statistical language models.'' \textit{Information Retrieval}, 
\textbf{7} (3-4), pp.~317--345.

\item
Lodhi, H., Saunders, C., Shawe-Taylor, J., Cristianini, N., and Watkins, C. 
(2001). ``Text Classification Using String Kernels.'' \textit{Journal of Machine 
Learning Research (JMLR)}, pp.~419--444.

\item
Goodman, J. (2001). ``A bit progress in language modeling, extended version.'' 
Technical report, Microsoft Research, pp.~403--434.

\item
Church, K. W. (2000). ``Empirical Estimates of Adaptation: The chance of Two 
Noriegas is closer to p/2 than p2.'' In \textit{Proceedings of 18th International 
Conference on Computational Linguistics}, \textbf{1}, pp.~180--186.

\item
Cristianini, N. and Shawe-Taylor, J. (2000). ``An Introduction to Support Vector 
Machines.'' Cambridge University Press, Camridge.

\item
Dumais, S., Platt, J., Hecherman, D., and Sahami, M. (1998). ``Inductive learning 
algorithms and representations for text categorization.'' In \textit{Proceedings of 
the 7th ACM International Conference on Information and Knowledge 
Management}, pp.~148--155.

\item
Mitchell, T. (1997). ``Machine Learning.'' McGraw Hill, international edition.

\item
Geng, Xiubo, Liu, Tie-Yan, Qin, Tao, and Li, Hang (2007). ``Feature Selection for 
Ranking.'' \textit{SIGIR '07: Proceedings of the 30th annual international ACM SIGIR 
conference on Research and development in information retrieval}, pp.~407--414.

\item
Takeda, Y. and Umemura K. (2002). ``Selecting indexing strings using 
adaptation.'' \textit{Proceedings of the 25th Annual International ACM SIGIR 
Conference on Research and Development in Information Retrieval}, pp.~11--15.

\item
Yiming, Yang and Pedersen, Jan O. (1997). ``A comparative study on feature 
selection in text categorization.'' \textit{Proceedings of ICML-97 14th 
International Conference on Machine Learning}, pp.~412--420.

\item
平田勝大, 岡部正幸, 梅村恭司 (2007). 文字列を特徴量とし反復度を用いたテキスト分類. 
情報処理学会研究会報告, \textbf{76}, pp.~121--126.

\end{thebibliography}


\clearpage

