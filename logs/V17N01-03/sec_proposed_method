未知語獲得とは，未知語について，テキスト中の一つ以上の用例から辞書項目を帰納的に生成するタスクである．
ここで，辞書項目は辞書の項目として記述される形態素であり，テキスト中に出現したその形態素を用例とよぶ．
例えば，未知語「ググる」について，「なんとなくググってみた．
」や「ググらずに答える．
」といったテキスト中の用例から辞書項目を生成する．
ただし，個々の用例の解釈には曖昧性があり，そうした曖昧性を解消することによって辞書項目が生成される．
辞書項目の生成には語幹と品詞の同定が必要となる．
「ググる」の例にあるように，動詞や形容詞は文法的役割に応じて形態変化を起こすが，この形態変化は活用という概念によって処理される．
活用する形態素は語幹と語尾からなる．
語幹は不変だが，語尾は活用に応じて変化する．
例えば，「ググって」は語幹「ググ」と語尾「って」からなる．
名詞は活用せず，語幹のみからなる．
品詞は形態素解析用に定義されたものに基づく．
ただし，既存の品詞は人手での付与が前提となっており，形態，構文，意味レベルの情報が混在している．
未知語獲得タスクにおいて，いきなり意味レベルの情報を獲得するのは難しいため，本論文では，ひとまず形態レベルの情報の獲得を目指す．
そのために，品詞分類を整理する．
以下の説明は形態素解析器JUMANが採用する品詞体系に基づく．
品詞体系の設定方法には様々な流儀があるため一般化が難しいが，少なくともipadicの品詞体系でも同様の議論が成り立つことは容易に想像できる．
品詞は「品詞」，「品詞細分類」，「活用型」，「活用形」の4種類からなる．
「品詞」には「名詞」，「動詞」，「形容詞」などがある．
「名詞」の「品詞細分類」には，「普通名詞」や「サ変名詞」の他，固有名詞用の「固有名詞」，「組織名」，「地名」，「人名」などがある．
しかし，固有名詞と普通名詞の識別は，形態レベルの文法的な情報のみでは困難なので，本論文では，便宜的に固有名詞も「普通名詞」とみなす．
用言の「動詞」と「形容詞」には「品詞細分類」は設定されていない．
代わりに活用を扱うために活用型と活用形が与えられる．
活用型は活用のタイプに基づく分類であり，活用形は個々の具体的な活用形態を指す．
例えば，「ググる」の活用型は「子音動詞ラ行」で，「ググって」の活用形は「タ系連用テ形」，「ググら」は「未然形」となる．
未知語獲得タスクにおける品詞は，「品詞」，「品詞細分類」，「活用型」の適当な組である．
簡単のために，名詞については「品詞細分類」，動詞と形容詞については「活用型」で呼ぶ．
例えば，「ググる」の品詞は「子音動詞ラ行」となる．
基本語彙は既に人手により辞書登録されているので，獲得対象をオープンクラスの品詞に絞り込める．
つまり，「来る」などの不規則変化動詞や助詞，助動詞などの付属語は獲得対象から除外される．
本論文では，名詞，動詞，および形容詞を獲得対象の品詞とする．
副詞もオープンクラスとみなせるが，今回は明示的な獲得対象としない．
副詞と名詞の識別も，形態レベルの情報だけでは困難だからである．
副詞の認識は今後の課題とする．
以上をまとめると，獲得対象の品詞は表[REF_tb:pos-list]の15種類となる．
形態素の単位認定基準，つまりある言葉が1形態素か否かは自明でない．
例えば，「ミンククジラ」のように構成的な名詞や「宣べ伝える」のような複合動詞を1形態素とするか分割すべきか明らかでない．
実際，人手で整備された既存の形態素解析用の辞書も，単位に一貫性があるとは言い難い．
他の単位認定基準としては，『現代日本語書き言葉均衡コーパス』が人間の作業者向けに詳細な基準を設けている[CITE]．
しかし，この基準は煩雑で，しかも意味レベルの情報も利用しているため，プログラムに落とし込んで未知語の自動獲得に利用することは困難である．
本論文では，厳密な単位認定にはこだわらないとする．
未知語獲得タスクに対して，我々はオンラインによる解法を提案する．
図[REF_fig:system]にオンライン未知語獲得のシステム構成を示す．
形態素解析器自体は，通常通り入力文に対して形態素列を出力する．
ただし，辞書として，人手で整備した基本語彙辞書の他に，自動獲得辞書も用いる．
形態素解析の裏では未知語獲得器が動く．
獲得器は，形態素解析器が出力する形態素列を文ごとに受け取り，そこから未知語を抽出する．
獲得器は，適当な時点で未知語を獲得し，形態素解析器の自動獲得辞書を更新する．
辞書更新により未知語獲得が以降の解析に反映される．
獲得器には高い精度での未知語獲得が要求される．
獲得された未知語の辞書へのフィードバックに人手が介在しないが，誤獲得が解析に悪影響を及ぼすことは避けたいからである．
獲得器は，未知語の用例を蓄積することで，それまでに解析されたテキストを獲得に利用できる．
未解析のテキストは獲得に利用できないが，見方を変えれば，次に読むテキストをあらかじめ決める必要がないことを意味する．
従って，獲得の都合に応じて対象テキストを動的に変更するという応用も可能である．
オンライン未知語獲得を実現するために，以下のサブタスクを設定する．
各文の形態素解析結果から未知語の用例を検出する．
検出された各未知語用例に対して，語幹と品詞からなる辞書項目の候補を列挙する．
各未知語用例に対して，最適な辞書項目の候補を選択する．
選択は，過去に検出された用例を蓄積しておき，それら複数用例の比較により行う．
比較される用例が増え，曖昧性が十分に解消できた時点で獲得し，形態素解析器の辞書を更新する．
未知語「ググる」の獲得を例にシステムの挙動を説明する．
「ググる」は語幹「ググ」と品詞「子音動詞ラ行」からなる．
テキストを読み進めて，ある時点で文「なんとなくググってみた．
」が入ってきたとする．
獲得器は，まず，この文の「ググ」を手がかりに未知語用例を検出する．
次に，この用例に対して考えられる辞書項目の候補を列挙する．
辞書項目の候補としては，語幹「ググ」と品詞「子音動詞ラ行」以外にも，同じ語幹で「子音動詞ワ行」，語幹「ググって」と品詞「子音動詞マ行」，語幹「なんとなくググ」と品詞「子音動詞ラ行」なども考えられる．
こうした複数の候補の中から正しい候補を選択する必要があるが，この1用例だけを見ても正しい候補を判断しがたい．
そこで獲得器は判断を保留し，用例を記憶に蓄えておく．
さらにテキストを読み進めると，「ググらずに答える．
」という文が入力される．
同様に検出と列挙を行ったのち，「ググってみた」の用例を記憶から取り出して，「ググらず」と比較する．
すると，両者を共通に解釈できる辞書項目の候補は語幹「ググ」と品詞「子音動詞ラ行」のみである．
このように複数の用例を比較して曖昧性を解消する．
比較する用例が増え，選択された候補が適当な終了条件を満たしたとき，その候補を獲得する．
これにより，「ググる」が自動獲得辞書に追加される．
オンライン未知語獲得のサブタスクのうち，本論文では列挙と選択について詳述する．
検出タスクについては簡単な手法を説明するにとどめる．
未知語検出は各文から未知語の用例を検出するタスクである．
文は，形態素解析結果に基づく形態素列，または文字列として表現される．
タスクの入力は，解析器が返す文の形態素列である．
一方出力は，未知語用例に対応する文の部分文字列であり，その範囲を[MATH]とする．
ただし，[MATH]が未知語用例の語幹の範囲[MATH]と厳密に一致する必要はない．
辞書項目，つまり語幹と品詞の組の候補の列挙は次の列挙タスクで行うが，どの程度の正確さで検出が必要かは列挙のアルゴリズムに依存する．
[REF_sec:enumeration-method]節で述べる列挙アルゴリズムは，語幹の境界候補の列挙を[MATH]を基点に行うので，検出範囲は[MATH]を満たす必要がある．
日本語において未知語用例の検出は自明なタスクではない．
一番単純な検出手法として，既知語とテキストの文字列マッチングを行い，マッチしない箇所を検出するというものが考えられる．
しかし，日本語の単純な音韻体系がわざわいして，多くの未知語に対して無関係な既知語がマッチし，検出漏れが起きる．
この現象は，形態素解析器が持つ文法知識を利用することである程度抑えられる．
形態素解析器は，入力文に対して，辞書引きと未知語処理により，出力すべき形態素の候補を列挙する．
未知語処理により列挙される形態素候補を未定義語と呼ぶ．
JUMANでは，字種に基づく簡単なヒューリスティクスが採用されている．
例えば，カタカナの連続が一つの形態素候補とされる．
これにより，未知語「ググる」を含む入力文「ググってみた．
」に対して，未定義語「ググ」が形態素候補となり，これを含むパスが出力に選ばれる．
従って，形態素解析結果中の未定義語[MATH]を検出範囲[MATH]とする．
ただし，[MATH]と[MATH]は，形態素[MATH]の文字列表現における開始・終了位置である．
形態素解析を用いる検出手法でも検出されない未知語用例が存在する．
例えば，「アブラハム」は「アブラ」（油）と「ハム」に分割され，「うざい」は「う」（卯／雨／鵜）と「ざい」（剤／在／材／罪／剤）に分割される．
こうした過分割未知語の検出は今後の課題とする．
列挙は，検出された各用例に対して，文中の前後の文脈を利用して，考えられる辞書項目の候補を列挙するタスクである．
辞書項目の候補は語幹と品詞からなる．
ここで，語幹の同定は前方境界と後方境界の二つの同定を意味する．
例えば，「なんとなくググってみた」の場合，「なく」と「ググ」の間に前方境界が，「ググ」と「って」の間に後方境界が引かれる．
そこで，辞書項目の候補を前方境界，後方境界，品詞の組で表現する．
列挙される候補は，効率よく正解候補を選択するためには，なるべく数が少ないことが望ましい．
選択は，各未知語用例に対して，最適な辞書項目の候補を選択するタスクである．
この際，検出済みの未知語用例を蓄積することで，複数の用例が比較できる．
選択タスクの実現には，最適な候補を選択する基準と，最終的に獲得を判断するための終了条件が必要となる．
辞書項目の列挙において，候補絞り込みの手がかりとして形態論的制約を利用する．
日本語は膠着語であり，形態素は，その文法的な役割に応じて，接尾辞，助動詞，助詞などに後続される．
この際，用言は後続する形態素に応じて活用形を変える．
また，形態素同士の連接には品詞に応じて制約が働く．
例えば，助詞「を」は，「走る」の基本連用形「走り」に後続して「走りを」という形は取り得るが，未然形「走ら」に後続して「走らを」とはならない．
このような連接に関する制限を形態論的制約と呼ぶ．
この形態論的制約を列挙に利用するためにサフィックスを導入する．
サフィックスとは，語幹に後続し得る文字列であり，自立語の語尾（あれば）と後続する付属語列を連結したものである．
サフィックスの例を表[REF_tb:naming-conventions]に示す．
いま，ある文字列に対してあるサフィックスが後続したとする．
このとき，そのサフィックスの直前が自立語の語幹の後方境界の可能性がある．
サフィックスの集合は生テキストから収集される．
ここで，形態素解析が既知語について十分に高精度であることを利用する．
具体的には，テキストを形態素解析し，既知語に後続するサフィックスを収集する．
こうして集められたサフィックスを品詞ごとに集約する．
いま，サフィックスが十分に大きなコーパスから収集されたとき，ある品詞に属す形態素の語幹に後続し得るサフィックスは，品詞に対応するサフィックス集合中のいずれかに限定される．
従って，サフィックスを候補列挙に用いることで，後方境界と同時に品詞の候補が列挙できる．
なおかつ，品詞候補を形態論的制約を満たすものに限定できる．
ただし，一般に，サフィックスは複数の品詞に後続し得る．
例えば，サフィックス「をも」は母音動詞にもサ変名詞にも後続できる．
サフィックスの収集には，Kawahara et al.の手法により編纂されたウェブコーパスを用いる[CITE]．
ただし，予備実験により，この大規模コーパスでもサフィックスの異なり数が収束しないと判明した．
「させられかねなかっただろう」のような低頻度の長いサフィックスが存在するからである．
そこで，サフィックスの最大長を5文字とし，それより長いサフィックスは先頭の5文字で統合する．
実験では，約1億ページから約66万の異なるサフィックスを得た．
サフィックスあたりの品詞数は平均で1.33であった．
サフィックスを用いて辞書項目の列挙を行う．
まず，列挙に利用する文中の前後の文脈，つまり前方境界と後方境界の探索範囲を文節を用いて限定する．
文節については，構文解析器KNPが係り受け解析の前処理として文節まとめあげを行うので，その結果を利用する．
検出された未知語用例が属す文節，および最大で前後2文節を探索範囲とする．
ただし，文頭，文末や句読点で探索を打ち切る．
後方境界と品詞の組の候補を図[REF_fig:suffix-match]のようにサフィックスを用いて列挙する．
検出範囲の開始位置[MATH]から探索範囲の終端までの各位置で，サフィックスのマッチングを行う．
サフィックスがマッチしたとき，サフィックス開始位置が後方境界の候補となり，サフィックスに対応する1個以上の品詞が候補となる．
長さの異なる複数のサフィックスがマッチした場合，以下の規則で採用するサフィックスを選択する．
原則として長い候補を優先するが，サフィックスの終了位置が文節境界と一致しなければならない．
ただし，サフィックスは最大5文字としているので，5文字のサフィックスがあれば無条件で採用する．
また，サフィックス以外の手がかりとして，以下を前方境界と後方境界の候補列挙に利用する．
文頭と文末
句読点や記号
「御」などの接頭辞
「首相」などの末尾要素
KNPにより与えられる文節境界
これらの手がかりにより列挙される候補のうち，後方境界については，特殊な品詞``EOB''を与える．
``EOB''はサフィックスなしに語幹単独で出現し得ることを示す．
例えば，「グーグル」などの名詞には句読点などが直接後続し得る．
また，母音動詞は基本連用形（名詞化）が語幹と同形なので，語幹単独で出現し得るとみなせる．
一方，「ググる」などの子音動詞ラ行は語幹単独では出現しない．
``EOB''は選択タスクにおいて語幹単独で出現し得る品詞に展開される．
辞書項目の選択には，それまでに検出された複数の用例を利用する．
具体的には，新たに入ってきた用例について，その用例と同じ辞書項目を表す可能性のある用例群を記憶から取り出して比較する．
ただし，真に同じ辞書項目を表す用例のみを取り出すのは難しいので，ひとまず前方境界を共有する用例群を取り出し，後の処理で絞り込みを行う．
また，獲得に至らなかった用例は記憶に追加し，獲得時には使われた用例群を削除する．
用例の効率的な管理のためにトライを利用する．
各用例の格納は，前方境界の候補数だけ行う．
トライのキーとして，各前方境界候補と，それより右で最左の後方境界候補に挟まれた文字列を用いる．
例えば，図[REF_fig:suffix-match]の用例に対して，「ググ」と「何となくググ」をキーとして2箇所に格納する．
用例取り出し時にはキーを使ってトライをたどり，途中のノード，およびキーの末端ノードの子孫に格納された用例群を取り出す．
辞書項目の候補，つまり前方境界，後方境界および品詞の候補のうち，最適な候補の選択を記憶から取り出された用例群の比較により行う．
図[REF_fig:selection]に選択の擬似コードを示す．
候補の絞り込みは前方境界，後方境界，品詞の順で行う．
また，語幹については短い候補（前方境界は右，後方境界は左）から順に調べる．
用例[MATH]の各前方境界候補に対して，まず記憶から前方境界[MATH]を共有する用例群[MATH]を取り出す(retrieveExamples)．
次に，用例群の比較により，若干の後方境界候補の足切りを行う(refineRearBoundaryCandidates)．
これにより，語幹の長さが0の候補や，後述の終了条件を満たさないことが明らかな候補を取り除く．
残った各後方境界候補[MATH]に対して，品詞の絞り込みを行う(refinePOSCandidates)．
品詞候補が[MATH]一つに絞り込まれ，その候補が獲得の終了条件を満たすなら，候補[MATH]を獲得する．
選択の方針は，単純に，多くの用例をうまく説明できる候補を選ぶというものであり，絞り込みは用例群の包含関係により行う．
refinePOSCandidatesでは，[MATH]を共有する用例群中の被覆率が閾値以上の品詞候補を選ぶ．
ただし，「普通名詞」，「サ変名詞」，「ナ形容詞」は区別が明確でなく，また，「母音動詞」の「基本連用形」と「普通名詞」の区別は困難なため，これらの品詞のみが候補として残った場合には「普通名詞」を採用する．
終了条件は，候補[MATH]を共有する用例群について，次の二つが満たされる場合とする．
一つ目は前方境界の妥当性のチェックである．
具体的には，句読点などの明らかな境界マーカーから前方境界が得られた候補の割合が閾値以上とする．
例えば，未知語「新撰組」に対して，形態素解析が「新」を接頭辞と解釈するため，常に「撰組」が辞書項目の候補となる．
選択アルゴリズムは短い候補を優先するので，「新撰組」よりも先に「撰組」が調べられる．
しかし，「撰組」の直前に句読点等が来る用例はないので，「撰組」は獲得されない．
二つ目は活用型の異なり数が閾値以上という条件である．
これにより，品詞が偶発的に選択されたのではなく，実際に該当品詞として使われていることを確認する．
品詞分類について先行研究との簡単な比較を示す．
Mori et al.の後ろの「文字列」と福島・鍜治らの「後続するひらがなn-gram」，および桑江らの「最長後続ひらがな列」は，本論文のサフィックスと同様の働きをする[CITE]．
Mori et al.は前後の文字列とその頻度をベクトルで表現し，語幹候補と品詞モデルとのベクトル間の距離の近さにより品詞を判定している．
しかし，同じ品詞に属す形態素が本当に似たベクトルを取るのだろうか．
直観的には，品詞は大雑把な分類であり，同じ品詞に属す形態素でも振る舞いにばらつきがありそうに思われる．
そこで，ウェブコーパスを対象に簡単な実験を行った．
まず，コーパスの形態素解析結果から既知語に後続するサフィックスを収集する．
次に，サフィックスを各形態素ごとに集約し，形態素ごとの後続サフィックスの頻度分布を求める．
同様にして，形態素が属す品詞ごとに，後続サフィックスの頻度分布を求める．
そして，各形態素と品詞との間で，後続サフィックスの頻度分布の近さを求める．
ただし，頻度分布の近さの尺度としてSkew divergence [MATH]を用いる[CITE]．
s_\alpha(q, r) & = D_{KL} (r || \alpha q + (1 - \alpha) r),
D_{KL} (q||r) & = \sum_y q(y) (\log q(y) - \log r(y))
ここで，[MATH]，[MATH]はサフィックスの頻度分布とし，[MATH]とする．
図[REF_fig:divergence]に，「子音動詞ラ行」の例を示す．
横軸は「子音動詞ラ行」の各形態素の絶対頻度を表し，縦軸は各形態素の，「母音動詞」との近さと「子音動詞ラ行」との近さとの「差」を表す．
低頻度区間では，二つの近さの差が小さく，近さによる品詞判定では識別が難しいと予想される形態素が目立つ．
それだけでなく，高頻度区間でも差が小さい形態素が散見される．
従って，出現頻度が大きくても，近さによる品詞判定が難しいと予想される場合が存在する．
福島・鍜治らは品詞識別にSVMを用い，素性として後続するひらがなn-gramを与える．
素性の値に福島らは頻度，鍜治らは出現したか否かの2値を使う．
SVMは識別器であり，品詞内の近さよりも品詞間の差異を学習すると期待される．
一方，提案手法は，サフィックスの頻度には注目せず，個々のサフィックスを品詞リストに写像する．
サフィックスは形態論的制約を満たすか否かの2値を表現しており，候補列挙の時点で，制約を満たさない品詞は候補から除外される．
このように，品詞の絞り込みが各用例に対して行われるので，単純に多くの用例を説明できる候補を選ぶだけで品詞分類が行える．
また，提案手法は一つの語幹に対応する品詞は一つという仮定を置いている．
これに対し，Mori et al.と桑江らは，「楽し-い」と「楽し-む」のように，一つの語幹が複数の品詞に属す可能性を明示的にモデル化している．
しかし，「楽し-い」と「楽し-む」のような派生関係にある形態素の品詞の衝突は，基本語彙が登録済みのため，極めてまれと推測される．
無関係な形態素同士の偶発的な衝突については，提案手法はテキストを逐次的に解析するため，同一ドメインのテキストを読んでいる場合，特に起きにくいと推測される．
獲得された未知語が実際には2個以上の形態素からなる可能性がある．
未知語は比較的少数の用例から獲得するため，未知語[MATH]が，観測された用例中でたまたま[MATH]という連続で現れていた場合，[MATH]を1形態素として獲得してしまう．
例えば，複合語「顆粒タイプ」が未知語「顆粒」よりも先に獲得されるかもしれない．
この問題に対処するために，未知語獲得時に，獲得済みの形態素が獲得形態素によって分割できるかを調べ，できる場合にはその形態素を辞書から削除する．
現在のところ，分割可能性の検査には形態素解析器を用いる．
これにより形態素解析器に記述された制約知識を利用する．
まず，分割対象形態素の候補列挙は単純な文字列マッチングにより行う．
次に，候補を一時的に辞書から取り除いた状態で，その候補の形態素解析を行い，獲得形態素によって分割されなかった場合に候補を辞書に戻す．
未知語獲得とは，未知語について，テキスト中の一つ以上の用例から辞書項目を帰納的に生成するタスクである．
ここで，辞書項目は辞書の項目として記述される形態素であり，テキスト中に出現したその形態素を用例とよぶ．
例えば，未知語「ググる」について，「なんとなくググってみた．
」や「ググらずに答える．
」といったテキスト中の用例から辞書項目を生成する．
ただし，個々の用例の解釈には曖昧性があり，そうした曖昧性を解消することによって辞書項目が生成される．
辞書項目の生成には語幹と品詞の同定が必要となる．
「ググる」の例にあるように，動詞や形容詞は文法的役割に応じて形態変化を起こすが，この形態変化は活用という概念によって処理される．
活用する形態素は語幹と語尾からなる．
語幹は不変だが，語尾は活用に応じて変化する．
例えば，「ググって」は語幹「ググ」と語尾「って」からなる．
名詞は活用せず，語幹のみからなる．
品詞は形態素解析用に定義されたものに基づく．
ただし，既存の品詞は人手での付与が前提となっており，形態，構文，意味レベルの情報が混在している．
未知語獲得タスクにおいて，いきなり意味レベルの情報を獲得するのは難しいため，本論文では，ひとまず形態レベルの情報の獲得を目指す．
そのために，品詞分類を整理する．
以下の説明は形態素解析器JUMANが採用する品詞体系に基づく．
品詞体系の設定方法には様々な流儀があるため一般化が難しいが，少なくともipadicの品詞体系でも同様の議論が成り立つことは容易に想像できる．
品詞は「品詞」，「品詞細分類」，「活用型」，「活用形」の4種類からなる．
「品詞」には「名詞」，「動詞」，「形容詞」などがある．
「名詞」の「品詞細分類」には，「普通名詞」や「サ変名詞」の他，固有名詞用の「固有名詞」，「組織名」，「地名」，「人名」などがある．
しかし，固有名詞と普通名詞の識別は，形態レベルの文法的な情報のみでは困難なので，本論文では，便宜的に固有名詞も「普通名詞」とみなす．
用言の「動詞」と「形容詞」には「品詞細分類」は設定されていない．
代わりに活用を扱うために活用型と活用形が与えられる．
活用型は活用のタイプに基づく分類であり，活用形は個々の具体的な活用形態を指す．
例えば，「ググる」の活用型は「子音動詞ラ行」で，「ググって」の活用形は「タ系連用テ形」，「ググら」は「未然形」となる．
未知語獲得タスクにおける品詞は，「品詞」，「品詞細分類」，「活用型」の適当な組である．
簡単のために，名詞については「品詞細分類」，動詞と形容詞については「活用型」で呼ぶ．
例えば，「ググる」の品詞は「子音動詞ラ行」となる．
基本語彙は既に人手により辞書登録されているので，獲得対象をオープンクラスの品詞に絞り込める．
つまり，「来る」などの不規則変化動詞や助詞，助動詞などの付属語は獲得対象から除外される．
本論文では，名詞，動詞，および形容詞を獲得対象の品詞とする．
副詞もオープンクラスとみなせるが，今回は明示的な獲得対象としない．
副詞と名詞の識別も，形態レベルの情報だけでは困難だからである．
副詞の認識は今後の課題とする．
以上をまとめると，獲得対象の品詞は表[REF_tb:pos-list]の15種類となる．
形態素の単位認定基準，つまりある言葉が1形態素か否かは自明でない．
例えば，「ミンククジラ」のように構成的な名詞や「宣べ伝える」のような複合動詞を1形態素とするか分割すべきか明らかでない．
実際，人手で整備された既存の形態素解析用の辞書も，単位に一貫性があるとは言い難い．
他の単位認定基準としては，『現代日本語書き言葉均衡コーパス』が人間の作業者向けに詳細な基準を設けている[CITE]．
しかし，この基準は煩雑で，しかも意味レベルの情報も利用しているため，プログラムに落とし込んで未知語の自動獲得に利用することは困難である．
本論文では，厳密な単位認定にはこだわらないとする．
未知語獲得タスクに対して，我々はオンラインによる解法を提案する．
図[REF_fig:system]にオンライン未知語獲得のシステム構成を示す．
形態素解析器自体は，通常通り入力文に対して形態素列を出力する．
ただし，辞書として，人手で整備した基本語彙辞書の他に，自動獲得辞書も用いる．
形態素解析の裏では未知語獲得器が動く．
獲得器は，形態素解析器が出力する形態素列を文ごとに受け取り，そこから未知語を抽出する．
獲得器は，適当な時点で未知語を獲得し，形態素解析器の自動獲得辞書を更新する．
辞書更新により未知語獲得が以降の解析に反映される．
獲得器には高い精度での未知語獲得が要求される．
獲得された未知語の辞書へのフィードバックに人手が介在しないが，誤獲得が解析に悪影響を及ぼすことは避けたいからである．
獲得器は，未知語の用例を蓄積することで，それまでに解析されたテキストを獲得に利用できる．
未解析のテキストは獲得に利用できないが，見方を変えれば，次に読むテキストをあらかじめ決める必要がないことを意味する．
従って，獲得の都合に応じて対象テキストを動的に変更するという応用も可能である．
オンライン未知語獲得を実現するために，以下のサブタスクを設定する．
各文の形態素解析結果から未知語の用例を検出する．
検出された各未知語用例に対して，語幹と品詞からなる辞書項目の候補を列挙する．
各未知語用例に対して，最適な辞書項目の候補を選択する．
選択は，過去に検出された用例を蓄積しておき，それら複数用例の比較により行う．
比較される用例が増え，曖昧性が十分に解消できた時点で獲得し，形態素解析器の辞書を更新する．
未知語「ググる」の獲得を例にシステムの挙動を説明する．
「ググる」は語幹「ググ」と品詞「子音動詞ラ行」からなる．
テキストを読み進めて，ある時点で文「なんとなくググってみた．
」が入ってきたとする．
獲得器は，まず，この文の「ググ」を手がかりに未知語用例を検出する．
次に，この用例に対して考えられる辞書項目の候補を列挙する．
辞書項目の候補としては，語幹「ググ」と品詞「子音動詞ラ行」以外にも，同じ語幹で「子音動詞ワ行」，語幹「ググって」と品詞「子音動詞マ行」，語幹「なんとなくググ」と品詞「子音動詞ラ行」なども考えられる．
こうした複数の候補の中から正しい候補を選択する必要があるが，この1用例だけを見ても正しい候補を判断しがたい．
そこで獲得器は判断を保留し，用例を記憶に蓄えておく．
さらにテキストを読み進めると，「ググらずに答える．
」という文が入力される．
同様に検出と列挙を行ったのち，「ググってみた」の用例を記憶から取り出して，「ググらず」と比較する．
すると，両者を共通に解釈できる辞書項目の候補は語幹「ググ」と品詞「子音動詞ラ行」のみである．
このように複数の用例を比較して曖昧性を解消する．
比較する用例が増え，選択された候補が適当な終了条件を満たしたとき，その候補を獲得する．
これにより，「ググる」が自動獲得辞書に追加される．
オンライン未知語獲得のサブタスクのうち，本論文では列挙と選択について詳述する．
検出タスクについては簡単な手法を説明するにとどめる．
未知語検出は各文から未知語の用例を検出するタスクである．
文は，形態素解析結果に基づく形態素列，または文字列として表現される．
タスクの入力は，解析器が返す文の形態素列である．
一方出力は，未知語用例に対応する文の部分文字列であり，その範囲を[MATH]とする．
ただし，[MATH]が未知語用例の語幹の範囲[MATH]と厳密に一致する必要はない．
辞書項目，つまり語幹と品詞の組の候補の列挙は次の列挙タスクで行うが，どの程度の正確さで検出が必要かは列挙のアルゴリズムに依存する．
[REF_sec:enumeration-method]節で述べる列挙アルゴリズムは，語幹の境界候補の列挙を[MATH]を基点に行うので，検出範囲は[MATH]を満たす必要がある．
日本語において未知語用例の検出は自明なタスクではない．
一番単純な検出手法として，既知語とテキストの文字列マッチングを行い，マッチしない箇所を検出するというものが考えられる．
しかし，日本語の単純な音韻体系がわざわいして，多くの未知語に対して無関係な既知語がマッチし，検出漏れが起きる．
この現象は，形態素解析器が持つ文法知識を利用することである程度抑えられる．
形態素解析器は，入力文に対して，辞書引きと未知語処理により，出力すべき形態素の候補を列挙する．
未知語処理により列挙される形態素候補を未定義語と呼ぶ．
JUMANでは，字種に基づく簡単なヒューリスティクスが採用されている．
例えば，カタカナの連続が一つの形態素候補とされる．
これにより，未知語「ググる」を含む入力文「ググってみた．
」に対して，未定義語「ググ」が形態素候補となり，これを含むパスが出力に選ばれる．
従って，形態素解析結果中の未定義語[MATH]を検出範囲[MATH]とする．
ただし，[MATH]と[MATH]は，形態素[MATH]の文字列表現における開始・終了位置である．
形態素解析を用いる検出手法でも検出されない未知語用例が存在する．
例えば，「アブラハム」は「アブラ」（油）と「ハム」に分割され，「うざい」は「う」（卯／雨／鵜）と「ざい」（剤／在／材／罪／剤）に分割される．
こうした過分割未知語の検出は今後の課題とする．
列挙は，検出された各用例に対して，文中の前後の文脈を利用して，考えられる辞書項目の候補を列挙するタスクである．
辞書項目の候補は語幹と品詞からなる．
ここで，語幹の同定は前方境界と後方境界の二つの同定を意味する．
例えば，「なんとなくググってみた」の場合，「なく」と「ググ」の間に前方境界が，「ググ」と「って」の間に後方境界が引かれる．
そこで，辞書項目の候補を前方境界，後方境界，品詞の組で表現する．
列挙される候補は，効率よく正解候補を選択するためには，なるべく数が少ないことが望ましい．
選択は，各未知語用例に対して，最適な辞書項目の候補を選択するタスクである．
この際，検出済みの未知語用例を蓄積することで，複数の用例が比較できる．
選択タスクの実現には，最適な候補を選択する基準と，最終的に獲得を判断するための終了条件が必要となる．
辞書項目の列挙において，候補絞り込みの手がかりとして形態論的制約を利用する．
日本語は膠着語であり，形態素は，その文法的な役割に応じて，接尾辞，助動詞，助詞などに後続される．
この際，用言は後続する形態素に応じて活用形を変える．
また，形態素同士の連接には品詞に応じて制約が働く．
例えば，助詞「を」は，「走る」の基本連用形「走り」に後続して「走りを」という形は取り得るが，未然形「走ら」に後続して「走らを」とはならない．
このような連接に関する制限を形態論的制約と呼ぶ．
この形態論的制約を列挙に利用するためにサフィックスを導入する．
サフィックスとは，語幹に後続し得る文字列であり，自立語の語尾（あれば）と後続する付属語列を連結したものである．
サフィックスの例を表[REF_tb:naming-conventions]に示す．
いま，ある文字列に対してあるサフィックスが後続したとする．
このとき，そのサフィックスの直前が自立語の語幹の後方境界の可能性がある．
サフィックスの集合は生テキストから収集される．
ここで，形態素解析が既知語について十分に高精度であることを利用する．
具体的には，テキストを形態素解析し，既知語に後続するサフィックスを収集する．
こうして集められたサフィックスを品詞ごとに集約する．
いま，サフィックスが十分に大きなコーパスから収集されたとき，ある品詞に属す形態素の語幹に後続し得るサフィックスは，品詞に対応するサフィックス集合中のいずれかに限定される．
従って，サフィックスを候補列挙に用いることで，後方境界と同時に品詞の候補が列挙できる．
なおかつ，品詞候補を形態論的制約を満たすものに限定できる．
ただし，一般に，サフィックスは複数の品詞に後続し得る．
例えば，サフィックス「をも」は母音動詞にもサ変名詞にも後続できる．
サフィックスの収集には，Kawahara et al.の手法により編纂されたウェブコーパスを用いる[CITE]．
ただし，予備実験により，この大規模コーパスでもサフィックスの異なり数が収束しないと判明した．
「させられかねなかっただろう」のような低頻度の長いサフィックスが存在するからである．
そこで，サフィックスの最大長を5文字とし，それより長いサフィックスは先頭の5文字で統合する．
実験では，約1億ページから約66万の異なるサフィックスを得た．
サフィックスあたりの品詞数は平均で1.33であった．
サフィックスを用いて辞書項目の列挙を行う．
まず，列挙に利用する文中の前後の文脈，つまり前方境界と後方境界の探索範囲を文節を用いて限定する．
文節については，構文解析器KNPが係り受け解析の前処理として文節まとめあげを行うので，その結果を利用する．
検出された未知語用例が属す文節，および最大で前後2文節を探索範囲とする．
ただし，文頭，文末や句読点で探索を打ち切る．
後方境界と品詞の組の候補を図[REF_fig:suffix-match]のようにサフィックスを用いて列挙する．
検出範囲の開始位置[MATH]から探索範囲の終端までの各位置で，サフィックスのマッチングを行う．
サフィックスがマッチしたとき，サフィックス開始位置が後方境界の候補となり，サフィックスに対応する1個以上の品詞が候補となる．
長さの異なる複数のサフィックスがマッチした場合，以下の規則で採用するサフィックスを選択する．
原則として長い候補を優先するが，サフィックスの終了位置が文節境界と一致しなければならない．
ただし，サフィックスは最大5文字としているので，5文字のサフィックスがあれば無条件で採用する．
また，サフィックス以外の手がかりとして，以下を前方境界と後方境界の候補列挙に利用する．
文頭と文末
句読点や記号
「御」などの接頭辞
「首相」などの末尾要素
KNPにより与えられる文節境界
これらの手がかりにより列挙される候補のうち，後方境界については，特殊な品詞``EOB''を与える．
``EOB''はサフィックスなしに語幹単独で出現し得ることを示す．
例えば，「グーグル」などの名詞には句読点などが直接後続し得る．
また，母音動詞は基本連用形（名詞化）が語幹と同形なので，語幹単独で出現し得るとみなせる．
一方，「ググる」などの子音動詞ラ行は語幹単独では出現しない．
``EOB''は選択タスクにおいて語幹単独で出現し得る品詞に展開される．
辞書項目の選択には，それまでに検出された複数の用例を利用する．
具体的には，新たに入ってきた用例について，その用例と同じ辞書項目を表す可能性のある用例群を記憶から取り出して比較する．
ただし，真に同じ辞書項目を表す用例のみを取り出すのは難しいので，ひとまず前方境界を共有する用例群を取り出し，後の処理で絞り込みを行う．
また，獲得に至らなかった用例は記憶に追加し，獲得時には使われた用例群を削除する．
用例の効率的な管理のためにトライを利用する．
各用例の格納は，前方境界の候補数だけ行う．
トライのキーとして，各前方境界候補と，それより右で最左の後方境界候補に挟まれた文字列を用いる．
例えば，図[REF_fig:suffix-match]の用例に対して，「ググ」と「何となくググ」をキーとして2箇所に格納する．
用例取り出し時にはキーを使ってトライをたどり，途中のノード，およびキーの末端ノードの子孫に格納された用例群を取り出す．
辞書項目の候補，つまり前方境界，後方境界および品詞の候補のうち，最適な候補の選択を記憶から取り出された用例群の比較により行う．
図[REF_fig:selection]に選択の擬似コードを示す．
候補の絞り込みは前方境界，後方境界，品詞の順で行う．
また，語幹については短い候補（前方境界は右，後方境界は左）から順に調べる．
用例[MATH]の各前方境界候補に対して，まず記憶から前方境界[MATH]を共有する用例群[MATH]を取り出す(retrieveExamples)．
次に，用例群の比較により，若干の後方境界候補の足切りを行う(refineRearBoundaryCandidates)．
これにより，語幹の長さが0の候補や，後述の終了条件を満たさないことが明らかな候補を取り除く．
残った各後方境界候補[MATH]に対して，品詞の絞り込みを行う(refinePOSCandidates)．
品詞候補が[MATH]一つに絞り込まれ，その候補が獲得の終了条件を満たすなら，候補[MATH]を獲得する．
選択の方針は，単純に，多くの用例をうまく説明できる候補を選ぶというものであり，絞り込みは用例群の包含関係により行う．
refinePOSCandidatesでは，[MATH]を共有する用例群中の被覆率が閾値以上の品詞候補を選ぶ．
ただし，「普通名詞」，「サ変名詞」，「ナ形容詞」は区別が明確でなく，また，「母音動詞」の「基本連用形」と「普通名詞」の区別は困難なため，これらの品詞のみが候補として残った場合には「普通名詞」を採用する．
終了条件は，候補[MATH]を共有する用例群について，次の二つが満たされる場合とする．
一つ目は前方境界の妥当性のチェックである．
具体的には，句読点などの明らかな境界マーカーから前方境界が得られた候補の割合が閾値以上とする．
例えば，未知語「新撰組」に対して，形態素解析が「新」を接頭辞と解釈するため，常に「撰組」が辞書項目の候補となる．
選択アルゴリズムは短い候補を優先するので，「新撰組」よりも先に「撰組」が調べられる．
しかし，「撰組」の直前に句読点等が来る用例はないので，「撰組」は獲得されない．
二つ目は活用型の異なり数が閾値以上という条件である．
これにより，品詞が偶発的に選択されたのではなく，実際に該当品詞として使われていることを確認する．
品詞分類について先行研究との簡単な比較を示す．
Mori et al.の後ろの「文字列」と福島・鍜治らの「後続するひらがなn-gram」，および桑江らの「最長後続ひらがな列」は，本論文のサフィックスと同様の働きをする[CITE]．
Mori et al.は前後の文字列とその頻度をベクトルで表現し，語幹候補と品詞モデルとのベクトル間の距離の近さにより品詞を判定している．
しかし，同じ品詞に属す形態素が本当に似たベクトルを取るのだろうか．
直観的には，品詞は大雑把な分類であり，同じ品詞に属す形態素でも振る舞いにばらつきがありそうに思われる．
そこで，ウェブコーパスを対象に簡単な実験を行った．
まず，コーパスの形態素解析結果から既知語に後続するサフィックスを収集する．
次に，サフィックスを各形態素ごとに集約し，形態素ごとの後続サフィックスの頻度分布を求める．
同様にして，形態素が属す品詞ごとに，後続サフィックスの頻度分布を求める．
そして，各形態素と品詞との間で，後続サフィックスの頻度分布の近さを求める．
ただし，頻度分布の近さの尺度としてSkew divergence [MATH]を用いる[CITE]．
s_\alpha(q, r) & = D_{KL} (r || \alpha q + (1 - \alpha) r),
D_{KL} (q||r) & = \sum_y q(y) (\log q(y) - \log r(y))
ここで，[MATH]，[MATH]はサフィックスの頻度分布とし，[MATH]とする．
図[REF_fig:divergence]に，「子音動詞ラ行」の例を示す．
横軸は「子音動詞ラ行」の各形態素の絶対頻度を表し，縦軸は各形態素の，「母音動詞」との近さと「子音動詞ラ行」との近さとの「差」を表す．
低頻度区間では，二つの近さの差が小さく，近さによる品詞判定では識別が難しいと予想される形態素が目立つ．
それだけでなく，高頻度区間でも差が小さい形態素が散見される．
従って，出現頻度が大きくても，近さによる品詞判定が難しいと予想される場合が存在する．
福島・鍜治らは品詞識別にSVMを用い，素性として後続するひらがなn-gramを与える．
素性の値に福島らは頻度，鍜治らは出現したか否かの2値を使う．
SVMは識別器であり，品詞内の近さよりも品詞間の差異を学習すると期待される．
一方，提案手法は，サフィックスの頻度には注目せず，個々のサフィックスを品詞リストに写像する．
サフィックスは形態論的制約を満たすか否かの2値を表現しており，候補列挙の時点で，制約を満たさない品詞は候補から除外される．
このように，品詞の絞り込みが各用例に対して行われるので，単純に多くの用例を説明できる候補を選ぶだけで品詞分類が行える．
また，提案手法は一つの語幹に対応する品詞は一つという仮定を置いている．
これに対し，Mori et al.と桑江らは，「楽し-い」と「楽し-む」のように，一つの語幹が複数の品詞に属す可能性を明示的にモデル化している．
しかし，「楽し-い」と「楽し-む」のような派生関係にある形態素の品詞の衝突は，基本語彙が登録済みのため，極めてまれと推測される．
無関係な形態素同士の偶発的な衝突については，提案手法はテキストを逐次的に解析するため，同一ドメインのテキストを読んでいる場合，特に起きにくいと推測される．
獲得された未知語が実際には2個以上の形態素からなる可能性がある．
未知語は比較的少数の用例から獲得するため，未知語[MATH]が，観測された用例中でたまたま[MATH]という連続で現れていた場合，[MATH]を1形態素として獲得してしまう．
例えば，複合語「顆粒タイプ」が未知語「顆粒」よりも先に獲得されるかもしれない．
この問題に対処するために，未知語獲得時に，獲得済みの形態素が獲得形態素によって分割できるかを調べ，できる場合にはその形態素を辞書から削除する．
現在のところ，分割可能性の検査には形態素解析器を用いる．
これにより形態素解析器に記述された制約知識を利用する．
まず，分割対象形態素の候補列挙は単純な文字列マッチングにより行う．
次に，候補を一時的に辞書から取り除いた状態で，その候補の形態素解析を行い，獲得形態素によって分割されなかった場合に候補を辞書に戻す．
