オンライン未知語獲得について，獲得される未知語の精度，および未知語獲得の形態素解析への貢献を評価する．
基本語彙辞書として，形態素解析器JUMANのデフォルトの辞書を用いる．
この辞書は約3万の基本語彙を収録している．
表記ゆれを展開し，固有名詞を含めれば，語彙数は約12万となる．
獲得対象テキストとして，ドメインが限定されたコーパスを用いる．
話題を共有するテキストの方が，互いに無関係なテキストよりも未知語が集中的に出現すると期待されるからである．
実験では，検索エンジン基盤TSUBAKI [CITE]を用い，その検索結果をドメイン限定コーパスとみなす．
各クエリに対して，システムは検索結果のページを順に読み，未知語を獲得する．
獲得は千ページ目で打ち切り，同じ千ページを拡張された語彙を用いて再解析する．
クエリとしては，「捕鯨問題」，「赤ちゃんポスト」，「ジャスラック」，「ツンデレ」，および「アガリクス」を使用する．
獲得された未知語は，語幹と品詞の両方が正しい場合に正解とする．
ただし，[REF_sec:acquisition-task]章で述べたように，語幹の単位認定は難しい．
実際，Nagataと内元らは，単位認定の不一致が報告されたエラーの原因の一つとみなしている[CITE]．
単位認定の不一致を回避するために，正解コーパスとの単純比較ではなく，人手による判定を採用する．
未知語獲得の形態素解析への貢献の評価は次の手順で行う．
獲得対象テキストを基本語彙辞書と拡張された辞書の2通りで形態素解析する．
二つの解析結果を比較して，図[REF_fig:diff]のように単語分割の境界が一致しない箇所を抽出する．
これを``diff''ブロックとよぶ．
``diff''ブロックの正誤判定は，形態素への分割と，分割および品詞割り当ての2通りにより行う．
ただし，形態素境界は，明らかに誤っていない場合に正解とする．
評価には，クエリごとに，再解析により解析結果が変化した文の中から無作為に抽出した50文を用いる．
品詞の評価については，「普通名詞」と「サ変名詞」という名詞の「品詞細分類」を区別しない．
また，JUMANが未知語に与える特殊な品詞「未定義語」は名詞とみなす．
表[REF_tb:queries]にクエリごとの統計を示す．
再解析により変化した文の割合に大きなばらつきがある(0.43--9.26%)．
基本語彙辞書はこれまで新聞記事を対象に整備されてきたため，新聞記事と似ていないドメインほど未知語獲得の効果が大きい傾向がみられる．
獲得された未知語の精度は97.3--98.5%と高い．
しかも，獲得時点で利用した用例数の中央値は4--7に過ぎない．
先行研究では出現回数が10回未満の候補を信用できないとして無視していたことを考えると非常に小さな値である[CITE]．
図[REF_fig:frequency]に，獲得された未知語の頻度とその頻度の順位との関係を示す．
ここで，頻度は，拡張された辞書を用いた再解析結果から数えたものである．
順位の下位区間における急な落ち込みは，用例数の不足により獲得されていない未知語の影響と推測される．
図[REF_fig:process]に，獲得の経過を示す．
ここで，獲得未知語の累積出現数は，拡張された辞書を用いた再解析結果から数えたものである．
終了時点での蓄積されている用例数と未知語の累積出現数の比較から，検出された未知語用例がすべて真の未知語と仮定すると，提案手法で検出される未知語のうちおよそ半分が獲得されたと推定できる．
表[REF_tb:examples]に獲得された未知語の例を示す．
予想される通り，獲得された未知語の大半が名詞(94.1--100%)やカタカナのみからなる形態素(67.9--79.4%)である．
「タイーホ」や「ぱくる」など新聞記事にはあまり見られない俗語も獲得されている．
字種が混在する「ドジっ娘」や「シャ乱Q」は字種に基づく形態素解析の未知語処理では正しく解析できない．
「すごい」に対する「スゴい」，「解かる」に対する「解る」のように，登録済みの形態素の異表記もあった．
誤り例には，「パクられる」や「フラグが立つ」など明らかに構成的な表現を1形態素と認識しているものがある．
ただし，これらは，さらに未知語獲得を進めて，それぞれ「パクる」や「フラグ」が獲得された場合，分割可能性のチェックにより消される．
他には，副詞の「やっぱ」が名詞と誤認識された．
表[REF_tb:change-seg]に``diff''ブロックの評価結果を示す．
ほとんどのブロックが拡張された語彙によって正しく解析されている（E [MATH] CおよびC [MATH] C）．
一方，獲得による副作用は限定されている(C [MATH] E)．
従って，獲得された未知語が形態素解析の精度を改善することが示された．
形態素解析において，カタカナ未知語が短いカタカナ形態素によって分割されることがある．
例えば，基本語彙辞書のみを用いると，未知語「アブラハム」は「アブラ」と「ハム」に過分割される．
「アブラハム」は，[REF_sec:detection]節で述べた単純な検出手法では検出されず，従って獲得もされない．
また，未知語の獲得によって新たな過分割が発生し得る．
例えば，「サー」の獲得によって，「サーバー」が「サー」と既知の「バー」によって過分割されるようになる．
このような過分割の問題は，本論文が利用した形態レベルの文法的振る舞いだけを調べても解決できない．
他の手がかり，例えば，「サーバー」がserverという一つの外来語だから分割できないといった知識が必要となる．
提案手法では，カタカナ「イイ」のように語尾までカタカナで表記された用言は誤って名詞と認識される．
現在の形態素解析は語尾のひらがな表記を前提としている．
この仮定は新聞記事に対しては妥当だが，ウェブテキストに対しては無効であり，より柔軟な解析が必要になる．
ただし，こうした未知語の解析は元々誤っており，獲得によって形態素解析が悪化するわけではない．
未知語問題への2通りの解決策のうち，未知語モデルによる手法は，その利点として，低頻度語の正しい同定が強調されている[CITE]．
しかし，ウェブの出現により，ほとんど無尽蔵のテキストが入手できるようになった現在，限られた情報のみを用いた同定は不可欠ではない．
仮に，解析対象のテキストが少量で，未知語獲得を行うには用例の出現回数が足りないとしても，ウェブから解析対象テキストと関連するテキストを収集することで，用例の出現回数を増やすことができる．
ここで，バッチ処理[CITE]と異なる，オンライン獲得という特徴を生かせる．
すなわち，解析対象テキストから検出された用例にマークして，それらの用例が獲得に使われたか追跡することで，未知語が十分に獲得された時点で処理を停止させることができる．
最後に，残された課題を整理する．
[REF_sec:acquisition-task]章で整理したように，形態素に付与される様々な情報のうち，本論文はひとまず形態レベルの情報の獲得を目指した．
形態レベルの手がかりでは得られない知識としては，名詞と副詞の区別の他に，固有名詞と普通名詞の区別などがある．
特に名詞の細分類は固有表現認識や省略・照応解析に役立つと期待されるので，テキストからの自動獲得を目指したい．
本論文では形態素の単位認定にこだわらなかったが，獲得された未知語の中には構成的なものが含まれている．
参考までに，クエリ「ジャスラック」の獲得結果を調べたところ，判断に迷う場合を含めると10%弱(45/460)が複合語であった．
ただし，複合語の基準としては，JUMAN 4.0から5.0への変更時に行った複合語の整理を参考にした．
日本語の複合名詞は，文法的なマーカなしに構成要素が直接連結されるため，形態レベルの手がかりでは構成要素に分割できない．
細粒度での単位認定を実現するには，他の手がかりを利用する必要がある．
形態レベルでの未知語獲得については，検出が大きな課題として残っている．
なかでもひらがな表記の未知語は曖昧性が高く，形態素解析器によってより短い既知の形態素へ過分割されることが少なくない．
予備調査として，形態素解析結果のうち，[MATH]，[MATH]，[MATH]文字というパターンのひらがな形態素のペアのみを対象に，未知語検出の再現率を求めたところ，本論文の手法では31%にとどまることが判明している．
ひらがな表記の未知語は数の上では少なく，頻度の上でも異なり数でも，未知語の大半をカタカナ名詞が占める．
しかし，カタカナ名詞は形態素解析の未知語処理でほぼ問題なく同定できるのに対し，ひらがな未知語の解析誤りは応用に大きな悪影響を及ぼしやすい．
例えば，「ようつべ」が「よ」，「うつ」，「べ」に誤って分解され，「うつ」が動詞と解釈された場合，文節まとめあげにより「よ」と「うつ」，「うつ」と「べ」の間に文節境界が引かれ，これに基づき見当違いな係り受け解析が行われてしまう．
提案手法の利点の一つは，既知の形態素を改めて獲得しないことによる効率の良さだが，今後はこの利点を維持しつつ検出の再現率を上げていきたい．
