形態素解析は，文を形態素列に分割し，各形態素に品詞をタグ付けするタスクである．
形態素解析は自然言語処理における基盤技術であり，構文解析や情報検索といった応用を実現するうえで高い精度の達成が不可欠となる．
日本語の形態素解析では，あらかじめ定義された辞書を用いる手法が高い精度を達成している[CITE]．
この手法では，入力文は辞書引きにより得られた形態素のラティスに展開され，ラティス中の最適なパスが出力として選択される．
しかし，辞書に基づく形態素解析には，辞書にない形態素（未知語）の解析を誤りやすいという問題がある．
例えば，形態素解析器JUMANは，デフォルトの辞書を用いると，未知の動詞「ググる」を誤って「ググ」と「る」に分割する．
この未知語問題は，未知語を解析用の辞書に追加することで解決する．
しかし，人手による辞書登録はコストがかかるため，計算機による自動化が望まれる．
人手によらない未知語問題への解決策として，2通りの手法が提案されている．
ひとつ目の手法では，形態素解析における未知語モデルを改良する[CITE]．
日本語の形態素解析で広く用いられる未知語モデルは，字種に基づく簡単なヒューリスティクスだが，代わりに統計や機械学習に基づく未知語モデルを導入すると未知語同定の精度が向上する．
二つ目の手法では，テキストから未知語を自動獲得し，形態素解析用の辞書を拡張する[CITE]．
二つの手法を比べると，前者は入力文中の個々の未知語を同定しようとするのに対し，後者は同じ未知語のテキスト中での複数の使われ方を比較できるという点で異なる．
複数の使われ方の比較は未知語の同定に効果的と考えられる．
例えば「ようつべ」（YouTubeのスラング）という形態素を知らないまま，「ようつべって…」という文を解釈したいとする．
このとき，「ようつべ」は，未知の名詞以外にも，未知の動詞「ようつべる」とも解釈でき，いずれが正しいか判断しがたい．
同様に，別の文「ようつべとは，…」について，名詞「ようつべ」の他に，動詞「ようつぶ」の命令形とも解釈できる．
しかし，両者を見比べると，2文とも名詞「ようつべ」で解釈できることから，名詞という解釈がより自然だと推測できる．
従って，本論文では後者の手法を採用する．
ただし，両者は対立するものではなく，組み合わせることで，より高い解析精度が得られるようになると期待できる．
未知語獲得の従来手法はバッチ処理であり，コーパスをソートしてすべての部分文字列を調べる[CITE]．
しかし，この手法は効率が悪い．
なぜなら高頻度の形態素のほとんどが解析用の辞書に登録済みであり，一般に出現頻度でコーパスの90%以上を網羅している．
こうした既知の形態素を改めて獲得しても無駄になる．
これに対し，提案手法では，辞書に登録されていない形態素のみを獲得対象とする．
従来研究は，資源の制約から，主に小規模な新聞記事を対象に行われてきたが，近年，ウェブの出現により大規模なテキストが入手可能となっている．
それに伴い，自然言語処理の様々な分野でデータの大規模化による性能向上が報告されている[CITE]．
しかし，未知語獲得は，データの大規模化が単純に解決する性質の問題ではない．
未知語の中には，「ブログ」のように高頻度ながら登録が漏れているものもあるが，大部分がいわゆるロングテールに属す低頻度の形態素である．
こうした形態素の出現するテキストには偏りがあるだけでなく，データを増やすだけでは，次々と新たな未知語が出現してきりがない．
従って，とにかくデータを与えてそこから未知語を獲得するよりも，個々の未知語候補に着目し，それが獲得されるまでデータを読み込む方が自然である．
そもそも，未知語の同定のために，何千，何万もの使われ方を調べる必要はなく，直観的には，ほとんどの場合，10件程度を見比べればほぼ明らかではないかと思われる．
本論文では，オンライン未知語獲得という枠組みと，その具体的な実現手法を提案する．
オンライン未知語獲得では，バッチ処理ではなく，逐次的に入力されるテキストから未知語を獲得する．
形態素解析器自体は，通常通りテキストを文単位で解析し，形態素列を出力する．
異なる点は，解析の裏で未知語獲得器が動作することである．
具体的には，解析された文から未知語を抽出し，適当な時点で形態素解析器の辞書を更新する．
これにより獲得された未知語が形態素解析に反映される．
オンライン未知語獲得では，獲得開始時に対象コーパスを決める必要がない．
そのため，例えば，クローラが毎日新たなページを取得するという設定でも，この差分のみから未知語が獲得できる．
オンライン未知語獲得は，検出，列挙，選択のサブタスクにより実現される．
このうち，列挙は日本語の持つ形態論的制約を利用し，選択は蓄積した複数用例の比較による．
実験により比較的少数の用例から高精度に未知語が獲得され，その結果形態素解析の精度が改善することが示された．
本論文の構成は次の通りである．
[REF_sec:acquisition-task]章で未知語獲得タスクを整理し，[REF_sec:online-acquisition]章でオンライン未知語獲得の枠組みを提案する．
[REF_sec:enumeration-and-selection]章では，オンライン未知語獲得の実現手法のうち，列挙と選択を説明する．
[REF_sec:experiments]章で実験結果を報告し，[REF_sec:related-work]章で関連研究，[REF_sec:conclusion]章で結論を述べる．
形態素解析は，文を形態素列に分割し，各形態素に品詞をタグ付けするタスクである．
形態素解析は自然言語処理における基盤技術であり，構文解析や情報検索といった応用を実現するうえで高い精度の達成が不可欠となる．
日本語の形態素解析では，あらかじめ定義された辞書を用いる手法が高い精度を達成している[CITE]．
この手法では，入力文は辞書引きにより得られた形態素のラティスに展開され，ラティス中の最適なパスが出力として選択される．
しかし，辞書に基づく形態素解析には，辞書にない形態素（未知語）の解析を誤りやすいという問題がある．
例えば，形態素解析器JUMANは，デフォルトの辞書を用いると，未知の動詞「ググる」を誤って「ググ」と「る」に分割する．
この未知語問題は，未知語を解析用の辞書に追加することで解決する．
しかし，人手による辞書登録はコストがかかるため，計算機による自動化が望まれる．
人手によらない未知語問題への解決策として，2通りの手法が提案されている．
ひとつ目の手法では，形態素解析における未知語モデルを改良する[CITE]．
日本語の形態素解析で広く用いられる未知語モデルは，字種に基づく簡単なヒューリスティクスだが，代わりに統計や機械学習に基づく未知語モデルを導入すると未知語同定の精度が向上する．
二つ目の手法では，テキストから未知語を自動獲得し，形態素解析用の辞書を拡張する[CITE]．
二つの手法を比べると，前者は入力文中の個々の未知語を同定しようとするのに対し，後者は同じ未知語のテキスト中での複数の使われ方を比較できるという点で異なる．
複数の使われ方の比較は未知語の同定に効果的と考えられる．
例えば「ようつべ」（YouTubeのスラング）という形態素を知らないまま，「ようつべって…」という文を解釈したいとする．
このとき，「ようつべ」は，未知の名詞以外にも，未知の動詞「ようつべる」とも解釈でき，いずれが正しいか判断しがたい．
同様に，別の文「ようつべとは，…」について，名詞「ようつべ」の他に，動詞「ようつぶ」の命令形とも解釈できる．
しかし，両者を見比べると，2文とも名詞「ようつべ」で解釈できることから，名詞という解釈がより自然だと推測できる．
従って，本論文では後者の手法を採用する．
ただし，両者は対立するものではなく，組み合わせることで，より高い解析精度が得られるようになると期待できる．
未知語獲得の従来手法はバッチ処理であり，コーパスをソートしてすべての部分文字列を調べる[CITE]．
しかし，この手法は効率が悪い．
なぜなら高頻度の形態素のほとんどが解析用の辞書に登録済みであり，一般に出現頻度でコーパスの90%以上を網羅している．
こうした既知の形態素を改めて獲得しても無駄になる．
これに対し，提案手法では，辞書に登録されていない形態素のみを獲得対象とする．
従来研究は，資源の制約から，主に小規模な新聞記事を対象に行われてきたが，近年，ウェブの出現により大規模なテキストが入手可能となっている．
それに伴い，自然言語処理の様々な分野でデータの大規模化による性能向上が報告されている[CITE]．
しかし，未知語獲得は，データの大規模化が単純に解決する性質の問題ではない．
未知語の中には，「ブログ」のように高頻度ながら登録が漏れているものもあるが，大部分がいわゆるロングテールに属す低頻度の形態素である．
こうした形態素の出現するテキストには偏りがあるだけでなく，データを増やすだけでは，次々と新たな未知語が出現してきりがない．
従って，とにかくデータを与えてそこから未知語を獲得するよりも，個々の未知語候補に着目し，それが獲得されるまでデータを読み込む方が自然である．
そもそも，未知語の同定のために，何千，何万もの使われ方を調べる必要はなく，直観的には，ほとんどの場合，10件程度を見比べればほぼ明らかではないかと思われる．
本論文では，オンライン未知語獲得という枠組みと，その具体的な実現手法を提案する．
オンライン未知語獲得では，バッチ処理ではなく，逐次的に入力されるテキストから未知語を獲得する．
形態素解析器自体は，通常通りテキストを文単位で解析し，形態素列を出力する．
異なる点は，解析の裏で未知語獲得器が動作することである．
具体的には，解析された文から未知語を抽出し，適当な時点で形態素解析器の辞書を更新する．
これにより獲得された未知語が形態素解析に反映される．
オンライン未知語獲得では，獲得開始時に対象コーパスを決める必要がない．
そのため，例えば，クローラが毎日新たなページを取得するという設定でも，この差分のみから未知語が獲得できる．
オンライン未知語獲得は，検出，列挙，選択のサブタスクにより実現される．
このうち，列挙は日本語の持つ形態論的制約を利用し，選択は蓄積した複数用例の比較による．
実験により比較的少数の用例から高精度に未知語が獲得され，その結果形態素解析の精度が改善することが示された．
本論文の構成は次の通りである．
[REF_sec:acquisition-task]章で未知語獲得タスクを整理し，[REF_sec:online-acquisition]章でオンライン未知語獲得の枠組みを提案する．
[REF_sec:enumeration-and-selection]章では，オンライン未知語獲得の実現手法のうち，列挙と選択を説明する．
[REF_sec:experiments]章で実験結果を報告し，[REF_sec:related-work]章で関連研究，[REF_sec:conclusion]章で結論を述べる．
