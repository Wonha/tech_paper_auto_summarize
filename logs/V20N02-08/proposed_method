Markov Logic
\label{mln}

述語項構造解析を含めて，我々が現実に遭遇する問題の多くは，局所的な分類学習だけで挑んでも十分な解決を望めないことは古くから認識されてきた．
局所的な分類学習に対し，統計的な変量の間にある全体的（大域的）な相互関係をとらえながら学習を行うのが，統計的関係学習である~\cite{ng:1992}．

Markov Logicは近年急速に広まりつつある統計的関係学習法の一つであり，全体最適化を可能にする学習と推論のための統合的な枠組みである．
これは一階述語論理とMarkov Networksを組み合わせたもので，
本来矛盾が許されない一階述語論理式に，ある程度の罰則を以って矛盾を許容する枠組みであると考えることができる．
また，それはMarkov Networksを一階述語論理式によって表現するテンプレート言語であるとの解釈もできる．
自然言語処理の分野においても，実体解析~\cite{singla:2006:icdm}，情報抽出~\cite{poon:2007:aaai}，共参照解析~\cite{poon:2008:emnlp}など，大域的な制約が重要な分野において特に利用されてきた．

本研究でこのMarkov Logicが日本語述語項構造解析に適した枠組みであると考える理由は三つある．
一つ目は，二律背反の絶対的な制約をモデル化する\emph{hard}制約と，実数値による重みで強さを制御できる\emph{soft}制約の2種類の全体制約を利用できること，
二つ目は，識別学習を利用できること，
三つ目は，フリーで利用できるライブラリがあることである．
統計的関係学習法としては，他にもPRM~\cite{koller:1999}や，RMN~\cite{taskar:2002:uai}があるが，
上に挙げた3点を満たしてはいない．

Markov Logicでは，重み付きの論理式の集合を\emph{Markov Logic Networks} (MLNs)と呼ぶ．
一つのMLN \emph{M}は，$(\phi,w)$の組の集合であり，$\phi$が一階述語論理式，$w$が実数値の重みとなる．

定義された一階述語に対する基底述語 (\emph{ground atom}) の集合を，可能世界と呼び，\emph{M}は一つの可能世界に対して，次のような確率分布を定義する．
\begin{equation}
\prob\left(\y\right)=\frac{1}{Z}\exp\left(
\sum_{\left(\phi,w\right)\in M} w \sum_{\boldc\in C^{\phi}}f_{\boldc}^{\phi}\left(\y\right)
\right)
\label{eq:prob}
\end{equation}
ここで，$\boldc$は論理式$\phi$の中にある変数に対して割り当てられる定数の組であり，
論理式$\phi$に$\boldc$を割り当てた論理式を基底論理式 (\emph{ground formula}) と呼んでいる．
$f_{\boldc}^{\phi}$ は，対応する基底論理式が可能世界$\y$の中で真の場合には1，偽の場合は0となるような二値の素性関数である．
$C^{\phi}$ は定数組の定義域であり，$\phi$が持つ変数はこの定義域内の値により全て置き換えることができる．
また$Z$ は正規化定数である．
この確率分布は，一つの Markov Network (\emph{Ground Markov Network}) に対応しており，このネットワーク構造の中で，頂点が示すのは基底述語，辺を含む部分完全グラフが示すのは基底論理式である．

Markov Logicにおける論理式の設計は人手で行う必要があり，この作業は従来の機械学習器を利用する場合の素性選択に対応する．
その前段階として，解くべき問題に合わせて有効な学習手法や効率的な推論手法を選択する必要があるのはMarkov Logicにおいても同様である．
しかし，これらの実装については，{\it Alchemy}\footnote{http://alchemy.cs.washington.edu/} や{\it Markov thebeast}\footnote{http://code.google.com/p/thebeast/}など，既存のツールを利用することができるので，
次節以降では，述語項構造解析のために，どのような論理式を設計するかに焦点を絞って述べるものとする．



提案手法
\label{method}

この節では日本語述語項構造解析のためのMarkov Logicモデルについて，その詳細を述べる．


\subsection{述語定義}

まずはMarkov Logic Network (MLN) の構築に必要な論理述語を定義することからはじめる．
論理述語には2種類ある．一つは推定したい情報を表すもので，モデルには学習時にだけその情報を与えるため，潜在述語 (\emph{hidden predicate}) と呼ばれる．
もう一つは，観測述語 (\emph{observed predicate}) と呼ばれ，学習時と推定時の両方において，モデルにその情報が与えられる．

表\ref{hidden}には本研究で定義した三つの潜在述語が示されている．
これら三つの潜在述語が，我々の推定したい情報を定義している．
即ち，文節$a$は述語の項になっているか（項同定），文節$i$は削除されるか（項候補削減），述語$p$は文節$a$を項に持ち，その意味役割が$r$になるか（意味役割付与）である．
最初の二つの推定事項に対しては1変数の$\mathit{isArg}(a)$と$\mathit{delete}(i)$が対応し，残り一つに対しては$\mathit{role}(p,a,r)$という3変数の潜在述語が対応することになる．

\begin{table}[b]
\caption{潜在述語}
\label{hidden}
\input{08table01.txt}
\end{table}

本研究の手法はMarkov Logicによる英語意味役割付与~\cite{meza:2009:naacl}を元にしている．
先に述べた通り，Meza-Ruizらは問題を四つの部分問題に分け，それに対して五つの潜在述語 (\emph{isPredicate, isArgument, hasRole, role, sense}) を定義している．
しかし，本研究では，先行研究~\cite{taira:2008:emnlp,imamura:2009:acl}との比較のため，項同定と意味役割付与に限定して行っている．
その結果，表\ref{hidden}の三つが本研究で定義する潜在述語となった．

項同定を固有の推定問題として扱うことには議論の余地がある．
項同定は述語との組で定義するべきで，$\mathit{isArg}$が単体で定義されるのは不自然と考えることもできる．
しかし，固有表現抽出などにより同定される，「人物・組織」といった名詞は，高確率で何らかの述語の項となり，
逆にどの述語とも結びつかないことが不自然である．
そこで，項同定を一つの推定すべき問題として定義することで，
項として同定されるものが，孤立するような事象を避けるように解析を行うのである．
同様の議論はMeza-Ruizらの研究でも見られ，英語においても項同定を一つのタスクとして扱うことで，
一定の性能向上が達成されることを彼らは報告している~\cite{meza:2009:naacl}．
ただし，\emph{isArg}は\emph{role}や\emph{delete}と制約で結ばれるため，
学習・推論時に項同定が独立して解析されるわけではなく，
項から述語に対する制約を与えるために定義した潜在述語であると捉えることもできる．

一方，観測述語は潜在述語の推定のために利用される手がかりとなる情報を定義する．
例えば，$\mathit{form}(i,w)$は文節$i$が表層形$w$を持つことを表現する観測述語である．
観測述語で表される情報には，表層形，品詞，固有表現など，様々なものが考えられるため，潜在述語に比べてその種類は多くなる．
全ての観測述語は表\ref{observed}にまとめて示した．


\begin{table}[t]
  \caption{観測述語}
\label{observed}
\input{08table02.txt}
\end{table}

潜在述語と観測述語が定義されれば，次はこれらの組み合わせによって論理式を考えていくことになる．
まずは$\mathit{isArg}$と$\mathit{role}$に着目し，その局所論理式と大域論理式について，それぞれ\ref{lf}節と\ref{gf}節で述べる．
$\mathit{delete}$については\ref{deletion}節でまとめて説明する．


\subsection{局所論理式}
\label{lf}

局所論理式 (\emph{local formula}) とは，潜在述語をただ一つしか含まない論理式のことである．
一方，観測述語については任意の数含めることができる．
即ち，一つの推定事項に対して，その素性や制約の組み合わせを考える論理式となる．

$\mathit{isArg}$ や$\mathit{delete}$に対する局所論理式は，対象となる一つの文節について，語彙的及び構文的な特徴を捉えたものである．
例えば単語表層形に対する局所的な特徴を表現した論理式は次のようになる
\begin{equation}
  \mathit{form}(a,+w) \Rightarrow \mathit{isArg}(a). \label{word}
\end{equation}
これは文節$a$が表層形$w$の単語を持つならば項であるということ表している．
尚，$+$という表現は，この論理式が表層形$w$によって別々に重み付けされることを示す．

$\mathit{role}$に対する局所論理式は，対象とする文節が二つあり，その間の特徴を捉えることになる．
例えば，
\begin{equation}
  \mathit{ne}(a,+n) \wedge \mathit{dep}(p,a,+d) \Rightarrow \mathit{role}(p,a,+r) \label{path}
\end{equation}
が表すのは，文節$a$に対する固有表現と，述語$p$と文節$a$の間の係り受け関係を組み合わせた特徴である．
この式(\ref{path})と同様に，表\ref{observed}にある$\mathit{goiMatch}$\footnote{$\mathit{goiMatch}$と$\mathit{goiCate}$にはシソーラスである日本語語彙大系~\cite{ikehara:1997}を利用している．}，$\mathit{dep}$，$\mathit{path}$の三つの観測述語は，他の観測述語と組み合わせで論理式を構築する．

式(\ref{word})や式(\ref{path})などの一階述語論理式は，Markov Networkの素性テンプレートと考えることができる．
即ち，一つのテンプレートからは複数の基底論理式 (\emph{ground formula}) が生成され，別々の重みがつくことになる．
式(\ref{word})が生成する基底論理式を，図\ref{example1}の例から考えてみると，
\begin{gather}
  \mathit{form}\left(a,``\mbox{昨日''}\right)\Rightarrow \mathit{isArg}\left(a\right) \label{yesterday}\\
  \mathit{form}\left(a,``\mbox{図書館''}\right)\Rightarrow \mathit{isArg}\left(a\right) \label{library}
\end{gather}
は，学習によってそれぞれ別の重みを獲得することになる．
図\ref{example1}の事例から学習すれば，``図書館''はニ格になり，``昨日''は項となっていないため，
式(\ref{library})が式(\ref{yesterday})よりも大きな重みを獲得するものと考えられる．
このように，論理式のもつ曖昧さは重みによって制御されるため，
曖昧な制約でも記述することができるのである．



\subsection{大域論理式}
\label{gf}

局所論理式で扱う素性は，局所的な分類器でも捉えることできるが，
Markov Logicではさらに次のような記述も可能である．
\begin{equation}
\mathit{isArg}\left(a\right) \Rightarrow \exists p. \exists \mathit{r.role}(p,a,r) \label{a2r}
\end{equation}
これはある文節$a$が項であるならば，少なくとも一つ以上の述語と関係があることを保証する論理式である．
式(\ref{a2r})のように，二つ以上の潜在述語を持つ論理式のことを大域論理式と呼ぶ．
この大域論理式を利用することで，本研究のモデルは複数の決定を同時に行うことができるようになる．
即ち，$\mathit{isArg}$と$\mathit{role}$の依存関係まで考慮して，最適な状態を推定することが可能になるのである．
このような大域的な素性は，局所的な分類器では捉えることが難しく，
Markov Logicを利用する最大の利点となる．

\begin{table}[t]
  \centering
  \caption{\emph{isArg} と \emph{role}のための大域論理式}
\label{global}
\input{08table03.txt}
\end{table}

本研究で$\mathit{isArg}$と$\mathit{role}$に対して定義する大域論理式は表\ref{global}にまとめて示した．
表\ref{global}にある大域論理式は全てhard制約であり，潜在述語の間の一貫性を確保するための制約である．
MLNの中で，hard制約は無限の重みを持つ特別な論理式として定義されており，
この制約に違反した可能世界は決して解として選択されない．
例えば，式(\ref{a2r})は$\mathit{isArg}$から$\mathit{role}$への一貫性を保証している．

$\mathit{role}$と$\mathit{isArg}$の一貫性を保つためにあるもう一つの論理式は，
\begin{equation}
\mathit{role}(p,a,r) \Rightarrow \mathit{isArg}\left(a\right) \label{r2a}
\end{equation}
であり，文節$a$が述語$p$の項となるならば，文節$a$は項であることを保証する．

残る大域論理式は，
\begin{equation}
\mathit{role}(p,a,r_1) \wedge r_1 \neq r_2 \Rightarrow \neg \mathit{role}(p,a,r_2) \label{r2r}
\end{equation}
のように二つ$\mathit{role}$間の関係を表現したもので，
述語$p$と項$a$の間には，ただ一つの意味役割しか成立しないことを保証している．
これにより，図\ref{models}で示したような論理的矛盾を回避できることになる．

日本語述語項構造解析において，大きな障害となるゼロ照応に対しては，
式(\ref{a2r})と式(\ref{r2r})が大きく貢献できると予想される．
つまり，式(\ref{r2r})は，ある述語において格が重複することを防ぐものであり，
式(\ref{a2r})は，述語との統語的な関係が弱い項候補であっても，孤立する（どの述語の格にもならない）ことが無いように，
文全体の項候補に対して適切な述語と格の割り当てを行うためのものである．
これにより，複数の述語に対して統語的関係の強い項候補が，他の候補との依存関係を考えずに，格を独占してしまう状態を回避できるのである．


\subsection{削除論理式}
\label{deletion}

本節では項候補削減に関する論理式を解説する．
項候補削減は，述語と項に関係のない文節を探索空間から削除することで，
効率的に項の同定を行うとともに，精度の向上を狙うのが目的である．
どのような考えに基づいて項候補を削減するか，その具体例を図\ref{example2}に示した．
この例には，文末に``行った''という述語があり，その項候補となる文節が五つ存在する．
この五つの中から，正しい項として，文節``彼は''をガ格に，``図書館に''をニ格に，それぞれ同定するのが述語項構造解析である．
そして，項候補削減は，五つの候補から項を選ぶのではなく，項にならない候補を削除する．
もしも``母の新しい車で''という抽出対象ではない具格を構成する句を削除できたなら，残り二つの候補から正しい項を選ぶことは容易である．
この項候補削減の着想は文書自動要約の要素技術である文圧縮からきており，
近年，係り受け関係を利用することによって，文の統語構造を維持したままに適切な単語の削除を行い，
文を圧縮する手法が提案されている．~\cite{clarke:2008:jair,huang:2012:aaai}
削除論理式のために定義された$\mathit{delete}$は，このような文圧縮の手法を利用して，
述語と項にならない文節を削除するために定義されたものである．

\begin{figure}[t]
\begin{center}
\includegraphics{20-2ia8f3.eps}
\end{center}
  \caption{具格を持つ述語項構造の例}
\label{example2}
\end{figure}

ただし，ここで重要なことは，本研究ではこの項候補削減を前処理として行うのではなく，項同定と同時に行っている点である．
なぜなら，過剰な項候補の削減は，再現率を大幅に傷つけることになるからで，
本研究ではこの現象を\emph{過剰削減}と呼んでいる．
項同定，項候補削減，意味役割付与の三つを同時に行うモデルを作ることにより，
過剰削減を防いだ上で述語項構造解析の性能を改善している．

削除論理式にも局所論理式と大域論理式がある．
まず，局所論理式として，次の式(\ref{notPred})のように，一つだけhard制約を導入する．
\begin{equation}
 \mathit{isPred}(i) \Leftrightarrow \neg \mathit{delete}(i). \label{notPred}
\end{equation}
これにより，述語になる文節は削除されないということを表現している．

残りの局所論理式については，全てsoft制約で，\ref{lf}節で述べた$\mathit{isArg}$と同じ素性を使って定義している．
例外は，次の式(\ref{bias})で，
\begin{equation}
 \mathit{dep}(i,j,+d) \wedge \mathit{isPred}(j) \Rightarrow \neg \mathit{delete}(i). \label{bias}
\end{equation}
これは述語と係り受け関係にある文節は削除しないという制約を表現している．
一般に，述語項構造関係にある文節対の多くは統語構造的にも依存関係があることが知られている．
表\ref{sts}にはコーパスの統計を示したが，述語項構造関係の多くが直接係り受け関係にあることが分かる．
この制約もsoft制約であり，削除されないことを保証するわけではない．
英語など，ラベルありの係り受け解析が行われる場合には，係り受けラベル$d$によってその制約の強弱が重み付けされる．
しかし，日本語の係り受けラベルは，多くの場合``D''になるため，ラベルによる強弱の差は期待できない．

しかし，局所論理式は一つの文節に対して，それを削除するか否かという視点しか持つことができず，削減による十分な性能改善は期待できない．
\emph{delete}の追加により十分な効果を得るためには，大域論理式の利用が必要になる．

\emph{delete}のための大域論理式は，表\ref{delFormula}に示すように，三つのhard制約と一つのsoft制約がある．
この表\ref{delFormula}にある上の三つが，$\mathit{isArg}$及び$\mathit{role}$との整合性を保証するためのhard制約である．
例えば，
\begin{equation}
 \mathit{delete}(i) \Rightarrow \neg \mathit{isArg}(i) 
\end{equation}
この論理式は削除された文節は項とならないことを保証している．

\begin{table}[b]
  \centering
  \caption{大域削除論理式}
\label{delFormula}
\input{08table04.txt}
\end{table}

表\ref{delFormula}にある最後の論理式は次のsoft制約として定義している，
\begin{equation}
 \mathit{form}(h,+w) \wedge \mathit{pos}(h,+p) \wedge \mathit{dep}(h,m,+d) \wedge \mathit{delete}(h) \Rightarrow \mathit{delete}(m) \label{del}
\end{equation}
これは，親（ヘッド）となる文節$h$が削除された時，それに依存した子文節$m$も同じく削除するということを表した大域論理式である．
この論理式は常に成り立つものではないが，コーパスからの学習した重みによって緩和された制約となり，適切な削除が行われる．
式(\ref{del})による制約の働きで，先に述べたような具格になる句の削除が実現される．

図\ref{example2}の例を考えてみると，
式(\ref{del})は次のように展開される．
\begin{equation}
 \mathit{form}(4,``\mbox{車で}'') \wedge \mathit{pos}(4,\mbox{名詞+助詞—格助詞}) \wedge \mathit{dep}(4,2,``D'') \wedge \mathit{delete}(4) \Rightarrow \mathit{delete}(2)
	\label{delGround}
\end{equation}
これはつまり，``車で''が削除されたならば，``母の''も同じく削除されるということを表現している．
soft制約なので必ず保証される制約ではないが，割り当てられている重みに準じて削除が行われる．
図\ref{tree}に示したのは，図\ref{example2}の文を解析して出力した係り受け木である．
この木の中では，式(\ref{del})の制約によって，``車で''以下の部分木に属する文節が全て削除されることになる．
本来，係り受け木でこのような枝刈りを行う場合，係り受けのラベルが大きな役割を果たすことが多い．
英語の文圧縮では，係り受けラベルを利用した単語・句の削除が行われている~\cite{clarke:2008:jair,clarke:2010:cl}．
しかし，日本語ではほとんどのラベルが``D（通常の係り受け）''であり，他の``P（並列）''，``A（同格）''，``I（部分並列）''，といったラベルは数が少なく，連用修飾や連体修飾といった係り受け関係情報を持たないため，
係り受けラベル$d$によって式(\ref{del})の重みを変えることが述語項構造解析に寄与しないと考える．
その代替になるものとして，表層形と品詞の組み合わせを利用している．
例えば，式(\ref{delGround})のように表層形が``車で''になり，品詞が``名詞''+``助詞—格助詞''ならば，具格の可能性が高いので，重みを大きくすることになる．
もし，英語に本研究の削減手法を適用するのであれば，
係り受けのラベルを利用するのが単純で効果的であろう．

\begin{figure}[t]
\begin{center}
\includegraphics{20-2ia8f4.eps}
\end{center}
  \caption{係り受け木を利用した具格の削減}
\label{tree}
\end{figure}



