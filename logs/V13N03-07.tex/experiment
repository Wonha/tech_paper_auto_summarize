\section{実験と検討} \label{chap4}

作成した関連用語収集システムの性能を評価する実験を行なった．
まず最初に，システムの評価に使用する参照セットを作成した．
次に，この参照セットを利用して，関連用語選択モジュールと候補語収集モジュー
ルの評価実験を行なった．
最後に，システム全体の性能を評価する実験を行なった．
なお，すべての実験において，
サーチエンジンとしてgoo\footnote{http://www.goo.ne.jp/}を用いた．

\subsection{参照セット}\label{sec:reference}

ある一定の条件を満たす用語を抽出するタスクでは，出力すべき用語のセット
(正解セット)を準備し，システムの出力結果と正解セットを比較して，システ
ムの評価を行なうのが一般的である．用語を抽出する対象となるコーパスがあ
らかじめ与えられている場合には，そのコーパスからある基準(例えば，人間
の判断)に従って収集した用語を正解用語とすることにより，正解セットを作
成することが可能である．しかし，本研究の場合，あらかじめ与えられている
コーパスはウェブということになるが，ウェブ全体からシードワードの関連用
語を人手で収集することは非現実的であるため，網羅的な正解セットを準備す
ることは事実上不可能である．

システムを評価するもう一つの方法として，システムの出力結果を一つ一つ人
手でチェックするという方法も考えられる\footnote{この場合，再現率を評価
することはできない．}．しかし，本研究で正解とする用語は，特定の専門分
野においてシードワードと関連する専門用語であるため，正解か否かの判断に
はその分野の専門知識が不可欠である．このため，多くの分野に対して実験を
行なおうとすれば，多数の専門家の協力を仰ぐ必要があり，非常にコストがか
かる．

そこで，我々は，専門家の知識の代替として，専門家の手によって書かれた書
籍から参照セットと呼ぶ用語集を作成し，これを用いてシステムの評価を行な
うことにした．作成した参照セットの概要を\mbox{表\ref{tbl:ref}}に示す．
参照セットは，6つの専門分野に対してそれぞれ3つと，一般語に対する1つ
の，計19セットからなる．

\begin{table}
 \begin{center}\footnotesize
  \caption{作成した参照セット}\label{tbl:ref}
   \begin{tabular}{|l|rrr|l|}
    \hline
    分野 & $|R_3|$ & $|R_2|$ & $|R_1|$  & 使用した書籍\\
    \hline
    自然言語処理 & 17 & 143 & 1337  & 
    \shortcite{nagao96nlp}，\shortcite{nagao98nlp}，\shortcite{tanaka99nlp}\\
    情報理論 & 33 & 108 & 744 & 
    \shortcite{hirasawa00it}，\shortcite{hirata03it}，\shortcite{yokoo04it}\\
    パターン認識 & 17 & 120 & 1352 & 
    \shortcite{toriwaki93pr}，\shortcite{ishii98pr}，\shortcite{nakagawa99pr}\\
    バイオインフォマティクス & 23 & 101 & 1077 & 
    \shortcite{mitaku03bio}，\shortcite{murakami03bio}，\shortcite{gojohbori03bio}\\
    マクロ経済学 & 63 & 244 & 1805 &
    \shortcite{akashi03macro}，\shortcite{wakita04macro}，\shortcite{fukuda05macro}\\
    ミクロ経済学 & 59 & 206 & 1076 &
    \shortcite{asada02micro}，\shortcite{yogo02micro}，\shortcite{ibori04micro}\\
    \hline
    一般語 & 50 & & & \shortcite{RSK} \\    \hline
    合計 & 262 & 922 & 7391 & \\ \hline
   \end{tabular}
 \end{center}
\end{table}

各専門分野の参照セットは，次の方法で作成した．
\begin{enumerate}
\item その分野の書籍を3冊用意する．
\item それぞれの書籍から巻末の索引語をすべて収集し，それぞれ索引語リストを作成する．
\item こうして得られた3つの索引語リストから，次の3つの用語集合を作成する．
\begin{description}
\item[$R_3$] 3冊の書籍で索引語となっている用語の集合．
\item[$R_2$] 2冊以上の書籍で索引語となっている用語の集合．
\item[$R_1$] いずれかの書籍で索引語となっている用語の集合．
\end{description}
\end{enumerate}
この手順から明らかなように，それぞれの分野の3つの参照セット間には，
次の関係が成り立つ．
\begin{equation}
R_3 \subseteq R_2 \subseteq R_1
\end{equation}

$R_3$に含まれる用語は，3冊の書籍すべてで索引語となっていた用語であり，
その分野の代表的な専門用語とみなすことができるだろう．これに対して，条
件を緩めた$R_2$，$R_1$は，その信頼度は下がるものの，すくなくとも，その
分野の専門用語の候補集合と考えてもよいであろう．このような考えに基づき，
これらの集合は，システムの性能を見積もるための参照解として使用できると
考えた．ただし，これらの集合を参照解として使用するということは，「特定の
分野の専門用語は，その分野の他の専門用語と必ず強く関連する」と仮定している
点に注意する必要がある．また，作成した参照セットは，その分野の専門用語
を網羅しているわけではない点にも注意が必要である．

一般語の参照セットは，小学生向けの国語辞典\cite{RSK}から，名詞50
語をランダムに選択することによって作成した．以下では，これを一般語$R_3$
と表記する．

なお，これらの参照セットに含まれる用語を，以下では参照用語と呼ぶ．


\subsection{関連用語選択モジュールの評価}\label{sec:ex_rel}

ここでは，参照セットを用いた人工的な設定下において，
関連用語選択モジュールが適切に機能するかどうかを調べた．
参照セットとしては，6つの専門分野の$R_3$と一般語$R_3$を用いた．
具体的には，以下の手順で行なった．
\begin{enumerate}
\item 
1つの専門分野の$R_3$を選ぶ．そこから専門用語を1つ選び，
シードワード$s$とする．その残りを$R_3^{-}$とする．
\item
$R_3^{-}$，上記で選択した専門分野以外の$R_3$，および，
一般語$R_3$に含まれる用語をすべて集め，これを
関連用語の候補語集合$X$とする．($|X|=261$である．\unskip)
\item
すべての$x \in X$に対して，$s$との関連度を計算し，関連度の大きい順に，
$X$の要素を並べる．最後に，上位20位までを取り出し，これを$T$とする．
\item
$|T \cap R_3^{-}|$を求める．
この数は，集合$T$に$s$と同じ分野の参照用語がいくつ含まれるかを表す．
\end{enumerate}
すなわち，ここでは，$s$と同じ分野の参照用語を仮想的な正解(関連用語)
とみなし，採用した尺度が，上位20位までに正解をどの程度出力するかを調べ
た．シードワードとしては，6つの専門分野からそれぞれ4用語ずつ，計24用語
を使用した．また，関連度を測る尺度としては，3.2節で述べたJaccard係数と
$\chi^2$統計量の2つの尺度の他に，比較のために，他の4つの尺度(共起頻
度，Dice係数，相互情報量，対数尤度比) に対しても結果を求めた．これらの
尺度とその計算式を\mbox{表\ref{tbl:relatedness}}に示す．この表の「略記」
は，本論文におけるそれぞれの尺度の略記法を示す．計算式の$a$，$b$，$c$，
$d$は
\mbox{表\ref{tbl:2by2}}に示したウェブページ数であり，$n$はウェブ全体のペー
ジ数である．実験では，$n=13600000$を用いた\footnote{この値は，助詞「に」，
「を」，「は」，「も」，「が」のいずれのヒット数よりも大きい値である．}．

\begin{table}
 \begin{center}\footnotesize
  \caption{比較尺度}\label{tbl:relatedness}
  \begin{tabular}{|l|l|l|}
   \hline
   尺度 & 略記 & 計算式 \\
   \hline
   Jaccard係数 & jac & $\frac{a}{a+b+c}$ \\
   $\chi ^2$統計量 & chi2 & $\frac{n(ad-bc)^2}{(a+b)(c+d)(a+c)(b+d)}$ \\\hline
   共起頻度 & cooc & $a$ \\
   Dice係数 & dice & $\frac{2a}{2a+b+c}$ \\
   相互情報量 & pmi & $\log \frac{an}{(a+b)(a+c)}$ \\
   対数尤度比 & llr & $a\log \frac{an}{(a+b)(a+c)}+
   b\log \frac{bn}{(a+b)(b+d)}+c\log \frac{cn}{(a+c)(c+d)}+
   d\log \frac{dn}{(b+d)(c+d)}$ \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

実験結果を\mbox{表\ref{tbl:rel_result}}に示す．この表において，
$|R_3^{-}|$は，候補語集合に含まれる仮想的な正解の数を表す．

\begin{table}
 \begin{center}\footnotesize
  \caption{関連度上位20語に含まれる$R_3$の参照用語数}\label{tbl:rel_result}
  \begin{tabular}{|l|rr|rrrr|}
   \multicolumn{7}{l}{「自然言語処理」($|R_3^{-}|=16$)}\\
   \hline
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{cooc} &
   \multicolumn{1}{c}{dice} &
   \multicolumn{1}{c}{pmi} &
   \multicolumn{1}{c|}{llr} \\
   \hline
   自然言語処理 & 10 & {\bf 12} & 6 & 10 & 11 & 9 \\
   意味解析 & 12 & {\bf 14} & 7 & 12 & 12 & 10 \\
   形態素解析 & 11 & {\bf 14} & 6 & 11 & 13 & 10 \\
   構文解析 & 11 & {\bf 14} & 7 & 11 & {\bf 14} & 10 \\
   \hline
   \multicolumn{7}{l}{\tiny }\\[-5pt]
   \multicolumn{7}{l}{「情報理論」($|R_3^{-}|=32$)}\\
   \hline
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{cooc} &
   \multicolumn{1}{c}{dice} &
   \multicolumn{1}{c}{pmi} &
   \multicolumn{1}{c|}{llr} \\
   \hline
   情報理論 & 13 & 19 & 7 & 13 & {\bf 20} & 15 \\
   通信路容量 & {\bf 20} & {\bf 20} & 17 & {\bf 20} & {\bf 20} & {\bf 20} \\
   情報源符号化 & {\bf 20} & {\bf 20} & 15 & {\bf 20} & {\bf 20} & {\bf 20} \\
   エントロピー & 10 & {\bf 20} & 3 & 10 & {\bf 20} & 12 \\
   \hline
   \multicolumn{7}{l}{\tiny }\\[-5pt]
   \multicolumn{7}{l}{「パターン認識」($|R_3^{-}|=16$)}\\
   \hline
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{cooc} &
   \multicolumn{1}{c}{dice} &
   \multicolumn{1}{c}{pmi} &
   \multicolumn{1}{c|}{llr} \\
   \hline
   パターン認識 & 12 & {\bf 13} & 5 & 12 & 8 & 10 \\
   線形識別関数 & 10 & {\bf 14} & 13 & 10 & 10 & 13 \\
   部分空間法 & 11 & {\bf 13} & 11 & 11 & 10 & 11 \\
   特徴抽出 & 11 & {\bf 13} & 6 & 11 & 9 & 10 \\
   \hline
   \multicolumn{7}{l}{\tiny }\\[-5pt]
   \multicolumn{7}{l}{「バイオインフォマティクス」($|R_3^{-}|=22$)}\\
   \hline
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{cooc} &
   \multicolumn{1}{c}{dice} &
   \multicolumn{1}{c}{pmi} &
   \multicolumn{1}{c|}{llr} \\
   \hline
   バイオインフォマティクス & {\bf 16} & 15 & 8 & {\bf 16} & 15 & 14 \\
   相同性 & {\bf 18} & {\bf 18} & 16 & {\bf 18} & 17 & {\bf 18} \\
   スプライシング & {\bf 17} & {\bf 17} & 12 & {\bf 17} & {\bf 17} & 15 \\
   GenBank & {\bf 19} & {\bf 19} & 15 & {\bf 19} & {\bf 19} & {\bf 19} \\
   \hline
   \multicolumn{7}{l}{\tiny }\\[-5pt]
   \multicolumn{7}{l}{「マクロ経済学」($|R_3^{-}|=62$)}\\
   \hline
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{cooc} &
   \multicolumn{1}{c}{dice} &
   \multicolumn{1}{c}{pmi} &
   \multicolumn{1}{c|}{llr} \\
   \hline
   マクロ経済学 & 14 & 16 & 14 & 14 & {\bf 17} & 14 \\
   投資関数 & 15 & {\bf 17} & 15 & 15 & {\bf 17} & 15 \\
   有効需要 & 15 & {\bf 19} & 14 & 15 & 17 & 17 \\
   マネーサプライ & {\bf 20} & 19 & 17 & {\bf 20} & 18 & 18 \\
   \hline
   \multicolumn{7}{l}{\tiny }\\[-5pt]
   \multicolumn{7}{l}{「ミクロ経済学」($|R_3^{-}|=58$)}\\
   \hline
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{cooc} &
   \multicolumn{1}{c}{dice} &
   \multicolumn{1}{c}{pmi} &
   \multicolumn{1}{c|}{llr} \\
   \hline
   ミクロ経済学 & 15 & {\bf 19} & 7 & 15 & {\bf 19} & 13 \\
   無差別曲線 & {\bf 20} & {\bf 20} & 13 & {\bf 20} & 18 & 18 \\
   限界効用 & {\bf 20} & {\bf 20} & 11 & {\bf 20} & 16 & 17 \\
   需要曲線 & 19 & {\bf 20} & 11 & 19 & {\bf 20} & 18 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\mbox{表\ref{tbl:rel_result}}から，次のことが観察される．
\begin{enumerate}
\item
Jaccard係数(jac)と$\chi^2$統計量(chi2)のどちらの尺度を用いた場合でも，
シードワードと同じ専門分野の専門用語が上位に集まっている．
\end{enumerate}

このことから，これらの尺度は関連用語選択の尺度として適切であり，これら
の尺度を用いた関連用語選択モジュールは適切に機能することが確認できた．

しかしながら，同時に，次の事実が観察される．
\begin{enumerate} \setcounter{enumi}{1}
\item 
シードワードと同じ専門分野の専門用語のすべてが，上位に集まるわけではない．
\end{enumerate}

例えば，「バイオインフォマティクス」の分野では，それぞれのシードワード
に対して，同じ専門分野の用語が22個，候補語集合(261個)の中に含まれて
いるのだが，上位20位に入らない語が存在した．このことは，本システムは，
一つのシードワードから，それが属す専門分野の専門用語を網羅的に収集する
能力を持たないことを意味する．

参照セットによる評価が拠り所にしている仮定「特定の分野の専門用語は，そ
の分野の他の専門用語と必ず強く関連する」は，現実には強すぎる仮定である．そ
のため，参照セットによる評価は，あくまでもシステムの性能の目安を知るた
めのものであり，万能ではない点に注意する必要がある．

一方，使用した6つの尺度に対しては，以下のような事実が観察される．
\begin{enumerate} \setcounter{enumi}{2}
\item 
$\chi^2$統計量(chi2)が最も安定して良い結果を示している．
\item 
相互情報量(pmi)，Jaccard係数(jac)およびDice係数(dice)，対数尤度比(llr)
も比較的良い結果を示している．これらの尺度と
$\chi^2$統計量との差は，それほど大きくない．
\item 
共起頻度(cooc)は他の5つの尺度と比較して，明らかに性能が劣っている．
\end{enumerate}

上記の結果は，Jaccard係数と$\chi^2$統計量の2つの尺度以外に，比較のた
めに用いた3つの尺度，すなわち，Dice係数，相互情報量，対数尤度比も，関
連用語選択の尺度となり得る可能性を持つことを示唆する．

このうち，Dice係数は，Jaccard係数とほとんど同じ尺度のため，考慮の対象か
ら除外する．また，相互情報量は，2つの用語の共起の割合が等しい場合，用
語の出現頻度が低ければ低いほど関連度が高くなるという性質をもつ
\cite[pp.~182]{manning99fsnlp}ため，専門用語性を測る尺度として不適切であ
る
\footnote{\mbox{\ref{sec:term}節}および\mbox{\ref{sec:select}節}で述べたように，
本研究では，極めて頻度が低い用語は専門用語とは見なさない．}．
対数尤度比は，専門用語性を判定するという意味づけが難しく，かつ，計算式が
複雑なので，特にこの尺度を採用すべきだという積極性に欠ける．
以上の理由により，我々は，関連用語選択の尺度として，
Jaccard係数と$\chi^2$統計量の2つの尺度を採用するという方針を
堅持することとし，以降の実験では，この2つの尺度のみを用いることにした．

\subsection{候補語収集モジュールの評価}\label{sec:ex_cand}

次に，参照セットを用いて候補語収集モジュールの性能を評価する
実験を行なった．実験の手順は次のとおりである．
\begin{enumerate}
\item 
1つの専門分野の$R_3$を選ぶ．
その中から専門用語を1つ選び，シードワード$s$とする．その残りを$R_3^{-}$とする．
\item
(1)で選択した専門分野と同じ専門分野の$R_2$，$R_1$
から，それぞれシードワード$s$を除去した集合$R_2^{-}$，$R_1^{-}$を作成する．
\item
シードワード$s$を候補語収集モジュールに与え，候補語集合$X$を得る．
\item 
$|X \cap R_3^{-}|$，$|X \cap R_2^{-}|$，$|X \cap R_1^{-}|$を計算する．
これらの値は，3つの参照セットのそれぞれに対して，候補語集合$X$に，シー
ドワードと同じ分野の参照用語がどれだけ含まれているかを表す．

\end{enumerate}

前節と同じ入力用語24語に対して，上記の手順を適用した結果を
\mbox{表\ref{tbl:cand_result}}に示す．
この表では，$R_3^{-}$，$R_2^{-}$，$R_1^{-}$に対する
結果を $R_3^{-}/R_2^{-}/R_1^{-}$ という形式で示している．

\begin{table}
 \begin{center}\footnotesize
  \caption{候補語に含まれる参照用語数}\label{tbl:cand_result}
   \begin{tabular}{|l|rr|cc|}
    \multicolumn{5}{l}{「自然言語処理」($|R_i^{-}|=16/142/1336$)} \\
    \hline
    \multicolumn{1}{|c}{入力用語} & 
    \multicolumn{1}{|c}{$|X|$} &
    \multicolumn{1}{c|}{$|X\cap R_i^{-}|$} &
    \multicolumn{1}{c}{$\frac{|X\cap R_i^{-}|}{|R_i^{-}|}$} & 
    \multicolumn{1}{c|}{$\frac{|X\cap R_i^{-}|}{|X|}$}
    \\
    \hline
    自然言語処理 & 2250 & 7/22/ 87 & .44/.15/.07 & .00/.01/.04\\
    意味解析 &  1408 & 11/27/100 & .69/.19/.07 & .00/.02/.07\\
    形態素解析 & 2022 & 6/24/ 87 & .38/.17/.07 & .00/.01/.04\\
    構文解析 &  2726 & 12/30/114 & .75/.21/.09 & .00/.01/.04\\
    \hline
    \multicolumn{5}{l}{\tiny }\\[-5pt]
    \multicolumn{5}{l}{「情報理論」($|R_i^{-}|=32/107/743$)} \\
    \hline
    \multicolumn{1}{|c}{入力用語} & 
    \multicolumn{1}{|c}{$|X|$} &
    \multicolumn{1}{c|}{$|X\cap R_i^{-}|$} &
    \multicolumn{1}{c}{$\frac{|X\cap R_i^{-}|}{|R_i^{-}|}$} &
    \multicolumn{1}{c|}{$\frac{|X\cap R_i^{-}|}{|X|}$}
    \\
    \hline
    情報理論 &  2677 & 14/28/64  & .44/.26/.09 & .01/.01/.02\\
    通信路容量  & 835 & 9/17/40  & .28/.16/.05 & .01/.02/.05\\
    情報源符号化  & 843 & 15/27/55 & .47/.25/.07 & .02/.03/.07\\
    エントロピー  & 4176 & 5/17/40 & .16/.16/.05 & .00/.00/.01\\
    \hline
    \multicolumn{5}{l}{\tiny }\\[-5pt]
    \multicolumn{5}{l}{「パターン認識」($|R_i^{-}|=16/119/1351$)} \\
    \hline
    \multicolumn{1}{|c}{入力用語} & 
    \multicolumn{1}{|c}{$|X|$} &
    \multicolumn{1}{c|}{$|X\cap R_i^{-}|$} &
    \multicolumn{1}{c}{$\frac{|X\cap R_i^{-}|}{|R_i^{-}|}$} &
    \multicolumn{1}{c|}{$\frac{|X\cap R_i^{-}|}{|X|}$}
    \\
    \hline
    パターン認識 &  2354 & 8/33/95 & .50/.28/.07 & .00/.01/.04\\
    線形識別関数 &  252 & 7/17/40 & .44/.14/.03 & .03/.07/.16\\
    部分空間法 &  537 & 7/11/23 & .44/.09/.02 & .01/.02/.04\\
    特徴抽出 &  1658 & 6/24/66 & .38/.20/.05 & .00/.01/.04\\
    \hline
    \multicolumn{5}{l}{\tiny }\\[-5pt]
    \multicolumn{5}{l}{「バイオインフォマティクス」($|R_i^{-}|=22/100/1076$)} \\
    \hline
    \multicolumn{1}{|c}{入力用語} & 
    \multicolumn{1}{|c}{$|X|$} &
    \multicolumn{1}{c|}{$|X\cap R_i^{-}|$} &
    \multicolumn{1}{c}{$\frac{|X\cap R_i^{-}|}{|R_i^{-}|}$} &
    \multicolumn{1}{c|}{$\frac{|X\cap R_i^{-}|}{|X|}$}
    \\
    \hline
    {\footnotesize バイオインフォマティクス} & 5037 & 10/34/130 & 
    .45/.34/.12 & .00/.00/.03\\
    相同性  & 3139 & 14/41/122 & .64/.41/.11 & .00/.01/.04\\
    スプライシング &  3216 & 12/31/ 99 & .55/.31/.09 & .00/.01/.03\\
    GenBank &  1355 & 13/31/ 75 & .59/.31/.07 & .01/.02/.06\\
    \hline
    \multicolumn{5}{l}{\tiny }\\[-5pt]
    \multicolumn{5}{l}{「マクロ経済学」($|R_i^{-}|=62/243/1804$)} \\
    \hline
    \multicolumn{1}{|c}{入力用語} & 
    \multicolumn{1}{|c}{$|X|$} &
    \multicolumn{1}{c|}{$|X\cap R_i^{-}|$} &
    \multicolumn{1}{c}{$\frac{|X\cap R_i^{-}|}{|R_i^{-}|}$} &
    \multicolumn{1}{c|}{$\frac{|X\cap R_i^{-}|}{|X|}$}
    \\
    \hline
    マクロ経済学 &  1872 & 22/55/116 & .35/.27/.06 & .01/.03/.06\\
    投資関数 &  1142 & 16/41/100 & .26/.17/.06 & .01/.04/.09\\
    有効需要 &  3243 & 33/88/200 & .53/.36/.11 & .01/.03/.06\\
    マネーサプライ &  1872 & 29/84/207 & .47/.35/.11 & .02/.04/.11\\
    \hline
    \multicolumn{5}{l}{\tiny }\\[-5pt]
    \multicolumn{5}{l}{「ミクロ経済学」($|R_i^{-}|=58/205/1075$)} \\
    \hline
    \multicolumn{1}{|c}{入力用語} & 
    \multicolumn{1}{|c}{$|X|$} &
    \multicolumn{1}{c|}{$|X\cap R_i^{-}|$} &
    \multicolumn{1}{c}{$\frac{|X\cap R_i^{-}|}{|R_i^{-}|}$} &
    \multicolumn{1}{c|}{$\frac{|X\cap R_i^{-}|}{|X|}$}
    \\
    \hline
    ミクロ経済学 &  1934 & 19/51/105 & .33/.25/.10 & .01/.03/.05\\
    無差別曲線 &  864 & 18/46/ 80 & .31/.22/.07 & .02/.05/.09\\
    限界効用 &  1628 & 27/57/112 & .47/.28/.10 & .02/.04/.07\\
    需要曲線 &  1411 & 20/60/108 & .34/.29/.10 & .01/.04/.08\\
    \hline
   \end{tabular}
 \end{center}
\end{table}

この結果から，次のことが観察される．
\begin{enumerate}
\item
本モジュールで収集される候補語の数は，おおよそ800〜3000である．
ただし，800未満の場合も存在する．
\end{enumerate}

収集された候補語の数が特に少なかったシードワードは，「線形識別関
数(252個)」である．この語は，そもそもウェブでのヒット数が少なく
($hits(\text{`線形識別関数'})=130$)，収集されるウェブページ数が少ない．
このことが，少数の候補語しか得られない原因となっている．経験的には，収
集される候補語の数は，シードワードのヒット数と正の相関がある．

\begin{enumerate} \setcounter{enumi}{1}
\item 
本モジュールが収集した候補語集合の中には，
シードワードと同じ専門分野の参照用語が含まれている．
参照セット$R_3$を用いた評価では，
平均的に14語程度，$R_3$の4割強が候補語集合に含まれている．
\end{enumerate}

本モジュールが候補語を収集する範囲は，非常に限定されている(シードワー
ドを中心とした前後2文)にもかかわらず，一定量の参照用語を収集すること
に成功している．これは，本モジュールが有効に機能していることを示している．

\begin{enumerate} \setcounter{enumi}{2}
\item 
参照セットを$R_2$，$R_1$に変更して参照用語数を拡大すると，
候補集合に含まれる参照用語の数は増加し，$R_1$では，数十から百を越える参
照用語を含むようになる．しかしながら，参照用語全体に対する比率
($\frac{|X\cap R_i^{-}|}{|R_i^{-}|}$)は減少する．
\end{enumerate}

このことは，候補語集合には，その分野の代表的な専門用語以外の専門用語も
含まれていることを示している．これは望ましい性質である．

しかし同時に，候補語集合は，その分野の専門用語を網羅的に含んでいるわ
けではないことを示している．つまり，候補語収集モジュールも，関連用語選
択モジュールと同様，一つのシードワードから当該分野の専門用語を網羅的に
収集する能力はないということである．

\begin{enumerate} \setcounter{enumi}{3}
\item 
参照セット$R_1$を用いた場合，収集した候補語に対する参照用語の割合(参
照用語の「密度」)は，平均的に6\%程度である．
\end{enumerate}

この「密度」は十分に高いとは言えない．システムの効率化のためには，この
密度を高めることが必要である．候補語集合には多数の一般語が含まれるた
め，既存の国語辞書等を用いて一般語を排除する方法が有効だと考えられる．


\subsection{システム全体の評価}\label{sec:ex_total}

\subsubsection{参照セットを用いた評価}

ここでは，実際にシステム全体を動作させ，適切な関連用語が収集できるかど
うかを参照セットを利用して調べた．具体的には，前節の実験で収集した候補
語とシードワードとの関連度(Jaccard係数，$\chi ^2$統計量)を計算し，関連
度上位$N(=10, 20, 30)$語に，シードワードと同じ分野の参照用語がどれだけ
含まれるかを，$R_3$，$R_2$，$R_1$のそれぞれの参照セットに対して調べた．
その結果を\mbox{表\ref{tbl:total_result}}に示す．

\begin{table}
 \begin{center}\scriptsize
  \caption{システム全体での評価}\label{tbl:total_result}
  \begin{tabular}{|l|c||cc|cc|cc|}
   \multicolumn{8}{l}{「自然言語処理」 }\\
   \hline
   \multicolumn{2}{|c||}{} &
   \multicolumn{2}{c}{$N=10$} & 
   \multicolumn{2}{|c}{$N=20$} &
   \multicolumn{2}{|c|}{$N=30$} \\
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{c||}{$|X\cap R_i^{-}|$} &
   \multicolumn{1}{c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c|}{chi2} \\
   \hline
   自然言語処理 &7/22/87&{\bf 3}/{\bf 4}/{\bf 6}&2/2/3&{\bf 4}/{\bf 7}/{\bf 11}&{\bf 4}/5/ 6&{\bf 4}/{\bf 8}/{\bf 13}&{\bf 4}/5/ 9 \\ 
   意味解析 &11/27/100&{\bf 4}/{\bf 5}/{\bf 8}&2/3/4&{\bf 5}/{\bf 7}/{\bf 11}&{\bf 5}/6/{\bf 11}&{\bf 6}/{\bf 8}/{\bf 14}&5/6/12 \\ 
   形態素解析 &6/24/87&{\bf 2}/{\bf 2}/{\bf 2}&1/1/1&{\bf 4}/{\bf 5}/ {\bf 8}&2/3/ 4&{\bf 4}/{\bf 5}/ {\bf 8}&{\bf 4}/{\bf 5}/ {\bf 8} \\ 
   構文解析 &12/30/114&{\bf 4}/{\bf 4}/{\bf 7}&1/1/4&{\bf 5}/{\bf 5}/ {\bf 9}&2/2/ 5&{\bf 5}/{\bf 6}/{\bf 10}&{\bf 5}/{\bf 6}/ 9 \\ 
   \hline
   \multicolumn{8}{c}{\tiny }\\[-5pt]
   \multicolumn{8}{l}{「情報理論」 }\\
   \hline
   \multicolumn{2}{|c||}{} &
   \multicolumn{2}{c}{$N=10$} & 
   \multicolumn{2}{|c}{$N=20$} &
   \multicolumn{2}{|c|}{$N=30$} \\
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{c||}{$|X\cap R_i^{-}|$} &
   \multicolumn{1}{c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c|}{chi2} \\
   \hline
   情報理論 & 14/28/64 & 2/5/5 & {\bf 5}/{\bf 6}/{\bf 6} & 4/ 7/ 9 & {\bf 7}/ {\bf 9}/{\bf 10} & 6/ 9/11 & {\bf 8}/{\bf 12}/{\bf 14} \\ 
   通信路容量 & 9/17/40 & {\bf 5}/5/6 & {\bf 5}/{\bf 6}/{\bf 7} & {\bf 6}/ {\bf 7}/ {\bf 9} & {\bf 6}/ {\bf 7}/ 8 & {\bf 7}/ {\bf 8}/{\bf 14} & {\bf 7}/ {\bf 8}/11 \\ 
   情報源符号化 & 15/27/55 & {\bf 6}/{\bf 7}/{\bf 9} & 5/{\bf 7}/8 & {\bf 7}/{\bf 10}/{\bf 14} & {\bf 7}/{\bf 10}/13 & 8/{\bf 13}/{\bf 19} & {\bf 9}/{\bf 13}/18 \\ 
   エントロピー & 5/17/40 & 0/0/{\bf 1} & 0/0/0 & {\bf 1}/ {\bf 1}/ {\bf 2} & 0/ 0/ 0 & {\bf 1}/ {\bf 1}/ {\bf 2} & 0/ 0/ 1 \\ 
   \hline
   \multicolumn{8}{c}{\tiny }\\[-5pt]
   \multicolumn{8}{l}{「パターン認識」 }\\
   \hline
   \multicolumn{2}{|c||}{} &
   \multicolumn{2}{c}{$N=10$} & 
   \multicolumn{2}{|c}{$N=20$} &
   \multicolumn{2}{|c|}{$N=30$} \\
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{c||}{$|X\cap R_i^{-}|$} &
   \multicolumn{1}{c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c|}{chi2} \\
   \hline
   パターン認識 & 8/33/95 & {\bf 2}/{\bf 3}/{\bf 6} & 0/2/3 & {\bf 3}/{\bf 4}/{\bf 11} & 1/3/ 7 & {\bf 3}/5/{\bf 15} & 2/{\bf 6}/11 \\ 
   線形識別関数 & 7/17/40 & 1/4/{\bf 9} & {\bf 2}/{\bf 5}/{\bf 9} & {\bf 3}/{\bf 6}/{\bf 12} & {\bf 3}/{\bf 6}/11 & {\bf 3}/{\bf 6}/{\bf 14} & {\bf 3}/{\bf 6}/13 \\ 
   部分空間法 & 7/11/23 & {\bf 1}/{\bf 1}/{\bf 2} & {\bf 1}/{\bf 1}/{\bf 2} & {\bf 1}/{\bf 1}/ {\bf 3} & {\bf 1}/{\bf 1}/ 2 & {\bf 1}/{\bf 1}/ {\bf 3} & {\bf 1}/{\bf 1}/ {\bf 3} \\ 
   特徴抽出 & 6/24/66 & {\bf 1}/{\bf 3}/{\bf 6} & 1/2/3 & {\bf 1}/{\bf 3}/ {\bf 8} & {\bf 1}/{\bf 3}/ {\bf 8} & {\bf 1}/3/10 & {\bf 1}/{\bf 4}/{\bf 11} \\ 
   \hline
   \multicolumn{8}{c}{\tiny }\\[-5pt]
   \multicolumn{8}{l}{「バイオインフォマティクス」 }\\
   \hline
   \multicolumn{2}{|c||}{} &
   \multicolumn{2}{c}{$N=10$} & 
   \multicolumn{2}{|c}{$N=20$} &
   \multicolumn{2}{|c|}{$N=30$} \\
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{c||}{$|X\cap R_i^{-}|$} &
   \multicolumn{1}{c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c|}{chi2} \\
   \hline
   {\tiny バイオインフォマティクス} & 10/34/130 & 0/0/{\bf 2} & 0/0/{\bf 2} & 0/{\bf 2}/ {\bf 7} & 0/0/ 3 & {\bf 1}/ {\bf 3}/{\bf 10} & 0/2/ 6 \\ 
   相同性 & 14/41/122 & {\bf 2}/{\bf 4}/{\bf 6} & 1/1/4 & {\bf 2}/4/ 8 & {\bf 2}/{\bf 5}/ {\bf 9} & {\bf 2}/ {\bf 5}/{\bf 12} & {\bf 2}/{\bf 5}/{\bf 12} \\ 
   スプライシング & 12/31/99 & {\bf 3}/{\bf 5}/{\bf 8} & 1/1/2 & {\bf 3}/{\bf 5}/{\bf 10} & {\bf 3}/4/ 6 & {\bf 3}/ {\bf 6}/{\bf 11} & {\bf 3}/5/ 8 \\ 
   GenBank & 13/31/75 & {\bf 3}/4/4 & {\bf 3}/{\bf 5}/{\bf 6} & {\bf 4}/{\bf 8}/{\bf 11} & {\bf 4}/{\bf 8}/10 & {\bf 6}/{\bf 12}/{\bf 17} & 4/8/12 \\
   \hline
   \multicolumn{8}{c}{\tiny }\\[-5pt]
   \multicolumn{8}{l}{「マクロ経済学」 }\\
   \hline
   \multicolumn{2}{|c||}{} &
   \multicolumn{2}{c}{$N=10$} & 
   \multicolumn{2}{|c}{$N=20$} &
   \multicolumn{2}{|c|}{$N=30$} \\
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{c||}{$|X\cap R_i^{-}|$} &
   \multicolumn{1}{c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c|}{chi2} \\
   \hline
   マクロ経済学 & 22/55/116 & 0/{\bf 1}/{\bf 2} & 0/0/1 & {\bf 1}/{\bf 2}/ {\bf 4} & 0/1/ 2 & {\bf 2}/ {\bf 4}/ {\bf 7} & 0/ 1/ 3 \\ 
   投資関数 & 16/41/100 & {\bf 5}/{\bf 6}/{\bf 7} & 4/5/5 & 5/{\bf 8}/{\bf 13} & {\bf 6}/{\bf 8}/{\bf 13} & {\bf 6}/{\bf 10}/18 & {\bf 6}/{\bf 10}/{\bf 19} \\ 
   有効需要 & 33/88/200 & {\bf 3}/{\bf 4}/{\bf 7} & 2/3/3 & {\bf 5}/{\bf 9}/{\bf 14} & 4/6/ 9 & {\bf 9}/{\bf 17}/{\bf 23} & 6/12/17 \\ 
   マネーサプライ & 29/84/207 & {\bf 3}/{\bf 3}/{\bf 8} & 2/2/6 & {\bf 5}/{\bf 6}/{\bf 11} & 4/5/ 9 & {\bf 5}/ {\bf 9}/{\bf 15} & {\bf 5}/ 8/{\bf 15} \\ 
   \hline
   \multicolumn{8}{c}{\tiny }\\[-5pt]
   \multicolumn{8}{l}{「ミクロ経済学」 }\\
   \hline
   \multicolumn{2}{|c||}{} &
   \multicolumn{2}{c}{$N=10$} & 
   \multicolumn{2}{|c}{$N=20$} &
   \multicolumn{2}{|c|}{$N=30$} \\
   \multicolumn{1}{|c}{入力用語} & 
   \multicolumn{1}{c||}{$|X\cap R_i^{-}|$} &
   \multicolumn{1}{c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c|}{chi2} \\
   \hline
   ミクロ経済学 & 19/51/105 & 0/{\bf 2}/{\bf 3} & 0/1/1 & 1/ 6/ 8 & {\bf 2}/ {\bf 7}/ {\bf 9} & 2/ 7/{\bf 12} & {\bf 3}/ {\bf 9}/11 \\ 
   無差別曲線 & 18/46/80 & {\bf 6}/{\bf 6}/{\bf 8} & 5/5/6 & {\bf 10}/{\bf 13}/{\bf 16} & 9/10/14 & 10/{\bf 14}/{\bf 20} & {\bf 11}/{\bf 14}/{\bf 20} \\ 
   限界効用 & 27/57/112 & {\bf 7}/{\bf 7}/{\bf 9} & 4/4/6 & {\bf 12}/{\bf 13}/{\bf 17} & 8/ 9/12 & {\bf 13}/{\bf 16}/{\bf 22} & 11/15/20 \\ 
   需要曲線 & 20/60/108 & {\bf 5}/{\bf 8}/{\bf 9} & {\bf 5}/{\bf 8}/{\bf 9} & {\bf 10}/{\bf 16}/{\bf 17} & 7/11/14 & {\bf 10}/18/21 & {\bf 10}/{\bf 19}/{\bf 22} \\ 
   \hline
  \end{tabular}
 \end{center}
\end{table}

この結果から，次のことが観察される．
\begin{enumerate}
\item 
参照セット$R_3$を用いた場合，
候補語集合に平均的に14個程度の参照用語が含まれているが，
そのうち関連度上位10位に含まれるのは，2〜3個程度である．
\item 
参照セット$R_1$を用いた場合，
候補語集合に平均的に100個弱の参照用語が含まれおり，
関連度上位10位に6個程度，上位20位に10個程度，上位30位に13個程度
の参照用語が含まれている．
\end{enumerate}

厳しい条件(参照セット$R_3$)ではそれほど性能が出ていないが，制限を緩
めた参照セット($R_1$)では，上位30位の半数程度が参照用語となっている．
このことは，本システムは，「ある分野の代表的な用語から，同じ分野の専門
用語を収集する」のではなく，「ある専門用語から，それと強く関連す
る比較的狭い範囲の専門用語を収集する」ことに長けていることを示唆する．
本システムは，このようなタスクにおいては，有効に機能していると考えられ
る．この点については，次の主観的評価のところで再度確認する．

\begin{enumerate} \setcounter{enumi}{2}
\item 
与えるシードワードによっては，参照用語をほとんど収集することができない
場合が存在する．
\end{enumerate}

本実験で極端に性能が悪かったのは，「エントロピー」と「部分空間法」をシー
ドワードとした場合である．エントロピーは「情報理論」分野以外(例えば
「熱力学」)でも用いられる専門用語である．本システムは，シードワードの
みを入力とするため，複数の分野で使われる専門用語に対して，関連用語を分
野毎に出力する能力を持たない．そのため，システムが出力する用語に，複数
の分野の専門用語が混在することになる．本実験では，「エントロピー」に対
する参照用語は「情報理論」の用語に限られるため，システムの出力に含まれ
る参照用語数は相対的に小さくなる．

一方，「部分空間法」は比較的広がりを持たない専門用語であり，それに強く
関連する専門用語が，そもそも参照セットにあまり存在していない．このこと
が上記の結果をもたらしていると考えられる．

\begin{enumerate} \setcounter{enumi}{3}
\item 
Jaccard係数と$\chi^2$統計量の2つの尺度では，使用する参照セットや
$N$の大小にかかわらず，大半のシードワードにおいて，
Jaccard係数の方が良い結果が得られている．
\end{enumerate}

つまり，Jaccard係数と$\chi^2$統計量の優劣が，\mbox{\ref{sec:ex_rel}節}の実験と
逆転している．この点についても，主観的評価のところで考察する．

\subsubsection{主観的評価}

最後に，「自然言語処理」分野について，主観的評価を行なった．具体的には，
それぞれのシードワードに対して得られた関連度上位30位までの用語を，
\begin{description}
\item[専門用語性] 該当用語は専門用語として適切か
\item[関連性] 該当用語はシードワードと強く関連しているか
\end{description}
という2つの観点でそれぞれ3段階の評点を付与した．
\begin{description}
 \item[A] 専門用語として適切である／シードワードと強く関連している
 \item[B] どちらともいえない(判断しかねる)
 \item[C] 専門用語として不適切である／シードワードと強く関連していない
\end{description}

2名の評価者(著者のうちの2名)が独立にこの評価を行ない，最終的に，
2名の評価者が専門用語性と関連性の両方でいずれもAと判定した用語を，
シードワードの関連用語(正解)とみなした．

上記の主観的評価の結果を\mbox{表\ref{tbl:subjective_evl}}に示す．この
表では，参照セットを用いた場合の結果も併せ，それぞれの正解の数を
「$R_3/R_2/R_1/\mbox{主観的評価}$」の形式で示した．

\begin{table}
 \begin{center}\scriptsize
  \caption{「自然言語処理」分野に対する主観的評価}\label{tbl:subjective_evl}
  \begin{tabular}{|l||rr|rr|rr|}
   \hline
   \multicolumn{1}{|c||}{} &
   \multicolumn{2}{c}{$N=10$} & 
   \multicolumn{2}{|c}{$N=20$} &
   \multicolumn{2}{|c|}{$N=30$} \\
   \multicolumn{1}{|c||}{入力用語} & 
   \multicolumn{1}{c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c}{chi2} &
   \multicolumn{1}{|c}{jac} &
   \multicolumn{1}{c|}{chi2} \\
   \hline
   自然言語処理 & {\bf 3}/{\bf 4}/{\bf 6}/ {\bf 7} & 2/2/3/{\bf 7} & {\bf 4}/{\bf 7}/{\bf 11}/{\bf 16} & {\bf 4}/5/ 6/14 & {\bf 4}/{\bf 8}/{\bf 13}/{\bf 24} & {\bf 4}/5/ 9/20 \\
   意味解析 & {\bf 4}/{\bf 5}/{\bf 8}/{\bf 10} & 2/3/4/6 & {\bf 5}/{\bf 7}/{\bf 11}/{\bf 18} & {\bf 5}/6/{\bf 11}/14 & {\bf 6}/{\bf 8}/{\bf 14}/{\bf 25} &  5/6/12/17 \\
   形態素解析 & {\bf 2}/{\bf 2}/{\bf 2}/ {\bf 9} & 1/1/1/7 & {\bf 4}/{\bf 5}/ {\bf 8}/{\bf 17} & 2/3/ 4/11 & {\bf 4}/{\bf 5}/ {\bf 8}/{\bf 20} & {\bf 4}/{\bf 5}/ {\bf 8}/16 \\
   構文解析 & {\bf 4}/{\bf 4}/{\bf 7}/ {\bf 8} & 1/1/4/7 & {\bf 5}/{\bf 5}/ {\bf 9}/{\bf 12} & 2/2/ 5/{\bf 12} & {\bf 5}/{\bf 6}/{\bf 10}/{\bf 17} & {\bf 5}/{\bf 6}/ 9/{\bf 17} \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

この結果から，次のことが観察される．
\begin{enumerate}
\item
主観的評価で正解と判定された用語数は，参照セット$R_1$を正解とした
場合の用語数より，いずれの場合も多い．
\item
Jaccard係数を用いた場合，上位10位では8〜9個程度，
上位20位では16個程度，上位30位では22個程度の正解が含まれている．
\end{enumerate}

これらの事実は，参照セットを用いたシステムの評価は，過小評価となっているこ
とを示している．
\mbox{\ref{sec:reference}節}で述べたように，
参照セットはその分野の専門用語を網羅的に集めたものではない．そのため，
参照セットに含まれなくてもその分野の専門用語として認められ，かつ，シー
ドワードと強く関連するような用語が数多く存在する．上記の結果は，これらの用
語を関連度上位に収集できているということを意味し，システムが有効に機能
していることを示している．

\begin{enumerate}\setcounter{enumi}{2}
\item
すべての場合において，Jaccard係数を用いた方が，$\chi ^2$統計量を用いた
場合より同等か良い結果を示している．
\end{enumerate}

この点については，最後に考察する．


\begin{table}
 \begin{center}\scriptsize
  \caption{「自然言語処理」に対するシステムの出力}\label{tbl:nlp_result}
  \begin{tabular}{|l|rr|rr|rr|cc|}
   \hline
   \multicolumn{1}{|c|}{} &
   \multicolumn{2}{c|}{} &
   \multicolumn{2}{c|}{$Jac(s,t)$} &
   \multicolumn{2}{c|}{$\chi ^2(s,t)$} &
   \multicolumn{2}{c|}{評価} \\
   \multicolumn{1}{|c|}{$t$} &
   \multicolumn{1}{c}{$hits(t)$} &
   \multicolumn{1}{c|}{$hits(s\&t)$} &
   \multicolumn{1}{c}{順位} &
   \multicolumn{1}{c|}{スコア} &
   \multicolumn{1}{c}{順位} &
   \multicolumn{1}{c|}{スコア} &
   \multicolumn{1}{c}{参照} &
   \multicolumn{1}{c|}{主観} \\
   \hline
   言語処理 & 19700 & 9950 &  1 & 0.505 & 1 & $6.86\times 10^6$ & & $\surd$ \\
   自然言語 & 20300 & 9950 & 2 & 0.490 & 2 & $6.66\times 10^6$ & 1 & $\surd$\\
   自然言語処理技術 & 1020 & 1020 & 3 & 0.103 & 3 & $1.39\times 10^6$  &  & \\
   形態素解析 & 5570 & 1270 & 4 & 0.089 & 7 & $3.94\times 10^5$  & 3 & $\surd$ \\
   形態素 & 8440 & 1460 & 5 & 0.086 & 9 & $3.43\times 10^5$  & 3 &$\surd$ \\
   コーパス & 15400 & 1740 & 6 & 0.074 & 12 & $2.66\times 10^5$  & 2 &$\surd$ \\
   構文解析 & 8190 & 1220 & 7 & 0.072 & 13 & $2.46\times 10^5$  & 3 &$\surd$ \\
   言語処理学会 & 1500 & 734 & 8 & 0.069 & 5 & $4.90\times 10^5$  &  &$\surd$ \\
   音声言語 & 9490 & 892 & 9 & 0.048 & 26 & $1.13\times 10^5$  & 1 & \\
   言語情報 & 9200 & 859 & 10 & 0.047 & 27 & $1.08\times 10^5$  &  & \\
   \hline
   機械学習 & 3750 & 612 & 11 & 0.047 & 21 & $1.35\times 10^5$  &  & $\surd$\\
   言語理解 & 3550 & 595 & 12 & 0.046 & 22 & $1.35\times 10^5$  & 1 & $\surd$\\
   自然言語処理研究会 & 406 & 406 & 13 & 0.041 & 4 & $5.55\times 10^5$  &  & $\surd$\\
   意味解析 & 1610 & 430 & 14 & 0.039 & 16 & $1.56\times 10^5$  & 3 & $\surd$\\
   知識表現 & 2190 & 440 & 15 & 0.038 & 24 & $1.20\times 10^5$  & 1 & $\surd$\\
   パターン認識 & 9370 & 699 & 16 & 0.038 &  &  &  & \\
   情報抽出 & 3110 & 462 & 17 & 0.037 &  &  & 2 & $\surd$ \\
   意味論 & 13900 & 799 & 18 & 0.035 &  &  &  & $\surd$\\
   人工知能 & 60100 & 2330 & 19 & 0.034 & 25 & $1.20\times 10^5$    &  & $\surd$\\
   機械翻訳 & 29500 & 1290 & 20 & 0.034 &  &  & 2 & $\surd$ \\
   \hline
   知識処理 & 2640 & 406 & 21 & 0.033 &  &  &  & $\surd$\\
   自動要約 & 1110 & 355 & 22 & 0.033 & 17  & $1.55\times 10^5$  &  & $\surd$\\
   知識ベース & 6310 & 520 & 23 & 0.033 &   & &  & $\surd$\\
   言語理論 & 3450 & 425 & 24 & 0.033 &   & & 1 & $\surd$\\
   自然言語処理学 & 305 & 305 & 25 & 0.031 & 6 & $4.17\times 10^5$  &  & \\
   人工知能学会誌 & 1750 & 334 & 26 & 0.029 &  &  &  & \\
   長尾真 & 2480 & 351 & 27 & 0.029 &  &  &  & $\surd$\\
   認知科学 & 17000 & 759 & 28 & 0.029 &  &  &  & $\surd$\\
   曖昧性 & 3210 & 365 & 29 & 0.029 &  &  & 2 & $\surd$\\
   対話システム & 2370 & 341 & 30 & 0.028 &  &  &  &$\surd$ \\
   \hline
   自然言語処理学講座 & 266 & 266 &  &  &  8 & $3.63\times 10^5$  &  & \\
   自然言語処理システム & 237 & 236 &  &  &  10 & $3.21\times 10^5$  &  & $\surd$\\
   自然言語処理研究 & 213 & 213 &  &  &  11 & $2.91\times 10^5$  &  & \\
   自然言語処理入門 & 123 & 123 &  &  &  14 & $1.68\times 10^5$  &  & \\
   計算言語学 & 461 & 234 &  &  & 15  & $1.62\times 10^5$  &  & $\surd$\\
   言語資源 & 438 & 222 &  &  & 18 & $1.54\times 10^5$  &  & $\surd$\\
   JAIST & 265 & 170 &  &  & 19 & $1.49\times 10^5$  &  & \\
   音声言語処理 & 621 & 253 &  &  & 20 & $1.41\times 10^5$  &  & $\surd$\\
   自然言語処理研究室 & 95 & 95 &  &  & 23 & $1.30\times 10^5$  &  & \\
   奥村学 & 473 & 189 &  &  & 28 & $1.03\times 10^5$  &  & $\surd$\\
   アルゴリズム & 127000 & 3080 &  &  & 29 & $9.70\times 10^4$  &  & \\
   テキスト自動要約 & 221 & 124 &  &  & 30 & $9.49\times 10^4$  &  & $\surd$\\
   \hline
  \end{tabular}
 \end{center}
\end{table}

「自然言語処理」をシードワードとしたときのシステムの出力(上位30語)と
その評価を
\mbox{表\ref{tbl:nlp_result}}に示す．この表において，「$Jac(s,t)$順位」は，
Jaccard係数を用いた場合の用語$t$の順位，「$\chi ^2(s,t)$順位」は，
$\chi ^2$統計量を用いた場合の用語$t$の順位である．順位の空欄は，その尺
度でその用語が上位30語に入らなかったことを示す．また，「参照」の数字は
参照セット$R_i$に含まれる場合の$i$の最大値を示す．「主観」欄のチェックは，
主観的評価において関連用語と判定されたことを示す．

この結果からも，本システムが得意とするのは，「ある専門用語(シードター
ム)から，それと強く関連する比較的狭い範囲の専門用語を収集する」
というタスクであることが確認できる．「自然言語処理」はひとつの分野を統
括する用語であるため，「形態素解析」や「構文解析」といった代表的用語が
得られているが，「茶筌」や「文脈自由文法」といった，それぞれのサブ分野
の専門用語は得ることができない．

我々は，このようなシステムの特性を問題視しない．逆に，好ましい特性と考
える．なぜならば，狭い範囲でも強く関連する用語を得ることができるのであ
れば，それを再帰的に適用することによって，関連用語集合を段階的に拡大し
ていくことができるからである．事実，「茶筌」や「文脈自由文法」といった
専門用語は，それぞれ「形態素解析」や「構文解析」をシードワードとしたと
き，本システムは，これらの用語をその関連用語として出力することができる．

\mbox{表\ref{tbl:nlp_result}}において，
$\chi ^2$統計量の上位30位以内に含まれ，かつ，Jaccard 
係数では30位以内に含まれなかった用語に見られる特徴として，「自然言語処
理学講座」や「自然言語処理研究」などの用語内にシードワードを含む
用語がある．これらの用語は，シードワードを含むため，サーチエンジンによ
るAND検索では，シードワードと100\%共起するが，用語自身のヒット数
$hits(t)$はやや小さい用語である．既に述べたように，Jaccard係数も$\chi
^2$統計量も，共起の割合が同じであれば，頻度が低い用語ほどスコアは小さ
くなるが，両者を比較すると，$\chi ^2$統計量の方が，低頻度語に高いスコ
アを与える傾向がある．この差が，現実の状況において，2つの尺度の優劣の
逆転現象をもたらす要因となっている．しかしながら，その差はそれほど大きく
ないため，どちらの尺度を用いるかはシステムの利用者に委ねるという立場を
結論とした．

