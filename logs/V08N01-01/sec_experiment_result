本節では，ランダム・プロジェクションを用いた検索モデルを構築し，その評価として，MEDLINEを用いた検索実験について述べる．
実験で用いたデータは，情報検索システムの評価用テストコレクションであるMEDLINEを利用した．
MEDLINEは医学・生物学分野における英文の文献情報データベースで，検索の対象となる文書の件数は1033件で，約1Mbyteの容量を持つテキストデータである．
また，MEDLINEには30個の評価用検索要求文と各要求文に対する正解文書が用意されている．
MEDLINEに含まれている1033件の文書全体から，前処理として，``a''や``about''などの一般的な439個の英単語を不要語リストに指定して，文書の内容と関係のほとんどない単語は削除した．
この後，接辞処理を行い，残った英単語を語幹に変換する処理を行った．
この前処理の結果，文書全体に5526個あった単語から，4329個の単語が索引語として抽出され，実験データとして用いた．
実験では，MEDLINEから前処理により得られた索引語を要素とする文書ベクトルと検索要求ベクトルを作成し，比較することで検索スコアを計算する．
文書ベクトルを作成するとき，ベクトルの要素には局所的，大域的な索引語の分布を考慮するために，索引語の頻度に重み付けした数値が用いられる．
数多く提案されている重みづけ手法で，今回の実験では以下の式で定義された対数エントロピー重み[CITE]を用いた．
[MATH]は[MATH]番目の文書に対する[MATH]番目の索引語への重み，[MATH]は文書全体に対する[MATH]番目の索引語への重みを表す．
ここで，[MATH]は全文書数，[MATH]は[MATH]番目の文書に出現する[MATH]番目の索引語の頻度，[MATH]は文書集合全体における[MATH]番目の索引語の頻度を表す．
これより，[MATH]番目の文書から得られる文書ベクトルの[MATH]番目の要素[MATH]は，
となる．
得られた文書ベクトルから，球面[MATH]平均アルゴリズムを用い，これらの文書ベクトルより指定された数の概念ベクトルを作成する．
作成した概念ベクトルを結合した行列に対し，ランダム・プロジェクションを行い，文書ベクトル，検索要求ベクトルの次元を削減する．
次元の削減されたベクトルを用いて，内積の計算を行い，その値を各文書に対する検索スコアとする．
これらのスコアのうち，上位50文書を検索結果として出力する．
検索システムの評価には，一般的に用いられている正解率(Precision)と再現率(Recall)を用いた[CITE][CITE]．
再現率と正解率は，それぞれ個別に用いて，システム評価を行うことができるが，本実験では，一般にランクづけ検索システムの評価に用いられる再現率・正解率曲線を用い，システムの評価を行った．
この曲線は，各質問に対しひとつの曲線が作成されるが，本稿の検索システム評価には，全30個の質問に対する各再現率での平均を計算した再現率・正解率曲線を用いた．
本実験では，ランダム・プロジェクションにより，ベクトルの次元を100から900まで圧縮した検索モデルについて，検索実験を行った．
その結果，各次元における平均正解率は表[REF_pre_sys]のようになった．
平均正解率は，ベクトルの次元が大きくなるにつれて増加し，次元数300において，次元圧縮を行わないベクトル空間モデルよりも良い結果となった．
また，次元数が400から500に変化させたときの平均正解率の増加が最も大きく，それ以降は変化の割合が少なくなっている．
次元数を大きくすれば，検索に必要な計算量が増加する．
このことから，効果的な検索を行うためには，全文書数の約半分に次元圧縮を行う必要があることが分かった．
検索モデルを作成する時間，および，一つの検索要求に対し，検索を行うために必要な時間を測定した結果を述べる．
検索実験には，Ultra Sparc(330MHz)のマシンを使用し，ベクトルの次元を500とした結果，表[REF_time]に示すように，ランダム・プロジェクションを用いた場合，モデルを作成する時間は約11分必要であった．
LSIの場合，SVDの計算についてはSVDPACKの中で最も高速なLanczos法を利用し，同様にベクトルの次元を500とした結果，モデルを作成する時間は約24分で必要であった．
この結果，ランダム・プロジェクションはLSIに比べ，高速に検索モデルを構築することができた．
このモデル作成時間においては，メモリサイズの大きさによる，SVDの計算時間に与える影響が考えられる．
スワップ領域を用いるほどの大規模なデータについては大きな影響を及ぼし，モデル作成の時間を多く必要とするが，本実験において用いたマシンには640Mバイトのメモリを搭載しているため，MEDLINEコレクションのような規模のデータに対しては，メモリサイズの影響はほとんどないと考えられる．
本実験で用いたMEDLINEには収録されているデータは1033件と比較的少ない．
このため，文書数を変化させたときの検索モデル構築時間の変化について比較を行った．
文書数を増加させるために，MEDLINEと同様なテストコレクションであるCISIを併せた2493記事，さらにCRANFIELDを併せた3893記事について，それぞれの検索モデル作成時間を測定した．
その結果，ランダム・プロジェクションとLSIのモデル作成時間は表[REF_model_time]のようになった．
これより，文書数が増加に対して球面[MATH]平均アルゴリズムの1回の反復による計算量が大きくなるのであるが，ランダム・プロジェクションが検索時間に関しても有効であることが分かる．
しかし，非常に大規模な文書数に対しては，より1回の反復による計算量が増加するため，反復計算を必要とせずに，球面[MATH]平均アルゴリズム並の概念ベクトルを得ることが課題となった．
ランダム・プロジェクションを用いた検索モデルに対して，モデルとしての有効性について評価をする．
この評価をするために，次元圧縮をしていない元のベクトル空間モデルと特異値分解を用いたLSIによる検索モデルについての検索実験も同時に行い，性能を比較した．
このとき，比較として用いたLSIは，次元数100として次元圧縮した検索モデルを用いている．
これらの検索モデルについて，同様に検索実験を行い，すべての検索質問の平均を求めた再現率・正解率曲線を図[REF_re_pre]に示す．
図[REF_re_pre]において，横軸は再現率を表し，縦軸は正解率を表す．
またグラフの`LSI100'は次元数100のLSI，`VSM'は次元圧縮なしのベクトル空間モデル，`RP500'，`RP700'，`RP900'はランダム・プロジェクションによるそれぞれに示された次元数に圧縮したモデルの実験結果である．
その結果，ベクトル空間モデルと比較して，ランダム・プロジェクションを用いた検索モデルは，大幅に性能が改善されていることが分かった．
また，次元数100のLSIと比較すると，ランダム・プロジェクションはLSIに比べ少し下がってはいるものの，ほぼ同じ程度に検索精度が改善されていることを示している．
このことから，ランダム・プロジェクションが検索モデルとして，LSIと同等の性能を持っていることが分かる．
[tb]
\ecaption{Recall-Precision curve for comparison between models}
ランダム・プロジェクションで次元圧縮に用いられる概念ベクトルが有効であるかを評価するために，他のベクトルを用いて次元圧縮が行われた場合との検索結果の比較を行った．
ベクトルには，乱数を用いて，全要素の平均が0，分散が1の正規分布[MATH]となるベクトルと，指定された数の文書ベクトルを任意に抽出して得られた部分集合からなるベクトルを，それぞれ次元圧縮に用いた．
この結果，再現率・正解率曲線は図[REF_concept]となった．
ここで，`Random'は正規分布となるベクトル，`Subset'は文書ベクトルの部分集合を表し，共にベクトルの次元数は500として，次元圧縮を行ったモデルの実験結果である．
また，サンプルに使った文書集合の偏りを考慮するため，グラフに示した実験でのベクトルの他にいくらかのサンプルを用意し，同様の実験を行い，平均的な検索精度を求めた．
その結果，正規分布による任意のベクトルにおける平均正解率の平均値は0.38，文書ベクトルの部分集合における平均値は0.47となった．
このグラフと平均値から，正規分布の性質を持つ任意のベクトルや文書ベクトルの部分集合を用いて次元圧縮を行った結果とそれぞれ比較すると，概念ベクトルを用いて次元圧縮を行った結果が，明らかに優れていることが分かる．
乱数により生成したベクトルを用いた場合，これらのベクトルの各要素には，索引の重要度や索引語間の関連性はほとんど存在しない．
このようなベクトルにより次元圧縮を行う場合，ベクトルの要素には文書の内容を表すような潜在的な意味がほとんど含まれていないために，検索性能が下がってしまったと考えられる．
文書ベクトルの部分集合を用いた場合は，次元圧縮後，ベクトル中のいくつかの要素が似通った意味を持っているために，検索性能が下がったと考えられる．
概念ベクトルは，内容の似通った文書がクラスタリングによりひとつにまとめられ，それらの重心を求めることで，文書の内容を端的に表すことができる．
また，クラスタリングを行うことで似通った内容を持つ概念ベクトルが少なくなるため，内容がほとんど変わらない概念ベクトルを重複して生成する可能性が少ない．
しかし，文書の部分集合では，内容の重複した文書が複数存在する可能性がある．
このため，次元圧縮後のベクトル空間モデルに意味の重なった要素が存在し，検索性能が下がってしまう可能性が大きくなってしまうと考えられる．
これらのことにより，情報検索に対してランダム・プロジェクションを用いて次元圧縮を行う場合，内容の近い文書や同義語などのような索引語の特徴を表した概念ベクトルを用いることにより，優れた検索性能が得られることが示された．
[tb]
\ecaption{Recall-Precision curve for comparison between vectors}
本節では，ランダム・プロジェクションを用いた検索モデルを構築し，その評価として，MEDLINEを用いた検索実験について述べる．
実験で用いたデータは，情報検索システムの評価用テストコレクションであるMEDLINEを利用した．
MEDLINEは医学・生物学分野における英文の文献情報データベースで，検索の対象となる文書の件数は1033件で，約1Mbyteの容量を持つテキストデータである．
また，MEDLINEには30個の評価用検索要求文と各要求文に対する正解文書が用意されている．
MEDLINEに含まれている1033件の文書全体から，前処理として，``a''や``about''などの一般的な439個の英単語を不要語リストに指定して，文書の内容と関係のほとんどない単語は削除した．
この後，接辞処理を行い，残った英単語を語幹に変換する処理を行った．
この前処理の結果，文書全体に5526個あった単語から，4329個の単語が索引語として抽出され，実験データとして用いた．
実験では，MEDLINEから前処理により得られた索引語を要素とする文書ベクトルと検索要求ベクトルを作成し，比較することで検索スコアを計算する．
文書ベクトルを作成するとき，ベクトルの要素には局所的，大域的な索引語の分布を考慮するために，索引語の頻度に重み付けした数値が用いられる．
数多く提案されている重みづけ手法で，今回の実験では以下の式で定義された対数エントロピー重み[CITE]を用いた．
[MATH]は[MATH]番目の文書に対する[MATH]番目の索引語への重み，[MATH]は文書全体に対する[MATH]番目の索引語への重みを表す．
ここで，[MATH]は全文書数，[MATH]は[MATH]番目の文書に出現する[MATH]番目の索引語の頻度，[MATH]は文書集合全体における[MATH]番目の索引語の頻度を表す．
これより，[MATH]番目の文書から得られる文書ベクトルの[MATH]番目の要素[MATH]は，
となる．
得られた文書ベクトルから，球面[MATH]平均アルゴリズムを用い，これらの文書ベクトルより指定された数の概念ベクトルを作成する．
作成した概念ベクトルを結合した行列に対し，ランダム・プロジェクションを行い，文書ベクトル，検索要求ベクトルの次元を削減する．
次元の削減されたベクトルを用いて，内積の計算を行い，その値を各文書に対する検索スコアとする．
これらのスコアのうち，上位50文書を検索結果として出力する．
検索システムの評価には，一般的に用いられている正解率(Precision)と再現率(Recall)を用いた[CITE][CITE]．
再現率と正解率は，それぞれ個別に用いて，システム評価を行うことができるが，本実験では，一般にランクづけ検索システムの評価に用いられる再現率・正解率曲線を用い，システムの評価を行った．
この曲線は，各質問に対しひとつの曲線が作成されるが，本稿の検索システム評価には，全30個の質問に対する各再現率での平均を計算した再現率・正解率曲線を用いた．
本実験では，ランダム・プロジェクションにより，ベクトルの次元を100から900まで圧縮した検索モデルについて，検索実験を行った．
その結果，各次元における平均正解率は表[REF_pre_sys]のようになった．
平均正解率は，ベクトルの次元が大きくなるにつれて増加し，次元数300において，次元圧縮を行わないベクトル空間モデルよりも良い結果となった．
また，次元数が400から500に変化させたときの平均正解率の増加が最も大きく，それ以降は変化の割合が少なくなっている．
次元数を大きくすれば，検索に必要な計算量が増加する．
このことから，効果的な検索を行うためには，全文書数の約半分に次元圧縮を行う必要があることが分かった．
検索モデルを作成する時間，および，一つの検索要求に対し，検索を行うために必要な時間を測定した結果を述べる．
検索実験には，Ultra Sparc(330MHz)のマシンを使用し，ベクトルの次元を500とした結果，表[REF_time]に示すように，ランダム・プロジェクションを用いた場合，モデルを作成する時間は約11分必要であった．
LSIの場合，SVDの計算についてはSVDPACKの中で最も高速なLanczos法を利用し，同様にベクトルの次元を500とした結果，モデルを作成する時間は約24分で必要であった．
この結果，ランダム・プロジェクションはLSIに比べ，高速に検索モデルを構築することができた．
このモデル作成時間においては，メモリサイズの大きさによる，SVDの計算時間に与える影響が考えられる．
スワップ領域を用いるほどの大規模なデータについては大きな影響を及ぼし，モデル作成の時間を多く必要とするが，本実験において用いたマシンには640Mバイトのメモリを搭載しているため，MEDLINEコレクションのような規模のデータに対しては，メモリサイズの影響はほとんどないと考えられる．
本実験で用いたMEDLINEには収録されているデータは1033件と比較的少ない．
このため，文書数を変化させたときの検索モデル構築時間の変化について比較を行った．
文書数を増加させるために，MEDLINEと同様なテストコレクションであるCISIを併せた2493記事，さらにCRANFIELDを併せた3893記事について，それぞれの検索モデル作成時間を測定した．
その結果，ランダム・プロジェクションとLSIのモデル作成時間は表[REF_model_time]のようになった．
これより，文書数が増加に対して球面[MATH]平均アルゴリズムの1回の反復による計算量が大きくなるのであるが，ランダム・プロジェクションが検索時間に関しても有効であることが分かる．
しかし，非常に大規模な文書数に対しては，より1回の反復による計算量が増加するため，反復計算を必要とせずに，球面[MATH]平均アルゴリズム並の概念ベクトルを得ることが課題となった．
ランダム・プロジェクションを用いた検索モデルに対して，モデルとしての有効性について評価をする．
この評価をするために，次元圧縮をしていない元のベクトル空間モデルと特異値分解を用いたLSIによる検索モデルについての検索実験も同時に行い，性能を比較した．
このとき，比較として用いたLSIは，次元数100として次元圧縮した検索モデルを用いている．
これらの検索モデルについて，同様に検索実験を行い，すべての検索質問の平均を求めた再現率・正解率曲線を図[REF_re_pre]に示す．
図[REF_re_pre]において，横軸は再現率を表し，縦軸は正解率を表す．
またグラフの`LSI100'は次元数100のLSI，`VSM'は次元圧縮なしのベクトル空間モデル，`RP500'，`RP700'，`RP900'はランダム・プロジェクションによるそれぞれに示された次元数に圧縮したモデルの実験結果である．
その結果，ベクトル空間モデルと比較して，ランダム・プロジェクションを用いた検索モデルは，大幅に性能が改善されていることが分かった．
また，次元数100のLSIと比較すると，ランダム・プロジェクションはLSIに比べ少し下がってはいるものの，ほぼ同じ程度に検索精度が改善されていることを示している．
このことから，ランダム・プロジェクションが検索モデルとして，LSIと同等の性能を持っていることが分かる．
[tb]
\ecaption{Recall-Precision curve for comparison between models}
ランダム・プロジェクションで次元圧縮に用いられる概念ベクトルが有効であるかを評価するために，他のベクトルを用いて次元圧縮が行われた場合との検索結果の比較を行った．
ベクトルには，乱数を用いて，全要素の平均が0，分散が1の正規分布[MATH]となるベクトルと，指定された数の文書ベクトルを任意に抽出して得られた部分集合からなるベクトルを，それぞれ次元圧縮に用いた．
この結果，再現率・正解率曲線は図[REF_concept]となった．
ここで，`Random'は正規分布となるベクトル，`Subset'は文書ベクトルの部分集合を表し，共にベクトルの次元数は500として，次元圧縮を行ったモデルの実験結果である．
また，サンプルに使った文書集合の偏りを考慮するため，グラフに示した実験でのベクトルの他にいくらかのサンプルを用意し，同様の実験を行い，平均的な検索精度を求めた．
その結果，正規分布による任意のベクトルにおける平均正解率の平均値は0.38，文書ベクトルの部分集合における平均値は0.47となった．
このグラフと平均値から，正規分布の性質を持つ任意のベクトルや文書ベクトルの部分集合を用いて次元圧縮を行った結果とそれぞれ比較すると，概念ベクトルを用いて次元圧縮を行った結果が，明らかに優れていることが分かる．
乱数により生成したベクトルを用いた場合，これらのベクトルの各要素には，索引の重要度や索引語間の関連性はほとんど存在しない．
このようなベクトルにより次元圧縮を行う場合，ベクトルの要素には文書の内容を表すような潜在的な意味がほとんど含まれていないために，検索性能が下がってしまったと考えられる．
文書ベクトルの部分集合を用いた場合は，次元圧縮後，ベクトル中のいくつかの要素が似通った意味を持っているために，検索性能が下がったと考えられる．
概念ベクトルは，内容の似通った文書がクラスタリングによりひとつにまとめられ，それらの重心を求めることで，文書の内容を端的に表すことができる．
また，クラスタリングを行うことで似通った内容を持つ概念ベクトルが少なくなるため，内容がほとんど変わらない概念ベクトルを重複して生成する可能性が少ない．
しかし，文書の部分集合では，内容の重複した文書が複数存在する可能性がある．
このため，次元圧縮後のベクトル空間モデルに意味の重なった要素が存在し，検索性能が下がってしまう可能性が大きくなってしまうと考えられる．
これらのことにより，情報検索に対してランダム・プロジェクションを用いて次元圧縮を行う場合，内容の近い文書や同義語などのような索引語の特徴を表した概念ベクトルを用いることにより，優れた検索性能が得られることが示された．
[tb]
\ecaption{Recall-Precision curve for comparison between vectors}
