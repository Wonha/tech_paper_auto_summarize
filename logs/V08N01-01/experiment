実験
本節では，ランダム・プロジェクションを用いた検索モデルを構築し，
その評価として，MEDLINEを用いた検索実験について述べる．

\subsection{データ}
実験で用いたデータは，情報検索システムの評価用テストコレクションである 
MEDLINEを利用した．
MEDLINEは医学・生物学分野における英文の文献情報データベースで，
検索の対象となる文書の件数は1033件で，約1Mbyteの容量を持つ
テキストデータである．
また，MEDLINEには30個の評価用検索要求文と各要求文に対する正解文書が
用意されている．

MEDLINEに含まれている1033件の文書全体から，
前処理として，``a''や``about''などの一般的な439個の英単語を
不要語リストに指定して，文書の内容と
関係のほとんどない単語は削除した．
この後，接辞処理を行い，残った英単語を語幹に変換する処理を行った．
この前処理の結果，文書全体に5526個あった単語から，
4329個の単語が索引語として抽出され，実験データとして用いた．

\subsection{検索実験方法}
実験では，MEDLINEから前処理により得られた索引語を要素とする文書ベクトルと
検索要求ベクトルを作成し，比較することで検索スコアを計算する．
文書ベクトルを作成するとき，ベクトルの要素には局所的，大域的な
索引語の分布を考慮するために，索引語の頻度に重み付けした数値が用いられる．
数多く提案されている重みづけ手法で，今回の実験では以下の式で定義された
対数エントロピー重み\cite{chisholm}を用いた．
$L_{ij}$ は $j$ 番目の文書に対する $i$ 番目の索引語への重み，
$G_i$ は文書全体に対する $i$ 番目の索引語への重みを表す．
\begin{equation}
L_{ij} = 
\left\{
\begin{array}{l}
1 + \log f_{ij} \ \ ( f_{ij} > 0 ) \\
0 \ \ \ \ \ \ \ \ \ \ \ \ \ ( f_{ij} = 0 )
\end{array}
\right.
\end{equation}
\begin{equation}
G_i = 1 + \sum_{j = 1}^{n} \frac{\frac{f_{ij}}{F_i} \log 
\frac{f_{ij}}{F_i}}{\log n}
\end{equation}
ここで，$n$ は全文書数，$f_{ij}$ は $j$ 番目の文書に出現する $i$ 番目の
索引語の頻度，$F_i$ は文書集合全体における $i$ 番目の索引語の頻度を表す．
これより，$j$ 番目の文書から得られる文書ベクトルの $i$ 番目の要素 $d_{ij}$ は，
\begin{equation}
d_{ij} = L_{ij} \times G_i
\end{equation}
となる．

得られた文書ベクトルから，球面 $k$ 平均アルゴリズムを用い，
これらの文書ベクトルより指定された数の概念ベクトルを作成する．
作成した概念ベクトルを結合した行列に対し，ランダム・プロジェクションを行い，
文書ベクトル，検索要求ベクトルの次元を削減する．
次元の削減されたベクトルを用いて，内積の計算を行い，
その値を各文書に対する検索スコアとする．
これらのスコアのうち，上位50文書を検索結果として出力する．

検索システムの評価には，一般的に用いられている正解率 (Precision) と
再現率 (Recall) を用いた\cite{lewis2}\cite{Witten}．
\begin{equation}
\mbox{Recall} = \frac{システムが出力した正解文書数}{全正解文書数}
\end{equation}
\begin{equation}
\mbox{Precision} = \frac{システムが出力した正解文書数}
{システムが出力した文書数}
\end{equation}
再現率と正解率は，それぞれ個別に用いて，システム評価を行うことができるが，
本実験では，一般にランクづけ検索システムの評価に用いられる
再現率・正解率曲線を用い，システムの評価を行った．
この曲線は，各質問に対しひとつの曲線が作成されるが，
本稿の検索システム評価には，全30個の質問に対する各再現率での平均を計算した
再現率・正解率曲線を用いた．

\vspace*{0.3cm}

実験結果および考察
\subsection{次元数による比較}
本実験では，ランダム・プロジェクションにより，
ベクトルの次元を100から900まで圧縮した検索モデルについて，
検索実験を行った．
その結果，各次元における平均正解率は表\ref{pre_sys}のようになった．
平均正解率は，ベクトルの次元が大きくなるにつれて増加し，
次元数300において，次元圧縮を行わないベクトル空間モデルよりも
良い結果となった．
また，次元数が400から500に変化させたときの平均正解率の増加が最も大きく，
それ以降は変化の割合が少なくなっている．
次元数を大きくすれば，検索に必要な計算量が増加する．
このことから，効果的な検索を行うためには，
全文書数の約半分に次元圧縮を行う必要があることが分かった．
\begin{table} \caption{各次元数における平均正解率} \ecaption{Average precision at each number of dimensions}
\label{pre_sys}
\renewcommand{\arraystretch}{}
\centering
\begin{tabular}{c|c|c} \hline \hline
次元数 & ランダム・プロジェクション & 平均正解率 \\ \hline
100 & あり & 0.3982 \\
200 & あり & 0.4711 \\
300 & あり & 0.5154 \\
400 & あり & 0.5231 \\
500 & あり & 0.5673 \\
600 & あり & 0.5748 \\
700 & あり & 0.5822 \\
800 & あり & 0.5979 \\
900 & あり & 0.6037 \\ \hline
1033 & なし & 0.4936 \\ \hline
\end{tabular}
\end{table}

\subsection{検索モデル作成時間}
検索モデルを作成する時間，および，一つの検索要求に対し，
検索を行うために必要な時間を測定した結果を述べる．
検索実験には，Ultra Sparc(330MHz) のマシンを使用し，
ベクトルの次元を500とした結果，表\ref{time}に示すように，
ランダム・プロジェクションを用いた場合，モデルを作成する時間は
約11分必要であった．
LSIの場合，SVDの計算についてはSVDPACKの中で最も高速なLanczos法を利用し，
同様にベクトルの次元を500とした結果，モデルを作成する時間は
約24分で必要であった．
この結果，ランダム・プロジェクションはLSIに比べ，
高速に検索モデルを構築することができた．

このモデル作成時間においては，メモリサイズの大きさによる，
SVDの計算時間に与える影響が考えられる．
スワップ領域を用いるほどの大規模なデータについては大きな影響を及ぼし，
モデル作成の時間を多く必要とするが，本実験において用いたマシンには
640Mバイトのメモリを搭載しているため，MEDLINEコレクションのような規模の
データに対しては，メモリサイズの影響はほとんどないと考えられる．

本実験で用いたMEDLINEには収録されているデータは1033件と比較的少ない．
このため，文書数を変化させたときの検索モデル構築時間の変化について
比較を行った．
文書数を増加させるために，MEDLINEと同様なテストコレクションである
CISIを併せた2493記事，さらにCRANFIELDを併せた3893記事について，
それぞれの検索モデル作成時間を測定した．
その結果，ランダム・プロジェクションとLSIのモデル作成時間は
表\ref{model_time}のようになった．
これより，文書数が増加に対して球面 $k$ 平均アルゴリズムの1回の反復による
計算量が大きくなるのであるが，ランダム・プロジェクションが検索時間に
関しても有効であることが分かる．
しかし，非常に大規模な文書数に対しては，より1回の反復による計算量が
増加するため，反復計算を必要とせずに，球面 $k$ 平均アルゴリズム並の
概念ベクトルを得ることが課題となった．
\begin{table} \caption{モデル作成時間とひとつの検索要求に対する検索時間} \ecaption{Processing time for making a retrieval model and retrieving one query}
\renewcommand{\arraystretch}{}
\label{time}
\centering
\begin{tabular}{c|c|c} \hline \hline
手法 & モデル作成時間 & 検索時間 \\ \hline
ランダム・プロジェクション & 約2分 & 4秒\\
LSI & 約24分 & 4秒\\ \hline
\end{tabular}
\end{table}
\begin{table} \caption{文書数の変化によるモデル作成時間} \ecaption{Processing time for making a retrieval model and retrieving one query}
\renewcommand{\arraystretch}{}
\label{model_time}
\centering
\begin{tabular}{l|c|c} \hline \hline
データ                 & ランダム・プロジェクション & LSI \\ \hline
MEDLINE                & 約2分                      & 約24分 \\
MEDLINE+CISI           & 約14分                     & 約26分 \\
MEDLINE+CISI+CRANFIELD & 約34分                     & 約43分 \\ \hline
\end{tabular}
\end{table}

\subsection{他の検索モデルとの比較}
ランダム・プロジェクションを用いた検索モデルに対して，
モデルとしての有効性について評価をする．
この評価をするために，次元圧縮をしていない元のベクトル空間モデルと
特異値分解を用いたLSIによる検索モデルについての検索実験も同時に行い，
性能を比較した．このとき，比較として用いたLSIは，
次元数100として次元圧縮した検索モデルを用いている．
これらの検索モデルについて，同様に検索実験を行い，
すべての検索質問の平均を求めた再現率・正解率曲線を図\ref{re_pre}に示す．
図\ref{re_pre}において，横軸は再現率を表し，縦軸は正解率を表す．
またグラフの`LSI100'は次元数100のLSI，`VSM'は次元圧縮なしのベクトル空間モデル，
`RP500'，`RP700'，`RP900'はランダム・プロジェクションによる
それぞれに示された次元数に圧縮したモデルの実験結果である．

その結果，ベクトル空間モデルと比較して，ランダム・プロジェクションを
用いた検索モデルは，大幅に性能が改善されていることが分かった．
また，次元数100のLSIと比較すると，ランダム・プロジェクションは
LSIに比べ少し下がってはいるものの，ほぼ同じ程度に検索精度が
改善されていることを示している．
このことから，ランダム・プロジェクションが検索モデルとして，
LSIと同等の性能を持っていることが分かる．
\begin{figure}[tb]
	\begin{center}
                 \atari(100,82)
		
	\end{center}
	\caption{モデルに対する再現率・正解率曲線}
	\ecaption{Recall-Precision curve for comparison between models}
	\label{re_pre}
\end{figure}

\subsection{概念ベクトルの有効性}
ランダム・プロジェクションで次元圧縮に用いられる
概念ベクトルが有効であるかを評価するために，
他のベクトルを用いて次元圧縮が行われた場合との検索結果の比較を行った．
ベクトルには，乱数を用いて，全要素の平均が0，分散が1の正規分布 $N(0, 1)$ 
となるベクトルと，指定された数の文書ベクトルを任意に
抽出して得られた部分集合からなるベクトルを，それぞれ次元圧縮に用いた．
この結果，再現率・正解率曲線は図\ref{concept}となった．
ここで，`Random'は正規分布となるベクトル，`Subset'は文書ベクトルの
部分集合を表し，共にベクトルの次元数は500として，次元圧縮を行ったモデルの
実験結果である．
また，サンプルに使った文書集合の偏りを考慮するため，
グラフに示した実験でのベクトルの他にいくらかのサンプルを用意し，
同様の実験を行い，平均的な検索精度を求めた．
その結果，正規分布による任意のベクトルにおける平均正解率の平均値は0.38，
文書ベクトルの部分集合における平均値は0.47となった．

このグラフと平均値から，正規分布の性質を持つ任意のベクトルや
文書ベクトルの部分集合を
用いて次元圧縮を行った結果とそれぞれ比較すると，概念ベクトルを用いて
次元圧縮を行った結果が，明らかに優れていることが分かる．
乱数により生成したベクトルを用いた場合，
これらのベクトルの各要素には，索引の重要度や索引語間の関連性は
ほとんど存在しない．
このようなベクトルにより次元圧縮を行う場合，ベクトルの要素には
文書の内容を表すような潜在的な意味がほとんど含まれていないために，
検索性能が下がってしまったと考えられる．

文書ベクトルの部分集合を用いた場合は，次元圧縮後，
ベクトル中のいくつかの要素が似通った意味を持っているために，
検索性能が下がったと考えられる．
概念ベクトルは，内容の似通った文書がクラスタリングによりひとつにまとめられ，
それらの重心を求めることで，文書の内容を端的に表すことができる．
また，クラスタリングを行うことで似通った内容を持つ概念ベクトルが
少なくなるため，内容がほとんど変わらない概念ベクトルを重複して生成する
可能性が少ない．
しかし，文書の部分集合では，内容の重複した文書が複数存在する可能性がある．
このため，次元圧縮後のベクトル空間モデルに意味の重なった要素が存在し，
検索性能が下がってしまう可能性が大きくなってしまうと考えられる．
これらのことにより，情報検索に対してランダム・プロジェクションを用いて
次元圧縮を行う場合，内容の近い文書や同義語などのような索引語の特徴を表した
概念ベクトルを用いることにより，優れた検索性能が得られることが示された．
\begin{figure}[tb]
	\begin{center}
                 \atari(90,75)
		
	\end{center}
	\caption{概念ベクトルに対する再現率・正解率曲線}
	\ecaption{Recall-Precision curve for comparison between vectors}
	\label{concept}
\end{figure}

