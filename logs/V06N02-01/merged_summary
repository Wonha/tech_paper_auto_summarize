前節にしたがって単語単位に分割されたテキストを学習データとしてN-gramモデルを学習するわけであるが，生起確率の計算上考慮すべきこととして数字，時刻などとくに各単語に確率上の差をつけるべき理由がないもの，および意味がまったく同じでありながら表記の異なる揺らぎが生じているものの取り扱いがある．
SCORE: 1.39406902172213, idx: 172

そこで新聞，電子会議室のそれぞれについてその種類，時期の違いを捨象するため，全学習データを文単位でシャッフルした上で８個に分割したサブセット(新聞: N-1,.
SCORE: 1.41492359244443, idx: 184

このように，本研究では比較的少量の人による分割データから揺らぎを含めた分割傾向を推定する手法について述べ，新聞およびパソコン通信の電子会議室を学習データとして，そのモデルからつくられた単語の集合と言語モデルについて考察した．
SCORE: 1.42349658468933, idx: 221

結果として，人が単語と意識する単位はその揺らぎを含めても発散することはなく，約44Kで94-98%程度のカバレージが得られること，形態素に比較して１文あたりの要素数が12-19%程度減少すること，電子会議室と新聞では，N-gramモデルからみた統計量に相当の差があり，予想されたように新聞単体では十分に対応できないものの，新聞をベースとして電子会議室のテキストを混合させたデータから作成した言語モデルは新聞のテストデータに対するパープレキシティを増大させることはほとんどなくその双方に対応可能であることがわかった．
SCORE: 1.5592995926623, idx: 222

