================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.22744] 本研究では音声認識への応用を目的として人が潜在意識的にもつ単語単位への分割モデルとその単位を用いた日本語の言語(N-gram)モデルについて考察した．
[i:2, score:0.22925] 本研究で用いた単語分割モデルは分割確率が2形態素の遷移で決定されるという仮定を置いたモデルで，人が単語境界と考える点で分割した比較的少量のテキストデータと形態素解析による分割結果とを照合することにより，パラメータの推定を行った．
[i:6, score:0.22780] このため，新聞・電子会議室の両データから作成した言語モデルはその双方のタスクに対応可能であった．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:12, score:0.21320] 従来日本語を対象とした自然言語処理では形態素単位に分割することが一般的であり，またその解析ツールが比較的よく整備されていたことからN-gramモデル作成においても「形態素」を単位として採用したものがほとんどである[CITE]．
[i:24, score:0.28595] そこで，われわれは，人が潜在意識としてもつ単語単位を形態素レベルのパラメータでモデル化するとともに，そのモデルに基づいて文を分割，N-gramモデルを作成する手法を提案し，認識率の観点からみて有効であることを示した[CITE]．
[i:26, score:0.25000] とくに新聞よりも「話し言葉」に近いと考えられるパソコン通信の電子会議室から収集した文章を対象に加え，新聞との違いについて実験結果を述べる．

================================================================
[section type  : proposed_method]
[section title : 単語単位への分割]
================================================================
[i:51, score:0.22286] は形態素単位への分割に対する記述例で，形態素の属性が動詞活用語尾[29]から接続助詞[69]「て」へ遷移したときに，その間で分割される確率を意味する．
[i:65, score:0.20441] つまりもっとも細かい分類における各パラメータについて，人が分割した結果と形態素解析の結果を照合してカウントし，その値をリーフから上位ノードに伝搬させた後，確率値に正規化すればよい．
[i:70, score:0.20188] 本手法によれば学習データ中に頻度が高いものについてはより細かい分類でモデル化され，頻度が下るにしたがって統計として信頼にたる単位まで縮退されたパラメータによる確率値が得られることになる．

================================================================
[section type  : proposed_method]
[section title : 形態素解析プログラムの変更]
================================================================
[i:71, score:0.00000] 
-----------------------------------------------------
  [subsection title : 現代語書き言葉以外の表現への文法の対応]
-----------------------------------------------------
  [i:lead, score:0.07155] 形態素解析システムは，一般に新聞記事に代表される現代語書き言葉を処理できるように開発されてきた．
.....
  [i:78, score:0.20112] 口語体によく現れる縮退形で，五段活用連用形に接続する「ちゃ」には，接続助詞「て」および係助詞「は」の連なり「ては」の縮退と（例:書いちゃいけない）と，接続助詞「て」および補助動詞「しまう」の語幹の連なり「てしま」の縮退（例:書いちゃう）とがある．
  [i:79, score:0.20202] 前者は直後で文節を切ることができる非活用語，後者はワア行五段活用をするので，ワア行五段活用語尾が接続し，かつ直後で文節末に遷移できる「ちゃ」という形態素の規則を作成すれば形態素解析処理を行うことができる[CITE]．
  [i:80, score:0.25631] しかし，品詞や活用形を単語分割モデルで利用すると，「ちゃ」に品詞として接続助詞を付与すれば「接続助詞にワア行五段活用語尾が接続する」という一般化が，また動詞を付与すれば「五段動詞語幹が文節末に遷移する」という一般化が行なわれかねない．
-----------------------------------------------------
  [subsection title : 複合名詞の分割]
-----------------------------------------------------
  [i:lead, score:0.16115] 形態素解析の辞書には，現在までの使用目的に応じて複合語が一語扱いで登録されていることが多いが，単語分割モデル構築のための形態素解析としては短単位に分割されていた方が都合がよい．
.....
  [i:89, score:0.16115] 形態素解析の辞書には，現在までの使用目的に応じて複合語が一語扱いで登録されていることが多いが，単語分割モデル構築のための形態素解析としては短単位に分割されていた方が都合がよい．
  [i:90, score:0.10052] そこで，複合語の中でも特に多い複合名詞を分割対象として，分割データベースとヒューリスティック規則により，形態素解析で複合名詞分割を行なうことにした．
  [i:91, score:0.18937] 複合名詞の分割データベースは，2カ月分の新聞記事（産経新聞）を形態素解析してその結果から一定以上の頻度で出現する3文字以上の名詞を抜き出した後，人手で，分割する位置の情報を付与することにより作成した．

================================================================
[section type  : proposed_method]
[section title : 分割モデルの作成と分割過程]
================================================================
[i:103, score:0.00000] 
-----------------------------------------------------
  [subsection title : 分割確率の推定]
-----------------------------------------------------
  [i:lead, score:0.42836] 分割ルールとその確率を推定するため，計17人の被験者により，新聞5カ月分（日経新聞3カ月および産経新聞2カ月），日本語用例集(合計約26,000文)，そしてパソコン通信「ピープル」の電子会議室（以下電子会議室）から採取した文章(約9,500文）を分割する作業を行った．
.....
  [i:104, score:0.42836] 分割ルールとその確率を推定するため，計17人の被験者により，新聞5カ月分（日経新聞3カ月および産経新聞2カ月），日本語用例集(合計約26,000文)，そしてパソコン通信「ピープル」の電子会議室（以下電子会議室）から採取した文章(約9,500文）を分割する作業を行った．
  [i:105, score:0.30213] 新聞や日本語用例集はいわゆる「書き言葉」のスタイルであるのに比較して電子会議室の文章はより口語体に近く，これらは分割モデルにも影響を与える可能性がある．
  [i:112, score:0.25959] たとえば電子会議室データから得られた確率木にのみ存在するノードの中で出現回数の多いものから上位3個をあげると以下のようになる．
-----------------------------------------------------
  [subsection title : 単語カバレージ]
-----------------------------------------------------
  [i:lead, score:0.18400] われわれの提案した単語単位に基づく語彙を作成するための予備実験として日経新聞3カ月分(合計446,079文)を用い，前節の手続きを適用して分割，連結を行う実験を行った．
.....
  [i:131, score:0.18400] われわれの提案した単語単位に基づく語彙を作成するための予備実験として日経新聞3カ月分(合計446,079文)を用い，前節の手続きを適用して分割，連結を行う実験を行った．
  [i:132, score:0.13734] 西村らの報告[CITE]によれば形態素を単位とした場合，約97%はおよそ3カ月分のテキストで収集できる（言い換えれば飽和する）ことがわかっている．
  [i:138, score:0.17796] これによれば単語単位を採用すると，形態素よりはより多くの種類が必要ではあるものの，決して発散するものではなく，たとえば上位約25,000個(種類)の単語で全トークンの約95%がカバーでき，取り扱いが可能な語彙数であることがわかる．

================================================================
[section type  : proposed_method]
[section title : 語彙とコーパス]
================================================================
[i:141, score:0.00000] 
-----------------------------------------------------
  [subsection title : コーパスの前処理]
-----------------------------------------------------
  [i:lead, score:0.31208] 用意したコーパスのソースは日経新聞（93年から96年），産経新聞（92年10月から97年），毎日新聞（91年と92年），EDRコーパス[CITE]，そしてパソコン通信「ピープル」に投稿された電子会議室の記事である．
.....
  [i:142, score:0.31208] 用意したコーパスのソースは日経新聞（93年から96年），産経新聞（92年10月から97年），毎日新聞（91年と92年），EDRコーパス[CITE]，そしてパソコン通信「ピープル」に投稿された電子会議室の記事である．
  [i:150, score:0.29078] そこでより口語体に近いデータとしてパソコン通信「ピープル」から約90の電子会議室に投稿されたテキストを用意した．
  [i:152, score:0.23929] 電子会議室の投稿文は文ばかりではなく，文字を利用した表，絵などが多数含まれている他，他人の記述を引用する場合が多く，これらを含めてしまったのでは学習用コーパスとして不適切であることは明らかである．
-----------------------------------------------------
  [subsection title : 語彙の作成]
-----------------------------------------------------
  [i:lead, score:0.33990] 以上の分割済みテキストの内，日経新聞，産経新聞，EDR，そして電子会議室について，95%以上のカバレージをもつ語彙を作成したところ，約44,000語の単語からなるセット(44K語彙)が得られた．
.....
  [i:159, score:0.33990] 以上の分割済みテキストの内，日経新聞，産経新聞，EDR，そして電子会議室について，95%以上のカバレージをもつ語彙を作成したところ，約44,000語の単語からなるセット(44K語彙)が得られた．
  [i:160, score:0.07409] このようにして得られた語彙は，人が日本語について単語単位だと感覚的に思うセットを示していると考えられる．
  [i:163, score:0.07294] また「たい」や「べき」といった単語も生成されており，分割に揺れがある部分では複数の分割に対応した単語が得られることがわかる．
-----------------------------------------------------
  [subsection title : 学習コーパス文の選択]
-----------------------------------------------------
  [i:lead, score:0.05657] 前節の結果得られた各文は局所的に見ると記号ばかりであったり，姓名の列挙部分であったりして学習コーパスには適さないものが含まれている．
.....
  [i:165, score:0.23168] また電子会議室のテキストはフィルターのルールでカバーしきれなかった部分で単語ではないトークンが無視できない程度に生じていた．
  [i:166, score:0.07349] このような文については人手で採用するかどうかを決める，あるいは当該部分を除くことが望ましいが，多量のコーパスについてそのような作業を行うのは不可能なため，ここでは以下の条件のいずれかに当てはまる文は採用しないことにした．
  [i:172, score:0.05855] 括弧による表現には確かに読み上げに適さないものも含まれているが，本研究では文章入力手段としての音声認識システムの構築を重視し，これらを削除しないことにした．

================================================================
[section type  : proposed_method]
[section title : 単語単位による言語モデル]
================================================================
[i:175, score:0.31616] 前節にしたがって単語単位に分割されたテキストを学習データとしてN-gramモデルを学習するわけであるが，生起確率の計算上考慮すべきこととして数字，時刻などとくに各単語に確率上の差をつけるべき理由がないもの，および意味がまったく同じでありながら表記の異なる揺らぎが生じているものの取り扱いがある．
[i:180, score:0.30732] 一方，テストデータとして新聞3種類，電子会議室のテキストを別に用意し，被験者(単語分割モデルの学習データを作成した被験者とは異なる）により分割を行なった．
[i:187, score:0.34483] そこで新聞，電子会議室のそれぞれについてその種類，時期の違いを捨象するため，全学習データを文単位でシャッフルした上で８個に分割したサブセット(新聞: N-1,.

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:224, score:0.35630] このように，本研究では比較的少量の人による分割データから揺らぎを含めた分割傾向を推定する手法について述べ，新聞およびパソコン通信の電子会議室を学習データとして，そのモデルからつくられた単語の集合と言語モデルについて考察した．
[i:225, score:0.52302] 結果として，人が単語と意識する単位はその揺らぎを含めても発散することはなく，約44Kで94-98%程度のカバレージが得られること，形態素に比較して１文あたりの要素数が12-19%程度減少すること，電子会議室と新聞では，N-gramモデルからみた統計量に相当の差があり，予想されたように新聞単体では十分に対応できないものの，新聞をベースとして電子会議室のテキストを混合させたデータから作成した言語モデルは新聞のテストデータに対するパープレキシティを増大させることはほとんどなくその双方に対応可能であることがわかった．
[i:226, score:0.20889] 分割モデル，N-gramモデルのいずれも，データの種類(新聞，パソコン通信）に依存している．

