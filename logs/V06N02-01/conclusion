このように，本研究では比較的少量の人による分割データから揺らぎを含めた分割傾向を推定する手法について述べ，新聞およびパソコン通信の電子会議室を学習データとして，そのモデルからつくられた単語の集合と言語モデルについて考察した．
結果として，人が単語と意識する単位はその揺らぎを含めても発散することはなく，約44Kで94-98%程度のカバレージが得られること，形態素に比較して１文あたりの要素数が12-19%程度減少すること，電子会議室と新聞では，N-gramモデルからみた統計量に相当の差があり，予想されたように新聞単体では十分に対応できないものの，新聞をベースとして電子会議室のテキストを混合させたデータから作成した言語モデルは新聞のテストデータに対するパープレキシティを増大させることはほとんどなくその双方に対応可能であることがわかった．
分割モデル，N-gramモデルのいずれも，データの種類(新聞，パソコン通信）に依存している．
これ自体は容易に予想できることであるが，その異なりが共通する事象の確率が異なるというよりも事象自体の異なりにより大きく現れていることは興味深い．
形態素との効率比較という意味では，同一学習データから作成した言語モデルを用いて単位長さ（たとえば文）あたりのパープレキシティを比較する必要がある．
これについて学習，テストデータ量は少ないものの，すでに報告を行っており，文あたりパープレキシティがほぼ等しく，したがって単位長が長い分，より有利な単位となっていることを確認している[CITE]．
コーパス量とパープレキシティの関係について，とくに日本語に関して報告された例はほとんどないため，他の研究と比較して議論することが難しい．
本研究の実験からは400万文強のデータではまだパープレキシティが減少するが，その改善率は低く数倍以上のデータがないと意味のある改善が難しいことを示唆している．
人が感覚的にある単位だと判断する日本語トークンについて考察した他の研究との関連についても述べておきたい．
原田[CITE]は人のもつ文節単位の概念に関する調査結果から，「文字列またはモーラ長が一定以上になると分割しようとする動機がたかまる」という仮説を提起している．
われわれの分割モデルでは分割が2形態素の遷移情報のみで独立に起こることを仮定しているが，この独立性については検討が必要であろう．
横田，藤崎[CITE]が短時間に認識できる文字数とその時間との関係から求めた認知単位は，とくに平均長は述べられていないものの，例をみる限りわれわれの単位より明らかに長い．
同論文では「人は文を文字単位で処理しているのではない」と結論しているが，加えて，分割できる最小単位の列として知覚されているのでもないということになる．
今後は，コーパスサイズをより大きくするとともに句読点を削除した場合との比較・考察や，単語分割モデルの分割確率とポーズ位置との関係[CITE]，さらに上記で述べた分割の独立性について検討したいと考える．
本研究にテキストデータ使用を許諾していただいた，産経新聞社，日本経済新聞社，毎日新聞社（CD-毎日新聞91-95），そして(株)ピープルワールドカンパニーに感謝いたします．
