
固有表現はIREX-NEの定義にしたがい，表[REF_table:tag]の8種類とする．
この節ではこの表にあげたSGMLタグを付与する方法について述べる．
{
}本手法では以下の手順で固有表現を抽出する．
テキストを形態素解析する．
実験では形態素解析にJUMAN[CITE]を用いた．
例えば，``在米女性を中心に「人権を考える会」ができ，…''という部分は表[REF_table:ex]の第1行のように形態素ごとに区切られ，それぞれの形態素ごとに第2行，第3行のような品詞の情報が得られる．
{
}
各形態素にラベルを付与する．
ラベルとしては，以下の合計40個を用意した．
IREX-NEで定義されている固有表現のタグに「OPTIONAL」を加えた9種類を，固有表現の始まり，中間，終り，単独に分けた9[MATH]4=36個．
例えば人名のタグの場合，それぞれ「PERSON:BEGIN」「PERSON:MIDDLE」「PERSON:END」「PERSON:SINGLE」を用いる．
このように分けたのは，複数の形態素が一つの固有表現を構成することがあることを考慮するためである．
「OPTIONAL」のタグはタグ付けが判定者にも困難な場合のために設けたものである．
これもIREX-NEにおける定義にしたがっている．
固有表現の判定は人間にも難しいことが多い．
例えば，「東京高裁」はLOCATIONかORGANIZATIONか，「日経平均株価」と言ったときの「日経」はORGANIZATIONとするべきかなどがそうである．
このような場合，それぞれ「東京高裁」，「日経」にこのタグを付与し，固有表現としては抽出しない．
この「OPTIONAL」をラベルとして考慮したのはその性質を学習することによって，例えばLOCATIONかORGANIZATIONの判定が困難なものをいずれかのタグに分類してしまうのを避けることができると考えたためである．
固有表現の前後の1形態素および固有表現に挟まれた1形態素を他の形態素と区別するための3個(「PRE」「POST」「MID」)．
例えば，``昨日大阪と神戸で…''という部分では「大阪」と「神戸」がそれぞれ地名を表す固有表現であり，その前後の形態素は次のようにラベル付けされる．
``昨日(PRE)／大阪(LOCATION:SINGLE)／と(MID)／神戸(LOCATION:SINGLE)／で(POST)…''
(括弧内はそれぞれ前の形態素に付与されたラベルの候補)
この三つのラベル「PRE」「POST」「MID」を用いたのは，固有表現の前後の形態素(接辞など)は固有表現を抽出する際に手がかりとなることが多いため，次にあげる「OTHER」と区別する方が良いと考えたからである．
以上のどのラベルもつかない「OTHER」．
今，一文が[MATH]個の形態素からなるとする．
手順(1)で得られた形態素解析結果を用いて，個々の形態素[MATH]にそれぞれ上記のラベルのいずれかを付与する．
形態素[MATH]に付与するラベルはコーパスから学習したMEモデルから各ラベルを付与したときの尤もらしさを確率として計算しそれを基に決める．
詳しくは，モデルについては[REF_sec:model]節で，最適解の探索アルゴリズムについては[REF_sec:viterbi]節で述べる．
書き換え規則による後処理JUMANの解析結果における形態素の境界とIREXで定義されている固有表現の境界は必ずしも一致しない．
このような一致しない場合に対応するために書き換え規則を自動獲得し，獲得した規則を用いて後処理を行う．
例えば，表[REF_table:ex]の「在米」に対しては以下のような書き換え規則が適用される．
[MATH]
書き換え規則の自動獲得手法については[REF_sec:post_processing]節で述べる．
ラベルを固有表現のタグに変換すべてのラベルが決まったら，それぞれのラベルに対し手順(2)で定義したラベルの定義にしたがって，ラベルからIREX-NEで定義されたタグへと変換する．
抽出したい固有表現は表[REF_table:tag]の8種類なので，最後に解析結果から「OPTIONAL」のタグを取り除く．
例えば，表[REF_table:ex]でスコアが最大であるラベル候補1の場合，手順(3)の操作によって``在米(OTHER)''の部分が``在(PRE)米(LOCATION:SINGLE)'' (括弧内はそれぞれ前の形態素に付与されたラベルの候補)に書き換えられる．
そして，ラベルをタグに変換することによって次のような出力を得る．
この節では形態素に付与するラベルの尤もらしさを確率として計算するためのモデルについて述べる．
モデルとしては，ME(最大エントロピー法)に基づく確率モデルを採用する．
まず，MEの基本について説明し，その後，MEに基づく固有表現ラベル付与確率モデルおよびそのモデルをコーパスから統計的に学習する方法について述べる．
一般に確率モデルでは，文脈(観測される情報のこと)とそのときに得られる出力値との関係は既知のデータから推定される確率分布によって表される．
いろいろな状況に対してできるだけ正確に出力値を予測するためには文脈を細かく定義する必要があるが，細かくしすぎると既知のデータにおいてそれぞれの文脈に対応する事例の数が少なくなりデータスパースネスの問題が生じる．
MEモデルでは，文脈は素性と呼ばれる個々の要素によって表され，確率分布は素性を引数とした関数として表される．
そして，各々の素性はトレーニングデータにおける確率分布のエントロピーが最大になるように重み付けされる．
このエントロピーを最大にするという操作によって，既知データに観測されなかったような素性あるいはまれにしか観測されなかった素性については，それぞれの出力値に対して確率値が等確率になるようにあるいは近付くように重み付けされる．
このように未知のデータに対して考慮した重み付けがなされるため，MEモデルは比較的データスパースネスに強いとされている．
このモデルは例えば言語現象などのように既知データにすべての現象が現れ得ないような現象を扱うのに適したモデルであると言える．
以上のような性質を持つMEモデルでは，確率分布の式は以下のように求められる．
文脈の集合を[MATH]，出力値の集合を[MATH]とするとき，文脈[MATH]で出力値[MATH]となる事象[MATH]の確率分布[MATH]をMEにより推定することを考える．
文脈[MATH]は[MATH]個の素性[MATH]の集合で表す．
そして，文脈[MATH]において，素性[MATH]が観測されかつ出力値が[MATH]となるときに1を返す以下のような関数を定義する．
これを素性関数と呼ぶ．
ここで，[MATH]は，文脈[MATH]において素性[MATH]が観測されるか否かによって1あるいは0の値を返す関数とする．
次に，それぞれの素性が既知のデータ中に現れた割合は未知のデータも含む全データ中においても変わらないとする制約を加える．
つまり，推定するべき確率分布[MATH]による素性[MATH]の期待値と，既知データにおける経験確率分布[MATH]による素性[MATH]の期待値が等しいと仮定する．
これは以下の制約式で表せる．
この式で，[MATH]という近似を行ない以下の式を得る．
ここで，[MATH]，[MATH]は，[MATH]，[MATH]をそれぞれ既知データにおける事象[MATH]の出現頻度，出力値[MATH]と事象[MATH]の共起頻度として以下のように推定する．
次に，式([REF_eq:constraint])の制約を満たす確率分布[MATH]のうち，エントロピー
を最大にする確率分布を推定するべき確率分布とする．
これは，式([REF_eq:constraint])の制約を満たす確率分布のうちで最も一様な分布となる．
このような確率分布は唯一存在し，以下の確率分布[MATH]として記述される．
ただし，
であり，[MATH]は素性関数[MATH]の重みである．
この重みは文脈[MATH]のもとで出力値[MATH]となることを予測するのに素性[MATH]がどれだけ重要な役割を果たすかを表している．
訓練集合が与えられたとき，[MATH]の推定にはImproved Iterative Scaling(IIS)アルゴリズム[CITE]などが用いられる．
式([REF_eq:p])の導出については文献[CITE]を参照されたい．
[REF_sec:overview]節に，個々の形態素に付与すべき固有表現のラベルを定義した．
以降では，形態素にそれぞれのラベルを付与したときの尤もらしさを表す確率をラベルの付与確率と呼ぶ．
一文が[MATH]個の形態素からなるとき，形態素[MATH]にラベル[MATH]を付与するときの付与確率は，前節で述べたMEモデルの式（[REF_eq:p]）を用いて[MATH]で求められる．
ここで[MATH]は「見出し語：人権,品詞(大分類)：名詞,品詞(細分類)：普通名詞」などの素性の集合であり，個々の[MATH]ごとに異なるため[MATH]と表した．
一文全体の付与確率は個々の確率の積で表す．
基本的に学習コーパスから得られる形態素情報を素性として用いる．
実験では，着目している形態素を含む前後2形態素ずつ合計5形態素に関する見出し語，品詞(大分類，細分類)とした．
品詞分類はそれぞれ大分類15個，細分類48個である．
これはJUMANのものにしたがった．
学習コーパスに1，2回しか現れないような素性はノイズとなる可能性があるのでそれを避けるために頻度による素性選択を行なう．
見出し語としては学習コーパス中に5回以上現れたものを用い，さらに式([REF_eq:f])の素性関数としては学習コーパスに3回以上観測されたものを用いる．
見出し語を5回以上現れたものとしたのはこれ以上少なくすると素性の数が増え現在のマシンパワーでは学習できなかったためである．
素性としては他にもいろいろ考えられるが，今回の実験では学習コーパスから得られる情報でかつ着目している形態素の周辺の情報のみを用いた場合にどの程度の精度が得られるかを調べることに重きを置いた．
さらに学習コーパス以外から得られる情報の有効性も調べるために追加実験として，固有名詞に関する辞書情報を利用しその辞書に登録されているかどうかを素性として利用した場合の実験も行なった．
これについては[REF_sec:exp]節で実験結果をあげて考察する．
本節ではラベル付与に用いるビタビアルゴリズムについて説明する．
このアルゴリズムは，スコアが一文全体で最適値となるようにラベルを付与するものである．
形態素[MATH]に対し，[REF_sec:named_entity_extraction_model]節で述べたラベル[MATH]の付与確率[MATH]の一文全体における掛け算[MATH]が最大になるように各ラベルを決める．
ただし，表[REF_table:conjunction_rule]の連接規則を満たすようにする．
この表で，＄(文末)，＃(文頭)は便宜上設けたもので実際に付与するラベルとは異なる．
表[REF_table:conjunction_rule]の連接規則は人手で作成した．
手順は以下の通りである．
文頭の形態素[MATH]に対し各ラベル[MATH]の付与確率[MATH] [MATH]を計算し，それぞれ各ラベルごとのスコア[MATH]とする．
つまり，[MATH], [MATH], [MATH], [MATH]とする．
次の形態素[MATH]に対し各ラベルの付与確率[MATH] [MATH]を計算し，それぞれ各ラベルごとのスコアを
とする．
ただし，[MATH]と[MATH]が連接規則を満たすものに限る．
さらに次の形態素[MATH]に対しても同様に各ラベルの付与確率[MATH] [MATH]を計算し，それぞれ各ラベルごとのスコアを
とする．
ただし，[MATH]と[MATH]が連接規則を満たすものに限る．
同様のことを文末まで繰り返し，
のうち最大のものを選ぶと，最適解であるラベルの並び[MATH], [MATH], [MATH], [MATH]が得られる．
MEモデルを用いたラベル付けの処理が終った後で，形態素解析により得られる形態素が固有表現より長い場合に対処するため，予め用意しておいた書き換え規則を適用する．
書き換え規則はBrillが品詞タグ付けに用いた[CITE]のと同様の手法である誤り駆動で獲得する．
Brillの規則獲得方法との違いはBrillがテンプレートを用いているのに対して我々は用いていない点である．
我々の場合，書き換え規則は学習コーパスに対するシステムの解析結果とコーパスの正解データとの差異を調べることによって自動獲得することができる．
差異の中から，コーパスでは同じ文字列に対応しているにもかかわらず形態素の数が異なる部分をすべて抽出し書き換え規則として利用する．
ただし，前件部は同じであるが後件部が異なるような規則が複数獲得された場合は，最も頻度の高い規則のみを用いる．
最も頻度の高い規則が複数種類ある場合，それらの規則はすべて捨てる．
さらに，ここで獲得した規則を学習コーパスに対するシステムの解析結果に適用し，誤りとなる数が正解となる数以上であるものはすべて捨てる．
例えば，以下のようなものが書き換え規則として獲得される．
[MATH]
