モデルの学習に用いたデータは，CRL(郵政省通信総合研究所)固有表現データ，IREX-NE予備試験トレーニングデータ，IREX-NE予備試験データ，IREX-NE本試験逮捕トレーニングデータの合計約12,000文である．
試験に用いたデータはIREX-NE本試験データである．
これらはすべて毎日新聞のデータに対して固有表現のタグが付与されたものである．
以下で簡単にデータの説明をする．
学習コーパスの書式はSGML形式で，各固有表現には表[REF_table:tag]のタグが付与されている．
これらのタグ付コーパスからテキスト部分を取り出して形態素解析し，表[REF_table:trans_rule2]にあげる変換規則を用いて各形態素にラベルが付与されたものに変換した後，学習に用いた．
毎日新聞1995年1月1日から10日までの全記事，約1万文に対して，固有表現をタグ付けしたデータである．
固有表現はIREX-NEの1999年2月14日に更新された定義に基づいている．
毎日新聞1994年4月13日の46記事，約500文に対して固有表現をタグ付けしたデータである．
固有表現はIREX-NEの1998年10月27日に更新された定義に基づいている．
毎日新聞1994年9月11日の36記事，約500文に対して固有表現をタグ付けしたデータである．
固有表現はIREX-NEの1998年10月27日に更新された定義に基づいている．
IREX-NEの定義は少しずつ更新されている．
しかし，それらの定義の違いによるノイズの数は人間が学習データを作成するときに生じるノイズの数とさほど違いはないと考え，すべて学習に用いた．
1999年4月14日から5月13日の毎日新聞のデータから選ばれた91記事で，ドメインを限らないもの71記事，約400文(以下，「一般ドメイン」と呼ぶ)と「逮捕」にドメインを限ったもの20記事，約100文(以下，「限定ドメイン」と呼ぶ)の2種類のデータからなる．
それぞれのドメインのデータにおける固有表現の数は表[REF_Answer]の通りである．
実験に用いた素性は形態素解析結果から得られる情報であり，着目している形態素を含む前後2形態素ずつ合計5形態素に関する見出し語，品詞(大分類，細分類)である．
見出し語としては学習コーパス中に5回以上現れた12,368個を用いた．
品詞分類はJUMANのものにしたがった．
それぞれ大分類15個，細分類48個である．
このうち，式([REF_eq:f])の素性関数としては学習コーパスに3回以上観測されたもの27,370個を用いた．
モデルの重み(式([REF_eq:alpha])の[MATH])の学習にはRistadのツール[CITE]を利用した．
次に我々の解析結果を表[REF_Result]に示す．
この表で第1列と第2列は書き換え規則を利用したときの限定ドメインの試験(ARREST)に対する結果とドメインを限定しない試験(GENERAL)に対する結果である．
第3列と第4列は書き換え規則を利用しなかったときのそれぞれのドメインに対する結果である．
どちらのドメインに対しても特別なチューニングはしなかった．
精度はどちらのドメインに対しても書き換え規則を用いたときの方が良く，F-measureは限定ドメインに対して83.91，一般ドメインに対して79.42であった．
IREX-NEの試験では「OPTIONAL」のタグが振られたものについては，その範囲内にシステムがどのような結果を出そうとも，評価には反映されない．
ただし，範囲外にずれて重なっている場合には不正解とされる．
本論文においてもこの評価方法にしたがった．
{
}
書き換え規則の適用対象となる固有表現は形態素単位より短い部分文字列を含むもので，本試験データでは限定ドメインに18個，一般ドメインに79個あった．
いずれも本試験データ全体の約5%に相当する．
学習コーパスから得られた書き換え規則の数は362個であり，そのうち限定ドメインの試験には9個の規則が延べ11回適用され誤りが1個(再現率[MATH]，適合率[MATH])，一般ドメインの試験には12個の規則が延べ42回適用され誤りが10個(再現率[MATH]，適合率[MATH])であった．
誤りは以下のようなものであった．
本来抽出するべき固有表現の部分文字列を誤って抽出してしまう場合(1個)．
「在日米軍横田基地」から「日」だけがLOCATIONとして抽出されていた．
これは，IREX-NEの定義によると「在日米軍横田基地」がLOCATIONとして抽出されるべきであるが，MEモデルを用いたラベル付けによってうまく抽出できなかった結果，書き換え規則が適用され誤って抽出されてしまった例である．
このような誤りをなくすためには，MEモデルを用いたラベル付けの精度を向上する必要がある．
学習コーパスでは固有表現となっていたが，正解データでは固有表現となっていない場合(10個)．
学習コーパスでは「邦人」の「邦」がLOCATION，「外相会談」の「外」がORGANIZATIONとなっていたが，本試験の正解データでは固有表現とみなされていなかった．
このような誤りをなくすためには学習コーパスの整備が必要である．
書き換え規則を用いることにより，F-measureで2ポイント(限定ドメイン)および1.5ポイント(一般ドメイン)程度の精度向上がみられた．
ここで用いた書き換え規則は形態素の境界とIREXで定義されている固有表現の境界が一致しない場合にのみ対応するために獲得したものである．
一致する場合についても同様の書き換え規則を適用することは可能であるが，そうした場合の追加実験ではF-measureで72.23(限定ドメイン)および73.12(一般ドメイン)と書き換え規則を用いない場合に比べてそれぞれ10ポイントおよび5ポイント程度精度が悪くなった．
これは我々の用いた簡便な獲得手法では，MEモデルにより付与したラベルを精度良く書き換えられるほどの規則を獲得できないことを示している．
しかし，得られた精度向上および規則獲得の簡便さを考慮すると，MEモデルで抽出できない部分を補う方法としては有効な方法であると言える．
本手法では形態素解析が終った後に固有表現のラベルを推定するが，形態素解析の段階で形態素の文法的属性(品詞など)と固有表現のラベルを同時に推定するような方法をとることも考えられる．
この場合でも書き換え規則は形態素解析の後処理として利用されている久光らの研究[CITE]と同様にして使えると考えられる．
実験に用いた素性の有効性を調べるために，それぞれの素性を削除したときの比較実験を行なった．
比較実験ではすべて書き換え規則を用いた．
結果を表[REF_Result3]にあげる．
{
}表中のFというのはF-measureのことで，精度の差というのは，着目している形態素とその前後2形態素ずつについて，見出し語，品詞大分類，品詞細分類のすべての情報を素性として用いたときの精度と比べたときの差を意味する．
どの素性を削除した場合にも精度が悪くなっており，どの素性も精度の向上に貢献していることが分かる．
特に見出し語は精度向上に著しく貢献している．
表[REF_Result3]の下から三行は，前後の形態素情報の利用範囲を変更したときの結果であり，着目している形態素の情報のみ(表では「(0)のみ」と示す．
)，着目している形態素とその前後の形態素の情報のみ(表では「(-1)(0)(1)」と示す．
)，着目している形態素とその前後2形態素の情報(表では「(-2)から(2)」と示す．
表[REF_Result]に示した結果と同じ．
)，着目している形態素とその前後3形態素の情報(表では「(-3)から(3)」と示す．
)をそれぞれ素性として用いたときの精度を表す．
用いる情報が前後2形態素ずつより多くても少なくても精度が悪くなった．
用いる情報を多くしたにもかかわらず精度が悪くなるのは，データスパースネスの問題が深刻になってくるためであると考えられる．
この節では，学習コーパスと解析精度の関係について考察する．
まず，図[REF_fig:learning_curve:training]，図[REF_fig:learning_curve:test]に学習コーパスとテストコーパスのそれぞれを解析した場合の学習コーパスの量と解析精度の関係をあげる．
図の横軸は学習コーパスの文数，縦軸はF-measureを表す．
学習コーパスの解析には限定ドメインとしてIREX-NE本試験逮捕トレーニングデータ，一般ドメインとしてIREX-NE予備試験データを用いた．
図では限定ドメイン，一般ドメインに対するグラフにはそれぞれ「arrest」，「general」，書き換え規則を用いた場合と用いなかった場合にはそれぞれ「with_rules」，「without_rules」という表記を用いている．
テストコーパスに対する学習曲線(図[REF_fig:learning_curve:test])を見ると，特に一般ドメインに対してはまだ精度は飽和していないようである．
学習コーパスに対する学習曲線(図[REF_fig:learning_curve:training])もわずかではあるが増加する傾向にある．
したがって，少なくとも一般ドメインに対しては学習コーパスの量が増えればもう少し精度の向上が期待できそうである．
[htbp]
\leavevmode
\leavevmode
1999年5月13日から17日にかけて，IREX-NEの本試験が行なわれた．
試験は13日に実行委員長より問題が配布され，17日までに各々のシステムのタグ付け結果を電子メイルで送り返すという形式で行なわれた．
IREX-NE本試験に参加したシステムは15システムであった．
それらをパターン駆動型，学習型，それらの組み合わせの3種類に分類すると，我々のシステムは学習型に分類される．
本節では主に他の学習型システムとの違いを説明し，そのうち重要であると思われる部分については追加実験を行なうことによりその違いがどの程度精度に影響を与えるかを調べる．
学習型のシステムのアプローチは我々のものも含めて四つあり，どれも基本的に関根らのとったアプローチ[CITE]に類似している．
関根らのシステム[CITE]を改良したものにはBorthwickのシステム[CITE]，野畑のシステム[CITE]，新納[CITE]のシステムがあり，それらと我々のシステムの違いを表にすると表[REF_Comparison]のようになる．
違いは主に学習モデル，形態素に付与するラベル(NEラベル)の定義，素性，後処理にある．
{
}
以下では主に表[REF_Comparison]の違いに着目して考察する．
我々の定義したNEラベルは関根らのシステムに比べると7種類多い．
これは，関根らのシステムよりさらにOPTIONAL(始まり，中間，終り，単独の4種類)およびPRE，POST，MIDのラベルを考慮したためである．
OPTIONALはタグ付けが判定者にも困難な場合のために設けられたものであり，その性質を学習することによって，例えばLOCATIONかORGANIZATIONの判定が困難なものをいずれかのタグに分類してしまうのを避けることができると考えられる．
PRE, POST, MIDのラベルは固有表現の前後および固有表現の間の形態素に付与するように設けたものである．
これは見方を変えると関根らがOTHER(あるいはNONE)としていたラベルを固有表現以外の部分の始まり(POSTに対応)，中間(OTHERに対応)，終り(PREに対応)，単独(MIDに対応)に細分類したものであるとも言える．
OPTIONALに関する4種類およびPRE，POST，MIDのラベルがどの程度精度に影響しているかを調べるために，それぞれのラベルをOTHERにマージして追加実験を行なった．
その結果を表[REF_Comparison2]〜表[REF_Comparison3]にあげる．
表の括弧内の数値は表[REF_Result]にあげた精度からの増減を表す．
これらの実験ではMEモデルによるラベル付けの精度の違いを調べることを目的としているためいずれも書き換え規則は用いていない．
{
[htbp]
}
表から分かるようにOPTIONALに関するラベルは期待していたほど精度に影響を与えていなかった．
PRE，POST，MIDのラベルは一般ドメイン(GENERAL)に対しては精度の向上に貢献しているのに対し，限定ドメイン(ARREST)に対してはその利用がかえって精度を低下させることになっている．
固有表現ごとに精度の増減を調べてみると，PRE，POST，MIDのラベルをOTHERにマージすることによって限定ドメインに対してはPERSONとLOCATIONの精度が良くなっており，他の固有表現に対しては悪くなっていることが分かる．
限定ドメインの内訳(表[REF_Answer])を見るとPERSONとLOCATIONの個数が多く，これらの固有表現に対する抽出精度が良くなったため全体の精度も良くなったと考えられる．
PERSONとLOCATIONに対する精度が良くなったのはPREやPOSTなどが数の多いPERSONやLOCATIONの性質に引っ張られてPERSONやLOCATIONの前後に位置しやすいラベルとして学習されたためである可能性が高い．
PERSONやLOCATIONについてはPREやPOSTなどをさらに細分類してPERSON:PREやPERSON:POSTのようなラベルを考えると良いかも知れない．
このような細分類は，PERSONやLOCATION，特にPERSONは固有表現直後の形態素が「さん」や「氏」など特別な語であることが多く，他の固有表現についてそのような傾向は見られない[CITE]ことからも妥当な方法であると考えられる．
しかし，抽出精度をもとに細分類を続けると本試験のデータに対しては精度が良くなるかもしれないが，他のデータに対しても良くなるとは言えなくなる．
したがって，これ以上細分類して本試験のデータに対する精度を調べることはあまり意味がないと思われる．
Borthwickのシステムとの精度の差(表[REF_Comparison])は主にこのラベルの定義の違いと素性の違いから生じていると考えられる．
素性の違いについては後で述べる．
一方，野畑はARTIFACT，LOCATION，ORGANIZATIONを細分類してF-measureで2ポイント程度精度が向上したと報告している．
我々のシステムにおいてもどの程度精度に影響するかを調べたいところであるが，学習コーパスに付与されたラベルを人手で細分類する必要があるため同じ学習コーパスを作成するのは困難であると判断し，野畑の細分類に基づいて追加実験をするのは見合わせた．
新納は形態素ごとではなく文字ごとにNEラベルを付与する方法を提案した．
この方法は形態素の区切りと固有表現の区切りが一致しない場合でも一つのモデルで固有表現を抽出できるという点で優れているが，精度は我々に比べてF-measureで20ポイント以上低い．
この理由は，後に述べる素性に関連することであるが，新納の方法が文字3-gramという少ない情報のみを用いてNEラベルを推定しているためであると考えられる．
3文字ということは多くても3形態素の情報しか用いていないということである．
我々の実験では，[REF_sec:features_and_accuracy]節でも述べたように着目する形態素およびその前後2形態素ずつの情報を用いた場合が最も精度が良いことから，新納の方法で我々のシステムと同程度の精度を得るためには少なくとも文字5-gram以上の情報を用いる必要があるだろう．
しかし，文字5-gramを得るには膨大な学習コーパスが必要であり，我々が実験に用いた学習コーパスだけでは我々のシステムと同程度の精度は得られないと予想される．
Borthwickや野畑は我々が用いた素性に加えて字種情報，統語的情報や辞書情報などを用いて精度を向上させている．
このうち字種情報については我々の素性においても形態素の品詞情報としてある程度考慮されている．
統語的情報については野畑のシステムで用いられている方法では人手の介入が必要であり，同じ条件での実験は困難である．
辞書情報については我々の素性に加えて追加実験を行ない，精度に与える影響を調べた．
辞書情報としてはBorthwickや野畑と同様に文献[CITE]で公開されているものを用いた．
これは組織名，地名に関する辞書で登録数は約1,000である．
それに加えて，学習コーパスに3回以上出現した固有表現約1,400個(ORGANIZATION: 272個, PERSON: 336個, LOCATION: 339個, ARTIFACT: 45個, DATE: 233個, TIME: 31個, MONEY: 21個, PERCENT: 45個, OPTIONAL: 56個)を取り出しそれぞれの固有表現ごとに9種類の辞書を作成した．
予めこれらの辞書に登録されている固有表現をJUMANを用いて形態素解析し，各形態素に我々の定義したNEラベルを付与しておく．
素性としては，形態素の見出し語がこれらの辞書中でどのようなNEラベルが付与されているかという情報を用いた．
つまり，我々が定義した40個のラベルの各々について付与されているかいないかのそれぞれを素性として用いる．
辞書中の形態素の見出し語の異なり数は合計約10,000個である．
この素性を，着目している形態素のみについて利用した場合，着目している形態素を含む前後1形態素ずつ合計3形態素について利用した場合，着目している形態素を含む前後2形態素ずつ合計5形態素について利用した場合それぞれについて追加実験を行なった．
それぞれの実験結果を表[REF_Comparison5]〜表[REF_Comparison7]にあげる．
結果は着目している形態素のみについて利用した場合が最も精度が良く，考慮する前後の形態素の数が増えるにつれて精度は悪くなった．
これは辞書の登録数が問題になっている可能性が高い．
辞書に登録されている固有名詞は高々2,400個程度であり，そのうち1形態素，2形態素，3形態素，4形態素以上からなるものはそれぞれ745個，448個，125個，60個である．
例えば二つ前の形態素の見出し語が辞書にあるかないかという情報(我々が辞書情報の素性として利用したもの)が有効なのは辞書に登録されている固有名詞の約8%，185(=125+60)個についてのみであるということになる．
今回，学習コーパス以外から得た辞書情報としては一般に公開されている1,000語程度の辞書を用いたが，一般に利用可能な大規模な固有名詞辞書があれば，辞書の登録数と精度の関係も調べてみたい．
{
[htbp]
}
次に，素性として一つ前の形態素に付与したラベルの情報を考慮したときの精度を調べた．
一般に学習による形態素解析では一つあるいは二つ前の形態素に付与したラベルの情報を用いて次のラベルを決定することが多い．
我々の手法においてこれと同様の情報がどの程度精度に影響を与えるかを調べることが目的である．
実験結果を表[REF_Comparison4]にあげる．
表から分かるようにどちらのドメインについても精度を下げる結果となった．
特に再現率の低下が著しい．
これは学習コーパスではOTHERの隣はOTHERであることが多く，この連接関係が他のラベルとの連接に比べて学習されやすいためOTHERが連続する場合が最適解となることが多くなるためであると考えられる．
{
}
Borthwickは我々と同様に形態素解析により得られる形態素が固有表現より長い場合に対処するために書き換え規則を用いて後処理をしている．
この後処理により，どちらのシステムもF-measureで2ポイント程度精度が向上している．
違いはBorthwickが日本語を母語とする人が人手で作成した規則を用いているのに対し，我々は学習コーパスから誤り駆動で自動獲得した規則を用いている点にある．
異なるドメインのテキストが与えられたとき，できるだけコストを少なく学習し直すためには規則を自動獲得できる方が望ましい．
誤り駆動型学習を用いて固有表現を抽出するシステムには颯々野らのシステム[CITE]がある．
このシステムは後処理として書き換え規則を適用することにより，形態素単位より短い文字列を含む固有表現だけでなく一つあるいは複数の形態素からなる固有表現も同様の手法を用いて抽出できる．
彼らがベースラインとして用いているシステムの精度がF-measureで40程度であるため，我々のシステムをベースラインとして用いることによってより良い精度が得られる可能性が高いと考えられる．
IREX-NE本試験での結果を表[REF_table:formalrun_results]にあげる．
最も良い精度を出したシステムは人手により作成された規則に基づいている．
我々のシステムは本試験ではシステム番号1223であり，精度はF-measureで限定ドメインに対して74.90，一般ドメインに対して72.18であった．
このように精度が悪かったのは「MIDDLE」に関するラベルの連接規則に洩れがあったためである．
「MIDDLE」に関するラベル同士が連接可能であるという規則が欠如していたため，``比例(ARTIFACT:BEGIN)／代表(ARTIFACT:MIDDLE)／並立(ARTIFACT:MIDDLE)／制(ARTIFACT:END)''のように4形態素以上からなる固有表現は抽出できなくなっていた．
本論文ではその洩れを埋めたときの精度を示した．
その精度は最高でF-measureで85.75(限定ドメイン)，80.17(一般ドメイン)であった．
これはIREX-NE本試験で我々が用いた素性に加えて，[REF_sec:feature]節で述べた人名や組織名などの固有名詞辞書も利用したときの精度であり，悪くない精度であると考えている．
我々の手法は学習コーパスがあれば人手のコストもかからないため，さまざまなドメインに対しても低コストでそれなりの精度が得られるものであると言える．
{
}
