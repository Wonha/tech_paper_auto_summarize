「オントロジー」という用語が喚起する定義や種類，目的などは多様化しているため，本研究がどのようなオントロジーで，何を目的として作るのかを明らかにする必要がある．
Sowaは，主なオントロジーのタイプとして，terminological ontology，prototype-based ontology，formal ontologyなどをあげている(Sowa 2003)．
Terminological ontologyは，概念の上位下位関係や部分全体関係などの関係が特定され，他の概念との相対的な関係が決められているタイプのものである．
このタイプのオントロジーは概念を完全に定義するものではない．
意味公理や論理的な定義よりも，プロトタイプや事例によって弁別されるオントロジーが，prototype-based ontologyである．
つまりプロトタイプ集合や事例集合が相対的な関係をもって分類されているタイプのものである．
また，論理形式で書かれる意味公理や定義によって概念が弁別されるオントロジーがformal ontologyである．
論理の複雑さの制限はない．
一般的なterminological ontologyとformal ontologyの違いは，種類というより，概念間の関係の深さが異なり，formal ontologyは規模が概して小さいが，深い記述がされるため推論をサポートするのに用いられる．
Biemannはそれぞれのタイプを図示し（図1），長所と短所を述べている[CITE]．
このうち，formal ontologyは直接推論に使えるものの，コード化に労力がかかり，大規模になると不整合もおきる危険性がある．
一方，terminological ontologyやprototype-based ontologyは自動化がしやすく作りやすい．
しかし，prototype-based ontologyは，概念ラベルがないので，QAシステムなどには使いにくい．
このオントロジーは語のクラスタリングによってすぐに導出されるのでterminological ontologyより構築しやすいが，利用しにくい．
その他の種類として，シソーラスがあげられる．
シソーラスは関連語のまとまりをもち，prototype-based ontologyに似ている．
しかし，関連語などの中には互いに異なった関係も含まれている場合がある．
テキストからオントロジーを学習するのに利用できる手法として，分布特性によるクラスタリングをはじめ，表層的な統語情報や特定の言語表現パタンなどを利用して，階層関係や部分全体関係などの単語間の関係を獲得する研究などがある[CITE]．
これらの研究と関係が深いが，Semantic lexiconの構築としてのオントロジーの学習という観点もある．
Semantic lexiconは，カテゴリと事例のセットという形であるが，オントロジーのように内部的に構造化されていない．
そのアルゴリズムのほとんどがbootstrappingのアプローチである[CITE]．
以上，Sowa，Biemann[CITE]に従ってオントロジーのタイプを概観したが，我々が目的とする形容詞のオントロジーは，形容詞が事例となり，その事例が共通してもつ概念がラベルとなり，その概念ラベルが構造化されたオントロジーという形である．
上記でいえば，Semantic lexiconのように形容詞の事例とそれらが共通にもつ概念を一つのユニットとして，それが，ラベルつきprototype-based ontologyのように構造化されたものである．
これは，EDR電子化辞書や分類語彙表などの語彙の概念体系／意味体系と同様の形である．
ただし，概念名については，EDR電子化辞書は説明的記述を使い，『分類語彙表』の項目では抽象的な語句あるいは代表的な形容詞を使っているが，本研究では，概念ラベルを抽象的な名詞で表現している．
オントロジーは柔軟に概念と表現を結びつける必要があるので，概念間の関係は一種類ではなく複数想定され，木構造よりネットワーク的な形態の可能性もある．
しかしまずは，概念の類義関係と階層関係をとらえていきたいと考える．
本稿では，その一環として，特に，形容詞の概念の上位・下位関係について焦点をあてる．
日本語では，高橋が，以下のような例を言語学的に観察している[CITE]．
(1)やぎは性質がおとなしい(2)ぞうは鼻が長い
(1)の「性質」は，主体「やぎ」からみると主体のある一面を表すので「側面語」であり，(2)は，主体「ぞう」からみると身体の一部であるので「部分語」と呼び分けて，統語的には同じ構造でも，語の文中での役割の違いを指摘した．
そして，側面語については，主語が示すものの側面を表すとともに，述語が示す属性の類概念（上位概念）を表す単語であると考察している．
また根本は，「色が白い」「速さがはやい」「年が若い」「背が高い」などは，同義反復的な性格が強いと述べている[CITE]．
このように，我々の言語活動の中でも，形容詞の上位概念を語彙化した表現がみられる．
本研究では，(1)の「性質—おとなしい」や「色—白い」「速さ—はやい」などの関係を，「概念とその具体事例」という関係と捉え，このような抽象的な名詞と形容詞の共起をコーパスから抽出する．
本稿では，このような抽象的な名詞を「概念」とよび，共起する形容詞を「事例」と考える．
次に抽出方法であるが，上記の例のような「NはXがAdj」というパタンは今回は利用していない．
この構文のNとX，Adjの意味関係は様々である．
それは，3.1節の(1)と(2)が構文上同じ形をしているにもかかわらず，NやAdjに対するXの意味関係が違っていることからもわかる．
従って，コーパスから「NはXがAdj」の文型を集めると，量は多いが，「概念とその具体事例」という関係を雑多な関係の中から取捨選択することが難しい．
これにはなんらかの基準が必要である．
（なるべくある程度のノイズがあっても自動化したり，あるいは人間が簡単に判別できる基準を求める必要があろうが，それは今後の課題とする．
）
抽出方法は，毎日新聞94年，95年の2年分のデータから，「XトイウY」の句を抽出することからスタートする．
「トイウ」の直前に現れる表現は，内容節（あるいは内容語）である．
寺村，益岡は連体修飾表現を分析しているが，特に益岡では「トイウ」内容節をとる場合は，YがXの属する範疇だとしている[CITE]．
たとえば，「質実剛健という気風」の例では，「気風」（Yに相当）は「質実剛健」（Xに相当）の属する範疇ということである．
そこで，何かを範疇化する可能性をもつ「Y」の収集を目的として，「XトイウY」を使って「Y」をコーパスから自動的に抽出した．
このプロセスは，具体事例によって説明される被修飾名詞の収集を意図している．
具体的には，コーパスを形態素解析（JUMANを使用）したあと，「トイウ」の前後の単語を抽出した．
最終的にYにくる被修飾名詞は15,391語となった．
次に，「トイウ」を介在して内容語を取るYを集めた後，Yと共起する形容詞をコーパスから抽出する．
たとえば，「温和な性格」とは表現しても，「トイウ」を介在させた「温和という性格」のような表現はあまり見られない．
そこで，単にYと共起する形容詞を取り出すことにした．
使用したデータは，毎日新聞11年分，日本経済新聞10年分，日経産業金融流通新聞7年分，読売新聞14年分である．
また，新聞以外でも形容詞とY（名詞）の共起をとるため，新潮文庫100選，新書100冊についても使用例を人手によって調べ追加した．
このように取り出した共起関係には，雑多な共起関係が含まれているので，本研究で対象とした，Xが具体事例でYがそれを範疇化した語という共起対（「赤い」と「色」のような共起対）を，最終的に人手で整理した．
人手によるデータ整理は，一人の作業者が行った．
判定基準は，神崎，神崎・井佐原で記述されている，連体用法にみられる形容詞と名詞の統語的・意味的関係の中から，以下の関係を採用した[CITE]．
Adj（形容詞）＋X（名詞）⇒XがAdj
Xを限定する表現（そのX，「NはXが〜」など）をとらなくても「XがAdj」に変換可能なもの．
被修飾名詞が属性を表現するタイプ．
（例）ゆるやかな傾斜
主語述語関係に変換ができない
形容詞は，被修飾名詞の意味を構成する一部の意味だけにかかり，類似した意味を重ねて強調する働き（例）古い昔
被修飾名詞の指示対象の内容を表す（例）悲しい思い
I)は直接的な属性—属性値の関係であり，II-1)は被修飾名詞の意味の一部を形容詞で顕在化し重ねることで強調する関係，II-2)は被修飾名詞の指示対象の内容を具体化する関係となっている．
どれも被修飾名詞の意味を含意しつつ形容詞表現で具体化する関係であるため，これら3つのパタンを採用した．
以上のように，上記プロセスの2のステップでは，最終的に人間の内省で取捨選択しており，やはり労力がかかるが，1のステップで，被修飾名詞を「何かを範疇化する可能性のある語」に限定することで，抽出対象とする形容詞と概念の共起対を多く含んだデータを得ようとした．
人間の取捨選択で得られた形容詞とY（名詞）共起対の総数は36,023共起対，異なりが10,524共起対である．
概念数は365で，最大共起形容詞数は，「こと」の1,594語である．
出現する共起形容詞数に対する各概念の例は以下のようになる．
そして，抽出した概念と形容詞グループを最終的に以下のようなリストにまとめた．
概念名となる抽象名詞と形容詞集合のリストを作る際，同じ抽象名詞であっても，明らかに指示対象が異なる場合は，番号をつけて区別した．
たとえば，物理的な「形」（たとえば「丸い形」）と，形式的な意味の「形」（たとえば「おだやかな形で〜」）では，「形」の指すものが異なるので，「形1」「形2」のように区別し，形容詞集合をわけた．
一方，形容詞についてはどのような名詞と共起しているか，だけをみており，ここで形容詞の多義は区別していない．
本節では，包含関係を求める尺度を使い，第3節で抽出した形容詞の概念の階層構築を行う．
概念間の包含関係を求める尺度として，Hagita and Sawakiが開発し山本・梅村が言語データへ応用した補完類似度(Complementary Similarity Measure, CSM)と，頻度を考慮したCSM (Freq)，そして，CSM以外の尺度としてオーバーラップ相関係数(Overlap Coefficient，Ovlp)を使う[CITE]．
2つの概念間の包含関係を計算したのち階層構築を行うが，予備実験を行った結果，全ての包含関係の概念ペアを使うと明らかにランダムな長い階層ができた．
そこで，包含関係が希薄な概念ペアが階層関係の精度を低くすることを阻止するため，包含関係の値に閾値を設定することにした．
しかし，閾値設定の問題点として，ゴールドスタンダードがないこのタスクで，複数の尺度や閾値の組み合わせから構築された階層の明らかな差異を，一見して判定できない場合，どのように妥当そうな階層を特定したらよいのだろうか．
第5節では心理実験によって階層評価を行うが，事前に明らかに不適当な尺度と閾値の組み合わせを除外するために，緩やかな階層の評価方法が必要になる．
本節では，包含関係の尺度を用いて階層構築を述べた後，包含関係の尺度と閾値の組み合わせの妥当性をいくつかの観点から眺め，妥当そうな類似尺度と閾値をある程度特定する方法を述べる．
包含関係の尺度として，3種類の方法を用いた．
まず，補完類似度(CSM)について述べる．
補完類似度は一対多関係を推定する尺度として提案されたが，事象間の一対多関係は，包含関係（あるいは上位下位関係）を表すので，包含関係を推定する尺度とも考えられる．
山本，梅村では，｛沖縄県，那覇市｝のような一対多関係を推定するタスクを行っており，そのタスクでは，コーパスからの関係抽出に用いられた他の類似尺度や連想規則の抽出に用いられる類似尺度など（たとえば相互情報量，コサイン関数，ダイス相関係数など）よりもよい結果を示したことが報告されている[CITE]．
この補完類似度を用いて，対象としている概念の包含関係，つまり上位下位関係を推定する．
補完類似度は以下のようになる．
今，共起形容詞のセットで定義した抽象名詞[MATH]と[MATH]があるとする．
我々のデータでは，FとTの特徴ベクトルは，双方の共起形容詞の出現状況を0または1で表現したものに相当する．
それを以下のように表す．
& \overrightarrow{F}=(f_{1}, f_{2},.
..
, f_{i},.
..
,f_{n})　(f_{i}=0または1)
& \overrightarrow{T}=(t_{1}, t_{2},.
..
, t_{i},.
..
, t_{n})　(t_{i}=0または1)
そして，補完類似度の式は以下のようになる．
CSM(F, T) = \frac{ad-bc}{(a+c)(b+d)}
& a = \sum_{i=1}^n f_i \cdot t_i, && b = \sum_{i=1}^n f_i \cdot(1 - t_i),
& c = \sum_{i=1}^n (1 - f_i) \cdot t_i, && d = \sum_{i=1}^n (1 - f_i) \cdot(1 - t_i),
& n = a + b + c + d &&
\nonumber
``[MATH]''はFとTで共通する共起形容詞の数である．
``[MATH]''はFとは共起するがTとは共起しない形容詞の数である．
``[MATH]''はFとは共起しないがTとは共起する形容詞の数である．
``[MATH]''はFともTとも共起しない形容詞の数である．
``[MATH]''は，ベクトルの次元数となる．
FがTを完全に包含する場合，[MATH]となり，TがFを包含する場合，[MATH]となるため，[MATH]となる．
補完類似度では，一致情報(ad)と不一致情報(bc)の差分をとるので，包含関係にある二語間の類似度は高くなる．
さらに，補完類似度はFからTの類似度とTからFの類似度が非対称であることも特徴の一つである．
FからTをみた補完類似度では，[MATH]はFだけに出現する形容詞の数，[MATH]はTだけに出現する形容詞の数である．
逆に，TからFをみた補完類似度では，[MATH]はTだけに出現する形容詞の数となり，[MATH]はFだけに出現する形容詞の数となる．
計算式の分母をみると，FとTがどちらの方向の類似度を計算するかで，[MATH]と[MATH]に代入される数値の大小が逆転し，それに伴って，類似度も非対称になる．
次にCSMと比較する手法として，オーバーラップ相関係数(Ovlp)と頻度つきCSM(Freq)の階層を用いる．
オーバーラップ相関係数について，Manning and Shutzeは包含関係を求める尺度として述べている[CITE]．
これは，二値ベクトル間の類似尺度で，計算式は以下のようになる．
& \overrightarrow{F}=(f_{1}, f_{2},.
..
, f_{i},.
..
,f_{n})　　& (f_{i}=0または1)
& \overrightarrow{T}=(t_{1}, t_{2},.
..
, t_{i},.
..
, t_{n}) & (t_{i}=0または1)
\nonumber
[b] \mathit{Ovlp}(F, T) &= \frac{|F \cap T|}{min}(|F|, |T|)
&= \frac{a}{min}(a + b , a + c)
& a = \sum_{i=1}^n f_i \cdot t_i, & b = \sum_{i=1}^n f_i \cdot(1 - t_i),
& c = \sum_{i=1}^n (1 - f_i) \cdot t_i &
\nonumber
[MATH]，[MATH]，[MATH]などのパラメータは，CSMでの定義と同様である．
次に頻度を考慮した補完類似度について計算式を示す．
これは，Sawaki, Hagiga, and Ishiiが二値画像のための補完類似度を，多値画像解析のために拡張したものである[CITE]．
Yamamoto, Kanzaki, and Isaharaではこれを言語データに応用している[CITE]．
これは，多値ベクトル間の類似尺度で，計算式は以下のようになる．
& \overrightarrow{F}_g = (f_{g1}, f_{g2},.
..
, f_{gi},.
..
,f_{gn})　　& (0 \leq f_{gi} < 1)
& \overrightarrow{T}_g = (t_{g1}, t_{g2},.
..
, t_{gi},.
..
, t_{gn}) & (0 \leq t_{gi} < 1)
\nonumber
CSM_{g}(F_{g}, T_{g}) = \frac{a_{g}d_{g}-b_{g}c_{g}}{nT_{g2} - T_{g}^{2}}
& a_{g} = \sum_{i=1}^n f_{gi} \cdot t_{gi}, && b_{g} = \sum_{i=1}^n f_{gi} \cdot(1 - t_{gi}),
& c_{g} = \sum_{i=1}^n (1 - f_{gi}) \cdot t_{gi}, && d_{g} = \sum_{i=1}^n (1 - f_{gi}) \cdot(1 - t_{gi}),
& T_{g} = \sum_{i=1}^n T_{gi}, && T_{g2} = \sum_{i=1}^n t_{gi}^2
\nonumber
この定義式において，各要素は，には，抽象名詞（概念に相当）がi番目の形容詞と頻繁に共起するかどうかの状況を表す，共起頻度に基づく重みを用いる．
重みは以下のように求める．
\mathit{Weight}(\mathit{noun}, \mathit{adj}) = \frac{Freq} (\mathit{noun}, \mathit{adj}){Freq} (\mathit{noun}, \mathit{adj}) + 1
\text{重みの値域は[MATH]である．
} \nonumber
ベクトル[MATH]を持つ抽象名詞を[MATH]と[MATH]を持つ抽象名詞を[MATH]とし，上式の重みで[MATH]を表すと，ベクトルは以下のように表される．
\overrightarrow{F}_g &= (f_{gi}, f_{g2}, .
..
, f_{gn}) \nonumber
&= (\mathit{Weight}(\mathit{noun}_F, \mathit{adj}_1), \mathit{Weight}(\mathit{noun}_F, \mathit{adj}_2), \dots , \mathit{Weight}(\mathit{noun}_F. \mathit{adj}_n)) \nonumber
\overrightarrow{T}_g &= (t_{gi}, t_{g2}, \dots , t_{gn}) \nonumber
&= (\mathit{Weight}(\mathit{noun}_T, \mathit{adj}_1), \mathit{Weight}(\mathit{noun}_T, \mathit{adj}_2), \dots , \mathit{Weight}(\mathit{noun}_T. \mathit{adj}_n))
CSMなどによって包含関係を計算し，値を正規化して得られたリストの一部を示すと以下のようになる．
単語Aから単語Bを見たときのCSM値が，単語Bから単語Aを見たときのCSM値より大きければ，単語Aが上位語，単語Bが下位語となる．
たとえば，本稿では概念とは第3節で抽出した抽象的な名詞で定義しており，上記の概念の並びは，左の概念からみた右の概念の包含関係を表している．
たとえば，左の概念が「印象」で右の概念が「感じ」の場合は，「印象」からみた「感じ」を示し，上記ではCSM値は0.936となる．
逆に，方向が逆転し，左の概念が「感じ」で右の概念が「印象」の場合は，「感じ」からみた「印象」の包含関係を表し，0.778となる．
この場合「印象」から「感じ」を見るほうが，CSM値が高いので，「印象」は「感じ」の上位概念となる．
ただし，この場合は両方向からのCSM値が高いので，かなり事例に重なりがあると考えられる．
上記のような二単語間の包含関係を求めた後，これを利用して階層を構築する．
階層構築方法は次のようになる．
初期階層として，CSM値の高い順に二単語をつなげる．
ここでは，仮に単語Aが上位語，単語Bが下位語という関係とする．
階層(0): A-B（``-''は上位下位関係を示す記号とする）
まず，階層(0): A-Bの下位語を探索する．
二単語間のCSM値のリストから，単語Bを上位語として，Bの下位語として最大値をとる単語Xを探して，単語Bの後ろに連結し，次に，その単語Xを上位語として，Xの下位語として最大値をとる単語Yを探して，単語Xの後ろに連結する．
この操作を下位語がなくなるまで繰り返す．
これによって以下のような階層ができる．
階層(1)：A-B-X-Y
次に，階層(0): A-Bの上位語を探索する．
二単語間のCSM値のリストから，単語Aを下位語として，Aの上位語として最大値をとる単語Wを探して，単語Aの前に連結し，次に，その単語Wを下位語として，Wの上位語として最大値をとる単語Vを探す．
この操作を上位語がなくなるまで繰り返す．
階層(1)と連結することで以下のような階層ができる．
階層(2): V-W-A-B-X-Y
ただし，上位下位関係は必ず保存する．
もし上位下位関係が逆転した場合はその関係は連結しない．
長い階層に完全に含まれる短い階層はマージし，二つの階層のうち一単語ずつ異なる場合は，各階層の差異となる二単語の補完類似度の値を測り，上位下位関係があれば結合した．
A-B-C-D-EとA-B-Dという階層があるとき
A-B-Dは，順序を保存した状態で長い階層に完全に含まれるのでマージし，短い階層は削除する．
A-B-C-D-E
A-B-C-D-EとA-B-X-D-Eがあるとき
CとXの補完類似度の値を求め，CとXに上位下位関係があれば結合した．
A-B-C-X-D-E
最後に各階層のトップに「こと」を結合する．
「こと」は全ての形容詞と共起するとして，計算時間の便宜上，「こと」は最後に各階層のトップに結合させることとした．
最終階層:こと-V-W-A-B-X-Y
4.2節で求めた概念間の包含関係を全て使って階層を構築すると，冗長な意味のない概念階層（つまり単語の羅列）になり，閾値があまりに高いと，概念階層は非常に短くなる（つまり，連結される名詞があまりにも少なくなる）．
そこで，包含関係が希薄な概念ペアが階層関係構築時に悪影響を及ぼすことを阻止するため，包含関係の値に閾値を設定することにした．
CSMについては0.3と0.2，Ovlpについては0.3と0.2，Freqについては0.2と0.1の閾値を設定し，その閾値以上の概念間の包含関係を用いて階層を構築した．
これらの閾値による階層は，概念を連結したある程度の長さの階層であり，かつ，明らかにおかしい概念の羅列ではない．
この閾値以上でも以下でも，前述の弊害が出る．
逆にいえば，前述の閾値からできた階層は，一見して妥当なのか，妥当ではないのか，すぐにはわからないともいえる．
手法ごとに多くの階層が生成され，閾値をいくつか設定すれば，その分だけ，また階層が増えるので，心理実験などで既存辞書との比較評価を行おうと思えば，妥当そうな階層を事前に選定した方が効率的である．
そこで，次のような観点から，階層を分析した．
形容詞の階層としてできた階層の割合
第2節で述べたprototype-based ontologyで構造化された事例集合（図1）をみるとわかるように，最下位レベルで出現している「チーズ」は，最上位レベルの事例集合にも出現している．
通常，上位概念の特徴は下位概念の特徴に「継承」される．
概念の特徴を定義するのが事例集合である場合，下位レベルで出現する事例は，上位レベルの概念の事例にもなる（「すずめ」は，鳥の事例でもあり，動物の事例でもあり，生物の事例である）．
この認知科学的ルールから，自動構築した階層の，最下位概念の事例集合（形容詞の集合）が，最上位概念までの各概念の事例集合に含まれているかを調べ，連続して出現していれば，その階層は，当該形容詞の階層と考える．
本稿のデータで考えると，「形容詞の階層としてできた階層」とは，ある形容詞が，最下位から最上位に位置するすべての概念の形容詞集合に出現している場合，その階層を「形容詞の階層としてできた階層」と呼ぶ．
もし，ある形容詞が，階層のどこかの概念の形容詞集合の成員でなければ，形容詞の階層とはよばず，手法によって得られた「階層」とよぶ．
この考えに則って，手法ごとに，得られた階層の中で，形容詞の階層として得られた階層が何割あるか，計算した．
分母は，ある手法に基づいて構築された全階層であり，分子は「形容詞の階層としてできた階層」である．
事例としてコーパスから抽出された全形容詞のうち，何語の形容詞に「形容詞の階層」が得られたか．
階層を構成する概念の割合
概念としてコーパスから抽出した抽象名詞は全部で365語あるが，そのうち何割が階層を構成しているか．
階層を構成する概念の割合は次のように計算した．
上記3つの観点から各手法の結果を求めると，表4のようになる．
表中で，高い数値の第一位から第三位に「○」，そのうち極端に数値が高い場合は「◎」を数字の前に付与した．
また，極端に数値が低いものには「＊」を付与した．
表1から，総合的にみるとCSM0.2とOvlp0.3が，形容詞の階層としてできた階層の割合も，階層ができた形容詞数や365の概念のうちで階層を構成する概念の割合もよいとわかる．
CSM0.3は，6種類の階層の中で形容詞の階層を最も多く作っているが，階層を構成している概念の数が最も低い．
これは同じ階層をもつ形容詞のグループが，未分化である可能性がある．
また，Ovlp0.2の階層は，形容詞の階層はあまり作られていないが，対象にしている365の概念をほとんど使って，階層を作っている．
これは，冗長に階層を作っている可能性がある．
程度の差こそあれ同様の傾向がみられるのはFreq0.1である．
形容詞をカバーする階層は少ないが，階層を構成している概念が多いことがわかる．
Freq0.2は，形容詞をカバーする階層は多めであるが，それより顕著な特徴は，階層を構成する概念の種類が少ないことである．
程度の差こそあれ，その点では，CSM0.3に似た傾向がみられる．
上記の結果より，CSM0.2とOvlp0.3は，外見的に妥当そうな階層となっているので，EDRと比較する階層としてこの二者を選択する．
また，頻度を考慮したCSM (Freq)については，両者の閾値とも外見上それほど適当ではないが，異なる種類を比較するということで，形容詞の階層が比較的得られているFreq0.2を，EDRとの比較実験に加えることとする．
第3節で取り出した言語データから形容詞概念を体系的にとらえるためには，階層関係と同時に類義関係も考慮する必要がある．
これまでに，形容詞と抽象的な名詞を類義関係によって自動分類する研究として，Kohonenの自己組織化神経回路網モデル(Self-Organizing map，SOM)を用いた研究がある[CITE]．
Kohonenの自己組織化神経回路網モデルは，高次元入力をもつ2次元配列のノード（ニューロン）で構成され，自己組織化によって高次元データを2次元空間に，その特徴を反映するように，非線形的に射影する．
特徴は，得られる分布が可視的でまた連続的であるということである．
特に，連続的な分布という性質は，言葉の意味の連続性を反映できると考えられ，馬らの研究に用いられている．
出力される2次元平面は，意味的に類似性の高い名詞どうしが近くに配置され，意味的に類似性の低い名詞どうしが遠くに配置されるような，意味的類似性を距離とする2次元表現である．
馬らは出力される2次元平面をマップと呼んでいる．
馬らの研究では，SOMの分類能力を多変量解析や階層型クラスタリング手法等と比較実験し，その結果，他手法より劣らない，あるいは彼らのタスクに関してはむしろよい結果を得たと報告している．
しかし，提案されたSOMによる分類では，類義関係以外の意味関係は求めることができなかった．
Kanzaki et al.では，上位下位関係（包含関係）をSOMに導入する実験を行っている[CITE]．
この実験でSOMの入力データとなる単語の特徴ベクトルは，当該単語に対する全対象単語との包含関係値を多次元ベクトルにしたものである．
つまり，この特徴ベクトルをSOMの入力とすることにより，類似した包含関係をもつ単語どうしが類義関係をもつことになる．
SOMは通常，類義関係を可視化するので，SOMに包含関係を導入した場合，出力されるマップは，上位下位関係が反映された方向性ある分布になるか，あるいは方向性の全くみられない分布になるかの可能性が考えられる．
包含関係を導入したSOMの分布は，評価方法が提案されていないためさらに検討する必要があるものの，抽象度が高い名詞から抽象度の低い名詞へと方向性ある分布を示唆したものとなった．
SOMによるマップに，概念の階層関係が反映されれば，同じような上位下位関係をもつ概念が類義関係となって近くに分布することになり，階層関係と類義関係を同時に反映した分類をえられる可能性がある．
結果は，既存のシソーラスなどと比較して差異を考察すると共に，形容詞側から，得られた概念体系に従って形容詞表現の様相をとらえていきたい．
