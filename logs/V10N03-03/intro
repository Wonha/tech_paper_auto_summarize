単語の意味を判別し，多義曖昧性を解消する技術（語義曖昧性解消; Word Sense Disambiguation）は，機械翻訳や情報検索，意味・構文解析など，自然言語処理のあらゆる分野において必要である[CITE]．
これは一般に，テキストに現れた単語の語義が辞書などであらかじめ与えられた複数の語義のいずれに該当するかを判定する分類問題である．
ただし，曖昧性解消をどのような応用に利用するかに依存して，どのような語義分類を与えるのが適切であるかは異なる．
そして，分類の粒度や語義定義の与え方に応じて，最適な分類手法は異なってくることが予想される．
それゆえ，具体的な応用に沿った語義曖昧性解消課題を設定して解決手法を研究することは有用である．
2001年に開催された語義曖昧性解消国際コンテストSenseval-2では，このような考え方に基づき，日本語翻訳タスクが実施された．
本タスクは，日本語単語（対象語）320語に対して，1語あたり約20の日英対訳用例を収集した翻訳メモリを語義分類の定義と見なし，新たな日本語表現に含まれる対象語の語義を翻訳メモリ中の適切な用例を選択することで分類する課題である[CITE]．
各対象語の語義分類は，翻訳メモリとして収集された日英の表現対であるが，語義を決定している重要な要因が日本語表現に現れる周辺文脈であるとみなすことにより単言語の語義曖昧性解消課題と捉えることができる．
この種の問題は，一般に，正解タグを付与した訓練データを用い，各分類に属する表現例の対象語周辺文脈の性質を機械学習によって獲得することで解決できる．
正解タグを付与した訓練データの作成のために，さまざまな全自動/半自動の訓練データ構築手法が提案されてきた[CITE]．
しかし，本タスクには，以下のような問題点がある．
翻訳メモリ中には，各語義分類ごとに1つしか正解例が与えられない．
また，正解タグを付与した訓練データも（タスクの配布物としては）与えられない．
翻訳メモリ中の表現は，（人間の感覚で）最低限語義を分別できる程度の，たかだか数語の文脈しか持たない．
語義分類間の違いがしばしば非常に微妙である．
本タスクでは，上記の問題点のため，正解例を機械的に拡張するための手がかりは乏しく，これを精度よく行うことは難しい．
このため，我々は，入力表現を直接的に翻訳メモリの各日本語表現と比較して表現間の類似度を計算し，用例を選択する手法を採用した．
我々は，情報抽出や文書分類の分野でよく用いられるベクタ空間モデル（Vector Space Model）による文書間比較[CITE]の手法に着目し，Schutzeによる，目的語の近傍に出現する単語の情報をベクタ（共起ベクタ）に表現して共起ベクタ間の余弦値を類似度の尺度とする手法[CITE]を用いた．
ベクタ空間モデルでは，通常，ベクタの各次元に文書中の単語の出現（真偽値）や出現頻度を配置する．
しかし本タスクへの適用を考えた場合，翻訳メモリの日本語表現中に対象語と共に出現する単語は非常に少ないため，単純に表層的な単語出現情報を用いるだけでは表現の特徴（表現間の差異）をつかみきれない．
またデータスパースネスの影響も深刻である．
そこで我々は，単語の代わりに対象語周辺の各種素性（文脈素性）の出現を各次元に配置したベクタ（文脈素性ベクタ）を用いることとした．
各文脈素性は，対象語周辺文脈を特徴づける要素を表すもので，表現中に出現する内容語の
対象語との構文的/位置的関係（構文解析の結果から獲得）
例:対象語にガ格でかかる，対象語より前にある，任意の位置，…
形態的/意味的属性（形態素解析の結果とシソーラスから獲得）
例:標準形=「子供」，品詞=「名詞」，シソーラス上の意味コード=「名\kern0pt86」，…
を任意に組み合わせたものである．
これは，対象語周辺の単語の出現をさまざまな抽象化のレベルで捉えることを意味する．
これにより，文脈素性ベクタは，表現間の微妙な違いを表現すると同時に，適応範囲の広い文脈特徴量となることが期待できる．
本稿では，まず[REF_sec:task]章でSenseval-2日本語翻訳タスクの特徴について述べるとともに，本タスクを解決するシステムの設計方針について述べる．
次に[REF_sec:method]章で文脈素性ベクタを用いた翻訳選択の手法を説明する．
そして[REF_sec:senseval_result]章でSenseval-2参加システムの諸元と，コンテスト参加結果を紹介する．
[REF_sec:vector_component]章では，[REF_sec:method]章で各種文脈素性の翻訳選択性能への寄与について調査した結果を報告し，考察を行う．
最後に[REF_sec:conclusion]章でまとめと今後の課題について述べる．
