各対象語の語義分類は，翻訳メモリとして収集された日英の表現対であるが，語義を決定している重要な要因が日本語表現に現れる周辺文脈であるとみなすことにより単言語の語義曖昧性解消課題と捉えることができる．
この種の問題は，一般に，正解タグを付与した訓練データを用い，各分類に属する表現例の対象語周辺文脈の性質を機械学習によって獲得することで解決できる．
正解タグを付与した訓練データの作成のために，さまざまな全自動/半自動の訓練データ構築手法が提案されてきた[CITE]．
しかし，本タスクには，以下のような問題点がある．
翻訳メモリ中には，各語義分類ごとに1つしか正解例が与えられない．
また，正解タグを付与した訓練データも（タスクの配布物としては）与えられない．
翻訳メモリ中の表現は，（人間の感覚で）最低限語義を分別できる程度の，たかだか数語の文脈しか持たない．
語義分類間の違いがしばしば非常に微妙である．
本タスクでは，上記の問題点のため，正解例を機械的に拡張するための手がかりは乏しく，これを精度よく行うことは難しい．
このため，我々は，入力表現を直接的に翻訳メモリの各日本語表現と比較して表現間の類似度を計算し，用例を選択する手法を採用した．
我々は，情報抽出や文書分類の分野でよく用いられるベクタ空間モデル（Vector Space Model）による文書間比較[CITE]の手法に着目し，Schutzeによる，目的語の近傍に出現する単語の情報をベクタ（共起ベクタ）に表現して共起ベクタ間の余弦値を類似度の尺度とする手法[CITE]を用いた．
ベクタ空間モデルでは，通常，ベクタの各次元に文書中の単語の出現（真偽値）や出現頻度を配置する．
しかし本タスクへの適用を考えた場合，翻訳メモリの日本語表現中に対象語と共に出現する単語は非常に少ないため，単純に表層的な単語出現情報を用いるだけでは表現の特徴（表現間の差異）をつかみきれない．
またデータスパースネスの影響も深刻である．
そこで我々は，単語の代わりに対象語周辺の各種素性（文脈素性）の出現を各次元に配置したベクタ（文脈素性ベクタ）を用いることとした．
各文脈素性は，対象語周辺文脈を特徴づける要素を表すもので，表現中に出現する内容語の
対象語との構文的/位置的関係（構文解析の結果から獲得）
例:対象語にガ格でかかる，対象語より前にある，任意の位置，…
形態的/意味的属性（形態素解析の結果とシソーラスから獲得）
例:標準形=「子供」，品詞=「名詞」，シソーラス上の意味コード=「名\kern0pt86」，…
を任意に組み合わせたものである．
これは，対象語周辺の単語の出現をさまざまな抽象化のレベルで捉えることを意味する．
これにより，文脈素性ベクタは，表現間の微妙な違いを表現すると同時に，適応範囲の広い文脈特徴量となることが期待できる．
