まず，生成したい教師データについて整理する．
本研究では，クレーム文を検知するためにナイーブベイズ分類器[CITE]を構築し，文がクレームを表しているか，あるいはクレームを表していないかのどちらかに分類したい．
このような分類器の構築に必要となる教師データは，言うまでもなく，クレームを表している文（以下，クレーム文と呼ぶ）の集合と，クレームを表していない文（以下，非クレーム文）の集合となる．
以下では，説明の便宜上，このデータ集合を得る手続きをラベル付けと呼び，【クレーム】および【非クレーム】というラベルによって，どちらの集合の要素となるかを区別することとする．
例えば，\fig{review}の各文に対してラベル付けが実施されたとすると，次のようなラベル付きの教師データが得られる．
【非クレーム】従業員の方は親切でした．
【非クレーム】最寄りの病院など教えて頂き，とても助かりました．
【非クレーム】ありがとうございました．
【クレーム】ただ残念だったのが，シャワーの使い方がよくわからなかったことです．
【クレーム】使い方の説明をおいて頂きたいです．
本論文で提案する教師データ自動生成手法は，評価表現の情報に基づくラベル付けステップと，ある文の文脈に対する文脈一貫性の情報に基づくラベル付けステップの2ステップで構成される．
各ステップをそれぞれ核文ラベル付けおよび近接文ラベル付けと呼ぶことにし，以下で順に説明する．
核文ラベル付けは，評価表現の情報に基いて行う．
評価表現とは，「おいしい」や「まずい」等，評価対象に対する評価を明示的にあらわす言語表現のことである．
一般的には，これら表現に「おいしい／肯定」や「まずい／否定」のような肯定・否定の評価極性値を付随させたものを集めて評価表現辞書と呼ばれている[CITE]．
核文ラベル付けステップでは，評価表現辞書に否定極性として登録されている評価表現に着目し，このような評価表現を含む文はクレームを表しやすいと仮定する．
そして，否定極性の評価表現を含む文をクレーム文としてラベル付けする．
以降，この手続きで得られる文を次ステップで得られる文と区別するため核文と呼び，特に，核文がクレーム文である場合はクレーム核文と呼ぶ．
例えば，「まずい／否定」という単語が評価表現辞書に登録されている場合，次の例文はクレーム核文としてラベル付けされる．
【クレーム（核）】朝食のカレーがまずい．
もし，ある文が肯定極性をもつ評価表現を含み，かつ「ない」や「にくい」などの否定辞が評価表現の3単語以内に後続していた場合もクレーム核文としてラベル付けする．
例えば，次の例文は「おいしい／肯定」の直後に否定辞「ない」が後続しているため，クレーム核文としてラベル付けされる．
【クレーム（核）】朝食のカレーがおいしく\unc{ない}．
また，評価表現の否定極性と肯定極性を読み替えて上記と同様の手続きを行った場合に得られる文を非クレーム核文と呼び，クレーム核文と同じようにラベル付けしておく．
【非クレーム（核）】朝食のカレーがおいしい．
【非クレーム（核）】ハヤシライスは別にまずくは\unc{ない}．
さらに，「ほしい」等の要求表現を集めた要求表現辞書が利用できる場合は，次の例のように要求表現を含む文をクレーム核文としてラベル付けする．
ただし，要求表現に注目したラベル付けの場合は，評価表現の時とは違って，否定辞の有無に関係なくクレーム核文としてラベル付けする．
【クレーム（核）】朝食に和食メニューをもっと増やしてほしい．
【クレーム（核）】朝食を洋風なものばかりにしてほしく\unc{ない}．
以降，クレーム核文と非クレーム核文をあわせた文の集合を[MATH]であらわす．
那須川ら[CITE]は，彼らの論文の中で，評価表現の（文をまたいだ）周辺文脈には以下のような傾向があると述べており，これを評価表現の文脈一貫性と呼んだ．
{文書中に評価表現が存在すると，その周囲に評価表現の連続する文脈（以降，評価文脈）が形成されることが多く，その中では，明示されない限り，好不評の極性が一致する傾向がある．
}
本研究では，この評価表現の文脈一貫性の考え方に基いて近接文ラベル付けを行う．
先の核文ラベル付けの際に考慮した評価表現（あるいは要求表現）を含む文の周辺文脈について，「評価表現（要求表現）の存在に基づいて（非）クレーム文として選ばれた文の前後文脈に位置する文は，やはり（非）クレーム文である」という仮定をおき，この仮定に従って，核文の周辺文脈に対してラベル付けを行う．
この手続きで得られる文を近接文（より詳細にはクレーム近接文あるいは非クレーム近接文）と呼ぶ．
[b]
近接文ラベル付けの手続きを\algo{alg1}に示す．
この手続きへの入力は，核文ラベル付けを終えたレビュー[MATH]と，核文に対する周辺文脈の長さを決定する窓枠長[MATH] ([MATH])であり，レビュー[MATH]に含まれる核文に対して，レビューの先頭側に現れる核文から末尾側に現れる核文に向かって順に処理が進む．
なお，\algo{alg1}において，[MATH]はレビュー[MATH]内の先頭から[MATH]番目の文をあらわし，[MATH]は[MATH]内の文数をあらわす．
処理の大きな流れとしては，line.2--9でラベル付けされる文が選択され，line.10--16でラベル付けが実施される．
line.17--34の各関数では，付与するラベルの種類（``クレーム''か``非クレーム''）を確定する際に必要な仮のラベル情報が決められ，その情報が格納される．
\fig{context}を使って近接文ラベル付けの具体的な実行例を示す．
図の例では，対象となるレビューは8つの文から構成されており，核文ラベル付けによって文[MATH]が非クレーム核文，文[MATH]がクレーム核文とラベル付けされた状態であり，この状態から近接文ラベル付けが開始される．
窓枠長は[MATH]とする．
この場合，まず，核文[MATH]の周辺文脈に対する処理がなされる（\algo{alg1}のline.3）．
[MATH]は文書の先頭文であり前方文脈(Backward context)は存在しない．
そのため，後方文脈(Forward context)の[MATH]と[MATH]に対してのみ処理がなされ(line.6--7)，それぞれ``非クレーム''ラベルが配列に格納される(line.29)．
次に核文[MATH]の周辺文脈に対する処理がなされる．
[MATH]はクレーム文であるため，前方文脈では[MATH]に対して2つ目のラベル``クレーム''が格納され(line.19)，また新たに[MATH]に対して``クレーム''ラベルが格納される(line.19)．
後方文脈では，まず[MATH]に対して``クレーム''ラベルが配列に格納される(line.28)．
その一方で，[MATH]は逆接関係の接続詞「しかし」の影響があるため，``クレーム''ではなく``非クレーム''ラベルが格納される(line.31)．
最後に，各文に対して格納されたラベル情報をチェックし，格納されたラベルに不整合がない場合は，そのラベル情報に従ってラベル付けを行う(line.10--16)．
不整合が生じている場合はその文に対してどのラベルも付与しない．
以上の操作によって，この例では2つの核文から新たに4つの近接文（[MATH]，[MATH]，[MATH]および[MATH]）が得られる．
以降，クレーム近接文と非クレーム近接文をあわせた文の集合を[MATH]であらわす，また，必要に応じて，核文の前方文脈から得られた近接文[MATH]と，後方文脈から得られた近接文[MATH]を区別する([MATH])．
前節で述べた手法によって自動生成された教師データは，人手によって作成された教師データと比べて質が劣化せざるを得ず，標準的な分類モデルをそのまま適用するだけでは期待した精度は得られない．
そこで，前節で述べた手法で得られる劣化を含むデータを使用するという前提をおき，この劣化データがもつ特性を踏まえてナイーブベイズ・モデルを拡張することを考える．
以下では，まず，通常のナイーブベイズ・モデル（多項モデル）について述べ，その後，モデルの拡張について述べる．
ナイーブベイズ分類器では，ある文[MATH]の分類クラスを判定する際に，条件付き確率[MATH]を考え，この確率値が最大となるクラス[MATH]を分類結果として出力する．
つまり，
である．
通常のナイーブベイズ・モデルでは上式を次のように展開する．
\argmax _{c}P(c|s) &= \argmax _{c}P(c)P(s|c)\nonumber
& = \argmax_{c} \bigp_{c}+\sum_{w\in{V}}^{}n_{w}(s)\log q_{w,c} \big
ここで，[MATH]は語彙集合，[MATH]は文[MATH]における単語[MATH]の出現回数をあらわす．
また，[MATH]，[MATH]は教師データを使ってそれぞれ以下の式で計算される．
本研究ではパラメータを推定する際にラプラススムージング[CITE]を用いる．
q_{w,c}&= \fracn_{w,c}(\mathcal{D})+1\sum_{w}^{}n_{w,c}(\mathcal{D})+|\mathcal{V}|
p_{c} &= \fracn_{c}(\mathcal{D})+1\sum_{c}^{}n_{c}(\mathcal{D})+|\mathcal{C}|
ここで，[MATH]は教師データとなる文の集合，[MATH]はデータ[MATH]においてクラス[MATH]に属する文に現れる[MATH]の出現回数，[MATH]はデータ[MATH]においてクラス[MATH]に属する文の数，[MATH]は語彙の種類数，[MATH]は分類クラスの種類数である．
以上からもわかるように，通常のモデルでは，分類対象となる文内の情報のみを考慮し，分類対象文の周辺文脈の様子は全く考慮されない．
たとえ同一文書内であっても個々の文は独立に評価・分類する．
また，教師データの利用にあたっても，当然のことながら，核文であるか近接文であるかといった区別はなく，両タイプの文が同等にモデルの構築に利用される．
前節で述べた教師データ生成過程から得られるデータには，核文および近接文という2種類の文が存在する．
この2種類の文のうち，核文は近接文とは独立にラベル付けされる一方で，近接文は核文の情報に基いて間接的にラベル付けされる．
そのため，核文ラベル付けが結果として誤りであった事例に関しては近接文もその誤りの影響を直接受けることになる．
また，当然ながら，文脈一貫性の仮定が成立しない事例もあり得る．
このような理由から，近接文は核文に比べて相対的に信頼性の低いデータとなる可能性が高い．
そこで，このことを考慮し，核文と近接文の情報をモデル内で区別して扱い，近接文の情報がモデル内で与える影響を下げるよう，\eq{eq1}の代わりに次のような\eq{eqex}を用いる．
\argmax _{c}P(c|s) &= \argmax _{c}P(c)P(s|c) \nonumber
&= \argmax_{c} \big{\log p_{c}+\sum_{w}n_{w}(s)\log q^{tgt}_{w,c} \nonumber
& \phantom{= \argmax_{c} \bigp_{c} + \frac{1}{|ctx(s,N)|}\sum_{w}n_{w}(ctx(s,N))\log q^{ctx}_{w,c} \big}
右辺第3項に現れる[MATH]は[MATH]の周辺文脈に位置する前方および後方のそれぞれ[MATH]文から構成される文の集合を表しており，この項が分類対象の周辺文脈をモデル化している．
この項の係数[MATH]で，周辺文脈の文数に応じてその影響を調整している．
なお，[MATH]は，集合[MATH]の要素となる全ての文における単語[MATH]の総出現回数をあらわす．
また，右辺第2項は通常のモデルと同様に分類対象となる文をモデル化したものであるが，第3項の周辺文脈との区別を明瞭にするため，[MATH]という記号を新たに導入した．
\eq{eqex}の[MATH]と[MATH]，および[MATH]はそれぞれ次式で求める．
式中の各記号の意味は\eq{eq2}，\eq{eq3}と同様である．
ここで，[MATH]は分類対象文をモデル化するための教師データ集合，[MATH]は分類対象の周辺文脈をモデル化するための教師データ集合である．
基本的には，前節で得られる教師データのうち，核文データを[MATH]に割り当て，近接文データを[MATH]に割り当てるが，正確な記述は後述の\sec{wariate}で与える．
q^{tgt}_{w,c} & = \fracn_{w,c}(\mathcal{D}_{tgt})+1\sum_{w}n_{w,c}(\mathcal{D}_{tgt})+|\mathcal{V}_{tgt}|
q^{ctx}_{w,c} & = \fracn_{w,c}(\mathcal{D}_{ctx})+1\sum_{w}n_{w,c}(\mathcal{D}_{ctx})+|\mathcal{V}_{ctx}|
p_{c} & = \fracn_{c}(\mathcal{D}_{tgt})+1\sum_{c}n_{c}(\mathcal{D}_{tgt})+|\mathcal{C}|
以降，便宜的にこの拡張されたモデルをNB+ctxと呼ぶ．
さらに，\eq{eqex}の第3項について，周辺文脈を分類対象文からの相対位置で詳細化した
を代わりに利用するモデルも考えられる．
ここで，[MATH]は，[MATH]の前方文脈に位置する[MATH]文から構成される文の集合であり，[MATH]は同様に後方文脈で構成される文集合である．
また，式中の[MATH]および[MATH]は次式で求める．
ただし，[MATH]である．
q^{Bctx}_{w,c} & = \fracn_{w,c}(\mathcal{D}^{B}_{ctx})+1\sum_{w}n_{w,c}(\mathcal{D}^{B}_{ctx})+|\mathcal{V}_{Bctx}|
q^{Fctx}_{w,c} & = \fracn_{w,c}(\mathcal{D}^{F}_{ctx})+1\sum_{w}n_{w,c}(\mathcal{D}^{F}_{ctx})+|\mathcal{V}_{Fctx}|
以降，便宜的にこのモデルをNB+ctxBFと呼ぶ．
ここでは，さきほどの説明で保留していた，パラメータ推定の際に必要となる教師データの与え方について述べる．
ここで，前節で述べた手法によって得られるデータ集合を確認すると，
[MATH]：クレーム核文と非クレーム核文をあわせた文の集合
[MATH]：クレーム近接文と非クレーム近接文をあわせた文の集合
[MATH]：[MATH]の要素のうち，核文の前方文脈から得られた文で構成される集合
[MATH]：[MATH]の要素のうち，核文の後方文脈から得られた文で構成される集合
であり，[MATH]であった．
これらデータ集合に対して，まず，核文と近接文を区別しない単純な割当として，得られた全データをまとめて利用することが考えられる．
この場合，拡張モデルNB+ctxにおいての割当は，
[MATH]
[MATH]
となる．
これを以降NB+ctx(all)と呼ぶ．
また同様に，拡張モデルNB+ctxBFにおいての単純な割当は，
[MATH]
[MATH]
[MATH]
となるが，これは先のNB+ctx(all)と事実上同等となるため以降の議論では割愛する．
次に，核文と近接文の区別を考慮したデータ割当を考える．
拡張モデルNB+ctxにおいての割当としては，
[MATH]
[MATH]
が考えられる．
これを以降NB+ctx(divide)と呼ぶ．
また同様に，拡張モデルNB+ctxBFにおいてのデータ割当として，
[MATH]
[MATH]
[MATH]
が考えられる．
これを以降NB+BFctx(divide)と呼ぶ．
最後に，通常のナイーブベイズについて考えると，この場合は，もともとのモデルにデータを区別する枠組みが存在しないため，
[MATH]
という割当のみを考えることになる．
なお，[MATH]という核文のみを考慮し，近接文を利用しない割当も考えられるが，これは[MATH]において近接文の窓枠長を[MATH]とする場合に等しいため，割当規則として明示的には議論しないが，第\sec{exp}の評価実験では，近接文の窓枠長が[MATH]の場合も含めて議論する．
以降，これをNBと呼ぶ．
ここまでの議論を整理すると，前節の手法で自動生成された教師データを利用するという前提のもとで，通常のナイーブベイズ・モデルも含めて，4つのクレーム文検出モデルが与えられたことになる．
次節では，評価実験を通じて，これらの有効性を検証していく．
まず，生成したい教師データについて整理する．
本研究では，クレーム文を検知するためにナイーブベイズ分類器[CITE]を構築し，文がクレームを表しているか，あるいはクレームを表していないかのどちらかに分類したい．
このような分類器の構築に必要となる教師データは，言うまでもなく，クレームを表している文（以下，クレーム文と呼ぶ）の集合と，クレームを表していない文（以下，非クレーム文）の集合となる．
以下では，説明の便宜上，このデータ集合を得る手続きをラベル付けと呼び，【クレーム】および【非クレーム】というラベルによって，どちらの集合の要素となるかを区別することとする．
例えば，\fig{review}の各文に対してラベル付けが実施されたとすると，次のようなラベル付きの教師データが得られる．
【非クレーム】従業員の方は親切でした．
【非クレーム】最寄りの病院など教えて頂き，とても助かりました．
【非クレーム】ありがとうございました．
【クレーム】ただ残念だったのが，シャワーの使い方がよくわからなかったことです．
【クレーム】使い方の説明をおいて頂きたいです．
本論文で提案する教師データ自動生成手法は，評価表現の情報に基づくラベル付けステップと，ある文の文脈に対する文脈一貫性の情報に基づくラベル付けステップの2ステップで構成される．
各ステップをそれぞれ核文ラベル付けおよび近接文ラベル付けと呼ぶことにし，以下で順に説明する．
核文ラベル付けは，評価表現の情報に基いて行う．
評価表現とは，「おいしい」や「まずい」等，評価対象に対する評価を明示的にあらわす言語表現のことである．
一般的には，これら表現に「おいしい／肯定」や「まずい／否定」のような肯定・否定の評価極性値を付随させたものを集めて評価表現辞書と呼ばれている[CITE]．
核文ラベル付けステップでは，評価表現辞書に否定極性として登録されている評価表現に着目し，このような評価表現を含む文はクレームを表しやすいと仮定する．
そして，否定極性の評価表現を含む文をクレーム文としてラベル付けする．
以降，この手続きで得られる文を次ステップで得られる文と区別するため核文と呼び，特に，核文がクレーム文である場合はクレーム核文と呼ぶ．
例えば，「まずい／否定」という単語が評価表現辞書に登録されている場合，次の例文はクレーム核文としてラベル付けされる．
【クレーム（核）】朝食のカレーがまずい．
もし，ある文が肯定極性をもつ評価表現を含み，かつ「ない」や「にくい」などの否定辞が評価表現の3単語以内に後続していた場合もクレーム核文としてラベル付けする．
例えば，次の例文は「おいしい／肯定」の直後に否定辞「ない」が後続しているため，クレーム核文としてラベル付けされる．
【クレーム（核）】朝食のカレーがおいしく\unc{ない}．
また，評価表現の否定極性と肯定極性を読み替えて上記と同様の手続きを行った場合に得られる文を非クレーム核文と呼び，クレーム核文と同じようにラベル付けしておく．
【非クレーム（核）】朝食のカレーがおいしい．
【非クレーム（核）】ハヤシライスは別にまずくは\unc{ない}．
さらに，「ほしい」等の要求表現を集めた要求表現辞書が利用できる場合は，次の例のように要求表現を含む文をクレーム核文としてラベル付けする．
ただし，要求表現に注目したラベル付けの場合は，評価表現の時とは違って，否定辞の有無に関係なくクレーム核文としてラベル付けする．
【クレーム（核）】朝食に和食メニューをもっと増やしてほしい．
【クレーム（核）】朝食を洋風なものばかりにしてほしく\unc{ない}．
以降，クレーム核文と非クレーム核文をあわせた文の集合を[MATH]であらわす．
那須川ら[CITE]は，彼らの論文の中で，評価表現の（文をまたいだ）周辺文脈には以下のような傾向があると述べており，これを評価表現の文脈一貫性と呼んだ．
{文書中に評価表現が存在すると，その周囲に評価表現の連続する文脈（以降，評価文脈）が形成されることが多く，その中では，明示されない限り，好不評の極性が一致する傾向がある．
}
本研究では，この評価表現の文脈一貫性の考え方に基いて近接文ラベル付けを行う．
先の核文ラベル付けの際に考慮した評価表現（あるいは要求表現）を含む文の周辺文脈について，「評価表現（要求表現）の存在に基づいて（非）クレーム文として選ばれた文の前後文脈に位置する文は，やはり（非）クレーム文である」という仮定をおき，この仮定に従って，核文の周辺文脈に対してラベル付けを行う．
この手続きで得られる文を近接文（より詳細にはクレーム近接文あるいは非クレーム近接文）と呼ぶ．
[b]
近接文ラベル付けの手続きを\algo{alg1}に示す．
この手続きへの入力は，核文ラベル付けを終えたレビュー[MATH]と，核文に対する周辺文脈の長さを決定する窓枠長[MATH] ([MATH])であり，レビュー[MATH]に含まれる核文に対して，レビューの先頭側に現れる核文から末尾側に現れる核文に向かって順に処理が進む．
なお，\algo{alg1}において，[MATH]はレビュー[MATH]内の先頭から[MATH]番目の文をあらわし，[MATH]は[MATH]内の文数をあらわす．
処理の大きな流れとしては，line.2--9でラベル付けされる文が選択され，line.10--16でラベル付けが実施される．
line.17--34の各関数では，付与するラベルの種類（``クレーム''か``非クレーム''）を確定する際に必要な仮のラベル情報が決められ，その情報が格納される．
\fig{context}を使って近接文ラベル付けの具体的な実行例を示す．
図の例では，対象となるレビューは8つの文から構成されており，核文ラベル付けによって文[MATH]が非クレーム核文，文[MATH]がクレーム核文とラベル付けされた状態であり，この状態から近接文ラベル付けが開始される．
窓枠長は[MATH]とする．
この場合，まず，核文[MATH]の周辺文脈に対する処理がなされる（\algo{alg1}のline.3）．
[MATH]は文書の先頭文であり前方文脈(Backward context)は存在しない．
そのため，後方文脈(Forward context)の[MATH]と[MATH]に対してのみ処理がなされ(line.6--7)，それぞれ``非クレーム''ラベルが配列に格納される(line.29)．
次に核文[MATH]の周辺文脈に対する処理がなされる．
[MATH]はクレーム文であるため，前方文脈では[MATH]に対して2つ目のラベル``クレーム''が格納され(line.19)，また新たに[MATH]に対して``クレーム''ラベルが格納される(line.19)．
後方文脈では，まず[MATH]に対して``クレーム''ラベルが配列に格納される(line.28)．
その一方で，[MATH]は逆接関係の接続詞「しかし」の影響があるため，``クレーム''ではなく``非クレーム''ラベルが格納される(line.31)．
最後に，各文に対して格納されたラベル情報をチェックし，格納されたラベルに不整合がない場合は，そのラベル情報に従ってラベル付けを行う(line.10--16)．
不整合が生じている場合はその文に対してどのラベルも付与しない．
以上の操作によって，この例では2つの核文から新たに4つの近接文（[MATH]，[MATH]，[MATH]および[MATH]）が得られる．
以降，クレーム近接文と非クレーム近接文をあわせた文の集合を[MATH]であらわす，また，必要に応じて，核文の前方文脈から得られた近接文[MATH]と，後方文脈から得られた近接文[MATH]を区別する([MATH])．
前節で述べた手法によって自動生成された教師データは，人手によって作成された教師データと比べて質が劣化せざるを得ず，標準的な分類モデルをそのまま適用するだけでは期待した精度は得られない．
そこで，前節で述べた手法で得られる劣化を含むデータを使用するという前提をおき，この劣化データがもつ特性を踏まえてナイーブベイズ・モデルを拡張することを考える．
以下では，まず，通常のナイーブベイズ・モデル（多項モデル）について述べ，その後，モデルの拡張について述べる．
ナイーブベイズ分類器では，ある文[MATH]の分類クラスを判定する際に，条件付き確率[MATH]を考え，この確率値が最大となるクラス[MATH]を分類結果として出力する．
つまり，
である．
通常のナイーブベイズ・モデルでは上式を次のように展開する．
\argmax _{c}P(c|s) &= \argmax _{c}P(c)P(s|c)\nonumber
& = \argmax_{c} \bigp_{c}+\sum_{w\in{V}}^{}n_{w}(s)\log q_{w,c} \big
ここで，[MATH]は語彙集合，[MATH]は文[MATH]における単語[MATH]の出現回数をあらわす．
また，[MATH]，[MATH]は教師データを使ってそれぞれ以下の式で計算される．
本研究ではパラメータを推定する際にラプラススムージング[CITE]を用いる．
q_{w,c}&= \fracn_{w,c}(\mathcal{D})+1\sum_{w}^{}n_{w,c}(\mathcal{D})+|\mathcal{V}|
p_{c} &= \fracn_{c}(\mathcal{D})+1\sum_{c}^{}n_{c}(\mathcal{D})+|\mathcal{C}|
ここで，[MATH]は教師データとなる文の集合，[MATH]はデータ[MATH]においてクラス[MATH]に属する文に現れる[MATH]の出現回数，[MATH]はデータ[MATH]においてクラス[MATH]に属する文の数，[MATH]は語彙の種類数，[MATH]は分類クラスの種類数である．
以上からもわかるように，通常のモデルでは，分類対象となる文内の情報のみを考慮し，分類対象文の周辺文脈の様子は全く考慮されない．
たとえ同一文書内であっても個々の文は独立に評価・分類する．
また，教師データの利用にあたっても，当然のことながら，核文であるか近接文であるかといった区別はなく，両タイプの文が同等にモデルの構築に利用される．
前節で述べた教師データ生成過程から得られるデータには，核文および近接文という2種類の文が存在する．
この2種類の文のうち，核文は近接文とは独立にラベル付けされる一方で，近接文は核文の情報に基いて間接的にラベル付けされる．
そのため，核文ラベル付けが結果として誤りであった事例に関しては近接文もその誤りの影響を直接受けることになる．
また，当然ながら，文脈一貫性の仮定が成立しない事例もあり得る．
このような理由から，近接文は核文に比べて相対的に信頼性の低いデータとなる可能性が高い．
そこで，このことを考慮し，核文と近接文の情報をモデル内で区別して扱い，近接文の情報がモデル内で与える影響を下げるよう，\eq{eq1}の代わりに次のような\eq{eqex}を用いる．
\argmax _{c}P(c|s) &= \argmax _{c}P(c)P(s|c) \nonumber
&= \argmax_{c} \big{\log p_{c}+\sum_{w}n_{w}(s)\log q^{tgt}_{w,c} \nonumber
& \phantom{= \argmax_{c} \bigp_{c} + \frac{1}{|ctx(s,N)|}\sum_{w}n_{w}(ctx(s,N))\log q^{ctx}_{w,c} \big}
右辺第3項に現れる[MATH]は[MATH]の周辺文脈に位置する前方および後方のそれぞれ[MATH]文から構成される文の集合を表しており，この項が分類対象の周辺文脈をモデル化している．
この項の係数[MATH]で，周辺文脈の文数に応じてその影響を調整している．
なお，[MATH]は，集合[MATH]の要素となる全ての文における単語[MATH]の総出現回数をあらわす．
また，右辺第2項は通常のモデルと同様に分類対象となる文をモデル化したものであるが，第3項の周辺文脈との区別を明瞭にするため，[MATH]という記号を新たに導入した．
\eq{eqex}の[MATH]と[MATH]，および[MATH]はそれぞれ次式で求める．
式中の各記号の意味は\eq{eq2}，\eq{eq3}と同様である．
ここで，[MATH]は分類対象文をモデル化するための教師データ集合，[MATH]は分類対象の周辺文脈をモデル化するための教師データ集合である．
基本的には，前節で得られる教師データのうち，核文データを[MATH]に割り当て，近接文データを[MATH]に割り当てるが，正確な記述は後述の\sec{wariate}で与える．
q^{tgt}_{w,c} & = \fracn_{w,c}(\mathcal{D}_{tgt})+1\sum_{w}n_{w,c}(\mathcal{D}_{tgt})+|\mathcal{V}_{tgt}|
q^{ctx}_{w,c} & = \fracn_{w,c}(\mathcal{D}_{ctx})+1\sum_{w}n_{w,c}(\mathcal{D}_{ctx})+|\mathcal{V}_{ctx}|
p_{c} & = \fracn_{c}(\mathcal{D}_{tgt})+1\sum_{c}n_{c}(\mathcal{D}_{tgt})+|\mathcal{C}|
以降，便宜的にこの拡張されたモデルをNB+ctxと呼ぶ．
さらに，\eq{eqex}の第3項について，周辺文脈を分類対象文からの相対位置で詳細化した
を代わりに利用するモデルも考えられる．
ここで，[MATH]は，[MATH]の前方文脈に位置する[MATH]文から構成される文の集合であり，[MATH]は同様に後方文脈で構成される文集合である．
また，式中の[MATH]および[MATH]は次式で求める．
ただし，[MATH]である．
q^{Bctx}_{w,c} & = \fracn_{w,c}(\mathcal{D}^{B}_{ctx})+1\sum_{w}n_{w,c}(\mathcal{D}^{B}_{ctx})+|\mathcal{V}_{Bctx}|
q^{Fctx}_{w,c} & = \fracn_{w,c}(\mathcal{D}^{F}_{ctx})+1\sum_{w}n_{w,c}(\mathcal{D}^{F}_{ctx})+|\mathcal{V}_{Fctx}|
以降，便宜的にこのモデルをNB+ctxBFと呼ぶ．
ここでは，さきほどの説明で保留していた，パラメータ推定の際に必要となる教師データの与え方について述べる．
ここで，前節で述べた手法によって得られるデータ集合を確認すると，
[MATH]：クレーム核文と非クレーム核文をあわせた文の集合
[MATH]：クレーム近接文と非クレーム近接文をあわせた文の集合
[MATH]：[MATH]の要素のうち，核文の前方文脈から得られた文で構成される集合
[MATH]：[MATH]の要素のうち，核文の後方文脈から得られた文で構成される集合
であり，[MATH]であった．
これらデータ集合に対して，まず，核文と近接文を区別しない単純な割当として，得られた全データをまとめて利用することが考えられる．
この場合，拡張モデルNB+ctxにおいての割当は，
[MATH]
[MATH]
となる．
これを以降NB+ctx(all)と呼ぶ．
また同様に，拡張モデルNB+ctxBFにおいての単純な割当は，
[MATH]
[MATH]
[MATH]
となるが，これは先のNB+ctx(all)と事実上同等となるため以降の議論では割愛する．
次に，核文と近接文の区別を考慮したデータ割当を考える．
拡張モデルNB+ctxにおいての割当としては，
[MATH]
[MATH]
が考えられる．
これを以降NB+ctx(divide)と呼ぶ．
また同様に，拡張モデルNB+ctxBFにおいてのデータ割当として，
[MATH]
[MATH]
[MATH]
が考えられる．
これを以降NB+BFctx(divide)と呼ぶ．
最後に，通常のナイーブベイズについて考えると，この場合は，もともとのモデルにデータを区別する枠組みが存在しないため，
[MATH]
という割当のみを考えることになる．
なお，[MATH]という核文のみを考慮し，近接文を利用しない割当も考えられるが，これは[MATH]において近接文の窓枠長を[MATH]とする場合に等しいため，割当規則として明示的には議論しないが，第\sec{exp}の評価実験では，近接文の窓枠長が[MATH]の場合も含めて議論する．
以降，これをNBと呼ぶ．
ここまでの議論を整理すると，前節の手法で自動生成された教師データを利用するという前提のもとで，通常のナイーブベイズ・モデルも含めて，4つのクレーム文検出モデルが与えられたことになる．
次節では，評価実験を通じて，これらの有効性を検証していく．
