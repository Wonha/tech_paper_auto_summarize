\section{実験と考察}
\subsection{実験環境，設定}
実験には以下の 2種類のタグ付きデータを用いた．
\begin{itemize}
 \item base NP 標準データセット ({\bf baseNP})\\
       Penn Tree-bank/WSJ の 15-18を学習データ，00-14，19-24 をテストデータとし，
       Brill Tagger\cite{Brill95}を用いて part-of-speech 
       (POS) を付与したデータである．テストデータのサイズ以外は，
       base NP 抽出に用いられるデータとして一般的なものである
 ．
 \item Chunking データセット ({\bf chunking})\\
        base NP 標準データセットと基本的に同一であるが，base NP 以外に 
       {\small VP, PP, ADJP, ADVP, CONJP, INITJ, LST, PRT, SBAR} の合計 10種類の英語の句を
       表現するタグが付与されている．テストデータのサイズを除けば，
       CoNLL-2000 Shead Task\cite{Tjong_Kim_Sang2000c} と同一のデータで
       ある．
\end{itemize}

それぞれのデータのサイズを表\ref{fg:env}に示す．

\begin{table}
\begin{center}
\begin{tabular}{r|r|r|r}
\hline
\hline
         & トークン(単語)数 & chunk数 & 文数 \\
\hline
baseNP 学習データ     & 211,727 &  53,371    &  8,936 \\
baseNP テストデータ   & 962,039 &   248,656  &  40,272 \\
chunking 学習データ   & 211,727  &  104,893   &  8,936 \\
chunking テストデータ & 962,039 &  483,301  &  40,272 \\
\end{tabular}
\end{center}
\caption{実験データ}
\label{fg:env}
\end{table}

実験には SVM 学習パッケージ {\it Tiny}SVM を用いた
\footnote{http://cl.aist-nara.ac.jp/\~\,taku-ku/software/TinySVM/ から入手可能}．
このツールは，本実験のようなバイナリの素性表現に特化して高速化が施されて
おり，VC bound を自動的に推定する機能を持っている．
また，すべての実験において，Kernel 関数は 2次の 多項式 Kernel を使用した．

評価方法としては，適合率と再現率の調和平均で与えられる F 値($\beta = 1$)
を用いた．これは chunk 同定において一般的に用いられる評価方法である．
以後，特にことわらない限りF値のことを精度と呼ぶ．

\subsection{実験結果}
表\ref{fg:ind}に，各 chunk の表現方法，および解析方向が異なる
計8種のモデルで独立に学習した実験結果(テストデータに対する精度，
推定された重み)をまとめた．また，比較対象として，Start/End 法を
用いた学習結果についても示している．

さらに，表\ref{fg:voting}に，これらを 均一重み，\,\, 交差検定 ($N=5$)，
\,\, VC bound，\,\,
Leave on Out bound の 4種類の重み付けで多数決を行った際の結果をまと
めた． 表\ref{fg:best}には，各の重み付け手法の中の最良の結果について，
その適合率と再現率を示す．

\begin{table}
\begin{center}
\begin{tabular}{@{}c@{ }@{}c@{ }|p{2.4zw}|ccc@{}}
\hline
\hline
\multicolumn{2}{c|}{学習条件} & \multicolumn{1}{c|}{精度} & \multicolumn{3}{c}{推定された重み}\\
 学習データ &  変換先 & $F_{\beta = 1}$ & 交差検定 & VC bound & L-O-O bound\\
\hline
 baseNP  &  IOB1-前 & 94.04 & .9394  & .4310 & .9193 \\
                   &  IOB1-後 & 94.08 & .9422  & .4351 & .9184 \\
                   &  IOB2-前 & 94.13 & .9410  & .4415 & .9172 \\
                   &  IOB2-後 & 94.13 & .9407  & .4300 & .9166 \\
                   &  IOE1-前 & 93.91 & .9386  & .4274 & .9183 \\
                   &  IOE1-後 & 94.14 & .9425  & .4400 & .{\bf 9217} \\
                   &  IOE2-前 & 94.09 & .9409  & .4350 & .9180 \\
                   &  IOE2-後 & {\bf 94.23} & {\bf .9426} & {\bf .4510} & .9193 \\
\hline
 chunking  &  IOB1-前 & 93.56 & .9342 & .6585 & .9605 \\
                   &  IOB1-後 & 93.58 & .9346 & .6614 & .9596 \\
                   &  IOB2-前 & 93.54 & .9341 & .6809 & .9586 \\
                   &  IOB2-後 & 93.52 & .9355 & .6722 & .9594 \\
                   &  IOE1-前 & 93.46 & .9335 & .6533 & .9589 \\
                   &  IOE1-後 & {\bf 93.65} & .9358 & .6669 & .9611 \\
                   &  IOE2-前 & 93.50 & .9341 & .6740 & {\bf .9606} \\
                   &  IOE2-後 & {\bf 93.65} & {\bf .9361} & {\bf .6913} & .9597 \\
\hline
\hline
 baseNP    &  IOBES-前 & 93.93 &  &  &  \\
           &  IOBES-後 & 93.94 &  &  &  \\
\hline
 chunking  &  IOBES-前 & 93.36 &  &  &  \\
           &  IOBES-後 & 93.41 &  &  &  \\
\end{tabular}
\end{center}
\caption{個々のモデルの精度比較}
\label{fg:ind}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{@{}c@{ }c|ccccc@{}}
\hline
\hline
\multicolumn{2}{c|}{学習条件} & \multicolumn{4}{c}{各重み付けに対する精度 $F_{\beta = 1}$} \\
 学習データ &  評価手法 & 均一重み & 交差検定 & VC bound & L-O-O bound \\
\hline
 baseNP &  IOB1 & 94.31 & 94.37 & 94.39 & 94.36      \\
        &  IOB2 & 94.33 & 94.39 & {\bf 94.41} & 94.38 \\
        &  IOE1 & 94.32 & 94.38 & 94.38 & 94.36 \\
        &  IOE2 & 94.33 & 94.38 & 94.40 & 94.38 \\
\hline
 chunking &  IOB1 & 93.78 & 93.81 & 93.81 & 93.81 \\
          &  IOB2 & 93.74 & {\bf 93.84} & {\bf 93.84} & {\bf 93.84} \\
          &  IOE1 & 93.79 & 93.81 & 93.81 & 93.81 \\
          &  IOE2 & 93.81 & 93.82 & 93.83 & 93.82 \\
\end{tabular}
\end{center}
\caption{重み付き多数決の結果}
\label{fg:voting}
\end{table}

\begin{table}
\begin{center}
 \begin{tabular}{c|ccc}
\hline
\hline
  データセット & 適合率 & 再現率 & $F_{\beta = 1}$ \\
\hline
baseNP & 94.48\% & 94.34\% & 94.41\\
chunking & 93.85\% & 93.83\% & 93.84\\
 \end{tabular}
\end{center}
\caption{各データセットに対する最良結果}
\label{fg:best}
\end{table}

 \subsection{Chunkの表現方法と解析精度}
表\ref{fg:ind}から，Inside/Outside に基づく 8 つの手法を比較すると，
「IOE2 + 後ろ向き」が最良の精度を，「IOE1 + 前向き」が最低の精度を示すことが分かる
\footnote{chunking データセット の 「IOE1 + 後ろ向き」 以外は，「IOE2 + 後ろ向き」 の結果が 10\% の棄却率で
有意であることが確認された．}．
これは，以下に述べる我々の直観と合致する．

\begin{itemize}
 \item 多くの場合，chunk中の主辞は末尾の単語となる．
       すなわち，後ろ向きからから解析すると，主辞を最初に決定できるため優位となる．\\
       $\rightarrow$        (後ろ向き $>$ 前向き)
 \item IOE は，主辞となりやすいchunkの末尾に特化した学習が行われる
       ため，先頭に特化する IOB に比べ優位となる．\\ $\rightarrow$ (IOE $>$ IOB)
 \item IOB は，chunkの先頭を，IOE は，chunkの末尾に特化して学習が
       行われる．そのため，IOB は，前向き，IOE は後ろ向きから解析すると
       特化して学習される単語が先に推定されるため，優位となる．\\
 $\rightarrow$ 
       (IOB + 前向き $>$ IOB + 後ろ向き，IOE 前向き $<$ IOE 後ろ向き)
 \item 同一のchunkが連続することは稀である．すなわち，chunkの連続
       に特化する IOB1/IOE1 は，chunkの先頭/末尾に特化する IOB2/IOE2 に比べ劣る．
       \\ $\rightarrow$  (\{IOB1 IOE1\} $<$ \{IOB2 IOE2\})
 \item 同一chunkが連続する場合は，前のchunkの末尾の単語 (主辞)よりは
       むしろ，後続するchunkの先頭の単語が境界の認定に役割を果たす場合が多い．
       そのため，chunkが連続する場合は，chunkの先頭に特化する IOB1 が
       IOE1 に比べ優位となる．\\ $\rightarrow$  (IOB1 $>$ IOE1 )
\end{itemize}

次に Inside/Outside 法(IOB1/IOB2/IOE1/IOE2 の各手法)と Start/End 法の精
度を比較する．颯々野らは，各学習アルゴリズムの特徴を考察しなが
ら，決定リストについては細かい組み合せを考慮する Start/End 法が，
最大エントロピー方についてはより粗い情報を考慮する
Inside/Outside 法が精度が良いと報告している\cite{Sassano00b}．
SVM を用いた本手法では，全体的に Inside/Outside 法の法が，Start/End に比べ高い精度を示している．
SVM は，決定リストのように単独の素性(ルール)で分類するのではなく，最大エントロピーと同じ
く複数の素性の線型結合で分類するために，この結果は，颯々野らの分析と合致する．

さらに，別の要因として以下が考えられる．まず，Start/Endは，5種類のタグを使い
表現するため，Inside/Outside と比較して，データスパースネス
の問題を助長してしまう恐れがある．また，5種類のタグを使うことで，矛盾のある
タグのシーケンスの数が増えてしまう．具体的には，S→E，I→B，
O →I といったタグの連続は，タグ付けとしては不適切である．
一方，IOB1 は， O→B のみ，IOB2 は O→I のみが不適切な連続である．
タグ付けに関する指針，制約といった「タグ付けスキーマ」は，それらを明示的な形で与えない本手法では，
システム自身がデータから学習する必要があり，それだけ余計なコストが生じて
しまう．つまり，矛盾のあるタグ列が少ない表現方法が優位であると考える．

\subsection{モデル選択能力}
重み付き多数決を行う際の重みは，各システムの未知データに対する
精度の予測値であるため，これらの大小を比較することでモデル選択が行える．

表\ref{fg:ind}から，VC bound，交差検定，それぞれが「IOE2 + 後ろ向き」に対し最高の重みを，
「IOE1 + 前向き」に最低の重みを算出しており，テストデータに対する精度をうまく予想してる．
これらの結果から，VC bound，交差検定がモデル選択基準として良好に機能していることが分かる．

交差検定はモデル選択に用いられる一般的な手法であるが，分割数が多くなると
推定に多くの計算量を必要とする．その一方で，VC bound は学習と同時にモデル選択
が行え，交差検定に比べ効率的であると考える．

Leave-One-Out bound は 他に比べ計算コストの小さいモデル選択手法であるが，
その能力は VC bound や 交差検定よりも劣ることが分かった．

\subsection{多数決の効果}
表\ref{fg:voting}から，多数決を行うことで，重みの付与方法によらず，
単独のどのモデルよりも精度が向上することが確認できる
\footnote{棄却率 10\%以下で有意差があると判定された}．

重み付き多数決の手法間の精度差には，多くの場合，顕著な差は見られなかった．
特に VC bound，交差検定，Leave-One-Out bound は，ほぼ同等の精度となった．
しかし，均一重みと比較して，上記の3つ手法で重みを推定するほうが，
若干ながら優位であることが分かる．

\subsection{関連研究との比較}
\subsubsection{baseNP データセット}
Tjong Kim Sang らは，弱学習アルゴリズムに MBL，ME，IGTree 等の7種類のアル
ゴリズム，さらにIOB1/IOB2/IOE1/IOE2の4種類の表現を用いて独立に学
習した複数のモデルの重み付き多数決を行うことで，baseNP データセット
に対し 93.86の精度が得られたと報告している
\cite{Tjong_Kim_Sang2000a,Tjong_Kim_Sang2000b}．

我々は単独の表現を用いた場合でも 93.91 - 94.23 の精度を得ている．
テストデータが異なるため，厳密な比較は行えないが，SVM 単独の結果は，従来手法と同等だと考える．
一方，従来手法は7種類の学習アルゴリズム，及び4つの chunk表現の異なるシステムの
多数決の結果であり，個々の学習器の学習，及びテストの計算量は，
SVM 単独のシステムに比べ大きい．システムの複雑さという観点から見れば，
SVM 単独のシステムは，従来手法に比べ優位であると考える．

さらに，従来手法と同様に，各表現の重み付き多数決を行うことで 94.40 の精度を得ることができた．
これは，従来法の精度 93.86 に比べ優れていると考える．
多数決を実行することは，全体としてシステムが複雑になることが一つの問題点である．
Tjong Kim Sang らによる手法は，MBL，ME，IGTree といった，7種類のアルゴリズムを用い
ており，全体として複雑になっている．さらに，個々の学習器のパラメータは恣意的に設定されており，
これらの最適なパラメータを考慮すると，設定すべきパラメータの数が多く，
制御が困難であると考える． 一方，本手法は，単一の SVM のみを用い，それ以外の学習アルゴリズムを用いていない．
重み付き多数決を行うという観点から見れば，本手法は，従来手法に比べシステム全体の設計が，
簡潔であり，設定すべきパラメータ数が少ない．この点も，本手法の優位な点と考える．

\subsubsection{CoNLL データセット}
CoNLL-2000 Shared Task において我々は SVM と IOB2 と 前向き解析 
の単独システム用いて 93.48 の精度を報告している \cite{kudo2000a}
 \footnote{テストデータが異なるため精度に若干差が出ている．}．
本実験結果から，多数決を行うことで，「IOB2 + 前向き」 に限らず，どの単独システム
に比べても精度が向上している．また CoNLL-2000 で報告された重み付き多数決に
基づく他の手法\cite{Tjong_Kim_Sang2000d} よりも高い精度を示すことができた．

\subsection{今後の課題}
\begin{itemize}
 \item 他の分野への応用\\
       我々の提案する手法は，日本語の文節まとめ上げや固有名詞，専門用語抽
       出と一般的な chunk 同定問題に応用可能である．我々の提案する
       手法がこれらの他の分野でも有効であるか実際に検証を行う予定である．

 \item 可変長モデル\\
       本稿では，左右2つの文脈のみを考慮する単純な固定長モデル
       を採用した．しかし実際には，個々のchunk を同定に必要な文脈長は
       可変であり，個々の chunk に対し最適な文脈長を選択することで
       さらなる精度向上が期待できる．颯々野らは日本語の固有名詞抽出におい
       て可変長モデルを提案し単純な固定長のモデルより高い精度が得られた
       と報告している\cite{Sassano00b}．今後 このような可変長
       のモデルを取りいれたいと考えている．
       
 \item より予測能力の高い bound の採用\\
       本稿では，重み付き多数決の重みとして，SVM に固有の概念 --- VC
       bound，Leave-One-Out bound を提案した．その一方で Chapelle らは，
       これらより予測能力の高い bound を提案し，Kernel 関数の選択や 
       Soft Margin パラメータの選択に極めて有効であるとこを示している\cite{ChaVap00}．
       これらの予測能力の高い bound を重みとして採用することでさらなる
       精度向上が期待できる．
\end{itemize}

