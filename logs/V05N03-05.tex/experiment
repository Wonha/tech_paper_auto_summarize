\section{評価実験}
\label{sec:exp-stat}

本節では，
前節で提案した統合的確率言語モデルの評価実験について述べる．
統合的確率言語モデルは本来形態素解析，構文解析を
同時に行うことを前提としているが，
そのような大規模な実験を行う前の予備実験として，
まずは文節列を入力とする文節間の係り受け解析のみを行った．
\subsection{構文モデルの学習}
\label{sec:learn-syn-model}

本節の実験では，入力として単語列，品詞列，文節区切りが
与えられたときに，それぞれの文節の係り先となる文節を決定する．
このような文節の係り受け解析をCFG(文脈自由文法)を用いて行った．

まず，CFG規則の終端記号として，
文節の統語的特性を反映した文節ラベルを用いる．
この文節ラベルの定義を(\ref{eq:BP-label})に示す．
\begin{equation}
  \label{eq:BP-label}
  文節ラベル ~~\stackrel{def}{=}~~
  (受け属性,係り属性,読点の有無,用言種別)
\end{equation}
ここで，``受け属性''，``係り属性''は
それぞれ文節の受け属性と係り属性であり，
``連用''，``連体''，``格関係''の組によって表わされる．
例えば，``パイ-を''や``彼女-の''など，
「名詞 助詞」といった品詞並びによって構成される文節は，
他の文節から連体修飾を受ける可能性があるので受け属性は``(連体)''となり，
他の文節を連体修飾したり用言を修飾してその格要素および表層格を表わす
可能性があるので係り属性は``(連用,格関係)''となる\footnote{
  ここでの``格関係''とは，用言を受け側とした格関係のみを指す．
  }．
また``読点の有無''は，その文節の末尾が読点であれば``1''，
そうでなければ``0''といった値を取る．
これは，読点を末尾に持つ文節は直後の文節には係りにくく，
読点を末尾に持たない文節よりも遠くに係る傾向があるので，
この違いを構文モデルに反映させるためである．
一方``用言種別''は，
``格関係''を受け属性に含む文節タイプを細分化するための属性であり，
文節の主辞が自動詞，他動詞，形容詞，名詞述語のときには
それぞれ``自動詞''，``他動詞''，``形容詞''，``名詞述語''
といった値を取る．
また，``格関係''を受け属性に持たない文節のときには
その値は常に``φ''である．
\ref{sec:lex-model} 節で例示した単語生成文脈決定規則は，
単語の共起関係の中でも特に用言の格関係に注目している．
用言を主辞とする文節の文節ラベルを細分化したのはこのためである．
この文節ラベルは，文節を構成する単語列の品詞情報をもとに
一意に決定されるものとする．
また，これらの文節ラベルの整合性\footnote{
  例えば，``連体''を係り属性に含む文節は
  ``連体''を受け属性に含まない文節には係らない．
  }をチェックする規則を作成し，
その集合を文節の係り受け解析に用いるCFGとした．
このCFGの概要を表\ref{tab:grammar} に示す．
\begin{table}[htbp]
  \begin{center}
    \caption{CFGの概要}
    \label{tab:grammar}

    \begin{tabular}{|l|r|}  \hline
      規則数       & 961 \\ \hline
      非終端記号数 &  51 \\ \hline
      終端記号数(文節ラベル数) &  42 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

本実験では，構文モデル$P(R)$ としてPGLRを利用した．
また，この構文モデルの学習には
京大コーパス\cite{kurohasi:97:a} を使用した．
京大コーパスの各例文には，単語区切り，単語の品詞，
文節区切りと文節の係り受け解析の結果(構文構造)が付加されている．
京大コーパスの9,944例文に対して，
コーパスの各例文とそれに付加された構文構造を作り出すような
LR表における状態遷移列を求め，また状態遷移が行われた回数を数え上げる．
このようにして得られた状態遷移回数を状態遷移確率に
変換することにより，PGLRのパラメタ推定を行った．
\subsection{語彙モデルの学習}
\label{sec:learn-lex-model}

本実験では，式(\ref{eq:lex-model-der-dp})に示した語彙モデル
$P(W|R)=P_{cf}(W|L) \cdot D(W|R)$ のうち，
$P_{cf}(W|L)$ の計算を省略できる．
なぜなら，
単語列及び品詞列はすでに入力として与えられているため，
全ての解析結果の候補について品詞から単語への生成確率の積
$P_{cf} (W|L)$ は等しいからである．
したがって，語彙モデルとして学習するのは
従属係数の積$D(W|R)$ のみでよい．
今回の実験では，
\lcrule{lc:filler}〜\#\ref{lc:josi} によって
定められる従属係数(\ref{eq:ldp-filler}),
(\ref{eq:ldp-marker-multi2}),(\ref{eq:ldp-josi})を
$D(W|R)$ の要素とし，これらの学習を行った．

まず，格要素の従属係数(\ref{eq:ldp-filler})の学習について説明する．
\begin{equation}
  \label{eq:ldp-filler}
  D(n | N[\slot{v}{p}]) = \frac{P(n|N[\slot{v}{p}])}{P(n|N)}
\end{equation}
RWCコーパス~\cite{rwc:95:a} とEDR共起辞書\cite{edr:95:a} から，
名詞$n$ が助詞$p$ を介して動詞$v$ に係る事例
$(n,p,v)$ をそれぞれのべ6,888,849組，975,510組収集した．
式(\ref{eq:ldp-filler})の分子および分母の確率モデルは
これらの訓練事例から最尤推定した．

さらに，分子の確率モデル$P(n|N[\slot{v}{p}])$ を推定する際に
以下のような近似を行った．

\begin{itemize}
\item 名詞$n$ の意味クラスによる抽象化

  名詞$n$ の意味クラスの集合を
  $C_n = \{c_{n_1},\cdots,c_{n_m}\}$ として，
  $P(n | N[\slot{v}{p}])$ を以下のように推定した．
  \begin{equation}
    \label{eq:ldp-filler-class}
    P(n | N[\slot{v}{p}]) \simeq
    \sum_j P(n|c_{n_j}) P(c_{n_j} | N[\slot{v}{p}])
  \end{equation}

  今回の実験では，名詞意味クラス$c_n$ として，
  日本語語彙体系\cite{ikehara:93:a,ikehara:97:a} の
  名詞シソーラス
  のルートから深さ3に位置する
  151個の意味クラスの集合を用いた．
  これらの意味クラスは互いに排他的である．

  $D(n|N[\slot{v}{p}])$ を推定する場合，
  名詞$n$ が日本語語彙体系に登録されておらず，
  その名詞意味クラスが不明な場合には，
  その従属係数は学習不可能であるとして
  $D(n|N[\slot{v}{p}]) \simeq 1$ とした．
  これは，$n$ と$\slot{v}{p}$ との間の
  従属関係を無視することに相当する．


\item バックオフ方式によるスムージング

  確率モデル$P(c_n | N[\slot{v}{p}])$ を推定する際，
  この確率の分母となる事例$(*,p,v)$ 
  ($*$ は任意の名詞意味クラスを表わす)の出現回数が
  ある閾値 $\lambda$ よりも小さい場合には，
  $v$ を動詞意味クラス$c_v$ を用いて抽象化した
  確率モデル$P(c_n | N[\slot{c_v}{p}])$ によって近似した．
  \begin{equation}
    P(c_n|N[\slot{v}{p}]) \simeq P(c_n | N[\slot{c_v}{p}])
  \end{equation}
  また，事例$(*,p,c_v)$ の出現回数が $\lambda$ を越えない
  場合には，動詞意味クラス$c_v$ の抽象度を段階的に上げていき，
  必ず$\lambda$ 個以上の訓練事例から確率モデルを推定するようにした．

  本実験においては，動詞意味クラス$c_v$ として
  分類語彙表~\cite{bgh:96} の
  5桁および2桁の分類コードを動詞意味クラスとして利用した．
  動詞を分類語彙表の2桁の分類コードに抽象化しても
  学習事例数が $\lambda$ を越えなかったとき，
  もしくは$(*,p,v)$ の事例数が $\lambda$ 以下であり
  かつ動詞$v$ が分類語彙表に登録されていなかった場合には，
  十分信頼度の高い確率モデルが学習できなかったとして，
  従属係数$D(n|N[\slot{v}{p}]) \simeq 1$ とした．
  なお，今回は$\lambda=100$ として実験を行った．
\end{itemize}

\bigskip
次に，用言に係る助詞に関する従属係数(\ref{eq:ldp-marker})の
学習について説明する．
\begin{equation}
  \label{eq:ldp-marker}
  D(p_i | P[\head{h}{n}{\phi_1,\cdots,\phi_i,p_{i+1},\cdots,p_n}]) =
  \frac{P(p_i |
    P[\head{h}{n}{\phi_1,\cdots,\phi_i,p_{i+1},\cdots,p_n}])}
  {P(p_i | P)}
\end{equation}
$n$ 個の助詞$p_1,\cdots,p_n$ が同じ用言$h$ に係っている場合には，
それぞれの$p_i$ に対応する従属係数(\ref{eq:ldp-marker})の積を
計算すれば良い．
この従属係数の積は式(\ref{eq:ldp-marker-multi})のように変形できる．

\begin{eqnarray}
  &&
  \prod_i
  D(p_i | P[\head{h}{n}{\phi_1,\cdots,\phi_{i-1},p_i,\cdots,p_n}]) \\
  &=&
  \prod_i
  \frac{P(p_i |
    P[\head{h}{n}{\phi_1,\cdots,\phi_i,p_{i+1},\cdots,p_n}])}
  {P(p_i | P)} \\
  &=&
  \label{eq:ldp-marker-multi}
  \frac{P(p_1,\cdots,p_n |
    P_1,\cdots,P_n[\head{h}{n}{\phi_1,\cdots,\phi_n}])}
  {\prod_i P(p_i | P)} \\
  \label{eq:ldp-marker-multi2}
  &\stackrel{def}{=}&
  D(p_1,\cdots,p_n | P_1,\cdots,P_n[\head{h}{n}{\phi_1,\cdots,\phi_n}])
\end{eqnarray}
したがって，学習しなければならないのは，
ある用言$h$ が$P_1,\cdots,P_n$ の$n$ 個の助詞の係り先となっているときに
単語$p_1,\cdots,p_n$ を同時に生成する確率モデル
$P(p_1,\cdots,p_n | 
P_1,\cdots,P_n[\head{h}{n}{\phi_1,\cdots,\phi_n}])$ と，
品詞$P$(助詞)から単語$p_i$ が生成される確率$P(p_i|P)$ である．
以降，簡単のため，前者の確率モデルを以下のように記述する．
\begin{eqnarray}
  \label{eq:kaku-model-def}
  P(\vec{p} ~|~ h,n) 
  &\stackrel{def}{=}&
  P(p_1,\cdots,p_n | 
  P_1,\cdots,P_n[\head{h}{n}{\phi_1,\cdots,\phi_n}]) \\
  \nonumber
  && 但し，~\vec{p} = (p_1,\cdots,p_n) 
\end{eqnarray}

確率モデル$P(\vec{p} | h,n)$ を学習するために，
$n$ 個の助詞 $\vec{p}$ が同じ用言$h$ に係るという事例
$(\vec{p},h)$ をEDRコーパスから収集した．
今回の実験では，用言$h$ として動詞，形容詞，名詞述語の3つを考えた．
用言$h$ が動詞，形容詞，名詞述語であるときの，
また$h$ に係る助詞の数$n$ が1，2，3，4以上であるときの
事例$(\vec{p},h)$ ののべ数を表\ref{tab:coocr-ph} にまとめる．

\begin{table}[htbp]
  \begin{center}
    \caption{EDRコーパスから収集した事例$(\vec{p},h)$ ののべ数}
    \label{tab:coocr-ph}

    \begin{tabular}{|c||r|r|r|r|} \hline
      $h$      &
      \makebox[15mm]{$n=1$} & \makebox[15mm]{$n=2$} &
      \makebox[15mm]{$n=3$} & \makebox[15mm]{$n\ge 4$} \\ \hline\hline
      動詞     & 231,730 & 123,915 & 30,375 & 3,961 \\ \hline
      形容詞   &  19,266 &   7,686 &  1,292 &   154 \\ \hline
      名詞述語 &  28,636 &   9,327 &  1,238 &    98 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

$n$ が4以上のときには学習に十分な事例を収集することができなかった．
そこで，$n$ が4以上のときには，従属係数を1，
すなわち助詞とその係り先用言との語彙的従属関係や
格間の従属関係を無視することにした．
\begin{equation}
  n \ge 4 のとき \qquad 
  D(p_1,\cdots,p_n | P_1,\cdots,P_n[\head{h}{n}{\phi_1,\cdots,\phi_n}])
  ~\simeq~1
\end{equation}
$n=1$ のときの式(\ref{eq:kaku-model-def})の分子の
確率モデル$P(\vec{p}|h,n)$ は
表\ref{tab:coocr-ph} に示した事例から最尤推定した．
また，$n=2,3$ のときの確率モデル$P(\vec{p}|h,n)$ は
最大エントロピー法を用いて推定した\footnote{
  この詳細については\cite{sirai:97:b} を参照．
  }．

最後に，体言に係る助詞に関する従属係数(\ref{eq:ldp-josi})の
学習について説明する．
\begin{equation}
  \label{eq:ldp-josi}
  D(p | P[nd]) = \frac{P(p | P[nd])}{P(p|P)}
\end{equation}
この従属係数を学習するために，EDRコーパスから
体言に係る助詞$p$ をのべ273,062個収集した．
式(\ref{eq:ldp-josi})の分子はこの訓練データから最尤推定した．
また，式(\ref{eq:ldp-josi})の分母$P(p|P)$ は，
ここで収集した体言に係る助詞の事例と，
表\ref{tab:coocr-ph} に示した用言に係る助詞の事例から，
同様に最尤推定した．
尚，式(\ref{eq:ldp-marker-multi})の分母の各項$P(p_i|P)$ も
式(\ref{eq:ldp-josi})の分母の確率モデルと同じものを使用した．


\subsection{実験結果}
\label{sec:result-stat}

\ref{sec:learn-syn-model} 節にて学習した構文モデル$P(R)$，
および\ref{sec:learn-lex-model} 節にて学習した語彙モデル$P(W|R)$ 
を用いて，文節の係り受け解析を行った．
まず，テスト文として，京大コーパスの中から文節数7〜9の文を
ランダムに500文選び，これをテスト文とした．
構文モデル$P(R)$ を学習する際に用いた訓練用例文には
これらのテスト文は含まれていない．
文節数7〜9という比較的文長の短い例文をテスト文として選んだのは，
本実験で用いたPGLRパーザがまだ開発の途中であり，
長い文長の例文の解析に非常に多くの時間を要するためである．

テスト文の係り受け解析結果の評価尺度として，
文節の正解率を以下のように定義する．
\begin{equation}
  \label{eq:def-bp-acc}
  文節の正解率 ~=~
  \frac{係り先の正しい文節の数}{テスト文に含まれる文節の数}
\end{equation}
この文節の正解率は生成確率が一位である解析結果の候補について計算する．
また，文の最後に位置する2つの文節は評価の対象から除外する．
これは，文の一番最後にある文節は係り先がなく，
また文の最後から2番目にある文節は
常に文の一番最後の文節に係るからである．

\ref{sec:lex-model} 節に述べたように，
語彙モデルにおいてはいくつかの種類の統計情報を取り扱う．
ここでは，構文的な統計情報，
および語彙モデルにおいて考慮された語彙的な統計情報の
それぞれの曖昧性解消における効果を調べるために，
以下に述べる6種類のモデルを用意し，それらを比較した．
結果を表\ref{tab:res-lex} に示す．

\begin{description}
\item[BL:] ベースライン

  全ての文節の係り先を，
  (1)全ての文節は係り得る文節の中でできるだけ近いものに係る，
  (2)一文中における文節の係り受け関係は互いに交差しない，
  として決定するモデルである．

\item[Syn:] 従属係数を無視したモデル

  $D(W|R)=1$ としたモデルである．
  すなわち，構文モデル$P(R)$ で学習した統計情報のみを用いて
  曖昧性解消を行う．

\item[F:] 格要素となる名詞に関する従属係数のみを用いたモデル

  $D(W|R)$ として，式(\ref{eq:ldp-filler})によって
  与えられる従属係数のみを考慮したモデルである．



\item[M:] 用言に係る助詞に関する従属係数のみを用いたモデル

  $D(W|R)$ として，式(\ref{eq:ldp-marker-multi2})によって
  与えられる従属係数のみを考慮したモデルである．

\item[P:] 体言に係る助詞に関する従属係数のみを用いたモデル

  $D(W|R)$ として，式(\ref{eq:ldp-josi})によって
  与えられる従属係数のみを考慮したモデルである．


\item[all:] 全ての従属係数を用いたモデル

  上記全ての従属係数を考慮したモデルである．
\end{description}

\begin{table}[tbp]
  \begin{center}
    \caption{文節の正解率}
    \label{tab:res-lex}

    \begin{tabular}{|l||r|r|} \hline
      & \makebox[15mm]{後置詞節} &
        \makebox[15mm]{全ての文節} \\ \hline\hline
      BL     & 62.92\% & 61.68\% \\ \hline
      Syn    & 69.63\% & 73.38\% \\ \hline
      F      & 71.36\% & 74.69\% \\ \hline
      M      & 78.19\% & 78.55\% \\ \hline
      P      & 84.06\% & 82.22\% \\ \hline
      all    & 86.30\% & 84.34\% \\ \hline
    \end{tabular}
  \end{center}
\end{table}

表\ref{tab:res-lex} から，
語彙モデルにおいて考慮した語彙的な統計情報のうち，
体言に係る助詞に関する従属係数(モデルP)が正解率の向上に
一番大きく貢献することがわかる．
すなわち，助詞が用言に係っているか否かの違いが
その生成確率に大きく影響し，
その違いを考慮することによって
曖昧性解消の精度を大きく向上させることができた．
また，表\ref{tab:res-lex} における``後置詞節''とは，
``彼女-が''，``パイ-を''など，
用言の格要素および表層格を表わす可能性のある文節を指す\footnote{
  この後置詞節には，``太郎-の''など，
  実際には体言を修飾する文節も含まれる．
  }．
テスト文全体における2,975個の文節のうち，
1,788個がこの後置詞節に相当する．
この後置詞節のみで評価した場合，
全ての文節で評価した場合に比べて，
語彙的な統計情報を考慮したモデル(F,M,P,all)と
構文的な統計情報のみを考慮したモデル(Syn)との
文節の正解率の差が大きくなっている．
これは，今回の実験で用いた語彙モデルにおいては，
語彙的な統計情報の中でも用言の格関係に注目しているため，
語彙モデルが``後置詞節''の係り先の曖昧性解消に
特に有効に働いているためと考えられる．

構文モデルと全ての語彙的従属関係を考慮した語彙モデルを
組み合わせて曖昧性解消に用いた場合(all)，
構文モデルのみを用いた場合(Syn)と比べて
文節の正解率が10.96\%向上し，
また構文モデルのみを曖昧性解消に用いたときの
ベースラインとの文節の正解率の差が11.70\%であることから，
文節の係り受け解析の精度向上において，
語彙モデルは構文モデルと同程度の貢献をしていると考えられる．
本研究で提案した統合的確率言語モデルにおいては，
語彙的な統計情報を局所化し構文的な統計情報とは独立に学習しているが，
このようなアプローチにおいても，語彙的な統計情報は
曖昧性解消の精度向上に十分大きく貢献すると期待できる．

最後に，本研究で提案する統合的確率言語モデルを用いた解析結果と
KNPパーザ\cite{kurohasi:94:a} による解析結果との比較を行った．
KNPパーザは形態素解析システムJUMAN\cite{matumoto:94:a} の
形態素解析結果を入力とし，
文節の区切りを認定してから文節の係り受け解析を行う．
そこで，\ref{sec:result-stat} 節の実験で用いた
500個のテスト文のうち，
JUMANの形態素解析結果による形態素区切り
およびKNPパーザによる文節区切りの結果が
コーパスと一致した388文を対象に，
両者の係り受け解析結果の比較を行った．
結果を表\ref{tab:comp-knp} に示す．

\begin{table}[htbp]
  \begin{center}
    \caption{KNPパーザとの比較}
    \label{tab:comp-knp}

    \begin{tabular}{|l||r|r|} \hline
      & \makebox[15mm]{後置詞節} &
        \makebox[15mm]{全ての文節} \\ \hline\hline
      本手法    & 86.57\% & 84.53\% \\ \hline
      KNPパーザ & 86.79\% & 85.71\% \\ \hline
    \end{tabular}
  \end{center}
\end{table}

本手法はKNPパーザよりも文節の正解率で1\%程度劣っている．
今回の実験では，統合的確率言語モデルに組み込む語彙的従属関係として，
格要素と動詞との従属関係，助詞と係り先用言との従属関係，
格間の従属関係などを考慮した．
しかしながら，これ以外にも，
曖昧性解消に有効であると考えられる語彙的従属関係が数多く存在する．
特に，今回の実験では連体修飾に関しては語彙的従属関係を
何も考慮していないので，そのことによる解析誤りが多かった．
例えば，「彼女の紫色の帽子が風に飛ばされた」という文においては，
文節``彼女-の''が(a)``紫色-の''に係る，
(b)``帽子-が''に係るという2つの解釈がある．
ところが，連体修飾する``彼女''については
語彙的従属関係を考慮していないので，
より近い文節に係る解釈(a)に高い確率が与えられてしまう．
これを回避するためには，以下のような従属係数を学習し
語彙モデルに加えればよい．
\begin{equation}
  \label{eq:dp-rentai-noun}
  D(n_1 | N[n_2]) = \frac{P(n_1 | N[n_2])}{P(n_1 | N)}
\end{equation}
式(\ref{eq:dp-rentai-noun})の分子$P(n_1 | N[n_2])$ は，
ある名詞$N$ が$n_2$ を連体修飾しているとき，
その名詞として単語$n_1$ が生成される確率を表わしている．
このような従属係数を考慮することにより，
``彼女''は``紫色''よりも``帽子''を連体修飾することが多い，
すなわち$D(彼女 | N[紫色]) << D(彼女 | N[帽子])$ であると
考えられるので，正しい解釈(b)に高い確率を与えると期待できる．
このように，
統合的確率言語モデルに新たな種類の語彙的従属関係を反映させるときには，
それに対応した従属係数を新たに語彙モデルに加えるという形で
容易に対処できる．
これは，
語彙的従属関係を局所化して構文的優先度などの他の統計情報と
独立に学習するように，
また異なる種類の語彙的従属関係は
異なる従属係数として独立に学習するように
モデルを設計したことに依る．

一方，後置詞節のみで評価した場合には，
本手法とKNPパーザの文節の正解率はほぼ等しい．
とはいえ，後置詞節の係り先の特定に失敗する場合も少なくない．
我々は現在その原因を調査中であり，
その一部については既に報告している\cite{sirai:97:d}．
今後，曖昧性解消に有効な統計情報を新たに組み込んだり，
また解析誤りの原因を調査しそれらに対処することにより，
係り受け解析の精度向上を図っていきたい．
