
提案手法の説明の前に，ここで，評価視点という用語について整理しておく．
本論文における評価視点は，基本的には，Huら[CITE]や小林ら[CITE]の定義に従っている．
後述する評価実験では，評価対象が宿泊施設であるので，そのことを踏まえると，本論文における評価視点は，
宿泊施設に対する意見の焦点となる宿泊施設の構成物や属性，あるいは，宿泊施設への宿泊という経験から生じる宿泊施設に対する意見の焦点となるもの
であると言い表せる．
例えば，宿泊施設の立地情報（「駅前」，「海沿い」）や施設が提供する設備に関する情報（「風呂」，「加湿器」），施設のサービス（「バイキング」，「接客態度」）等が具体的な評価視点となる．
また，評価視点の表現形式は，単一単語（「バイキング」）だけでなく，複合語（「朝食バイキング」）や句（「朝食のバイキング」）などの場合もある．
本研究では以上の形式は評価視点として認めているが，処理の都合上，以下に示すように，連体修飾節を伴う場合は修飾部を除外して扱った．
下記例の場合，下線部は評価視点として認めたが，どちらの例でも「メニューが新しくなった」は評価視点には含めていない．
なお，表現形式の特定は以下のようにおこなった．
単語の特定には形態素解析器MeCabを使用した．
複合語については，MeCabで解析後，名詞が連続している箇所を複合語として特定している．
句については，現在は「名詞の名詞」というパターンで特定しており，他の形は想定していない．
ただし，上記パターンの名詞は名詞連続に置換可能とした．
メニューが新しくなった朝食バイキングが良かった．
メニューが新しくなった朝食のバイキングが良かった．
提案手法について述べる．
まず，使用する記号，および，評価視点のランキング課題を以下のように定義する．
評価対象の集合を[MATH]とする．
全ての評価対象に対する全てのレビューの集合を[MATH]とし，[MATH]の要素であるレビューの中に書かれた評価視点(token)の系列を[MATH]，[MATH]の異なり要素(type)の集合を[MATH] ([MATH])とする．
例えば，以下のような，それぞれ1文と2文からなる短い2つのレビューを要素とする集合[MATH]があり，各文の下線部が評価視点であったとすると，系列[MATH]と集合[MATH]は次のようになる．
[MATH]_{1}[MATH]_{2}[MATH]
[MATH]_{1}[MATH]_{2}[MATH]
[MATH]
この時，ある評価対象[MATH]に関して評価視点をランキングするアルゴリズムを次の\algo{alg1}とする．
このアルゴリズムが示している通り，[MATH]の要素[MATH]がランキングの対象である．
本論文では曖昧性を排除するために，以降，[MATH]のことを単に評価視点と呼び，評価視点[MATH]が[MATH]内で出現したものを評価視点トークンと呼ぶ．
[h]
\STATE{INPUT    [MATH]：評価対象
[MATH]：評価視点集合}
[1] \FOR{[MATH]} \STATE[MATH] \ENDFOR\RETURN[MATH]
上記の\algo{alg1}で自明でない部分は，評価対象[MATH]における評価視点[MATH]の重要度を決定するスコア関数[MATH]のみである．
本研究では，このスコア関数として，以下のような対数尤度比(Log-Likelihood Ratio，LLR)に基づく尺度を提案する．
これは内山ら[CITE]が特定分野における単語の特徴度を測る尺度として提案したものを評価視点ランキング課題に適用したものである．
以下，内山ら[CITE]を参考にしながら，上記尺度の詳細について述べる．
まず始めに，ある評価対象[MATH]と評価視点[MATH]が与えられた際，レビュー中で観測された評価視点トークン[MATH]に関する確率変数[MATH]と[MATH]を以下のように定義する：
W_j & =
1 & vは評価視点u_jのレビュー内での出現である
0 & otherwise
T_k & =
1 & vが観測されたのは評価対象o_kのレビュー内である
0 & otherwise
ここで，評価視点トークン[MATH] ([MATH])に対応する確率変数[MATH]，[MATH]の値をそれぞれ[MATH]，[MATH]とすると，[MATH]から次のような確率変数の値の組みで表された系列[MATH]が新たに得られる．
この時，それぞれの評価視点トークンが確率的に独立であると仮定すると，[MATH]の生起確率は次式で表される：
また，各トークンを変数[MATH]，[MATH]の値ごとに出現頻度を集計することを考え，各頻度を\tab{kankei}のように，それぞれ[MATH]，[MATH]，[MATH]，[MATH]で表すことにする．
ここで，[MATH]である．
以上の準備のもと，次の対数尤度比を考える：
LLR_0(o_k,u_j) & = \log\frac{Pr(\mathcal{V}_{jk}; H_{dep})}{Pr(\mathcal{V}_{jk}; H_{indep})} \nonumber
& = \sum_{i=1}^{n}\log\frac{Pr(W_j=w^{i}_j,T_k=t^{i}_k;H_{dep})}{Pr(W_j=w^{i}_j,T_k=t^{i}_k;H_{indep})}
ここで，[MATH]および[MATH]は，以下のような，確率変数に関する仮説である．
[MATH]:確率変数[MATH]と[MATH]とは互いに依存している．
[MATH]:確率変数[MATH]と[MATH]とは互いに独立である．
\eq{llr0}において，[MATH]の下では，
が成り立つ．
また，各種の確率は，
Pr(W_j=1, T_k=1; H_\mathit{dep}) & = \frac{a}{n} ,　Pr(W_j=1, T_k=0; H_\mathit{dep}) = \frac{b}{n}
Pr(W_j=0, T_k=1; H_\mathit{dep}) & = \frac{c}{n} ,　Pr(W_j=0, T_k=0; H_{dep}) = \frac{d}{n}
Pr(W_j=1) & = \frac{a+b}{n} ,　Pr(W_j=0) = \frac{c+d}{n}
Pr(T_k=1) & = \frac{a+c}{n} ,　Pr(T_k=0) = \frac{b+d}{n}
で推定する．
この尺度は，2つの確率変数[MATH]と[MATH]とが依存しているという条件，および，独立であるという条件の下で，データが観測される確率の比の対数を表しており，[MATH]と[MATH]の依存性が高い程，大きな値をとる．
もし，ある評価視点がどの評価対象にも共通するような一般的な視点であれば，評価視点トークンは，どの評価対象のレビュー中にも同じように出現すると考えられる．
すなわち，[MATH]と[MATH]とは互いに独立であると考えられ，上記尺度は小さな値をとる．
一方で，ある評価視点が特定の評価対象にのみ特徴的な出現を示すようであれば，[MATH]と[MATH]とは依存しており，上記尺度は大きな値をとる．
つまり，この尺度をスコア関数とすることで，特定の評価対象に特徴的な評価視点に対して大きなスコアを割り振ることができる．
ただし，上記尺度は，ある評価視点が特定の評価対象に対して特徴的に言及される場合と特徴的に言及されない場合を区別できない．
そのため，どちらの状況であっても大きな値をとってしまう．
そこで，言及される場合とされない場合を区別できるよう，実際には以下のように補正して利用する．
ただし，
である．

レビューではユーザの数だけ書き手が存在しており，同じ概念が述べられていたとしても，ユーザによって異なる単語が使われることがしばしばある．
例えば，価格について何かを述べたいときに，あるユーザは「価格」と表記したが，別ユーザは「料金」や「値段」等，別の単語を使うことがある．
また，レビューは，評価対象という自明な文脈をもつ文書であるため，同じ評価対象のもとでユーザが共有しているであろう情報がしばしば省略表記される傾向があり，例えば，最寄り駅の「東京駅」を単に「駅」と表記するユーザ等，その表記はユーザによってさまざまに変化する．
一般的に，このような異表記の問題や表記揺れの問題（以下，単に異表記の問題と呼ぶ）はよく知られているが，評価視点のランキング課題に対しても悪影響を与えていると考えられる．
前節で述べた提案尺度では評価視点の出現頻度の情報を用いているが，異表記が考えられる評価視点については，異表記の数だけ頻度が分散してカウントされてしまい，その結果，それらの評価を誤ってしまう．
以下では，この異表記問題の影響を回避する手法について述べる．
本手法は，評価視点をクラスタリングすることによって，同じ意味あるいは類似した意味の評価視点をクラスタにまとめ上げ，クラスタ情報に基いてランキングを補正する．
手法は，クラスタ情報をランキングに反映させる方法によって，事前処理法と事後処理法の2つに分かれる（\fig{clustering}）．
以下ではまず，2つの手法について述べ，その後，各手法の中で用いるクラスタリング手法について述べる．
事前処理法（\fig{clustering}の(b)）では，ランキングの前に評価視点のクラスタリングを実施し，同一の意味あるいは類似した意味の評価視点をクラスタにまとめ上げる．
そして，同じクラスタとなる視点群をひとつの評価視点であるように扱い出現頻度を数えることで対数尤度比を計算し，ランキングをおこなう．
具体的には，\sec{llr}で導入した\eq{w}の評価視点トークンに関する確率変数[MATH]を次の\eq{w2}のように再定義してスコア関数を計算することで，クラスタ情報をランキングに反映させる．
ただし，下記の式中の[MATH]と[MATH]は\eq{w}と同様，評価視点トークンと評価視点をそれぞれ意味する．
事後処理法（\fig{clustering}の(c)）では，ランキングを先に行い，その後，クラスタリングによって得られたクラスタ情報に従ってランキング結果を補正する．
具体的には，ある評価視点[MATH]がクラスタ[MATH]に所属する場合を考えると，ランキングに使用するスコア関数\eq{finalrank}で得られた値に対して，次の\eq{finalrank2}を計算する．
\eq{finalrank2}が示すように，事後処理法では，元の重要度をクラスタ内で平均化した値を重要度として採用する．
次に，上記の補正手法で用いるクラスタリングについて述べる．
クラスタリングのアルゴリズムは，以下に示す標準的なアルゴリズム[CITE]を採用する．
ただし，アルゴリズム内で利用される評価視点間の類似度尺度については，以下で述べるシソーラスに基づく類似度において，ユーザレビューの特性を踏まえて拡張を施した尺度を新たに採用する．
なお，クラスタリングの議論をおこなう場合，一般には距離や非類似度を定義することが多いが，説明の便宜上，ここでは類似度を定義している点に注意されたい．
以下，クラスタリング・アルゴリズムについて概要を述べた後，評価視点間の類似度尺度について述べる．
クラスタリングには，以下に示す3つのアルゴリズムを採用した．
いずれも，凝集型の手法であり，もっともクラスタ間類似度の高い2つのクラスタをボトムアップに再帰的に併合しながらクラスタリングを進める点が共通しているが，クラスタ間類似度の定義が異なる．
単連結法(single linkage method)は，クラスタ[MATH]と[MATH]の要素間の類似度[MATH]の中で，最大の類似度をクラスタ間の類似度[MATH]とする：
完全連結法(complete linkage method)は，クラスタ[MATH]と[MATH]の要素間の類似度の中で，最小の類似度をクラスタ間の類似度とする：
また，群平均法(group average method)は，クラスタ[MATH]と[MATH]の各要素間の平均類似度をクラスタ間の類似度とする：
次に，評価視点間の類似度[MATH]について説明する．
評価視点間の類似度には，以下で述べる3種類の類似度尺度を併用した．
なお，どの類似度も0以上1以下の値をとり，同じ評価視点が入力となった場合に対して最大値[MATH]を返す([MATH])．
2つの単語[MATH]と[MATH]の類似度を求める手法として，シソーラスに基づく類似度がある．
これは次式のように定義される[CITE]：
ここで，[MATH]と[MATH]は階層構造をなすシソーラス中での当該単語の位置する深さをあらわし，[MATH]は階層構造における単語[MATH]と単語[MATH]の共通祖先ノードが位置する深さの最大値をあらわす．
また，[MATH]はシソーラスに含まれる見出し語の集合である．
一般に，シソーラスは人手により構築されていることから，シソーラスの見出し語に含まれる単語間の類似度を測るにはこの尺度は有用と言える．
しかし，今回対象としている評価視点には「施設管理」といったシソーラスには登録されにくい複合語なども含まれているため，上記尺度そのままでは多数の評価視点間の類似度が[MATH]となってしまう問題がある．
そこで，本論文では類似度が求められる評価視点ペアの被覆率を上げるために，以下のように拡張した類似度を採用する：
ここで，形態素解析によって各評価視点を形態素に分割したものをそれぞれ[MATH]，[MATH]で表しており，拡張版では，従来の式で類似度が求められない場合は対象を分割して類似度を求めていることがわかる．
例えば，引数[MATH]が「施設管理」である例を考える．
ここで，「施設管理」はシソーラスに含まれておらず，またもう一方の引数[MATH]はシソーラスに含まれる何らかの単語であるとする．
この場合の類似度計算は\eq{thesaurus_k}の2行目によっておこなわれ，「施設管理」を「施設」と「管理」に分割させた後，それぞれの形態素に対して\eq{thesaurus}の[MATH]へ問合せを実行し，個別に[MATH]との類似度を求める．
そして，問合せ結果の平均を「施設管理」と[MATH]との間の類似度であるとする．
\eq{thesaurus_k}では，分割操作によって，シソーラスのエントリとの照合率が改善され，類似度が求められない事例数を削減させる効果が期待できる．
次に，上記のシソーラスに基づく類似度尺度を補完するために，評価視点の表層文字列に基づく類似度を考える．
本研究では，最長共通部分文字列LCS (longest common subsequence) [CITE]に基づく以下の類似度尺度を採用する：
ここで，[MATH]は[MATH]と[MATH]の最長共通部分文字列の長さであり，上式は，その値を[MATH]，[MATH]それぞれの文字列の長さを基に正規化している．
表層文字列に基づく類似度は，「焼きたてパン」と「焼き立てパン」のような部分的な漢字表記とひらがな表記の違いや，「バイキング」と「朝食バイキング」のような文字数の比較的多いカタカナ列からなる評価視点の類似性を測る際に特に効果的であると期待できる．
例えば，6文字で構成される「焼きたてパン」と「焼き立てパン」がそれぞれ[MATH]と[MATH]である例を考える．
両者の違いは，ひらがな「た」と漢字「立」の1文字だけであり，その他は各文字の順序等すべて同じである．
この場合，[MATH]で，[MATH]となり，高い類似度が得られる．
LCSの代わりに，不連続になる部分文字列の影響を考慮した文字列カーネル[CITE]を用いた予備実験も行ったが，LCSとほぼ同様の実験結果を得た．
そのため，\sec{experiment}の実験ではLCSを用いた結果のみ報告する．
類似度を補完するもう一つの方法として，評価視点が現れる文脈の情報に基づく類似度を考える．
これは一般に，似た意味をもつ単語は似た文脈に現れやすいと言われており，この性質に従って，単語が現れる周辺文脈を基に類似度を求める手法である．
本研究では，代表的な手法の一つである，次式のコサイン類似度を採用する[CITE]：
ここで，[MATH]と[MATH]は，それぞれ[MATH]と[MATH]の文脈に現れる単語から構成される単語頻度ベクトルである．
また，ここでは，当該の評価視点に対応するすべての評価視点トークンから文脈情報を獲得し，それらの情報からひとつのベクトルを作成する．
文脈情報に基づく類似度は，「東京駅」と「駅」や「最寄り駅」のような，文脈に依存した評価視点の類似性を測る際に特に効果的であると期待できる．
ここまで述べたように各類似度尺度は，それぞれ異なる情報に基いており，互いに相補関係にあると言える．
そこで，クラスタリングの際は，各類似度尺度を単独で用いるのではなく，次式のように統合して用いる事とする：
