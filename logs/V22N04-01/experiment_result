学習と評価には10個のラベルとそれらの入力（説明文書）のペアから構成されるデータを用いた．
表[REF_tab:dist]はラベル名と各ラベルの入力（説明文書）の数とそれらの全ラベルに占める割合を示す．
ただし，学習データは，手動収集データをベースとし，そのベースとなるデータに異なる数の自動収集データと疑似データを加えることにより13個のデータセット（表[REF_tab:data]）を作成して用いた．
表中のm300はベースとなるデータセットで手動で収集した300個のデータである．
また，たとえばa2400は2,400個の自動収集データとm300で構成されたデータセット，p2400は2,400個の疑似データとm300から構成されたデータセット，そしてa2400p2400は2,400個の自動収集データ，2,400個の疑似データ，そしてm300から構成されたデータセットである．
また，評価には学習データと異なる100個のデータを用いた．
個々の説明文書は2.4節で述べた方法で，2ラベル間で重複する単語を除外する場合と3ラベル以上で共通する単語を除外する場合においてそれぞれ182と223次元の特徴ベクトルに変換される．
各種の機械学習の各学習データセットにおける最適なパラメータは，それぞれの学習データセットに対しグリッドサーチと5-fold交差検証を行って決定した．
グリッドサーチに用いるパラメータの詳細は表[REF_tab:gs]にまとめている．
たとえば，DBNの入力が182次元の場合の構造（隠れ層）の欄に152-121-91がある．
これは，そのDBNは182-152-121-91-10という構造を持つ，ということを表している．
ただし，数字182と10は入力層と出力層のユニット数であり，それぞれ特徴ベクトルの次元数とラベルの数に対応している．
また，これら隠れ層のユニット数は恣意的にではなく，前半の3つについては線形等間隔に設定している．
すなわち，入力層のユニット数(182)から，ピラミッド的に，最初の隠れ層のユニット数を[MATH] (152)，次の隠れ層のユニット数を[MATH] (121)，そして，最後の隠れ層のユニット数を[MATH] (91)のように設定している．
一方，後半の3つについては，Bengioの[CITE]の薦め，すなわち，過学習への対処が適切であれば隠れ層のユニット数は基本的に多いほどよい，ネットワーク構造は各層が同じサイズでよい場合が多い（ピラミッドまたは逆ピラミッドである必要はない）に基づき，すべての隠れ層のユニット数を入力層のユニット数の3/2倍であるように設定した．
入力層のユニット数が223の場合も同様な考え方に基づいて設定した．
DBNがMLPとSVMよりパラメータが多いため，同じ細かさのグリッドサーチで最適なパラメータを決めてしまうと，パラメータの多いDBNのほうが細かなチューニングができるため有利になる可能性がある．
このようなバイアスをなくすために，MLPとSVMについてそのパラメータグリッドをより細かくし，MLPとSVMの探索すべきパラメータセットの数（つまり，パラメータの組み合わせの数）をDBNのそれと等しいかそれ以上にした．
一方，MLPについては，構造，学習率，学習回数がDBNとまったく同じものも比較に用いた．
本稿では後者をMLP 1，前者をMLP 2と呼ぶ．
その結果，DBNとMLP 2は同じく864通りのパラメータセット，SVM (Linear)とSVM (RBF)は900通りのパラメータセット，また，MLP 1は72通りのパラメータセットを持つことになる．
MLPとSVMに加え，用例に基づく手法をベースラインとして比較実験に加えた．
これは，評価データを学習データの一つひとつと比較し，共通する単語のもっとも多い，または共通する単語数をその評価データの単語数で正規化した値がもっとも大きい学習データのラベルを評価データのラベルとする方法である．
ここで両者をそれぞれBaseline 1とBaseline 2と呼ぶ．
図[REF_fig:baseline]は本手法および本手法による予測結果の正解率算出のアルゴリズムを示す．
ただし，カウントに用いる単語は2.4節で述べた(1)〜(4)の手順に従って説明文書から抽出されたものである．
図[REF_fig:prec]は各機械学習において，異なる学習データセットを用いた場合の評価データへの予測精度を示す．
ここでの精度は，各パラメータセットの交差検証誤差を昇順（小さい順）に並べたときの上位N個（ただしNは5から30まで可変）のパラメータセットを用いた場合の平均精度である．
なお，本論文に用いられている平均精度はすべてマクロ平均で算出したものである．
図に示しているように，全般的に見れば，学習データセットa2400p2400を用いた場合（逆三角形マークの点線），すなわち手動収集データに自動収集データと疑似データの両方を最も多く加えた場合，DBNとMLPは最高の精度，そしてSVMもほぼ最高の精度を出している．
また，手動収集データに自動収集データと疑似データの両方を適度に加えた場合（点線）は，手動収集データのみの場合（星マークの太線）に比べ，DBNとMLPとSVM (RBF)の予測精度はおおむね向上している．
しかしSVM (Linear)についてはそのような傾向は見られなかった．
さらに，手動収集データのみを用いた場合と，自動収集データと疑似データのどちらか一方のみを手動収集データに加えた場合について比べると，DBNとSVM (RBF)については自動収集データのみを加えた場合（実線），MLPについては疑似データのみを加えた場合（破線）のほうがそれぞれに精度の向上が見られた．
自動収集データのほうが疑似データよりもノイズが多いことから，上記結果はDBNとSVM (RBF)のほうがMLPよりもノイズの多い学習データを有効利用できる可能性が高いことを示している．
図[REF_fig:cmp]は各機械学習間の評価データへの予測精度の比較を示す．
ここでの精度は図[REF_fig:prec]と同様，各パラメータセットの交差検証誤差を昇順に並べたときの上位N個（ただしNは5から30まで可変）のパラメータセットを用いた場合の平均精度である．
学習データセットも図[REF_fig:prec]のとまったく同じであるがそれらの詳細の明示は省略されている．
ただし，各グラフの縦軸の範囲が統一されているため，グラフDBN vs. SVM (RBF)において，SVM (RBF)の精度が0.9未満なもの（計4本の線）が表示されていない（なお，すべての結果は図[REF_fig:prec]には示されている）．
この図からはDBNのほう（実線）が他の機械学習（破線）より性能がよいことが一目瞭然にわかる．
表[REF_tab:baseline]，[REF_tab:rst-top1]，[REF_tab:rst-top5]，[REF_tab:rst-top10]はそれぞれ，各学習データセットを用いた場合の，ベースラインの予測精度，交差検証誤差が最小のパラメータセットを用いた場合の予測精度，交差検証誤差を昇順に並べたときの上位5個，10個のパラメータセットを用いた場合の平均予測精度を示す．
まず，機械学習とは対照的に，ベースライン手法では，ノイズの多い学習データを加えても（つまり，手動収集データに自動収集データのみを加えた場合と，自動収集データと疑似データの両方を加えた場合），予測精度の向上に役立たないばかりか，逆に，これらのデータは予測精度を大きく下げてしまった．
次に，ほとんどの場合において，ベースラインの予測精度は機械学習のそれよりかなり低かった．
また，ほとんどの場合において，DBNがすべての機械学習において最高の予測精度を出している（各学習セットにおいて各機械学習手法中の最高の精度は太字で表されている）．
前節の実験結果はすでに提案手法の予測精度が従来の機械学習手法より高いことを示しただけでなく，学習データにおけるノイズに対する頑健性もある程度示せたと考える．
しかし上記実験では，手動学習データのラベル間の重複単語を除外していたため，疑似データの作成時はそれらをノイズとして加えることができず，提案手法のノイズへの頑健性に疑問が残る．
本節の実験は，2ラベル間の重複単語を残しているため，前節の実験よりも，より適切にノイズの頑健性を確認できると考える．
図[REF_fig:prec-add]は図[REF_fig:prec]と同様，各機械学習において，異なる学習データセットを用いた場合の評価データへの予測精度を示す．
DBNのグラフにおいて，すべての点線と2本の実線が星マークの太線（つまり手動データ）の上にあること，また，SVM (RBF)においてすべての点線と実線が星マークの太線の上にあることから，前の実験結果と同様，DBNとSVM (RBF)については疑似データを含めたノイズのある学習データの利用が有効であることが確認できる．
一方，MLPとSVM (Linear)については，手動データの星マークの太線がほとんど一番上に位置していることから，疑似データを含めたノイズのある学習データの有効性がほとんど見られない．
すなわち，MLPとSVM (Linear)のノイズに対する頑健性については，前節の実験結果よりも悪い結果となった（逆にDBNの優位性がより顕著になったとも言える）．
なお，182次元の特徴ベクトルを用いた実験結果ではa2400p2400を用いた場合（逆三角形マークの点線），すなわち手動収集データに自動収集データと疑似データの両方を最も多く加えた場合，DBNが最高の精度を出しているのに対し，本実験結果ではDBNはa600p600を用いた場合（正三角形マークの点線）に最高の精度を出している．
これは，精度の高いデータに対し，加えてよいノイズのあるデータについては適正の数があるはずで，次元数が増えると個々の特徴ベクトルの本来のノイズの度合いが増強したため，ノイズデータの適正数が減少したと考えることができ，両者の結果は矛盾しないと思われる．
交差検証誤差が最小のパラメータセットを用いた場合と，交差検証誤差を昇順に並べたときの上位10個のパラメータセットを用いた場合について，DBNと他の手法との性能の有意差検定を行った．
交差検証誤差が最小のパラメータセットを用いた場合，各学習データセットについて単独で検定を行うとデータ数が少なすぎるため，各学習データセットの結果を1つにまとめて符号検定とt検定を行った．
一方，交差検証誤差上位10個のパラメータセットを用いた場合は各学習データセットについて単独でt検定を行った．
検定結果を表[REF_tab:test-top1]，[REF_tab:test-top10]に示す．
これらの結果から，182次元と223次元の特徴ベクトルのいずれを用いても，多数の場合においてDBNが他の手法より有意に優れていることが確認できる．
また，詳細をみると，たとえばa2400p2400の学習データセットについては182次元の特徴ベクトルを，a600p600/a1200p1200の学習データセットについては223次元の特徴ベクトルを用いたほうが有意差が顕著であることがわかり，特徴ベクトルの構成方法について，DBNと他の手法との性能差の観点からどれが一番よいかは一概に断言することができない．
最後に，参考として，各手法のラベル（検索語）ごとの予測精度（表[REF_tab:label-prec]）と，交差検証誤差が最小のパラメータセット（表[REF_tab:parameter]）を示しておく．
表[REF_tab:label-prec]から，182次元の「PCケース」を除き各ラベルへの予測精度にばらつきが小さいことがわかる．
また，全般的にDBNのほうがほかの手法より各ラベルに対する予測精度がよいことがわかる．
さらに，たとえばDBNの予測精度は182次元の場合のほうが10個中の6個のラベルについて223次元の場合に勝っており，182次元と223次元のどちらのほうがよいかが一概に言えないことがわかる．
表[REF_tab:parameter]には，隠れ層のユニット数が182次元で273，223次元で335が多く出現しており，隠れ層のユニット数は多いほうがよいというBengioの提言と合致している．
