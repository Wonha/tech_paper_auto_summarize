機械学習の汎化能力を向上させるために，学習データとして，精度は高いが規模が小さい手動収集データに加え，精度はそれほど高くない（つまり，ノイズはある）が相対的に規模の大きい自動収集データを用いることにした．
しかし，自動収集したデータには説明文書とラベルがそもそも一致しない，つまり説明文書へのラベルが履き違えられている可能性も考えられる．
そのために，手動で収集した説明文書をオリジナルのデータとしてとらえ，それらに適度なノイズを加えて作成した疑似データも用いることにした．
このようなデータは自動収集したデータに比べノイズが少なくラベルの履き違いもないと考えることができる．
疑似データの具体的な生成手順は以下の通りである．
オリジナルの説明文書からすべての異なり単語を抽出する．
個々のオリジナルの説明文書に対し，追加，削除，または追加&削除の処理を加える．
具体的には，手順(1)で抽出した単語のうち，説明文書にない単語を説明文書の単語数の10%個ランダムに選んで加える，説明文書から単語を説明文書の単語数の10%個ランダムに選んで削除する，または上記の（10%ずつの）追加と削除を同時に施す，という処理を等確率（つまり，それぞれを1/3の確率）で行う．
手順(2)で得られたデータを疑似データとする．
なお，この生成方法においては，1つのオリジナルの説明文書に対し，疑似データを複数生成することが可能である．
評価データは学習データとは別に自動収集したものを用いる．
ただし，自動収集データは，ラベルが正確とは限らないため，評価データとして用いても適切な評価とならない可能性がある．
そのため，評価データとして自動収集データの中からラベルの正しいものを人手で選別して用いることにした．
以下の手順(1)〜(4)で説明文書から関連語・周辺語を抽出する．
それに手順(5)(6)を加えることにより，機械学習に必要な特徴ベクトルへの変換を行う．
手動収集のデータを形態素解析し，名詞（固有名詞，サ変接続，一般）を抽出する．
名詞が連続しているならば，日本語同士なら結合し，英語同士なら空白を間に入れて結合し，1つの単語と見なす．
各ラベルから出現頻度がトップ50以内の単語を抽出する．
ラベル間で重複している単語を除外する．
本研究では，以下に述べる考えに基づき2ラベル間で重複する単語を除外する，または，3ラベル以上で共通する単語を除外するという2通りの方法を採用した．
まず，各ラベルにできるだけ特徴的な単語のみを素性にするためには重複単語をできるだけ除外するのが効果的と考える．
また，今回は実験規模が小さくあまり問題にならないが，予測用語の数の増加に伴う特徴ベクトル次元の大幅な増加を抑える1つの方法として重複単語を除外することが考えられる．
特徴ベクトル次元の抑制はまた一般的に，学習におけるデータスパースネス問題の緩和にもつながる．
しかし一方，ラベル間の単語重複をまったく認めないと，たとえば「USBメモリ」のような，「USB」や「メモリ」に共通する重要な単語を除外してしまう問題も考えられる．
そのため，本研究では2ラベル間の重複を許容し3ラベル以上で共通する単語を除外する方法も用いる．
上記手順で得られた単語をベクトルの要素とし，個々の要素はその単語が出現していれば1，出現していなければ0の2値を取る．
2.1, 2.2, 2.3節で述べたすべてのデータに対し形態素解析を行い，手順(5)にしたがって特徴ベクトルに変換する．
