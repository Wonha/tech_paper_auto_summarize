================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:6, score:265] 実験の結果，DBNの予測精度はベースライン手法よりはるかに高くMLPとSVMのいずれよりも高かった．
[i:8, score:293] さらに，よりノイズの多い学習データを加えてもDBNの予測精度はさらに向上したのに対し，MLPの精度向上は見られなかった．
[i:9, score:267] このことから，DBNのほうがMLPよりもノイズの多い学習データを有効利用できることが分かった．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:29, score:404] 実験の結果，まず，学習データとして手動収集データのみを用いても自動収集データと疑似データを加えてもDBNの予測精度は用例に基づくベースライン手法よりははるかに高くMLPとSVMのいずれよりも高いことが確認できた．
[i:31, score:382] さらに，手動収集データにノイズの多い自動収集データのみを加えて学習した場合，DBNとSVMには予測精度の向上が見られたがMLPにはみられなかった．
[i:32, score:290] この結果から，MLPよりもDBNとSVMのほうがノイズに強くノイズの多い学習データも有効利用できる可能性が高いと言えよう．

================================================================
[section type  : proposed_method]
[section title : 関連語・周辺語コーパス]
================================================================
[i:33, score:107] 機械学習を用いて関連語・周辺語から検索用語を予測・提示する場合，その学習データとして，入力（関連語・周辺語）と正解となるレスポンス（検索用語）のペアからなるコーパスが必要となる．
[i:35, score:85] また，教師あり機械学習では，レスポンスをラベルと呼ぶ場合が多いので，本稿では検索用語をラベルと呼ぶ．
[i:36, score:68] 表[REF_tab:example]はコーパスの入力（関連語・周辺語とその元となる説明文書）とラベルのペアの例を示す．
-----------------------------------------------------
  [subsection title : 手動収集と自動収集]
-----------------------------------------------------
  [i:lead, 129] 本研究では，ラベルを説明している文書には関連語・周辺語が多く含まれると考え，インターネットからこのようなWebページを手動と自動の2通りの方法で収集した．
.....
  [i:39, score:129] 本研究では，ラベルを説明している文書には関連語・周辺語が多く含まれると考え，インターネットからこのようなWebページを手動と自動の2通りの方法で収集した．
  [i:41, score:95] 一方，自動収集では，ラベルの後に「とは」「は」「というものは」「については」「の意味は」の5語を付けて（たとえば，ラベルが「グラフィックボード」であれば「グラフィックボードとは」「グラフィックボードというものは」などで）Googleで検索したものを説明文書として収集する．
  [i:42, score:92] 手動収集データは規模が小さい代わりに精度が高く，自動収集データは精度が低い代わりに規模が大きい．
-----------------------------------------------------
  [subsection title : 疑似データ]
-----------------------------------------------------
  [i:lead, 157] 機械学習の汎化能力を向上させるために，学習データとして，精度は高いが規模が小さい手動収集データに加え，精度はそれほど高くない（つまり，ノイズはある）が相対的に規模の大きい自動収集データを用いることにした．
.....
  [i:43, score:157] 機械学習の汎化能力を向上させるために，学習データとして，精度は高いが規模が小さい手動収集データに加え，精度はそれほど高くない（つまり，ノイズはある）が相対的に規模の大きい自動収集データを用いることにした．
  [i:45, score:154] そのために，手動で収集した説明文書をオリジナルのデータとしてとらえ，それらに適度なノイズを加えて作成した疑似データも用いることにした．
  [i:46, score:92] このようなデータは自動収集したデータに比べノイズが少なくラベルの履き違いもないと考えることができる．
-----------------------------------------------------
  [subsection title : 評価データ]
-----------------------------------------------------
  [i:lead, 62] 評価データは学習データとは別に自動収集したものを用いる．
.....
  [i:53, score:62] 評価データは学習データとは別に自動収集したものを用いる．
  [i:54, score:68] ただし，自動収集データは，ラベルが正確とは限らないため，評価データとして用いても適切な評価とならない可能性がある．
  [i:55, score:66] そのため，評価データとして自動収集データの中からラベルの正しいものを人手で選別して用いることにした．
-----------------------------------------------------
  [subsection title : 関連語・周辺語抽出とベクトル変換]
-----------------------------------------------------
  [i:lead, 31] 以下の手順(1)〜(4)で説明文書から関連語・周辺語を抽出する．
.....
  [i:58, score:76] 手動収集のデータを形態素解析し，名詞（固有名詞，サ変接続，一般）を抽出する．
  [i:64, score:81] また，今回は実験規模が小さくあまり問題にならないが，予測用語の数の増加に伴う特徴ベクトル次元の大幅な増加を抑える1つの方法として重複単語を除外することが考えられる．
  [i:66, score:58] しかし一方，ラベル間の単語重複をまったく認めないと，たとえば「USBメモリ」のような，「USB」や「メモリ」に共通する重要な単語を除外してしまう問題も考えられる．

================================================================
[section type  : proposed_method]
[section title : 深層学習]
================================================================
[i:71, score:169] その代表的な手法としてDeep Belief Network (DBN) [CITE]とStacked Denoising Autoencoder (SdA) [CITE]が提案されている．
[i:72, score:139] 数多くの課題において，その両者の性能がほぼ同じと言われているが，本研究ではよりスマートなアーキテクチャを有するDBNを用いることにした．
[i:74, score:288] そのため，DBNは，Restricted Boltzmann Machine (RBM)を複数並べ教師なし学習の特徴抽出器として利用する多層のニューラルネットと，ラベルを出力する教師あり学習の最終層から構成される．
-----------------------------------------------------
  [subsection title : Restricted Boltzmann Machine (RBM)]
-----------------------------------------------------
  [i:lead, 101] RBMは制限付きボルツマンマシンとも呼ばれ，学習データの確率分布を教師なし学習で表現する（言い換えれば，学習データの生成モデルを統計的な機械学習の方法で構築する），一種の確率的なグラフィカルモデルである．
.....
  [i:77, score:150] 本来のボルツマンマシンの可視層と隠れ層のユニット間の結合を制限することにより，効率的な教師なし学習を実現している．
  [i:78, score:162] RBMの構造は図[REF_fig_rbm]に示しているように可視層と隠れ層の2層から構成され，層内ユニット間に結合がなく，層間のユニット，すなわち可視ユニット([MATH])と隠れユニット([MATH])，は結合されている．
  [i:83, score:131] ただし，[MATH] ([MATH])はサンプリングの繰り返し回数，[MATH]，[MATH]はユニット[MATH]と[MATH]間の結合の重み，そして，[MATH]と[MATH]は可視層と隠れ層のユニット[MATH]と[MATH]のオフセット（バイアス）である．
-----------------------------------------------------
  [subsection title : Deep Belief Network (DBN)]
-----------------------------------------------------
  [i:lead, 208] 図[REF_fig_dbn]は一例として，三つのRBMと教師あり学習器から構成されるDBNを示す．
.....
  [i:95, score:208] 図[REF_fig_dbn]は一例として，三つのRBMと教師あり学習器から構成されるDBNを示す．
  [i:100, score:233] ここでは簡便化のために，RBMの層（ただし入力層を除く）をDBNの隠れ層と見なす．
  [i:101, score:230] つまり，図の例は三層の隠れ層のDBNである（隠れ層の数とRBMの数は同じであることに注意されたい）．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[i:104, score:0] 
-----------------------------------------------------
  [subsection title : 実験設定]
-----------------------------------------------------
  [i:lead, 79] 学習と評価には10個のラベルとそれらの入力（説明文書）のペアから構成されるデータを用いた．
.....
  [i:121, score:271] DBNがMLPとSVMよりパラメータが多いため，同じ細かさのグリッドサーチで最適なパラメータを決めてしまうと，パラメータの多いDBNのほうが細かなチューニングができるため有利になる可能性がある．
  [i:122, score:263] このようなバイアスをなくすために，MLPとSVMについてそのパラメータグリッドをより細かくし，MLPとSVMの探索すべきパラメータセットの数（つまり，パラメータの組み合わせの数）をDBNのそれと等しいかそれ以上にした．
  [i:125, score:272] その結果，DBNとMLP 2は同じく864通りのパラメータセット，SVM (Linear)とSVM (RBF)は900通りのパラメータセット，また，MLP 1は72通りのパラメータセットを持つことになる．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, 105] 図[REF_fig:prec]は各機械学習において，異なる学習データセットを用いた場合の評価データへの予測精度を示す．
.....
  [i:134, score:444] 図に示しているように，全般的に見れば，学習データセットa2400p2400を用いた場合（逆三角形マークの点線），すなわち手動収集データに自動収集データと疑似データの両方を最も多く加えた場合，DBNとMLPは最高の精度，そしてSVMもほぼ最高の精度を出している．
  [i:135, score:414] また，手動収集データに自動収集データと疑似データの両方を適度に加えた場合（点線）は，手動収集データのみの場合（星マークの太線）に比べ，DBNとMLPとSVM (RBF)の予測精度はおおむね向上している．
  [i:137, score:376] さらに，手動収集データのみを用いた場合と，自動収集データと疑似データのどちらか一方のみを手動収集データに加えた場合について比べると，DBNとSVM (RBF)については自動収集データのみを加えた場合（実線），MLPについては疑似データのみを加えた場合（破線）のほうがそれぞれに精度の向上が見られた．

================================================================
[section type  : proposed_method]
[section title : 本課題の意義について]
================================================================
[i:168, score:84] 本研究では特定の分野の関連語・周辺語または説明文書を入力としたときの検索用語の予測・提示を行う検索支援を想定している．
[i:169, score:73] まず，説明文書による支援の意義は，たとえばThe 5th NTCIR Workshop Meeting on Evaluation of Information Access Technologies: Information Retrieval, Question Answering and Cross-Lingual Information Accessのようなワークショップ型共同研究[CITE]における長い文書を検索課題としたタスクからも類推できる．
[i:172, score:284] 実際，表[REF_tab:keyword-prec]は，DBNについて，各学習データセットを用いた場合の，表[REF_tab:keyword]に示す3関連語・周辺語（[MATH]ノイズ語）による全検索用語の平均予測精度を示している．

================================================================
[section type  : conclusion]
[section title : 結び]
================================================================
[i:174, score:268] 本稿では深層学習の代表的な手法であるDeep Belief Network (DBN)を用いて関連語・周辺語またはそれらの語から構成される説明文書から適切な検索用語を予測する手法を提案した．
[i:179, score:265] 実験の結果，DBNの予測精度はベースライン手法よりはるかに高くMLPとSVMのいずれよりも高かった．
[i:183, score:267] このことから，DBNのほうがMLPよりもノイズの多い学習データを有効利用できることが分かった．

