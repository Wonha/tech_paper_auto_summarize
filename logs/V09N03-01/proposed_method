決定リスト

決定リストとは，クラス分類のためのルールを，その信頼度の
高い順に並べたものである．
それぞれのルールは，「もし（証拠$E_i$）ならば，クラスは$C_j$
である」という形式をしている．証拠というのは，判定の手がかりとなる
事例の特徴である．

例として，英語の多義語{\it plant}（A: 植物, B: 工場）
に関してYarowskyが行なった実験での決定リストを表\ref{tab:ex_dlist}に
示す\cite{Yarowsky:Decision}．
最上位のルールは，「右隣にlifeという単語があったら，語義はA」
という意味，4番目のルールは，「距離2〜10単語以内にmanufacturingという単語があったら，語義はB」という意味である．

\begin{table}
  \caption{決定リストの例}
  
  \label{tab:ex_dlist}
\begin{center}
\begin{tabular}{ccc} \hline\hline
信頼度 & 証拠 & 語義\\ \hline
8.10&	{\it plant} {\bf life}	&	A\\
7.58&	{\bf manufacturing} {\it plant}	&	B\\
7.39&	{\bf life} (within $\pm$2--10words)	&	A\\
7.20&	{\bf manufacturing} (within $\pm$2--10words)	&	B\\
6.27&	{\bf animal} (within $\pm$2--10words)	&	A\\
4.70&	{\bf equipment} (within $\pm$2--10words)	&	B\\
4.39&	{\bf employee} (within $\pm$2--10words)	&	B\\
:&	:	&	:\\
\hline
\end{tabular}
\end{center}
\end{table}

実際にクラスの分類を行なう際には，その事例に対して適用可能なルールのうち，
最も上位のルールを用いて分類が行なわれる．例えば入力文が，
\begin{center}
... divide life into {\it plant} and animal kingdom ...
\end{center}
\noindent
であるとすると，適用可能なルールのうち最上位なのは3番目のルールである
から，{\it plant}の語義はAだと判定されることになる．

このように，決定リストによる手法では，他の多くの機械学習手法と
異なり，特徴を単独で利用する．単独でしか利用しないのは一見不利な
ようであるが，語義曖昧性解消などの，文脈の語彙的な特徴を利用する問題
に関しては，単独の証拠が分類の決定的な証拠になることが多いため，
決定リストによる手法が有効であるといわれている．

本論文で提案する決定リストのルール信頼度の推定手法は，特定の
自然言語処理に特化したものではないが，本論文では，決定リストの
適用例として，上記のような語義曖昧性解消の問題を取り上げる．

ここで，本論文で用いる文脈上の特徴を以下に示す．

\begin{itemize}
\item{Window}

ターゲットから，距離10単語以内に出現する単語

\item{Adjacent}

ターゲットの左隣に出現する単語

ターゲットの右隣に出現する単語

\item{Pair}

ターゲットの左隣にある単語対

ターゲットを挟む単語対

ターゲットの右隣にある単語対

\end{itemize}
\vspace{3mm}
すなわち，文脈情報としての詳細さが異なる三つのタイプの特徴を利用する．
文脈情報として最も詳細なのは  Pair であり，最も粗いのが Window である．

\subsection{ルールの信頼度}

決定リストは，事例とその正解ラベルを含む訓練コーパスから作成される．
決定リストの作成において最も重要な問題は，それぞれのルールの
信頼度の計算法である．文献\cite{Yarowsky:Decision}では，
次の式に従って信頼度を計算している．

\begin{equation}
\label{eq:yarowsky}
	（信頼度）=\log\Big(\frac{P(C_A|E_i)}{P(C_B|E_i)}\Big)
\end{equation}

すなわち，証拠$E_i$のもとでクラス（語義）がAである確率と，同じ証拠$E_i$のもとで
クラスがBである確率との比の対数をとったものである．


従来の決定リストを用いた自然言語処理の研究では，
ルールの信頼度の算出法として，
式（\ref{eq:yarowsky}），あるいは，式（\ref{eq:yarowsky}）を
クラスが3つ以上の場合でも適用できるように変形した次の式，
\begin{equation}
\label{eq:yarowsky1}
	（信頼度）=\log\Big(\frac{P(C_A|E_i)}{1-P(C_A|E_i)}\Big)
\end{equation}
が用いられることが多い\cite{Yarowsky:Decision,Yarowsky:Hierarchical,新納:日本語形態素解析}．また，対数をとらずに，

\begin{equation}
\label{eq:reliability}
	（信頼度）=P(C_A|E_i)
\end{equation}
とする場合もある \cite{白木:複数決定リスト}．

ここで，式（\ref{eq:reliability}）と式（\ref{eq:yarowsky1}）を見比べて
みると，
式（\ref{eq:yarowsky1}）は，式（\ref{eq:reliability}）に関して単調増加であり，
決定リストでは信頼度の大小関係しか問題にならないのだから，
後述するスムージングの問題を考慮しなければ，式（\ref{eq:yarowsky1}）
を用いた場合と，式（\ref{eq:reliability}）を用いた場合では，結果的に作成される
決定リストは等価になる．一般にクラス分類器の目標は，
分類の正解率を最大にすることであるから，ルールの信頼度としては，
そのルールが正解する確率である式（\ref{eq:reliability}）を用いるのが
自然である．
また，クラス分類器が，自然言語処理システムの一部を構成している場合，
分類の信頼度は確率として出力された方が扱いやすいことが多い．
そこで本論文では，ルールの信頼度として式（\ref{eq:reliability}）を
用いることにする．

式（\ref{eq:reliability}）の値は，訓練事例が多ければ，
ベルヌーイ試行における最尤推定により，次のように計算することができる．

\begin{equation}
	（信頼度）=P(C_A|E_i)=\frac{f(C_A, E_i)}{f(E_i)}
\end{equation}
ただし，$f(C_A, E_i)$は，クラスAに属するターゲットと証拠$E_i$が
同時に出現した回数．$f(E_i)$は，証拠$E_i$の出現回数である．
ところが，通常は出現回数が少ない証拠も多い．例えば，

\begin{equation}
	f(C_A, E_i) = 1, \\
	f(E_i) = 1
\end{equation}
の場合，信頼度は$1/1 = 1$と計算されるが，たった一つの
事例しかないのに，その信頼度は100\%，すなわち最も信頼度の
高いルールだとみなされてしまう．
このように，出現回数の少ない事例において，
そのままでは統計的に信頼性のある確率値が算出できないことを
スパースネスの問題という．

そこで本論文では，ベイズ学習の手法を用いてこの問題の解決を試みる．

ベイズ学習によるルール確率値の推定

いま，求めたいルールの確率値を$\theta$とする．最尤推定の枠組では，
確率モデルの尤度が最大となるように$\theta$
を決定するが，ベイズ学習の枠組では，$\theta$を確率変数と考えて，
その確率分布を求める問題と考える．
本論文では，得られた確率分布を決定リストのルールの信頼度
として利用したいのだから，その確率分布から$\theta$の期待値を計算して
利用すればよい．

訓練コーパスにおいて，
確率を求めたいルールに関する事例が$n$個あり，そのうちの
$k$個において，そのルールが正しいというデータがあるとする．
このデータを$y$とすると，データ$y$を観測した後の
$\theta$の事後密度は，

\begin{eqnarray}
	p(\theta | y) &=& \frac{p(\theta)p(y|\theta)}{p(y)}  \\
\label{eq:jigo}
	&=& \frac{p(\theta)p(y|\theta)}{\int_0^1 {p(\theta)p(y|\theta)} d\theta}
\end{eqnarray}
で与えられる．ここで，事象$y$はベルヌーイ試行と考えられるから，
その確率は二項分布により次のように与えられる．

\begin{equation}
	p(y|\theta) = {}_n C_k \theta^k (1-\theta)^{n-k}
\end{equation}
これを式（\ref{eq:jigo}）に代入して，

\begin{eqnarray}
	p(\theta | y) &=& \frac{p(\theta){}_n C_k \theta^k (1-\theta)^{n-k}}{\int_0^1 {p(\theta){}_n C_k \theta^k (1-\theta)^{n-k}} d\theta} \\
	&=& \frac{p(\theta)\theta^k (1-\theta)^{n-k}}{\int_0^1 {p(\theta)\theta^k (1-\theta)^{n-k}} d\theta}
\label{eq:post}
\end{eqnarray}
を得る．ここで，事前分布$p(\theta)$をどのように設定するのか，
という問題が浮上する．事前分布は，$\theta$について学習者が
持っている事前知識を表す．
ベイズ学習における事前分布の設定方法に関しては，大きく分けて2つの
アプローチがある．一つは，できるだけ公平で無知の状態を表すように
事前分布を設定する方法である．そのような事前分布としては，
一様分布やJeffreysの無情報事前分布などが提案されている\cite{繁桝:ベイズ}．
もう一つは，学習者が事前に持っている知識を積極的に表現する
ような事前分布を設定する方法である．

\subsection{一様分布}
\vspace{-6pt}
まず，無知の状態を表す事前分布として，一様分布を用いた場合について説明する．
いま，あるルールの確率に関して，事前知識が全くないものと考えると，
すべての確率値の事前確率について同じ値とするのが自然である．
$\theta$は[0,1]を定義域とする連続の確率変数であり，$p(\theta)$は
密度関数であるから，

\begin{equation}
	p(\theta) = 1
\end{equation}
とすればよい．そうすると，事後分布は次のようになる．

\begin{eqnarray}
p(\theta | y)
&=& \frac{\theta^k (1-\theta)^{n-k}}{\int_0^1 {\theta^k (1-\theta)^{n-k}} d\theta} \\
	&=& \frac{\theta^{(k+1)-1} (1-\theta)^{(n+2)-(k+1)-1}}{\int_0^1 {\theta^{(k+1)-1} (1-\theta)^{(n+2)-(k+1)-1}} d\theta}
\end{eqnarray}
この確率分布は，ベータ分布と呼ばれ，
期待値は次式で与えられる\cite{鈴木:ベイズ}．

\begin{equation}
	E[\theta] = \frac{k+1}{n+2}
\end{equation}

いま，$k$と$n$は，それぞれ，$f(C_A, E_i)$と$f(E_i)$に対応している
のだから，

\begin{equation}
\label{eq:myreliability}
	（信頼度）=P(C_A|E_i)=\frac{f(C_A, E_i)+1}{f(E_i)+2}
\end{equation}
となる．結論は非常にシンプルである．すなわち，頻度$f(C_A, E_i)$と
$f(E_i)$をそのまま用いる代わりに，$f(C_A, E_i)+1$と
$f(E_i)+2$を用いればよい，ということである．


事前分布の利用による確率値の正確な推定
前章では，ベイズ学習において事前情報が全くないものとし，
事前分布を一様分布として事後分布の導出を行なった．
しかし，\ref{sc:experiments}章で述べる実験結果から明らかなように，
実際の正解率と，ベイズ学習による確率から計算された期待正解率との
間には開きがある．これは，推定された確率が真の確率からずれている
ことを示している．この原因には，以下の3つが考えられる．

\begin{itemize}
\item トレーニングデータ vs. テストデータ

  もし，学習のためのトレーニングデータと，テストデータの性質が
異なっている場合，実際の正解率は低下する．これは，コーパスベースの
手法の本質的な問題である．

\item Global vs. history-conditional

 決定リストにおいて，あるルールが適用されるということは，そのルールより
上位のルールが，その文脈に適用できなかったことを示している．
したがって，確率値はその条件を反映したものでなければならない．
ところが，
式（\ref{eq:myreliability}）では，そのような条件を考慮せず，単に事例全体の中での確率しか
考慮していない．そのような条件を考慮した確率値を算出するためには，
決定木を構成するように，決定リストにルールを追加するたびに，
それに適合する事例を削除していく，というようなことをする必要がある．
しかし，そのようにすると，下位にいくにしたがって
事例の数が少なくなっていくため，確率値の推定誤差が大きくなって
しまうことや，計算量が事例数の2乗に比例するようになってしまうという
問題がある．
文献 \cite{Yarowsky:Hierarchical}では，
ルールの確率値を，上記の２つの確率，すなわち事例全体の中での確率と，
上位のルールにマッチしなかったという条件付き確率との
重み付き平均をとることによって計算している．


\item 事前分布

 前章では，事前分布を一様分布と仮定した．しかし，例えば，
分類すべきクラスの数が5個あり，学習者が全く情報を持たないと
すれば，特定のクラスを出力するルールが正解する確率の
事前分布としては 0.2 を期待値とするような分布
であるべきであろう．しかし，一様分布の期待値は 0.5 である．
この例からもわかるように，
一様分布はどんな場合でも適切な事前分布というわけではない．

\end{itemize}

上記の三つの問題に対して，最初の二つの問題については本論文では扱わない．
本章では，他のルールの確率値を利用して適切な事前分布を設定する手法を提案する．





\vspace{-0.5mm}
事前分布とは，$\theta$に関するデータがない段階で仮定される，$\theta$が
とる値の確率分布である．いま，$\theta$は，あるルールの確率を
表しているが，ここで $\theta$を単独で考えるのではなく，
$\theta$は，同じ証拠タイプ内の他の多くのルールの
確率値と同じような性質を持っている
と考えることにする．つまり，あるルールの事前分布を，他の
ルールの確率値を利用して構成する\footnote{
このような考え方は，経験ベイズと呼ばれることもある \cite{gelman:bayesian}．
また，ベイズ統計の枠組を用いてはいないが，
単語の出現確率の代表的なディスカウンティング
手法であるグッド・チューリング推定法の考え方ともよく似ている\cite{北:確率的}．}

まず，ルールの確率値の分布がどのような性格を持っているのかを
見るために，実際のルールの確率値の分布の例を図\ref{fig:distribution}に示す．
これは，\ref{sc:experiments}章の実験で用いられた多義語accident
において，それぞれの証拠のタイプに属するルールの確率値の，
正規化されたヒストグラムを示したものである（グラフ中の曲線については後述する）．
ただし，各々のルールの確率値は，事前分布を一様分布としたベイズ学習
により算出し，出現回数が10回未満のルールは除いている．

ここで，ルールの確率値の統計的性質は，
そのルールの証拠の事例数に依存しない
と仮定すれば，図\ref{fig:distribution} に示したような，事例の数が
多いルールの実際の確率値の分布を利用して，事前分布を構成することができる．
事前分布の確率分布としては，ベータ分布を採用する．
ベータ分布は，ベルヌーイ試行において自然共役事前分布と呼ばれる
確率分布であり，事後分布の導出が解析的に可能であることが知られている\cite{繁桝:ベイズ}．
ベータ分布は，2つのパラメータによって決定されるが，本論文では
最も簡単なパラメータ推定法の一つであるモーメント法によって
パラメータを決定する．モーメント法とは，母集団$j$次モーメント
\begin{equation}
E_{(a,b)}[\theta^j] = \int \theta^j p(\theta) d\theta
\end{equation}
と，標本$j$次モーメント
\begin{equation}
\mu_j = \frac{1}{m}\sum_{i=1}^m (\frac{k_i+1}{n_i+2})^j
\end{equation}
がそれぞれ等しいと置いた連立方程式を得くことでパラメータ$a,b$を
計算する方法である．
図\ref{fig:distribution}の
グラフ中の曲線は，ヒストグラムで示した確率値のデータから，モーメント法
によって得たベータ分布を表している．


\begin{figure}
\begin{center}
\epsfile{file=window.eps,width=4.6cm,height=4.6cm}
\epsfile{file=adjacent.eps,width=4.6cm,height=4.6cm}
\epsfile{file=pair.eps,width=4.6cm,height=4.6cm}
\end{center}
\caption{ルールの確率値の分布}
\label{fig:distribution}
\end{figure}

以下に事前分布をベータ分布とした場合の，事後分布の
導出の過程を示す．まず，ベータ分布は次の式で与えられる．

\begin{equation}
p(\theta) = \frac{1}{B(a, b)}\theta^{(a-1)}(1-\theta)^{(b-1)}
\end{equation}
ただし，$B(a, b)$ はベータ関数

\begin{equation}
B(a, b) =  \int_0^1 {\theta^{(a-1)}(1-\theta)^{(b-1)}} d\theta
\end{equation}
である．

ベータ分布の1次モーメントは，
\begin{equation}
\frac{a}{a + b}
\end{equation}

2次モーメントは，
\begin{equation}
\frac{a+1}{a + b + 1} \cdot \frac{a}{a+b}
\end{equation}
で与えられるから，同じタイプの証拠に属し，出現頻度が
閾値（本論文では10とした）
以上のルールの確率値の，1次モーメント，2次モーメントを
それぞれ $\mu_1,\mu_2$とすれば，ベータ分布の2つのパラメータは，
\begin{eqnarray}
a &=& \frac{\mu_1(\mu_1 - \mu_2)}{\mu_2 - \mu_1^2} \\
b &=& \frac{(\mu_1 - \mu_2)(1 - \mu_1)}{\mu_2 - \mu_1^2}
\end{eqnarray}
と指定すればよい．


この事前分布を式（\ref{eq:post}）に代入することにより，
事後分布は次のようになる．

\begin{equation}
p(\theta|A) = \frac{1}{B(a+k, b+n-k)}\theta^{(a+k-1)}(1-\theta)^{(b+n-k-1)}
\end{equation}

事後分布の期待値，すなわちルールの信頼度は次のように得られる．
\begin{equation}
	E[\theta] = \frac{a+k}{a+b+n}
\end{equation}

このように，信頼度は最終的に加算スムージングのような形式で得られる
ことから，信頼度の計算自体は非常に簡単に行なうことができる．
\vspace{-2pt}
