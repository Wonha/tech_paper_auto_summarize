実験 \label{sc:experiments}

提案手法の有効性を確かめるため，決定リストを用いて，
英語の語義曖昧性解消と，日本語の疑似単語判定問題に関して実験を
行なった．語義曖昧性解消とは，多義語の語義を文脈から判定する
問題で，自然言語処理における典型的なクラス分類問題である．
また，疑似単語判定とは，複数の単語をシステムの側からは単一の単語に
しか見えないようにしておき，どの単語であるのかを文脈から判定
させるという問題である．この問題は，人工的な語義曖昧性解消問題と
いうことができる．

実験によって評価すべき点は二つある．一つはもちろん，クラス分類の
正解率である．従来手法と比べて，正解率が向上するかどうかを評価する．
もう一つは，出力する確率値の正確さである．つまり，
ルールの確率値が，どの程度正確に推定できているかということである．
それを評価するために，「期待正解率」というものを考える．
これは，それぞれの分類に用いられたルールの確率値を平均
したものである．もし，確率値の推定が理想的に行なわれたとすれば，
実際の正解率と，期待正解率はほぼ等しくなるはずである．すなわち，
実際の正解率と期待正解率のずれは，確率値の推定の「悪さ」を表す
ことになる．

比較対象とする従来手法は以下の二つである．

\begin{itemize}
\item 間引き

出現回数が閾値未満の証拠のルールは使用しないようにする手法．
ルールの確率値は式（\ref{eq:reliability}），すなわち最尤推定により算出する．
確率値が等しい場合は，出現回数の多いルールを優先する．

\item 対数尤度比

式（\ref{eq:yarowsky1}）を用いる手法．
文献\cite{Yarowsky:Decision}\cite{新納:複合語}などで用いられている．
この場合，式（\ref{eq:yarowsky1}）の分母が0になってしまう可能性があるため，
頻度の比の式の分母と分子に小さな値 $\alpha$ を足す．このようにすることで，
分母が0になってしまう問題を防げる．また，同じ確率であれば，
頻度の高い証拠のルールを優先することとした．

\end{itemize}

\subsection{Senseval-1データセットによる実験}

英語の語義曖昧性解消については，語義曖昧性解消の競技会である Senseval-1
のデータセットが公開されているので，それを利用して実験を行なった
\footnote{http://www.itri.brighton.ac.uk/events/senseval/}. 
Senseval-1データセットには，訓練データが利用可能な多義語が36個
含まれている．表\ref{tab:senseval1}に，それぞれの多義語の
語義数，訓練事例数，テスト事例数を示す．

\begin{table*}
  \caption{Senseval-1 データセット}
  
  \label{tab:senseval1}
\begin{center}
\renewcommand{\arraystretch}{}
\begin{tabular}{|lcrrr|lcrrr|} \hline
       &      &        & 訓練~  & テスト &
       &      &        & 訓練~  & テスト \\
多義語 & 品詞 & 語義数 & 事例数 & 事例数 &
多義語 & 品詞 & 語義数 & 事例数 & 事例数 \\
\hline
    accident & n &   8 & 1234 &  267 &        giant & a &   5 &  315 &   97 \\ 
       amaze & v &   1 &  133 &   70 &        giant & n &   7 &  342 &  118 \\ 
        band & p &  32 & 1326 &  302 &       invade & v &   6 &   45 &  207 \\ 
   behaviour & n &   3 &  994 &  279 &         knee & n &  22 &  417 &  251 \\ 
         bet & n &  15 &  106 &  273 &       modest & a &   9 &  374 &  270 \\ 
         bet & v &   9 &   59 &  116 &        onion & n &   4 &   26 &  214 \\ 
      bitter & p &  17 &  144 &  372 &      promise & n &   8 &  586 &  113 \\ 
      bother & v &   8 &  282 &  209 &      promise & v &   6 & 1160 &  224 \\ 
   brilliant & a &  10 &  440 &  229 &         sack & n &  11 &   97 &   82 \\ 
        bury & v &  14 &  272 &  201 &         sack & v &   4 &  185 &  178 \\ 
   calculate & v &   5 &  218 &  218 &     sanction & p &  10 &   96 &  431 \\ 
     consume & v &   6 &   56 &  183 &        scrap & n &  14 &   27 &  156 \\ 
      derive & v &   6 &  255 &  217 &        scrap & v &   3 &   30 &  186 \\ 
      excess & n &   8 &  178 &  186 &        seize & v &  11 &  287 &  259 \\ 
       float & n &  12 &   61 &   75 &        shake & p &  39 &  963 &  356 \\ 
       float & v &  16 &  182 &  229 &        shirt & n &   8 &  531 &  184 \\ 
    floating & a &   5 &   39 &   47 &       slight & a &   6 &  380 &  218 \\ 
    generous & a &   6 &  307 &  227 &       wooden & a &   4 &  361 &  196 \\ 
\hline
\end{tabular}
\end{center}
\vspace{0.5mm}
\begin{flushright}
（品詞がpとは品詞情報が判定システムに与えられないことを示す）
\end{flushright}
\end{table*}

本実験では，品詞タグ付けなどの前処理は行わず，生のテキストデータを利用して
決定リストの学習と評価を行なった．

従来手法に関しては，最も良い場合と比較するため，間引きの閾値を
変化させて，最も正解率が高くなる値を採用した．本データセットに
関しては，最も良い閾値は2であった．
また，対数尤度比でのスムージングのパラメータ $\alpha$に関しても
0.1きざみで変化させ，最も正解率が高くなる値を採用した．本データセット
に関しては，最も良い$\alpha$は0.9 であった．

表\ref{tab:basic}に結果を示す．表中の数字は正解率を表している．
正解率の右側にある括弧内の数字は，先に述べた「期待正解率」との差の
絶対値を表している．この値が小さいほど，確率値の推定が正確である
ことを示している．

\begin{table*}
  \caption{Senseval-1 データセットによる評価}
  
  \label{tab:basic}
\begin{center}
\renewcommand{\arraystretch}{}
\begin{tabular}{l|c|cc|c|cc|cc} \hline
     &       &   &         &           & \multicolumn{2}{c|}{ベイズ} & \multicolumn{2}{c}{ベイズ}   \\
単語 & 品詞  & \multicolumn{2}{c|}{間引き}     & 対数尤度比 & \multicolumn{2}{c|}{一様分布} & \multicolumn{2}{c}{ベータ分布} \\
\hline
  accident & n  & 85.0\% & (13.6) & 85.0\% & 83.9\% & (7.8) & 89.9\% & (3.2) \\
     amaze & v  & 100.0\% & (0.1) & 100.0\% & 100.0\% & (1.0) & 100.0\% & (0.2) \\
      band & p  & 86.8\% & (11.4)  & 84.4\%  & 84.1\% & (5.9) & 87.4\% & (2.6) \\
 behaviour & n  & 95.3\% & (4.6) & 94.6\%  & 94.6\% & (2.7) & 94.6\% & (3.1) \\
       bet & n  & 48.4\% & (30.7)  & 44.3\%  & 45.1\% & (27.8) & 50.5\% & (9.5) \\
       bet & v  & 66.4\% & (26.2) & 69.0\%  & 70.7\% & (10.1) & 76.7\% & (2.3) \\
    bitter & p  & 44.9\% & (31.9) & 49.2\%  & 49.2\% & (22.2) & 51.1\% & (4.0) \\
    bother & v  & 76.1\% & (18.8) & 78.5\%  & 78.5\% & (5.5) & 78.0\% & (5.1) \\
 brilliant & a  & 48.5\% & (33.6) & 48.5\%  & 47.6\% & (24.9) & 49.3\% & (11.7) \\
      bury & v  & 44.3\% & (34.7) & 49.8\%  & 49.3\% & (22.4) & 49.3\% & (10.0) \\
 calculate & v  & 88.5\% & (11.0) & 86.7\%  & 86.7\% & (2.6) & 86.7\% & (2.8) \\
   consume & v  & 43.7\% & (37.1) & 42.1\%  & 42.6\% & (29.1) & 42.1\% & (18.3) \\
    derive & v  & 55.3\% & (33.1) & 53.9\%  & 54.4\% & (20.8) & 64.1\% & (3.5) \\
    excess & n  & 79.6\% & (13.8) & 81.7\%  & 81.7\% & (8.9) & 81.2\% & (9.7) \\
     float & n  & 50.7\% & (38.4) & 53.3\%  & 53.3\% & (21.8) & 56.0\% & (5.3) \\
     float & v  & 41.5\% & (38.0) & 45.4\%  & 45.0\% & (27.7) & 42.8\% & (16.5) \\
  floating & a  & 63.8\% & (20.5) & 59.6\%  & 59.6\% & (13.0) & 61.7\% & (7.7) \\
  generous & a  & 44.1\% & (36.9) & 48.9\%  & 49.3\% & (23.5) & 46.7\% & (9.8) \\
     giant & a  & 97.9\% & (1.5) & 96.9\%  & 96.9\% & (1.9) & 96.9\% & (0.9) \\
     giant & n  & 74.6\% & (20.1)  & 78.8\%  & 79.7\% & (5.9) & 79.7\% & (4.2) \\
    invade & v  & 44.4\% & (35.0) & 46.4\%  & 46.9\% & (24.4) & 50.2\% & (15.1) \\
      knee & n  & 71.3\% & (18.8) & 70.5\%  & 70.9\% & (8.3) & 72.9\% & (0.2) \\
    modest & a  & 66.7\% & (24.0) & 67.0\%  & 66.3\% & (10.8) & 66.3\% & (2.5) \\
     onion & n  & 84.6\% & (15.1) & 84.6\%  & 84.6\% & (6.5) & 84.6\% & (9.8) \\
   promise & n  & 74.3\% & (19.8) & 74.3\%  & 74.3\% & (7.4) & 74.3\% & (5.4) \\
   promise & v  & 87.5\% & (12.0) & 88.4\% & 88.4\% & (5.4) & 92.9\% & (1.7) \\
      sack & n  & 82.9\% & (10.1) & 85.4\%  & 81.7\% & (3.3) & 85.4\% & (2.6) \\
      sack & v  & 97.8\% & (2.3) & 97.8\%  & 97.8\% & (0.6) & 97.8\% & (1.5) \\
  sanction & p  & 72.6\% & (21.9)  & 74.5\%  & 74.5\% & (7.6) & 77.7\% & (2.3) \\
     scrap & n  & 42.3\% & (47.6) & 41.7\%  & 41.7\% & (38.7) & 45.5\% & (31.8) \\
     scrap & v  & 87.6\% & (11.7) & 87.6\%  & 87.6\% & (1.8) & 87.6\% & (4.5) \\
     seize & v  & 59.5\% & (26.9) & 60.6\%  & 60.2\% & (17.1) & 64.5\% & (4.3) \\
     shake & p  & 60.1\% & (25.0) & 62.1\%  & 61.2\% & (19.7) & 61.2\% & (17.6) \\
     shirt & n  & 82.1\% & (13.0) & 83.7\%  & 83.7\% & (3.7) & 82.6\% & (2.6) \\
    slight & a  & 90.8\% & (8.3) & 94.0\% & 94.0\% & (0.3) & 94.0\% & (0.8) \\
    wooden & a  & 93.9\% & (6.1) & 93.9\% & 93.9\% & (3.1) & 93.9\% & (3.9) \\
\hline
平均 &  & 70.4\% & (20.9)  & 71.2\% & 71.1\% & (12.3) & 72.7\% & (6.6) \\
\hline
\end{tabular}
\end{center}

\vspace{0.5mm}
\begin{flushright}
（括弧内の数字は正解率と期待正解率との差）
\end{flushright}
\end{table*}

まず，正解率に関して見ると，間引きの正解率が最も低い．
これは，間引きによって重要なルールを
捨ててしまっていることが原因だと考えられる．対数尤度比による
手法と，事前分布を一様分布としてベイズ学習による手法が，
ほぼ同じ正解率である．ただし，ここで注意するべきなのは，
対数尤度比による手法では，スムージングのパラメータに関して，
正解率が最もよくなるようにチューニングがなされたうえでの結果だ
ということである．事前分布を一様分布としたベイズ学習による
手法は，そのようなチューニングを全く必要としないにもかかわらず，
それとほぼ同じ正解率を達成している．また，期待正解率と実際の正解率
とのずれに関しても，最尤推定（間引き）に比べてかなり小さく，
ベイズ学習による推定の有効性を示している．

最も正解率が高いのは，他のルールの確率値を利用してベータ分布によって事前分布を
構成する手法である\footnote{ただし，本手法で得られた正解率（72.7\%）は
，Senseval-1参加システムでの最高正解率（78.9\%）\cite{Yarowsky:Hierarchical}
よりも低い．本論文では正解率を追求することが目的ではないため，
stemming や品詞タグ付けなどの前処理を行なっていない．そのような
前処理や，\cite{Yarowsky:Hierarchical}のような言語学的知識を利用した
決定リストの階層化などを行なえば，正解率を上昇させることは可能だと考えられる．
}
．これは，適切な事前分布によって，ルールの確率値
の推定が正確になり，本当に信頼できるルールが上位に位置するように
なったからだと考えられる．そのことを裏付けるように，
実際の正解率と期待正解率のずれが，一様分布の場合と比較して半減している．
つまり，確率値の推定がそれだけ正確になったということを示している．


\subsection{日本語の疑似単語判定の実験}

日本語の語義曖昧性解消に関しては，
Senseval-1 のようなデータセットが公開されていない
ことから，疑似単語を用いて実験を行なった．
疑似単語とは，複数の異なる単語を判定システムの側からは同一の単語にしか
見えないようにし，文脈からどの単語であるのかを判定させる手法である．
例えば，「銀行」という単語と，「土手」という単語を用いて疑似単語
を作ったとすると，判定システムからは，入力文は例えば，
\begin{center}
... お金をおろしに＊＊へ行く途中 ...
\end{center}
\noindent
のように見える．＊＊の部分が疑似単語である．
そして，文脈から，「銀行」であるのか「土手」であるの
かを判定させるというわけである．これは，文脈から多義語の語義の判定を行う
多義性解消の問題とかなり似た問題になる．

実験に用いる疑似単語に関しては，ベースラインとしての正解率
（単純に最も出現頻度の高い単語を選ぶ方法の正解率）
が高くならないように，一つの疑似単語を構成する各々の単語の出現頻度が
ほぼ等しくなるようにして構成した．
コーパスとしては，「CD-毎日新聞97年版」を
JUMAN version 3.6 \cite{juman}で形態素解析したものを用いた．
事例の数に関しては，各々の疑似単語について，
1024の訓練事例，1000のテスト事例を重なりがないように
コーパスからランダムに抽出して，トレーニングとテストを行なった．

\begin{table*}
  \caption{日本語疑似単語による評価}
  
  \label{tab:comp}
\begin{center}
\begin{tabular}{l|c|c|c|c} \hline
               	&	&		&ベイズ 	&ベイズ\\
疑似単語 	&間引き	&対数尤度比	&一様分布	&ベータ分布\\
\hline
政策／テレビ		&90.4\%	(7.1)&92.4\%	&92.0\% (1.5)&92.6\% (2.5)	\\
大統領／首相		&84.9\%	(9.9)&90.5\%	&88.6\% (0.0)&89.4\% (1.2)	\\
仕事／言葉／資金／文化	&66.2\%	(18.8)&72.8\%	&71.6\% (9.6)&75.1\% (6.3)	\\
持つ／含む		&83.7\%	(13.1)&87.2\%	&86.6\% (2.3)&90.3\% (0.9)	\\
考える／見る／目指す	&67.8\%	(17.8)&67.6\%	&70.5\% (8.4)&73.6\% (2.1)	\\
入る／示す／開く／進める&73.1\%	(15.2)&77.2\%	&76.3\% (6.8)&79.3\% (2.8)	\\
近い／難しい		&84.1\%	(12.3)&88.5\%	&88.6\% (2.0)&90.5\% (0.2)	\\
新しい／高い／強い	&65.7\%	(18.2)&68.9\%	&68.7\% (10.1)&72.6\% (2.6)	\\
若い／厳しい／大きい／よい &67.8\%	(16.3)&72.8\%	&72.0\% (7.8) &77.4\% (1.4)	\\
\hline
平均			&76.0\%	(14.3)&79.8\%	&79.4\% (5.4)&82.3\% (2.2)	\\
\hline
\end{tabular}
\end{center}

\vspace{0.5mm}
\begin{flushright}
（括弧内の数字は正解率と期待正解率との差）
\end{flushright}

\end{table*}

\begin{table*}
  \caption{事前分布の期待値}
  
  \label{tab:prior}
\begin{center}
\begin{tabular}{l|c|c|c} \hline
疑似単語 			&Window &Adjacent	&Pair	 \\
\hline
政策／テレビ			&0.74	&0.77	&0.82  \\
大統領／首相			&0.67   &0.75   &0.80  \\
仕事／言葉／資金／文化		&0.54   &0.64   &0.70  \\
持つ／含む			&0.70   &0.82   &0.89  \\
考える／見る／目指す		&0.57   &0.65   &0.68  \\
入る／示す／開く／進める	&0.51   &0.54   &0.72  \\
近い／難しい			&0.68   &0.74   &0.85  \\
新しい／高い／強い		&0.54   &0.64   &0.64  \\
若い／厳しい／大きい／よい 	&0.48   &0.64   &0.71  \\
\hline
\end{tabular}
\end{center}
\end{table*}

従来手法のパラメータに関しては，英語の多義語での実験と同様に，正解率が最も
高くなる値を採用した．間引きの閾値に関しては 3，対数尤度比のスムージング
パラメータ $\alpha$に関しては 0.4とした．

表\ref{tab:comp}に結果を示す．傾向は，表\ref{tab:basic}に示した
英語の多義語での結果とほとんど同じである．最も正解率が悪いのは，
間引きによる手法である．一様分布のベイズ学習は，対数尤度比とほぼ同じ正解率を
達成している．最も正解率が高いのは，
他のルールの確率値を利用してベータ分布によって事前分布を構成する手法である．

ここで，事前分布をベータ分布とした場合の，証拠のタイプによる事前分布の
違いを見るために，表\ref{tab:prior}に事前分布の期待値を示す．この
表からわかるように，事前分布の期待値の傾向は，$Window < Adjacent < Pair$
となっている．すなわち，あるルールに関して何もデータがなければ，
そのルールがWindowであるよりもAdjacentである方が，さらに，
AdjacentであるよりもPairである方が信頼できるということである．これは，
より詳細な文脈情報を用いた方が正確な判断ができるという
我々の直感とも一致する．
また，これらの事前分布に影響によって，最終的な信頼度も
全体として，PairやAdjacentのルールが上位に位置することになる．


\clearpage
