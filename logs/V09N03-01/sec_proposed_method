決定リストとは，クラス分類のためのルールを，その信頼度の高い順に並べたものである．
それぞれのルールは，「もし（証拠[MATH]）ならば，クラスは[MATH]である」という形式をしている．
証拠というのは，判定の手がかりとなる事例の特徴である．
例として，英語の多義語plant（A:植物, B:工場）に関してYarowskyが行なった実験での決定リストを表[REF_tab:ex_dlist]に示す[CITE]．
最上位のルールは，「右隣にlifeという単語があったら，語義はA」という意味，4番目のルールは，「距離2〜10単語以内にmanufacturingという単語があったら，語義はB」という意味である．
実際にクラスの分類を行なう際には，その事例に対して適用可能なルールのうち，最も上位のルールを用いて分類が行なわれる．
例えば入力文が，
.
..
divide life into plant and animal kingdom .
..
であるとすると，適用可能なルールのうち最上位なのは3番目のルールであるから，plantの語義はAだと判定されることになる．
このように，決定リストによる手法では，他の多くの機械学習手法と異なり，特徴を単独で利用する．
単独でしか利用しないのは一見不利なようであるが，語義曖昧性解消などの，文脈の語彙的な特徴を利用する問題に関しては，単独の証拠が分類の決定的な証拠になることが多いため，決定リストによる手法が有効であるといわれている．
本論文で提案する決定リストのルール信頼度の推定手法は，特定の自然言語処理に特化したものではないが，本論文では，決定リストの適用例として，上記のような語義曖昧性解消の問題を取り上げる．
ここで，本論文で用いる文脈上の特徴を以下に示す．
{Window}
ターゲットから，距離10単語以内に出現する単語
{Adjacent}
ターゲットの左隣に出現する単語
ターゲットの右隣に出現する単語
{Pair}
ターゲットの左隣にある単語対
ターゲットを挟む単語対
ターゲットの右隣にある単語対
すなわち，文脈情報としての詳細さが異なる三つのタイプの特徴を利用する．
文脈情報として最も詳細なのはPairであり，最も粗いのがWindowである．
決定リストは，事例とその正解ラベルを含む訓練コーパスから作成される．
決定リストの作成において最も重要な問題は，それぞれのルールの信頼度の計算法である．
文献[CITE]では，次の式に従って信頼度を計算している．
すなわち，証拠[MATH]のもとでクラス（語義）がAである確率と，同じ証拠[MATH]のもとでクラスがBである確率との比の対数をとったものである．
従来の決定リストを用いた自然言語処理の研究では，ルールの信頼度の算出法として，式（[REF_eq:yarowsky]），あるいは，式（[REF_eq:yarowsky]）をクラスが3つ以上の場合でも適用できるように変形した次の式，
が用いられることが多い[CITE]．
また，対数をとらずに，
とする場合もある[CITE]．
ここで，式（[REF_eq:reliability]）と式（[REF_eq:yarowsky1]）を見比べてみると，式（[REF_eq:yarowsky1]）は，式（[REF_eq:reliability]）に関して単調増加であり，決定リストでは信頼度の大小関係しか問題にならないのだから，後述するスムージングの問題を考慮しなければ，式（[REF_eq:yarowsky1]）を用いた場合と，式（[REF_eq:reliability]）を用いた場合では，結果的に作成される決定リストは等価になる．
一般にクラス分類器の目標は，分類の正解率を最大にすることであるから，ルールの信頼度としては，そのルールが正解する確率である式（[REF_eq:reliability]）を用いるのが自然である．
また，クラス分類器が，自然言語処理システムの一部を構成している場合，分類の信頼度は確率として出力された方が扱いやすいことが多い．
そこで本論文では，ルールの信頼度として式（[REF_eq:reliability]）を用いることにする．
式（[REF_eq:reliability]）の値は，訓練事例が多ければ，ベルヌーイ試行における最尤推定により，次のように計算することができる．
ただし，[MATH]は，クラスAに属するターゲットと証拠[MATH]が同時に出現した回数．
[MATH]は，証拠[MATH]の出現回数である．
ところが，通常は出現回数が少ない証拠も多い．
例えば，
の場合，信頼度は[MATH]と計算されるが，たった一つの事例しかないのに，その信頼度は100%，すなわち最も信頼度の高いルールだとみなされてしまう．
このように，出現回数の少ない事例において，そのままでは統計的に信頼性のある確率値が算出できないことをスパースネスの問題という．
そこで本論文では，ベイズ学習の手法を用いてこの問題の解決を試みる．
いま，求めたいルールの確率値を[MATH]とする．
最尤推定の枠組では，確率モデルの尤度が最大となるように[MATH]を決定するが，ベイズ学習の枠組では，[MATH]を確率変数と考えて，その確率分布を求める問題と考える．
本論文では，得られた確率分布を決定リストのルールの信頼度として利用したいのだから，その確率分布から[MATH]の期待値を計算して利用すればよい．
訓練コーパスにおいて，確率を求めたいルールに関する事例が[MATH]個あり，そのうちの[MATH]個において，そのルールが正しいというデータがあるとする．
このデータを[MATH]とすると，データ[MATH]を観測した後の[MATH]の事後密度は，
で与えられる．
ここで，事象[MATH]はベルヌーイ試行と考えられるから，その確率は二項分布により次のように与えられる．
これを式（[REF_eq:jigo]）に代入して，
を得る．
ここで，事前分布[MATH]をどのように設定するのか，という問題が浮上する．
事前分布は，[MATH]について学習者が持っている事前知識を表す．
ベイズ学習における事前分布の設定方法に関しては，大きく分けて2つのアプローチがある．
一つは，できるだけ公平で無知の状態を表すように事前分布を設定する方法である．
そのような事前分布としては，一様分布やJeffreysの無情報事前分布などが提案されている[CITE]．
もう一つは，学習者が事前に持っている知識を積極的に表現するような事前分布を設定する方法である．
まず，無知の状態を表す事前分布として，一様分布を用いた場合について説明する．
いま，あるルールの確率に関して，事前知識が全くないものと考えると，すべての確率値の事前確率について同じ値とするのが自然である．
[MATH]は[0,1]を定義域とする連続の確率変数であり，[MATH]は密度関数であるから，
とすればよい．
そうすると，事後分布は次のようになる．
この確率分布は，ベータ分布と呼ばれ，期待値は次式で与えられる[CITE]．
いま，[MATH]と[MATH]は，それぞれ，[MATH]と[MATH]に対応しているのだから，
となる．
結論は非常にシンプルである．
すなわち，頻度[MATH]と[MATH]をそのまま用いる代わりに，[MATH]と[MATH]を用いればよい，ということである．
前章では，ベイズ学習において事前情報が全くないものとし，事前分布を一様分布として事後分布の導出を行なった．
しかし，[REF_sc:experiments]章で述べる実験結果から明らかなように，実際の正解率と，ベイズ学習による確率から計算された期待正解率との間には開きがある．
これは，推定された確率が真の確率からずれていることを示している．
この原因には，以下の3つが考えられる．
トレーニングデータvs.テストデータ
もし，学習のためのトレーニングデータと，テストデータの性質が異なっている場合，実際の正解率は低下する．
これは，コーパスベースの手法の本質的な問題である．
Global vs. history-conditional
決定リストにおいて，あるルールが適用されるということは，そのルールより上位のルールが，その文脈に適用できなかったことを示している．
したがって，確率値はその条件を反映したものでなければならない．
ところが，式（[REF_eq:myreliability]）では，そのような条件を考慮せず，単に事例全体の中での確率しか考慮していない．
そのような条件を考慮した確率値を算出するためには，決定木を構成するように，決定リストにルールを追加するたびに，それに適合する事例を削除していく，というようなことをする必要がある．
しかし，そのようにすると，下位にいくにしたがって事例の数が少なくなっていくため，確率値の推定誤差が大きくなってしまうことや，計算量が事例数の2乗に比例するようになってしまうという問題がある．
文献[CITE]では，ルールの確率値を，上記の２つの確率，すなわち事例全体の中での確率と，上位のルールにマッチしなかったという条件付き確率との重み付き平均をとることによって計算している．
事前分布
前章では，事前分布を一様分布と仮定した．
しかし，例えば，分類すべきクラスの数が5個あり，学習者が全く情報を持たないとすれば，特定のクラスを出力するルールが正解する確率の事前分布としては0.2を期待値とするような分布であるべきであろう．
しかし，一様分布の期待値は0.5である．
この例からもわかるように，一様分布はどんな場合でも適切な事前分布というわけではない．
上記の三つの問題に対して，最初の二つの問題については本論文では扱わない．
本章では，他のルールの確率値を利用して適切な事前分布を設定する手法を提案する．
事前分布とは，[MATH]に関するデータがない段階で仮定される，[MATH]がとる値の確率分布である．
いま，[MATH]は，あるルールの確率を表しているが，ここで[MATH]を単独で考えるのではなく，[MATH]は，同じ証拠タイプ内の他の多くのルールの確率値と同じような性質を持っていると考えることにする．
つまり，あるルールの事前分布を，他のルールの確率値を利用して構成する
まず，ルールの確率値の分布がどのような性格を持っているのかを見るために，実際のルールの確率値の分布の例を図[REF_fig:distribution]に示す．
これは，[REF_sc:experiments]章の実験で用いられた多義語accidentにおいて，それぞれの証拠のタイプに属するルールの確率値の，正規化されたヒストグラムを示したものである（グラフ中の曲線については後述する）．
ただし，各々のルールの確率値は，事前分布を一様分布としたベイズ学習により算出し，出現回数が10回未満のルールは除いている．
ここで，ルールの確率値の統計的性質は，そのルールの証拠の事例数に依存しないと仮定すれば，図[REF_fig:distribution]に示したような，事例の数が多いルールの実際の確率値の分布を利用して，事前分布を構成することができる．
事前分布の確率分布としては，ベータ分布を採用する．
ベータ分布は，ベルヌーイ試行において自然共役事前分布と呼ばれる確率分布であり，事後分布の導出が解析的に可能であることが知られている[CITE]．
ベータ分布は，2つのパラメータによって決定されるが，本論文では最も簡単なパラメータ推定法の一つであるモーメント法によってパラメータを決定する．
モーメント法とは，母集団[MATH]次モーメント
と，標本[MATH]次モーメント
がそれぞれ等しいと置いた連立方程式を得くことでパラメータ[MATH]を計算する方法である．
図[REF_fig:distribution]のグラフ中の曲線は，ヒストグラムで示した確率値のデータから，モーメント法によって得たベータ分布を表している．
以下に事前分布をベータ分布とした場合の，事後分布の導出の過程を示す．
まず，ベータ分布は次の式で与えられる．
ただし，[MATH]はベータ関数
である．
ベータ分布の1次モーメントは，
2次モーメントは，
で与えられるから，同じタイプの証拠に属し，出現頻度が閾値（本論文では10とした）以上のルールの確率値の，1次モーメント，2次モーメントをそれぞれ[MATH]とすれば，ベータ分布の2つのパラメータは，
と指定すればよい．
この事前分布を式（[REF_eq:post]）に代入することにより，事後分布は次のようになる．
事後分布の期待値，すなわちルールの信頼度は次のように得られる．
このように，信頼度は最終的に加算スムージングのような形式で得られることから，信頼度の計算自体は非常に簡単に行なうことができる．
