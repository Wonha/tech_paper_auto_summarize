提案手法の有効性を確かめるため，決定リストを用いて，英語の語義曖昧性解消と，日本語の疑似単語判定問題に関して実験を行なった．
語義曖昧性解消とは，多義語の語義を文脈から判定する問題で，自然言語処理における典型的なクラス分類問題である．
また，疑似単語判定とは，複数の単語をシステムの側からは単一の単語にしか見えないようにしておき，どの単語であるのかを文脈から判定させるという問題である．
この問題は，人工的な語義曖昧性解消問題ということができる．
実験によって評価すべき点は二つある．
一つはもちろん，クラス分類の正解率である．
従来手法と比べて，正解率が向上するかどうかを評価する．
もう一つは，出力する確率値の正確さである．
つまり，ルールの確率値が，どの程度正確に推定できているかということである．
それを評価するために，「期待正解率」というものを考える．
これは，それぞれの分類に用いられたルールの確率値を平均したものである．
もし，確率値の推定が理想的に行なわれたとすれば，実際の正解率と，期待正解率はほぼ等しくなるはずである．
すなわち，実際の正解率と期待正解率のずれは，確率値の推定の「悪さ」を表すことになる．
比較対象とする従来手法は以下の二つである．
間引き
出現回数が閾値未満の証拠のルールは使用しないようにする手法．
ルールの確率値は式（[REF_eq:reliability]），すなわち最尤推定により算出する．
確率値が等しい場合は，出現回数の多いルールを優先する．
対数尤度比
式（[REF_eq:yarowsky1]）を用いる手法．
文献[CITE][CITE]などで用いられている．
この場合，式（[REF_eq:yarowsky1]）の分母が0になってしまう可能性があるため，頻度の比の式の分母と分子に小さな値[MATH]を足す．
このようにすることで，分母が0になってしまう問題を防げる．
また，同じ確率であれば，頻度の高い証拠のルールを優先することとした．
英語の語義曖昧性解消については，語義曖昧性解消の競技会であるSenseval-1のデータセットが公開されているので，それを利用して実験を行なった.
Senseval-1データセットには，訓練データが利用可能な多義語が36個含まれている．
表[REF_tab:senseval1]に，それぞれの多義語の語義数，訓練事例数，テスト事例数を示す．
（品詞がpとは品詞情報が判定システムに与えられないことを示す）
本実験では，品詞タグ付けなどの前処理は行わず，生のテキストデータを利用して決定リストの学習と評価を行なった．
従来手法に関しては，最も良い場合と比較するため，間引きの閾値を変化させて，最も正解率が高くなる値を採用した．
本データセットに関しては，最も良い閾値は2であった．
また，対数尤度比でのスムージングのパラメータ[MATH]に関しても0.1きざみで変化させ，最も正解率が高くなる値を採用した．
本データセットに関しては，最も良い[MATH]は0.9であった．
表[REF_tab:basic]に結果を示す．
表中の数字は正解率を表している．
正解率の右側にある括弧内の数字は，先に述べた「期待正解率」との差の絶対値を表している．
この値が小さいほど，確率値の推定が正確であることを示している．
（括弧内の数字は正解率と期待正解率との差）
まず，正解率に関して見ると，間引きの正解率が最も低い．
これは，間引きによって重要なルールを捨ててしまっていることが原因だと考えられる．
対数尤度比による手法と，事前分布を一様分布としてベイズ学習による手法が，ほぼ同じ正解率である．
ただし，ここで注意するべきなのは，対数尤度比による手法では，スムージングのパラメータに関して，正解率が最もよくなるようにチューニングがなされたうえでの結果だということである．
事前分布を一様分布としたベイズ学習による手法は，そのようなチューニングを全く必要としないにもかかわらず，それとほぼ同じ正解率を達成している．
また，期待正解率と実際の正解率とのずれに関しても，最尤推定（間引き）に比べてかなり小さく，ベイズ学習による推定の有効性を示している．
最も正解率が高いのは，他のルールの確率値を利用してベータ分布によって事前分布を構成する手法である．
これは，適切な事前分布によって，ルールの確率値の推定が正確になり，本当に信頼できるルールが上位に位置するようになったからだと考えられる．
そのことを裏付けるように，実際の正解率と期待正解率のずれが，一様分布の場合と比較して半減している．
つまり，確率値の推定がそれだけ正確になったということを示している．
日本語の語義曖昧性解消に関しては，Senseval-1のようなデータセットが公開されていないことから，疑似単語を用いて実験を行なった．
疑似単語とは，複数の異なる単語を判定システムの側からは同一の単語にしか見えないようにし，文脈からどの単語であるのかを判定させる手法である．
例えば，「銀行」という単語と，「土手」という単語を用いて疑似単語を作ったとすると，判定システムからは，入力文は例えば，
.
..
お金をおろしに＊＊へ行く途中.
..
のように見える．
＊＊の部分が疑似単語である．
そして，文脈から，「銀行」であるのか「土手」であるのかを判定させるというわけである．
これは，文脈から多義語の語義の判定を行う多義性解消の問題とかなり似た問題になる．
実験に用いる疑似単語に関しては，ベースラインとしての正解率（単純に最も出現頻度の高い単語を選ぶ方法の正解率）が高くならないように，一つの疑似単語を構成する各々の単語の出現頻度がほぼ等しくなるようにして構成した．
コーパスとしては，「CD-毎日新聞97年版」をJUMAN version 3.6 [CITE]で形態素解析したものを用いた．
事例の数に関しては，各々の疑似単語について，1024の訓練事例，1000のテスト事例を重なりがないようにコーパスからランダムに抽出して，トレーニングとテストを行なった．
（括弧内の数字は正解率と期待正解率との差）
従来手法のパラメータに関しては，英語の多義語での実験と同様に，正解率が最も高くなる値を採用した．
間引きの閾値に関しては3，対数尤度比のスムージングパラメータ[MATH]に関しては0.4とした．
表[REF_tab:comp]に結果を示す．
傾向は，表[REF_tab:basic]に示した英語の多義語での結果とほとんど同じである．
最も正解率が悪いのは，間引きによる手法である．
一様分布のベイズ学習は，対数尤度比とほぼ同じ正解率を達成している．
最も正解率が高いのは，他のルールの確率値を利用してベータ分布によって事前分布を構成する手法である．
ここで，事前分布をベータ分布とした場合の，証拠のタイプによる事前分布の違いを見るために，表[REF_tab:prior]に事前分布の期待値を示す．
この表からわかるように，事前分布の期待値の傾向は，[MATH]となっている．
すなわち，あるルールに関して何もデータがなければ，そのルールがWindowであるよりもAdjacentである方が，さらに，AdjacentであるよりもPairである方が信頼できるということである．
これは，より詳細な文脈情報を用いた方が正確な判断ができるという我々の直感とも一致する．
また，これらの事前分布に影響によって，最終的な信頼度も全体として，PairやAdjacentのルールが上位に位置することになる．
