



\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setcounter{page}{73}
\setcounter{巻数}{6}
\setcounter{号数}{7}
\setcounter{年}{1999}
\setcounter{月}{10}
\受付{1999}{3}{24}
\再受付{1999}{4}{30}
\採録{1999}{5}{10}

\setcounter{secnumdepth}{2}
\setlength{\parindent}{\jspaceskip}

\title{局所的要約知識の自動獲得手法}
\author{加藤 直人\affiref{NHK} \and 浦谷 則好\affiref{ATR}}

\headauthor{加藤, 浦谷}
\headtitle{局所的要約知識の自動獲得手法}

\affilabel{NHK}{日本放送協会放送技術研究所}
{NHK Science and Technical Research Laboratoies}
\affilabel{ATR}{ATR 音声翻訳通信研究所}
{ATR Interpreting Telecommunications Research Laboratories}

\jabstract{
日本語ニュースを局所的要約する際に必要となる要約知識を，コーパスから自動獲得する手法について述べる．局所的要約とは注目個所の近傍の情報（局所的情報）を用いて行なう要約をいう．局所的情報には注目個所そのものやその前後の単語列などがある．本手法では要約知識として置換規則と置換条件を用い，これらを原文−要約文コーパスから自動獲得する．はじめに原文中の単語と要約文中の単語のすべての組み合わせに対して単語間の距離を計算し，ＤＰマッチングによって最適な単語対応を求める．その結果より，置換規則は単語対応上で不一致となる単語列として獲得する．一方，置換条件は置換規則の前後ｎグラムの単語列として獲得する．原文と要約文にそれぞれＮＨＫニュース原稿とＮＨＫ文字放送の原稿を使って実際に要約知識を自動獲得し，得られた要約知識を評価する実験を行った．その結果，妥当な要約知識が獲得できることを確認した．}

\jkeywords{自動要約，コーパス，自動獲得，言語知識，日本語ニュース，ｎグラム}

\etitle{A new approach to acquiring linguistic \\knowledge for locally summarizing \\Japanese news sentences}
\eauthor{Naoto Katoh \affiref{NHK} \and Noriyoshi Uratani\affiref{ATR}}

\eabstract{This paper proposes a new approach to acquiring linguistic knowledge for local context-based summarization. Our summarization method can transform characters, words, and Bunsetsu-phrases to the shorter ones by using linguistic information on some words to be summarized and some words located before and after the summarized words. Our linguistic knowledge for summarization, which is composed of transformation rules and transformation conditions, is automatically acquired from Japanese news corpus. In our corpus, original articles and the human-summarized ones are collected from NHK news text and NHK teletext respectively. The proposed method analyzes original news sentences and the summarized ones by Japanese morphological analyzer, and aligns original words with the summarized words by DP matching based on distances between both of the words. Transformation rules are acquired as the result of the difference. Transformation conditions are extracted as n-gram words located near a transformation rule. We acquired linguistic knowledge from NHK news corpus and obtained a high accuracy rate as a result of a series of experiments to evaluate the linguistic knowledge.}

\ekeywords{automatic summarization, corpus, automatic acquisition, linguistic knowledge, Japanese news, n-gram}

\begin{document}
\maketitle


\section{大域的要約と局所的要約}
\label{sec:sec2}
本論文では，文章全体にわたる広範な情報（大域的情報）を用い
て行なう要約を{\gt 大域的要約}と呼ぶ．大域的情報とは文章中に含
まれる単語の出現頻度や，文章中での文の位置などである．例えば，
これらの情報を使って重要文を抽出し連結することで要約を行う手
法が提案されている~\cite{Luhn58,Edmundson69,Watanabe95,Kupiec95,Zechner96}~．
このような要約手法は，実現
の容易さから，市販の自然言語処理システム（ワードプロセッサ，
機械翻訳システム）の一機能として組み込まれていることもある．
しかし，要約文章は重要文を単に連結したものであるため，文章全
体の概要を知るという用途には利用できるものの，文章としての自
然さに欠ける．

一方，注目個所の近傍の情報（局所的情報）を用いて行なう要約
を{\gt 局所的要約}と呼ぶ．局所的情報とは注目個所そのものや，そ
の前後の単語列などである．例えば，ある単語列に注目してそれを
より短い単語列に言い換えることにより要約を行なう手法が提案さ
れている~\cite{Yamamoto95,Wakao97,Yamazaki98}~
．これらの手法には，どの単語列をどのように
言い換えるか（置換規則），また，どのような場合に言い換えるか
（置換条件）という要約知識が必須となる．要約対象を拡大したり
要約精度をあげるためには，このような要約知識を増やしたり精練
したりしなければならない．しかし，従来はこうした知識を人手で
作成していたため大規模なシステムはない．

文章を自動要約するには大域的要約と局所的要約の両方を用いる
ことが望まれるが，本論文では局所的要約だけに焦点をあてる．こ
れは，我々が自動要約の当面の応用としてニュースの字幕原稿の自
動作成を考えているからである．ニュースの字幕原稿とはアナウン
サーが話す元原稿を要約して画面に表示したものである．字幕は，
すべての情報を与えるという観点からはむしろ元原稿を要約しない
で作成するほうが望ましいが，字幕の表示速度や読み易さという観
点からはやはり元原稿を要約して作成する必要がある．この元原稿
の要約に従来の大域的要約手法を適用すると文全体を省略してしま
うので，大きな情報の欠落を伴うという問題が生じる．また，元原
稿の文は局所的情報で要約できる場合が多いので，ニュースの字幕
原稿作成には局所的要約のほうが適している．

以下，単に「要約」と書いた場合には局所的要約を指すものとす
る．

\section{原文−要約文コーパス}
\label{sec:sec3}
本論文で提案する要約知識自動獲得手法では，原文と要約文から
なる電子化されたコーパスが大量に必要となる．この章では我々が
使用している原文−要約文コーパスについて説明する．

我々は原文にＮＨＫニュース原稿，要約文にＮＨＫ文字放送の原
稿
\footnote{
我々が局所的要約の当面の適用として考えているのはニュース字幕作成であ
るので，要約文としてニュース字幕の原稿を使えることがもちろん望ましい．
しかし，現行では字幕が付与されているニュースはほとんどない．そこで本手
法では大量にある文字放送の原稿を要約文に使った．
}
を使っている．ＮＨＫニュース原稿とは，主にＮＨＫ総合ＴＶ
（ＧＴＶ）のニュース（例えば，「７時のニュース」）でアナウン
サーが読む原稿の元になるものであり，電子的に保存されている．
アナウンサーが読んで伝えることを目的として書かれているため，
新聞記事と比較すると冗長な表現も少なくない．一方ＮＨＫ文字放
送の原稿とは，ＧＴＶの電波に多重され放送されている文字放送
（テレビジョン文字多重放送）の番組の原稿である．文字放送は専
用のデコーダーで受信することができ，わずかの例外を除いては市
販の受信ソフトにより文字コードとして計算機に取り込むことが可
能である．ＧＴＶの文字放送は数百の番組があるが，本論文で用い
ている番組はテレモケイザイニュース，テレモコクサイニュース，
テレモサンギョウ，ＮＨＫニュース，ＮＨＫフルサトネットワーク
の５つの番組である．文字放送の原稿の記事数は番組や日によって
異なるが，１番組当たり４〜８記事であり，一日に数回ニュース内
容が更新される．また，１記事は１画面の中に収まるように作成さ
れている．ＮＨＫニュース原稿とＮＨＫ文字放送の原稿の一例を図
１に示す．

\begin{figure}
  \vspace*{-1cm}
\begin{center}
\epsfile{file=77.eps,scale=1.0}
\vspace*{-4mm}
\vspace{-3mm}
  \caption{原文と要約文の例}
\end{center}
\end{figure}

はじめに，ＮＨＫニュース原稿とＮＨＫ文字放送の原稿の１記事
全体を定量的に比較する．比較は9,243記事に対して，文の数，文字
数の平均を計算して行った．結果を表１に示す．文の数では，ニュー
ス原稿は１記事当たり５〜６文であるのに対して，文字放送の原稿
はほとんどの場合が２文である．文字数でみると，文字放送の原稿
の１文は短く，ニュース原稿が約２０％に縮約されている．

\begin{table}
 \begin{center}
  \caption{ＮＨＫニュース原稿と文字放送の原稿の特徴}
  \begin{tabular}{c|c|c|c} \hline \hline
   平均 & ニュース原稿 & 文字放送の原稿 & 要約率 \\ \hline
   平均文数 & 5.4 & 2.2 & 40.7\% \\
   平均文字数 & 495.5 & 107.2 & 21.6\% \\ \hline
  \end{tabular}
 \end{center}
\end{table}

図１の例で，ニュース原稿と文字放送の原稿を各文ごとに具体的
に比較する．文字放送の原稿の第１文とニュース原稿の第１文は共
通に存在する単語列が多い．また，異なっている部分は局所的要約
が行なわれている．すなわち，次のようにニュース原稿の単語列が
文字放送の原稿中では短い単語列に置換されている．（ここで，矢
印の左辺が原文中の単語列，右辺が要約文中の単語列である．また，
記号φは空を表す．）

　「ごみの焼却場などから出る」（連体節）→「φ」

　「有害物質のダイオキシン」→「有害物質ダイオキシン」

　「摂取基準を引き下げること」→「摂取基準引き下げ」

　「受けて」→「受け」

　「国内の基準」→「国内基準」

　「なりました」→「なった」

\vspace{-3mm}
文字放送の原稿の第２文はニュース原稿の第２，３文から要約さ
れている．文字放送の原稿の第２文は「１０ピコグラム」というキー
ワードを中心にして要約が生成されている．すなわち，前半はニュー
ス原稿第２文の「１０ピコグラム」辺りの節までを要約し，後半は
第３文の「１０ピコグラム」からの節を要約し，これらを繋げるこ
とにより要約が行なわれている．つまり，第２文の要約は「１０ピ
コグラム」という共通単語列を考慮して要約しており，節を対象に
した大域的要約である．

ニュース原稿の第４，５，６文は文字放送の原稿中では省略され
ている．すなわち，これらは文を対象にした大域的要約が行なわれ
たものである．

\section{コーパスからの要約知識の自動獲得}
\label{sec:sec4}
\subsection{要約知識}
\label{sec:sec4-1}
我々の要約知識は置換規則と置換条件からなる．

置換規則とは原文の単語列を短い単語列に置き変えよというものである．例えば，次の規則は連体格助詞「の」という単語を省略するという置換規則である．\vspace{8mm}\\
\hspace*{5mm}【置換規則の例】\\
\hspace*{10mm}「の／体助」→「φ」\\
\hspace*{10mm}（ここで「の」は表層文字列，「体助」は品詞が“連体格助詞”　であることを表す．）\vspace{8mm}\\
一方，置換条件とは置換規則が適用できるか否かを判定する条件である．置換規則の適用はその前後の単語列で決まる．例えば，次は上述の置換規則の例に対する置換条件の一部である．\vspace{8mm}\\
\hspace*{5mm}【置換条件の例】\\
\hspace*{10mm}「日本 の 経済」のときは置換規則適用可\\
\hspace*{10mm}「日本 の 銀行」のときは置換規則適用不可 \vspace{8mm}\\
この置換条件の例では，「日本の経済」中の「の／体助」は省略可能であるが，「日本の銀行」中の「の／体助」は省略できないということを表している．この例のように，置換規則は必ず適用できるわけではなく，適用してはいけない場合もある．実際には後述するように，適用できる程度を[0.0, 1.0]の実数値で表現している．

以下では，置換規則と置換条件をコーパスから自動的に獲得する手法について具体的に説明する．
\subsection{置換規則}
\label{sec:sec4-2}
置換規則は，原文と要約文の差分として自動的に獲得する．

本手法でははじめに原文−要約文コーパスのそれぞれの文を形態
素解析し，単語単位に分割する．形態素解析
\footnote{
形態素解析の誤りが置換規則の自動獲得に影響を及ばすことが考えられるが，
後述するように実際には出現頻度の高いものを使っているので影響は少ない．
}
は我々独自のシステムを使っている．

次に，形態素解析で得られた原文中の単語と要約文中の単語の最
適な単語対応を求める．これは，原文中の単語 $w_i$（表層文字列を$c^o_i$ ，
品詞を $p^o_i$ と表す）と要約文中の単語 $x_j$（表層文字列 $c^s_j$，品詞 $p^s_j$ ）
のすべての組み合わせに対して単語間の距離を計算し，その距離に
基づいて単語間のＤＰマッチングを取ることによって実現している．
この中で単語間の距離をどのように定義するかが重要となる．

単語間の距離は，対応する単語の有無や単語の類似性により式(1)
のように３つの場合に分けて定義した．\vspace{8mm}\\
【単語間の距離】
$$ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
distword(w_i, x_j)
  = distword(c^O_i/p^O_i, c^S_j/p^S_j)
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (1) $$
\[ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \left\{ \begin{array}{lr}
           \lambda _1{distchar(c^O_i, c^S_j)+\lambda _2distpos(p^O_i, p^S_j)}
             & \mbox{ \ \ \ \ \ \ \ \ \ \ \ (1a)} \\
             \mbox{ \ \ \ $if \ \ w_i \neq φ \wedge x_j \neq φ \wedge ContWord(p^O_i)=ContWord(p^S_j)$}
               & \mbox{} \\
           2.0
             & \mbox{ \ \ \ \ \ \ \ \ \ \ \ (1b)} \\
             \mbox{ \ \ \ $if \ \ w_i \neq φ \wedge x_j \neq φ \wedge ContWord(p^O_i) \neq ContWord(p^S_j)$ }
               & \mbox{} \\
           1.5
             & \mbox{ \ \ \ \ \ \ \ \ \ \ \ (1c)} \\
             \mbox{ \ \ \ $if \ \ w_i = φ \vee x_j = φ$}
               & \mbox{} \\
          \end{array}
  \right. \]
\vspace{8mm}\\
ここで，φは空を表す記号であり，$w_i = φ$ は対応する単語が省略
されたことを表す．また，内容語判定関数 $ContWord$ は単語 $w_i$ が内
容語であるかないかをその品詞（ $p_i$ ）から判定する関数であり，式
(2)で定義する．
\vspace{8mm}\\
【内容語判定関数】
$$ \ \ \ \ \ \ \ \ \ \ \ \ ContWord(p) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2) $$
\[ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \left\{ \begin{array}{llr}
        1 & \mbox{ $if \ \ p=$ 内容語である品詞 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
          & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2a)} \\
        0 & \mbox{ $otherwise$ }
          & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2b)}
          \end{array}
  \right. \]
\vspace{8mm}\\
　式(1a)は２つの単語が共に内容語であるか，共にそうではない場
合であり，式(3)，式(4)を用いて計算される．単語間の距離は，シ
ソーラス上の距離と品詞間の距離を重み付け（ $\lambda _1 + \lambda _2 =1$ ）して計算される．シソーラス上の距離は表層文字列が完全一致する場合に
は 0.0（式(3a)）をとる．一致しない場合には，それぞれの単語が内
容語であれば，意味的な距離をシソーラスを使って計算する．実際
には角川類語新辞典~\cite{Oono97}~の分類番号の一致する桁に基づき，
式(3b)〜(3d)で計算している．
\vspace{8mm}\\
【シソーラス上の距離】
$$ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ distchar(c^O_i, c^S_j) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3) $$
\[ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \left\{ \begin{array}{llr}
        0.0 & \mbox{ $if \ \ c^O_i=c^S_j$ \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3a)} \\
        0.1 & \mbox{ $if$ 上位３桁のみが一致 \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3b)} \\
        0.4 & \mbox{ $if$ 上位２桁のみが一致 \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3c)} \\
        0.8 & \mbox{ $if$ 上位１桁のみが一致 \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3d)} \\
        1.0 & \mbox{ $otherwise$ \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3e)}
          \end{array}
  \right. \]
\vspace{8mm}\\
式(1a)の第２項である品詞間の距離は，式(4)のように３つの場合に
分けて定義している．
\vspace{8mm}\\
【品詞間の距離】
$$ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ distpos(p^O_i, p^S_j) 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4) $$
\[ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \left\{ \begin{array}{llr}
        0.0 & \mbox{ $if \ \ p^O_i=p^S_j$ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4a)} \\
        0.2 & \mbox{ $if \ \ p^O_i$ と $p^S_j$ は人手で指定したもの }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4b)} \\
        1.0 & \mbox{ $otherwise$ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4c)}
          \end{array}
  \right. \]
\vspace{8mm}\\
ここで式(4b)は，「名詞とサ変名詞」のように，完全一致しないが
類似している品詞同士であり，人手で指定した．しかし，現在のと
ころその数はあまり多くない
\footnote{
人手で指定している品詞の組み合わせは現在のところ約40個である．品詞間
の距離は，理想的にはすべての品詞（我々の形態素解析システムでは約230個
ある）の組み合わせに対して，細かく人手で定義することが望ましい．
}
．式(1a)は，定義式からわかるように[0.0, 1.0]の値を取る．

さて，式(1b)は内容語である単語と内容語でない単語が対応する
場合であり，このような対応は不適切である場合が多いので他の場
合よりも大きい値にした．式(1c)は対応する単語が省略されている
場合であり，式(1b)と式(1a)の最大値（ $= 1.0$ ）の間の値とした．

以上のように定義した単語間の距離に基づいて単語間のＤＰマッ
チングをとると，図２のように，前の単語列が一致し（単語数 $q1$ 個），
一部が不一致となり（ $p$ 個），その後にまた単語\mbox{列が一致する}（ $q2$ 
個）という部分が求められる．この不一致となる単語列が置換規則
となる．さらに，一致する部分が長く，不一致の部分が短いほうが
置換規則としての信頼性が高いと考えられる．そこで置換規則自動
獲得の信頼度として式(5)を定義すると，この値の大きいほうが知識
として有効である．実際にはあるしきい値（ $f_0$ ）を決め，式(5)の値
がしきい値より大きいものを収集した．
\vspace{8mm}\\

\vspace{-3mm}
【置換規則自動獲得の信頼度】
$$ f(w_i w_{i+1} \ldots w_{i+p-1}, x_i x_{i+1} \ldots x_{i+p-1}) =\frac{q1+q2}{p} \eqno{(5)} $$
\begin{figure}
\begin{center}
\epsfile{file=81.eps,scale=1.0}
\vspace{-5mm}
  \caption{単語対応の差分による置換規則と置換条件の自動獲得}
\end{center}
\end{figure}

\vspace{-7mm}
さらに置換規則としての信頼度を高めるために，収集され
た置換規則の頻度統計をとり，頻度が高い置換規則を最終的に有効
な置換規則とした．

\vspace{-2mm}
\subsection{置換条件}
\label{sec:sec4-3}
\vspace{-1mm}
置換条件には置換規則の前後の単語ｎグラムが使われている．置
換条件は置換規則と同時に収集されるが，原文の単語列が置換され
る場合 $w_i w_{i+1} \ldots w_{i+p-1} → x_i x_{i+1} \ldots x_{i+p-1}$（正例と呼ぶ）とともに，原文の
単語列がそのまま保存される場合 $w_i w_{i+1} \ldots w_{i+p-1} → w_i w_{i+1} \ldots w_{i+p-1}$（負例
と呼ぶ）も収集している．負例を自動獲得する場合にも式(5)による
信頼度を使っている．

\begin{figure}
\begin{flushleft}
 \ \ \ \ \ \ \ \ \ \ \ \ {\gt 置換規則：} $w_i w_{i+1} \ldots w_{i+p-1} → x_i x_{i+1} \ldots x_{i+p-1}$ \\
 \ \ \ \ \ \ \ \ \ \ \ \ {\gt 置換条件：}
\nolinebreak
\end{flushleft}
\begin{center}
 \ \ \ \ \ \ \ \ \ \ \ {\gt 置換前条件 } \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ {\gt 置換後条件 } \ \ \ \ \ \ \\
 \ \ \ 正例 \ \ \ $w^1_{i-r1} \ldots w^1_{i-2} w^1_{i-1} \ \ \ \ w^1_{i+p} w^1_{i+p+1} \ldots w^1_{i+p+r2-1}$ \\
 \ \ \ 負例 \ \ \ $w^2_{i-r1} \ldots w^2_{i-2} w^2_{i-1} \ \ \ \ w^2_{i+p} w^2_{i+p+1} \ldots w^2_{i+p+r2-1}$ \\
 \ \ \ \ \ \ \ \ \ \ : \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ : \\
 \ \ \ 正例 \ \ \ $w^k_{i-r1} \ldots w^k_{i-2} w^k_{i-1} \ \ \ \ w^k_{i+p} w^k_{i+p+1} \ldots w^k_{i+p+r2-1}$ \\
 \ \ \ \ \ \ \ \ \ \ : \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ : \\
\end{center}
\caption{置換規則と置換条件}
\end{figure}

置換規則の前のｎグラムを置換前条件，後のｎグラムを置換後条
件と呼び，それぞれのｎの値を $r1$ ， $r2$ とおく．すると，要約知識は
図３のように表すことができる．この図で $k$ は $k$ 番目にある置換条
件を表すのに用いている．このような置換条件を参照して，ある置
換規則 $w_i w_{i+1} \ldots w_{i+p-1} → x_i x_{i+1} \ldots x_{i+p-1}$ が適用できるかどうかの程度は，
式(6)で定義された置換条件上の距離として計算される．置換条件上
の距離の計算ではまず，それぞれの $k$ に対して，原文の単語列の前 
 $r1$ グラム（ $w_{i-r1} \ldots w_{i-2} w_{i-1}$ ）と $k$ 番目の置換前条件（ $w^k_{i-r1} \ldots w^k_{i-2} w^k_{i-1}$ ）
との距離（式(6b)），原文の単語列の後 $r2$ グラム（ $w_{i+p} w_{i+p+1} \ldots 
w_{i+p+r2-1}$ ）と $k$ 番目の置換後条件（ $w^k_{i+p} w^k_{i+p+1} \ldots w^k_{i+p+r2-1}$ ）との距離（式
(6c)）を求める．次にそれらを重み付けた和（式(6a)）を計算し，さ
らにすべての $k$ に対する最小値を求め，この最小値を置換条件上の
距離とする．定義から明らかなように，式(6)は[0.0, 1.0] の値をとる．
\vspace{8mm}\\
【置換条件上の距離】
$$  \min_{k}( g(w_i w_{i+1} \ldots w_{i+p-1}, x_i x_{i+1} \ldots x_{i+p-1}, k) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \eqno{(6)} $$

 \ \ \ \ \ \ \ \ \ \ \ 
$g(w_i w_{i+1} \ldots w_{i+p-1}, x_i x_{i+1} \ldots x_{i+p-1}, k)$
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (6a)

 \ \ \ \ \ \ \ \
$= \mu _1g^-(w_{i-r1} \ldots w_{i-2} w_{i-1} , w^k_{i-r1} \ldots w^k_{i-2} w^k_{i-1} )$

 \ \ \ \ \ \ \ \
$+ \mu _2g^+(w_{i+p} w_{i+p+1} \ldots w_{i+p+r2-1} , w^k_{i+p} w^k_{i+p+1} \ldots w^k_{i+p+r2-1} )$

 \ \ \ \ \ \ \ \
$(\mu _1+\mu _2=1)$

\[ g^-(w_{i-r1} \ldots w_{i-2} w_{i-1} , w^k_{i-r1} \ldots w^k_{i-2} w^k_{i-1})
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \]
\[ =\frac{ \sum_{j=1}^{r1} \bigl\{ weight_1(j) \times distword(w_{i-j} , w^k_{i-j}) \bigr\}}
{ \sum_{j=1}^{r1} weight_1(j) }
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \]
\begin{flushright}(6b)\end{flushright}

\[ g^+(w_{i+p} w_{i+p+1} \ldots w_{i+p+r2-1} , w^k_{i+p} w^k_{i+p+1} \ldots w^k_{i+p+r2-1} ) 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \]
\[ =\frac{ \sum_{j=1}^{r2} \bigl\{ weight_2(j) \times distword(w_{i+p+j-1} , w^k_{i+p+j-1}) \bigr\}}
{ \sum_{j=1}^{r2} weight_2(j) } 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \]
\begin{flushright}(6c)\end{flushright}

 \ \ \ \ \ \ \ \ \ \ \ \
$weight_1(j) = { \alpha _1 }^{j-1}$
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
(6d)

 \ \ \ \ \ \ \ \ \ \ \ \
$weight_2(j) = { \alpha _2 }^{j-1}$
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
(6e)

（$\alpha _1$, $\alpha _2$ は定数，$0.0 \le \alpha _1 \le 1.0$, \ \ $0.0 \le \alpha _2 \le 1.0$）
\vspace{10mm}\\
ただし，$g^-$ ， $g^+$ はそれぞれ，原文と収集された置換前条件，置換後
条件間の距離を計算する関数であり，置換規則となる単語列から離
れるほど，その影響が少なくなるように $weight(j)$ で重み付けしてい
る．さらに，置換前条件と置換後条件は $\mu $ で重み付けしている．

式(6)で最小値を与える置換条件が正例に関するものであるならば，
置換規則が適用され局所的に要約される．しかし，置換規則の適用
を式(6)で単純に判定してしまうと，負例，すなわち置換規則を適用
しない方を解とする場合が多くなってしまう．これは，置換条件の
正例が置換しなければならないというものではなく，置換してもよ
いという程度の意味しか持たないからである．そこで後述する要約
知識の評価実験では，あるしきい値（ $g_0$ ）を決め，式(6)で求められ
た最小値を与える解が負例であっても正例での最小値がしきい値以
下であるならば，正例を解とした．

\end{document}


