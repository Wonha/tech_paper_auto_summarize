本研究で用いた要約データは，日本語新聞記事・英語新聞記事・日本語講演録の3種類のテキストデータを対象として作成されたものである．
日本語新聞記事の要約データ，英語新聞記事の要約データは，ともに評価コンテストのために作成された公式のデータである．
この2種類のデータを対象とすることで，異なる言語に対して用いることのできる要約システムを構築することを意図している．
日本語講演録の要約データは，講演音声についての大規模なコーパスを構築するプロジェクトの中で作成された，学会講演の書き起しデータに対して作成されたものである．
このようなデータを対象とすることによって，書き言葉と話し言葉それぞれに対応できる要約システムを構築することを意図している．
以下，本研究で用いた3種類の要約データそれぞれについて説明する．
TSC (Text Summarization Challenge)は，自動要約の研究の発展を目的として2001年に開始された自動要約の評価プロジェクトであり，国立情報学研究所によって主催されている評価ワークショップNTCIRのタスクの一つである[CITE]．
TSCは，複数の要約課題を提示して参加者を募り，参加者が作成した個々の自動要約システムを同一のデータに基づいて評価を行い，また自動要約の評価基準自体についての議論，さらに研究者間で共有できる要約データの作成・公開を行ってきている．
第1回にあたるTSC2001では，日本語の新聞記事を対象として，A1:重要文抽出型要約，A2:人間の自由作成要約と比較可能な要約，B: IRタスク用要約の3種類の課題が提示された．
本論文ではこのうち課題A1で用いられた重要文データを実験に用いた．
予備試験，本試験データはそれぞれ30記事あり，ともに社説15記事と報道記事15記事で構成されている．
この課題では，予備試験，本試験ともに3種類の要約率(10 %, 30 %, 50 %)に応じて重要文抽出を行うことが課された．
本論文では，TSCで用いられた要約データを「TSCデータ」と呼ぶ．
TSCデータは課題で用いられた新聞記事と，要約率ごとに作成されたそれらの記事の要約とから成る．
TSCデータは日本語書き言葉要約データの例として[REF_section:evaluation]章に示す評価結果，[REF_section:analysis]章に示す分析で用いられる．
Document Understanding Conference(DUC)は，米国DARPAの支援の下にNational Institute of Standards and Technology(NIST)によって実施されている，自動要約の評価プロジェクトである[CITE]．
DUCは日本におけるTSCと同様に，同一のデータに基づく複数の要約システムの評価，要約データの作成・公開を行うことで自動要約の研究の発展を図って行われているプロジェクトであり，2000年に最初のワークショップが行われた後，2001年から本格的に要約課題の提示，自動要約システムの評価が開始され，その結果に対する議論を経て課題内容や評価基準の改良が施されてきている．
DUC2001では，英語新聞記事を対象として単一文書の要約・複数文書の要約の2種類の課題が出された．
対象とするデータは両課題において共通であり，トレーニングデータとして30記事セット，テストデータとして新たに30記事セットが主催者から配布された．
各記事セットには約10記事ずつ含まれており，それらの記事はAP通信やFinancial Times, Los Angels Times, Wall Streat Jounalなどの新聞から取られている．
各記事セットは，例えば「最高裁判事に任命されたトーマス氏についての記事」「ピナツボ火山の噴火についての記事」などの主題ごとに集められた記事から成っている．
DUCでは，要約率ではなく語数によって作成する要約の長さが制限された．
単一文書の要約では，各記事を100語以内に要約して出力することが課された．
複数文書の要約では，各記事セットごとに50語，100語，200語，400語の4種類の要約が課された．
DUC2001で用いられたデータのうち，本論文で示す実験では単一文書要約課題のデータを用いた．
ただし主催者側から与えられた正解データは，文抽出(extract)データではなく人間が作成した要約(abstract)データであったので，我々はこのabstractデータをもとに記事セット中の対応する文を抜き出し，重要文抽出の正解データを作成した．
本論文では，DUCで用いられた要約データを「DUCデータ」と呼ぶ．
DUCデータは英語書き言葉要約データの例として[REF_section:evaluation]章に示す評価結果，[REF_section:analysis]章に示す分析で用いられる．
話し言葉の要約データとして本研究の実験に用いたコーパスは，国立国語研究所，東京工業大学，通信総合研究所の3団体が共同で構築作業をすすめているCSJコーパス(Corpus of Spontaneous Japanese)[CITE]から得たものである．
CSJコーパスは，学会講演などのモノローグを中心に収集・構築されているコーパスである．
本論文では，このCSJコーパスのうち，1999年日本音響学会秋季研究発表会(AS99)の講演から35講演，2000年言語処理学会年次大会(NL00)の講演から25講演の計60講演を取り出して用いた．
重要文抽出の実験では，60講演のうち50講演(AS99から30講演，NL00から20講演)をトレーニングデータとし，10講演(AS99から5講演，NL00から5講演)をテストデータとして用いた．
重要文抽出を適用するには文境界が与えられている必要があるが，講演の書き起しデータは話し言葉の特性上，書き言葉のようには文の境界が予め与えられていない．
このため，三人の被験者(論文の著者は含まない)が全60講演について文境界の検出と重要文抽出のデータ作成をともに行った．
文境界においては，さらに各被験者の結果を言語学の専門家が統合して単一の文境界データを作成した．
文境界データにおける各講演の平均文数は68.7文であった．
一方重要文抽出においては，各被験者における重要文の判断の揺れが大きく，正解データを統一することは困難であったので，[REF_section:evaluation]章で示す評価結果では被験者の抽出結果を個々に正解とみなして評価している．
なお，重要文抽出の要約率は10 %に設定した．
本来のCSJコーパスはここで用いたものよりも大規模なコーパスであるが，本論文ではCSJコーパスを用いて作成された要約データを「CSJデータ」と呼ぶ．
CSJデータは，日本語話し言葉要約データの例として[REF_section:evaluation]章に示す評価結果，[REF_section:analysis]章に示す分析で用いられる．
自動要約では，文章中で重要な文を選択するために有効と思われる素性を考案し，それを用いた評価尺度を関数の形で表現し，その評価値の高い文を抽出するという重要文抽出の手法が主に用いられており，本システムでもこの手法を採用している．
本章ではこの重要文抽出で用いた評価尺度について説明し，次にしきい値・重み付けなどその他の部分について説明する．
TSC，CSJ，DUC各データに特化した部分については，個々に特化した項目を明記する．
それ以外で特に対象データについて限定していない記述は，各データに対して共通して用いられた部分である．
本システムでは，個々の素性についてそれを基にした評価尺度を与える関数を予め定義している．
それぞれの情報に対しては，複数の関数を用意しているものがある．
それらの関数の選択も，各評価尺度に対する重みと同様，トレーニングデータを用いて行なう．
使用した評価尺度は，文の位置情報・文の長さ・単語のtf*idf値・記事の見出し，そして言語的パタンである．
各関数の出力したスコアに重みを掛け合せたものの和が，各文の重要度となる．
本システムでは，文の位置情報に基づく関数を3種類用意した．
重要文を抽出する際には，この三つのうちの一つが用いられる．
1つ目の関数は，出力すべき文が[MATH]文であると指定されたときに，記事の先頭から[MATH]文目までにスコア1をつけ，それ以外は0とするものである：
ここで[MATH]は記事中の文の数を示す．
この関数は，最初の[MATH]文を要約結果とする単純な重要文選択の方法が好成績を納めてきているという事実に基いたものである．
2つ目の関数は文の位置の逆数を与えるものである．
つまり[MATH]番目の文に対するスコアは，
となる．
この2つ目の関数は先頭に近い程重要であるという点では1つ目の関数と同じであるが，他の評価尺度と組み合わせた際に両者の差が出てくることを意図して定義されたものである．
3つ目の関数は，2つ目の関数に手を加え，先頭からの文の位置と末尾からの文の位置を共に用いるものである．
つまり，全文数が[MATH]である記事において，[MATH]番目の文に対するスコアは以下のようになる．
この関数は，先頭か末尾に近い文ほど重要であるという仮定を表現したものである．
各文の長さに基づく評価尺度については，以下の3種類の関数を用意した．
1つ目の関数は，文の長さをそのままスコアとして与えるものである：
これは，「長い文ほど重要である」という仮定を表現したものである．
2つ目の関数は，長さ[MATH]が一定の値[MATH]より短い文にはペナルティとして負の値を与えるものである：
このペナルティは，極端に短い文は重要文として選択されることが非常に稀であるという観測事実に基いている．
3つ目の関数は，1つ目と2つ目の関数を組み合わせたもので，各文の長さをスコアとして与えるが，一定値[MATH]より短ければペナルティとして負の値を与えるものである：
この関数は先に挙げた両者の関数の長所を組み合わせることを意図している．
TSCデータ・CSJデータにおける評価の際には，文の長さを文字数で表し，トレーニングデータを用いた実験の結果から一定値[MATH]を20(文字)とした．
DUCデータにおける評価の際には，文の長さを単語数で表し，同様にトレーニングデータを用いた実験の結果から一定値[MATH]を10(単語)とした．
この評価尺度は，各文中の単語についてtf*idf値を計算し文のスコア付けを行うものである．
tf*idf値は，各記事中の単語[MATH]の頻度tf[MATH]と，その単語がある記事群の中で現れた記事の数，すなわち記事頻度df[MATH]とを組み合わせて計算される値で，記事中のある単語がどの程度その記事特有の単語であるかを示す．
記事数DN個の記事群が与えられたとき，最も単純なtf*idf値の計算式は以下のようになる：
右辺第二項は特にinverse document frequency (idf)と呼ばれる値である．
tf*idf値は，与えられた検索要求に関連する記事をデータベースから検索する情報検索の分野において，記事の特徴を示すための指標として用いられるものであり，検索の精度を向上させるためにいくつか異なるtf*idf値の計算手法が提案されている．
その一つは以下のようなものである：
また，特に情報検索の分野において効果を挙げている[CITE]の定義に基づく式は以下のものである：
tf*idf値を重要文抽出に用いる意図は，「その記事に特有な単語をより多く含む文は，その記事においてより重要である」という仮定を表現することである．
各文のスコアは，文中の各単語に対するtf*idf値の和によって与えられる：
なお[REF_section:analysis]章で示す結果では，tf*idf値を用いた文のスコアから文の長さによる影響を避けるため，以下の式のようにtf*idf値の和を文の長さ[MATH]で割って正規化した値を文のスコアとしている：
TSCデータ，CSJデータに対しては単語の切り分けにJUMAN ver.3.61[CITE]を用い，tf*idf値を与える単語を時相名詞や副詞的名詞を除いた名詞に限定した．
記事頻度を求めるための記事群には，1994年と1995年の毎日新聞の記事を用いた．
DUCデータに対しては，品詞による単語の選別は行わず，ストップワードのリストを作成し，そのリストに含まれない単語についてtf*idf値を求めた．
記事頻度を求めるための記事群としては，1994年と1995年のWall Street Journalの記事を用いた．
TSCデータ, CSJデータにおいては，各単語のtf*idf値を求める際に関数T3を用いた．
DUCデータにおいては，T1〜T3の3つの関数のうち一つをトレーニングデータを用いて選択するようにした結果，T1が選択された．
この評価尺度は，対象記事の見出しに含まれる単語に対するtf*idf値を用いて文のスコア付けを行うものである．
これは「見出しと類似している文は重要である」という仮定に基いている．
類似度を求める際に対象とする単語は，前節のtf*idf値を用いた関数と同様に，日本語であるTSCデータ, CSJデータでは時相名詞や副詞的名詞を除いた名詞，英語であるDUCデータではストップワードのリストに含まれない単語である．
文([MATH])中の対象単語について，その名詞が見出し([MATH])に含まれていれば，そのtf*idf値を文のスコアに加算する．
文のスコアを与える式を以下に示す：
CSJデータにおいては，講演録そのものには見出しは存在しないが，それに対応する予稿から見出しを取り出して用いた．
TSCデータ，DUCデータについては，さらに名詞の代わりに固有表現(Named Entity: NE)を用いて見出しとの類似度を計算する関数も定義した．
TSCデータに対する日本語の固有表現抽出には，最大エントロピー法を用いたシステムを使用した[CITE]．
抽出する日本語固有表現の定義はIREXワークショップ[CITE]で用いられたものに拠っている．
DUCデータに対する英語の固有表現抽出には，パターンベースの固有表現抽出システムを用いた．
このシステムは，拡張された固有表現の定義150クラスを抽出の対象とするものである[CITE]．
固有表現を用いる際には，簡便性のため，tf*idf値ではなく頻度のみを用いた．
すなわち，各記事中の固有表現[MATH]に対する頻度[MATH]を用いれば，関数の式は以下のように示される：
DUCデータに対しては，言語的パタンの獲得方法とそれを用いた評価尺度を導入した．
ここで用いているパタンの獲得手法は，日本語情報抽出において提案された手法に基づいている[CITE]．
この手法は，例えば地震の発生を報道する記事には「○月×日ｘ時ｙ分ごろ，△□で地震があった」といった表現がよく現われるように，「分野(domain)を特定したときに，記事によく現れる表現はその分野において重要だ」という仮定に基づいてパタンを自動的に獲得するものである．
DUC2001においては，約10記事ずつを1セットとして30記事セットのデータが配布されたので，この各記事セットを情報抽出における一つの分野とみなし，各セットごとにパタンの自動獲得を行った．
パタンの獲得方法は以下の過程に従って行われる：
文の解析：
与えられた記事セット中の記事全文について品詞・固有表現のタグづけ，係り受け解析を行う．
部分木の抽出：
係り受け木中の部分木を全て取り出す．
固有表現による抽象化：
部分木中に固有表現があった場合には，その固有表現を対応するクラスに置き換えたものと，元の表現のままの二通りの部分木をパタンとして用意する．
複数の固有表現がある場合は，各置換操作の組み合わせだけ部分木を生成する．
部分木のスコア付け：
木全体の頻度と，部分木中の各単語の記事頻度から部分木のスコアを求める．
このスコアの定義は，その記事セットに特有な部分木を取り出すという意図に基づいており，スコアが高い部分木ほど重要なパタンであると仮定することになる．
パタンは重要文抽出を行う前に取り出され，スコアとともにシステムに格納される．
実際に重要文抽出を行うときには，システムは各文[MATH]について品詞・固有表現のタグづけや係り受け解析を行って係り受け木を作成し，次いで格納されたパタンとの比較を行う．
パタン[MATH]のスコアと文[MATH]の評価尺度をそれぞれ式に表わすと以下のようになる：
ここで，[MATH]はパタン[MATH]の記事セット中の頻度，[MATH]は[MATH]中の単語数を示す．
DNは予め与えられた記事群中の記事数，df[MATH]はその記事群の中で単語[MATH]が現れる記事の数である．
すなわち，[MATH]は，パタン[MATH]中の単語の平均idf値であり，これとパタンの頻度[MATH]を用いて[REF_section:system_tfidf]節で述べたtf*idf値のような値を各パタンに与えることが，パタンのスコアを表す式の意図するところである．
あるパタン[MATH]が文[MATH]の係り受け木の一部と一致した場合には，そのパタンのスコアが文の評価尺度として加算される．
さらに各文について一致した全パタンのスコアを加算し，その値の対数をとったものを最終的な文の評価尺度[MATH]としている．
本システムでは，各評価尺度の値(Score[MATH])に重み([MATH])を掛け合わせたものの総和をとり，各文([MATH])のスコアを与える：
この重み付けの最適値は，トレーニングデータを用いて求めた．
具体的には，予め設定した値域内で，重みの値を変化させながらトレーニングデータに対する実験・評価を繰り返し，最も良い値を与える重みづけの値を求めた．
複数の関数が定義されている評価尺度においては，その関数の選択も重み付けとともに行なわれた．
TSCデータ, DUCデータにおいては，それぞれ予備試験のデータをトレーニングデータとして用いた．
TSCデータにおいては，30の新聞記事を更に社説15記事とそれ以外の報道記事15記事とに分けてそれぞれについて最適な重み付けを求めた．
CSJデータでは，60講演のうち，テストデータとして残した10講演を除く50講演をトレーニングデータとして用いた．
[REF_section:evaluation]章に示す実験結果では，各情報においてどの関数が選ばれたか，重みの程度がどのくらいだったかを報告する．
本システムでは，重要文抽出を行う際に記事中の全文にスコア付けを行い，その結果を元にスコアの良い順に各文を順位付けする．
これらの文のうち何文まで出力するかを決定するのに，本システムでは文数・文字数(単語数)・スコアの3種類のしきい値を用いることができる．
どのしきい値を用いても，出力される文の順番は元の記事のまま保たれる．
文の数[MATH]がしきい値として与えられたならば，システムは順位付けされた文の上位[MATH]文までを重要文として抽出する．
文字数または単語数が与えられたときには，システムはこれを文数のしきい値に変換する．
スコアがしきい値として与えられたならば，システムはそのしきい値より大きい値をもつ文のみを出力する．
TSCデータ，CSJデータについては，文の数[MATH]をしきい値として用いた．
DUCデータについては，DUC2001において100語前後の要約を出力することが課題に指定されていたので，単語数をしきい値として用いた．
[REF_section:evaluation]章では，複数の素性を用いた重要文抽出システムが，TSC，DUC，CSJの各データについて良好な結果を得たことを示した．
しかしながら，評価結果だけでは，各データにおいて有効な素性に違いはあるのか，複数の素性を組み合わせて用いたことにどのような効果があったのかという点についてはっきり示されていない．
そこで本章では，まず各素性についてその値の変化に対応する重要文の分布を図示し，どのような素性の用い方が効果的であるかを調べた．
次に，有効な素性の組み合わせを調べるため，二つの素性間の相関と素性の組み合わせによる重要文の数・割合の分布を示した．
本節では，重み付けの値を得たトレーニングデータにおいて重要と判断された文と素性との関連を調べ，素性を用いた評価尺度のうちどのようなものが有効であるかを考察する．
具体的には，文の位置・文の長さ・tf*idf値・見出しの4種類の素性について，その評価尺度の値に対応する記事全体の文数・重要文の文数を調べた．
文の位置・tf*idf値・見出しについてのグラフでは，各素性ごとにそれに基づく評価尺度の値の昇順に文を順位付けしてその順位を5 %または10 %ごとに区分し，各区分ごとに重要文の占める割合を示した．
一方，文の長さについてのグラフでは，傾向をより見やすくするために，文の長さの値そのものに対して記事中の文数とそれに含まれる重要文の数とを示した．
TSCデータにおいては，さらに記事の種類を社説と報道記事に分け，個々の要約率における正解要約(10 %, 30 %, 50 %)に含まれる重要文の割合をグラフによって示した．
なおCSJデータについては，重要文の数・割合として3人の被験者による抽出結果の平均値を用いている．
データ全体の文数・重要文の数を示すため，表[REF_table:training_num_of_sent]に各トレーニングデータの記事数と文数・重要文の数・要約率を掲げる．
DUCデータにおいては，要約の制限は要約率ではなく語数(100語)であったため，全データにおける重要文の割合を要約率として示した．
各データ中の文の位置と重要文との関係を図[REF_figure:position_train]に示す．
グラフ中の横軸は各記事中の文の位置であり，先頭を0，末尾を1として正規化した値を表している．
TSC報道記事データ(Report)では，先頭に近いところに一番大きなピークがあり，「先頭の方ほど重要な文が多い」という仮定は当たっているようである．
一方，社説データ(Editorial)では，先頭に重要な文がある割合は報道記事に比べて小さいが，末尾からの文の位置と文数の関係を見ると，末尾に近いところにも大きなピークがある．
社説においては，先頭だけでなく末尾の部分にも被験者に選択された文が多かったということになる．
DUCデータにおいては，末尾よりも先頭からの文の位置と重要文数の関係が比較的強く，DUCデータにおける文の位置と重要文との関係はTSC報道記事データに近い．
一方CSJデータにおいては，先頭よりも末尾の方に被験者に選択された文がより多く，CSJデータにおける文の位置と重要文との関係はTSC社説データに近いことがグラフから分かる．
CSJデータは学会講演から取られたものであるので，最後に発表をまとめる表現が重要文とされることが多いことがその要因として考えられる．
文の長さと文の数・重要文の数との関係を図[REF_figure:length_train]に示す．
TSCデータ, CSJデータでは文の長さを文字数で，DUCデータでは文の長さを単語数で示している．
どのデータにおいても，短い文に対しては記事全体の文数に比べて重要文の文の割合が小さい．
一定の長さ以下の文にペナルティを与える関数は重要でない文を除く上で有効であったといえる．
また非常に長い文は，その数は少ないが重要文である割合が高く，一定の長さ以上の文を重要文とみなすような関数を用いることも考えられる．
tf*idf値を用いた評価尺度と重要文との関係を図[REF_figure:tfidf_train]に示す．
ここでは各単語ごとのtf*idf値の計算には式T1を用い，また文の長さによる影響を避けるため，各文ごとにtf*idf値の和を文長によって正規化している．
横軸に示している値は，tf*idf値を用いた評価尺度の値そのものではなく，評価尺度の値によって各文を順序付けした相対順位である．
TSC報道記事データでは，tf*idf値が大きくなるにつれて，特に30 %，50 %の要約率において正解要約に含まれる文の割合が大きくなる．
tf*idf値の高い文は重要であると見なすことは報道記事において効果があったと考えられる．
DUCデータ，CSJデータにおいては，tf*idf値が大きくなるに従って緩やかに重要文である割合が増しているが，際立った特徴は見られなかった．
TSCデータにおいても10 %におけるグラフは，報道記事データ・社説データの双方においてほぼ同様の傾向を示しており，CSJデータの要約率は10 %であり，DUCデータにおける要約率の平均は23.5 %であることを考慮すると，要約率が小さい場合には，tf*idf値はどのデータにおいてもとくに目立った特徴は示していないといえる．
見出しを用いた評価尺度と重要文との関係を図[REF_figure:hl_noun_train],図[REF_figure:hl_ne_train]に示す．
図[REF_figure:hl_noun_train]は単語を単位とした見出しと文との類似度に基づくグラフ，図[REF_figure:hl_ne_train]は固有表現を単位とした見出しと文との類似度に基づくグラフである．
CSJデータに対しては固有表現を単位とした評価尺度を適用していないので，図[REF_figure:hl_ne_train]のグラフはTSCデータとDUCデータのもののみ掲げてある．
横軸に示している値は，tf*idf値におけるグラフと同様に，見出しを用いた評価尺度の値によって各文を順序付けした相対順位である．
tf*idf値を用いた評価尺度とTSC報道記事データとの関連と同様に，TSC社説データにおいて見出しを用いた評価尺度による順位が大きくなるにつれて，特に30 %，50 %の要約率において正解要約に含まれる文の割合が大きくなる．
見出しを用いた評価尺度の値が高い文を重要であると見なすことは，社説において効果があったと考えられる．
DUCデータ，CSJデータにおいては，tf*idf値に比べると評価尺度による順位が90 %以上のときの重要文の増加の割合がより大きい．
見出しを用いた評価尺度の値が大きい文は，数としては少ないが重要文である割合が高いことが分かる．
固有表現を単位とした評価尺度においては，グラフ全体の傾きは単語を単位とした評価尺度よりも小さく，重要文の割合と評価尺度の値との関連はあまり見られないが，評価尺度による順位が90 %以上のときには，単語を単位とした評価尺度と同様に重要文の割合が増加している．
複数の素性を用いて重要文抽出を行うには，素性間の独立性が高いことと，素性を組み合わせたときに重要文が多い値域を絞り込めることが重要である．
本節では，まず素性間の独立性を調べるために，各素性による文のスコアの順序に基づく順位相関係数を求め，素性間の独立性を調べた結果を示す．
次に，独立性が比較的高い素性同士のいくつかの組み合わせについて，その組み合わせによる重要文の数・割合の分布を示した．
各要約データにおける文の位置・文の長さ・tf*idf値・見出しの4種類の素性について，その評価尺度の値に基づく順位相関係数(Spearman)を求めた．
各素性の組ごとの順位相関係数の値を表[REF_rank_cc_results]に示す．
結果からは，どのデータにおいても
文の位置は他のどの素性とも相関が低く，比較的独立であること
文の長さとtf*idf値との相関が高いこと
TF*idf値と見出し(単語)との相関が高いこと
が分かる．
これら4種類の素性は重要文抽出に用いられる典型的な素性であり，[REF_section:evaluation]章ではこれらの素性を組合せて重要文抽出を行い日本語・英語双方のコンテストにおいて良好な結果を得たことを示したが，順位相関係数の値からはこれらの素性は必ずしも相互に独立ではないことが分かった．
前節の結果から，4種類の素性は互いに独立であるとはいえないが，文の位置と他の素性との組み合わせはどのデータにおいても他の組み合わせと比較して独立性が高いことが分かった．
本節では，これらの素性の組み合わせにおいて重要文の分布とどのように関連しているかを調べる．
TSCデータについては，素性の組み合わせについて示すにはデータ中の文数が少ないため，ここではDUCデータとCSJデータについて調べた結果のみを示している．
前節の結果独立性の高かった文の位置と他の素性の組み合わせについて，重要文の分布がどう変化するかを示す．
表[REF_table:diagram_pst_len]，[REF_table:diagram_pst_tfidf]，[REF_table:diagram_pst_hlnoun]は，二つの素性の組み合わせによって重要文の数・割合がどう変化するかを示したものである．
これらの表では各素性ごとにその評価尺度の値の昇順に文を順位付けし，その順位を10 %ごとに区分して各区分ごとに重要文の数と割合を文字によって段階分けして示した．
各区分中の文字は，重要文が各区分に均一に分布している場合に比べて，どのくらい偏りがあるかを示すものである．
左側の文字は重要文の数の偏りを示すもので，具体的には，データ中の全重要文の数を[MATH]としたときに各区分中の重要文の数[MATH]が重要文の各区分に対する平均値[MATH]からどのくらい離れているかを，以下のような範囲ごとに示している．
ここで[MATH]は各区分に対する重要文数の標準偏差である．
同様に，各区分の右側の文字は，重要文の全文数に対する割合が均一に分布している場合と比較して，どのくらい偏りがあるかを示すものである．
全文数[MATH]に占める重要文の割合を[MATH]としたときに，各区分中の重要文の割合[MATH]が以下の範囲にあることを示している．
ここで[MATH]は各区分に対する重要文の割合の標準偏差である．
すなわち，重要文が素性に関係なく均一に分布している状態ならば，全ての区分がCcとなる．
重要文の数が多くてもその割合が小さければ，単にその区分に含まれる文の数が多いだけで，重要文の抽出に有効な区分ではない．
逆に重要文の割合が大きくてもその数が小さければ，その区分は重要文抽出の性能向上に有効ではあるが，寄与する度合は小さい．
まず，表[REF_table:diagram_pst_len]に示した文の位置と文長の組み合わせについて調べてみると，DUCデータでは文の位置が先頭から20 %以内で，かつ文長による順位が50 %以降の場合(文の位置[MATH] 0.2，文長[MATH] 0.5)において重要文の数，割合とも大きいことが分かる．
一方CSJデータでは文の位置が末尾から10 %以内で，かつ文長による順位が30 %以降の場合(文の位置= 1.0，文長[MATH] 0.3)に重要文の数，割合とも大きい．
次に，文の位置とtf*idf値の組み合わせについての結果を表[REF_table:diagram_pst_tfidf]に示す．
CSJデータにおいて文の位置が先頭から20 %以内のところに重要文の割合が大きい区分が若干増えたこと以外は，文長との組み合わせとほぼ同様の結果になっている．
これらの結果から，文の位置と組み合わせて文長またはtf*idf値を用いた際には，ともにそのスコアが低い文を除くことで文の位置による重要文抽出の精度をより向上させていることが分かる．
最後に，文の位置と見出しの組み合わせについての結果を表[REF_table:diagram_pst_hlnoun]に示す．
見出しを用いた評価尺度の場合，ほぼ半数の文が見出しと共通する語を持たないため，スコアが0になる．
このため，対応する文が存在しない区分が中間に現われている．
見出しを用いた評価尺度においては，そのスコアが0であるような文においても重要文の数が多く，文長またはtf*idf値のような効果は得られていない．
しかし，DUCデータにおいて文の位置が先頭から20 %以内で見出しによる順位が70 %以降の場合(文の位置[MATH] 0.2，見出し[MATH] 0.7)，重要文の割合は大きくなっている．
また，CSJデータにおいては，文の位置が末尾から10 %以内(文の位置= 1.0)の場合に加えて，文の位置= 0.1，見出し= 1.0の区分においても重要文の数，割合が大きくなっている．
従って，文の位置と組み合わせて見出しの情報を用いた場合には，文長やtf*idf値とは逆に，そのスコアが高い文を優先することで文の位置単独の場合よりも重要文抽出の精度が向上するといえる．
これらの実験結果をまとめると「重要文抽出に用いた素性を組み合わせたときに，その値の増減に応じて連続的に重要文の数・割合が増えるのではなく，組み合わせによってできる一定の境界があって，その内外で重要文の数・割合が大きく異なることがある」ということになる．
つまり，重要文抽出を行う際には，式[REF_eq:weight]のように素性を用いた評価尺度を線型に組み合わせる方法ではなく，ここで発見された特徴を生かすような非線型の評価尺度を導入することで，同じ素性を用いても精度向上の可能性があるということである．
また，DUCデータとCSJデータの双方において素性の組み合わせによる非線型な重要文の数・割合の変化がみられたことは，英語新聞記事と日本語講演録という異なる種類のデータにおいても，非線型な素性の組み合わせが重要文抽出に有効であることを示唆しているといえる．
日本語新聞記事においても，[CITE]はSVMを用いた重要文抽出を行う際に連続値を持つ素性を一定の値域に区切って二値素性に変換して用いているが，その分析において報告されている有効な二値素性の組み合わせからも，同様に非線型な素性の組み合わせが有効であることが推測される．
