\documentstyle[jnlpbbl]{jnlp_j_b5}


\newcommand{\kakko}[1]{}
\newcommand{\BM}{}
\newcommand{\SIM}{}
\newcommand{\co}{}
\newcommand{\f}{}
\newcommand{\AVSIM}{}
\newcommand{\SntScore}{}


\setcounter{page}{201}
\setcounter{巻数}{10}
\setcounter{号数}{4}
\setcounter{年}{2003}
\setcounter{月}{7}
\受付{2002}{12}{13}
\再受付{2003}{2}{23}
\採録{2003}{4}{10}

\setcounter{secnumdepth}{2}

\title{日英新聞の記事および文を対応付けるための\\高信頼性尺度}
\author{内山 将夫\affiref{U} \and 井佐原 均\affiref{U}}

\headauthor{内山，井佐原}
\headtitle{日英新聞の記事および文を対応付けるための高信頼性尺度}

\affilabel{U}{通信総合研究所}{Communications Research Laboratory}

 \jabstract{大規模な日英対訳コーパスを作ることを目的として，1989
   年から2001年までの読売新聞とThe Daily Yomiuri とから日英記事
   対応と文対応とを得た．そのときの方法は，まず，内容が対応する
   日本語記事と英語記事とを言語横断検索により得て，次に，その対
   応付けられた日英記事中にある日本語文と英語文とをDPマッチング
   により対応付けるというものである．しかし，それにより対応付け
   られた記事対応や文対応には，間違った対応(ノイズ)が多く含まれ
   る．そのため，我々は，本稿において，そのようなノイズを避けて，
   正しい対応のみを得るための信頼性の高い尺度を提案し，その信頼
   性の評価をした．実験の結果，我々の提案した尺度を用いることに
   より，良質な記事対応や文対応が得られることがわかった．また，
   その数は，良質な記事対応は約4万7千であり，文対応は，1対1対応
   が約15万，1対1対応以外が約3万8千であった．これらは，現時点で
   一般に利用できる日英2言語コーパスとしては最大のものである．}

\jkeywords{日英対訳コーパス，記事アライメント，文アライメント}

\etitle{Reliable Measures for Aligning \\ Japanese-English News Articles and Sentences}
\eauthor{Masao Utiyama\affiref{U} \and Hitoshi Isahara\affiref{U}}

 \eabstract{ We have aligned Japanese and English news articles
   and sentences, extracted from the Yomiuri and the Daily
   Yomiuri newspapers,  to make a large parallel corpus. We
   first used a method based on cross-language information
   retrieval to align the Japanese and English articles and then
   used a method based on dynamic programming (DP) matching to
   align the Japanese and English sentences  in these
   articles. However, the articles and sentences  included many
   incorrect alignments. To remove these, we propose two
   measures that evaluate the validity of the alignments.  Using
   these measures, we successfully extracted a valid
   correspondence of about 47 thousands article pairs, 150
   thousands 1-to-1 sentence pairs, and 38 thousands 1-to-many
   sentence pairs. We were therefore able to build the largest
   Japanese-English parallel corpus available to the public.}

\ekeywords{Japanese-English parallel corpus, article alignment, sentence alignment}


\begin{document}
\maketitle
\thispagestyle{empty}




















\section{対応付けに用いた日英新聞記事}
\label{sec:corpora}

対応付けの元データは，日本語記事は「読売新聞」，英語記事は「The
Daily Yomiuri」であり，それぞれ「読売新聞記事データ」における
1989年9月から2001年12月までの記事を利用した．この期間における年
間の記事数は，日本語記事は10万から35万程度であり，英語記事は4千
から1万3千程度である．また，総記事数は，日本語記事は約200万であ
り，英語記事は約11万である．このように，英語記事の方が少ないの
で，対応付けにおいては，各英語記事に対応する日本語記事を求める
ことにした．

記事のメタ情報として，The Daily Yomiuriには，1996年7月中旬から，
「本紙翻訳 = Y/N」という情報が各記事に付いている．これは，その
英語記事を書くにあたって，読売新聞の記事を元にしたかどうかとい
う意味であるので，1996年7月中旬からは，「本紙翻訳=Y」である英語
記事についてのみ，対応する日本語記事を求めることにした．このと
きの英語記事の数は 35318 である．一方，1996年7月中旬以前には，
そのような情報はないので，全ての英語記事について対応する日本語
記事を求めることにした．このときの英語記事の数は  59086  である．
なお，以下では，1996年7月中旬以前の記事集合を「1989-1996」と書
き，1996年7月中旬以降の記事集合を「1996-2001」と書くことにする．

1989-1996については，全英語記事を利用するため，1996-2001と違っ
て，そもそも，各英語記事について対応する日本語記事がない場合が
ある．そのため，どのくらい
の英語記事に，対応する日本語記事があるかを推測するために，「本
紙翻訳=Y」の割合を，1997年から2001年の記事について調べたところ，
67.9\,\%であった．

対応を求めるにあたって，各英語記事に対応する日本語記事は，互い
に近い日付であると考えられる．そのため，各英語記事について，そ
の日付の前後2日の範囲の日本語記事の中から対応する記事を見付ける
ことにした．このとき，1日分の英語記事について，日本語記事は5日
分があるが，このときの平均記事数は，1989-1996については，英語記
事が24，日本語記事が1532，1996-2001については，英語記事が18，日
本語記事が2885である．

このように，非常に曖昧性があり，かつ，対応記事も場合によっては
存在しないという，ノイズの多い状況のなかから対応記事を見つける
必要があるので，信頼性の高い記事対応(評価)尺度が必要である．

また，文対応についていえば，たとえ記事同士が対応していたとして
も，その対応は，直訳関係にあるものは少なく，どちらかというと，
日本語記事を材料として英語記事を書いたというような状況である．
たとえば，以下の例では，英語と日本語とで，e1，e3，e4とj1，j2，
j3，j4とによる3対4に複雑に絡みあう対応があり，その間にe2と
j5による対応がある．

\begin{quote}
  \footnotesize
\kakko{e1} Two bullet holes were found at the home of
Kengo Tanaka, 65, president of Bungei Shunju,
in Akabane, Tokyo, by his wife Kimiko, 64, 
at around 9 a.m. Monday. \kakko{/e1}
\kakko{e2} Police suspect right-wing activists, who have
mounted criticism against articles about the
Imperial family appearing in the Shukan Bunshun,
the publisher's weekly magazine, were responsible
for the shooting. \kakko{/e2}
\kakko{e3} Police received an anonymous phone call 
shortly after 1 a.m. Monday by a caller who 
reported hearing gunfire near Tanaka's residence. \kakko{/e3}
\kakko{e4} Police found nothing after investigating the 
report, but later found a bullet in the Tanakas' 
bedroom, where they were sleeping at the time of 
the shooting. \kakko{/e4}
\end{quote}

\begin{quote}
  \footnotesize
\kakko{j1} 二十九日午前八時五十五分ごろ、東京都北区
赤羽西四文芸春秋社長、田中健五さん（６５）方の二階
東側外壁に、短銃で撃たれた跡があるのを、妻喜美子
さん（６４）が見つけた。 \kakko{/j1}
\kakko{j2} 赤羽署で調べたところ、寝室の外壁に二か所の
穴が確認され、銃弾一発が寝室内から発見された。 \kakko{/j2}
\kakko{j3} これに先立ち、午前一時すぎ、田中さん方周辺で
「短銃の発射音のような音が二、三発聞こえた」という
 匿名の通報が同署にあり、署員が確認に向かったが、
 この時点で銃痕は発見できなかった。 \kakko{/j3}
\kakko{j4} 発射音がしたころ、田中夫妻は寝室で就寝中だった
 という。 \kakko{/j4}
\kakko{j5} 同社が発行している週刊誌「週刊文春」が、最近、
皇室批判記事を掲載していたことから、同署では、
皇室批判に反発する右翼の犯行の可能性があるとみて、
捜査をしている。 \kakko{/j5}
\end{quote}

このような文対応は，人間の観察者(たとえば，日英記事のスタイルを
比較研究しているような人)にとっては価値があるが，文対応の結果を
自然言語処理，たとえば，機械翻訳に利用しようとしている場合には，
今のところは，有用性は限定されている．そのため，なるべく直訳同
士にあるような文対応を抽出したいのであるが，このような状況から
直訳に近い文対応を抽出するためには，信頼性の高い文対応(評価)尺
度が必要である．

\section{対応付けの方針}
\label{sec:guideline}

これまで，\ref{sec:intro}節で，日英対訳コーパスが必要とされてて
いることを述べ，また，\ref{sec:corpora}節において，対応付
けの元となる日英新聞記事に付いて述べた．本節では，これらの節に
基づいて，本稿における，記事対応付けおよび文対応付けの方針につ
いて述べる．それは以下の2点である．

\begin{enumerate}
  
\item まず，日英記事対応付けと文対応付けとは，本稿における目的
  ではあるが，そのような対応付けをすること自体の目的は，その対
  応付けの結果を利用して，機械翻訳なり英語教育なりに役立てるこ
  とである．そのため，対応付けについては，もし，既存の言語資源
  および手法を利用することにより，ある程度の量と精度の対応付け
  が得られるなら，あえて新しい言語資源や手法を開発することなく，
  既存の言語資源や手法を有効に利用する．
  
\item しかし，対象とするコーパスには，多くのノイズがあるため，
  既存の言語資源や手法をそのまま利用した場合に得られる対応付け
  には，間違った対応付けも多く含まれる．そのため，その対応付け
  のなかから，良さそうな対応付けのみを抽出するための信頼性の高
  い尺度を考える．
\end{enumerate}
  
こうした場合には，対象とするコーパスに潜在的に存在する対応付け
のうちで，既存の言語資源や手法により抽出されなかったものは利用
できない，そのため，対応付けの再現率は低い可能性がある．しかし，
良さそうな対応付けとして抽出されたものの精度は高いことが期待で
きる．

つまり，上記の方針は，再現率よりも精度を重視するということであ
る．以下，この方針に基づき，\ref{sec:artalign}節と
\ref{sec:sntalign}節では，既存の言語資源や手法に基づいて記事対
応と文対応とを取る方法について述べ，\ref{sec:artscore}節では，
得られた対応付けの中から良さそうな対応付けを得る尺度について述
べる．

\section{記事対応付けの方法}
\label{sec:artalign}

記事対応付けは，言語横断検索の枠組で行なう．つまり，英語記事を
質問とし，それに関連する記事を日本語記事データベースから検索す
ることにより，与えられた英語記事と対応する日本語記事を見付ける．

このとき，一般に，質問である英語記事を日本語に変換するか，ある
いは，データベースである日本語記事を英語に変換する必要がある．
本研究では，データベースである日本語記事を英語(の単語集合)に変
換した．そうした主な理由は，手元にある言語資源が日英方向の変換
に便利だったからである．

\subsection{日本語記事の英単語集合への変換}
\label{sec:artj2e}

我々は，辞書引きに基づいて日本語記事を英単語集合に変換すること
にした．利用した日英辞書は，EDR日英対訳辞書，EDICT (一般的な日
英対訳辞書)，ENAMDICT (固有名詞の日英対訳辞書)である
\footnote{{\tt
    http://www.csse.monash.edu.au/\~{}jwb/edict.html}}．これら
の辞書の見出し語に対して，IPADIC (version 2.4.4) の品詞体系を付
与し，茶筌\footnote{{\tt
    http://chasen.aist-nara.ac.jp/index.html.ja}} (version
2.2.8)の追加辞書として利用した．追加したエントリ数は，EDR日英対
訳辞書が約18万，EDICTが約6万，ENAMDICTが約22万である\footnote
{ここで追加したエントリは，IPADICに含まれていないもののみである．
  なお，たとえば，EDR日英対訳辞書とEDICTとなどで，個別に追加し
  た辞書間における重複があったとしても，それらの重複を除去する
  ことはせずに追加している．}．

こうすることにより，茶筌の解析結果から容易に日英対訳辞書のエン
トリがアクセスできるようになる．たとえば，「あおぎ見た月」は，
追加辞書なしの状態では
\begin{quote}
  \footnotesize
\begin{verbatim}
あおぎ　あおぐ　動詞-自立
見　　　見る　　動詞-自立
た　　　た　　　助動詞
月　　　月　　　名詞-一般               
\end{verbatim}
\end{quote}
と形態素解析される(形態素情報の一部を省略)が，追加辞書ありの状
態では
\begin{quote}
  \footnotesize
\begin{verbatim}
あおぎ見　　あおぎ見る　　動詞-自立
た　　　　　た　　　　　　助動詞
月　　　　　月　　　　　　名詞-一般               
\end{verbatim}
\end{quote}
のように解析され，特に工夫をせずとも，複合語である「あおぎ見る」
の訳語として「look up」「face upwards」「look up to」「respcet」
「admire」などが得られる．また，この方法によると，「くすの木台
に行く」を形態素解析した場合のように，辞書にない単語に起因する
解析誤りである「くす/の/木/台/に/行く」のようなものも「くすの木
台/に/行く」として解析でき，かつ，「くすの木台」の訳語として
「Kusunokidai」も容易に得られる．このように，IPADICを増強するこ
とにより，解析誤りを避けながら，容易に日英辞書の辞書引きができ
ると共に，複合語や固有名詞の翻訳という言語横断検索において重要な作業も同
時にできるため，この方法は有用である．

このようにして日本語の各単語(もしくは複合語)において，その品詞
が内容語(主に名詞)に相当するものから英訳語を得て，そこから簡単
なヒューリスティクスにより主辞を抽出し当該日本語単語の変換結果としたが，このとき，
各単語についてその全ての訳語の主辞全てを変換結果として採用するとすると，訳語の主辞のなかには当該文脈の訳として適当でないものもあるため，検索結果に悪影響を与えると考えられる．そのため，なるべく，訳語として適当なものだけを変換結果として利用した
い．そうするためには，訳語の曖昧性を解消すれば良いのだが，それ
を正確にするのは困難である．そのため，ここでは，ヒューリスティ
クスとして，まず，訳語の主辞の中から，より多くの訳語に含まれて
いるようなものを優先し，次に，同順位のものについては，その訳語
の主辞に対応する日本語単語を含む日本語記事の年と同年の英語記事
において，その訳語の主辞を含む英語記事数(document frequency,
df)が多いような訳語の主辞を優先する\footnote{たとえば，「今日」
  には「today」「nowadays」「this day」「present day」などが訳
  としてあるが，このうち，主辞だけをみると，「day」が一番多いの
  で，まず，これを取る．次に,  「nowadays」「today」 の中から，
  dfが高いものを取る．}ことにした．そして，このヒューリスティク
スにより優先付けられた上位2個のみを変換結果として利用した．なお，dfが0である
ような訳語の主辞は，最初から，候補に含めない．

\subsection{英語記事からの日本語記事の検索}
\label{sec:clir}

一旦，日本語記事が英単語集合に変換されてしまえば，あとは，通常
の情報検索と同様にして，質問として与えられた英語記事に最も類似
するような日本語記事(の英単語集合への変換結果)を検索することが
できる．そして，その日本語記事をもって対応記事とする．このとき
の英語記事と日本語記事の類似度としては，$\BM$
\cite{robertson94:_some_simpl_effec_approx_poiss}を利用した．
$\BM$は，情報検索に有用な尺度として知られており，
TREC\footnote{http://trec.nist.gov/} (Text REtrieval
Conference) や 
NTCIR\footnote{http://research.nii.ac.jp/\~{}ntcadm/index-en.html}
(NII-NACSIS Test Collection for IR Systems)  でも，その有効性は
実証されている．

ここで，質問である英語記事$Q$と日本語記事の変換結果$D$との類似
度$\BM(D,Q)$は以下である．

\begin{displaymath}
  \BM(D,Q) = \sum_{T \in Q} w^{(1)} \frac{(k_1+1){\it tf\/}}{K+{\it tf\/}}\frac{(k_3 + 1){\it qt
f\/}}{k_3+{\it qtf\/}}
\end{displaymath}
\begin{quote}
  \footnotesize

  ただし，

  $T$は$Q$に含まれる単語(ターム)である．

  $w^{(1)}$は$T$の重みであり，$w^{(1)} = \log \frac{(N-n+0.5)}{(n+0.5)}$．
  
  $N$は，検索対象の文書集合における全文書数である．ただし，検索
  対象は，質問である英語記事の日付の前後2日の範囲の日本語記事
  (の英単語への変換結果)である．
  
  $n$は，$T$を含む文書の数である．
  
  $K = k_1((1-b) + b \frac{{\it dl\/}}{{\it avdl\/}})$である．
  ただし，$k_1$，$b$，$k_3$は経験的に定める定数であり，本研究で
  は，$k_1=1$, $b=1$, $k_3=1000$である．また，${\it dl\/}$は，
  $D$の長さであり，${\it avdl\/}$は，文書集合における文書の長さ
  の平均値である．ただし，文書の長さとは，その文書に含まれる単
  語の延べ数のことである．
  
  $tf$は，$D$に含まれる$T$の数である．

  $qtf$は，$Q$に含まれる$T$の数である．

\end{quote}

以上をまとめると，記事対応付けにおいては，日本語記事を英単語集
合に変換し，その変換結果に対して，英語記事を質問として情報検索
をし，その結果の$\BM$による類似度が1位の日本語記事を，英語記事
の対応記事とする．この対応付けられた日英記事中にある日本語文と
英語文との対応付けは，次節で述べる方法で行なう．

\section{文対応付けの方法}
\label{sec:sntalign}

日英記事における文間の対応はDPマッチングで求めた
\cite{gale93:_progr_align_senten_bilin_corpor,uturo94:_bilin_text_match_bilin_diction_statis}
．DPマッチングで文対応を得るアルゴリズムの簡潔な記述には
\cite{uturo94:_bilin_text_match_bilin_diction_statis}を参照せよ．
ここでは，日本語文(集合)から得られた内容語集合$J$と英語文(集合)
から得られた内容語集合$E$との類似度，$\SIM(J,E)$についてのみ述
べる．
\begin{displaymath}
  \SIM(J,E) = \frac{\co(J \cap E)+1}{|J| + |E| - 2\co(J \cap E) + 2}
\end{displaymath}
である\footnote{単語集合同士の類似度については，その他にも様々
  なものが考えられるが，それらについて詳細な比較検討はしていな
  いが，本節で述べる文対応付けの実験結果の精度からは，
  $\SIM(J,E)$が文対応付けの類似度として妥当なものであると言え
  る．}．ただし，$\f(x)$を文$X$における$x$の頻度とすると$|X| =
\sum_{x \in X} \f(x)$である．また，$\co(J \cap E)$は，$J$中の単
語と$E$中の単語との1対1対応を，日英および英日対訳辞書に基づき求
めた場合の集合を $J \cap E = \{(j,e)| j \in J, e \in E\}$とする
と，$\co(J \cap E) = \sum_{(j,e)\in J \cap E}
\min(\f(j),\f(e))$である．

$J$と$E$と$J \cap E$とは，以下のようにして求めた．まず，辞書引
きにあたって，日本語文については，茶筌により形態素解析をした結
果から，内容語および複合語を抽出した．これが$J$である．また，英
語文については，Brill's Tagger
\cite{brill92:_simpl_rule_based_part_speec_tagger}により品詞付
けをし，基本形を WordNet \footnote{{\tt
    http://www.cogsci.princeton.edu/\~{}wn/}}  のライブラリを利
用して求め，その結果から，内容語と複合語を抽出した．これが$E$で
ある．次に，$J \cap E$については，ある  $(j, e)$の組$(j \in J
\wedge e \in E)$について，もし，$j$の訳語に$e$があるか，$e$の訳
語に$j$がある場合には，$(j,e)$には対応の可能性があるとし，その
ような全ての対応の可能性のなかから，訳語の曖昧性の低いほうから1
対1に対応付けていった．すなわち，$(j,e)$の曖昧性として，$j$の訳
語の数を採用し，それの小さいものから対応付けをしていくのだが，
既に，$(j,e)$のどちらかでもが選ばれている対応はスキップする，と
いう方法を採用した．なお，このときの訳語の対応付けに用いた対訳
辞書は，EDR日英対訳辞書とEDR英日対訳辞書を統合して生成した日英
および英日対訳辞書である．これらの辞書において，日英方向のエン
トリ数は約32万，英日方向のエントリ数は約37万である．


以上のように定義された類似度を用いて，文対応を付けたが，このと
き，文対応付けに用いたプログラムでは，DPマッチングにおける文間
の対応としては，1対$n$ もしくは $n$対1，ただし，$1 \le n \le 6$ 
しか許していない．

この条件下で，文対応プログラムの精度を，人手により文対応が付け
られている，白書データ\cite{hakusho}に適用することにより求めた．
白書データには，18対の日英ファイルがあるが，そのうち，訳抜け(0
対$n$もしくは$n$対0の文対応)の数が3以下の12ファイルを対象とした．
これらのファイル対について，日本語文の平均数は413，英語文の平均
数は495である．

このとき，再現率の平均は 0.982，適合率の平均は 0.986である．こ
れより，このプログラムの精度は十分に高いと言える．なお，
\begin{displaymath}
  再現率 = \frac{プログラムの得た文対の中で正しい対の数}{正しい対の総数}
\end{displaymath}
\begin{displaymath}
  適合率 = \frac{プログラムの得た文対の中で正しい対の数}{プログラムが推定した対の総数}
\end{displaymath}
ただし，$1$対$n$の文対応からは，$n$個の対が得られる．たとえば，
文$J_1$と文$E_1, E_2, E_3$が対応しているとすると，得られる対は
$(J_1,E_1), (J_1,E_2), (J_1,E_3)$の3個である．

我々は，辞書のみに基づいて文対応付けをした．それに対して，
\cite{uturo94:_bilin_text_match_bilin_diction_statis}は，辞書情
報に統計情報を組合せることにより，文対応の精度が向上すると述べ
ている．しかし，我々のプログラムの精度は既に十分に高い
ので，統計情報は利用しなかった．

\section{記事対応尺度と文対応尺度}
\label{sec:artscore}

\ref{sec:artalign}節と\ref{sec:sntalign}節とにおいて，記事対応
の類似度$\BM$と文対応の類似度$\SIM$とを導入した．しかしながら，
これらの類似度のみを利用して記事対応や文対応を付けた場合には，
\ref{sec:arteval}節や\ref{sec:snteval}節で実験で示すように，十
分に精度の高い記事対応や文対応を得ることはできない．そのため，
本節では，記事対応と文対応の双方について，新たな尺度を定義する．
本研究の主要な貢献は，以下で述べる二つの尺度$\AVSIM$と
$\SntScore$とを提案し，その性能を実験により詳細に検討すると同時
に，大規模な日英対応付けコーパスを構築し，それを一般に利用可能
にした点である．

まず，記事対応についてであるが，我々は，\ref{sec:artalign}節に
おいて，日本語記事$J$と英語記事$E$の類似度として$\BM(J,E)$を導
入した．この類似度は，単語集合間の類似度であるので，文の順序な
どは考慮できない．そのため，文の順序を考慮できる記事対応尺度と
して，$\AVSIM(J,E)$を定義する．これは，$J$と$E$との文対応
\footnote{これらは，もし対応が1対nである場合には，文と文集合と
  の対応となるが，そのような場合も含めて文対応と呼ぶ．}を
$\{(J_1,E_1), ..., (J_m,E_m)\}$としたとき，以下の式である．
\begin{displaymath}
  \AVSIM(J,E) = \frac{\sum_{k=1}^{m} \SIM(J_k,E_k)}{m}
\end{displaymath}
$\AVSIM$が高い値となるのは，個々の文対応の類似度$\SIM$が高い場
合であるので，そのような場合には，記事としての対応も良いと考え
た．

次に文対応の良さの尺度について述べる．\ref{sec:sntalign}節で述
べたように，我々の文対応付けプログラムの精度は，白書データのよ
うに日本語文と英語文とが原文と訳文という関係にあるようなものを
対応付ける限りにおいては，高精度である．しかし，
\ref{sec:corpora}節で述べたように，日本語記事と英語記事との関係
は，一般には，原文と訳文という関係ではない．そのため，
\ref{sec:sntalign}節の方法で文対応付けをした場合には，適切な対
応と共に不適切な対応も多く得られる．そのようにノイズの多い状況
から，適切な対応のみを抽出するためには，文対応の尺度として，文
類似度だけでなく，記事対応の尺度も利用すれば良いと考えた．その
ため，日本語記事$J$と英語記事$E$との記事対応における，文$J_k$と
$E_k$との文対応尺度として，
\begin{displaymath}
  \SntScore(J_k, E_k) = \AVSIM(J,E) \times \SIM(J_k, E_k)
\end{displaymath}
を定義した．この尺度は，同一記事対応内で文対応を比べる場合には
文類似度$\SIM$と同じ順位を与えるが，異なる記事間での文対応の比
較では，文類似度だけでなく，記事対応の尺度値も高いような文対応
を優先する．

\section{記事対応付けの精度}
\label{sec:arteval}

\subsection{無作為抽出による精度評価}
\label{sec:randeval}

記事対応付けは，各英語記事との類似度$\BM$が高い日本語記事を検索
することによりなされる．このとき，類似度1位の日本語記事について
の記事対応付けの精度を1996-2001と1989-1996とについて表
\ref{tab:prec1}に示す\footnote{評価を記述する際には1996-2001を
  メインとする．その理由は，今後とも The Daily Yomiuri には「本
  紙翻訳=Y/N」の情報が付くと考えられるので，1996-2001の精度評価
  の方が相対的に重要と考えられるからである．}．

\begin{table}[htbp]
  \small
  \centering
  \caption{類似度1位の記事対応の精度}
  \begin{tabular}{|c|ccc|ccc|}\hline
         & \multicolumn{3}{|c|}{1996-2001} & \multicolumn{3}{|c|}{1989-1996}\\
    \raisebox{1.5ex}[0pt]{評価値} & 下限 & 割合 & 上限 & 下限 & 割合 & 上限\\ \hline
    A    & 0.49 & 0.59 & 0.69 & 0.20 & 0.29 & 0.38\\
    B    & 0.06 & 0.12 & 0.18 & 0.08 & 0.15 & 0.22\\
    C    & 0.03 & 0.08 & 0.13 & 0.03 & 0.08 & 0.13\\
    D    & 0.13 & 0.21 & 0.29 & 0.38 & 0.48 & 0.58\\ \hline
  \end{tabular}
  \label{tab:prec1}
\end{table}

表\ref{tab:prec1}において，「評価値」とは，記事対応の良さの人手
による判定の評価値であり，その基準は，Aは「記事全体の記述の5〜6割程度以上につい
て意味の対応がとれる」，Bは「2〜3割程度以上5〜6割程度以下につい
て意味の対応がとれる」，Dは「全然違う」，Cは「A,B,D以外」である
\footnote{A,B,C,Dの判定は第1著者がした．判定については，
  1996-2001については，ダブルチェックをした．1996-2001について
  の初回の判定における各評価値の割合は，A=0.62, B=0.09, C=0.09,
  D=0.20である．したがって，同一評価者内においては判定結果は安
  定していると言える．なお，1996-2001については，更に，類似度1
  位の評価値がCかDの場合には，10位以内までを見て，A,Bがないかを
  探した場合の各評価値の割合は，A=0.62, B=0.15, C=0.05, D=0.18 
  であるので，類似度1位のものとそれほど違わない．そのため，
  1989-1996については，類似度1位のもののみしか判定しなかった．}．
「割合」とは，1996-2001  と 1989-1996 のそれぞれから，100記事対
応ずつを一様無作為抽出したときに，その評価値であった記事対応の
割合である．「下限」「上限」とは，割合の95\,\%信頼区間の下限と上
限である．

\ref{sec:corpora}節で述べたように，1996-2001については，「本紙
翻訳=Y」なる英語記事のみを対象したが，1989-1996については，全英
語記事を対象とした．そのため，1989-1996の精度は，1996-2001より
も低い．また，1996-2001の精度が1989-1996の精度よりも高いといっ
ても，それでも，評価値Aが約60\,\%，AもしくはBが約70\,\%であるので，
$\BM$による記事対応付けの結果をそのまま利用した場合には，ノイズ
となる記事対応が多すぎる．

我々の観察によれば，評価値がAもしくはBの記事対応は，そこから日
英言語表現間の対応が抽出できそうという意味において，有用な記事
対応である．このような記事対応のみを抽出するには，$\BM$による記
事対応付けの結果をそのまま全て利用するのではなく，対応の良さに
より対応付けの結果をソートし，その上位のみを抽出すれば良い．

\subsection{ソートした場合の記事対応の精度}
\label{sec:sorteval}

記事対応の良さの指標として，$\AVSIM$と$\BM$のどちらが適当かを比
較した．表\ref{tab:prec1}と同じデータに対して，それぞれの値の降
順により記事対応をソートし，評価値がAもしくはBの場合を正解とし，
各順位までにおける正解の個数とその割合とを調べた．それを表
\ref{tab:rankprec}に示す．表\ref{tab:rankprec}から，我々は，
$\AVSIM$の方が$\BM$よりも，記事対応の良さとして適切な尺度である
と判断した．

\begin{table}[htbp]
  \footnotesize
  \centering
  \caption{順位と精度}
  \begin{tabular}{|c|cc|cc||cc|cc|}\hline
    & \multicolumn{4}{|c||}{1996-2001} & \multicolumn{4}{|c|}{1989-1996} \\ \cline{2-9}
    & \multicolumn{2}{|c|}{$\AVSIM$} & \multicolumn{2}{|c||}{$\BM$} &\multicolumn{2}{|c|}{$\AVSIM$} & \multicolumn{2}{|c|}{$\BM$}\\
    \raisebox{2.5ex}[0pt]{順位} & 数 & 割合 & 数 & 割合 & 数 & 割合 & 数 & 割合 \\ \hline
     5 &  5 & 1.00 &  5 & 1.00 &  5 & 1.00 &  2 & 0.40\\
    10 & 10 & 1.00 &  8 & 0.80 & 10 & 1.00 &  4 & 0.40\\
    20 & 20 & 1.00 & 16 & 0.80 & 19 & 0.95 &  9 & 0.45\\
    30 & 30 & 1.00 & 25 & 0.83 & 28 & 0.93 & 16 & 0.53\\
    40 & 40 & 1.00 & 34 & 0.85 & 34 & 0.85 & 24 & 0.60\\
    50 & 50 & 1.00 & 39 & 0.78 & 37 & 0.74 & 28 & 0.56\\
    60 & 60 & 1.00 & 47 & 0.78 & 42 & 0.70 & 30 & 0.50\\
    70 & 66 & 0.94 & 55 & 0.79 & 42 & 0.60 & 35 & 0.50\\
    80 & 70 & 0.88 & 62 & 0.78 & 43 & 0.54 & 38 & 0.47\\
    90 & 71 & 0.79 & 68 & 0.76 & 43 & 0.48 & 40 & 0.44\\
   100 & 71 & 0.71 & 71 & 0.71 & 44 & 0.44 & 44 & 0.44\\\hline
  \end{tabular}
  \label{tab:rankprec}
\end{table}

$\AVSIM$の精度の方が$\BM$の精度よりも高い理由は，
\ref{sec:artscore}節で述べたように，$\AVSIM$が，$\BM$と違って，
個々の文対応の良さまでも考慮した尺度であるからと考える．

\subsection{評価値とAVSIM}
\label{sec:judgeeval}

人手により判定された評価値A,B,C,Dと$\AVSIM$との対応の程度を調べ
ることを目的とし，表\ref{tab:prec1}と同じデータに対して，各評価
値となった記事対応について，$\AVSIM$の統計量を求めた．それらを，
1996-2001については表\ref{tab:avsim1}に，1989-1996については表
\ref{tab:avsim2}に示す．

\begin{table}[htbp]
  \small
  \centering
  \caption{AVSIMの統計量(1996-2001)}
  \begin{tabular}{|c|c|ccc|cc|}\hline
    評価値 & 数 & 下限 & 平均 & 上限 & 閾値  & 有意差\\\hline
    A & 59 & 0.176 & 0.193 & 0.209 & 0.168 & ** \\
    B & 12 & 0.122 & 0.151 & 0.179 & 0.111 & ** \\
    C & 8  & 0.077 & 0.094 & 0.110 & 0.085 & *  \\
    D & 21 & 0.065 & 0.075 & 0.086 &       &    \\   \hline
  \end{tabular}
  \label{tab:avsim1}
\end{table}

\begin{table}[htbp]
  \small
  \centering
  \caption{AVSIMの統計量(1989-1996)}
  \begin{tabular}{|c|c|ccc|cc|}\hline
    評価値 & 数 & 下限 & 平均 & 上限 & 閾値  & 有意差\\\hline
    A & 29 & 0.153 & 0.175 & 0.197 & 0.157 & *\\
    B & 15 & 0.113 & 0.141 & 0.169 & 0.131 & \\
    C & 8  & 0.092 & 0.123 & 0.154 & 0.097 & **\\
    D & 48 & 0.076 & 0.082 & 0.088 &       & \\\hline
  \end{tabular}
  \label{tab:avsim2}
\end{table}

これらの表において，「数」とは，その評価値であった記事対
応の数である．また，「平均」とは，そのような記事対応の$\AVSIM$
の平均値であり，「下限」および「上限」は，平均値の95\,\%信頼区間
の下限と上限である．「閾値」は，その評価値であるような記事対応
と，次の評価値であるような記事対応とを分けるときに，どの
$\AVSIM$で区切れば良いかを示す．たとえば，表\ref{tab:avsim1}で
は，A判定とB判定とは$\AVSIM$の値が0.168により分かれる．この閾値
は，線形判別分析により求めた値である．また，「有意差」の欄にあ
る「**」と「*」は，それぞれ，その評価値と次の評価値とで平均値に
差があるかを，Welch検定により片側検定したときに，その差が，1\,\%
と5\,\%水準で有意であることを示す．

二つの表において，1989-1996のBとCとの区分を除いては，全ての評価
値において，各評価値と次の評価値とでは，平均値に有意な差がある
ことがわかる．このことから，$\AVSIM$は，各評価値を十分に明確に
区切ることができると言える．なお，1989-1996では，BとCが分かれて
いないことについて，その理由を調べた．そうすると，実際，
1989-1996 では，C だといっても，記述の重複が，1996-2001 の C と
比べて，多いものが多かった．定性的には，1996-2001 の C は，「D 
ではない(全然違うわけではない)」という意味で C であり，1989-1996 の C は，「B かもし
れない」という意味で C であった．

次に，1996-2001と1989-1996とで，同じ評価値を与えられた記事対応
の$\AVSIM$の平均値に統計的に有意な差があるかを調べた．つまり，
たとえば，表\ref{tab:avsim1}では，評価値Aの平均値は0.193であり，
表\ref{tab:avsim2}では，0.175であるが，この二つの平均値の差が統
計的に有意かどうかを両側検定によるWelch検定により調べたところ，
有意水準5\,\%においては，A,B,C,Dいずれの評価値においても有意差は
みられなかった．そのため，1996-2001と1989-1996とで，同じ評価値
の記事対応は，同じ程度の$\AVSIM$であると判断した．そのため，
$\AVSIM$は，異なる記事集合を利用した場合であっても，安定して，
記事対応の良さを示す指標であると考える．

\begin{table}[htbp]
  \small
  \centering
  \caption{評価値と記事数の推定}
  \begin{tabular}{|c|c|c|c|}\hline
       & 1996-2001 & 1989-1996 & 計\\ \hline
    A  &   15491   &   16004 & 31495\\
    B  &    9244   &    5999 & 15243\\
    C  &    4944   &   10258 & 15202\\
    D  &    5639   &   26825 & 32464\\\hline
    計 &   35318   &   59086 & 94404\\\hline
  \end{tabular}
  \label{tab:numart}
\end{table}

最後に，表\ref{tab:avsim1}と表\ref{tab:avsim2}にある閾値
\footnote{表\ref{tab:avsim1}での閾値の丸めていない値は，
  0.1681076526, 0.111106681, 0.08531399165であり，表
  \ref{tab:avsim2}では， 0.1566618237, 0.130510963,
  0.09692189387である．これらの値を実際には利用した．}に基づいて，
1989-1996と1996-2001とについて，A,B,C,Dであるような記事数を推定した結果を表\ref{tab:numart}に示
す．表より，評価値がAもしくはBと推定される記事対応は，全体では，
46738 $(= 31495+15243)$だけある．我々は，約4万7千という記事対応
は，訳語抽出などの自然言語処理への応用や，英語教育などへの応用
にとって，十分有効に利用できる量であると考える．

以上より，$\AVSIM$は，人手による評価値A,B,C,Dに良く対応した尺度
であり，かつ，異なる記事集合においても同一評価値については安定
した数値をとる尺度であることがわかった．また，$\AVSIM$に基づい
て記事対応を抽出することにより，約4万7千の良質な記事対応が抽出
できることが期待できることがわかった．

\section{記事対応付けの精度向上の可能性}
\label{sec:enhancement}

\ref{sec:arteval}節で述べたように，$\AVSIM$は，記事対応の良さを
示す信頼性の高い尺度である．そのため，$\BM$の代り(もしくは重み
つき和などによる組み合わせで)，最初から$\AVSIM$を利用して記事対
応を求めれば，\ref{sec:randeval}節で述べた全体的な精度も向上す
ると考えられる．

しかし，我々は，現時点では，$\BM$による類似度1位の記事対応につ
いてのみしか，$\AVSIM$を求めていない．その理由は，10位以内など
の比較的少しの記事をみただけでは記事対応精度に顕著な向上がない
からであり，かつ，現時点での文対応プログラムの実行速度が遅いか
らである．今の文対応プログラムでは，一記事あたりの対応を取るた
めに，数秒は掛る\footnote{プログラムの動作環境は，CPUは Pentium-4 1500MHz，OSはRed Hat Linux 7.1である．}．そのため，一位同士の対応について$\AVSIM$を得
るだけでも，9万4千記事程度なので，数日間は掛かる．したがって，
たとえば，100位以内をみるだけでも，数100日間掛かることになる．
これは非現実的である．

しかし，今後，もっと高速の文対応プログラムを作り，それを利用す
ることにより，より高精度な記事対応が得られるものと考えている．

また，今は，各英語記事について，その記事の日付の前後2日の範囲し
か調べていないが，記事によっては，5日前のものが翻訳されているも
のがあった．このようなものまでカバーするためには，もっと広い範
囲から対応候補記事を集める必要がある．

この2点は，システム全体を効率化しスケールアップすることにより達
成可能なので，将来的には実現したい．

\section{文対応付けの精度}
\label{sec:snteval}

\ref{sec:corpora}節で述べたように，たとえ，日英記事間に内容上の
対応があったとしても，文間対応があるとは限らないので，対応付け
られた記事から得られる文対応はノイズが多いものとなる．そのため，
$\BM$による類似度1位の記事対応全てから得られる文対応全てを
$\SntScore$により降順にソートし，その上位のみを利用することによ
り対応の良いものを抽出することにした\footnote{文対応精度評価は，
  1989-1996 と  1996-2001 とを分けずに行なう．その理由は以下の2
  点である．(1)  まず，作成するコーパスでは，1989-2001  全体か
  ら選んだ文対応のなかから良く対応していそうなもののみを抽出し
  たい．そのためには，全体を評価した方が良い．(2) 記事対応の精
  度評価の結果から，同程度の$\AVSIM$は，1989-1996 と1996-2001 
  とで同じ評価値に対応するので，$\SntScore$も1989-1996と
  1996-2001とで分ける必要はないと考えられる．}．

このような文対応の数は，1989-1996と1996-2001を合せた全体で，約
130万だけある．なお，ここでの文とは，日本語文については，簡単な
プログラムにより，句点などで日本語記事を分割した結果であり，英
語文については，MXTERMINATOR
\cite{reynar97:_maxim_entrop_approac_ident_senten_bound}に対し
て前処理と後処理を適用して英語記事を分割した結果である．

文対応のなかでは，1対1対応が最も重要である．また，文対応といっ
ても，新聞記事には，中見出しなどの，必ずしも文でないものもある．
そのため，1対1対応のなかで，文末が句点やピリオドなどで終ってい
るもののみを取り出し，これを特に「1:1」と呼び，その他の対応を
「1:n」と呼ぶことにする．1:1の数は，約64万ある．1:nの数は，約66
万ある．

1:1の精度を求めるために，$\SntScore$により降順にソートされた上
位30万対応について，3万対応ごとに100ずつを一様無作為抽出した．
この各対応について，x/o の2値評価をした\footnote{評価は第1著者
  がした．ダブルチェックによると，初回の判定と2回目の判定とで
  100個あたり多くて2,3個程度のo/xの違いがあった．したがって，同
  一評価者内においては判定結果は安定していると言える．なお，1:n
  についてはダブルチェックはしていない．}．ここで，x は「意味が
全然違う」であり，oは「意味が全然違うことはない」である．その結
果の x/o の数を表\ref{tab:snteval}に示す．

\begin{table}[htbp]
  \small
  \centering
  \caption{順位と1:1の精度}
  \begin{tabular}{|r|c|c|}\hline
    範囲      & o数 & x数\\\hline
 1 - & 100 &  0 \\ 
 30001 - &  99 &  1 \\ 
 60001 - &  99 &  1 \\ 
 90001 - &  97 &  3 \\ 
 120001 - &  96 &  4 \\ 
 150001 - &  92 &  8 \\ 
 180001 - &  82 & 18 \\ 
 210001 - &  74 & 26 \\ 
 240001 - &  47 & 53 \\ 
 270001 - &  30 & 70 \\ \hline
\end{tabular}
  \label{tab:snteval}
\end{table}

表から分かるように，順位が下っていくにつれて，x の数が指数的に
増加している．このことは，$\SntScore$が，効率良く，適切な1:1を
上位に順位付けていることを示している．

表\ref{tab:snteval}から，15万対までは十分に信頼できる対応である
と言える．なお，15万対までの o の累積の割合は  0.982 である．

\begin{table}[htbp]
  \small
  \centering
\caption{順位と1:nの精度}
  \begin{tabular}{|r|c|c|c|}\hline
   範囲  & 1:nの数 &  o数  & x数 \\\hline
     1 - &  38090  &   98  &  2 \\
 90001 - &  59228  &   87  &  13 \\
180001 - &  71711  &   61  &  39 \\\hline
\end{tabular}
  \label{tab:paraeval}
\end{table}

次に，1:nの精度を求めるために，$\SntScore$により降順にソートさ
れた上位について，表\ref{tab:snteval}の「1-90000」
「90001-180000」「180001-270000」の各範囲について，それらの1:1
の$\SntScore$の範囲に収まるような1:nの精度を求めた．精度を求め
るときには，1:1のときと同様に，各範囲から100対を一様無作為抽出
し，x/o の2値評価をした．その結果を表\ref{tab:paraeval}に示す．
表より，「1-90000」の範囲の38090個の1:nについては，精度の良い対
応であると言える．

以上述べたように，$\SntScore$により文対応をソートすることにより，
1:1と1:nの双方について，上位には，十分に精度の高い文対応が得ら
れる．次に，$\SIM$について，$\SntScore$との比較のため，その精度
を述べる．比較にあたっては，$\SIM$の降順でソートした上位におけ
る精度を調べ，その精度により比較する．

まず，1:1についてであるが，$\SIM$の降順により1:1をソートし
た場合の上位15万対から100対を一様無作為抽出してo/xの判定をした結果
は，o数=93・x数=7であった．これを，表\ref{tab:snteval}に示され
る，$\SntScore$における上位15万対における無作為抽出500対でのo数
=491・x数=9と比べると，比率の差の検定を片側検定ですると，有意水
準1\,\% (実際には0.16\,\%)で$\SntScore$の方が有意にoの比率が高い．

次に，1:nについてであるが，1:1のときと同様に，1:nを$\SIM$の降順
にソートし，上位38090対から100対を一様無作為抽出してo/xの判定を
した結果は，o数=89・x数=11であった．これを，表
\ref{tab:paraeval}に示される$\SntScore$における上位38090対にお
ける無作為抽出100対でのo数=98・x数=2と比べると，比率の差の検定
を片側検定ですると，有意水準1\,\% (実際には0.49\,\%)で$\SntScore$の
方が有意にoの比率が高い．

これらより，1:1と1:nの双方について，$\SntScore$の方が，有用な尺
度であると言える．$\SntScore$の精度の方が$\SIM$の精度よりも高い
理由は，\ref{sec:artscore}節で述べたように，$\SntScore$が，
$\SIM$と違って，記事対応の良さまでも考慮した尺度であるからと考
える．

\section{データ公開}
\label{sec:openToThepublic}

我々は，本稿で述べた日英新聞記事対応付けの結果を数値情報として
エンコーディングすることにより，読売新聞とThe Daily Yomiuriの記
事データを持っている場合には，対応付けの結果が復元できるデータ
を作った．また，\ref{sec:snteval}節で述べた文対応について，日英
それぞれの文末が句点やピリオドなどで終了しているものについて，
1:1の上位15万対と1:nの上位3万対とを，読売新聞社からの許可を得て，
生の文として，上記数値データに追加したデータを試験的に公開した．

公開した期間は2002年10月23日から2002年11月22日の1ヶ月間であり，
公開の情報は，言語処理学会のメイリングリストを通じて流した．そ
の結果，31の機関からデータ入手の申し込みを受けた\footnote{今後の配布については第1著者まで問合せのこと．}．

それら機関の内訳\footnote{これら内訳は機関名などから推測したも
  のである．}は，国内が28，国外が3であった．また，企業からの申
し込みは4件あり，そのほかの27件は中学・高校・大学もしく
は研究機関であった．また，自然言語処理関係の研究機関から15件，
その他の機関からは16件であった．それら16件は，言語学関係が13件，
中学・高校が2件，また，民間企業で翻訳業務をしている企業からの申
し込みが1件あった．

これらの内訳から，このような日英対応付けデータが，自然言語処理
の研究機関だけでなく，言語学や中学・高校の英語教育などに関わる
人にとっても関心の高いものであることがわかる．

\section{今後の課題}
\label{sec:futurework}

本稿で述べた対応付けは，\ref{sec:guideline}節で述べた方針に基づ
いている．すなわち，既存の言語資源や手法を用いて対応付けをして，
その結果から，なるべく対応の良さそうなもののみを抽出するという
ものである．

その結果，\ref{sec:arteval}節や\ref{sec:snteval}節で述べたよう
に，上位にソートされた記事対応や文対応については，十分に精度の
高い対応が得られた．しかし，ソートの適用対象は，
\ref{sec:artalign}節や\ref{sec:sntalign}節の方法で求められた記
事対応や文対応であるので，どんなに精度良くソートしたとしても，
最初に求められた記事対応や文対応に含まれているよりも多くの正解
対応を得ることはできない．

たとえば，記事対応では，$\BM$により検索された記事対応しか対象と
していないため，$\BM$の検索精度により，抽出できる記事対応の精度
は制限される．この記事対応付けについては，\ref{sec:enhancement}
節で，$\AVSIM$を用いることにより，精度が向上すると考えられると
述べた．これと同様に，文対応においても，新聞記事に適した文対応
付けアルゴリズムを用いることにより，抽出できる，正解である文対
応の数が増えるものと考える．そのようなアルゴリズムを考案し，よ
り多くの正解対応を求めることが今後の課題である．

\end{document}
