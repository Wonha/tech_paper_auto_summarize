\section{実験 \label{sec:5}}

\subsection{人間の係り受け解析判断 \label{subsec:5.1}}

\subsubsection{実験設定}

\ref{sec:4}節に示したゲームを用いて，心理言語実験を行う．
ここでは\ref{sec:3}節に示した埋め込み構造に基づくガーデンパス文に対する係り受け解析の精度と反応時間について評価する．
21--27歳の日本語を母語とする\mmodified{大学生・大学院生13}人を対象とし，被験者には謝金を支払う．ゲームの利用方法を教示するため，被験者は6ページのマニュアルを5分間読む．その後，係り受け関係の教示のために，文の構造を解説している小学校4年生の国語の教科書2ページを読む．\modified{教示時には速度と正解率の両方を計測していることを被験者に伝え，速く・正確に解析を行うことを依頼する．ゲーム中は各文が正解しているか否かのみを提示する．}

練習として被験者は3--6文節により構成される10文1セットを対象に実験を行う．被験者の希望により，同じ文を3セットまで練習することができる．練習に利用した平均文数は \mmodified{16.9}文で 5--12分要する．練習に用いた文の正しい係り受け構造は図入りのマニュアルに全て示されている．尚，\mmodified{13}人の被験者のうち Nintendo WiiFit および関連ゲームを高頻度で遊んだことのあるものは1人のみ．

本実験において60文を解析用データとして準備した．\ref{sec:3}節に示した\modified{判定対象となる3種類の例文(CTRL・EB・LB) 10文ずつ計30文}とフィラー30文からなる．判定対象となる文は全て6文節だが，フィラー文は6--7文節．判定対象となる文はTokimotoの実験で利用されたものと同一であり，フィラー文はTokimotoが行ったように文中に出現する語彙は10年分の新聞記事頻度と NTT語彙特性\cite{Goitokusei}の語彙親密度により統制する．

各被験者は1回の本実験で40文を解析する．文は以下の順で提示する：最初の5文はフィラー文・次の30文はフィラー15文＋CTRL文5文＋EB文5文＋LB文5文をランダム順処理したもの・最後5文はフィラー文．被験者毎に異なるデータセットを作成する．1人の被験者に対して同じ文を2度提示しない．

図\ref{fig:room}に実験環境を示す．42インチのディスプレイ上には1024$\times$768解像度で表示したうちの 800$\times$600ピクセルの部分がゲーム画面である．実験に利用した部屋は防音室ではないが，可能な限り静音化した．バランスボードと画面の距離は230~cm．\modified{図中ホワイトボードの後ろに教示者がおり，練習時には操作方法の指示を行う．}

\begin{figure}[t]
\begin{center}
\includegraphics{18-4ia920f3.eps}
\end{center}
\caption{実験環境}
 \label{fig:room}
\end{figure}



\subsubsection{実験結果}

表\ref{table:result:pacc}に文型毎の文正解率と文単位の反応時間の標準残差（内的にスチューデント化した残差）の平均と標準偏差を示す．
標準残差の計算時は正しく解析した際の時間を以下のパラメータで線形回帰する\footnote{\modified{線形回帰は文の処理時間を正規化するために行う．回帰による予測値と実測値の乖離を検討し，所要時間の文型間の差異を評価する．}}：(a)モーラ数・(b)文字数・(c)文節数・(d)文の提示順・(e) ``default reduce''の数・(f) ``default shift''の数・(g) ``REDUCE''の数・(h) ``SHIFT''の数・(i)隣接する2アクションで``SHIFT''/``REDUCE''が交替した回数（逆順も含む）．

文正解率より，ガ格は文末の動詞に係け，ヲ格は近い動詞に係ける EB文の構造をより正解できる傾向が見られる．京大コーパスのマニュアルには，格要素が両方に係る場合，ガ格は最右要素，ヲ格は最左要素に係けるとある．その点について被験者については教示していない．ゲームがshift reduce 法に基づくために全ての要素をより近い要素に係ける傾向があると予測したが，CTRL文が EB文に比べてより誤ることから必ずしも近い要素に係ける傾向があるとはいえない．

\begin{table}[b]
\caption{文正解率と文単位の反応時間（人間の係り受け解析判断）}
\label{table:result:pacc}
\input{02table01.txt}
\end{table}
\begin{table}[b]
\caption{アクション単位の反応時間（人間の係り受け解析判断）}
\label{table:result:ptime}
\input{02table02.txt}
\end{table}

文単位の反応時間より，LB文は他の文に比べて解析に時間がかかることがわかった（調整化残差の分析より5\%水準で有意差あり）．CTRL文とEB文については統計的な有意差は見られなかった．
表 \ref{table:result:ptime} にアクション毎の反応時間を示す．表の先頭行にアクションのインデックスを示す．
対象となる文は全て6文節からなり，解析に必要なアクションの数は10であり，表中の列はこれに対応する．このうちほぼ半分のアクションは ``default reduce''・``default shift''である．
表中には，各3文型(CTRL・EB・LB)毎の結果を4行で示し，1行目は正しく解析するのに必要なアクション・2行目は反応時間（アクション間の実時間差からアニメーション提示時間を引いたもの）標準残差の平均・3行目は反応時間標準残差の標準偏差・4行目はアクション間の実時間差の平均を示す．
1行目のアクションの略号はそれぞれ：``r'' は``default reduce''・``s''は``default shift''・``R''は``REDUCE''・``S''は``SHIFT''を表す．
2行目と3行目の標準残差は正しく解析できた文についてアクション毎の反応時間を(a)モーラ数・(b)文字数・(d)文の提示順で線形回帰をしたものである．尚，文の反応時間のときに考慮した(c)および(e)--(i)は，各文型集合毎で全く一致するので考慮しない．

全ての文型について人間が反応可能な最初もしくは2番目のアクションで時間を要している．
このことから，被験者は正しく解析するために，逐次的に解析するわけではなく，最初に全文を読んでから解析（の入力）をしていると考える．



\subsubsection{関連研究}


Mazukaらは様々な心理言語実験手法について紹介している\cite{Mazuka1997a}．
ここでは各実験手法との対比を行う．

視線検出法では，被験者が文を読む際にどのくらい早く読むかを計測する．1回目の走査の時間・読み直しを行うかどうか・2回目の走査にかかる時間を計測する．この方法は文を読む速度を自然な方法で計測可能だが，視線検出システムは大変高価である．

自己ペースリーディング法は被験者の意思に基づいて文節（もしくは句）を逐次的に提示しながら，文を読む速度を計測する．文節を逐次的に提示するために，被験者は近い文節に係けるバイアスを持ち，ガーデンパス文を読む際には再解析(reanalysis steps)を強いることになる．実験では，再解析コストを\modified{誤り率と}文を読む速度により評価を行うことを目的とする．

質問法は被験者に対して文を理解しているか否かを直接聞く方法である．
目的に応じて質問は統制される．
{\it Who-did-what} 質問文では被験者が各文の意味を理解しているかどうかを評価する．
{\it Difficulty rating} 質問文では被験者が各文を理解するのにどのくらい簡単もしくは困難だったかを評価する．
{\it Misleadingness rating} 質問文では被験者が各文に対してどのくらい誤解しやすいかを評価する．

\modified{質問法は読む速度が得られる手法との組み合わせて行われることが多い．}
Tokimoto は図\ref{fig:examplesentences}に示す文を自己ペースリーディング法による読む速度の残差および{\it Who-did-what}質問法による誤り率で評価した．
彼の実験では，各文型の再解析コストは CTRL $<$ EB $<$ LBの順であった．
我々の結果を誤り率に変換すると EB $<$ （フィラー $<$）CTRL $<$ LB となり結果が異なる．ガーデンパス効果は LB 文にのみ認められた．{\modified この違いは手法と目的の違いに由来する．
Tokimotoは文節を逐次的に提示し，人間が文の意味を正しく理解しているか否かを調査することを目的とする．
対照的に我々の実験では被験者は実験中常に文全体を見ることができ，係り受け解析が正しく行えるかを調査することを目的とする．}

最後に，我々の実験設定において係り受け解析を shift reduce 法に基づいて解析することが適切かどうか考察する．ゲームで提示されるトレイ（スタックおよびキュー）は文脈情報として，それぞれ3文節ずつの窓幅の情報を与える．1文節目と3文節目($\langle$ $NP^{NOM}_1$, $V^{PAST}_3 \rangle$)および2文節目と3文節目($\langle$ $NP^{ACC}_2$, $V^{PAST}_3 \rangle$)の係り受け関係を判断する際に6文節目の動詞$V^{PAST}_6$の情報はトレイには表示されない．しかしながら画面の上部には常に文の全体を表示しており，この shift reduce 法に由来するバイアスを低減している．尚，文全体を表示しない（つまり文末の文節を見せない）設定で実験を行った場合，全て CTRL 文の構造に割り当て Tokimotoらの方法と同じく再解析に陥ることが，被験者5人による事前実験によりわかっている．



\subsection{人間と係り受け解析器の比較}

\subsubsection{実験設定}

\modified{\ref{subsec:5.1}節の心理言語実験で用いた 60文を各種係り受け解析器で解析することにより，人間による結果と6種類の係り受け解析器の結果とを比較する．}
KNP-3.01 は形態素解析器 JUMAN-6.0 の出力を元とし，CaboCha-0.60pre4 は形態素解析器 MeCab-0.98+IPADIC-2.7.0の出力を元とする．この2つの解析器についてはデフォールトのパラメータ設定を用いる．さらに，
Shift Reduce 法\cite{Sassano04} に基づく実装を京大コーパス約8,000文で訓練したもの (Shift Reduce 8K) と約34,000文で訓練したもの (Shift Reduce 34K)の2つと，
Tournament 法\cite{Iwatate08}に基づく実装を 約8,000文で訓練したもの (Tournament 8K) と約34,000文で訓練したもの(Tournament 34K)の2つを用いる．この4つの解析器では形態素解析器の出力として JUMAN-6.0を，さらに正しい文節区切りを与え，機械学習器としてサポートベクトルマシンを用いる．学習器に与える素性については元の論文に可能な限り合わせた．


\subsubsection{実験結果}

表\ref{table:result:vsnlp} に人間の判断と6種類の解析器の判断に基づく文正解率を示す．表中[J]はJuman-6.0の出力を，[M]はMeCab-0.98+IPADIC-2.7.0の出力を用いていることを意味し，[GB]は正しい文節区切りを与えていることを意味する．フィラー列は一般的な文に対する性能を表す．

全ての解析器は CTRL 文において性能が良く LB 文においては性能が悪かった．
この結果より，解析器はCTRL 文中の文節$NP^{NOM}_1$・$NP^{ACC}_2$・$NP^{DAT}_4$に対して正しい最も近い右要素$V^{PAST}_*$に係けることができているといえる． KNP-3.01のCTRL文に対する誤りは文節区切りの誤りであった．

CaboCha-0.60pre4 を含む shift reduce 法は近い係り受け関係を選好する傾向がある．
実際，$\langle$ $NP^{NOM}_1$, $V^{PAST}_3 \rangle$ もしくは $\langle$ $NP^{ACC}_2$, $V^{PAST}_3 \rangle$の係り受け関係を判断する際に，6番目の文節$V^{PAST}_6$は機械学習器の素性の窓幅の外側にあり評価されない．ゆえにこれらの解析器は EB文とLB文を全く解析できない．

\begin{table}[t]
\caption{文正解率 (\%) （人間と解析器の係り受け解析判断）}
 \label{table:result:vsnlp}
\input{02table03.txt}
\end{table}

Tournament 法は長い距離で係る係り受け関係をステップラダートーナメントにより考慮することができるため，いくつかの EB 文を解析できている．訓練データ量8,000文と34,000文との結果の差異は，係り受け関係$\langle$ $NP^{NOM}_1$, $V^{PAST}_3 \rangle$が 8,000文データには出現しないが 34,000文データには出現することによると考える．LB 文については，京都大学テキストコーパスのタグ付け基準「格要素が両方に係る場合，主格以外は近い方に係ける」が影響していると考える．

KNP-3.01 が EB・LB文に関して最良の結果を達成している．
KNP-3.01は格解析モデル\cite{Kawahara06}を含んでおり，EB・LB文の統語的意味的曖昧性をある程度解消できたのではないかと考える．

EB・LB文を正しく解析するためには，共起の情報\cite{Abekawa06}・格フレーム情報
\cite{Kawahara06}・格フレーム間遷移情報\cite{Kawahara09}を用いる手法が考えられる．特に LB文には次節で示すように生成モデルによる選択選好性のみでは解決できない文が含まれており，正しい解析のためには選択選好性と格要素の重複性排除の両方を同時推論する方策が必要であろう．


\subsubsection{関連研究}


Abekawaらは今回対象とした現象に似た関係節内の関係・外の関係の識別を行った\cite{Abekawa05}．
本研究で扱った CTRL文は外の関係に対応し，EB・LB文は内の関係に対応する．
彼らは決定木モデルを用いて，共起情報・格フレーム情報・外の関係になる度合いを用いて，この2種類を識別する手法を提案した．


\subsection{Late Boundary 各文の分析}


ここでは人間にも解析器にも解析が困難であった Late Boundary (LB) 文について，統語的制約と選択選好性の観点から分析する．
LB 文は主節の動詞 \modified{$V_{6}$} がガ格ヲ格ニ格の三項を取り，関係節内の動詞 \modified{$V_{3}$} がガ格ヲ格の\modified{二項}を取る．関係節内の動詞 \modified{$V_{3}$} が後置する係り先の \modified{$NP_{4}$} をヲ格として取るために二重ヲ格違反と常に左に係る統語的制約により一意に構造が決まる．
これに対し「より近い要素に係ける」という選好性と，主節の動詞 \modified{$V_{6}$}・関係節内の動詞 \modified{$V_{3}$}間の選択選好性の強弱関係により，制約を無視してしまい誤るという傾向がある．
より詳細に分析するために LB 文 10文について，人の文正解率・KNPの結果・京都大学格フレームの頻度の大小関係・Google のヒット件数に基づく正規化頻度の大小関係を表\ref{table:result:LB}に示す．\modified{京都大学格フレームの頻度について，$NP_{2}$vs$NP_{4}$ は $NP_{2}^{ACC}V_{3}$ と$NP_{4}^{ACC}V_{3}$で，$V_{3}$vs$V_{6}$ は $NP_{2}^{ACC}V_{3}$ と$NP_{2}^{ACC}V_{6}$ で，それぞれどちらの頻度が高いかを表す．}尚，0 は両方の組み合わせが京都大学格フレームに登録されていなかったことを表す．Google の正規化頻度は，前者を $NP_{2}^{ACC}$ と $NP_{4}^{ACC}$ の件数で，後者を $V_{3}$ と $V_{6}$ の件数で正規化を行う．\modified{例文は人の文正解率の良い順に並べられ，下線は選択選好性が例文を正しく解析するために良い影響を与えるものを表す．}

\begin{table}[b]
\caption{LB文の実験結果と選択選好性} 
\label{table:result:LB} 
\input{02table04.txt}
\end{table}


KNP が正解している文は人間にとっても解析が容易で，LB 文の人正解率が高い傾向にある．
京都大学格フレームが例文の係り受け全てを被覆していないが，人と誤り傾向の相関があることがわかる．Google の正規化頻度は全例文を被覆しているが，係り受け関係ではなく\modified{連続文字列}によるものなので，\modified{人間の誤り傾向と Google のヒット件数による選択選好性の間に矛盾があるところがいくつかある．}実際，3つの項をとる述語に対してガ格・ヲ格・ニ格の順に述語から遠く置かれる傾向にあることを考えると直接比較できるものではない．
しかしながら，$NP_{2}$ と $NP_{4}$ のどちらが $V_{3}$ に係るかを評価した際に京都大学格フレームだけでなく，Google ヒット件数でも $NP_{2}$ の方が強い場合には，人も間違える傾向にあることがわかる．このことから選択選好性の強弱関係が統語的に制約に反している場合には人は係り受け構造同定を誤りやすいことがわかる．


