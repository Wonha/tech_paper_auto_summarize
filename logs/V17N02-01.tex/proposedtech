    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.2}
\usepackage[dvips]{graphicx}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\usepackage{multirow}
\usepackage{amsmath,amssymb}
\usepackage[noreplace,multi]{otf}
\usepackage{slashbox}



\Volume{17}
\Number{2}
\Month{April}
\Year{2010}


\received{2009}{7}{1}
\revised{2009}{10}{1}
\rerevised{2009}{10}{23}
\accepted{2010}{2}{22}

\setcounter{page}{3}


\jtitle{中国語への翻字における関連語抽出の応用}
\jauthor{黄　　海湘\affiref{Author_1} \and 藤井　　敦\affiref{Author_2}}
\jabstract{
外国語を翻字するときに，日本語や韓国語ではカタカナやハングルなどの表音文字を用いるのに対して，中国語では漢字を用いる．
しかし，漢字は表意文字であるため，発音が同じでも漢字によって意味や印象は異なる可能性がある．
この問題を解消するために，ユーザが与えた関連語に基づいて翻字に使用する漢字を選択する手法がある．
しかしユーザの負担が大きいため，本研究は，翻字対象の関連語をWorld Wide Webから自動的に抽出し，中国語への翻字に使用する手法を提案する．
評価実験によって提案手法の有効性を示す．
}
\jkeywords{翻字，意味，印象，表意文字，関連語}


\etitle{An Application of Related Term Extraction to Transliteration into Chinese}
\eauthor{HaiXiang Huang\affiref{Author_1} \and Atsushi Fujii\affiref{Author_2}} 
\eabstract{
To transliterate foreign words, in Japanese and Korean, phonograms such as Katakana and Hangul are used. In Chinese, the pronunciation of a source word is spelled out with Kanji characters. However, because Kanji comprises ideograms, different characters are associated with the same pronunciation but can potentially convey different meanings and impressions. 
To select appropriate Kanji characters, an existing method requests a user to provide one or more related terms, but it is expensive.
In this paper, we propose a method to select characters in transliteration into Chinese using related terms automatically extracted from the World Wide Web.
We show the effectiveness of our method experimentally.
}
\ekeywords{Transliteration, Meaning, Impression, Ideograms, Related terms}

\headauthor{黄，藤井}
\headtitle{中国語への翻字における関連語抽出の応用}

\affilabel{Author_1}{筑波大学大学院図書館情報メディア研究科}{Graduate School of Library, Information and Media Studies, University of Tsukuba}
\affilabel{Author_2}{東京工業大学大学院情報理工学研究科}{Graduate School of Information Science and Engineering, Tokyo Institute of Technology}



\begin{document}
\maketitle


\section{提案する翻字手法}\label{sec:method}

\subsection{概要}\label{sec:overview}

\begin{figure}[b]
\begin{center}
\includegraphics{17-2ia2f1.eps}
\end{center}
 \caption{提案する翻字手法の概要}
 \label{fig:1}
\end{figure}

本研究で提案する翻字手法の概要を図\ref{fig:1}に示す． 
図\ref{fig:1}は，\cite{Article_21}と同様に左から「発音モデル」，「印象モデル」，「言語モデル」に大別される．
図\ref{fig:1}において，太い破線で囲まれた部分が本研究の特長である．
以下，\mbox{図\ref{fig:1}}に基づいて翻字手法について説明する．
本手法への入力は2つある．
1つ目は，翻字対象となる外国語の用語である．
2つ目は，翻字対象の種別として「人名」，「企業名」，「商品名」などのカテゴリを入力する．
本手法はこれらの入力に対して，1つ以上の漢字列を翻字の候補として出力する．
\cite{Article_21}では，3つ目の入力として翻字対象の意味や印象を表す「印象キーワード」を人手で入力する必要がある．
しかし，本手法ではWebから関連語を自動抽出する．
「発音モデル」，「印象モデル」，「言語モデル」に基づく翻字手法や関連語抽出手法そのものに新規性はない．
本研究の貢献は，{\cite{Article_21}の翻字手法に関連語抽出手法を統合して，
ユーザが印象キーワードを与える負担を削減する点にある．

図\ref{fig:1}の最左では，「発音モデル」によって翻字対象と発音が似ている漢字列とそれぞれの確率が得られており，これらの漢字列が翻字候補となる．
現在，翻字対象となる外国語として日本語のカタカナ語を対象としている．
カタカナ語は発音表記であるローマ字に変換することが容易だからである．
ただし，ローマ字表記に変換することができれば，他の言語を入力することも可能である．

図\ref{fig:1}の中央では，「印象モデル」によって，自動抽出した翻字対象の関連語に関連する漢字とそれぞれの確率が得られている．
図\ref{fig:1}では，「\UTFC{559C}\UTFC{7231}」，「\UTFC{666E}\UTFC{53CA}」，「\UTFC{666E}\UTFC{901A}」，「\UTFC{597D}」といった関連語の集合を用いて，「\UTFC{7231}」，「\UTFC{666E}」，「\UTFC{597D}」といった漢字とそれぞれの確率が得られている．

\cite{Article_19}と\cite{Article_21}では，関連語（印象キーワード）はユーザが中国語で与える必要がある．
したがって，ユーザは翻字対象が指す実体や概念について知っていなければならず，また，中国語も知っていなければならない．
その結果，システムを利用できるユーザが制限されてしまう．
本研究は関連語を自動抽出して，この問題を解消する．
なお，「印象キーワード」という用語は\cite{Article_21}に従っており，実際には人手で与えた関連語である．

図\ref{fig:1}の最右では，入力された種別に対応する言語モデルとして「企業名言語モデル」が選ばれている．

発音モデルで得られた翻字候補は複数になる場合があるため，それぞれに順位を付ける．
具体的には，発音モデルで得られた確率を印象モデルおよび言語モデルで得られた漢字の確率と統合して，翻字対象に順位を付ける．

以下，\ref{sec:prob}で確率的な漢字選択手法の全体像について説明する．
\ref{sec:pronu}〜\ref{sec:categ}で「発音」，「印象」，「言語」のモデル化について個別に説明し，\ref{sec:auto}で関連語の抽出について説明する．
\ref{sec:prob}〜\ref{sec:categ}は\cite{Article_21}に基づいている．


\subsection{漢字選択ための確率モデル}\label{sec:prob}

本研究における翻字の目的は，「翻字対象のローマ字表記$R$」，「関連語$W$」，「翻字対象の種別$C$」が与えられた条件のもとで，$P(K|R,W,C)$が最大になる漢字列$K$を選択することである．
式(\ref{eq:Bayes})を用いて$P(K|R,W,C)$を計算する．
\pagebreak
\begin{equation}
 \begin{split}
  P(K|R,W,C)&=\frac{P(R,W,C|K)\times P(K)}{P(R,W,C)} \\
            &\approx \frac{P(R|K)\times P(W|K)\times P(C|K)\times P(K)}{P(R,W,C)}\\
            &\propto P(R|K)\times P(W|K)\times P(C|K)\times P(K)\\
            &= P(R|K)\times P(W|K)\times P(C,K)\label{eq:Bayes}
 \end{split}
\end{equation}
式(\ref{eq:Bayes})の1行目はベイズの定理を用いた変形であり，2行目では$R$，$W$，$C$が互いに独立であると仮定している．
$P(R,W,C)$は$K$に依存しないため無視する．
最終的に，$P(K|R,W,C)$は$P(R|K)$，$P(W|K)$，$P(C,K)$の積として近似され，それぞれ「発音モデル」，「印象モデル」，「言語モデル」と呼ばれる．


\subsection{発音モデル}\label{sec:pronu}

発音モデルは，中国語の漢字列$K$が与えられた条件のもとで，ローマ字表記$R$が生成される条件付き確率$P(R|K)$であり，式(\ref{eq:Pronun})を用いて計算する．
ローマ字表記はヘボン式を使用し，中国語のピンイン$Y$を中間言語として，中国語の漢字に変換する．
\begin{equation}
 \begin{split}
  P(R|K)&\approx P(R|Y)\times P(Y|K) \\
        &\approx\prod_{i=1}^N P(r_{i}|y_{i})\times\prod_{i=1}^N P(y_{i}|k_{i})\label{eq:Pronun}
 \end{split}
\end{equation}
$r_{i}$，$y_{i}$，$k_{i}$はそれぞれローマ字の音節，ピンインの音節，漢字１文字である．
例えば，漢字列「\UTFC{7231}\UTFC{666E}\UTFC{751F}」が与えられた条件のもとで，ローマ字の音節「e pu son」が生成される確率を計算する場合は，ピンインの音節「ai pu sheng」を中継して，式(\ref{eq:Cyukei})のように計算する．
\begin{eqnarray}
&&P(\textrm{e pu son}|\textrm{\UTFC{7231}\UTFC{666E}\UTFC{751F}})\label{eq:Cyukei}\nonumber\\
&&=\!P(\textrm{e\,pu\,son}|\textrm{ai\,pu\,sheng})\!\times \!P(\textrm{ai\,pu\,sheng}|\,\textrm{\UTFC{7231}\UTFC{666E}\UTFC{751F}}) \nonumber\\
&&=\!P(\textrm{e}|\textrm{ai})\!\times \!P(\textrm{pu}|\textrm{pu})\!\times \!P(\textrm{son}|\textrm{sheng})\!\times \!P(\textrm{ai}|\textrm{\UTFC{7231}})\times \!P(\textrm{pu}|\textrm{\UTFC{666E}})\!\times \!P(\textrm{sheng}|\textrm{\UTFC{751F}})
\end{eqnarray}

\begin{table}[b]
\caption{ローマ字音節とピンイン音節の対応頻度と確率}
\label{table:Pry}
\input{02table01.txt}
\end{table}
\begin{table}[b]
\caption{ピンイン音節と漢字の対応頻度と確率}
\label{table:Pyk}
\input{02table02.txt}
\end{table}

式(\ref{eq:Pronun})中の$P(r_{i}|y_{i})$と$P(y_{i}|k_{i})$は式(\ref{eq:Ryk})を用いて計算する．
\begin{equation}
 \begin{split}
  P(r_{i}|y_{i})=\frac{F(r_{i},y_{i})}{\displaystyle{\sum_{j}}F(r_{j},y_{i})} \\
  P(y_{i}|k_{i})=\frac{F(y_{i},k_{i})}{\displaystyle{\sum_{j}}F(y_{j},k_{i})}\label{eq:Ryk}
 \end{split}
\end{equation}
$F(r_{i},y_{i})$はローマ字の音節$r_{i}$とピンインの音節$y_{i}$が対応する頻度であり，$F(y_{i},k_{i})$はピンインの音節$y_{i}$と漢字$k_{i}$が対応する頻度である．
これらの頻度を計算するために，日中対訳辞書\cite{Book_02}のピンイン付き中国語と対応するカタカナ語$1,136$対を参考にして，ローマ字とピンインの音節，ピンインの音節と漢字を人手で対応付けた．
これらの一部をそれぞれ表１と2に示す．
表\ref{table:Pry}と\ref{table:Pyk}において，中国語のピンインには，発音の四声に基づいて1〜4の識別子が付けられている．
表\ref{table:Pry}では，1つのローマ字音節$r_{i}$に複数のピンインの音節$y_{i}$が対応している．
例えば，ローマ字の「a」に対して，3種類のピンイン音節「a1」，「ai4」，「an1」が対応している．
表\ref{table:Pyk}では，確率$P(y_{i}|k_{i})$は$1.00$になる場合が多く，一般的には１つの漢字は１つのピンインと対応することが分かる．
しかし，「\UTFC{4F5B}」と「\UTFC{4F3D}」はそれぞれ2つのピンインと対応している．

翻字を行う際に，ローマ字表記$R$の分割が複数ある場合は，すべての可能な分割を考慮する．
例えば，「epuson（エプソン）」は，二つのピンイン列と一致して次のように分割される．
\begin{itemize}
\item e pu son: ai pu sheng
\item e pu so n: ai pu sou an
\end{itemize}



\subsection{印象モデル}\label{sec:meaning}

印象モデルは，漢字列$K$が与えられた条件のもとで，関連語列$W$が生成される条件付き確率$P(W|K)$である．
$W$と$K$をそれぞれ単語$w_{i}$と漢字１文字$k_{j}$の単位で分割して，$P(W|K)$を$P(w_{i}|k_{j})$に基づいて近似する．
しかし，$w_{i}$と$k_{j}$の数が常に同じであるとは限らないため，式(\ref{eq:Ass})を用いて$P(W|K)$を計算する．
すなわち，各$k_{j}$について$P(w_{i}|k_{j})$が最大となる$w_{i}$だけを考慮する．
\begin{equation}
 P(W|K)\approx {\displaystyle \prod_{j}}\max_{i}P(w_{i}|k_{j})\label{eq:Ass}
\end{equation} 

\begin{table}[b]
\caption{$P(w_{i}|k_{j})$の例}
\label{table:Pwk}
\input{02table03.txt}
\end{table}

表\ref{table:Pwk}に漢字3つと関連語4つに関する$P(w_{i}|k_{j})$を示す．
表中の「--」は，$w_{i}$と$k_{j}$が対応しないことを示している．
表\ref{table:Pwk}の例において，$P(W|K)$は式(\ref{eq:wk})のように計算される．
\begin{eqnarray}
&&P(\textrm{\UTFC{559C}\UTFC{7231} \UTFC{666E}\UTFC{53CA} \UTFC{666E}\UTFC{901A} \UTFC{751F}\UTFC{52A8}}|\textrm{\UTFC{7231}\UTFC{666E}\UTFC{751F}})\label{eq:wk} \nonumber\\
&&=\!P(\textrm{\UTFC{559C}\UTFC{7231}}|\textrm{\UTFC{7231}})\!\times \!P(\textrm{\UTFC{666E}\UTFC{53CA}}|\textrm{\UTFC{666E}})\!\times \!P(\textrm{\UTFC{751F}\UTFC{52A8}}|\textrm{\UTFC{751F}})=0.02 \times 0.03 \times 0.03\\
&&=0.000018  \nonumber
\end{eqnarray}

$P(w_{i}|k_{j})$は式(\ref{eq:Ass2})を用いて計算する．
\begin{equation}
P(w_{i}|k_{j})=\frac{F(w_{i},k_{j})}{{\displaystyle\sum_{w}}F(w,k_{j})}\label{eq:Ass2}
\end{equation}
$F(w_{i},k_{j})$は$w_{i}$ と$k_{j}$の共起頻度であり，本研究では漢字字典を用いて計算する．
すなわち，漢字字典の見出し漢字を$k_{j}$として，$k_{j}$の意味記述に使用されている単語を$w_{i}$とする．
中国語の漢字字典\footnote{\UTFC{65B0}\UTFC{534E}\UTFC{5B57}\UTFC{5178}\UTFC{7535}\UTFC{5B50}\UTFC{7248}（新華字典電子版）v1.0.}から外来語の表記に良く使われる見出し漢字$599$文字を人手で選択し，見出し漢字の意味記述をSuperMorpho\footnote{http://www.omronsoft.com/}で形態素解析して，単語と見出し漢字の共起頻度を計算した．\
表~\ref{table:kanji2word}に$F(w_{i},k_{j})$の例を示す．
表\ref{table:kanji2word}では，$P(w_{i}|k_{j})$が高いほど，漢字と単語の関係が強いことを示している．
例えば，「\UTFC{9AD8}（高い）」，「\UTFC{597D}（良い）」，「\UTFC{4E50}（楽しい）」という3つの漢字$k_{j}$に対して$P(w_{i}|k_{j})$が最も高い単語$w_{i}$は，それぞれ「\UTFC{52A0}\UTFC{9AD8}（高くする）」，「\UTFC{597D}\UTFC{5403}（おいしい）」，「\UTFC{4E50}\UTFC{4E8E}（喜び）」である．
ここで括弧内は各中国語に対する日本語訳を示す．

\begin{table}[t]
\caption{漢字辞典における漢字と単語との共起頻度と確率}
\label{table:kanji2word}
\input{02table04.txt}
\end{table}


\subsection{言語モデル}\label{sec:categ}

言語モデル$P(C,K)$は，用語の種別$C$に関するコーパスを用いてモデル化する．
具体的には，式(\ref{eq:Language})を用いて計算する．
\begin{equation}
P(C,K)=P(C) \!\times \!P(K|C) \propto P(K|C)\label{eq:Language}
\end{equation}
$P(C)$は$K$に依存しないので無視する．
原理的には，種別$C$のコーパスが与えられた条件のもとで，漢字列$K$が生成される条件付き確率を計算する．
実際は，種別$C$に関するコーパスを用いて漢字のNグラム確率を計算する．
現在は，$N=1$としている．
本研究では，以下に示す3種類の言語モデルを構築し，実験に使用した．
\begin{itemize}
\item 標準言語モデル：中国北京大学計算語言学研究所\footnote{http://icl.pky.edu.cn/}が富士通\footnote{http://www.frdc-fujitsu.com.cn/}と共同で作成した「PFR\UTFC{4EBA}\UTFC{6C11}\UTFC{65E5}\UTFC{62A5}\UTFC{6CE8}\UTFC{8BED}\UTFC{6599}\UTFC{5E93}（人民日報タグ付きコーパス）」\mbox{1998年}1月の新聞記事一ヶ月分から構築したモデルであり，異なり$4,540$（延べ$12,229,563$）の漢字を含む．
\item 企業名言語モデル：中国科学院計算技術研究所が主催している「\UTFC{4E2D}\UTFC{6587}\UTFC{81EA}\UTFC{7136}\UTFC{8BED}\UTFC{8A00}\UTFC{5904}\UTFC{7406}\UTFC{5F00}\UTFC{653E}\UTFC{5E73}\UTFC{53F0}（中国語自然言語処理オープンソース）」\footnote{http://www.nlp.org.cn/}が提供している$22,569$社を含む「\UTFC{516C}\UTFC{53F8}\UTFC{540D}\UTFC{5F55}\UTFC{5E93}（企業名リスト）」から構築したモデルであり，異なり$2,167$（延べ$78,432$）の漢字を含む．
\item 人名言語モデル：上記「\UTFC{4E2D}\UTFC{6587}\UTFC{81EA}\UTFC{7136}\UTFC{8BED}\UTFC{8A00}\UTFC{5904}\UTFC{7406}\UTFC{5F00}\UTFC{653E}\UTFC{5E73}\UTFC{53F0}」が提供している「\UTFC{5E26}\UTFC{8BCD}\UTFC{6027}\UTFC{8BCD}\UTFC{9891}\UTFC{7684}\UTFC{6269}\UTFC{5C55}\UTFC{8BCD}\UTFC{5178}（品詞および出現頻度付き拡張辞典）」から$38,406$件の人名を抽出して構築したモデルであり，異なり$2,318$（延べ$104,443$）の漢字を含む．
\end{itemize}

また，上記のモデルを構築する際に，SuperMorphoを用いてコーパスの形態素解析を行い，句読点，記号，機能語を事前に削除した．

\subsection{関連語の自動抽出}\label{sec:auto}

本研究では，翻字対象が指す実体や概念に対して，その意味や印象を中国語で表記した関連語をWebから自動的に抽出し，翻字に利用する．
図\ref{fig:2}に，「エプソン」の関連語を自動抽出する過程を示す．
図\ref{fig:2}の上部では翻字対象に関連する関連語候補を抽出し，下部では抽出する関連語を選択している．
以下，それぞれについて説明する．

\begin{figure}[b]
\begin{center}
\includegraphics{17-2ia2f2.eps}
\end{center}
 \caption{関連語自動抽出の概要}
 \label{fig:2}
\end{figure} 

翻字対象の関連語を抽出するためには，翻字対象に関する文書が必要である．
例えば，翻字対象が商品名であれば，その商品を紹介する文書であり，翻字対象が企業名であれば，企業の理念などに関する文書である．
このような文書として，フリー百科事典「ウィキペディア（Wikipedia）」日本語版\footnote{http://ja.wikipedia.org/wiki/}の記事を利用した．
2009年6月15日の時点では約$150$万の項目があり，一般名詞，人名，地名，企業名，商品名などが登録されている．
図{\ref{fig:karati}}は地名「カラチ」をWikipediaで検索して得られた記事ページの抜粋である．
図{\ref{fig:karati}}において，最上部の「カラチ」は記事の名称（記事名）であり，その下は本文である．
図{\ref{fig:karati}}の{\mbox{「目次」}}に示されているように，本文は「1 歴史」，{\mbox{「2 気候」}}，{\mbox{「3 人口統計」}}などの「セクション（節）」によって構造化されることがある．

関連語候補の抽出は以下の手順に従って行う．
\begin{enumerate}
\item 翻字対象語をWikipediaで検索して記事ページを取得する．
現在の手法では，記事ページがない用語に対しては関連語を抽出することができない．
\item 取得した記事ページからHTMLタグを削除し，茶筌\footnote{http://chasen.naist.jp/hiki/ChaSen/}で形態素解析を行う．
\item 形態素解析の結果から，名詞と形容詞を翻字対象の関連語候補として抽出する．
ただし，「名詞」のうち「名詞—数」，「名詞—接尾—助数詞」，「名詞—副詞可能」，「名詞—非自立」，「名詞—代名詞」は抽出しない． 
図\ref{fig:2}では，「普及」や「普通」などの名詞と「好き」や「良い」などの形容詞が関連語の候補として抽出されている．
\end{enumerate}

\begin{figure}[b]
\begin{center}
\includegraphics{17-2ia2f3.eps}
\end{center}
 \caption{Wikipediaにおける「カラチ」の記事ページの抜粋}
 \label{fig:karati}
\end{figure}

ここで，図{\ref{fig:karati}}に示した記事ページの本文は構造化されているため，上記の手順（2）において，
関連語抽出に有効な特定のセクション内だけを解析対象とする手法が考えられる．
しかし，
Wikipediaのガイドブックによる記事ページの編集方針\footnote{http://ja.wikipedia.org/wiki/Wikipedia:ガイドブック\_編集方針}では，記事は{\mbox「記事名（項目名）」}と{\mbox「本文」}で構成され，
本文の基本構成は概要から次第に詳細内容になり，
段落の数が多くなるようなら，「見出し」を付けて「セクション（節）」に分けるとしか規定していない．
見出しの付け方やセクションの分け方は記事の著者によって方針が異なる．

例えば，図{\ref{fig:karati}}で示した「カラチ」の記事ページは，
\pagebreak
「歴史」，「気候」，「人口統計」，「交通」，「姉妹都市」，「脚注」，「ギャラリー」の7セクションで構成されている．
一方，「ハワイ」の記事ページは，「歴史」，「地理」，「人口動勢」，「政治と法律」，「経済」，「教育」，「芸術・文化」，「日本との関わり」，「その他」，「注」，「関連項目」，「外部リンク」の12セクションで構成されている．
同じ地名に関する記述であるにも拘らず，「カラチ」と「ハワイ」の記事に共通するセクションは「歴史」だけである．
さらに，同じ見出しのセクションでも，著者によって記述の方針が異なる可能性がある．
このような状況では関連語抽出に有効なセクションを事前に定義することが困難である．
そこで，今回の実験では本文全体を対象として関連語の候補を抽出した．

Wikipediaから抽出した名詞と形容詞の中には，翻字対象との関連が低い語も含まれているため，翻字に使用する関連語を選択する必要がある．
単語間の関連度を計算する手法\cite{Article_22,Article_25}が複数提案されている．
本研究では，翻字対象と関連語候補間の相互情報量\cite{Article_03,Article_15}を計算して，その値が高い語を関連語として抽出する．
ここでいう相互情報量とは，正確にはpointwise mutual informationであり，式(\ref{eq:mutual})を用いて計算する．
\begin{equation}
I(X,Y)=\log \frac{P(X,Y)}{P(X)\times P(Y)} \label{eq:mutual}
\end{equation}
$P(X)$と$P(Y)$は単語$X$と$Y$それぞれの出現確率であり，$P(X,Y)$は$X$と$Y$が同時に出現する確率である．
ここでは便宜上，$X$を翻字対象，$Y$を1つの関連語候補とする．
図\ref{fig:2}の例では，$X$は「エプソン」であり，$Y$は「好き，普及，普遍，良い」のいずれかである．

関連語の選択は以下の手順に従って行う．
\begin{enumerate}
\item $P(X)$，$P(Y)$，$P(X,Y)$を計算するために，「$X$」，「$Y$」，「$X$ and $Y$」を検索キーワードとしてYahoo! JAPAN\footnote{http://www.yahoo.co.jp/}で検索し，検索結果の総数でそれぞれの確率を近似する．
\item 式(\ref{eq:mutual})の値が高い候補を関連語として選択する．
図\ref{fig:2}では，「エプソン」の関連語として「好き」，「普及」，「普通」，「良い」が選ばれている．
選択する関連語の件数は実験的に決めるパラメタである．\ref{sec:exp}の評価実験では，関連語の件数を段階的に変化させて翻字への影響について考察する．
\item （2）で選択した関連語を中国語に翻訳する．
原理的には，この作業は機械翻訳システムを利用することで自動化することができる．
しかし，現在はYahoo! JAPAN\footnote{http://honyaku.yahoo.co.jp/}を利用して人手で翻訳している．
ただし，Yahoo! JAPANで翻訳できずに原言語がそのまま返される関連語は削除する．
\mbox{図\ref{fig:2}}では，「\UTFC{559C}\UTFC{7231}」，「\UTFC{666E}\UTFC{53CA}」，「\UTFC{666E}\UTFC{901A}」，「\UTFC{597D}」はそれぞれ「好き」，「普及」，「普通」，「良い」に対する訳語であり，翻字対象の関連語として使用される．
\end{enumerate}



\end{document}
