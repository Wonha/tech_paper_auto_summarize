語義曖昧性解消は古典的な自然言語処理の課題の一つであり，先行研究の多くは教師あり学習により成果を挙げてきた[CITE]．
しかし，教師あり学習による語義曖昧性解消においてはデータスパースネスが大きな問題となる．
多義語の語義がその共起語より定まるという仮定に基づけば，一つの多義語と共起し得る単語の種類が数万を超えることは珍しくなく，この数万種類のパターンに対応するために充分な語義ラベル付きデータを人手で確保し，教師あり手法を適用するのは現実的でない．
一方で語義ラベルが付与されていない，いわゆるラベルなしのデータを大量に用意することは，ウェブの発展，学術研究用のコーパスの整備などにより比較的容易である．
このような背景から，訓練データと大量のラベルなしデータを併用してクラス分類精度を向上させる半教師あり学習，または訓練データを必要としない教師なし学習による効果的な語義曖昧性解消手法の確立は重要であると言える．
本稿では半教師あり手法の一つであるブートストラッピング法を取り上げ，従来のブートストラッピング法による語義曖昧性解消手法の欠点に対処した手法を提案する．
ブートストラッピング法による語義曖昧性解消においては主にSelf-training（自己訓練）[CITE]とCo-training（共訓練）[CITE]の二つのアプローチがある[CITE]．
まずこれらの手法に共通する手順を述べると次のようになる．
Self-trainingとCo-trainingの違いは，前者はStep 2で用いる分類器は一つであるのに対し，後者は二つ用いる点にある．
またCo-trainingにおいては二つの独立した素性集合を設定し，各分類器を一方の素性集合のみを用いて作成する．
Co-trainingにおいてこのように設定するのは，Step 3において追加する事例を一方の素性のみから決定することから，追加事例のもう一方の素性を見たとき新しい規則の獲得が期待できるためである．
Self-trainingとCo-trainingの欠点はいずれも性能に影響するパラメータが多数存在し，かつこれらのパラメータを最適化する手段がないことである．
具体的にはStep 1のプールサイズ[MATH], Step 3の[MATH]に加える事例の個数[MATH],手順の反復回数[MATH]は全てパラメータであり，タスクに合わせた調整を必要とする．
本稿では，ラベル付きデータとラベルなしデータを同時に活用しつつも，パラメータ設定をほとんど不要とする新しい手法を提案する．
本手法はまずヒューリスティックと教師あり学習で構築した分類器によるラベルなしデータの二段階の「分類」を行う．
ここで「分類」とは語義曖昧性解消を行い，語義ラベルを付与することを意味する．
本稿では以後特に断りがない限り，分類とはこの語義ラベル付与のことを指す．
二段階分類したラベルなしデータの中で条件を満たすデータはオリジナルのラベル付きデータに加えられる．
その結果，パラメータ設定がほぼ不要なブートストラッピング的半教師あり手法による語義曖昧性解消を実現する．
さらに追加するラベルなしデータの条件を変えることで複数の分類器を作成し，アンサンブル学習することで，パラメータの変化に頑健な分類器を生成する．
本稿の構成は以下の通りである．
[REF_sec:work]節にて関連研究および本研究の位置付けを述べる．
[REF_sec:method]節にて提案手法およびその原理を並行して述べる．
[REF_sec:exp]節にてSemEval-2日本語タスク[CITE]のデータセットに提案手法を適用した実験の結果を示す．
[REF_sec:conc]節にて結論を述べる．
語義曖昧性解消は古典的な自然言語処理の課題の一つであり，先行研究の多くは教師あり学習により成果を挙げてきた[CITE]．
しかし，教師あり学習による語義曖昧性解消においてはデータスパースネスが大きな問題となる．
多義語の語義がその共起語より定まるという仮定に基づけば，一つの多義語と共起し得る単語の種類が数万を超えることは珍しくなく，この数万種類のパターンに対応するために充分な語義ラベル付きデータを人手で確保し，教師あり手法を適用するのは現実的でない．
一方で語義ラベルが付与されていない，いわゆるラベルなしのデータを大量に用意することは，ウェブの発展，学術研究用のコーパスの整備などにより比較的容易である．
このような背景から，訓練データと大量のラベルなしデータを併用してクラス分類精度を向上させる半教師あり学習，または訓練データを必要としない教師なし学習による効果的な語義曖昧性解消手法の確立は重要であると言える．
本稿では半教師あり手法の一つであるブートストラッピング法を取り上げ，従来のブートストラッピング法による語義曖昧性解消手法の欠点に対処した手法を提案する．
ブートストラッピング法による語義曖昧性解消においては主にSelf-training（自己訓練）[CITE]とCo-training（共訓練）[CITE]の二つのアプローチがある[CITE]．
まずこれらの手法に共通する手順を述べると次のようになる．
Self-trainingとCo-trainingの違いは，前者はStep 2で用いる分類器は一つであるのに対し，後者は二つ用いる点にある．
またCo-trainingにおいては二つの独立した素性集合を設定し，各分類器を一方の素性集合のみを用いて作成する．
Co-trainingにおいてこのように設定するのは，Step 3において追加する事例を一方の素性のみから決定することから，追加事例のもう一方の素性を見たとき新しい規則の獲得が期待できるためである．
Self-trainingとCo-trainingの欠点はいずれも性能に影響するパラメータが多数存在し，かつこれらのパラメータを最適化する手段がないことである．
具体的にはStep 1のプールサイズ[MATH], Step 3の[MATH]に加える事例の個数[MATH],手順の反復回数[MATH]は全てパラメータであり，タスクに合わせた調整を必要とする．
本稿では，ラベル付きデータとラベルなしデータを同時に活用しつつも，パラメータ設定をほとんど不要とする新しい手法を提案する．
本手法はまずヒューリスティックと教師あり学習で構築した分類器によるラベルなしデータの二段階の「分類」を行う．
ここで「分類」とは語義曖昧性解消を行い，語義ラベルを付与することを意味する．
本稿では以後特に断りがない限り，分類とはこの語義ラベル付与のことを指す．
二段階分類したラベルなしデータの中で条件を満たすデータはオリジナルのラベル付きデータに加えられる．
その結果，パラメータ設定がほぼ不要なブートストラッピング的半教師あり手法による語義曖昧性解消を実現する．
さらに追加するラベルなしデータの条件を変えることで複数の分類器を作成し，アンサンブル学習することで，パラメータの変化に頑健な分類器を生成する．
本稿の構成は以下の通りである．
[REF_sec:work]節にて関連研究および本研究の位置付けを述べる．
[REF_sec:method]節にて提案手法およびその原理を並行して述べる．
[REF_sec:exp]節にてSemEval-2日本語タスク[CITE]のデータセットに提案手法を適用した実験の結果を示す．
[REF_sec:conc]節にて結論を述べる．
