================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.40578] 本稿で取り上げるブートストラッピングとは，ラベルなしデータを既存の教師あり学習手法を用いて分類し，その中で信頼度の高いデータをラベル付きデータに加え，この手順を反復することによって分類の性能を向上させる半教師あり学習手法である．
[i:2, score:0.49948] 従来のブートストラッピングによる語義曖昧性解消においては，プールサイズ，ラベル付きデータに追加するラベルなしデータの事例数，手順の反復回数といったパラメータをタスクに合わせ調整する必要があった．
[i:3, score:0.41621] 本稿にて提案する手法はヒューリスティックと教師あり学習（最大エントロピー法）によるラベルなしデータの二段階の分類，および学習に用いるラベルなしデータの条件を変えた複数の分類器のアンサンブルに基づく．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:10, score:0.37291] このような背景から，訓練データと大量のラベルなしデータを併用してクラス分類精度を向上させる半教師あり学習，または訓練データを必要としない教師なし学習による効果的な語義曖昧性解消手法の確立は重要であると言える．
[i:12, score:0.40586] ブートストラッピング法による語義曖昧性解消においては主にSelf-training（自己訓練）[CITE]とCo-training（共訓練）[CITE]の二つのアプローチがある[CITE]．
[i:25, score:0.33698] さらに追加するラベルなしデータの条件を変えることで複数の分類器を作成し，アンサンブル学習することで，パラメータの変化に頑健な分類器を生成する．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:32, score:0.29796] また，アンサンブル学習に基づく語義曖昧性解消には教師あり学習のアンサンブル，教師なし学習のアンサンブル，半教師あり学習のアンサンブルに基づいた手法が提案されており，これら先行研究を併せて概説する．
-----------------------------------------------------
  [subsection title : ブートストラッピングに基づく研究]
-----------------------------------------------------
  [i:lead, score:0.23786] Self-trainingに基づいた語義曖昧性解消の先駆けとしてはYarowskyの研究[CITE]が挙げられる．
.....
  [i:40, score:0.43463] MihalceaはCo-trainingとSelf-trainingの両方を語義曖昧性解消に適用し，[REF_sec:intro]節にて述べたパラメータの影響について調査した[CITE]．
  [i:43, score:0.42797] これは手順の反復のたびに生成される各分類器の多数決より語義判定しブートストラッピングするという方式であり，ブートストラッピングとアンサンブル学習の組合せの一種と見ることができる．
  [i:57, score:0.45433] 意味ドリフトは，語義曖昧性解消の観点から考えると，どのような語義の語も持つ素性をジェネリックパターンと考え，ジェネリックパターンを持つ（信頼性が低いとされるべき）ラベルなしデータに対し手順の反復過程においてラベルが与えられることにより，反復終了後に生成される分類器の性能が低下してしまう現象と解釈できる．
-----------------------------------------------------
  [subsection title : アンサンブル学習に基づく研究]
-----------------------------------------------------
  [i:lead, score:0.31719] 教師あり学習のアンサンブルに基づく研究としては，AdaBoostを用いた[CITE]，素性として用いる文脈の大きさを変えて複数のNaive Bayes分類器をアンサンブルした[CITE]，六種の分類器の組合せによる[CITE]，二段階の分類器の出力の選択に基づいた[CITE]，複数のNaive Bayes分類器の出力の比較に基づいた[CITE]が挙げられる．
.....
  [i:61, score:0.31719] 教師あり学習のアンサンブルに基づく研究としては，AdaBoostを用いた[CITE]，素性として用いる文脈の大きさを変えて複数のNaive Bayes分類器をアンサンブルした[CITE]，六種の分類器の組合せによる[CITE]，二段階の分類器の出力の選択に基づいた[CITE]，複数のNaive Bayes分類器の出力の比較に基づいた[CITE]が挙げられる．
  [i:73, score:0.37636] Leらが解決法を提案した問題点は，(1)ラベル付きデータのラベル毎のデータ数の偏り，(2)ラベル付きデータに追加するラベルなしデータ決定の基準，(3)手順の反復の停止条件および最終分類器の作成法の三つである．
  [i:75, score:0.43818] Leらはこれらの解決のため，追加するラベルなしデータのリサイズ，複数のデータ追加条件の閾値の設定および対応する複数の追加データ集合の設定，訓練データを用いた追加データの評価および手順反復停止条件の設定，そして追加データと教師あり学習手法別の各分類器のいくつかの組合せ法を提案した．
-----------------------------------------------------
  [subsection title : 本研究の位置付け]
-----------------------------------------------------
  [i:lead, score:0.06160] [REF_sec:work1]節と[REF_sec:work2]節を踏まえた上での本研究の位置付けは以下の通りである．
.....
  [i:83, score:0.31282] これは，教師あり学習を用い追加データを訓練データとして分類器を作成しオリジナルのラベル付きデータを分類して得られるエラー率，および追加データの総数に基づき設定される．
  [i:91, score:0.23641] しかし，[REF_sec:intro]節にて目標としたようにブートストラッピングにおけるパラメータの削減は達成を目指す．
  [i:97, score:0.22671] 以上の検討に基づき，本研究では反復を伴わず，かつ教師あり学習手法を併用した高性能なブートストラッピング的手法を確立する．

================================================================
[section type  : proposed_method]
[section title : 提案手法]
================================================================
[i:113, score:0.55417] 手掛り付き事例の獲得は，手掛り語を用いたラベルなしデータからの手掛り付き事例の抽出・分類（1回目），訓練データを用いて作成された一次分類器による手掛り付き事例の語義分類，一次分類器による分類結果に基づく手掛り付き事例の分類（2回目）といった多段の手順により実現される．
[i:119, score:0.57327] 具体的には，手法第一段階は図[REF_fig:img01]の手掛り語獲得から手掛り付き事例抽出・分類1回目まで，手法第二段階は一次分類器による手掛り付き事例の分類から二次分類器によるテストデータの語義分類まで，手法第三段階は最終分類器によるテストデータの語義分類のみと対応する．
[i:121, score:0.56928] 手法第二段階はラベルなしデータから抽出した手掛り付き事例の教師あり学習手法による分類とその結果に基づく二次分類器の作成として括り出し，詳細を[REF_sec:second]節にて述べる．
-----------------------------------------------------
  [subsection title : Stage 1：ヒューリスティックによる分類]
-----------------------------------------------------
  [i:lead, score:0.43677] 分類第一段階は訓練データからの手掛り語の獲得ならびにヒューリスティックによるラベルなしデータからの手掛り付き事例の抽出・分類（1回目）からなる．
.....
  [i:127, score:0.43677] 分類第一段階は訓練データからの手掛り語の獲得ならびにヒューリスティックによるラベルなしデータからの手掛り付き事例の抽出・分類（1回目）からなる．
  [i:128, score:0.44009] 本手法で獲得する手掛り語[MATH]とは，訓練データ[MATH]において語義ラベルが付与された対象語[MATH]の前後[MATH]語以内において共起する内容語の表層形であり，かつ与えられた訓練データ内で共起する[MATH]に付与された語義ラベルが必ずある一つの語義ラベル[MATH]に定まる語の集合とする．
  [i:173, score:0.42159] またここに述べた理由は，[REF_sec:second]節にて述べる手掛り付き事例分類2回目において，[REF_sec:intro]節で述べたパラメータ[MATH], [MATH], [MATH]が削減可能となる理由にもなる．
-----------------------------------------------------
  [subsection title : Stage 2：教師あり学習手法による分類]
-----------------------------------------------------
  [i:lead, score:0.47170] 分類第二段階では[REF_sec:first]節で抽出・分類した手掛り付き事例に対し，オリジナルの訓練データから得られる一次分類器を用いて2回目の分類を行う．
.....
  [i:179, score:0.47170] 分類第二段階では[REF_sec:first]節で抽出・分類した手掛り付き事例に対し，オリジナルの訓練データから得られる一次分類器を用いて2回目の分類を行う．
  [i:197, score:0.47074] 前述の学習手法，素性，そして訓練データ[MATH]を用いて一次分類器[MATH]を作成し，[MATH]を用いて[REF_sec:first]節で抽出・分類した手掛り付き事例[MATH]を再分類する．
  [i:207, score:0.36098] これは従来法において必要だった[REF_sec:intro]節に挙げたパラメータ，ラベル付きデータ[MATH]に加える事例の個数[MATH]および手順の反復回数[MATH]を決めることなしに適切な事例を[MATH]に加えられることも意味する．
-----------------------------------------------------
  [subsection title : Stage 3：アンサンブル学習による最終分類器作成]
-----------------------------------------------------
  [i:lead, score:0.27188] 本節では[REF_sec:second]節で作成した二次分類器[MATH]をアンサンブルして最終分類器[MATH]を作成する方法を述べる．
.....
  [i:227, score:0.27188] 本節では[REF_sec:second]節で作成した二次分類器[MATH]をアンサンブルして最終分類器[MATH]を作成する方法を述べる．
  [i:228, score:0.32050] アンサンブルには[REF_sec:first]節の手掛り語抽出において決定法を保留していた窓幅[MATH]を利用する．
  [i:250, score:0.41064] またMihalceaはCo-trainingの反復過程にて分類器の多数決を適用した結果，反復回数の差による性能差が小さくなりかつ全体的な性能も向上したと報告したが，本手法における分類器の組合せにおいても同様の効果が期待できる．
-----------------------------------------------------
  [subsection title : まとめ]
-----------------------------------------------------
  [i:lead, score:0.02548] 提案手法を一つのアルゴリズムとして表現すると次のようになる．
.....
  [i:264, score:0.24738] 次に留意すべきは[REF_sec:intro]節で述べた[MATH], [MATH], [MATH]といったパラメータがないにも関わらず，ブートストラッピングの効果が充分に見込めるという点である．
  [i:265, score:0.22692] このメカニズムは，上記Step 2に示した手掛り語[MATH]の条件，Step 4の[MATH]の抽出の条件，Step 6の[MATH]抽出の条件，さらにStep 8, 9が巧妙に作用しあっていることに基づいている．
  [i:266, score:0.22653] 最後に注意すべきは，本手法はStep 0から9までの1度の実行だけで，充分なブートストラッピングが可能であり，2回以上の反復を必要としない点である．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[i:297, score:0.42706] 次に手掛り語獲得において辞書用例データを使用した場合の最終分類器の評価結果を図[REF_fig:img04]，二次分類器の評価結果を図[REF_fig:img05]に示す．
[i:315, score:0.42284] 最後に一次分類器の精度，[MATH]が表[REF_tbl:tbl01]に示した[MATH]の範囲における最高値・最低値の精度のときの値の最終分類器の精度，および[MATH]の範囲での最終分類器の精度の平均値のそれぞれについて，SemEval-2日本語タスクの語義曖昧性解消対象語別に求めた結果を表[REF_tbl:tbl02]に示す．
[i:328, score:0.41152] ここで後者の原因は手掛り付き事例抽出の条件の[MATH]を可変にし，さらに多くの二次分類器を作成してアンサンブルすることで取り除ける可能性がある．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:342, score:0.35569] 本稿では，従来のブートストラッピング法による語義曖昧性解消手法の欠点であるパラメータ調整の難しさに対処するため，パラメータ設定をほぼ不要とするブートストラッピング的半教師あり語義曖昧性解消手法を提案した．
[i:343, score:0.35624] この手法は二段階の分類をラベルなしデータに適用するものであり，反復回数を一回に留めるにも関わらず充分な効果があるブートストラッピングを実現した．
[i:344, score:0.36752] またラベル付きデータに追加するラベルなしデータの条件を変え，複数の分類器を作成しアンサンブル学習することで唯一のパラメータの調整も容易とする手法を確立した．

