提案手法は[REF_sec:intro]節で述べたラベルなしデータの二段階の分類とその結果を用いたアンサンブル学習による最終分類器作成の全三段階からなる．
手法の流れを次に，また本手法に基づくシステム全体像を図[REF_fig:img01]に示す．
まず図[REF_fig:img01]の見方を述べる．
長方形の囲みは各種処理，楕円の囲みは各処理の出力を示す．
各種処理の中には語義分類の処理が三回登場するが，これらの括弧内の分類器はそれぞれの分類処理のために作成し使用する分類器を示している．
実線の矢印は各処理において入出力されるデータの流れを示す．
点線は入出力するデータへの処理に利用するデータであり，分類器作成のために訓練データとして用いるデータも含まれる．
図[REF_fig:img01]における訓練データとはオリジナルのラベル付きデータを指す．
本システムにおける最終的な語義曖昧性解消の対象は，テストデータとして図[REF_fig:img01]のように入力し，その結果は語義分類最終結果として出力される．
図[REF_fig:img01]に基づく本システムの概観は次のようになる．
まず本システムの最初の手順は手掛り語の獲得である．
手掛り語は訓練データから抽出する形で獲得する．
第二の手順はラベルなしデータからの手掛り付き事例の獲得である．
手掛り付き事例の獲得は，手掛り語を用いたラベルなしデータからの手掛り付き事例の抽出・分類（1回目），訓練データを用いて作成された一次分類器による手掛り付き事例の語義分類，一次分類器による分類結果に基づく手掛り付き事例の分類（2回目）といった多段の手順により実現される．
最後の手順はテストデータの語義曖昧性解消である．
これは獲得した手掛り付き事例と訓練データを用いた二次分類器の作成，および異なる条件で作成された複数の二次分類器によるテストデータの分類結果に基づく最終分類器の判定より構成される．
本節では，以後本手法を全三段階に区切り，詳述していく．
ここで一つ注意点がある．
それは今，本システムを上述のように手掛り語，手掛り付き事例，語義分類最終結果と出力されるデータに着目し，手順を三つに区切ったが，これは以後に述べる三段階の手順と対応関係にないということである．
具体的には，手法第一段階は図[REF_fig:img01]の手掛り語獲得から手掛り付き事例抽出・分類1回目まで，手法第二段階は一次分類器による手掛り付き事例の分類から二次分類器によるテストデータの語義分類まで，手法第三段階は最終分類器によるテストデータの語義分類のみと対応する．
手法第一段階はヒューリスティックによるラベルなしデータの分類として一括りし，手掛り語ならびに手掛り付き事例の詳細と併せて[REF_sec:first]節にて詳述する．
手法第二段階はラベルなしデータから抽出した手掛り付き事例の教師あり学習手法による分類とその結果に基づく二次分類器の作成として括り出し，詳細を[REF_sec:second]節にて述べる．
手法第三段階はアンサンブル学習による最終分類器の作成として括り，[REF_sec:third]節にて詳述する．
[REF_sec:summary]節では本手法のまとめをする．
このような手法の全三段階の区切りは，[REF_sec:exp]節にて述べる実験結果の考察において意味を持つことになる．
なお本稿では，訓練データ，テストデータおよびラベルなしデータはいずれもUniDicを用いて形態素解析済みであり，訓練データにおいてラベルは各形態素に付与されているものとする．
また本稿では便宜上，形態素を単語または語とも呼ぶことにする．
分類第一段階は訓練データからの手掛り語の獲得ならびにヒューリスティックによるラベルなしデータからの手掛り付き事例の抽出・分類（1回目）からなる．
本手法で獲得する手掛り語[MATH]とは，訓練データ[MATH]において語義ラベルが付与された対象語[MATH]の前後[MATH]語以内において共起する内容語の表層形であり，かつ与えられた訓練データ内で共起する[MATH]に付与された語義ラベルが必ずある一つの語義ラベル[MATH]に定まる語の集合とする．
後者の条件は，[MATH]が付与された[MATH]を[MATH]とすると，形態素[MATH]共起の下で[MATH]が[MATH]である確率を[MATH]とすると，
を満たす[MATH]であることとも書き換えることができる．
前者の条件にある窓幅[MATH]については[REF_sec:third]節で詳述する．
このような条件を満たす[MATH]が語義ラベルが付与されていない[MATH]と共起したとき，この[MATH]は単純に式([REF_eq1])より[MATH]である可能性が高いと考え，以後[MATH]は[MATH]の語義曖昧性解消の手掛りとして利用する．
また表層形を条件としたのは，基本形，品詞といった情報は表層形と比べ情報の粒度が荒く，表層形の方が手掛りとしての信頼性が高いと考えたことによる．
もし式([REF_eq1])を満たす[MATH]が[MATH]全体で一度だけ出現する語である場合，[MATH]が[MATH]に決定付けられる可能性は低いとも考えられるが，これは二度以上出現する語の場合も大差はないと筆者は考える．
[MATH]は語義曖昧性解消において単純ベイズや決定リストのルールの信頼度などにしばしば用いられ，その中で[MATH]をスムージングして用いる例もいくつかある[CITE]．
しかしこの場合は最適な閾値を求める必要があり，問題がかえって難しくなってしまう．
このため，今回は単純な式([REF_eq1])を[MATH]の条件とした．
なお上述の[MATH]は添え字が示すように共起する[MATH]に付与されていた[MATH]の情報を含む．
よって実際の手掛り語獲得では，例えば対象語が「相手」，[MATH]，訓練データの一つに「相手に取って不足はない」があり，この文中の「相手」に``117-0-0-3''という語義IDが付与されていたとする．
このとき「取っ」という語が訓練データにおいて``117-0-0-3''の語義の「相手」とのみ共起するのであれば，この訓練データからは《取っ, 117-0-0-3》という二つ組一つを抽出する．
ここでは，まず手掛り付き事例抽出の手順を述べる前にSemEval-2日本語タスクにおける対象語[MATH]の表記ゆれへの対処について述べる．
SemEval-2においては[MATH]について与えられる情報は訓練データ[MATH]を除くと与えられた辞書に記述された見出し語[MATH]と語義の語釈文[MATH]のみであり，[MATH]の表記に関する情報は充分には与えられない．
例えば，[MATH]の一つに「子供」があるが，これは他にも「子ども」「こども」といった表記があるのに対し，[MATH]にない「子ども」という表記の情報は与えられていない．
この問題に対処しない場合，ラベルなしデータから[MATH]の事例を充分な数獲得できないだけでなく，[MATH]の表記により語義の傾向が変わる場合も考えられ，抽出する事例の語義に偏りが生まれる可能性も考えられる．
このため，UniDicの辞書を用いて，以下の手順で[MATH]の取り得る表記（表層形）[MATH]の獲得を行った．
なお下記のStep 2では実際には[MATH]からひらがなのみで構成される表層形を除外して[MATH]を抽出している．
これはこのような語は語彙素の同定が困難であり表層形獲得精度の低下を招くためである．
また[MATH]は品詞細分類の情報も合わせて獲得し，以後[MATH]の事例としてこの二つ組の情報が一致するものを獲得する．
続いて，獲得した手掛り語[MATH]および対象語の表層形[MATH]を用いてラベルなしデータ[MATH]より手掛り付き事例の抽出および1回目の分類を行う．
手順を以下に示す．
手掛り付き事例[MATH]とは対象語[MATH]の前後に手掛り語[MATH]が共起する事例を指し，上記手順より抽出される．
また，ここで抽出される[MATH]の[MATH]は[MATH]の添え字の[MATH]であり，[MATH]に[MATH]を付与することで分類したとみなすことができる．
よって上記手順では，手掛り付き事例の抽出と分類を同時に行っていると解釈できる．
一方で，[MATH]の集合[MATH]と[MATH]の差集合は語義ラベルが付与されないということで，語義判定不可に分類されたと考えることもできる．
上記手順を具体例を挙げ説明すると次のようになる．
[MATH]に「相手」，[MATH]に《取っ, 117-0-0-3》が含まれているとし，[MATH]より「ゼネコン三十一社を相手取って一人あたり三千三百万円の損害賠償を求めた」という文に対し上記手順を適用するとする．
また，[MATH]とする．
この場合，文中の「相手」が[MATH]となり，[MATH]の前後2語以内に「取っ」が共起するため，[MATH]``117-0-0-3''とし，[MATH]を手掛り付き事例[MATH]として抽出する．
さて，ここでパラメータ[MATH]についてであるが，これは[MATH]獲得に用いるパラメータ[MATH]とは区別する．
さらに[MATH]の値は上述の例と同様に``2''と固定する．
この2という数は[REF_sec:second]節で述べる教師あり学習による分類の素性として対象語前後``2''語以内の形態素を用いることと対応するのだが，その理由を列挙すると以下のようになる．
[MATH]獲得に用いる訓練データ[MATH]は本タスクにおいて数少ない信頼できるデータである．
したがって，[MATH]からは出来る限り多くの特徴を抽出したい．
一方，ラベルなしデータ[MATH]は多量に存在するが，これを自動的に分類したデータは当然ながら必ずしも信頼できるわけではない．
反復回数一回でなるべく信頼性が高くかつ充分な数のデータの獲得が望ましい．
[MATH]を教師あり学習の素性抽出の範囲と一致させた場合，抽出した手掛り付き事例[MATH]の素性に必ず[MATH]が含まれる．
このため，[MATH]を教師あり手法で再分類したとき高精度の分類が期待できる．
[MATH]は[MATH]に関わらず式([REF_eq1])を満たす．
つまりある程度の範囲までは[MATH]を大きくすることで信頼性を維持しつつ多数の[MATH]を獲得できる．
[MATH]が充分な数あれば，一度の処理で多数の[MATH]を分類しやはり充分な数のデータを[MATH]に加えることができる．
上述の理由には従来法の欠点と提案法の利点の両方が含まれている．
その対応関係は，理由(4)は(2)への対処であり，(5)は(4)の補足かつ(1)への対処であり，(6)は(5)を踏まえた(3)への対処となる．
またここに述べた理由は，[REF_sec:second]節にて述べる手掛り付き事例分類2回目において，[REF_sec:intro]節で述べたパラメータ[MATH], [MATH], [MATH]が削減可能となる理由にもなる．
詳しくは[REF_sec:second]節にて改めて述べる．
以上のアルゴリズムをもって，本手法の第一段階とする．
節題の通り，本処理は経験則に基づく部分が多い．
しかし，本処理は以降の処理においても必要とされる性質を備えている．
これらは[REF_sec:second]節および[REF_sec:third]節にて詳述する．
分類第二段階では[REF_sec:first]節で抽出・分類した手掛り付き事例に対し，オリジナルの訓練データから得られる一次分類器を用いて2回目の分類を行う．
そして，その結果得られる手掛り付き事例を用いて二次分類器を作成する．
本手法で用いる教師あり学習手法は最適化にL-BFGS [CITE]を用いた最大エントロピー法[CITE]とした．
この理由はSemEval-2日本語タスクフォーマルラン参加チームの一つの報告[CITE]に最大エントロピー法が有効というものがあったためである．
また学習の素性もFujitaらの報告を参考に次のように設定した．
範囲
対象語前後2語以内
1グラム素性
形態素の表層形
形態素の基本形
2グラム・3グラム・対象語を含むスキップ2グラム素性
形態素の表層形
形態素の基本形
形態素の品詞と対象語との相対位置の組合せ
形態素の品詞細分類と対象語との相対位置の組合せ
具体的には，対象語「相手」の事例「相手に取って不足はない」に対しては次の素性が獲得できる．
下記例中の``*''を含む素性はスキップ2グラムを示す．
また品詞に付与されている番号は対象語との相対位置である．
前述の学習手法，素性，そして訓練データ[MATH]を用いて一次分類器[MATH]を作成し，[MATH]を用いて[REF_sec:first]節で抽出・分類した手掛り付き事例[MATH]を再分類する．
この分類2回目の結果が分類1回目の結果と一致する，つまり[MATH]の[MATH]の分類結果を[MATH]としたとき，[MATH]である場合，[MATH]を[MATH]とし[MATH]に加え，これを用いて[MATH]同様に二次分類器[MATH]を作成する．
[REF_sec:first]節で述べたように[MATH]はその素性に必ず手掛り語[MATH]を含む．
そのため[MATH]は[MATH]と一致する可能性が高いが，実際に一致を確認し，一致しなければ[MATH]作成においてこの手掛り付き事例は使わない．
この結果，[MATH]作成に用いられる[MATH]のラベル[MATH]は信頼性の高いものとなる．
このシステムの重要な点は単に二種類の分類手法の結果が合致するものを選択することではない．
そうだとすれば，分類1回目は一般的な教師あり学習手法を用いても良いことになってしまう．
重要なのは分類2回目にて[MATH]が高い精度で分類可能な事例[MATH]を分類1回目において選択していることにある．
つまり，分類1回目が分類2回目の精度向上を明確に支援していることがポイントである．
これにより[MATH]全てを[MATH]に加えても信頼性は保持され，同時に充分な数のブートストラッピングが可能になる．
これは従来法において必要だった[REF_sec:intro]節に挙げたパラメータ，ラベル付きデータ[MATH]に加える事例の個数[MATH]および手順の反復回数[MATH]を決めることなしに適切な事例を[MATH]に加えられることも意味する．
なぜなら，[MATH]を定めずとも全事例を[MATH]に加えればよく，[MATH]を定めずとも一度の実行で充分な数の事例の獲得が可能だからである．
またプールサイズ[MATH]については，Blumらの考察[CITE]から考えるとブートストラッピングの反復において意味を持つ値であると思われる．
よって，反復回数1の本手法は単にプールを設定する必要がなく，事例を全てのラベルなしデータ[MATH]から抽出することで処理できる．
また，[MATH]は[MATH]であれば[MATH]の素性にない語（つまり対象語から3語以上離れた位置にある語）を含むことから，[MATH]の素性はやはり[MATH]の素性にない語を含む．
すると[MATH]が分類2回目の結果，[MATH]に追加されれば，上述の通り分類2回目の信頼性は高いと言えるため，[MATH]は[MATH]と比べ正しく分類できる[MATH]が増える可能性が高い．
したがって，本手法は[MATH]の[MATH]への追加における効率性が高い手法であるとも言うことができる．
上述の性質はCo-trainingとの類似性を指摘することもできる．
Co-trainingは[REF_sec:intro]節で述べたように二つの素性集合のうち一方のみに基づいて分類することで他方の素性について新しい規則の獲得が期待できるのが特徴である．
本手法では，[MATH]と[MATH]に用いる素性の二種類の素性を実質的に両方考慮して手掛り付き事例を分類している．
しかし，[MATH]に用いる素性は後者の素性のみである．
つまり，一方は他方の一部ということになるが，一方の素性で分類した結果を他方の素性を用いる分類器の訓練データに加えるという点ではCo-trainingと共通する．
その一方で，提案手法は[MATH]に追加する[MATH]の分類に二種類，つまり全ての素性を用いており，一方のみを使う場合と比較すると分類結果の信頼性が高いという利点がある．
このような変則的なCo-trainingと通常のCo-trainingの間にどのような差異が生まれるかは未調査だが，ここに述べた性質は性能の向上に結び付くと期待される．
本処理の直感的な意味としては，[MATH]にまず簡単な問題を解かせ，その結果を[MATH]の学習に利用していると解釈できる．
一方で従来のブートストラッピングは，難易度がランダムな問題を複数解かせ，その中でシステムが自信を持って答えられるものから学習すると考えられる．
しかし後者の場合，回答に対し「間違った自信」を持ってしまい，結果として不適切な学習をしてしまう危険性があり得る．
前者の，つまり提案した手法は，確実ではないが[MATH]が解くのが簡単であろう問題を選択しており，この危険性はいくらか低減していると推測される．
この推測が正しいとすれば，[MATH]に提示する問題を選択する分類1回目の処理は重要な意味を持つことになる．
また，ここで提示するのは勿論ラベルなしの文章であるが，見方を変えると「良い文章」をシステムに提示することでより良い学習が可能になると考えられ，興味深い．
本節では[REF_sec:second]節で作成した二次分類器[MATH]をアンサンブルして最終分類器[MATH]を作成する方法を述べる．
アンサンブルには[REF_sec:first]節の手掛り語抽出において決定法を保留していた窓幅[MATH]を利用する．
すなわち，[MATH]をパラメータとする二次分類器を[MATH]とし，[MATH]を変化させた[MATH]を複数組合せ[MATH]とする．
組合せの方法は各最大エントロピー分類器が出力する各ラベルの推定確率の中で最高値を出力した分類器の判定を採用する方式とする．
つまり入力を[MATH]，[MATH]が[MATH]に対し出力する語義[MATH]である推定確率を[MATH]とすると，
より求まる[MATH]を[MATH]の出力とする．
式([REF_eq2])の方式で良い結果が得られる根拠は手掛り語[MATH]の条件の一つである式([REF_eq1])にある．
式([REF_eq1])の制約の下で[MATH]の値を大きくしたとき，得られる[MATH]に以下の二つの変化が見られる．
[MATH]変化前になくかつ[MATH]変化後に式([REF_eq1])を満たす語が追加される．
[MATH]変化前にはあるが[MATH]変化後に式([REF_eq1])を満たさなくなる語が削除される．
ここで重要なのは後者の性質である．
式([REF_eq1])の性質上，後者の変化より[MATH]から削除された語は[MATH]をどんなに大きくしても再度[MATH]に追加されることは絶対にない．
[MATH]変化後に削除される語は必ずしも重要度が高い語とも低い語とも言えないが，少なくとも一度は[MATH]の条件を満たすため重要度が高い語を含む可能性は高い．
よって，[MATH]の変化によって変わる各[MATH]の集合には他の集合にはない重要度の高い[MATH]が含まれている可能性が少なからずあるということになる．
したがって，[MATH]の差異により各分類器に長所・短所が生まれ，アンサンブル学習の効果が生まれやすいということができる．
逆に，[MATH]をアンサンブルしない場合，[MATH]の差異により性能に大きく差がつくと考えられ，[MATH]をパラメータとした調整は難しいと考えられる．
また[MATH]を増やせば，それだけ対象語から離れた位置にある語を特徴とすることになるため，少しずつ[MATH]の信頼性が落ちていくものと考えられるが，これに伴い任意の[MATH]に対し[MATH]の[MATH]の推定確率[MATH]も落ちていくと予想される．
すると，[MATH]の出力を式([REF_eq2])を満たす[MATH]としたが，[MATH]の増大に従い[MATH]の判定が採用される確率も減少していくと考えられる．
よって，[MATH]の増大は[MATH]の信頼性の減少を意味するが，同時に[MATH]の判定の採用確率も減ぜられる．
このため本手法は[MATH]の増大に対し頑健なアンサンブル手法であるとも言うことができる．
本手法はMihalceaのSmoothed Co-training [CITE]およびWangらTrajectory Basedの手法[CITE]と類似性を持つ．
まずWangらは文脈の大きさを変えながら複数のNaive Bayes分類器を作成しているが，提案手法の処理はこれとよく似ている．
Wangらの手法は文脈の大きさというパラメータの影響の差による性能差が小さくなることで性能が上がると見られるが，本手法でも同様の効果が期待できる．
またMihalceaはCo-trainingの反復過程にて分類器の多数決を適用した結果，反復回数の差による性能差が小さくなりかつ全体的な性能も向上したと報告したが，本手法における分類器の組合せにおいても同様の効果が期待できる．
なお，分類器の組合せのもう一つの単純な方式として推定確率を重みとした重み付き多数決方式，つまり
が考えられる．
ここで記号の意味は式([REF_eq2])と同じである．
しかし，式([REF_eq3])の方式は事前実験の結果，式([REF_eq2])の方式ほどは良くないことがわかった．
これは，[MATH]の増大に伴い[MATH]の推定確率が低くなることに変わりはないが，式([REF_eq2])と比べ[MATH]の大きな[MATH]の判定がより重めに考慮されていることが原因と思われる．
最後に本手法唯一のパラメータである[MATH]の変化の範囲について述べる．
一つの方法としては範囲を設けない，つまり任意の[MATH]を許すことが考えられるが，当然ながら[MATH]を増やすことで計算時間が増加する．
また，[MATH]の増大に伴う分類器の信頼性の減少に対しある程度は頑健であるとはいえ，限度の存在があり得る．
このため[MATH]の変化の範囲には何らかの閾値を定めるのが妥当と考えられる．
[REF_sec:exp]節で述べる実験ではパラメータ[MATH]を定め，[MATH]の範囲で[MATH]を1刻みで変化させるとし，[MATH]の変化により語義曖昧性解消の性能がどのように変化していくか見ていく．
提案手法を一つのアルゴリズムとして表現すると次のようになる．
まず着目すべきは本手法はStep 8に示した[MATH]以外にパラメータが存在しないことである．
そして[REF_sec:exp]節で示すようにこのパラメータの設定は比較的容易である．
次に留意すべきは[REF_sec:intro]節で述べた[MATH], [MATH], [MATH]といったパラメータがないにも関わらず，ブートストラッピングの効果が充分に見込めるという点である．
このメカニズムは，上記Step 2に示した手掛り語[MATH]の条件，Step 4の[MATH]の抽出の条件，Step 6の[MATH]抽出の条件，さらにStep 8, 9が巧妙に作用しあっていることに基づいている．
最後に注意すべきは，本手法はStep 0から9までの1度の実行だけで，充分なブートストラッピングが可能であり，2回以上の反復を必要としない点である．
しかし，Step 4の[MATH]の抽出は必然的に再現率を犠牲にするため，本手法1回の実行で完全な学習ができる訳ではない．
本手法の反復による更なる精度の向上は今後の課題である．
提案手法は[REF_sec:intro]節で述べたラベルなしデータの二段階の分類とその結果を用いたアンサンブル学習による最終分類器作成の全三段階からなる．
手法の流れを次に，また本手法に基づくシステム全体像を図[REF_fig:img01]に示す．
まず図[REF_fig:img01]の見方を述べる．
長方形の囲みは各種処理，楕円の囲みは各処理の出力を示す．
各種処理の中には語義分類の処理が三回登場するが，これらの括弧内の分類器はそれぞれの分類処理のために作成し使用する分類器を示している．
実線の矢印は各処理において入出力されるデータの流れを示す．
点線は入出力するデータへの処理に利用するデータであり，分類器作成のために訓練データとして用いるデータも含まれる．
図[REF_fig:img01]における訓練データとはオリジナルのラベル付きデータを指す．
本システムにおける最終的な語義曖昧性解消の対象は，テストデータとして図[REF_fig:img01]のように入力し，その結果は語義分類最終結果として出力される．
図[REF_fig:img01]に基づく本システムの概観は次のようになる．
まず本システムの最初の手順は手掛り語の獲得である．
手掛り語は訓練データから抽出する形で獲得する．
第二の手順はラベルなしデータからの手掛り付き事例の獲得である．
手掛り付き事例の獲得は，手掛り語を用いたラベルなしデータからの手掛り付き事例の抽出・分類（1回目），訓練データを用いて作成された一次分類器による手掛り付き事例の語義分類，一次分類器による分類結果に基づく手掛り付き事例の分類（2回目）といった多段の手順により実現される．
最後の手順はテストデータの語義曖昧性解消である．
これは獲得した手掛り付き事例と訓練データを用いた二次分類器の作成，および異なる条件で作成された複数の二次分類器によるテストデータの分類結果に基づく最終分類器の判定より構成される．
本節では，以後本手法を全三段階に区切り，詳述していく．
ここで一つ注意点がある．
それは今，本システムを上述のように手掛り語，手掛り付き事例，語義分類最終結果と出力されるデータに着目し，手順を三つに区切ったが，これは以後に述べる三段階の手順と対応関係にないということである．
具体的には，手法第一段階は図[REF_fig:img01]の手掛り語獲得から手掛り付き事例抽出・分類1回目まで，手法第二段階は一次分類器による手掛り付き事例の分類から二次分類器によるテストデータの語義分類まで，手法第三段階は最終分類器によるテストデータの語義分類のみと対応する．
手法第一段階はヒューリスティックによるラベルなしデータの分類として一括りし，手掛り語ならびに手掛り付き事例の詳細と併せて[REF_sec:first]節にて詳述する．
手法第二段階はラベルなしデータから抽出した手掛り付き事例の教師あり学習手法による分類とその結果に基づく二次分類器の作成として括り出し，詳細を[REF_sec:second]節にて述べる．
手法第三段階はアンサンブル学習による最終分類器の作成として括り，[REF_sec:third]節にて詳述する．
[REF_sec:summary]節では本手法のまとめをする．
このような手法の全三段階の区切りは，[REF_sec:exp]節にて述べる実験結果の考察において意味を持つことになる．
なお本稿では，訓練データ，テストデータおよびラベルなしデータはいずれもUniDicを用いて形態素解析済みであり，訓練データにおいてラベルは各形態素に付与されているものとする．
また本稿では便宜上，形態素を単語または語とも呼ぶことにする．
分類第一段階は訓練データからの手掛り語の獲得ならびにヒューリスティックによるラベルなしデータからの手掛り付き事例の抽出・分類（1回目）からなる．
本手法で獲得する手掛り語[MATH]とは，訓練データ[MATH]において語義ラベルが付与された対象語[MATH]の前後[MATH]語以内において共起する内容語の表層形であり，かつ与えられた訓練データ内で共起する[MATH]に付与された語義ラベルが必ずある一つの語義ラベル[MATH]に定まる語の集合とする．
後者の条件は，[MATH]が付与された[MATH]を[MATH]とすると，形態素[MATH]共起の下で[MATH]が[MATH]である確率を[MATH]とすると，
を満たす[MATH]であることとも書き換えることができる．
前者の条件にある窓幅[MATH]については[REF_sec:third]節で詳述する．
このような条件を満たす[MATH]が語義ラベルが付与されていない[MATH]と共起したとき，この[MATH]は単純に式([REF_eq1])より[MATH]である可能性が高いと考え，以後[MATH]は[MATH]の語義曖昧性解消の手掛りとして利用する．
また表層形を条件としたのは，基本形，品詞といった情報は表層形と比べ情報の粒度が荒く，表層形の方が手掛りとしての信頼性が高いと考えたことによる．
もし式([REF_eq1])を満たす[MATH]が[MATH]全体で一度だけ出現する語である場合，[MATH]が[MATH]に決定付けられる可能性は低いとも考えられるが，これは二度以上出現する語の場合も大差はないと筆者は考える．
[MATH]は語義曖昧性解消において単純ベイズや決定リストのルールの信頼度などにしばしば用いられ，その中で[MATH]をスムージングして用いる例もいくつかある[CITE]．
しかしこの場合は最適な閾値を求める必要があり，問題がかえって難しくなってしまう．
このため，今回は単純な式([REF_eq1])を[MATH]の条件とした．
なお上述の[MATH]は添え字が示すように共起する[MATH]に付与されていた[MATH]の情報を含む．
よって実際の手掛り語獲得では，例えば対象語が「相手」，[MATH]，訓練データの一つに「相手に取って不足はない」があり，この文中の「相手」に``117-0-0-3''という語義IDが付与されていたとする．
このとき「取っ」という語が訓練データにおいて``117-0-0-3''の語義の「相手」とのみ共起するのであれば，この訓練データからは《取っ, 117-0-0-3》という二つ組一つを抽出する．
ここでは，まず手掛り付き事例抽出の手順を述べる前にSemEval-2日本語タスクにおける対象語[MATH]の表記ゆれへの対処について述べる．
SemEval-2においては[MATH]について与えられる情報は訓練データ[MATH]を除くと与えられた辞書に記述された見出し語[MATH]と語義の語釈文[MATH]のみであり，[MATH]の表記に関する情報は充分には与えられない．
例えば，[MATH]の一つに「子供」があるが，これは他にも「子ども」「こども」といった表記があるのに対し，[MATH]にない「子ども」という表記の情報は与えられていない．
この問題に対処しない場合，ラベルなしデータから[MATH]の事例を充分な数獲得できないだけでなく，[MATH]の表記により語義の傾向が変わる場合も考えられ，抽出する事例の語義に偏りが生まれる可能性も考えられる．
このため，UniDicの辞書を用いて，以下の手順で[MATH]の取り得る表記（表層形）[MATH]の獲得を行った．
なお下記のStep 2では実際には[MATH]からひらがなのみで構成される表層形を除外して[MATH]を抽出している．
これはこのような語は語彙素の同定が困難であり表層形獲得精度の低下を招くためである．
また[MATH]は品詞細分類の情報も合わせて獲得し，以後[MATH]の事例としてこの二つ組の情報が一致するものを獲得する．
続いて，獲得した手掛り語[MATH]および対象語の表層形[MATH]を用いてラベルなしデータ[MATH]より手掛り付き事例の抽出および1回目の分類を行う．
手順を以下に示す．
手掛り付き事例[MATH]とは対象語[MATH]の前後に手掛り語[MATH]が共起する事例を指し，上記手順より抽出される．
また，ここで抽出される[MATH]の[MATH]は[MATH]の添え字の[MATH]であり，[MATH]に[MATH]を付与することで分類したとみなすことができる．
よって上記手順では，手掛り付き事例の抽出と分類を同時に行っていると解釈できる．
一方で，[MATH]の集合[MATH]と[MATH]の差集合は語義ラベルが付与されないということで，語義判定不可に分類されたと考えることもできる．
上記手順を具体例を挙げ説明すると次のようになる．
[MATH]に「相手」，[MATH]に《取っ, 117-0-0-3》が含まれているとし，[MATH]より「ゼネコン三十一社を相手取って一人あたり三千三百万円の損害賠償を求めた」という文に対し上記手順を適用するとする．
また，[MATH]とする．
この場合，文中の「相手」が[MATH]となり，[MATH]の前後2語以内に「取っ」が共起するため，[MATH]``117-0-0-3''とし，[MATH]を手掛り付き事例[MATH]として抽出する．
さて，ここでパラメータ[MATH]についてであるが，これは[MATH]獲得に用いるパラメータ[MATH]とは区別する．
さらに[MATH]の値は上述の例と同様に``2''と固定する．
この2という数は[REF_sec:second]節で述べる教師あり学習による分類の素性として対象語前後``2''語以内の形態素を用いることと対応するのだが，その理由を列挙すると以下のようになる．
[MATH]獲得に用いる訓練データ[MATH]は本タスクにおいて数少ない信頼できるデータである．
したがって，[MATH]からは出来る限り多くの特徴を抽出したい．
一方，ラベルなしデータ[MATH]は多量に存在するが，これを自動的に分類したデータは当然ながら必ずしも信頼できるわけではない．
反復回数一回でなるべく信頼性が高くかつ充分な数のデータの獲得が望ましい．
[MATH]を教師あり学習の素性抽出の範囲と一致させた場合，抽出した手掛り付き事例[MATH]の素性に必ず[MATH]が含まれる．
このため，[MATH]を教師あり手法で再分類したとき高精度の分類が期待できる．
[MATH]は[MATH]に関わらず式([REF_eq1])を満たす．
つまりある程度の範囲までは[MATH]を大きくすることで信頼性を維持しつつ多数の[MATH]を獲得できる．
[MATH]が充分な数あれば，一度の処理で多数の[MATH]を分類しやはり充分な数のデータを[MATH]に加えることができる．
上述の理由には従来法の欠点と提案法の利点の両方が含まれている．
その対応関係は，理由(4)は(2)への対処であり，(5)は(4)の補足かつ(1)への対処であり，(6)は(5)を踏まえた(3)への対処となる．
またここに述べた理由は，[REF_sec:second]節にて述べる手掛り付き事例分類2回目において，[REF_sec:intro]節で述べたパラメータ[MATH], [MATH], [MATH]が削減可能となる理由にもなる．
詳しくは[REF_sec:second]節にて改めて述べる．
以上のアルゴリズムをもって，本手法の第一段階とする．
節題の通り，本処理は経験則に基づく部分が多い．
しかし，本処理は以降の処理においても必要とされる性質を備えている．
これらは[REF_sec:second]節および[REF_sec:third]節にて詳述する．
分類第二段階では[REF_sec:first]節で抽出・分類した手掛り付き事例に対し，オリジナルの訓練データから得られる一次分類器を用いて2回目の分類を行う．
そして，その結果得られる手掛り付き事例を用いて二次分類器を作成する．
本手法で用いる教師あり学習手法は最適化にL-BFGS [CITE]を用いた最大エントロピー法[CITE]とした．
この理由はSemEval-2日本語タスクフォーマルラン参加チームの一つの報告[CITE]に最大エントロピー法が有効というものがあったためである．
また学習の素性もFujitaらの報告を参考に次のように設定した．
範囲
対象語前後2語以内
1グラム素性
形態素の表層形
形態素の基本形
2グラム・3グラム・対象語を含むスキップ2グラム素性
形態素の表層形
形態素の基本形
形態素の品詞と対象語との相対位置の組合せ
形態素の品詞細分類と対象語との相対位置の組合せ
具体的には，対象語「相手」の事例「相手に取って不足はない」に対しては次の素性が獲得できる．
下記例中の``*''を含む素性はスキップ2グラムを示す．
また品詞に付与されている番号は対象語との相対位置である．
前述の学習手法，素性，そして訓練データ[MATH]を用いて一次分類器[MATH]を作成し，[MATH]を用いて[REF_sec:first]節で抽出・分類した手掛り付き事例[MATH]を再分類する．
この分類2回目の結果が分類1回目の結果と一致する，つまり[MATH]の[MATH]の分類結果を[MATH]としたとき，[MATH]である場合，[MATH]を[MATH]とし[MATH]に加え，これを用いて[MATH]同様に二次分類器[MATH]を作成する．
[REF_sec:first]節で述べたように[MATH]はその素性に必ず手掛り語[MATH]を含む．
そのため[MATH]は[MATH]と一致する可能性が高いが，実際に一致を確認し，一致しなければ[MATH]作成においてこの手掛り付き事例は使わない．
この結果，[MATH]作成に用いられる[MATH]のラベル[MATH]は信頼性の高いものとなる．
このシステムの重要な点は単に二種類の分類手法の結果が合致するものを選択することではない．
そうだとすれば，分類1回目は一般的な教師あり学習手法を用いても良いことになってしまう．
重要なのは分類2回目にて[MATH]が高い精度で分類可能な事例[MATH]を分類1回目において選択していることにある．
つまり，分類1回目が分類2回目の精度向上を明確に支援していることがポイントである．
これにより[MATH]全てを[MATH]に加えても信頼性は保持され，同時に充分な数のブートストラッピングが可能になる．
これは従来法において必要だった[REF_sec:intro]節に挙げたパラメータ，ラベル付きデータ[MATH]に加える事例の個数[MATH]および手順の反復回数[MATH]を決めることなしに適切な事例を[MATH]に加えられることも意味する．
なぜなら，[MATH]を定めずとも全事例を[MATH]に加えればよく，[MATH]を定めずとも一度の実行で充分な数の事例の獲得が可能だからである．
またプールサイズ[MATH]については，Blumらの考察[CITE]から考えるとブートストラッピングの反復において意味を持つ値であると思われる．
よって，反復回数1の本手法は単にプールを設定する必要がなく，事例を全てのラベルなしデータ[MATH]から抽出することで処理できる．
また，[MATH]は[MATH]であれば[MATH]の素性にない語（つまり対象語から3語以上離れた位置にある語）を含むことから，[MATH]の素性はやはり[MATH]の素性にない語を含む．
すると[MATH]が分類2回目の結果，[MATH]に追加されれば，上述の通り分類2回目の信頼性は高いと言えるため，[MATH]は[MATH]と比べ正しく分類できる[MATH]が増える可能性が高い．
したがって，本手法は[MATH]の[MATH]への追加における効率性が高い手法であるとも言うことができる．
上述の性質はCo-trainingとの類似性を指摘することもできる．
Co-trainingは[REF_sec:intro]節で述べたように二つの素性集合のうち一方のみに基づいて分類することで他方の素性について新しい規則の獲得が期待できるのが特徴である．
本手法では，[MATH]と[MATH]に用いる素性の二種類の素性を実質的に両方考慮して手掛り付き事例を分類している．
しかし，[MATH]に用いる素性は後者の素性のみである．
つまり，一方は他方の一部ということになるが，一方の素性で分類した結果を他方の素性を用いる分類器の訓練データに加えるという点ではCo-trainingと共通する．
その一方で，提案手法は[MATH]に追加する[MATH]の分類に二種類，つまり全ての素性を用いており，一方のみを使う場合と比較すると分類結果の信頼性が高いという利点がある．
このような変則的なCo-trainingと通常のCo-trainingの間にどのような差異が生まれるかは未調査だが，ここに述べた性質は性能の向上に結び付くと期待される．
本処理の直感的な意味としては，[MATH]にまず簡単な問題を解かせ，その結果を[MATH]の学習に利用していると解釈できる．
一方で従来のブートストラッピングは，難易度がランダムな問題を複数解かせ，その中でシステムが自信を持って答えられるものから学習すると考えられる．
しかし後者の場合，回答に対し「間違った自信」を持ってしまい，結果として不適切な学習をしてしまう危険性があり得る．
前者の，つまり提案した手法は，確実ではないが[MATH]が解くのが簡単であろう問題を選択しており，この危険性はいくらか低減していると推測される．
この推測が正しいとすれば，[MATH]に提示する問題を選択する分類1回目の処理は重要な意味を持つことになる．
また，ここで提示するのは勿論ラベルなしの文章であるが，見方を変えると「良い文章」をシステムに提示することでより良い学習が可能になると考えられ，興味深い．
本節では[REF_sec:second]節で作成した二次分類器[MATH]をアンサンブルして最終分類器[MATH]を作成する方法を述べる．
アンサンブルには[REF_sec:first]節の手掛り語抽出において決定法を保留していた窓幅[MATH]を利用する．
すなわち，[MATH]をパラメータとする二次分類器を[MATH]とし，[MATH]を変化させた[MATH]を複数組合せ[MATH]とする．
組合せの方法は各最大エントロピー分類器が出力する各ラベルの推定確率の中で最高値を出力した分類器の判定を採用する方式とする．
つまり入力を[MATH]，[MATH]が[MATH]に対し出力する語義[MATH]である推定確率を[MATH]とすると，
より求まる[MATH]を[MATH]の出力とする．
式([REF_eq2])の方式で良い結果が得られる根拠は手掛り語[MATH]の条件の一つである式([REF_eq1])にある．
式([REF_eq1])の制約の下で[MATH]の値を大きくしたとき，得られる[MATH]に以下の二つの変化が見られる．
[MATH]変化前になくかつ[MATH]変化後に式([REF_eq1])を満たす語が追加される．
[MATH]変化前にはあるが[MATH]変化後に式([REF_eq1])を満たさなくなる語が削除される．
ここで重要なのは後者の性質である．
式([REF_eq1])の性質上，後者の変化より[MATH]から削除された語は[MATH]をどんなに大きくしても再度[MATH]に追加されることは絶対にない．
[MATH]変化後に削除される語は必ずしも重要度が高い語とも低い語とも言えないが，少なくとも一度は[MATH]の条件を満たすため重要度が高い語を含む可能性は高い．
よって，[MATH]の変化によって変わる各[MATH]の集合には他の集合にはない重要度の高い[MATH]が含まれている可能性が少なからずあるということになる．
したがって，[MATH]の差異により各分類器に長所・短所が生まれ，アンサンブル学習の効果が生まれやすいということができる．
逆に，[MATH]をアンサンブルしない場合，[MATH]の差異により性能に大きく差がつくと考えられ，[MATH]をパラメータとした調整は難しいと考えられる．
また[MATH]を増やせば，それだけ対象語から離れた位置にある語を特徴とすることになるため，少しずつ[MATH]の信頼性が落ちていくものと考えられるが，これに伴い任意の[MATH]に対し[MATH]の[MATH]の推定確率[MATH]も落ちていくと予想される．
すると，[MATH]の出力を式([REF_eq2])を満たす[MATH]としたが，[MATH]の増大に従い[MATH]の判定が採用される確率も減少していくと考えられる．
よって，[MATH]の増大は[MATH]の信頼性の減少を意味するが，同時に[MATH]の判定の採用確率も減ぜられる．
このため本手法は[MATH]の増大に対し頑健なアンサンブル手法であるとも言うことができる．
本手法はMihalceaのSmoothed Co-training [CITE]およびWangらTrajectory Basedの手法[CITE]と類似性を持つ．
まずWangらは文脈の大きさを変えながら複数のNaive Bayes分類器を作成しているが，提案手法の処理はこれとよく似ている．
Wangらの手法は文脈の大きさというパラメータの影響の差による性能差が小さくなることで性能が上がると見られるが，本手法でも同様の効果が期待できる．
またMihalceaはCo-trainingの反復過程にて分類器の多数決を適用した結果，反復回数の差による性能差が小さくなりかつ全体的な性能も向上したと報告したが，本手法における分類器の組合せにおいても同様の効果が期待できる．
なお，分類器の組合せのもう一つの単純な方式として推定確率を重みとした重み付き多数決方式，つまり
が考えられる．
ここで記号の意味は式([REF_eq2])と同じである．
しかし，式([REF_eq3])の方式は事前実験の結果，式([REF_eq2])の方式ほどは良くないことがわかった．
これは，[MATH]の増大に伴い[MATH]の推定確率が低くなることに変わりはないが，式([REF_eq2])と比べ[MATH]の大きな[MATH]の判定がより重めに考慮されていることが原因と思われる．
最後に本手法唯一のパラメータである[MATH]の変化の範囲について述べる．
一つの方法としては範囲を設けない，つまり任意の[MATH]を許すことが考えられるが，当然ながら[MATH]を増やすことで計算時間が増加する．
また，[MATH]の増大に伴う分類器の信頼性の減少に対しある程度は頑健であるとはいえ，限度の存在があり得る．
このため[MATH]の変化の範囲には何らかの閾値を定めるのが妥当と考えられる．
[REF_sec:exp]節で述べる実験ではパラメータ[MATH]を定め，[MATH]の範囲で[MATH]を1刻みで変化させるとし，[MATH]の変化により語義曖昧性解消の性能がどのように変化していくか見ていく．
提案手法を一つのアルゴリズムとして表現すると次のようになる．
まず着目すべきは本手法はStep 8に示した[MATH]以外にパラメータが存在しないことである．
そして[REF_sec:exp]節で示すようにこのパラメータの設定は比較的容易である．
次に留意すべきは[REF_sec:intro]節で述べた[MATH], [MATH], [MATH]といったパラメータがないにも関わらず，ブートストラッピングの効果が充分に見込めるという点である．
このメカニズムは，上記Step 2に示した手掛り語[MATH]の条件，Step 4の[MATH]の抽出の条件，Step 6の[MATH]抽出の条件，さらにStep 8, 9が巧妙に作用しあっていることに基づいている．
最後に注意すべきは，本手法はStep 0から9までの1度の実行だけで，充分なブートストラッピングが可能であり，2回以上の反復を必要としない点である．
しかし，Step 4の[MATH]の抽出は必然的に再現率を犠牲にするため，本手法1回の実行で完全な学習ができる訳ではない．
本手法の反復による更なる精度の向上は今後の課題である．
