NNBの性能を測りその特色を調べるため，ふたつのコーパスを用いた実験を行った．
一つ目はオークションの商品分類の実験であり，二つ目はニュースグループの文書分類の実験である．
これらの二つの実験において，形態素解析により得た表層形のbag-of-wordsを用いてNB，CNB，NNBの文書分類の性能を比較した．
また，NBBとCNBの差は事前確率[MATH]と[MATH]の部分であるため，CNBとNNBから第一項を省略した形の式（[MATH]なしのCNB）でも実験を行った．
なお，形態素解析ソフトにはMeCabを利用した．
また，スムージング手法としては，予備実験によりラプラススムージング[CITE]とJeffreys Perks法[CITE]を試し，Jeffreys Perks法の方が結果がよかったため，これを採用した．
さらに，Bayesではない手法の比較対象として，SVMについても実験を行った．
この際，分類器としてはマルチクラス対応のSVM (libsvm)を使用した．
カーネルは予備実験の結果，線形カーネルが最も高い正解率を示したため，これを採用した．
また，学習の素性はBayesの手法とそろえ，表層形のbag-of-wordsの頻度ベクトルを使用した．
すべての実験には五分割交差検定を用いた．
オークションの商品分類の実験は，Yahoo!オークションの商品タイトルを商品カテゴリに分類する実験である．
詳細は[CITE]にならった．
本実験では，「デスクトップ」「記念切手」「赤ちゃん用の玩具」の三つのジャンルカテゴリに含まれる商品を対象に実験を行った．
これらのジャンルカテゴリは，以下のようにトップカテゴリ（オークション）から絞り込むことができる．
オークション[MATH]コンピュータ[MATH]パソコン[MATH] Windows [MATH]デスクトップ
オークション[MATH]アンティーク，コレクション[MATH]切手，官製はがき[MATH]日本[MATH]特殊切手，記念切手
オークション[MATH]おもちゃ，ゲーム[MATH]ベビー用
ここで，[MATH]の左が親カテゴリ，右が子カテゴリを示す．
「デスクトップ」と「記念切手」は2012年6月26日に，「赤ちゃん用の玩具」は2012年6月29日に取得したデータである．
ひとつの商品はひとつの葉カテゴリにのみ属しているものとし，出品者によって登録されたカテゴリを正しいカテゴリとして実験を行った．
なお，例えばジャンルカテゴリが「デスクトップ」の場合，「ASUSの1,000円〜1,099円」や「IBMパソコン単体31,000円〜34,999円」といったものが葉カテゴリである．
また，[CITE]にならい，出品者個人による商品情報表記の癖などの偏りをなくすため，各カテゴリにつき1人の出品者の商品は1つしか使用しないものとし，商品タイトルの全単語を利用した実験と名詞のみを使用した二つの実験を行った．
\tabref{Tab:同じ出品者による商品をひとつにする前と後の商品数}にそれぞれのジャンルカテゴリ中の葉カテゴリ数，同じ出品者による商品をひとつにする前と後の商品数を示す．
ここで，商品数（処理前），商品数（処理後）はそれぞれ，同じ出品者による商品をひとつにする前と後の商品数である．
なお，「赤ちゃん用の玩具」の商品数（処理後）には8205，8204と二つ数字があるが，8205は全ての品詞の分類，8204は名詞のみの分類による商品数を示している．
「赤ちゃん用の玩具」のデータには，形態素解析の結果，全ての形態素が名詞以外の品詞に割りつけられた商品が1件あったため，このような結果になっている．
また，\figref{Fig:pc}，\figref{Fig:stamp}，\figref{Fig:toy}にそれぞれ「デスクトップ」，「記念切手」，「赤ちゃん用の玩具」のカテゴリごとの文書数，単語トークン数，名詞のトークン数を折れ線グラフにしたものを示す．
横軸のカテゴリindexは，カテゴリを文書数で並べ替えたときに降順につけたものである．
これらの図から，カテゴリの分類実験において，カテゴリごとに文書数，トークン数が非常に偏っていることが分かる．
特に，「記念切手」が最も偏っていることが読みとれる．
また，\tabref{Tab:オークションのカテゴリ分類実験のデータ}にオークションのカテゴリ分類実験の訓練事例中の商品数の標準偏差，訓練事例中の文書数の標準偏差を訓練事例中の総文書数の平均で割った値（以降，標準偏差／平均と表記），トークン数，1商品当たりの平均単語数を示す．
標準偏差／平均は，カテゴリ（またはクラス）ごとの商品数（または文書数）のばらつきを見るために示した．
ばらつきを測るのには標準偏差を用いるのが一般的であるが，本実験のように全商品数（または文書数）が異なる実験設定同士を比べる際には，全商品数（文書数）の絶対値が大きくなるにつれて標準偏差も大きくなるという問題があったためである．
標準偏差を平均で割ることによって，全商品数（文書数）のスケールに左右されないデータのばらつきを測った．
\tabref{Tab:オークションのカテゴリ分類実験のデータ}のこの「訓練事例中の商品数の標準偏差／平均」を見てみると，「記念切手」の値が「デスクトップ」や「赤ちゃん用の玩具」より高いことから，\figref{Fig:pc}〜\figref{Fig:toy}から読みとったように，「記念切手」が最も偏っていることが読みとれる．
ニュースグループの文書分類の実験のコーパスには20 Newsgroupsを利用した．
20 Newsgroupsは，全20クラス，18774件のニュース記事からコーパスが構成されており，文書数はどのクラスもおよそ1000件である(cf. \tabref{Tab:クラスごとの文書数を不均一にした実験のクラスごとの文書数})．
CNBとNNBの式，式([REF_eq:cnb])と式([REF_eq:nnb2])を比較してみると，事前確率[MATH]と[MATH]の部分が異なっていることが分かる．
残りの[MATH]については等しい．
しかし，単語数が少ない文書を分類する際には，単語数が多い文書を分類する際よりも，相対的に事前確率の影響が大きくなることが予想される．
そのため，一文書あたりの単語数を減らして実験を行い，その分類正解率を比較する．
この際，一文書あたりの単語数を[MATH]とし，パラメータを[MATH]とすると，一文書あたりの単語数を[MATH]（ただし割り切れない場合には1を加算する）として実験した．
パラメータ[MATH]は，0〜4を試した．
[MATH]が0のときには，オリジナルの20 Newsgroupsと等しい．
ニュースグループの分類実験において一文書あたりの単語数を減らした実験の訓練事例中の単語数，1文書当たりの平均の単語トークン数を\tabref{Tab:一文書あたりの単語数を減らした実験のデータ}に示す．
なお，このとき訓練事例中の総文書数はすべて18,774であり，訓練事例中の文書数の標準偏差はすべて95.95である．
また，訓練事例中の文書数の標準偏差／平均は0.10になる．
NNBは事前確率を数学的に正しく考慮しているため，文書分類ではクラスごとの文書数が不均一である際に効果を発揮すると考えられる．
そのため，20 Newsgroupsにおいて，クラスごとに文書を間引きすることによって，クラスごとの文書数を不均一にして実験を行い，比較する．
この際，クラスのインデックスを[MATH]，パラメータを[MATH]とすると，[MATH]だけは常にオリジナルの文書数を保ったままとし，[MATH]から文書数を[MATH]に減らして実験を行った．
例えば，[MATH]のときには，[MATH]の時にはそれぞれ[MATH]となり，[MATH]のときには，[MATH]の時にはそれぞれ[MATH]となる．
パラメータ[MATH]は，1〜4を試した．
\tabref{Tab:クラスごとの文書数を不均一にした実験のクラスごとの文書数}に，クラスごとの文書数を不均一にした実験のクラスごとの文書数を示す．
また，\tabref{Tab:一文書あたりの単語数を減らした実験のデータ}にニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の訓練事例中の総文書数，文書数の標準偏差，標準偏差／平均，単語トークン数，1文書当たりの平均の単語トークン数を示す．
また，ニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の訓練事例中の総文書数，文書数の標準偏差，標準偏差／平均，単語トークン数，1文書当たりの平均の単語トークン数を\tabref{Tab:クラスごとの文書数を不均一にした実験のデータ}に示す．
