NNBはCNBと同様に補集合を利用して文書分類を行うが，CNBと異なってNBと同じ事後確率最大化の式から導出が可能である．
その結果，事前確率を数学的に正しく考慮することで，クラスごとの文書数が異なっているときにもより正確な文書分類を行えるようにした．
本節ではNBの導出と，CNBの概念について触れた後，提案手法であるNNBの導出について述べる．
一般に確率モデルによる文書分類では，分類対象となる文書を[MATH]，ある一つのクラスを[MATH]としたとき，事後確率[MATH]を最大化するクラス[MATH]を求める[CITE]．
NB分類器を用いた文書分類では，事後確率にBayesの定理を適用する．
文書の取り出される確率[MATH]はすべてのクラスについて一定であることを考慮すると，事後確率が最大のクラスを推定することは，クラスの出現確率[MATH]と各クラスでの文書の出現確率[MATH]の積を最大化するクラスを推定することと等しくなる．
式([REF_eq:bayes])において，[MATH]は全文書中でクラス[MATH]に属する文書の割合を用いて容易に推定ができるが，[MATH]を直接推定するのは難しい．
そこで，まず文書[MATH]を単語列[MATH]で近似する．
次に，各クラスで単語が独立に生起すると仮定すると，式([REF_eq:bayes2])は
と近似される．
したがって，[MATH]の属するクラス[MATH]は最終的に以下の式で求められる．
多項モデルを用いたNB分類器では，クラス間の文書数に大きなばらつきがある場合に，文書数の小さいクラスで[MATH]が大きくなる傾向がある．
[MATH]は「そのクラス中に出てきたそのトークン[MATH]の数／そのクラス中に出てきたそのトークンの総数」であるため，訓練事例の単語トークン数に大きな差ができた結果，大きいクラスの[MATH]は比較的小さく，小さいクラスの[MATH]はかなり大きくなることが予想できる．
その結果，小さいクラスに出現した単語を含む文書が出現した場合，その文書は，その単語をもつ小さなクラスに割り当てられることになる．
また，文書数の少ないクラスでは，新規文書に出現した単語がそのクラスに含まれていない割合が多くなり，データがスパースになりやすい．
そこで，学習する文書数のばらつきを抑え，スパースネス問題を緩和するようNBを改良したのが[CITE]のCNBである．
具体的には，「クラス[MATH]に属す訓練事例」ではなく「クラス[MATH]に属さない訓練事例」すなわち「[MATH]に属する訓練事例（補集合）」を用いて学習を行う．
図[REF_Fig:コンプ文書数変化]は，NBとCNBでの学習に用いる文書数の違いを表している．
文書数10，10，20，40の4つのクラスがある場合，NBではこの文書数を自身のクラスの学習に使う．
そのため，文書数が最も少ないクラスと最も多いクラスでは学習に使用する文書数に4倍の差がある．
一方，CNBでは自身のクラスに属する文書以外の文書から学習を行うため，学習に用いる文書数は最小のもので40，最大のもので70となり，NBに比べてばらつきが小さくなる．
CNBは，文書内にある単語の出現確率の積から尤度を計算し，分類するクラスを決めるという点ではNBと同じである．
つまり，式([REF_eq:rnb])を用いて文書[MATH]の属するクラス[MATH]を推定する．
しかし，CNBでは[MATH]を最尤推定で求めるのではなく，[MATH]以外のクラス[MATH]の尤度の積から推定する．
つまり，[MATH]の属するクラス[MATH]は最終的に以下の式で求められる．
前節で説明したCNBは，NBの持つ「クラス間の文書数のばらつきによって分類結果が偏る」という特徴を緩和する手法である．
しかし，CNBはヒューリスティックによる解決法であって，事後確率最大化の式から導出することはできない．
そこで本研究では，事後確率最大化の式から導出でき，かつ，CNBの「訓練にクラスの補集合を利用する」という長所をもつ分類器を作成する．
以下でNBと同様の，事後確率最大化の式（式([REF_eq:bayes])）からの式の変形について述べる．
まず，事後確率[MATH]を最大化するクラス[MATH]を求める式を補集合を利用するように変形する．
次に，Bayesの定理を用いて式([REF_eq:eqnnb1])を変形する．
そして，式([REF_eq:eqnnb2])を近似する．
[MATH]は式([REF_eq:bayes2])，([REF_eq:bayes3])と同様に
と近似される．
したがって，文書[MATH]の属するクラス[MATH]を以下の式で推定する．
なお，[MATH]であり，CNBと同じく最大化で表現すると以下の式になる．
式([REF_eq:cnb])と比較すると，[MATH]の最大化の部分，つまり事前確率[MATH]の部分が異なっていることが分かる．
式([REF_eq:nnb2])は事後確率最大化の式から求められたため，事前確率を数学的に正しく考慮した式となっている．
なお，Rennieらの研究では，式([REF_eq:cnb])において事前確率の扱いについてあまり注意を払っていないが，我々はクラスごとに単語数の偏りが大きいデータセットについて分類を行う場合には，[MATH]を利用するか[MATH]を利用するかの影響は必ずしも無視して良いとは言えないと考える．
また，Rennieらの研究では，[MATH]は[MATH]に比べて分類結果への影響が小さいと判断し，事前確率は計算してもしなくても結果は同じと考え，実際の分類には[MATH]を無視して[MATH]のみを計算しているため，P(c)なしのCNBについても参考として実験を行う．
\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}と\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}に全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示し，\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}に名詞だけを使用したオークションのカテゴリ分類実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示す．
また，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率}と\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}にニュースグループの分類実験において，一文書あたりの単語数を減らした実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示し，\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}に同分類実験において，クラスごとの文書数を不均一にした実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示す．
なお，正解率は，（分類に成功したもの）／（実験データ数）として求めた．
同じ文書集合の実験で，NB，CNB，NNBのうちで最も良かった正解率を太字で示した．
さらに，次に良かった正解率との差がカイ二乗検定で有意だったものに関しては下線を引いた．
また，[MATH]なしのCNBとSVMに関しては，上記の三手法のうち最も良かった手法と同じか，それよりも良いものは太字で示し，その優劣にかかわらず，差がカイ二乗検定で有意だったものに関しては下線を引いた．
さらに，参考として最頻出カテゴリ（クラス）を答えた場合の正解率も併記した．
\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率}から，オークションのカテゴリ分類実験において，マイクロ平均を比較した際，NNBが常にNBとCNBを有意に上回っていることが分かる．
また同じ二つの表から，NNBが[MATH]なしのCNBよりも大抵（名詞だけの実験の「デスクトップ」が例外である）上回っていることが分かる．
このうち，「記念切手」の実験では，全単語使用した場合，名詞だけを使用した場合に拘わらず，カイ二乗検定によりその差が有意であった．
しかし，これらの実験において最も良い結果なのはSVMであり，NNBを有意に上回っている．
また，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}から，オークションのカテゴリ分類実験において，マクロ平均においても，有意ではないながら，NNBが常にNBとCNBを上回っていることが分かる．
また同じ二つの表から，[MATH]なしのCNBが有意ではないものの，NNBを上回っていることが分かる．
さらに，SVMは「デスクトップ」と「記念切手」においては有意に，「赤ちゃん用の玩具」では有意ではないものの，NNBを上回った．
また，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}から，ニュースグループの分類実験においても，マイクロ平均で比較した場合，常にNBBがNBとCNBを上回ることが分かる．
ただし，その差が有意なのは，クラスごとの文書数を不均一にした実験（\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}）のパラメータが1のときと3のときだけである．
また，これらの実験において，[MATH]なしのCNBはしばしばNNBを上回っているが，有意に上回っていることは一度もなかった．
さらに\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率}の一文書あたりの単語数を減らした実験では，パラメータ0，1，2のとき，NNBの分類正解率がSVMを有意に上回っている．
しかし，パラメータ3，4のときはSVMが最高であり，NNBと比較してその差は有意であった．
一方，\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}から，クラスごとの文書数を不均一にした実験では，全ての実験設定のときにNNBがSVMを上回っている．
この差はカイ二乗検定により有意であった．
これに対し，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，ニュースグループの分類実験において，マクロ平均においても，NNBが常にNBとCNBを上回っていることが分かる．
また同じ二つの表から，[MATH]なしのCNBがNNBを上回っていることが分かるが，これらの差はいずれも有意ではない．
さらに，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}の一文書あたりの単語数を減らした実験では，常に有意でないながらもNNBの分類正解率がSVMを上回っている．
しかし，パラメータ3，4のときは，マイクロ平均と同様にSVMが最高であり，NNBと比較してその差は有意であった．
一方，\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，クラスごとの文書数を不均一にした実験では，全ての実験設定のときにNNBがSVMを上回っている．
この差はパラメータ0と1のとき，カイ二乗検定により有意であった．
NNBはCNBと同様に補集合を利用して文書分類を行うが，CNBと異なってNBと同じ事後確率最大化の式から導出が可能である．
その結果，事前確率を数学的に正しく考慮することで，クラスごとの文書数が異なっているときにもより正確な文書分類を行えるようにした．
本節ではNBの導出と，CNBの概念について触れた後，提案手法であるNNBの導出について述べる．
一般に確率モデルによる文書分類では，分類対象となる文書を[MATH]，ある一つのクラスを[MATH]としたとき，事後確率[MATH]を最大化するクラス[MATH]を求める[CITE]．
NB分類器を用いた文書分類では，事後確率にBayesの定理を適用する．
文書の取り出される確率[MATH]はすべてのクラスについて一定であることを考慮すると，事後確率が最大のクラスを推定することは，クラスの出現確率[MATH]と各クラスでの文書の出現確率[MATH]の積を最大化するクラスを推定することと等しくなる．
式([REF_eq:bayes])において，[MATH]は全文書中でクラス[MATH]に属する文書の割合を用いて容易に推定ができるが，[MATH]を直接推定するのは難しい．
そこで，まず文書[MATH]を単語列[MATH]で近似する．
次に，各クラスで単語が独立に生起すると仮定すると，式([REF_eq:bayes2])は
と近似される．
したがって，[MATH]の属するクラス[MATH]は最終的に以下の式で求められる．
多項モデルを用いたNB分類器では，クラス間の文書数に大きなばらつきがある場合に，文書数の小さいクラスで[MATH]が大きくなる傾向がある．
[MATH]は「そのクラス中に出てきたそのトークン[MATH]の数／そのクラス中に出てきたそのトークンの総数」であるため，訓練事例の単語トークン数に大きな差ができた結果，大きいクラスの[MATH]は比較的小さく，小さいクラスの[MATH]はかなり大きくなることが予想できる．
その結果，小さいクラスに出現した単語を含む文書が出現した場合，その文書は，その単語をもつ小さなクラスに割り当てられることになる．
また，文書数の少ないクラスでは，新規文書に出現した単語がそのクラスに含まれていない割合が多くなり，データがスパースになりやすい．
そこで，学習する文書数のばらつきを抑え，スパースネス問題を緩和するようNBを改良したのが[CITE]のCNBである．
具体的には，「クラス[MATH]に属す訓練事例」ではなく「クラス[MATH]に属さない訓練事例」すなわち「[MATH]に属する訓練事例（補集合）」を用いて学習を行う．
図[REF_Fig:コンプ文書数変化]は，NBとCNBでの学習に用いる文書数の違いを表している．
文書数10，10，20，40の4つのクラスがある場合，NBではこの文書数を自身のクラスの学習に使う．
そのため，文書数が最も少ないクラスと最も多いクラスでは学習に使用する文書数に4倍の差がある．
一方，CNBでは自身のクラスに属する文書以外の文書から学習を行うため，学習に用いる文書数は最小のもので40，最大のもので70となり，NBに比べてばらつきが小さくなる．
CNBは，文書内にある単語の出現確率の積から尤度を計算し，分類するクラスを決めるという点ではNBと同じである．
つまり，式([REF_eq:rnb])を用いて文書[MATH]の属するクラス[MATH]を推定する．
しかし，CNBでは[MATH]を最尤推定で求めるのではなく，[MATH]以外のクラス[MATH]の尤度の積から推定する．
つまり，[MATH]の属するクラス[MATH]は最終的に以下の式で求められる．
前節で説明したCNBは，NBの持つ「クラス間の文書数のばらつきによって分類結果が偏る」という特徴を緩和する手法である．
しかし，CNBはヒューリスティックによる解決法であって，事後確率最大化の式から導出することはできない．
そこで本研究では，事後確率最大化の式から導出でき，かつ，CNBの「訓練にクラスの補集合を利用する」という長所をもつ分類器を作成する．
以下でNBと同様の，事後確率最大化の式（式([REF_eq:bayes])）からの式の変形について述べる．
まず，事後確率[MATH]を最大化するクラス[MATH]を求める式を補集合を利用するように変形する．
次に，Bayesの定理を用いて式([REF_eq:eqnnb1])を変形する．
そして，式([REF_eq:eqnnb2])を近似する．
[MATH]は式([REF_eq:bayes2])，([REF_eq:bayes3])と同様に
と近似される．
したがって，文書[MATH]の属するクラス[MATH]を以下の式で推定する．
なお，[MATH]であり，CNBと同じく最大化で表現すると以下の式になる．
式([REF_eq:cnb])と比較すると，[MATH]の最大化の部分，つまり事前確率[MATH]の部分が異なっていることが分かる．
式([REF_eq:nnb2])は事後確率最大化の式から求められたため，事前確率を数学的に正しく考慮した式となっている．
なお，Rennieらの研究では，式([REF_eq:cnb])において事前確率の扱いについてあまり注意を払っていないが，我々はクラスごとに単語数の偏りが大きいデータセットについて分類を行う場合には，[MATH]を利用するか[MATH]を利用するかの影響は必ずしも無視して良いとは言えないと考える．
また，Rennieらの研究では，[MATH]は[MATH]に比べて分類結果への影響が小さいと判断し，事前確率は計算してもしなくても結果は同じと考え，実際の分類には[MATH]を無視して[MATH]のみを計算しているため，P(c)なしのCNBについても参考として実験を行う．
\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}と\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}に全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示し，\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}に名詞だけを使用したオークションのカテゴリ分類実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示す．
また，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率}と\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}にニュースグループの分類実験において，一文書あたりの単語数を減らした実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示し，\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}に同分類実験において，クラスごとの文書数を不均一にした実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示す．
なお，正解率は，（分類に成功したもの）／（実験データ数）として求めた．
同じ文書集合の実験で，NB，CNB，NNBのうちで最も良かった正解率を太字で示した．
さらに，次に良かった正解率との差がカイ二乗検定で有意だったものに関しては下線を引いた．
また，[MATH]なしのCNBとSVMに関しては，上記の三手法のうち最も良かった手法と同じか，それよりも良いものは太字で示し，その優劣にかかわらず，差がカイ二乗検定で有意だったものに関しては下線を引いた．
さらに，参考として最頻出カテゴリ（クラス）を答えた場合の正解率も併記した．
\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率}から，オークションのカテゴリ分類実験において，マイクロ平均を比較した際，NNBが常にNBとCNBを有意に上回っていることが分かる．
また同じ二つの表から，NNBが[MATH]なしのCNBよりも大抵（名詞だけの実験の「デスクトップ」が例外である）上回っていることが分かる．
このうち，「記念切手」の実験では，全単語使用した場合，名詞だけを使用した場合に拘わらず，カイ二乗検定によりその差が有意であった．
しかし，これらの実験において最も良い結果なのはSVMであり，NNBを有意に上回っている．
また，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}から，オークションのカテゴリ分類実験において，マクロ平均においても，有意ではないながら，NNBが常にNBとCNBを上回っていることが分かる．
また同じ二つの表から，[MATH]なしのCNBが有意ではないものの，NNBを上回っていることが分かる．
さらに，SVMは「デスクトップ」と「記念切手」においては有意に，「赤ちゃん用の玩具」では有意ではないものの，NNBを上回った．
また，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}から，ニュースグループの分類実験においても，マイクロ平均で比較した場合，常にNBBがNBとCNBを上回ることが分かる．
ただし，その差が有意なのは，クラスごとの文書数を不均一にした実験（\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}）のパラメータが1のときと3のときだけである．
また，これらの実験において，[MATH]なしのCNBはしばしばNNBを上回っているが，有意に上回っていることは一度もなかった．
さらに\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率}の一文書あたりの単語数を減らした実験では，パラメータ0，1，2のとき，NNBの分類正解率がSVMを有意に上回っている．
しかし，パラメータ3，4のときはSVMが最高であり，NNBと比較してその差は有意であった．
一方，\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}から，クラスごとの文書数を不均一にした実験では，全ての実験設定のときにNNBがSVMを上回っている．
この差はカイ二乗検定により有意であった．
これに対し，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，ニュースグループの分類実験において，マクロ平均においても，NNBが常にNBとCNBを上回っていることが分かる．
また同じ二つの表から，[MATH]なしのCNBがNNBを上回っていることが分かるが，これらの差はいずれも有意ではない．
さらに，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}の一文書あたりの単語数を減らした実験では，常に有意でないながらもNNBの分類正解率がSVMを上回っている．
しかし，パラメータ3，4のときは，マイクロ平均と同様にSVMが最高であり，NNBと比較してその差は有意であった．
一方，\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，クラスごとの文書数を不均一にした実験では，全ての実験設定のときにNNBがSVMを上回っている．
この差はパラメータ0と1のとき，カイ二乗検定により有意であった．
