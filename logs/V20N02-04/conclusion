考察 \label{Sec:考察}

オークションのカテゴリ分類実験の結果とニュースグループの分類実験の結果を総合してNNBの特色について考察する．
まず，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}〜\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，
全ての実験を通して，NNBはNBとCNBを上回っていること，また$P(c)$なしのCNBに有意に勝っていることはあっても有意に負けていることはないことが
読みとれる\footnote{ただし，有意ではないものの，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}では常に$P(c)$なしのCNBがNNBを上回っている．$P(c)$は事前確率であるため，カテゴリ間のデータ数に偏りがあり，なおかつ単語トークン数が少ない場合には，NNBは大きなカテゴリに分類されやすいことが予想できる．そのため，マイクロ平均は$P(c)$なしのCNBを有意に上回ったが，マクロ平均は$P(c)$なしのCNBが高くなる傾向がある可能性がある．}
．
このことから，NNBは他のBayesの定理を利用した文書分類手法に比較しても引けを取らない文書分類手法であると言える．特にNBと比較したときには，マイクロ平均では常に有意に，
マクロ平均ではオークションのカテゴリ実験において「デスク
トップ」と「記念切手」の全品詞を使った分類実験以外の実験で有意に勝っていた．
なお，
マクロ平均ではサンプル数の減少から，NNBと比較した際，SVMとNBだけにしか有意差が
認められなかったため，今後は主にマイクロ平均について考察する．

オークションのカテゴリ分類実験とニュースグループの分類実験の実験設定の違いのうち，NNBの式に大きく関わりそうな点は二点あるだろう．
一つ目は第一項の事前確率に関わる，クラスごとの文書数（またはカテゴリごとの商品数）のばらつき，
二つ目はそれ以外の部分に関わる，一文書ごとの単語トークン数である．
\ref{Sec:ニュースグループの文書分類の実験}節でも述べたように，
CNBとNNBの式，式 (\ref{eq:cnb}) と式 (\ref{eq:nnb2}) を比較してみると，事前確率$P(c)$と$ \frac{1}{1-P(c)}$の部分が異なっており，
残りの$\prod_{i=1}^{n} \frac{1}{P(w_i|\bar{c})}$については等しい．
NNBは事前確率を数学的に正しく考慮しているため，文書分類ではクラスごとの文書数が不均一である際に効果を発揮すると考えられる．
また，単語数が少ない文書を分類する際には，単語数が多い文書を分類する際よりも，相対的に事前確率の影響が大きくなることが予想される．


クラスごとの文書数のばらつきを見るために，
\figref{Fig:標準偏差／平均}に同実験においてクラスごとの文書数を不均一にした実験の，クラスごとの文書数の標準偏差／平均を横軸とした
分類正解率の散布図を示す．

\begin{figure}[b]
\begin{center}
\includegraphics{20-2ia4f5.eps}
\end{center}
\hangcaption{ニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の，
	クラスごとの文書数の標準偏差／平均を横軸とした分類正解率の散布図}
\label{Fig:標準偏差／平均}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{20-2ia4f6.eps}
\end{center}
\hangcaption{ニュースグループの分類実験において一文書あたりの単語数を減らした実験の，一文書あたりの単語トークン数を横軸とした分類正解率の散布図}
\label{Fig:1文書ごとに平均した単語数}
\end{figure}

また，単語トークン数の影響を見るために，\figref{Fig:1文書ごとに平均した単語数}にニュースグループの分類実験において一文書あたりの単語数を減らした実験の，
一文書あたりの単語トークン数を横軸とした分類正解率の散布図を示す．その上でNNBの特徴をNB，CNB（$P(c)$のないものを含む），SVMの順で比較しつつ考察する．

\figref{Fig:標準偏差／平均}から，NBはクラスごとの文書数のばらつきが多い際にその分類正解率が著しく低下することが分かる．
また，商品のカテゴリ分類実験において，NBの分類正解率がとても低いのも
同じ原因によるものであることがうかがえる．商品のカテゴリ分類実験において，標準偏
\linebreak
差／平均は「デスクトップ」，「記念切手」，「赤ちゃん用の玩具」
がそれぞれ1.44，2.84，1.33と高く，
カテゴリごとの商品数のばらつきが大きいからである．
この原因として，クラスごとの$P(w_i|c)$のデータスパースネスの差が考えられる．ここでNBの式を再掲する．
\begin{equation}
\hat{c}=\argmax_{c} P(c) \prod_{i=1}^{n} P(w_i|c) \label{eq:rnb2}
\end{equation}
NBではクラスごとの文書数のばらつきが大きい際には，クラスによって訓練事例の単語トークン数に大きな差ができる．
例えば最も大きなクラスでは，その訓練事例となるトークン数が一万となり，小さなクラスでは10トークンといった具合である．
その結果，小さなクラスではデータがス
パースになり，より頻繁にスムージングが行われる．そのため，NBでは，個々の分類問題と
相性の良いスムージング手法を用いることが求められるが，今回のジェフリー・パークス法は
ラプラス法よりは良いとはいえ，まだ実際よりも大きな値を小さなクラスに与えていたと思わ
れる\footnote{\citeA{佐藤}のスムージング（頻度0の時には0.1/Nを用いる．このNは訓練事例中の全単語トークン数．）を用いるとNBだけ飛躍的に正解率が上昇した．ただし，本論文の主張との矛盾はない結果であった．}．
このように，NBではデータスパースネスによって誤分類が起きて分類正解率が著しく
下がることがあるが，この
問題を補集合を用いることで解決したのがCNBであり，この点についてNNBはCNBと全く同じ特色を持っている．

次に，NNBとCNBの差について考察する．
\figref{Fig:標準偏差／平均}を見てみると，$P(c)$を考慮しないCNBとNNBの差はあまりないが，NNBはCNBより若干
良いことが分かる．
これは，クラスごとの文書数に偏りが出てくると，CNBとNNBの違いである事前確率が異なってくるため，
その分類正解率に差がつくからであると考えられる．

次に\figref{Fig:1文書ごとに平均した単語数}を見てみると，一文書当たりの平均の単語数が減ると，どの手法を用いても全体的に分類正解率が低下することが分かる．
これは，単語数が減ることで，統計の材料となる$w_i$が減っているためであると考えられる．
これに対し，一文書当たりの単語数を変化させても，CNBとNNBの差が大きくなることはなかった．
これは，ニュースグループのオリジナルのコーパスでは，そもそもクラスごとの文書数に偏りがあまり見られないため，事前確率に偏りがなく，CNBとNNBがそう違わない結果になったためであると考えられる．

ここで，オークションのカテゴリ分類実験の実験設定も共に比較してみる．
\figref{Fig:CNBとNNB}に縦軸を標準偏差／平均，横軸をクラスごとの単語数にした，実験設定ごとのCNBとNNBの差の散布図を示す．
左の図が事前確率を考慮したCNBとNNBの差が有意であるかを表しており，右の図が事前確率を考慮しないCNBとNNBの差が有意であるかを表している．
なお，両方の図において，縦軸の値が0.10である五つの点が，ニュースグループの一文書当たりの単語数を減らした一連の実験であり，
横軸の値が128.71である五つの点が，ニュースグループのクラスごとの文書数を不均一にした一連の実験である．
オークションのカテゴリ分類実験の実験設定では，
ニュースグループの実験よりも，ひとつの文書（商品）ごとのトークン数が少なく（一文書当たりの単語数を最も減らした実験と同じくらいである），
なおかつクラス（カテゴリ）ごとの文書数（商品数）の偏りが，クラスごとの文書数を不均一にしたニュースグループの実験と同じくらい，またはそれ以上に偏っていることが分かる．

\begin{figure}[t]
\begin{center}
\includegraphics{20-2ia4f7.eps}
\end{center}
\hangcaption{横軸を標準偏差／平均，縦軸をクラスごとの単語数にした，実験設定ごとのCNBとNNBの差の散布図}
\label{Fig:CNBとNNB}
\end{figure}

\figref{Fig:CNBとNNB}により，標準偏差／平均が小さい時にはCNBとNNBの差はほとんどないこと，また，標準偏差／平均が大きくなるにつれてNNBが有意にCNBを上回るようになる傾向がうかがえる．
また，一文書あたりの単語数が少ない時に，なおかつ標準偏差／平均が大きければ，NNBが有意に事前確率を考慮しないCNBに対しても有意に上回ることが分かる．
オークションのカテゴリ分類実験の「記念切手」（左上の二点）のときには，両方の条件が共に十分当てはまったため，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回ったものと
思われる．

次に，SVMとの比較を行う．
残念ながら，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回った「記念切手」の実験設定を含む，オークションのカテゴリ分類実験では，SVMの分類正解率がいつも他手法を有意に上回った．
しかし，ニュースグループの文書分類実験では，一文書あたりの文書数を減らした場合のパラメータが3と4の実験を除き，NNBがSVMを有意に上回った．
上述したように，$w_i$の数が減ってしまうと，Bayesianアプローチの正解率は下がることが一文書当たりの単語数が減った際にSVMを有利にしたと考えられる．
しかし，ニュースグループのオリジナルのコーパスの実験では，CNBとの差は有意ではないながらも，NNBが全ての分類器の中で最も高い分類正解率となっている．
このことから，NNBは時にはSVMを有意に上回り，他手法と比較しても最も良い分類正解率を示しうる手法であることが分かる\footnote{\citeA{Gabrilovich}では，ニュースグループの分類実験において素性選択をする前でも76.9\%，素性選択後は85.3\%という正解率を報告している．また，\citeA{Siolas}では，同実験において素性選択を行うと86.44\%となっている．このように，SVMは素性選択などによってもっと性能をあげることが可能であるため，それらの手法を用いればSVMの方が性能が良くなる可能性が高い．また，五分割交差検定の分割法を変えて実験してみると，SVMの正解率が75.79\%となったことから，SVMの性能は，選択されるテストセットの選び方によって変化することが分かった．NNBなどのベイズの手法の正解率も，五分割交差検定の分割法により変化することが予想される．}．

\begin{table}[t]
\caption{ニュースグループの分類実験にかかった時間}
\label{Tab:ニュースグループの分類実験にかかった時間}
\input{04table14.txt}
\end{table}

また，最後に，提案手法の速度についての目安を知るために，最も実行時間がかかるオリジ
ナルのニュースグループの分類実験において，それぞれの手法の実行時間を測った．
\tabref{Tab:ニュースグループの分類実験にかかった時間}に
その結果を示す．SVMはC言語により実装されたツールによるものであり，それ以外の
BayesianアプローチはPerlにより個人的に実装したものであるため，一概に比較は難しいが，
NNBがCNBとほぼ同じ速度で実行されることが分かる．



まとめ \label{Sec:まとめ}

本稿では，文書分類のための新手法として，Negation Naive Bayes (NNB)を提案し，その性質を他のBayesianアプローチである
Naive Bayes (NB)，Complement Naive Bayes (CNB) と比較した．
NNBは，CNBと同様にクラスの補集合を用いるが，NBと同じ事後確率最大化の式から導出されるため，事前確率を数学的に正しく考慮している点で異なっている．
NNBの性質を見るために，ふたつのコーパスを用いた実験を行った．
一つ目はオークションの商品分類の実験であり，二つ目はニュースグループの文書分類の実験である．
このうち，ニュースグループの文書分類の実験では，一文書あたりの単語数を減らした実験と，クラスごとの文書数を不均一にした実験を行い，
オリジナルの文書集合の実験に加え，それぞれパラメータを変えて四通りを試した．
その結果，すべての実験においてNNBとCNBがNBの分類性能を上回ること，また，一文書当たりの単語数が減り，クラスごとの文書数が偏るときに
マイクロ平均でNNBはCNBを上回ることが分かった．事前確率を無視したCNBと比較しても，これらの条件が共に当てはまる際には，NNBがCNBを有意に上回った．
これは，CNBとNNBの違いは事前確率にあるため，クラスごとの文書数が偏るときにその影響が見られ，なおかつ一文書当たりの単語数が減る際には
相対的に事前確率の影響が大きくなるためであると考えられる．
また，CNBまたは事前確率を無視したCNBがNNBを有意に上回ることはなかった．
さらに，ニュースグループの分類実験においては，その際のCNBとの差は微小ながら，参考として比較したサポートベクターマシン (SVM) をカイ二乗検定で有意に上回り，
比較手法中で最も良い分類正解率を示す結果も見られた．

これらのことから，特に一文書当たりの単語数が減り，クラスごとの文書数が偏る場合において，NNBが他のBayesianアプローチより勝る手法であること，
また，時にはSVMを有意に上回り，比較手法中で最も良い分類正解率を示す手法であることが分かった．



\acknowledgment

本研究の一部は，文部科学省科学研究費補助金［若手B (No: 24700138)］の助成により行われた.
ここに，謹んで御礼申し上げる．また，本論文の内容の一部は，Recent Advances in Natural Language Processing 2011で発表した
ものである \cite{Komiya}．


\nocite{Kenneth}
\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Box \BBA\ Tiao}{Box \BBA\ Tiao}{1973}]{JeffreysPerks}
Box, G. E.~P.\BBACOMMA\ \BBA\ Tiao, G.~C. \BBOP 1973\BBCP.
\newblock {\Bem Bayesian Inference in Statistical Analysis}.
\newblock Reading, MA: Addison-Wesley.

\bibitem[\protect\BCAY{Church}{Church}{2000}]{Kenneth}
Church, K.~W. \BBOP 2000\BBCP.
\newblock \BBOQ Empirical Estimates of Adaptation: The chance of Two Noriegas
  is closer to $p/2$ than $p^2$.\BBCQ\
\newblock In {\Bem Proceedings of the COLING '00}, \mbox{\BPGS\ 182--191}.

\bibitem[\protect\BCAY{Gabrilovich \BBA\ Markovitch}{Gabrilovich \BBA\
  Markovitch}{2004}]{Gabrilovich}
Gabrilovich, E.\BBACOMMA\ \BBA\ Markovitch, S. \BBOP 2004\BBCP.
\newblock \BBOQ Text Categorization with Many Redundant Features: Using
  Aggressive Feature Selection to Make SVMs Competitive with C4.5.\BBCQ\
\newblock In {\Bem Proceedings of the The Twenty-First International Conference
  on Machine Learning}, \mbox{\BPGS\ 321--328}.

\bibitem[\protect\BCAY{花井\JBA 山村}{花井\JBA 山村}{2005}]{花井}
花井拓也\JBA 山村毅 \BBOP 2005\BBCP.
\newblock
  単語間の依存性を考慮したナイーブベイズ法によるテキスト分類(類似性の発見).\
\newblock \Jem{情報処理学会研究報告 自然言語処理研究会報告, 2005(22)},
  \mbox{\BPGS\ 101--106}.

\bibitem[\protect\BCAY{井筒\JBA 横澤\JBA 篠原}{井筒 \Jetal }{2005}]{井筒}
井筒清史\JBA 横澤誠\JBA 篠原健 \BBOP 2005\BBCP.
\newblock Web文書タイプ自動分類手法の比較評価と適用.\
\newblock In {\Bem IPSJ SIG Notes 2005(32)}, \mbox{\BPGS\ 25--32}.

\bibitem[\protect\BCAY{Komiya, Sato, Fujimoto, \BBA\ Kotani}{Komiya
  et~al.}{2011}]{Komiya}
Komiya, K., Sato, N., Fujimoto, K., \BBA\ Kotani, Y. \BBOP 2011\BBCP.
\newblock \BBOQ Negation Naive Bayes for Categorization of Product Pages on the
  Web.\BBCQ\
\newblock In {\Bem Proceedings of the RANLP 2011}, \mbox{\BPGS\ 586--591}.

\bibitem[\protect\BCAY{Lewis}{Lewis}{1992}]{Lewis}
Lewis, D.~D. \BBOP 1992\BBCP.
\newblock \BBOQ An Evaluation of Phrasal and Clustered Representations on a
  Text Categorization Task.\BBCQ\
\newblock In {\Bem Proceedings of the 15th Annual International ACM SIGIR
  Conference on Research and Development in Information Retrieval},
  \mbox{\BPGS\ 37--50}.

\bibitem[\protect\BCAY{marquis~de Laplace}{marquis~de Laplace}{1814}]{ラプラス}
marquis~de Laplace, P.~S. \BBOP 1814\BBCP.
\newblock {\Bem Essei philosophique sur les probabilites}.
\newblock Paris: Mme. Ve. Courcier.

\bibitem[\protect\BCAY{marquis~de Laplace}{marquis~de
  Laplace}{1995}]{ラプラス2}
marquis~de Laplace, P.~S. \BBOP 1995\BBCP.
\newblock {\Bem Philosophical Essay On Probabilities}.
\newblock New York: Springer-Verlag.

\bibitem[\protect\BCAY{McCallum \BBA\ Nigam}{McCallum \BBA\
  Nigam}{1998}]{Andrew}
McCallum, A.\BBACOMMA\ \BBA\ Nigam, K. \BBOP 1998\BBCP.
\newblock \BBOQ A Comparison of Event Models for Naive Bayes Text
  Classification.\BBCQ\
\newblock In {\Bem Proceedings of the AAAI/ICML-98 Workshop on Learning for
  Text Categorization}, \mbox{\BPGS\ 41--48}.

\bibitem[\protect\BCAY{持橋}{持橋}{2006}]{持橋}
持橋大地 \BBOP 2006\BBCP.
\newblock 自然言語処理におけるベイズ統計.\
\newblock \Jem{電子情報通信学会技術研究報告 NC, ニューロコンピューティング},
  \mbox{\BPGS\ 25--30}.

\bibitem[\protect\BCAY{持橋\JBA 菊井}{持橋\JBA 菊井}{2006}]{持橋06}
持橋大地\JBA 菊井玄一郎 \BBOP 2006\BBCP.
\newblock 無限混合ディリクレ文書モデル.\
\newblock \Jem{自然言語処理研究会報告 2006-NL-172}, \mbox{\BPGS\ 47--53}.

\bibitem[\protect\BCAY{Rennie, Shih, Teevan, \BBA\ Karger}{Rennie
  et~al.}{2003}]{Rennie}
Rennie, J. D.~M., Shih, L., Teevan, J., \BBA\ Karger, D.~R. \BBOP 2003\BBCP.
\newblock \BBOQ Tackling the Poor Assumptions of Naive Bayes Text
  Classifiers.\BBCQ\
\newblock In {\Bem Proceedings of the ICML2003}, \mbox{\BPGS\ 616--623}.

\bibitem[\protect\BCAY{佐藤\JBA 藤本\JBA 小谷}{佐藤 \Jetal }{2010}]{佐藤}
佐藤直人\JBA 藤本浩司\JBA 小谷善行 \BBOP 2010\BBCP.
\newblock ウェブ上の商品情報を利用した商品のカテゴリ分類.\
\newblock \Jem{人工知能学会 第87回知識ベースシステム研究会}, \mbox{\BPGS\
  7--10}.

\bibitem[\protect\BCAY{Siolas \BBA\ d'Alch\'{e}{-}Buc}{Siolas \BBA\
  d'Alch\'{e}{-}Buc}{2000}]{Siolas}
Siolas, G.\BBACOMMA\ \BBA\ d'Alch\'{e}{-}Buc, F. \BBOP 2000\BBCP.
\newblock \BBOQ Support Vector Machines based on a Semantic Kernel for Text
  Categorization.\BBCQ\
\newblock In {\Bem Proceedings of the nternational Joint conference on Neural
  Networks}, \mbox{\BPGS\ 205--209}.

\bibitem[\protect\BCAY{高村\JBA {Roth, D.}}{高村\JBA {Roth, D.}}{2007}]{高村}
高村大也\JBA {Roth, D.} \BBOP 2007\BBCP.
\newblock Predictive Naive Bayes Classifierの提案と言語処理への適用.\
\newblock \Jem{言語処理学会第13回年次大会発表論文集}, \mbox{\BPGS\ 546--549}.

\bibitem[\protect\BCAY{Zhang}{Zhang}{2004}]{Zhang}
Zhang, H. \BBOP 2004\BBCP.
\newblock \BBOQ The Optimality of Naive Bayes.\BBCQ\
\newblock In {\Bem Proceedings of the the 17th International FLAIRS conference
  (FLAIRS2004)}, \mbox{\BPGS\ 562--567}.

\end{thebibliography}

\begin{biography}
\bioauthor{古宮嘉那子}{
2005年東京農工大学工学部情報コミュニケーション工学科卒．2009年同大大学院
博士後期課程電子情報工学専攻修了．博士（工学）．同年東京工業大学精密工学研究所研究員，
2010年東京農工大学工学研究院特任助教，現在に至る．自然言語処理の研究に従事．
情報処理学会，人工知能学会，言語処理学会各会員．
}
\bioauthor{伊藤　裕佑}{
2012年東京農工大学工学部情報工学科卒．在学中に自然言語処理の研究に従事．
}
\bioauthor{佐藤　直人}{
2009年東京農工大学工学部情報工学科卒．2011年同大大学院
博士前期課程情報工学科修了．在学中にゲーム研究と自然言語処理の研究に従事．
}
\bioauthor{小谷　善行}{
東京農工大学大学院教授．工学研究院先端情報科学部門・情報工学科．人工知能，知識処理，ゲームシステム，
ソフトウェア工学，教育工学の研究に従事．情報処理学会，電子情報通信学会，人工知能学会等会員．コンピュータ将棋協会副会長．
最近では，多量データからの知識獲得に興味を持っている．
}

\end{biography}


\biodate

