オークションのカテゴリ分類実験の結果とニュースグループの分類実験の結果を総合してNNBの特色について考察する．
まず，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}〜\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，全ての実験を通して，NNBはNBとCNBを上回っていること，また[MATH]なしのCNBに有意に勝っていることはあっても有意に負けていることはないことが読みとれる．
このことから，NNBは他のBayesの定理を利用した文書分類手法に比較しても引けを取らない文書分類手法であると言える．
特にNBと比較したときには，マイクロ平均では常に有意に，マクロ平均ではオークションのカテゴリ実験において「デスクトップ」と「記念切手」の全品詞を使った分類実験以外の実験で有意に勝っていた．
なお，マクロ平均ではサンプル数の減少から，NNBと比較した際，SVMとNBだけにしか有意差が認められなかったため，今後は主にマイクロ平均について考察する．
オークションのカテゴリ分類実験とニュースグループの分類実験の実験設定の違いのうち，NNBの式に大きく関わりそうな点は二点あるだろう．
一つ目は第一項の事前確率に関わる，クラスごとの文書数（またはカテゴリごとの商品数）のばらつき，二つ目はそれ以外の部分に関わる，一文書ごとの単語トークン数である．
[REF_Sec:ニュースグループの文書分類の実験]節でも述べたように，CNBとNNBの式，式([REF_eq:cnb])と式([REF_eq:nnb2])を比較してみると，事前確率[MATH]と[MATH]の部分が異なっており，残りの[MATH]については等しい．
NNBは事前確率を数学的に正しく考慮しているため，文書分類ではクラスごとの文書数が不均一である際に効果を発揮すると考えられる．
また，単語数が少ない文書を分類する際には，単語数が多い文書を分類する際よりも，相対的に事前確率の影響が大きくなることが予想される．
クラスごとの文書数のばらつきを見るために，\figref{Fig:標準偏差／平均}に同実験においてクラスごとの文書数を不均一にした実験の，クラスごとの文書数の標準偏差／平均を横軸とした分類正解率の散布図を示す．
また，単語トークン数の影響を見るために，\figref{Fig:1文書ごとに平均した単語数}にニュースグループの分類実験において一文書あたりの単語数を減らした実験の，一文書あたりの単語トークン数を横軸とした分類正解率の散布図を示す．
その上でNNBの特徴をNB，CNB（[MATH]のないものを含む），SVMの順で比較しつつ考察する．
\figref{Fig:標準偏差／平均}から，NBはクラスごとの文書数のばらつきが多い際にその分類正解率が著しく低下することが分かる．
また，商品のカテゴリ分類実験において，NBの分類正解率がとても低いのも同じ原因によるものであることがうかがえる．
商品のカテゴリ分類実験において，標準偏差／平均は「デスクトップ」，「記念切手」，「赤ちゃん用の玩具」がそれぞれ1.44，2.84，1.33と高く，カテゴリごとの商品数のばらつきが大きいからである．
この原因として，クラスごとの[MATH]のデータスパースネスの差が考えられる．
ここでNBの式を再掲する．
NBではクラスごとの文書数のばらつきが大きい際には，クラスによって訓練事例の単語トークン数に大きな差ができる．
例えば最も大きなクラスでは，その訓練事例となるトークン数が一万となり，小さなクラスでは10トークンといった具合である．
その結果，小さなクラスではデータがスパースになり，より頻繁にスムージングが行われる．
そのため，NBでは，個々の分類問題と相性の良いスムージング手法を用いることが求められるが，今回のジェフリー・パークス法はラプラス法よりは良いとはいえ，まだ実際よりも大きな値を小さなクラスに与えていたと思われる．
このように，NBではデータスパースネスによって誤分類が起きて分類正解率が著しく下がることがあるが，この問題を補集合を用いることで解決したのがCNBであり，この点についてNNBはCNBと全く同じ特色を持っている．
次に，NNBとCNBの差について考察する．
\figref{Fig:標準偏差／平均}を見てみると，[MATH]を考慮しないCNBとNNBの差はあまりないが，NNBはCNBより若干良いことが分かる．
これは，クラスごとの文書数に偏りが出てくると，CNBとNNBの違いである事前確率が異なってくるため，その分類正解率に差がつくからであると考えられる．
次に\figref{Fig:1文書ごとに平均した単語数}を見てみると，一文書当たりの平均の単語数が減ると，どの手法を用いても全体的に分類正解率が低下することが分かる．
これは，単語数が減ることで，統計の材料となる[MATH]が減っているためであると考えられる．
これに対し，一文書当たりの単語数を変化させても，CNBとNNBの差が大きくなることはなかった．
これは，ニュースグループのオリジナルのコーパスでは，そもそもクラスごとの文書数に偏りがあまり見られないため，事前確率に偏りがなく，CNBとNNBがそう違わない結果になったためであると考えられる．
ここで，オークションのカテゴリ分類実験の実験設定も共に比較してみる．
\figref{Fig:CNBとNNB}に縦軸を標準偏差／平均，横軸をクラスごとの単語数にした，実験設定ごとのCNBとNNBの差の散布図を示す．
左の図が事前確率を考慮したCNBとNNBの差が有意であるかを表しており，右の図が事前確率を考慮しないCNBとNNBの差が有意であるかを表している．
なお，両方の図において，縦軸の値が0.10である五つの点が，ニュースグループの一文書当たりの単語数を減らした一連の実験であり，横軸の値が128.71である五つの点が，ニュースグループのクラスごとの文書数を不均一にした一連の実験である．
オークションのカテゴリ分類実験の実験設定では，ニュースグループの実験よりも，ひとつの文書（商品）ごとのトークン数が少なく（一文書当たりの単語数を最も減らした実験と同じくらいである），なおかつクラス（カテゴリ）ごとの文書数（商品数）の偏りが，クラスごとの文書数を不均一にしたニュースグループの実験と同じくらい，またはそれ以上に偏っていることが分かる．
\figref{Fig:CNBとNNB}により，標準偏差／平均が小さい時にはCNBとNNBの差はほとんどないこと，また，標準偏差／平均が大きくなるにつれてNNBが有意にCNBを上回るようになる傾向がうかがえる．
また，一文書あたりの単語数が少ない時に，なおかつ標準偏差／平均が大きければ，NNBが有意に事前確率を考慮しないCNBに対しても有意に上回ることが分かる．
オークションのカテゴリ分類実験の「記念切手」（左上の二点）のときには，両方の条件が共に十分当てはまったため，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回ったものと思われる．
次に，SVMとの比較を行う．
残念ながら，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回った「記念切手」の実験設定を含む，オークションのカテゴリ分類実験では，SVMの分類正解率がいつも他手法を有意に上回った．
しかし，ニュースグループの文書分類実験では，一文書あたりの文書数を減らした場合のパラメータが3と4の実験を除き，NNBがSVMを有意に上回った．
上述したように，[MATH]の数が減ってしまうと，Bayesianアプローチの正解率は下がることが一文書当たりの単語数が減った際にSVMを有利にしたと考えられる．
しかし，ニュースグループのオリジナルのコーパスの実験では，CNBとの差は有意ではないながらも，NNBが全ての分類器の中で最も高い分類正解率となっている．
このことから，NNBは時にはSVMを有意に上回り，他手法と比較しても最も良い分類正解率を示しうる手法であることが分かる．
また，最後に，提案手法の速度についての目安を知るために，最も実行時間がかかるオリジナルのニュースグループの分類実験において，それぞれの手法の実行時間を測った．
\tabref{Tab:ニュースグループの分類実験にかかった時間}にその結果を示す．
SVMはC言語により実装されたツールによるものであり，それ以外のBayesianアプローチはPerlにより個人的に実装したものであるため，一概に比較は難しいが，NNBがCNBとほぼ同じ速度で実行されることが分かる．
本稿では，文書分類のための新手法として，Negation Naive Bayes (NNB)を提案し，その性質を他のBayesianアプローチであるNaive Bayes (NB)，Complement Naive Bayes (CNB)と比較した．
NNBは，CNBと同様にクラスの補集合を用いるが，NBと同じ事後確率最大化の式から導出されるため，事前確率を数学的に正しく考慮している点で異なっている．
NNBの性質を見るために，ふたつのコーパスを用いた実験を行った．
一つ目はオークションの商品分類の実験であり，二つ目はニュースグループの文書分類の実験である．
このうち，ニュースグループの文書分類の実験では，一文書あたりの単語数を減らした実験と，クラスごとの文書数を不均一にした実験を行い，オリジナルの文書集合の実験に加え，それぞれパラメータを変えて四通りを試した．
その結果，すべての実験においてNNBとCNBがNBの分類性能を上回ること，また，一文書当たりの単語数が減り，クラスごとの文書数が偏るときにマイクロ平均でNNBはCNBを上回ることが分かった．
事前確率を無視したCNBと比較しても，これらの条件が共に当てはまる際には，NNBがCNBを有意に上回った．
これは，CNBとNNBの違いは事前確率にあるため，クラスごとの文書数が偏るときにその影響が見られ，なおかつ一文書当たりの単語数が減る際には相対的に事前確率の影響が大きくなるためであると考えられる．
また，CNBまたは事前確率を無視したCNBがNNBを有意に上回ることはなかった．
さらに，ニュースグループの分類実験においては，その際のCNBとの差は微小ながら，参考として比較したサポートベクターマシン(SVM)をカイ二乗検定で有意に上回り，比較手法中で最も良い分類正解率を示す結果も見られた．
これらのことから，特に一文書当たりの単語数が減り，クラスごとの文書数が偏る場合において，NNBが他のBayesianアプローチより勝る手法であること，また，時にはSVMを有意に上回り，比較手法中で最も良い分類正解率を示す手法であることが分かった．
オークションのカテゴリ分類実験の結果とニュースグループの分類実験の結果を総合してNNBの特色について考察する．
まず，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}〜\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，全ての実験を通して，NNBはNBとCNBを上回っていること，また[MATH]なしのCNBに有意に勝っていることはあっても有意に負けていることはないことが読みとれる．
このことから，NNBは他のBayesの定理を利用した文書分類手法に比較しても引けを取らない文書分類手法であると言える．
特にNBと比較したときには，マイクロ平均では常に有意に，マクロ平均ではオークションのカテゴリ実験において「デスクトップ」と「記念切手」の全品詞を使った分類実験以外の実験で有意に勝っていた．
なお，マクロ平均ではサンプル数の減少から，NNBと比較した際，SVMとNBだけにしか有意差が認められなかったため，今後は主にマイクロ平均について考察する．
オークションのカテゴリ分類実験とニュースグループの分類実験の実験設定の違いのうち，NNBの式に大きく関わりそうな点は二点あるだろう．
一つ目は第一項の事前確率に関わる，クラスごとの文書数（またはカテゴリごとの商品数）のばらつき，二つ目はそれ以外の部分に関わる，一文書ごとの単語トークン数である．
[REF_Sec:ニュースグループの文書分類の実験]節でも述べたように，CNBとNNBの式，式([REF_eq:cnb])と式([REF_eq:nnb2])を比較してみると，事前確率[MATH]と[MATH]の部分が異なっており，残りの[MATH]については等しい．
NNBは事前確率を数学的に正しく考慮しているため，文書分類ではクラスごとの文書数が不均一である際に効果を発揮すると考えられる．
また，単語数が少ない文書を分類する際には，単語数が多い文書を分類する際よりも，相対的に事前確率の影響が大きくなることが予想される．
クラスごとの文書数のばらつきを見るために，\figref{Fig:標準偏差／平均}に同実験においてクラスごとの文書数を不均一にした実験の，クラスごとの文書数の標準偏差／平均を横軸とした分類正解率の散布図を示す．
また，単語トークン数の影響を見るために，\figref{Fig:1文書ごとに平均した単語数}にニュースグループの分類実験において一文書あたりの単語数を減らした実験の，一文書あたりの単語トークン数を横軸とした分類正解率の散布図を示す．
その上でNNBの特徴をNB，CNB（[MATH]のないものを含む），SVMの順で比較しつつ考察する．
\figref{Fig:標準偏差／平均}から，NBはクラスごとの文書数のばらつきが多い際にその分類正解率が著しく低下することが分かる．
また，商品のカテゴリ分類実験において，NBの分類正解率がとても低いのも同じ原因によるものであることがうかがえる．
商品のカテゴリ分類実験において，標準偏差／平均は「デスクトップ」，「記念切手」，「赤ちゃん用の玩具」がそれぞれ1.44，2.84，1.33と高く，カテゴリごとの商品数のばらつきが大きいからである．
この原因として，クラスごとの[MATH]のデータスパースネスの差が考えられる．
ここでNBの式を再掲する．
NBではクラスごとの文書数のばらつきが大きい際には，クラスによって訓練事例の単語トークン数に大きな差ができる．
例えば最も大きなクラスでは，その訓練事例となるトークン数が一万となり，小さなクラスでは10トークンといった具合である．
その結果，小さなクラスではデータがスパースになり，より頻繁にスムージングが行われる．
そのため，NBでは，個々の分類問題と相性の良いスムージング手法を用いることが求められるが，今回のジェフリー・パークス法はラプラス法よりは良いとはいえ，まだ実際よりも大きな値を小さなクラスに与えていたと思われる．
このように，NBではデータスパースネスによって誤分類が起きて分類正解率が著しく下がることがあるが，この問題を補集合を用いることで解決したのがCNBであり，この点についてNNBはCNBと全く同じ特色を持っている．
次に，NNBとCNBの差について考察する．
\figref{Fig:標準偏差／平均}を見てみると，[MATH]を考慮しないCNBとNNBの差はあまりないが，NNBはCNBより若干良いことが分かる．
これは，クラスごとの文書数に偏りが出てくると，CNBとNNBの違いである事前確率が異なってくるため，その分類正解率に差がつくからであると考えられる．
次に\figref{Fig:1文書ごとに平均した単語数}を見てみると，一文書当たりの平均の単語数が減ると，どの手法を用いても全体的に分類正解率が低下することが分かる．
これは，単語数が減ることで，統計の材料となる[MATH]が減っているためであると考えられる．
これに対し，一文書当たりの単語数を変化させても，CNBとNNBの差が大きくなることはなかった．
これは，ニュースグループのオリジナルのコーパスでは，そもそもクラスごとの文書数に偏りがあまり見られないため，事前確率に偏りがなく，CNBとNNBがそう違わない結果になったためであると考えられる．
ここで，オークションのカテゴリ分類実験の実験設定も共に比較してみる．
\figref{Fig:CNBとNNB}に縦軸を標準偏差／平均，横軸をクラスごとの単語数にした，実験設定ごとのCNBとNNBの差の散布図を示す．
左の図が事前確率を考慮したCNBとNNBの差が有意であるかを表しており，右の図が事前確率を考慮しないCNBとNNBの差が有意であるかを表している．
なお，両方の図において，縦軸の値が0.10である五つの点が，ニュースグループの一文書当たりの単語数を減らした一連の実験であり，横軸の値が128.71である五つの点が，ニュースグループのクラスごとの文書数を不均一にした一連の実験である．
オークションのカテゴリ分類実験の実験設定では，ニュースグループの実験よりも，ひとつの文書（商品）ごとのトークン数が少なく（一文書当たりの単語数を最も減らした実験と同じくらいである），なおかつクラス（カテゴリ）ごとの文書数（商品数）の偏りが，クラスごとの文書数を不均一にしたニュースグループの実験と同じくらい，またはそれ以上に偏っていることが分かる．
\figref{Fig:CNBとNNB}により，標準偏差／平均が小さい時にはCNBとNNBの差はほとんどないこと，また，標準偏差／平均が大きくなるにつれてNNBが有意にCNBを上回るようになる傾向がうかがえる．
また，一文書あたりの単語数が少ない時に，なおかつ標準偏差／平均が大きければ，NNBが有意に事前確率を考慮しないCNBに対しても有意に上回ることが分かる．
オークションのカテゴリ分類実験の「記念切手」（左上の二点）のときには，両方の条件が共に十分当てはまったため，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回ったものと思われる．
次に，SVMとの比較を行う．
残念ながら，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回った「記念切手」の実験設定を含む，オークションのカテゴリ分類実験では，SVMの分類正解率がいつも他手法を有意に上回った．
しかし，ニュースグループの文書分類実験では，一文書あたりの文書数を減らした場合のパラメータが3と4の実験を除き，NNBがSVMを有意に上回った．
上述したように，[MATH]の数が減ってしまうと，Bayesianアプローチの正解率は下がることが一文書当たりの単語数が減った際にSVMを有利にしたと考えられる．
しかし，ニュースグループのオリジナルのコーパスの実験では，CNBとの差は有意ではないながらも，NNBが全ての分類器の中で最も高い分類正解率となっている．
このことから，NNBは時にはSVMを有意に上回り，他手法と比較しても最も良い分類正解率を示しうる手法であることが分かる．
また，最後に，提案手法の速度についての目安を知るために，最も実行時間がかかるオリジナルのニュースグループの分類実験において，それぞれの手法の実行時間を測った．
\tabref{Tab:ニュースグループの分類実験にかかった時間}にその結果を示す．
SVMはC言語により実装されたツールによるものであり，それ以外のBayesianアプローチはPerlにより個人的に実装したものであるため，一概に比較は難しいが，NNBがCNBとほぼ同じ速度で実行されることが分かる．
本稿では，文書分類のための新手法として，Negation Naive Bayes (NNB)を提案し，その性質を他のBayesianアプローチであるNaive Bayes (NB)，Complement Naive Bayes (CNB)と比較した．
NNBは，CNBと同様にクラスの補集合を用いるが，NBと同じ事後確率最大化の式から導出されるため，事前確率を数学的に正しく考慮している点で異なっている．
NNBの性質を見るために，ふたつのコーパスを用いた実験を行った．
一つ目はオークションの商品分類の実験であり，二つ目はニュースグループの文書分類の実験である．
このうち，ニュースグループの文書分類の実験では，一文書あたりの単語数を減らした実験と，クラスごとの文書数を不均一にした実験を行い，オリジナルの文書集合の実験に加え，それぞれパラメータを変えて四通りを試した．
その結果，すべての実験においてNNBとCNBがNBの分類性能を上回ること，また，一文書当たりの単語数が減り，クラスごとの文書数が偏るときにマイクロ平均でNNBはCNBを上回ることが分かった．
事前確率を無視したCNBと比較しても，これらの条件が共に当てはまる際には，NNBがCNBを有意に上回った．
これは，CNBとNNBの違いは事前確率にあるため，クラスごとの文書数が偏るときにその影響が見られ，なおかつ一文書当たりの単語数が減る際には相対的に事前確率の影響が大きくなるためであると考えられる．
また，CNBまたは事前確率を無視したCNBがNNBを有意に上回ることはなかった．
さらに，ニュースグループの分類実験においては，その際のCNBとの差は微小ながら，参考として比較したサポートベクターマシン(SVM)をカイ二乗検定で有意に上回り，比較手法中で最も良い分類正解率を示す結果も見られた．
これらのことから，特に一文書当たりの単語数が減り，クラスごとの文書数が偏る場合において，NNBが他のBayesianアプローチより勝る手法であること，また，時にはSVMを有意に上回り，比較手法中で最も良い分類正解率を示す手法であることが分かった．
