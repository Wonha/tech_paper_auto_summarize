================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.75425] NNBは，クラスの補集合を用いるという点ではComplement Naive Bayes (CNB)と等しいが，Naive Bayes (NB)と同じ事後確率最大化の式から導出されるため，事前確率を数学的に正しく考慮している点で異なっている．
[i:3, score:0.65724] ニュースグループの文書分類では，一文書あたりの単語数（トークン数）を減らした実験と，クラスごとの文書数を不均一にした実験を行い，NNBの性質を考察した．
[i:4, score:0.79907] NB，CNB，サポートベクターマシン(SVM)と比較したところ，特に一文書当たりの単語数が減り，クラスごとの文書数が偏る場合において，NNBが他のBayesianアプローチより勝る手法であること，また，時にはSVMを有意に上回り，比較手法中で最も良い分類正解率を示す手法であることが分かった．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:7, score:0.59669] そのため，[CITE]は「クラスに属する文書」ではなく「クラスに属さない文書」，つまり「補集合」を用いることによりNBの欠点を緩和したComplement Naive Bayes (CNB)を提唱した．
[i:8, score:0.43438] しかし，CNBはNBと同じ式，つまり事後確率最大化の式から導くことができない．
[i:10, score:0.72205] その結果，クラスごとの単語数（トークン数）が少なく，なおかつクラス間の文書数に大きなばらつきがある場合には分類正解率がNB，CNBをカイ二乗検定で有意に上回ること，また，これらの条件が特に十分に当てはまる場合には，事前確率を無視したCNBも同検定で有意に上回ることを示す．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:23, score:0.41054] NBを発展させた研究として，補集合を用いて学習を行うCNBが有名である[CITE]．
[i:24, score:0.54656] CNBは，「クラスに属する文書」ではなく「クラスに属さない文書」，つまり「補集合」を用いることによりNBの欠点を緩和した手法である．
[i:25, score:0.64279] 本研究では，多項モデルを用いたNBとCNBに注目し，その分類における特徴を考慮して，Bayesのアプローチを用いた新しい分類手法NNBを提案する．

================================================================
[section type  : proposed_method]
[section title : Negation Naive Bayesの導出]
================================================================
[i:26, score:0.70677] NNBはCNBと同様に補集合を利用して文書分類を行うが，CNBと異なってNBと同じ事後確率最大化の式から導出が可能である．
[i:27, score:0.27168] その結果，事前確率を数学的に正しく考慮することで，クラスごとの文書数が異なっているときにもより正確な文書分類を行えるようにした．
[i:28, score:0.60140] 本節ではNBの導出と，CNBの概念について触れた後，提案手法であるNNBの導出について述べる．
-----------------------------------------------------
  [subsection title : Naive Bayes分類器]
-----------------------------------------------------
  [i:lead, score:0.23359] 一般に確率モデルによる文書分類では，分類対象となる文書を[MATH]，ある一つのクラスを[MATH]としたとき，事後確率[MATH]を最大化するクラス[MATH]を求める[CITE]．
.....
  [i:29, score:0.23359] 一般に確率モデルによる文書分類では，分類対象となる文書を[MATH]，ある一つのクラスを[MATH]としたとき，事後確率[MATH]を最大化するクラス[MATH]を求める[CITE]．
  [i:30, score:0.29625] NB分類器を用いた文書分類では，事後確率にBayesの定理を適用する．
  [i:31, score:0.22110] 文書の取り出される確率[MATH]はすべてのクラスについて一定であることを考慮すると，事後確率が最大のクラスを推定することは，クラスの出現確率[MATH]と各クラスでの文書の出現確率[MATH]の積を最大化するクラスを推定することと等しくなる．
-----------------------------------------------------
  [subsection title : Complement Naive Bayes分類器]
-----------------------------------------------------
  [i:lead, score:0.33195] 多項モデルを用いたNB分類器では，クラス間の文書数に大きなばらつきがある場合に，文書数の小さいクラスで[MATH]が大きくなる傾向がある．
.....
  [i:43, score:0.48539] 図[REF_Fig:コンプ文書数変化]は，NBとCNBでの学習に用いる文書数の違いを表している．
  [i:46, score:0.54134] 一方，CNBでは自身のクラスに属する文書以外の文書から学習を行うため，学習に用いる文書数は最小のもので40，最大のもので70となり，NBに比べてばらつきが小さくなる．
  [i:47, score:0.55185] CNBは，文書内にある単語の出現確率の積から尤度を計算し，分類するクラスを決めるという点ではNBと同じである．
-----------------------------------------------------
  [subsection title : Negation Naive Bayes分類器]
-----------------------------------------------------
  [i:lead, score:0.55678] 前節で説明したCNBは，NBの持つ「クラス間の文書数のばらつきによって分類結果が偏る」という特徴を緩和する手法である．
.....
  [i:51, score:0.55678] 前節で説明したCNBは，NBの持つ「クラス間の文書数のばらつきによって分類結果が偏る」という特徴を緩和する手法である．
  [i:53, score:0.46859] そこで本研究では，事後確率最大化の式から導出でき，かつ，CNBの「訓練にクラスの補集合を利用する」という長所をもつ分類器を作成する．
  [i:65, score:0.38228] また，Rennieらの研究では，[MATH]は[MATH]に比べて分類結果への影響が小さいと判断し，事前確率は計算してもしなくても結果は同じと考え，実際の分類には[MATH]を無視して[MATH]のみを計算しているため，P(c)なしのCNBについても参考として実験を行う．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[i:67, score:0.39577] 一つ目はオークションの商品分類の実験であり，二つ目はニュースグループの文書分類の実験である．
[i:68, score:0.66908] これらの二つの実験において，形態素解析により得た表層形のbag-of-wordsを用いてNB，CNB，NNBの文書分類の性能を比較した．
[i:69, score:0.58392] また，NBBとCNBの差は事前確率[MATH]と[MATH]の部分であるため，CNBとNNBから第一項を省略した形の式（[MATH]なしのCNB）でも実験を行った．
-----------------------------------------------------
  [subsection title : オークションの商品分類の実験]
-----------------------------------------------------
  [i:lead, score:0.32953] オークションの商品分類の実験は，Yahoo!オークションの商品タイトルを商品カテゴリに分類する実験である．
.....
  [i:93, score:0.48688] また，\figref{Fig:pc}，\figref{Fig:stamp}，\figref{Fig:toy}にそれぞれ「デスクトップ」，「記念切手」，「赤ちゃん用の玩具」のカテゴリごとの文書数，単語トークン数，名詞のトークン数を折れ線グラフにしたものを示す．
  [i:97, score:0.55610] また，\tabref{Tab:オークションのカテゴリ分類実験のデータ}にオークションのカテゴリ分類実験の訓練事例中の商品数の標準偏差，訓練事例中の文書数の標準偏差を訓練事例中の総文書数の平均で割った値（以降，標準偏差／平均と表記），トークン数，1商品当たりの平均単語数を示す．
  [i:101, score:0.61148] \tabref{Tab:オークションのカテゴリ分類実験のデータ}のこの「訓練事例中の商品数の標準偏差／平均」を見てみると，「記念切手」の値が「デスクトップ」や「赤ちゃん用の玩具」より高いことから，\figref{Fig:pc}〜\figref{Fig:toy}から読みとったように，「記念切手」が最も偏っていることが読みとれる．
-----------------------------------------------------
  [subsection title : ニュースグループの文書分類の実験]
-----------------------------------------------------
  [i:lead, score:0.18401] ニュースグループの文書分類の実験のコーパスには20 Newsgroupsを利用した．
.....
  [i:104, score:0.59862] CNBとNNBの式，式([REF_eq:cnb])と式([REF_eq:nnb2])を比較してみると，事前確率[MATH]と[MATH]の部分が異なっていることが分かる．
  [i:120, score:0.66110] また，\tabref{Tab:一文書あたりの単語数を減らした実験のデータ}にニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の訓練事例中の総文書数，文書数の標準偏差，標準偏差／平均，単語トークン数，1文書当たりの平均の単語トークン数を示す．
  [i:121, score:0.62401] また，ニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の訓練事例中の総文書数，文書数の標準偏差，標準偏差／平均，単語トークン数，1文書当たりの平均の単語トークン数を\tabref{Tab:クラスごとの文書数を不均一にした実験のデータ}に示す．

================================================================
[section type  : proposed_method]
[section title : 結果]
================================================================
[i:129, score:0.85023] \tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率}から，オークションのカテゴリ分類実験において，マイクロ平均を比較した際，NNBが常にNBとCNBを有意に上回っていることが分かる．
[i:133, score:0.85421] また，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}から，オークションのカテゴリ分類実験において，マクロ平均においても，有意ではないながら，NNBが常にNBとCNBを上回っていることが分かる．
[i:143, score:0.87751] これに対し，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，ニュースグループの分類実験において，マクロ平均においても，NNBが常にNBとCNBを上回っていることが分かる．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[i:150, score:0.90904] まず，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}〜\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，全ての実験を通して，NNBはNBとCNBを上回っていること，また[MATH]なしのCNBに有意に勝っていることはあっても有意に負けていることはないことが読みとれる．
[i:186, score:0.78983] オークションのカテゴリ分類実験の「記念切手」（左上の二点）のときには，両方の条件が共に十分当てはまったため，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回ったものと思われる．
[i:188, score:0.79823] 残念ながら，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回った「記念切手」の実験設定を含む，オークションのカテゴリ分類実験では，SVMの分類正解率がいつも他手法を有意に上回った．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[i:196, score:0.71504] 本稿では，文書分類のための新手法として，Negation Naive Bayes (NNB)を提案し，その性質を他のBayesianアプローチであるNaive Bayes (NB)，Complement Naive Bayes (CNB)と比較した．
[i:197, score:0.71794] NNBは，CNBと同様にクラスの補集合を用いるが，NBと同じ事後確率最大化の式から導出されるため，事前確率を数学的に正しく考慮している点で異なっている．
[i:201, score:0.76414] その結果，すべての実験においてNNBとCNBがNBの分類性能を上回ること，また，一文書当たりの単語数が減り，クラスごとの文書数が偏るときにマイクロ平均でNNBはCNBを上回ることが分かった．

