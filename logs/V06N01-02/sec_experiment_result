実験用データはすでに品詞のタグづけされたタイ語コーパスから得られた10,452の文であった.
それを無作為に8,322文と2,130文に分けてそれぞれ訓練とテストに使った.
訓練文においては22,311個の単語が複数の品詞を持ち,テスト文においては6,717個の単語が複数の品詞を持ちえた.
タイ語には47種類の品詞が定義されているため,式(6), (10), (18)の中の[MATH]は47となる.
マルチニューロタガーは五つの（入力に用いられる左右の単語の数がそれぞれ[MATH]の）シングルニューロタガーSNT[MATH]から構成された.
個々のタガーSNT[MATH]は入力長さ[MATH]（[MATH]）で入力層[MATH]中間層[MATH]出力層に[MATH]個のユニットを持つ三層パーセプトロンであった.
但し, [MATH]である.
SNT[MATH]の出力の閾値[MATH][式(29)]は0.5に設定された.
また,重みの更新量を決める学習率[MATH]と慣性率[MATH][式(26)]はそれぞれ0.1と0.9に,訓練を止める基準である目標誤差[MATH][式(28)]は0.005に設定された.
訓練セットから得られた各入力部分の重み[式(5)]は([MATH], [MATH], [MATH], [MATH], [MATH], [MATH], [MATH]) = (0.575, 0.524, 0.749, 2.667, 0.801, 0.575, 0.649)であった.
表２はテストデータへの品詞タグづけ結果を示す.
マルチニューロタガーはIGの有無とは関係なく,その正解率はどのシングルニューロタガーのそれよりも高かった.
従って,マルチニューロタガーを用いることによって,文脈の長さを事前に経験的に選ぶ必要がなく,いつも状況に応じて適切な長さの文脈を自動的に選んでいると言える.
IGを用いる場合,タグづけの正解率は短い文脈を用いた場合では下がり,長い文脈（入力長さが5以上）を用いた場合では上がった.
この表は更にシングルニューロタガーだけを用いてもかなり高い正解率でタグづけすることができることを示した.
実際, [CITE]によれば,英語タガーを10,000オーダーのデータを用いて訓練させた場合,タグづけの正解率は僅か85%程度であった.
両者の違いはそもそもタイ語のタグづけ問題が英語のそれより容易であることにあるかもしれない.
しかしながら,少なくとも訓練そのものに関してはタイ語のほうが英語より難しいと考えられる.
なぜならば,英語の場合は線形分離可能な問題しか解決できない二層パーセプトロンでタグづけ問題を学習できたのに対し,タイ語の場合は三層以上でなければ学習が正しくできなかった.
表２テストデータへの品詞タグづけ結果
一般的に,訓練データの数が十分でない場合,タグづけの正解率は用いる文脈が長くなるにつれて確定的な答えが少なくなるために落ちていく.
しかしながら,本実験ではこのような現象が現れなかった.
その理由は新しい訓練方法,即ち,長い入力のタガーの訓練は短いタガーの訓練結果に依存すること,にあると考えられる.
これを確かめるために, [MATH]でIGなしのシングルニューロタガーSNT[MATH]を改めて前の結果を利用せずに訓練し直した.
その結果, SNT[MATH]のタグづけの正解率は91.1%まで下がった.
これは短い入力のシングルニューロタガーSNT[MATH]（[MATH]）のいずれよりも低い数字であった.
図４SNT[MATH]の異なる条件での訓練曲線
図４は異なる条件でのSNT[MATH]の訓練曲線を示す.
太い実線,細い実線,そして点線はそれぞれSNT[MATH]の訓練結果を利用した場合, SNT[MATH]の訓練結果を利用しない場合,そしてSNT[MATH]の訓練結果を利用せず, IGも用いない場合である.
この図は,訓練時間の大幅な短縮には前の訓練結果の利用だけでなくIGの利用も効果的であることを示している.
