0	一つ一つ 単語 しばしば 複数 品詞 品詞 曖昧性 持ち 得る 
0	単語 一旦 文 組み込ま れ 持ち 得る 品詞 前後 品詞 唯一 決まる 場合 多い 
0	品詞 タグ づけ よう 曖昧性 文脈 用いる こと 除去 する こと 
0	品詞タグ づけ 研究 特に 英語 日本語 多数 行なわ れ き 
0	これら 研究 通じ これ 主 四つ アプローチ ルールベース ものCITEHMM ngram 用い 確率モデル 基づい ものCITEメモリベース ものCITE ニューラルネット 用い ものCITE 提案 さ れ 
0	これら 研究 大量 訓練データ CITE 1000000個 データ 用いれ いずれ 手法 用い 訓練データ タグ づけ 95以上 正解率 行 なえる こと 示し 
0	実際 英語 日本語 除い 数多く 言語 本稿 取り上げ タイ語 コーパス自体 まだ 整備段階 ある の 現状 予め 大量 訓練データ 得る の 困難 
0	これら 言語 如何 少ない 訓練データ 十分実用的 高い 正解率 品詞タグ づけ システム 構築 する 重要 課題 なる 
0	これ 提案 さ れ 確率モデル ニューラルネットモデル ほとんど タグ づけ 長 さ 固定 文脈 用いる もの HMMモデル 状態遷移 定義 する の 固定 さ れ ngramベース モデル 用いる 入力 構成部分 同一 影響度 持つ もの さ れ い 
0	訓練データ 少ない 場合タグ づけ 結果 確信度 高める ため まず できるだけ 長い 文脈 用い 訓練データ 不足 確定的 答え 出 場合 順次 文脈 短く する よう フレキシブル タグ づけ する こと 必要 さ れよ 
0	客観的 基準 入力 構成部分 品詞タグ づけ 影響度 計り 影響度 応じ 重み それぞれ 構成部分 与えれ より 望ましい 
0	シンプル 効果的 思わ れる 解決法 マルチモジュールモデル 導入 する こと 
0	マルチモジュールモデル 複数 それぞれ 異なっ 長 さ 文脈 入力 し モジュール それら 出力 選別 する セレクター 構成 さ れる システム こと 
0	よう システム 確率モデル メモリベースモデル 実現 しよ する それぞれ以下 述べる 不具合 生じる 
0	確率モデル 比較的 短い 文脈 用いる 場合 必要 さ れる パラメター 数 それほど 多く なら 
0	ここ 提案 し いる よう 複数 モジュール 場合 応じ 使い分ける よう システム ある程度 長 さ 文脈 用いる こと 必要 なり 確率モデル パラメター 数 膨大 なる 
0	品詞 50種類 ある 言語 左右最大三つ 単語 情報 文脈 タグ づけ 行なう 場合 最長文脈 入力 し ngramベース確率モデル サイズ MATH ngramテーブル 用意 し なら 
0	IGTree よう メモリベースモデルCITE 品詞タグ づけ 実際 用いる 特徴 数 ツリー 張る ノード特徴 範囲内 可変 特徴 タグ づけ 影響度 それら 選択 する 優先順位 反映 さ れる 
0	特徴 数 大きく 取っ 場合 手法 タグ づけ 計算コスト 非常 かかっ しまう ケース 生じる 
0	実際 Daelmansら モデルCITE ノード 数 僅か ４ 設定 さ れ おり 実質的 固定 長 さ 文脈 用い いる 見 よい 
0	本稿 複数 ニューラルネット 構成 さ れる マルチニューロタガー 提案 する 
0	品詞 タグ づけ 長 さ 固定 文脈 用いる の なく 最長文脈優先 フレキシブル 行なわ れる 
1	個々 ニューラルネット 訓練 それぞれ独立 行なわ れる の なく 短い 文脈 訓練結果訓練 獲得 し 重み 長い 文脈 訓練 初期値 使う 
1	結果訓練時間 大幅 短縮 でき 複数 ニューラルネット 用い 訓練時間 ほとんど 変わら 
1	タグ づけ 目標単語自身 影響 最も 強く 前後 単語 それぞれ 位置 応じ 影響度 持つ こと 反映 さ せる ため 入力 構成部分 情報量最大 考慮 し 訓練データ 得 られる インフォメーションゲイン 略し IG 呼ぶ 影響度 重み付け られる 結果訓練時間 更に 大幅 短縮 さ れ タグ づけ 性能 僅か 改善 さ れる 
1	計算機実験 結果マルチニューロタガー 8322文 小規模タイ語コーパス 訓練 用いる こと 訓練タイ語データ 94以上 正解率 タグ づけ する こと でき 
1	結果 固定 長 さ 文脈 入力 し シングルニューロタガー 用い 場合 優れ マルチニューロタガー タグ づけ 過程 動的 適切 長 さ 文脈 見つけ いる こと 示し 
