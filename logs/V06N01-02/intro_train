0	複数 一つ一つ 曖昧性 単語 しばしば 品詞 得る 持ち
0	単語 決まる 文 品詞 得る 組み込ま 持ち 前後 多い 一旦 れ 唯一 場合
0	曖昧性 用いる よう する づけ 除去 品詞 タグ こと 文脈
0	き 日本語 研究 英語 行なわ 多数 特に れ づけ 品詞タグ
0	ものCITEメモリベース ルールベース 研究 提案 用い ニューラルネット これら アプローチ 基づい ものCITEHMM 確率モデル 四つ ngram 主 通じ れ さ ものCITE これ
0	1000000個 研究 訓練データ 正解率 示し 行 これら 用い 95以上 手法 データ CITE タグ こと 大量 いずれ なえる 用いれ づけ
0	現状 大量 数多く 得る 実際 コーパス自体 まだ 取り上げ ある の タイ語 訓練データ 困難 予め 本稿 整備段階 日本語 言語 除い 英語
0	重要 システム なる する 品詞タグ づけ 訓練データ 如何 十分実用的 正解率 少ない 高い 課題 これら 構築 言語
0	構成部分 用いる 状態遷移 HMMモデル ngramベース 固定 の 提案 同一 ニューラルネットモデル モデル づけ する 持つ これ 入力 長 さ 影響度 れ もの 定義 文脈 ほとんど 確率モデル タグ い
0	文脈 必要 長い こと 短く できるだけ タグ 場合 づけ する 結果 フレキシブル 確信度 よう 高める さ 出 答え 場合タグ 訓練データ ため 確定的 順次 用い 少ない 不足 れよ まず
0	それぞれ より 望ましい づけ 品詞タグ 入力 影響度 計り 基準 与えれ 応じ 重み 構成部分 客観的
0	効果的 解決法 こと マルチモジュールモデル する 思わ 導入 シンプル れる
0	れる 異なっ それら 複数 構成 選別 し モジュール する セレクター システム 長 さ 入力 こと 文脈 それぞれ 出力 マルチモジュールモデル 
0	確率モデル 生じる メモリベースモデル 述べる よう システム する しよ 実現 不具合 それぞれ以下
0	れる 用いる それほど 比較的 パラメター なら 多く 場合 さ 数 文脈 必要 短い 確率モデル 
0	ある程度 さ システム 数 長 なる よう 場合 なり 確率モデル 必要 こと 文脈 膨大 使い分ける 複数 用いる ここ いる し 応じ モジュール 提案 パラメター
0	づけ 場合 用意 入力 ある サイズ 文脈 50種類 タグ 品詞 行なう 言語 MATH 左右最大三つ 最長文脈 ngramテーブル 情報 し なら 単語 ngramベース確率モデル
0	特徴 それら 範囲内 用いる れる 可変 張る IGTree メモリベースモデルCITE づけ する 品詞タグ よう 数 さ 影響度 ノード特徴 反映 選択 タグ 優先順位 実際 ツリー
0	手法 特徴 ケース かかっ しまう 場合 づけ 数 大きく 計算コスト 生じる 非常 取っ タグ
0	固定 ４ モデルCITE 僅か いる 用い ノード おり Daelmansら 文脈 見 実際 よい 設定 れ さ 長 数 実質的
0	マルチニューロタガー れる ニューラルネット 構成 複数 提案 本稿 する さ 
0	用いる れる 行なわ 固定 最長文脈優先 の 長 さ フレキシブル づけ 品詞 タグ なく 文脈
1	初期値 短い 長い なく 文脈 れる 行なわ 使う それぞれ独立 ニューラルネット 獲得 訓練 の 個々 訓練結果訓練 し 重み
1	短縮 ニューラルネット 用い 複数 ほとんど 大幅 でき 訓練時間 結果訓練時間 変わら
1	最も 短縮 応じ し 単語 考慮 性能 ため 訓練データ IG 強く れる 呼ぶ 僅か 構成部分 目標単語自身 せる インフォメーションゲイン こと 反映 それぞれ 改善 得 重み付け 位置 略し タグ 大幅 られる 情報量最大 づけ 結果訓練時間 れ 影響度 さ 更に 影響 持つ 入力 前後
1	する でき づけ 小規模タイ語コーパス こと 結果マルチニューロタガー タグ 用いる 8322文 94以上 計算機実験 訓練 正解率 訓練タイ語データ
1	過程 タグ こと 動的 文脈 長 さ 適切 入力 結果 場合 づけ し シングルニューロタガー 固定 示し 用い 優れ マルチニューロタガー いる 見つけ
