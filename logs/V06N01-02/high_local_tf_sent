================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[1929] タグづけにおいては,目標単語自身の影響が最も強く,前後の単語もそれぞれの位置に応じた影響を与えていることを反映させるために,入力の各構成部分は情報量最大を考慮して訓練データから得られるインフォメーションゲイン（略してIGと呼ぶ）を影響度として重み付けられる.

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[2085] タグづけにおいては,目標単語自身の影響が最も強く,前後の単語もそれぞれの位置に応じた影響度を持つことを反映させるために,入力の各構成部分は情報量最大を考慮して訓練データから得られるインフォメーションゲイン（略してIGと呼ぶ）を影響度として重み付けられる,その結果,訓練時間が更に大幅に短縮され,タグづけの性能も僅かながら改善される.

================================================================
[section type  : proposed_method]
[section title : 品詞タグづけ問題]
================================================================
[1719] 入力されるタイ語テキストは電子辞書を用いて単語に分割され,各単語の持ち得る品詞もリストアップされるため,品詞のタグづけ問題は以下に示すような文脈を用いた品詞の曖昧性除去あるいは一種のクラス分け問題と見なせる.

================================================================
[section type  : proposed_method]
[section title : インフォメーションゲイン（IG）]
================================================================
[1700] ここで,特徴を入力の構成部分,特徴の値をその構成部分の取りうる品詞,データの属するクラスを目標単語の取りうる品詞にそれぞれ置き換えてやれば,各構成部分のIGはその構成部分の品詞タグづけへの影響度として考えることができる.

================================================================
[section type  : proposed_method]
[section title : マルチニューロタガー]
================================================================
[1088] 本稿は最長文脈優先に基づいて長さ可変文脈で品詞タグづけを行うマルチニューロタガーを提案する.
-----------------------------------------------------
  [subsection title : シングルニューロタガー]
-----------------------------------------------------
  [1543] 単語[MATH]が入力の位置[MATH] ([MATH], [MATH], or [MATH])に与えられた時,入力[MATH]の構成部分[MATH]は以下のように重み付けされたパターンで定義される.
-----------------------------------------------------
  [subsection title : マルチニューロタガー]
-----------------------------------------------------
  [1683] 目標単語[MATH]を中心とした,最大長さ[MATH]の単語列([MATH], [MATH], [MATH], [MATH], [MATH], [MATH])がマルチニューロタガーに与えられた時,それぞれ同じく単語[MATH]を中心とした長さ[MATH]の部分単語列が前節に述べた方法で[MATH]に符号化され,個々のシングルニューロタガーSNT[MATH] ([MATH])に入力される.
-----------------------------------------------------
  [subsection title : 三層パーセプトロン]
-----------------------------------------------------
  [1477] その時,ネットワークは,入力層に与えられた入力パターン[MATH]を以下の(20)-(24)を用いて出力層へ前向きに伝播しながら変換する.
-----------------------------------------------------
  [subsection title : 訓練]
-----------------------------------------------------
  [1553] 図に示しているように, SNT[MATH]が訓練された後,その重み[MATH]と[MATH]はSNT[MATH]の対応するところにコピーされ, SNT[MATH]の初期値として使われている.
-----------------------------------------------------
  [subsection title : 特徴]
-----------------------------------------------------
  [1671] それに対し,例えば中間層のユニット数が入力層の半分であるような三層パーセプトロンを用いたニューロタガーの場合,必要とされるパラメータ（ユニット間の結合）の数は僅か[MATH] [MATH] [MATH]である.

================================================================
[section type  : experiment_result]
[section title : 実験結果]
================================================================
[1692] また,重みの更新量を決める学習率[MATH]と慣性率[MATH][式(26)]はそれぞれ0.1と0.9に,訓練を止める基準である目標誤差[MATH][式(28)]は0.005に設定された.

================================================================
[section type  : conclusion]
[section title : 結び]
================================================================
[1597] マルチニューロタガーは, 8,322文の小規模タイ語コーパスを訓練に用いることにより,未訓練タイ語データを94%以上の正解率でタグづけすることができた.

