\section{評価実験と議論}\label{sec:exp}
\subsection{対象データ}
我々は Reuters-21578 データセット\footnote{
David D. Lewis の web サイトから利用できる．URL: http:\slash\slash
www.daviddlewis.com\slash
resources\slash testcollections\slash reuters21578\slash
} を提案手法の有効性の検証に使った．
このデータセットには，訓練事例とテスト事例の分け方 (split) にいくつか
のバリエーションがある．
今回我々は ``ModApte'' と呼ばれる分け方を用いた．文書分類の文献で最も
広く使われているものである．
``ModApte'' では，訓練事例 9,603，テスト事例 3,299 と分けられている．
Reuters-21578 には 100 以上のカテゴリが含まれているが，他の多くの文献と
同様，我々も最も頻度が高い 10 カテゴリのみ利用した．
表~\ref{tbl:numcat} に，その 10 カテゴリと，カテゴリごとの訓練事例数とテ
スト事例数を示す．
\begin{table}
\caption{カテゴリごとの訓練事例数とテスト事例数} 
\begin{center}
\begin{tabular}{l|r|r} \hline\hline
カテゴリ名 & 訓練事例 & テスト事例 \\ \hline
earn & 2877 & 1087 \\
acq & 1650 & 719 \\
money-fx & 538 & 179 \\
grain & 433 & 149 \\
crude & 389 & 189 \\
trade & 369 & 117 \\
interest & 347 & 131 \\
ship & 197 & 89 \\
wheat & 212 & 71 \\
corn & 181 & 56  \\ 
\hline
\end{tabular}
\end{center}
\label{tbl:numcat}
\end{table}

\subsection{性能評価尺度}
本研究では，F値 (F-measure) \cite{vanRijsbergen1979,Lewis1994} を実験
結果を評価する第一の尺度として用いる．
F値は次のように定義される:
\begin{eqnarray}
{\rm F値} & = & \frac{(1 + \beta^{2})pq}{\beta^{2}p + q}
\label{eq:f-measure}
\end{eqnarray}
ここで $p$ は適合率 (precision)，$q$ は再現率 (recall)，$\beta$ は適合
率と再現率の相対的な重みを決めるをパラメータである．
$p$ と $q$ は次のように定義される:
\begin{eqnarray*}
p & = & \frac{分類器の出力が +1 でかつ正しい事例の数}{分類器の出力が +1 であった事例の
数} \\
q & = & \frac{分類器の出力が +1 でかつ正しい事例の数}{ラベルが +1 である事例の
数}
\end{eqnarray*}
式~(\ref{eq:f-measure}) では通常 $\beta = 1$ が用いられる．
これは適合率と再現率に等しく重みを置くことを意味する．

複数のカテゴリを持つデータセットに対して，分類器の性能を評価しようとす
るとき，F値を計算する方法としては二つある．
マクロ平均 (macro-averaging) とマイクロ平均 (micro-averaging) である
\cite{Yang1999b}．
前者はまずそれぞれのカテゴリに対してF値を計算し，平均する方法である．
後者は全てのカテゴリ全体に対して適合率と再現率をまず計算し，それを使っ
てF値を計算する方法である．

\subsection{SVM の設定}
実験には我々が作成した SVM のツールを用いた．
線形 SVM を用い，誤分類のコスト $C$ は $0.016541$ に設定した．
この値は $1 / {\rm avg}(\bmath{x}\cdot \bmath{x})$ により
決めた．ここで $\bmath{x}$ は事例数 9603 の訓練事例に含まれる素性ベクタである．
実験を単純にするため，$C$ の値は全ての実験において固定した．
表~\ref{tbl:numcat} で示した 10 のカテゴリそれぞれに対して 2 値分類を行
なう分類器を構築した．

\subsection{実験結果と考察}
まず，\GenerateByDeletion\ と \GenerateByAddition\ をそれぞれ独立に用
いて仮想事例を作って実験を行なった．なお，このときサポートベクタに対し
てのみ仮想事例を作った．
全ての実験に対して，\GenerateByDeletion\ と \GenerateByAddition\ のい
ずれに対しても，
パラメータ $t$ は $0.05$\footnote{
最初に，$t$ として $0.01, 0.05, 0.10$ の三つの値を
試した．\GenerateByDeletion\ を使って，事例数 9,603 の訓練事例から仮想
事例を作った．
テスト事例に対して，$t = 0.05$ の場合に最も高いマイクロ平均 F値が得ら
れた．
同じ $t$ の値を，\GenerateByAddition\ の場合にも用いた．
}とした．


仮想事例を使った SVM を学習して得るための手順は次の通り:
\begin{enumerate}
\item (仮想事例を使わずに) SVM を訓練する．
\item サポートベクタを抽出する．
\item それらサポートベクタから仮想事例を生成する．
\item 元々の訓練事例と仮想事例とを合わせて使って新たな SVM を訓練する．
\end{enumerate}

\begin{table}
\caption{異なる手法間のマイクロ平均 F値の比較．``VSV'' は
仮想サポートベクタ，``GenByDel'' は \\
\GenerateByDeletion，``GenByAdd'' は \GenerateByAddition\ を意味する．
}\label{tbl:pretest}
\begin{center}
\begin{tabular}{l|rrrrrrr} \hline\hline
    & \multicolumn{7}{c}{訓練事例中の事例数} \\ \cline{2-8}
手法 & 9603 & 4802 & 2401 & 1200 & 600 & 300 & 150 \\ \hline
A. オリジナル SVM & 89.42 & 86.58 & 81.69 & 77.24 & 71.08 & 64.44 & 53.28 \\
B. SVM + 1 VSV per SV (GenByDel) & 90.17 & 88.62 & 84.45 & 81.11 & 75.32 & 70.11 & 60.16 \\
C. SVM + 1 VSV per SV (GenByAdd) & 90.00 & 88.51 & 84.48 & 81.14
& 75.33 & 69.59 & 60.04 \\
D. SVM + 2 VSVs per SV (Combined) & 90.27 & 89.33 & 86.27 & 83.59 & 77.44
& 72.81 & 64.22 \\
E. SVM + 4 VSVs per SV (Combined) & 90.45 & 89.69 & 87.12 & 84.97 & 79.16 & 73.25 & 65.05
\\ \hline
\end{tabular}
\end{center}
\end{table}

訓練事例のサイズを変えて，\GenerateByDeletion\ と \GenerateByAddition\ の
二つの手法の性能を評価した．
7つのサイズ (9603, 4802, 2401, 1200, 600, 300, 150) を用意した\footnote{
事例数 4802 以下のセットを作る際，事例をランダムに選択したので，事例数
が少ないセットにおいて頻度の小さいカテゴリでは，
$+1$ のラベルを持つ事例が非常に少ないか
まったく無い場合がある．
}\<．
この二つの手法を用いた場合のマイクロ平均 F値を表~\ref{tbl:pretest} に示す．
表~\ref{tbl:pretest} の手法Bが \GenerateByDeletion{}，
手法Cが \GenerateByAddition{}である．
この表から両手法ともオリジナルのSVM (手法A) よりも性能が良いことが分かる．
訓練事例の事例数が少ないほうが，性能の向上が大きい．
事例数 9603 の訓練事例の場合，\GenerateByDeletion\ による F値向上は
 0.75 ($= 90.17 - 89.42$) であるが，一方，事例数 150 の訓練事例では，
F値向上は 6.88 ($= 60.16 - 53.28$) となっている．
これらの結果から，事例数が少ない訓練事例には，よりよい決定境界を与える
のに十分なだけの事例のバリエーションが存在しておらず，それゆえ，事例数
が少ない訓練事例では，仮想事例の効果が大きくなったと考えられる．
上記結果より，\GenerateByDeletion\ と \GenerateByAddition\ の両手法が
本タスクに対してはよい仮想事例を生成しており，それが精度向上につながった
と結論付けてよいだろう．

仮想事例を作り出す簡単な二つの方法 \GenerateByDeletion\ と
\GenerateByAddition\ が効果的なことが分かったが，次にこれらを組み合わ
せた方法についても調べた．
1つのサポートベクタにつき，2つの仮想事例を作ることにする．
つまり，\GenerateByDeletion\ で 1 事例を作り，\GenerateByAddition\ で
もう 1 事例を作る．
この組み合わせた手法を手法Dとし，そのマイクロ平均F値を
表~\ref{tbl:pretest} に示す．
この手法によるF値向上は，\GenerateByDeletion{}，
\GenerateByAddition\ それぞれを単独で用いた場合よりも大きい．

さらに，1つの事例から \GenerateByDeletion\ で2つ，\GenerateByAddition\ 
で2つ事例を作り出す手法についても実験を行なった．
つまり，1つのサポートベクタから4つの仮想事例を作る．
この手法を手法Eとし，そのF値を表~\ref{tbl:pretest} に示す．
1つのサポートベクタから4つの仮想事例を作り出す手法が最もよい結果を得た．


\begin{figure}
\begin{center}
\epsfile{file=microf1-j02.eps,scale=0.95}
\end{center}
\caption{マイクロ平均 F値と訓練事例中の事例数}\label{fig:micro-f1}
\end{figure}
\begin{figure}
\begin{center}
\epsfile{file=macrof1-j02.eps,scale=0.95}
\end{center}
\caption{マクロ平均 F値と訓練事例中の事例数．事例数が少ないところで
は，適合率が\\
未定義となり，F値は計算することができなかった．}
\label{fig:macro-f1}
\end{figure}

\begin{figure}
\begin{center}
\epsfile{file=error-j02.eps}
\end{center}
\caption{エラー率と訓練事例中の事例数}\label{fig:error}
\end{figure}


本節の以下の議論では，オリジナルの SVM と，1つのサポートベクタから生成
された4つの仮想事例を使う SVM (以降 \SVMFourVSVs\ と記す) の実験結果の比較に焦点をあてる．
オリジナル SVM と \SVMFourVSVs\ の学習曲線を図~\ref{fig:micro-f1}，
図~\ref{fig:macro-f1} に示す．
マイクロ平均 F値，マクロ平均 F値の両方で，\SVMFourVSVs\ がオリジナル 
SVM より明らかに性能が良い．
\SVMFourVSVs\ は，あるレベルの F値を得るのに，オリジナル SVM に比べて概
ね半分以下の訓練事例数で済んでいる．
例えば，オリジナル SVM では，マイクロ平均 F値 64.44 を得るのに 300 事
例必要である (表~\ref{tbl:pretest} 参照)．一方，\SVMFourVSVs\ では 150 
事例で 65.05 を得ている．
F値の改善は，ただ再現率が大きく改善したせいで実現され，その裏でエラー
率が上昇している可能性もある．
これを確認するため，32990 のテスト (3299 のテストを10カテゴリそれぞれ
について) に対してのエラー率の変化を
図~\ref{fig:error} にプロットした．
エラー率においても，\SVMFourVSVs\ がオリジナル SVM よりも優れている
\footnote{
我々は 有意水準 0.05 で ``p-test''~\cite{Yang1999} と呼ばれる検定を行
なった．
事例数 9603 の訓練事例では，エラー率の改善は統計的に有意とは言えなかっ
たが，それ以外の全ての場合においては統計的有意となった．
}．

\begin{table}
\caption{10カテゴリそれぞれに対するオリジナル SVM による F値．ハイフン `-' は
F値が\\
計算できなかったことを示す．分類器が常に $-1$ を返し，適合率が未定義となった
ため．\\
太字はオリジナル SVM が \SVMFourVSVs\ (表~\ref{tbl:vsv-each} 参照) より優れ
ていることを示す．
}\label{tbl:sv-each}
\begin{center}
\begin{tabular}{l|rrrrrrr} \hline\hline
  & \multicolumn{7}{c}{訓練事例中の事例数} \\ \cline{2-8}
カテゴリ名  & 9603 & 4802 & 2401 & 1200 & 600 & 300 & 150 \\ \hline
earn & 98.06 & 97.49 & 97.40 & 96.39 & 95.94 & 94.85 & 93.73 \\
acq & 91.94 & 89.87 & 84.43 & 84.01 & 78.17 & 63.10 & 12.03 \\
money-fx & 64.90 & 61.69 & 56.03 & 51.69 & 17.91 & 01.11 & 05.38 \\
grain & 86.96 & 81.68 & 75.20 & 59.63 & 41.27 & 06.49 & \undefv \\
crude & 84.59 & 81.52 & 67.11 & 33.33 & 01.05 & \undefv & \undefv \\
trade & 74.89 & 64.58 & 54.86 & 40.26 & 12.80 & 01.69 & \undefv \\
interest & {\bf 63.89} & 60.29 & 50.27 & 35.15 & 08.57 & 05.88 & \undefv \\
ship & 66.19 & 44.07 & 32.73 & 02.22 & \undefv & \undefv & \undefv \\
wheat & {\bf 89.61} & 80.60 & 38.30 & 08.11 & \undefv & \undefv & \undefv \\
corn & 84.62 & 62.79 & 10.17 & \undefv & \undefv & \undefv & \undefv \\ \hline
マクロ平均 & 80.56 & 72.46 & 56.65 & \undefv & \undefv & \undefv &\undefv \\
マイクロ平均 & 89.42 & 86.58 & 81.69 & 77.24 & 71.08 & 64.44 & 53.28
\\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}
\caption{10カテゴリそれぞれに対する \SVMFourVSVs\ による F値．太字は 
\SVMFourVSVs\ が\\
オリジナル SVM より優れていることを示す (表~\ref{tbl:sv-each} 参照)．
}\label{tbl:vsv-each}
\begin{center}
\begin{tabular}{l|rrrrrrr} \hline\hline
  & \multicolumn{7}{c}{訓練事例中の事例数} \\ \cline{2-8}
カテゴリ名  & 9603 & 4802 & 2401 & 1200 & 600 & 300 & 150 \\ \hline
earn & {\bf 98.07} & {\bf 98.02} & {\bf 97.56} & {\bf 97.37} & {\bf 97.14} & {\bf 96.00} & {\bf 95.46} \\
acq & {\bf 94.20} & {\bf 93.06} & {\bf 91.71} & {\bf 88.81} & {\bf 88.92} & {\bf 78.70} & {\bf 59.92} \\
money-fx & {\bf 70.83} & {\bf 73.10} & {\bf 62.86} & {\bf 65.68} & {\bf 47.91} & {\bf 32.43} &{\bf 33.76} \\
grain & {\bf 89.20} & {\bf 84.72} & {\bf 85.11} & {\bf 80.44} & {\bf 60.79} & {\bf 44.10} & {\bf 01.00} \\
crude & {\bf 84.93} & {\bf 86.33} & {\bf 76.92} & {\bf 74.36} & {\bf 15.53} & {\bf 02.00} & \undefv \\
trade & {\bf 75.83} & {\bf 73.21} & {\bf 62.31} & {\bf 43.53} & {\bf 37.58} & {\bf 18.32} & {\bf 01.65} \\
interest & 62.73 & {\bf 63.16} & {\bf 65.77} & {\bf 63.35} & {\bf 59.11} & {\bf 37.50} & {\bf 11.92} \\
ship & {\bf 73.68} & {\bf 67.14} & {\bf 50.79} & {\bf 30.48} & {\bf 06.45} & {\bf 02.22} & \undefv \\
wheat & 87.42 & {\bf 82.61} & {\bf 87.94} & {\bf 68.91} & {\bf 10.67} & \undefv & \undefv \\
corn & {\bf 87.50} & {\bf 84.11} & {\bf 46.75} & {\bf 68.09} & {\bf 03.45} & \undefv & \undefv \\ \hline
マクロ平均 & {\bf 82.44} & {\bf 80.55} & {\bf 72.77} & {\bf 68.10} & {\bf 42.76} & \undefv & \undefv \\
マイクロ平均 & {\bf 90.45} & {\bf 89.69} & {\bf 87.12} & {\bf 84.97} & {\bf 79.16} & {\bf 73.25} & {\bf 65.05}
\\ \hline
\end{tabular}
\end{center}
\end{table}

10カテゴリそれぞれに対する性能の変化を表~\ref{tbl:sv-each}，
表~\ref{tbl:vsv-each} に示す．
\SVMFourVSVs\ は殆どの場合
でオリジナルSVMよりもよい．
事例数 9603 での ``interest'' と ``wheat'' の場合のみ，
\SVMFourVSVs\ が下回っているが，理由は不明である\footnote{
仮想事例の効果は事例数が多いほど減少するという一般的な傾向があるので，
文書の性質によっては，
一定数以上の事例の場合に効果が出ないことは十分考えられる．
ただ，何がその限界を決めているのかは現時点では不明である．
}．
頻度が小さい ``ship'' や ``wheat''，``corn'' といったカテゴリに対して，
オリジナルSVMの性能は良くない．
分類器が決して $+1$ を出力しなかった場合，つまり再現率ゼロの場合も多い．
これは，ラベルとして $+1$ を持つ事例が非常に少ないバランスの悪い訓練事
例のために，
オリジナル SVM がよい超平面を見つけられなかったことを示している\footnote{
SVMでバランスの悪い訓練事例に対処する方法として，誤分類のコスト $C$ を，
$+1$ のラベルを持つ事例，$-1$ のラベルを持つ事例それぞれで別の値に設定
する方法がある\cite{Morik1999}．
}．
これに対し，\SVMFourVSVs\ はそういうバランスの悪い訓練事例のような難しい場合でも
よりよい結果を得ている．



