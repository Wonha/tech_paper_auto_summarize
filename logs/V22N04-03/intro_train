0  対訳 文中 の 単語 の 対応 関係 を 解析 する 単語 アラインメント は  統計 的 機械 翻訳 に 欠か せ ない 重要 な 処理 の 一つ で あり  研究 が 盛ん に 行わ れ て いる  
0  その 中 で  生成 モデル で ある IBM モデル 1  5  CITE  や HMM に 基づく モデル  CITE  は 最も 有名 な 手法 で あり  それら を 拡張 し た 手法 が 数多く 提案 さ れ て いる  CITE  
1  近年 で は  Yang ら が  フィードフォワードニューラルネットワーク  FFNN  の 一 種 で ある  Context  Dependent Deep Neural Network for HMM  CD  DNN  HMM  CITE  を HMM に 基づく モデル に 適用 し た 手法 を 提案 し  中 英 アラインメントタスク において IBM モデル 4 や HMM に 基づく モデル より も 高い 精度 を 達成 し て いる  CITE  
0  この FFNN  HMM アラインメントモデル は  単語 アラインメント に 単純 マルコフ 性 を 仮定 し た モデル で あり  アラインメント 履歴 として  一つ 前 の 単語 アラインメント 結果 を 考慮 する  
0  一方 で  ニューラルネットワーク  NN  の 一種 に フィードバック 結合 を 持つ リカレントニューラルネットワーク  RNN  が ある  
0  RNN の 隠れ 層 は 再帰 的 な 構造 を 持ち  自身 の 信号 を 次 の ステップ の 隠れ 層 へ と 伝達 する  
0  この 再帰 的 な 構造 により  過去 の 入力 データ の 情報 を 隠れ 層 で 保持 できる ため  入力 データ に 内在 する 長距離 の 依存 関係 を 捉える こと が できる  
0  この よう な 特長 を 持つ RNN に 基づく モデル は  近年  多く の タスク で 成果 を あげ て おり  FFNN に 基づく モデル の 性能 を 凌駕 し て いる  
0  例えば  言語 モデル  CITE  や 翻訳 モデル  CITE  の 構築 で 効果 を 発揮 し て いる  
0  一方 で  単語 アラインメントタスク において RNN を 活用 し た モデル は 提案 さ れ て い ない  
1  本 論文 で は  単語 アラインメント において  過去 の アラインメント の 情報 を 保持 し て 活用 する こと は 有効 で ある と 考え  RNN に 基づく 単語 アラインメントモデル を 提案 する  
0  前述 の 通り  従来 の FFNN に 基づく モデル は  直前 の アラインメント 履歴 しか 考慮 し ない  
1  一方 で  RNN に 基づく モデル は  隠れ 層 の 再帰 的 な 構造 として アラインメント の 情報 を 埋め込む こと で  FFNN に 基づく モデル より も 長い  文頭 から 直前 の 単語 アラインメント の 情報  つまり 過去 の アラインメント 履歴 全体 を 考慮 できる  
0  NN に 基づく モデル の 学習 に は  通常  教師 データ が 必要 で ある  
0  しかし  単語 単位 の 対応 関係 が 付与 さ れ た 対 訳文 を 大量 に 用意 する こと は 容易 で は ない  
0  この 状況 に対して  Yang ら は  従来 の 教師 なし 単語 アラインメントモデル  IBM モデル  HMM に 基づく モデル  により 生成 し た 単語 アラインメント を 疑似 の 正解 データ として 使い  モデル を 学習 し た  CITE  
0  しかし  この 方法 で は  疑似 正解 データ の 作成 段階 で 生み出さ れ た  誤っ た 単語 アラインメント が 正しい アラインメント として 学習 さ れ て しまう 可能 性 が ある  
1  これら の 状況 を 踏まえ て  本 論文 で は  正解 の 単語 アラインメント や 疑似 の 正解 データ を 用意 せ ず に RNN に 基づく モデル を 学習 する 教師 なし 学習 法 を 提案 する  
1  本 学習 法 で は  Dyer ら の 教師 なし 単語 アラインメント  CITE  を 拡張 し  正しい 対 訳文 における 単語 対 と 語彙 空間 全体 における 単語 対 を 識別 する よう に モデル を 学習 する  
0  具体 的 に は  まず  語彙 空間 全体 から の サンプリング により 偽 の 対 訳文 を 人工 的 に 生成 する  
0  その後  正しい 対 訳文 における アラインメントスコア の 期待 値 が  偽 の 対 訳文 における アラインメントスコア の 期待 値 より 高く なる よう に モデル を 学習 する  
0  RNN に 基づく モデル は  多く の アラインメントモデル と 同様 に  方向 性   原 言語  MATH  目的 言語  MATH  又は  MATH  を 持ち  各 方向 の モデル は 独立 に 学習  使用 さ れる  
1  ここ で  学習 さ れる 特徴 は 方向 毎 に 異なり  それら は 相補 的 で ある と の 考え に 基づき  各 方向 の 合意 を 取る よう に モデル を 学習 する こと により アラインメント 精度 が 向上 する こと が 示さ れ て いる  Matusov  Zens  and Ney 2004  Liang  Taskar  and Klein 2006  Gra  c  c  a  Ganchev  and Taskar 2008  Ganchev  Gra  c  c  a  and Taskar 2008  
0   CITE  そこ で  提案 手法 において も   MATH  と   MATH  の 2 つ の RNN に 基づく モデル の 合意 を 取る よう に それら の モデル を 同時に 学習 する  
1  両方向 の 合意 は  各 方向 の モデル の word embedding が 一致 する よう に モデル を 学習 する こと で 実現 する  
1  具体 的 に は  各 方向 の word embedding の 差 を 表す ペナルティ 項 を 目的 関数 に 導入 し  その 目的 関数 に したがっ て モデル を 学習 する  
0  この 制約 により  それぞれ の モデル の 特定 方向 へ の 過 学習 を 防ぎ  双方 で 大域 的 な 最適 化 が 可能 と なる  
1  提案 手法 の 評価 は  日 英 及び 仏 英単語 アラインメント 実験 と 日 英 及び 中 英 翻訳 実験 で 行う  
1  評価 実験 を通じて  前記 提案 全て を 含む  合意 制約 付き 教師 なし 学習 法 で 学習 し た RNN に 基づく モデル  は  FFNN に 基づく モデル や IBM モデル 4 より も 単語 アラインメント 精度 が 高い こと を 示す  
1  また  機械 翻訳 実験 を通じて  学習 データ 量 が 同じ 場合 に は  FFNN に 基づく モデル や IBM モデル 4 を 用い た 場合 より も 高い 翻訳 精度 を 実現 できる こと を 示す  
0  具体 的 に は  アラインメント 精度 は FFNN に 基づく モデル より 最大 0  0792  F 1 値   IBM モデル 4 より 最大 0  0703  F 1 値   翻訳 精度 は FFNN に 基づく モデル より 最大 0  74  BLEU  IBM モデル 4 より 最大 0  58  BLEU  上回っ た  
0  また  各 提案  RNN の 利用  教師 なし 学習 法  合意 制約  個別 の 有効 性 も 検証 し  機械 翻訳 において は 一部 の 設定 における 精度 改善 に とどまる が  単語 アラインメント において は 各 提案 により 精度 が 改善 できる こと を 示す  
1  以降   REF _ sect  related  節 で 従来 の 単語 アラインメントモデル を 説明 し   REF _ sect  RNN  節 で RNN に 基づく 単語 アラインメントモデル を 提案 する  
1  そして   REF _ sect  learning  節 で RNN に 基づく モデル の 学習 法 を 提案 する  
