================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[3194] ニューラルネットワークに基づくモデルでは，従来，教師あり学習が行われてきたが，本論文では，本モデルの学習法として，Dyerらの教師なし単語アラインメント[CITE]を拡張して人工的に作成した負例を利用する教師なし学習法を提案する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[3039] ここで，学習される特徴は方向毎に異なり，それらは相補的であるとの考えに基づき，各方向の合意を取るようにモデルを学習することによりアラインメント精度が向上することが示されている(Matusov, Zens, and Ney 2004; Liang, Taskar, and Klein 2006; Gra\c{c}a, Ganchev, and Taskar 2008; Ganchev, Gra\c{c}a, and Taskar 2008)．

================================================================
[section type  : proposed_method]
[section title : 従来の単語アラインメントモデル]
================================================================
[2685] [REF_sect:SWA]節では生成モデルを概観し，[REF_sect:FFNN]節では識別モデルの一例として，提案手法のベースラインとなるFFNNに基づくモデル[CITE]を説明する．
-----------------------------------------------------
  [subsection title : 生成モデル]
-----------------------------------------------------
  [2953] IBMモデル1，2やHMMに基づくモデルでは，式([REF_eqn:base1])中の特定アラインメント[MATH]との生成確率[MATH]をアラインメント確率[MATH]と語彙翻訳確率[MATH]で定義する：
-----------------------------------------------------
  [subsection title : FFNNに基づく単語アラインメントモデル]
-----------------------------------------------------
  [2570] FFNNに基づくモデルは，式([REF_eqn:base2])のアラインメント確率[MATH]及び語彙翻訳確率[MATH]をFFNNにより計算する：

================================================================
[section type  : proposed_method]
[section title : RNNに基づく単語アラインメントモデル]
================================================================
[3259] 一方で，RNNに基づくモデルは，直前のアラインメントとの距離[MATH]に依存した重み行列を隠れ層で使うことで，アラインメントと語彙翻訳の両者を考慮する1つのモデルで単語アラインメントをモデル化する．

================================================================
[section type  : proposed_method]
[section title : モデルの学習]
================================================================
[2280] 提案モデルの学習では，特定の目的関数に従い，各層の重み行列（つまり，[MATH]，[MATH]，[MATH]，[MATH]，[MATH]，[MATH]）を最適化する．
-----------------------------------------------------
  [subsection title : 教師なし学習]
-----------------------------------------------------
  [3394] 学習に効果的な負例を生成するために，[MATH]の各単語は，[MATH]から抽出する代わりに，[MATH]正則化付きIBMモデル1 [CITE]によって対訳文中で[MATH]との共起確率が[MATH]以上と判定された目的言語の単語集合から抽出する．
-----------------------------------------------------
  [subsection title : 両方向の合意制約]
-----------------------------------------------------
  [3532] ステップ3-1と3-2では，それぞれ，各[MATH]と[MATH]に対して，[MATH]正則化付きIBMモデル1 ([MATH])が特定した翻訳候補の単語集合から無作為に単語をサンプリングすることにより，負例となる対訳文を[MATH]個([MATH]と[MATH])生成する（[REF_sect:usv]節参照）．

================================================================
[section type  : experiment_result]
[section title : 評価実験]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : 実験データ]
-----------------------------------------------------
  [2592] また，NAACL 2003のshared taskオリジナルの学習データの総数は約110万文対あるが，今回のHansardsの実験では，学習時の計算量を削減するため，無作為にサンプリングした10万文対を学習データとして用いた．
-----------------------------------------------------
  [subsection title : 実験対象]
-----------------------------------------------------
  [3434] このFFNNに基づくモデルは，[CITE]に倣って[REF_sect:FFNN]節の教師あり手法により学習したモデル[MATH]に加えて，[REF_sect:usv]節と[REF_sect:agreement]節で提案した教師なし学習や合意制約の効果を確かめるため，[MATH]，[MATH]，[MATH]のモデルを評価した．
-----------------------------------------------------
  [subsection title : 実験結果（単語アラインメント）]
-----------------------------------------------------
  [3190] NNに基づく教師ありモデルに対しては，学習データに付与されている正しい単語アラインメントを学習したモデル(REF)と，IBM4で特定した単語アラインメントを学習したモデル(IBM4)の2種類の精度を示す．
-----------------------------------------------------
  [subsection title : 実験結果（機械翻訳）]
-----------------------------------------------------
  [2872] また，NTCIR-9とFBISでは，提案モデルは学習データの一部から学習したが，学習データ全てから学習した[MATH]と同等の精度を達成している．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : RNNに基づくモデルの効果]
-----------------------------------------------------
  [2639] 図[REF_fig:wa](b)は，このような単純な単語アラインメントは，[MATH]と[MATH]の両モデルで正しく解析できることを示している．
-----------------------------------------------------
  [subsection title : 学習データ量の影響]
-----------------------------------------------------
  [2937] 「40 K」，「9 K」，「1 K」は，それぞれ，IWSLTの全学習データ，[MATH]の全学習データ，[MATH]の全学習データから無作為に抽出した1,000文対を学習データとした時の，[MATH]のテストデータに対するアラインメント精度である．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[3195] 提案モデルでは，アラインメント対象の文脈をアラインメント履歴([MATH])に暗示的に埋め込み利用しているが，今後は，FFNNに基づくモデルのように周辺単語の入力（[MATH]や[MATH]）として明示的に利用することも検討したい．

