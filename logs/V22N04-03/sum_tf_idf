================================================================
  [ type  : abstract ]
  [ title : abstract ]
本論文では，隠れ層の再帰的な構造により，過去のアラインメント履歴全体を活用するリカレントニューラルネットワーク(RNN)による単語アラインメントモデルを提案する．  [score 215.857796042671]

================================================================
  [ type  : intro ]
  [ title : はじめに ]
評価実験を通じて，前記提案全てを含む「合意制約付き教師なし学習法で学習したRNNに基づくモデル」は，FFNNに基づくモデルやIBMモデル4よりも単語アラインメント精度が高いことを示す．  [score 302.686498456082]

================================================================
  [ type  : proposed_method ]
  [ title : 従来の単語アラインメントモデル ]
[REF_sect:SWA]節では生成モデルを概観し，[REF_sect:FFNN]節では識別モデルの一例として，提案手法のベースラインとなるFFNNに基づくモデル[CITE]を説明する．  [score 91.7289667010076]
------------------------------------------------------------
  [ title : 生成モデル ]
IBMモデル1，2やHMMに基づくモデルでは，式([REF_eqn:base1])中の特定アラインメント[MATH]との生成確率[MATH]をアラインメント確率[MATH]と語彙翻訳確率[MATH]で定義する：  [score 192.049294788458]
..................................................
生成モデルでは，[MATH]単語から構成される原言語の文を[MATH]，それに対応する[MATH]単語で構成される目的言語の文を[MATH]とすると，[MATH]は[MATH]からアラインメント[MATH]を通じて生成されると考える．  [score 103.804744246475]
------------------------------------------------------------
  [ title : FFNNに基づく単語アラインメントモデル ]
FFNNに基づくモデルは，式([REF_eqn:base2])のアラインメント確率[MATH]及び語彙翻訳確率[MATH]をFFNNにより計算する：  [score 187.355681620743]
..................................................
FFNNは，非線形関数を持つ隠れ層を備えることにより，入力データから多層的に非線形な素性を自動的に学習することができ，入力データの複雑な特徴を捉えることができる．  [score 131.099635330361]

================================================================
  [ type  : proposed_method ]
  [ title : RNNに基づく単語アラインメントモデル ]
一方で，RNNに基づくモデルは，直前のアラインメントとの距離[MATH]に依存した重み行列を隠れ層で使うことで，アラインメントと語彙翻訳の両者を考慮する1つのモデルで単語アラインメントをモデル化する．  [score 230.972806673844]

================================================================
  [ type  : proposed_method ]
  [ title : モデルの学習 ]
提案モデルは，FFNNに基づくモデル同様，式([REF_eqn:FFNN3])で定義されるランキング損失に基づいて教師あり学習することができる（[REF_sect:FFNN]節参照）．  [score 118.000323592951]
------------------------------------------------------------
  [ title : 教師なし学習 ]
[MATH]正則化付きIBMモデル1は，単純なIBMモデル1と比較して，より疎なアラインメントを生成するため，疑似翻訳[MATH]の候補の範囲を制限することが可能となる．  [score 164.457978776135]
..................................................
本節で提案する教師なし学習は，Dyerらにより提案されたcontrastive estimation (CE) [CITE]に基づく教師なし単語アラインメントモデル[CITE]を拡張した手法である．  [score 69.2911576879239]
------------------------------------------------------------
  [ title : 両方向の合意制約 ]
ここで，[MATH]と[MATH]は，それぞれ，[MATH]と[MATH]のアラインメントモデルのパラメータ，[MATH]はlookup層のパラメータ（[MATH]の重みでありword embeddingを表す），[MATH]は合意制約の強さを制御するパラメータ，[MATH]は[MATH]のノルムである．  [score 173.031881653025]
..................................................
FFNNに基づくモデルとRNNに基づくモデルは，共に方向性を持つモデルである．  [score 110.661806055266]

================================================================
  [ type  : experiment_result ]
  [ title : 評価実験 ]
  [score ]
------------------------------------------------------------
  [ title : 実験データ ]
単語アラインメントの評価実験は，NAACL 2003のshared task [CITE]で使われたHansardsデータにおける仏英のタスク(Hansards)と，Basic Travel Expression Corpus (BTEC) [CITE]における日英のタスク(IWSLT[MATH])で実施した．  [score 141.643025423829]
..................................................
提案手法の有効性を検証するため，単語アラインメントの精度及び翻訳精度の評価実験を行った．  [score 92.5001101701057]
------------------------------------------------------------
  [ title : 実験対象 ]
このFFNNに基づくモデルは，[CITE]に倣って[REF_sect:FFNN]節の教師あり手法により学習したモデル[MATH]に加えて，[REF_sect:usv]節と[REF_sect:agreement]節で提案した教師なし学習や合意制約の効果を確かめるため，[MATH]，[MATH]，[MATH]のモデルを評価した．  [score 181.260338901956]
..................................................
評価実験では，提案手法であるRNNに基づくモデルに加え，ベースラインとして，IBMモデル4とFFNNに基づくモデルを評価した．  [score 157.34255383838]
------------------------------------------------------------
  [ title : 実験結果（単語アラインメント） ]
この結果より，教師ありと教師なしの両方の学習において，両方向の合意制約を導入することでFFNNに基づくモデル及びRNNに基づくモデルのアラインメント精度を改善できることが分かる．  [score 265.502151533299]
..................................................
表[REF_tbl:res_wa]に各手法の単語アラインメントの精度をF1値で示す．  [score 101.583937708388]
------------------------------------------------------------
  [ title : 実験結果（機械翻訳） ]
その後，学習したアラインメントモデルにより学習データ全ての単語アラインメントを自動的に付与し，翻訳モデルを学習した．  [score 128.149525186201]
..................................................
表[REF_tbl:res_mt]に各手法により付与されたアラインメントを用いたSMTシステムの翻訳精度を示す．  [score 119.798647183588]

================================================================
  [ type  : conclusion ]
  [ title : 考察 ]
  [score ]
------------------------------------------------------------
  [ title : RNNに基づくモデルの効果 ]
[REF_sect:res_alignment]節で述べた通り，RNNに基づくモデルの効果は，日英アラインメント([MATH])と比べて仏英アラインメント(Hansards)に対して少ない．  [score 210.539304328548]
..................................................
図[REF_fig:wa]に[MATH]及び[MATH]で解析した単語アラインメントの具体例を示す．  [score 98.3361044340218]
------------------------------------------------------------
  [ title : 学習データ量の影響 ]
そして，本論文で提案した，RNNの利用，教師なし学習，合意制約の個別の有効性も確認できることから，データサイズに依らず提案手法が有効であることが分かる．  [score 127.175107787153]
..................................................
BTECにおける日英アラインメントタスクにおいて様々なサイズの学習データを使った時のアラインメント精度を表[REF_tbl:size]に示す．  [score 117.403246117859]

================================================================
  [ type  : conclusion ]
  [ title : まとめ ]
複数の単語アラインメントタスクと翻訳タスクの実験を通じて，RNNに基づくモデルは従来のFFNNに基づくモデル[CITE]よりアラインメント精度及び翻訳精度が良いことを示した．  [score 207.32346372264]

