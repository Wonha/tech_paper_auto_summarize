提案手法の有効性を検証するため，単語アラインメントの精度及び翻訳精度の評価実験を行った．
単語アラインメントの評価実験は，NAACL 2003のshared task [CITE]で使われたHansardsデータにおける仏英のタスク(Hansards)と，Basic Travel Expression Corpus (BTEC) [CITE]における日英のタスク(IWSLT[MATH])で実施した．
翻訳精度の評価実験は，IWSLT2007における日英翻訳タスク[CITE] (IWSLT)，新聞データから作成されたFBISコーパスにおける中英翻訳タスク(FBIS)，NTCIR-9及びNTCIR-10における日英特許翻訳タスク[CITE] (NTCIR-9, NTCIR-10)で行った．
表[REF_tbl:data]に各タスクで使用する対訳文の数を示す．
「Train」は学習データ，「Dev」はディベロップメントデータ，「Test」はテストデータを表す．
[MATH]及びIWSLTの実験データは共にBTECのデータであり，[MATH]の実験データは，IWSLTの学習データのうち，単語アラインメントが人手で付与された9,960対訳文である[CITE]．
9,960の対訳文の最初の9,000を学習データ，残りの960をテストデータとした．
[MATH]の学習データは単語アラインメントが付与されているラベルあり学習データであるのに対し，Hansardsの学習データは単語アラインメントが付与されてないラベルなし学習データである．
Hansards及び[MATH]のアラインメントタスクでは，各アラインメントモデルのハイパーパラメータは学習データの一部を用いた2分割交差検証により予め決定し，ディベロップメントデータは使わなかった．
また，NAACL 2003のshared taskオリジナルの学習データの総数は約110万文対あるが，今回のHansardsの実験では，学習時の計算量を削減するため，無作為にサンプリングした10万文対を学習データとして用いた．
大規模データの実験は今後の課題とする．
FBISでは，NIST02の評価データをディベロップメントデータとして使い，NIST03とNIST04の各評価データでテストした．
評価実験では，提案手法であるRNNに基づくモデルに加え，ベースラインとして，IBMモデル4とFFNNに基づくモデルを評価した．
また，単語アラインメントタスクにおける合意制約の有効性を考察するため，ベースラインとして，典型的なHMMに基づくアラインメントモデルであるVogelらのモデル[CITE] ([MATH])とこのVogelらのモデルにLiangらの両方向の合意制約[CITE]を導入したモデル([MATH])も評価した．
IBMモデル4は，IBMモデル1-4とHMMに基づくモデルを順番に適用して学習した[CITE]．
具体的には，IBMモデル1，HMMに基づくモデル，IBMモデル2，3，4をこの順で5回ずつ繰り返した([MATH])．
これは，GIZA++のデフォルトの設定である(IBM4)．
[MATH]及び[MATH]はBerkleyAlignerを用いた．
Liangらの通り，IBMモデル1，HMMに基づくモデルを順番に5回ずつ繰り返し，各モデルを学習した[CITE]．
FFNNに基づくモデルでは，word embeddingの長さ[MATH]を30，文脈の窓幅を5とした．
したがって，[MATH]は[MATH]である．
また，隠れ層として，ユニット数[MATH]が100の層を1層使用した．
このFFNNに基づくモデルは，[CITE]に倣って[REF_sect:FFNN]節の教師あり手法により学習したモデル[MATH]に加えて，[REF_sect:usv]節と[REF_sect:agreement]節で提案した教師なし学習や合意制約の効果を確かめるため，[MATH]，[MATH]，[MATH]のモデルを評価した．
「[MATH]」は教師ありモデル，「[MATH]」は教師なしモデル，「[MATH]」は学習時に合意制約を使うことを意味する．
RNNに基づくモデルでは，word embeddingの長さ[MATH]を30，再帰的に連結している隠れ層のユニット数[MATH]を100とした．
したがって，[MATH]は[MATH]である．
また，提案の学習法の効果を検証するため，FFNNに基づくモデル同様，[MATH]，[MATH]，[MATH]，[MATH]の4種類を評価した．
FFNNに基づくモデル及びRNNに基づくモデルの各層のユニット数や[MATH]などのパラメータは，学習データの一部を用いた2分割交差検証により予め設定した．
NNに基づくモデルの学習について説明する．
まず，各層の重み行列を初期化する．
具体的には，lookup層の重み行列[MATH]は，局所解への収束を避けるため，学習データの原言語側と目的言語側からそれぞれ予め学習したword embeddingに初期化する．
その他の重みは，[MATH]のランダムな値に初期化する．
word embeddingの学習には，Mikolovらの手法[CITE]を基にしたRNNLMツールキット（デフォルトの設定）を用いる．
その際，コーパスでの出現数が5回以下の単語は[MATH]に置き換える．
各重みの初期化後は，ミニバッチSGDにより特定の目的関数に従って各重みを最適化する．
本実験では，バッチサイズ[MATH]を100，学習率を0.01とし，50エポックで学習を終えた．
また，学習データへの過学習を避けるため，目的関数には[MATH]正則化項（正則化の比率は0.1）を加えた．
教師なし学習におけるパラメータ[MATH]，[MATH]，[MATH]は，それぞれ，100，50，0.001とし，合意制約に関するパラメータ[MATH]は0.1とした．
翻訳タスクでは，フレーズベース機械翻訳(SMT)システムMoses [CITE]を用いた．
日本語の各文はChaSen，中国語の各文はStanford Chinese segmenterにより単語へ分割した．
その後，40単語以上の文は学習データから除いた．
言語モデルは，SRILMツールキット[CITE]により，modified Kneser-Neyスムージング[CITE]を行い学習した．
IWSLT，NTCIR-9及びNTCIR-10では，学習データの英語側コーパスから構築した5グラム言語モデル，FBISでは，English GigawordのXinhua部分のデータから構築した5グラム言語モデルを使用した．
翻訳モデルは，各単語アラインメント手法により特定されたアラインメント結果に基づいて学習した．
SMTシステムの各パラメータは，ディベロップメントデータを用いてMERT [CITE]によりチューニングした．
表[REF_tbl:res_wa]に各手法の単語アラインメントの精度をF1値で示す．
NNに基づく教師ありモデルに対しては，学習データに付与されている正しい単語アラインメントを学習したモデル(REF)と，IBM4で特定した単語アラインメントを学習したモデル(IBM4)の2種類の精度を示す．
Hansardsの学習データには正しい単語アラインメントが付与されていないため，REFに対する実験は実施していない．
評価手順は，まず，各アラインメントモデルにより，[MATH]と[MATH]のアラインメントをそれぞれ生成する．
その後，「grow-diag-final-and」ヒューリスティックス[CITE]により，両方向のアラインメントを結合する．
そして，その結合したアラインメント結果をF1値で評価する．
有意差検定は，有意差水準5%の符号検定で行った．
具体的には，テストデータの各単語に対して，他方の手法では不正解だが正しく判定したものを[MATH]，他方の手法では正解だが誤って判定したものを[MATH]として，2手法の評価に有意な差があるかどうかを片側検定の符号検定で判定した．
表[REF_tbl:res_wa]中の「[MATH]」は，ベースラインとなるFFNNに基づくモデル[MATH](REF/IBM4)との精度差が有意であることを示し，「[MATH]」は，ベースラインのFFNNに基づくモデル[MATH](REF/IBM4)に加えてIBM4との精度差も有意であることを示す．
また，正しい教師ラベルを使用するモデル(REF)と使用しないモデル（REF以外）のそれぞれで最高の精度を太字で示す．
表[REF_tbl:res_wa]より，[MATH]とHansardsの両タスクにおいて，本論文の提案手法（RNNに基づくモデル，教師なし学習，合意制約）RNN[MATH]が最もアラインメント精度が高いことが分かる．
特に，ベースラインとの精度差は有意であることから，本論文の提案を組み合わせることにより，従来手法より高いアラインメント精度を達成できることが実験的に確認できる．
次に，本論文の各提案の個別の有効性について確認する．
表[REF_tbl:res_wa]より，[MATH]とHansardsの両タスクにおいて，[MATH](IBM4)，[MATH](REF)は，それぞれ，，[MATH](IBM4)，[MATH](REF)よりも精度が良い．
特に，[MATH]では，[MATH](REF)，[MATH](IBM4)と[MATH](REF)，[MATH](IBM4)とのそれぞれの性能差は有意であることが分かる．
これは，RNNに基づくモデルにより長いアラインメント履歴を捉えることで，アラインメント精度が向上することを示しており，RNNを利用したモデルの有効性を確認できる．
ただし，Hansardsにおいては，RNNの効果が少ない．
この言語対による効果の違いについては[REF_sect:discuss_RNN]節で考察する．
[MATH]とHansardsの両タスクにおいて，[MATH](REF/IBM4)，[MATH]のアラインメント精度は，それぞれ，[MATH](REF/IBM4)，[MATH]を上回っており，これらの精度差は有意であった．
さらに，[MATH](REF/IBM4)，[MATH]は，それぞれ，[MATH](REF/IBM4)，[MATH]より有意にアラインメント精度が良い．
この結果より，教師ありと教師なしの両方の学習において，両方向の合意制約を導入することでFFNNに基づくモデル及びRNNに基づくモデルのアラインメント精度を改善できることが分かる．
一方で，HMM[MATH]の方がHMM[MATH]よりも精度が良いことから，提案の合意制約に限らず，両方向の合意をとるようにモデルを学習することは有効であることが確認できる．
HMMに基づくモデルに導入したLiangらの両方向の合意制約と提案の合意制約の傾向の違いは，[REF_sect:discuss_size]節で考察する．
[MATH]では，[MATH]と[MATH]は，それぞれ，[MATH](IBM4)と[MATH](IBM4)より有意にアラインメント精度が良い．
一方で，Hansardsでは，これらの精度は同等である．
この傾向はFFNNに基づくモデルでも同様である．
これは，学習データの質（IBM4の精度）が悪い場合，教師あり学習はIBM4による疑似学習データに含まれる誤りの悪影響を受けるのに対し，提案の教師なし学習は学習データの質に依らずに精度の良いFFNNやRNNに基づくモデルを学習できることを示している．
表[REF_tbl:res_mt]に各手法により付与されたアラインメントを用いたSMTシステムの翻訳精度を示す．
評価尺度は，大文字と小文字を区別したBLEU4 [CITE]を用いた．
MERTの不安定な振る舞いの影響を緩和するため，MERTによるチューニングは3回行い，その平均値を表[REF_tbl:res_mt]に示す[CITE]．
IWSLTでは，アラインメントモデル及び翻訳モデルの学習には学習データ全てを用いた．
一方で，NTCIR-9，NTCIR-10とFBISでは，アラインメントモデルの学習における計算量を削減するため，学習データから無作為にサンプリングした10万文対からアラインメントモデルを学習した．
その後，学習したアラインメントモデルにより学習データ全ての単語アラインメントを自動的に付与し，翻訳モデルを学習した．
また，詳細な比較を行うため，全学習データから学習したIBMモデル4に基づくSMTシステムの精度をIBM4[MATH]として示す．
翻訳精度の有意差検定は，有意差水準5%でブートストラップによる検定手法[CITE]により行った．
表[REF_tbl:res_mt]の「*」は，ベースライン（IBM4及び[MATH](IBM4)）との精度差が有意であることを示す．
また，各タスクで最高精度（IBM4[MATH]を除く）を太字で示す．
表[REF_tbl:res_wa]と表[REF_tbl:res_mt]より，単語アラインメント精度を改善しても，必ずしも翻訳精度が向上するとは限らないことが分かる．
この事は従来より知られており，例えば，[CITE]においても同様の現象が確認されている．
しかしながら，表[REF_tbl:res_mt]より，全ての翻訳タスクで，[MATH]と[MATH]は[MATH](IBM4)とIBM4よりも有意に翻訳精度がよいことが分かる．
この結果から，提案手法は翻訳精度の改善にも寄与することが実験的に確認できる．
また，NTCIR-9とFBISでは，提案モデルは学習データの一部から学習したが，学習データ全てから学習した[MATH]と同等の精度を達成している．
学習データ量の影響は[REF_sect:discuss_size]節で考察する．
提案手法の有効性を検証するため，単語アラインメントの精度及び翻訳精度の評価実験を行った．
単語アラインメントの評価実験は，NAACL 2003のshared task [CITE]で使われたHansardsデータにおける仏英のタスク(Hansards)と，Basic Travel Expression Corpus (BTEC) [CITE]における日英のタスク(IWSLT[MATH])で実施した．
翻訳精度の評価実験は，IWSLT2007における日英翻訳タスク[CITE] (IWSLT)，新聞データから作成されたFBISコーパスにおける中英翻訳タスク(FBIS)，NTCIR-9及びNTCIR-10における日英特許翻訳タスク[CITE] (NTCIR-9, NTCIR-10)で行った．
表[REF_tbl:data]に各タスクで使用する対訳文の数を示す．
「Train」は学習データ，「Dev」はディベロップメントデータ，「Test」はテストデータを表す．
[MATH]及びIWSLTの実験データは共にBTECのデータであり，[MATH]の実験データは，IWSLTの学習データのうち，単語アラインメントが人手で付与された9,960対訳文である[CITE]．
9,960の対訳文の最初の9,000を学習データ，残りの960をテストデータとした．
[MATH]の学習データは単語アラインメントが付与されているラベルあり学習データであるのに対し，Hansardsの学習データは単語アラインメントが付与されてないラベルなし学習データである．
Hansards及び[MATH]のアラインメントタスクでは，各アラインメントモデルのハイパーパラメータは学習データの一部を用いた2分割交差検証により予め決定し，ディベロップメントデータは使わなかった．
また，NAACL 2003のshared taskオリジナルの学習データの総数は約110万文対あるが，今回のHansardsの実験では，学習時の計算量を削減するため，無作為にサンプリングした10万文対を学習データとして用いた．
大規模データの実験は今後の課題とする．
FBISでは，NIST02の評価データをディベロップメントデータとして使い，NIST03とNIST04の各評価データでテストした．
評価実験では，提案手法であるRNNに基づくモデルに加え，ベースラインとして，IBMモデル4とFFNNに基づくモデルを評価した．
また，単語アラインメントタスクにおける合意制約の有効性を考察するため，ベースラインとして，典型的なHMMに基づくアラインメントモデルであるVogelらのモデル[CITE] ([MATH])とこのVogelらのモデルにLiangらの両方向の合意制約[CITE]を導入したモデル([MATH])も評価した．
IBMモデル4は，IBMモデル1-4とHMMに基づくモデルを順番に適用して学習した[CITE]．
具体的には，IBMモデル1，HMMに基づくモデル，IBMモデル2，3，4をこの順で5回ずつ繰り返した([MATH])．
これは，GIZA++のデフォルトの設定である(IBM4)．
[MATH]及び[MATH]はBerkleyAlignerを用いた．
Liangらの通り，IBMモデル1，HMMに基づくモデルを順番に5回ずつ繰り返し，各モデルを学習した[CITE]．
FFNNに基づくモデルでは，word embeddingの長さ[MATH]を30，文脈の窓幅を5とした．
したがって，[MATH]は[MATH]である．
また，隠れ層として，ユニット数[MATH]が100の層を1層使用した．
このFFNNに基づくモデルは，[CITE]に倣って[REF_sect:FFNN]節の教師あり手法により学習したモデル[MATH]に加えて，[REF_sect:usv]節と[REF_sect:agreement]節で提案した教師なし学習や合意制約の効果を確かめるため，[MATH]，[MATH]，[MATH]のモデルを評価した．
「[MATH]」は教師ありモデル，「[MATH]」は教師なしモデル，「[MATH]」は学習時に合意制約を使うことを意味する．
RNNに基づくモデルでは，word embeddingの長さ[MATH]を30，再帰的に連結している隠れ層のユニット数[MATH]を100とした．
したがって，[MATH]は[MATH]である．
また，提案の学習法の効果を検証するため，FFNNに基づくモデル同様，[MATH]，[MATH]，[MATH]，[MATH]の4種類を評価した．
FFNNに基づくモデル及びRNNに基づくモデルの各層のユニット数や[MATH]などのパラメータは，学習データの一部を用いた2分割交差検証により予め設定した．
NNに基づくモデルの学習について説明する．
まず，各層の重み行列を初期化する．
具体的には，lookup層の重み行列[MATH]は，局所解への収束を避けるため，学習データの原言語側と目的言語側からそれぞれ予め学習したword embeddingに初期化する．
その他の重みは，[MATH]のランダムな値に初期化する．
word embeddingの学習には，Mikolovらの手法[CITE]を基にしたRNNLMツールキット（デフォルトの設定）を用いる．
その際，コーパスでの出現数が5回以下の単語は[MATH]に置き換える．
各重みの初期化後は，ミニバッチSGDにより特定の目的関数に従って各重みを最適化する．
本実験では，バッチサイズ[MATH]を100，学習率を0.01とし，50エポックで学習を終えた．
また，学習データへの過学習を避けるため，目的関数には[MATH]正則化項（正則化の比率は0.1）を加えた．
教師なし学習におけるパラメータ[MATH]，[MATH]，[MATH]は，それぞれ，100，50，0.001とし，合意制約に関するパラメータ[MATH]は0.1とした．
翻訳タスクでは，フレーズベース機械翻訳(SMT)システムMoses [CITE]を用いた．
日本語の各文はChaSen，中国語の各文はStanford Chinese segmenterにより単語へ分割した．
その後，40単語以上の文は学習データから除いた．
言語モデルは，SRILMツールキット[CITE]により，modified Kneser-Neyスムージング[CITE]を行い学習した．
IWSLT，NTCIR-9及びNTCIR-10では，学習データの英語側コーパスから構築した5グラム言語モデル，FBISでは，English GigawordのXinhua部分のデータから構築した5グラム言語モデルを使用した．
翻訳モデルは，各単語アラインメント手法により特定されたアラインメント結果に基づいて学習した．
SMTシステムの各パラメータは，ディベロップメントデータを用いてMERT [CITE]によりチューニングした．
表[REF_tbl:res_wa]に各手法の単語アラインメントの精度をF1値で示す．
NNに基づく教師ありモデルに対しては，学習データに付与されている正しい単語アラインメントを学習したモデル(REF)と，IBM4で特定した単語アラインメントを学習したモデル(IBM4)の2種類の精度を示す．
Hansardsの学習データには正しい単語アラインメントが付与されていないため，REFに対する実験は実施していない．
評価手順は，まず，各アラインメントモデルにより，[MATH]と[MATH]のアラインメントをそれぞれ生成する．
その後，「grow-diag-final-and」ヒューリスティックス[CITE]により，両方向のアラインメントを結合する．
そして，その結合したアラインメント結果をF1値で評価する．
有意差検定は，有意差水準5%の符号検定で行った．
具体的には，テストデータの各単語に対して，他方の手法では不正解だが正しく判定したものを[MATH]，他方の手法では正解だが誤って判定したものを[MATH]として，2手法の評価に有意な差があるかどうかを片側検定の符号検定で判定した．
表[REF_tbl:res_wa]中の「[MATH]」は，ベースラインとなるFFNNに基づくモデル[MATH](REF/IBM4)との精度差が有意であることを示し，「[MATH]」は，ベースラインのFFNNに基づくモデル[MATH](REF/IBM4)に加えてIBM4との精度差も有意であることを示す．
また，正しい教師ラベルを使用するモデル(REF)と使用しないモデル（REF以外）のそれぞれで最高の精度を太字で示す．
表[REF_tbl:res_wa]より，[MATH]とHansardsの両タスクにおいて，本論文の提案手法（RNNに基づくモデル，教師なし学習，合意制約）RNN[MATH]が最もアラインメント精度が高いことが分かる．
特に，ベースラインとの精度差は有意であることから，本論文の提案を組み合わせることにより，従来手法より高いアラインメント精度を達成できることが実験的に確認できる．
次に，本論文の各提案の個別の有効性について確認する．
表[REF_tbl:res_wa]より，[MATH]とHansardsの両タスクにおいて，[MATH](IBM4)，[MATH](REF)は，それぞれ，，[MATH](IBM4)，[MATH](REF)よりも精度が良い．
特に，[MATH]では，[MATH](REF)，[MATH](IBM4)と[MATH](REF)，[MATH](IBM4)とのそれぞれの性能差は有意であることが分かる．
これは，RNNに基づくモデルにより長いアラインメント履歴を捉えることで，アラインメント精度が向上することを示しており，RNNを利用したモデルの有効性を確認できる．
ただし，Hansardsにおいては，RNNの効果が少ない．
この言語対による効果の違いについては[REF_sect:discuss_RNN]節で考察する．
[MATH]とHansardsの両タスクにおいて，[MATH](REF/IBM4)，[MATH]のアラインメント精度は，それぞれ，[MATH](REF/IBM4)，[MATH]を上回っており，これらの精度差は有意であった．
さらに，[MATH](REF/IBM4)，[MATH]は，それぞれ，[MATH](REF/IBM4)，[MATH]より有意にアラインメント精度が良い．
この結果より，教師ありと教師なしの両方の学習において，両方向の合意制約を導入することでFFNNに基づくモデル及びRNNに基づくモデルのアラインメント精度を改善できることが分かる．
一方で，HMM[MATH]の方がHMM[MATH]よりも精度が良いことから，提案の合意制約に限らず，両方向の合意をとるようにモデルを学習することは有効であることが確認できる．
HMMに基づくモデルに導入したLiangらの両方向の合意制約と提案の合意制約の傾向の違いは，[REF_sect:discuss_size]節で考察する．
[MATH]では，[MATH]と[MATH]は，それぞれ，[MATH](IBM4)と[MATH](IBM4)より有意にアラインメント精度が良い．
一方で，Hansardsでは，これらの精度は同等である．
この傾向はFFNNに基づくモデルでも同様である．
これは，学習データの質（IBM4の精度）が悪い場合，教師あり学習はIBM4による疑似学習データに含まれる誤りの悪影響を受けるのに対し，提案の教師なし学習は学習データの質に依らずに精度の良いFFNNやRNNに基づくモデルを学習できることを示している．
表[REF_tbl:res_mt]に各手法により付与されたアラインメントを用いたSMTシステムの翻訳精度を示す．
評価尺度は，大文字と小文字を区別したBLEU4 [CITE]を用いた．
MERTの不安定な振る舞いの影響を緩和するため，MERTによるチューニングは3回行い，その平均値を表[REF_tbl:res_mt]に示す[CITE]．
IWSLTでは，アラインメントモデル及び翻訳モデルの学習には学習データ全てを用いた．
一方で，NTCIR-9，NTCIR-10とFBISでは，アラインメントモデルの学習における計算量を削減するため，学習データから無作為にサンプリングした10万文対からアラインメントモデルを学習した．
その後，学習したアラインメントモデルにより学習データ全ての単語アラインメントを自動的に付与し，翻訳モデルを学習した．
また，詳細な比較を行うため，全学習データから学習したIBMモデル4に基づくSMTシステムの精度をIBM4[MATH]として示す．
翻訳精度の有意差検定は，有意差水準5%でブートストラップによる検定手法[CITE]により行った．
表[REF_tbl:res_mt]の「*」は，ベースライン（IBM4及び[MATH](IBM4)）との精度差が有意であることを示す．
また，各タスクで最高精度（IBM4[MATH]を除く）を太字で示す．
表[REF_tbl:res_wa]と表[REF_tbl:res_mt]より，単語アラインメント精度を改善しても，必ずしも翻訳精度が向上するとは限らないことが分かる．
この事は従来より知られており，例えば，[CITE]においても同様の現象が確認されている．
しかしながら，表[REF_tbl:res_mt]より，全ての翻訳タスクで，[MATH]と[MATH]は[MATH](IBM4)とIBM4よりも有意に翻訳精度がよいことが分かる．
この結果から，提案手法は翻訳精度の改善にも寄与することが実験的に確認できる．
また，NTCIR-9とFBISでは，提案モデルは学習データの一部から学習したが，学習データ全てから学習した[MATH]と同等の精度を達成している．
学習データ量の影響は[REF_sect:discuss_size]節で考察する．
