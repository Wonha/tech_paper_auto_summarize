================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.67737] 本論文では，隠れ層の再帰的な構造により，過去のアラインメント履歴全体を活用するリカレントニューラルネットワーク(RNN)による単語アラインメントモデルを提案する．
[i:2, score:0.54598] 提案モデルは，IBMモデル[CITE]などの多くの従来手法と同様に，各方向で独立にアラインメントを学習するため，両方向を考慮した大域的な学習を行うことができない．
[i:5, score:0.65911] 日英及び仏英単語アラインメント実験を通じて，RNNに基づくモデルは，フィードフォワードニューラルネットワークによるモデル[CITE]やIBMモデル4よりも単語アラインメント精度が高いことを示す．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:19, score:0.75920] 一方で，RNNに基づくモデルは，隠れ層の再帰的な構造としてアラインメントの情報を埋め込むことで，FFNNに基づくモデルよりも長い，文頭から直前の単語アラインメントの情報，つまり過去のアラインメント履歴全体を考慮できる．
[i:22, score:0.69085] この状況に対して，Yangらは，従来の教師なし単語アラインメントモデル（IBMモデル，HMMに基づくモデル）により生成した単語アラインメントを疑似の正解データとして使い，モデルを学習した[CITE]．
[i:35, score:0.80090] 評価実験を通じて，前記提案全てを含む「合意制約付き教師なし学習法で学習したRNNに基づくモデル」は，FFNNに基づくモデルやIBMモデル4よりも単語アラインメント精度が高いことを示す．

================================================================
[section type  : proposed_method]
[section title : 従来の単語アラインメントモデル]
================================================================
[i:44, score:0.36707] [REF_sect:SWA]節では生成モデルを概観し，[REF_sect:FFNN]節では識別モデルの一例として，提案手法のベースラインとなるFFNNに基づくモデル[CITE]を説明する．
-----------------------------------------------------
  [subsection title : 生成モデル]
-----------------------------------------------------
  [i:lead, score:0.42654] 生成モデルでは，[MATH]単語から構成される原言語の文を[MATH]，それに対応する[MATH]単語で構成される目的言語の文を[MATH]とすると，[MATH]は[MATH]からアラインメント[MATH]を通じて生成されると考える．
.....
  [i:49, score:0.58225] IBMモデル1，2やHMMに基づくモデルでは，式([REF_eqn:base1])中の特定アラインメント[MATH]との生成確率[MATH]をアラインメント確率[MATH]と語彙翻訳確率[MATH]で定義する：
  [i:53, score:0.49185] これらのモデルは，EMアルゴリズム[CITE]により，単語単位のアラインメントが付与されていない対訳文の集合（ラベルなし学習データ）から学習される．
  [i:54, score:0.51516] また，ある対訳文([MATH], [MATH])の単語アラインメントを解析する際は，学習したモデルを用いて，次式([REF_eqn:viterbi_alignment])を満たすアラインメント（ビタビアラインメント）[MATH]を求める：
-----------------------------------------------------
  [subsection title : FFNNに基づく単語アラインメントモデル]
-----------------------------------------------------
  [i:lead, score:0.41194] FFNNは，非線形関数を持つ隠れ層を備えることにより，入力データから多層的に非線形な素性を自動的に学習することができ，入力データの複雑な特徴を捉えることができる．
.....
  [i:60, score:0.60848] FFNNに基づくモデルは，式([REF_eqn:base2])のアラインメント確率[MATH]及び語彙翻訳確率[MATH]をFFNNにより計算する：
  [i:65, score:0.57301] アラインメントスコアは直前のアラインメント[MATH]に依存しているため，FFNNに基づくモデルも単純マルコフ過程に従う．
  [i:85, score:0.63419] ここで，[MATH]は最適化するパラメータ（重み行列の重み），[MATH]は学習データ，[MATH]はパラメータ[MATH]のモデルによる[MATH]のスコア（式([REF_eqn:FFNN])参照），[MATH]は正解アラインメント，[MATH]はパラメータ[MATH]のモデルでスコアが最も高い不正解アラインメントである．

================================================================
[section type  : proposed_method]
[section title : RNNに基づく単語アラインメントモデル]
================================================================
[i:87, score:0.58250] ここで，[MATH]はアラインメント[MATH]のスコアであり，FFNNに基づくモデルと異なり，直前のアラインメント[MATH]だけでなく，[MATH]個の全てのアラインメントの履歴[MATH]に依存している．
[i:112, score:0.69160] 一方で，RNNに基づくモデルは，直前のアラインメントとの距離[MATH]に依存した重み行列を隠れ層で使うことで，アラインメントと語彙翻訳の両者を考慮する1つのモデルで単語アラインメントをモデル化する．
[i:114, score:0.68669] このため，過去のアラインメント履歴全体をこの隠れ層の入出力[MATH]にコンパクトに埋め込むことで，直前のアラインメント履歴のみに依存する従来のFFNNに基づくモデルよりも長いアラインメント履歴を活用して単語アラインメントを行うことができる．

================================================================
[section type  : proposed_method]
[section title : モデルの学習]
================================================================
[i:119, score:0.44001] 提案モデルは，FFNNに基づくモデル同様，式([REF_eqn:FFNN3])で定義されるランキング損失に基づいて教師あり学習することができる（[REF_sect:FFNN]節参照）．
[i:120, score:0.37172] しかし，この学習法は正解の単語アラインメントが必要であるという問題がある．
[i:121, score:0.28590] この問題を解決するため，次の[REF_sect:usv]節で，ラベルなし学習データから提案モデルを学習する教師なし学習法を提案する．
-----------------------------------------------------
  [subsection title : 教師なし学習]
-----------------------------------------------------
  [i:lead, score:0.29017] 本節で提案する教師なし学習は，Dyerらにより提案されたcontrastive estimation (CE) [CITE]に基づく教師なし単語アラインメントモデル[CITE]を拡張した手法である．
.....
  [i:124, score:0.51658] Dyerらは，ラベルなし学習データ中の対訳文[MATH]において考えられる全ての単語アラインメントを観測データ，目的言語側を単語空間[MATH]全体とした単語アラインメント，つまり，対訳文[MATH]中の原言語の各単語と[MATH]中の各単語との全単語対を近傍データとしてCEを適用した．
  [i:126, score:0.40377] ここで，[MATH]は対訳文[MATH]に対する全ての単語アラインメントの集合，E[MATH]は[MATH]におけるスコア[MATH]の期待値を表す．
  [i:140, score:0.52280] [MATH]正則化付きIBMモデル1は，単純なIBMモデル1と比較して，より疎なアラインメントを生成するため，疑似翻訳[MATH]の候補の範囲を制限することが可能となる．
-----------------------------------------------------
  [subsection title : 両方向の合意制約]
-----------------------------------------------------
  [i:lead, score:0.42328] FFNNに基づくモデルとRNNに基づくモデルは，共に方向性を持つモデルである．
.....
  [i:142, score:0.44402] すなわち，[MATH]に対する[MATH]のアラインメントモデルにより，単語[MATH]に対して[MATH]との1対多アラインメントを表す．
  [i:143, score:0.45629] 通常，方向性を持つモデルは方向毎に独立に学習され，両方向のアラインメント結果をヒューリスティックに結合し決定される．
  [i:145, score:0.48245] 一方で，各方向のモデルの合意を取るように同時に学習することで，アラインメント精度を改善できることが示されている．

================================================================
[section type  : experiment_result]
[section title : 評価実験]
================================================================
-----------------------------------------------------
  [subsection title : 実験データ]
-----------------------------------------------------
  [i:lead, score:0.38774] 提案手法の有効性を検証するため，単語アラインメントの精度及び翻訳精度の評価実験を行った．
.....
  [i:161, score:0.49097] 単語アラインメントの評価実験は，NAACL 2003のshared task [CITE]で使われたHansardsデータにおける仏英のタスク(Hansards)と，Basic Travel Expression Corpus (BTEC) [CITE]における日英のタスク(IWSLT[MATH])で実施した．
  [i:165, score:0.48111] [MATH]及びIWSLTの実験データは共にBTECのデータであり，[MATH]の実験データは，IWSLTの学習データのうち，単語アラインメントが人手で付与された9,960対訳文である[CITE]．
  [i:167, score:0.45437] [MATH]の学習データは単語アラインメントが付与されているラベルあり学習データであるのに対し，Hansardsの学習データは単語アラインメントが付与されてないラベルなし学習データである．
-----------------------------------------------------
  [subsection title : 実験対象]
-----------------------------------------------------
  [i:lead, score:0.51557] 評価実験では，提案手法であるRNNに基づくモデルに加え，ベースラインとして，IBMモデル4とFFNNに基づくモデルを評価した．
.....
  [i:172, score:0.51557] 評価実験では，提案手法であるRNNに基づくモデルに加え，ベースラインとして，IBMモデル4とFFNNに基づくモデルを評価した．
  [i:182, score:0.53525] このFFNNに基づくモデルは，[CITE]に倣って[REF_sect:FFNN]節の教師あり手法により学習したモデル[MATH]に加えて，[REF_sect:usv]節と[REF_sect:agreement]節で提案した教師なし学習や合意制約の効果を確かめるため，[MATH]，[MATH]，[MATH]のモデルを評価した．
  [i:187, score:0.51474] FFNNに基づくモデル及びRNNに基づくモデルの各層のユニット数や[MATH]などのパラメータは，学習データの一部を用いた2分割交差検証により予め設定した．
-----------------------------------------------------
  [subsection title : 実験結果（単語アラインメント）]
-----------------------------------------------------
  [i:lead, score:0.42409] 表[REF_tbl:res_wa]に各手法の単語アラインメントの精度をF1値で示す．
.....
  [i:215, score:0.73631] 表[REF_tbl:res_wa]より，[MATH]とHansardsの両タスクにおいて，本論文の提案手法（RNNに基づくモデル，教師なし学習，合意制約）RNN[MATH]が最もアラインメント精度が高いことが分かる．
  [i:225, score:0.76495] この結果より，教師ありと教師なしの両方の学習において，両方向の合意制約を導入することでFFNNに基づくモデル及びRNNに基づくモデルのアラインメント精度を改善できることが分かる．
  [i:231, score:0.60509] これは，学習データの質（IBM4の精度）が悪い場合，教師あり学習はIBM4による疑似学習データに含まれる誤りの悪影響を受けるのに対し，提案の教師なし学習は学習データの質に依らずに精度の良いFFNNやRNNに基づくモデルを学習できることを示している．
-----------------------------------------------------
  [subsection title : 実験結果（機械翻訳）]
-----------------------------------------------------
  [i:lead, score:0.44269] 表[REF_tbl:res_mt]に各手法により付与されたアラインメントを用いたSMTシステムの翻訳精度を示す．
.....
  [i:232, score:0.44269] 表[REF_tbl:res_mt]に各手法により付与されたアラインメントを用いたSMTシステムの翻訳精度を示す．
  [i:237, score:0.52995] その後，学習したアラインメントモデルにより学習データ全ての単語アラインメントを自動的に付与し，翻訳モデルを学習した．
  [i:242, score:0.46347] 表[REF_tbl:res_wa]と表[REF_tbl:res_mt]より，単語アラインメント精度を改善しても，必ずしも翻訳精度が向上するとは限らないことが分かる．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
-----------------------------------------------------
  [subsection title : RNNに基づくモデルの効果]
-----------------------------------------------------
  [i:lead, score:0.39868] 図[REF_fig:wa]に[MATH]及び[MATH]で解析した単語アラインメントの具体例を示す．
.....
  [i:252, score:0.65943] [REF_sect:res_alignment]節で述べた通り，RNNに基づくモデルの効果は，日英アラインメント([MATH])と比べて仏英アラインメント(Hansards)に対して少ない．
  [i:253, score:0.41429] これは，英語とフランス語は語順が似ていて，日英に比べて1対1アラインメントが多く（図[REF_fig:wa]参照），仏英単語アラインメントは局所的な手がかりで捉えられる場合が多いためであると考えられる．
  [i:254, score:0.43792] 図[REF_fig:wa](b)は，このような単純な単語アラインメントは，[MATH]と[MATH]の両モデルで正しく解析できることを示している．
-----------------------------------------------------
  [subsection title : 学習データ量の影響]
-----------------------------------------------------
  [i:lead, score:0.46463] BTECにおける日英アラインメントタスクにおいて様々なサイズの学習データを使った時のアラインメント精度を表[REF_tbl:size]に示す．
.....
  [i:255, score:0.46463] BTECにおける日英アラインメントタスクにおいて様々なサイズの学習データを使った時のアラインメント精度を表[REF_tbl:size]に示す．
  [i:256, score:0.45353] 「40 K」，「9 K」，「1 K」は，それぞれ，IWSLTの全学習データ，[MATH]の全学習データ，[MATH]の全学習データから無作為に抽出した1,000文対を学習データとした時の，[MATH]のテストデータに対するアラインメント精度である．
  [i:260, score:0.41845] すなわち，RNNに基づくモデルは，IBM4の学習データの22.5%以下(9,000/40,000)のデータから同等の精度を持つモデルを学習できたことが分かる．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[i:268, score:0.63029] また，RNNに基づくモデルの学習法として，Dyerらの教師なし単語アラインメント[CITE]を拡張して人工的に作成した負例を利用する教師なし学習法を提案した．
[i:270, score:0.70580] 複数の単語アラインメントタスクと翻訳タスクの実験を通じて，RNNに基づくモデルは従来のFFNNに基づくモデル[CITE]よりアラインメント精度及び翻訳精度が良いことを示した．
[i:272, score:0.58351] 提案モデルでは，アラインメント対象の文脈をアラインメント履歴([MATH])に暗示的に埋め込み利用しているが，今後は，FFNNに基づくモデルのように周辺単語の入力（[MATH]や[MATH]）として明示的に利用することも検討したい．

