表[REF_tbl:res_wa]に各手法の単語アラインメントの精度をF1値で示す．
NNに基づく教師ありモデルに対しては，学習データに付与されている正しい単語アラインメントを学習したモデル(REF)と，IBM4で特定した単語アラインメントを学習したモデル(IBM4)の2種類の精度を示す．
Hansardsの学習データには正しい単語アラインメントが付与されていないため，REFに対する実験は実施していない．
評価手順は，まず，各アラインメントモデルにより，[MATH]と[MATH]のアラインメントをそれぞれ生成する．
その後，「grow-diag-final-and」ヒューリスティックス[CITE]により，両方向のアラインメントを結合する．
そして，その結合したアラインメント結果をF1値で評価する．
有意差検定は，有意差水準5%の符号検定で行った．
具体的には，テストデータの各単語に対して，他方の手法では不正解だが正しく判定したものを[MATH]，他方の手法では正解だが誤って判定したものを[MATH]として，2手法の評価に有意な差があるかどうかを片側検定の符号検定で判定した．
表[REF_tbl:res_wa]中の「[MATH]」は，ベースラインとなるFFNNに基づくモデル[MATH](REF/IBM4)との精度差が有意であることを示し，「[MATH]」は，ベースラインのFFNNに基づくモデル[MATH](REF/IBM4)に加えてIBM4との精度差も有意であることを示す．
また，正しい教師ラベルを使用するモデル(REF)と使用しないモデル（REF以外）のそれぞれで最高の精度を太字で示す．
表[REF_tbl:res_wa]より，[MATH]とHansardsの両タスクにおいて，本論文の提案手法（RNNに基づくモデル，教師なし学習，合意制約）RNN[MATH]が最もアラインメント精度が高いことが分かる．
特に，ベースラインとの精度差は有意であることから，本論文の提案を組み合わせることにより，従来手法より高いアラインメント精度を達成できることが実験的に確認できる．
