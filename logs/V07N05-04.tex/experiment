実験結果\label{sec:result}

３つ組／４つ組モデルを用いた係り受け解析の実験環境と用いた素性、
及び実験結果を示す。
さらに、学習コーパスの量を変えた実験や、
３つ組／４つ組モデルを導入したことの効用を確かめるための対照実験の結果を載せる。

\subsection{実験環境}\label{subsec:env}

EDR日本語コーパス\cite{EDR}の208,157文
\footnote{このうち、括弧付けの順番が逆転している5,263文は除外した。}のうち、
192,778文を学習、3,372文をテストに用いた。
\ref{subsec:restrict}節で述べたような観察や、
次節で述べる考察などにはその他の6,744文を用いている。
これは、テストコーパスの解析結果を人が見てモデルを修正することによる
コーパスへの特化を防ぐためである。

前節で述べた通り、係り先の候補が２つの場合のための「３つ組モデル」と
候補が３つ以上の場合のための「４つ組モデル」の二つのモデルを別個に作る。
学習コーパス中の文をSLUNGで構文解析して、
係り先候補が２つである文節に対して、
係り元文節と２つの係り先候補の属性の組を履歴として「３つ組モデル」を構成する。
そして、係り先候補が３つ以上である文節に対しては、
\ref{subsec:restrict}節で述べた方法で候補を３つに制限し、
係り元文節と３つの係り先候補の属性の組を履歴として「４つ組モデル」を構成する。
これらは最大エントロピー法のツール 
ChoiceMaker Maximum Entropy Estimator\cite{Borthwich99}を使って推定される。

推定の際に用いた素性を表\ref{tab:features}~に示す。
素性の値は\cite{Haruno98}~\cite{Uchimoto99}に倣っており、
品詞の分類などにはJUMANの出力結果を用いている。但し、
京大コーパスを用いた実験と違って、
形態素解析の正解は与えられておらず、誤りを含む場合がある。

以下で各素性について解説する。なお、
{\bf 主辞}とは、
品詞大分類が「特殊」「助動詞」「助詞」「接尾辞」「判定詞」の
いずれかであるものを除いて、文節内で最も右側にある語、
{\bf 語形}とは、
品詞大分類が「特殊」であるものを除いて、文節内で最も右側にある語である。


\begin{description}
\item[品詞] 語形・主辞ともに、JUMANの品詞細分類が用いられる。
\item[助詞・副詞] 頻度の高い26種の助詞と69種の副詞。
\item[主辞語彙] 品詞に依らず、主辞として現れる語のうち頻度の高い294種の語彙。
\item[語形語彙] 品詞が「助動詞」「接尾辞」のうち、頻度の高い70種の語彙。
\item[活用形] JUMANの出力する活用形を、
「基本形」「連用形」「連体形」「テ形」「タ形」「その他」の６種に分類したもの。
\item[文節間読点の数・「は」の数]
係り元と係り先の文節間にある読点の数を、「0」「1」「2」「3以上」の４値で表す。
同様に、副助詞「は」の数を 「0」「1」「2以上」の３値で表す。
\end{description}

表\ref{tab:features}~中の「異なり数」とは各素性の取りうる値の総数であり、
素性番号19〜27の組み合わせ素性に関しては、それぞれの要素の積を記してある。
実際には、履歴の数と出力値の数（2または3）の積だけの素性が用いられる。
また、係り先に関する素性（素性番号8〜27）は、それぞれの係り先候補（３つ組モデルでは２つ、
４つ組モデルでは３つ）に対して素性が割り振られる
\footnote{例として、14の係り先読点の素性は、
３つ組モデルに対しては、２つの候補それぞれに対して
読点の有無を考え、さらに「第一候補に係る場合」「第二候補に係る場合」の
二つの出力値があるため、$2 \times 2 \times 2 = 8$、
同様に４つ組モデルに対しては $2 \times 3 \times 3 = 18$の素性がある。}。
このうち、コーパス中で３回以上出現したものが有効素性となる。

\begin{table}
	\begin{center}
	\begin{tabular}{|c|l|r|r|r|}
	\hline 
	\multicolumn{1}{|c|}{素性} &
	\smash{\lower2.0ex\hbox{素性の種類}} & 
	\smash{\lower2.0ex\hbox{異なり数}} &
	\multicolumn{2}{c|}{有効素性数} \\
	\cline{4-5} 番号 & & & ３つ組 & ４つ組 \\
	\hline \hline
	1 & 係り元主辞品詞 & 24 & 42 & 64 \\ \hline
	2 & 係り元語形品詞 & 34 & 66 & 99 \\ \hline
	3 & 係り元助詞 & 27 & 47 & 73 \\ \hline
	4 & 係り元副詞 & 70 & 131 & 193 \\ \hline
	5 & 係り元語形語彙 & 71 & 110 & 225 \\ \hline
	6 & 係り元活用形 & 6 & 12 & 18 \\ \hline
	7 & 係り元読点の有無 & 2 & 4 & 6 \\ \hline \hline
	8 & 係り先主辞品詞 & 24 & 70 & 158 \\ \hline
	9 & 係り先語形品詞 & 34 & 96 & 231 \\ \hline
	10 & 係り先主辞語彙 & 295 & 1164 & 2597 \\ \hline
	11 & 係り先助詞 & 27 & 92 & 204 \\ \hline
	12 & 係り先語形語彙 & 71 & 216 & 454 \\	\hline
	13 & 係り先活用形 & 6 & 24 & 53 \\ \hline
	14 & 係り先読点の有無 & 2 & 8 & 18 \\ \hline
	15 & 係り先「は」の有無 & 2 & 8 & 18 \\ \hline
	16 & 係り先引用「と」の有無 & 2 & 6 & 17 \\ \hline
	17 & 文節間読点の数 & 4 & 16 & 36 \\ \hline
	18 & 文節間「は」の数 & 3 & 12 & 27 \\ \hline \hline
	19 & 係り元語形品詞×係り先主辞品詞 & 816 & 1187 & 2727 \\ \hline 
	20 & 係り元語形品詞×係り元読点×係り先読点 & 136 & 380 & 870 \\ \hline 
	21 & 係り元助詞×係り先主辞語彙 & 7965 & 6465 & 13463 \\ \hline
	22 & 係り元語形品詞×係り先語形品詞 & 1156 & 1213 & 3108 \\ \hline
	23 & 係り元助詞×係り先助詞 & 729 & 618 & 1637 \\ \hline
	24 & 係り元語形品詞×係り先助詞 & 918 & 1025 & 2494 \\ \hline
	25 & 係り元語形品詞×係り先語形語彙 & 2414 & 1483 & 3514 \\ \hline
	26 & 係り元語形品詞×助詞×読点の有無×係り先主辞品詞 & 132192 & 1331 & 3058 \\ \hline
	27 & 係り元主辞品詞×語形品詞×活用形×係り先主辞品詞×活用形 & 705024 & 6605 & 14700 \\ \hline
	\hline & 合計 & - & 22433 & 50063 \\ \hline
	\end{tabular}
	\caption{用いた素性 \\
	{\footnotesize 8番以降の素性は、係り先に関する素性なので、
	２つまたは３つの全ての候補に対して考える。}} \label{tab:features}
	\end{center}
\end{table}

\subsection{実験結果}\label{subsec:result}

\ref{subsec:env}~に記したコーパスに対する、次の２つの精度を
測定した結果を表\ref{tab:result}~に示す。

\begin{description}
\item[文節正解率] 
	文中の最後の文節を除く全ての文節に対して、
	その係り先が正解と一致する割合。
	表\ref{tab:result}~においてのみ、
	後ろから二番目の文節（可能な係り先が最後の文節のみであるので、
	必ず正解する）を除外した値を参考のために載せてある。
\item[文正解率]
	一文中の係り受けが全て正解する文の割合。
	なお、テストコーパスの平均文節数は8.82である。
\end{description}

なお、「解析成功文」とは、
テストコーパスのうち構文解析が成功した文、
即ちSLUNGが少なくとも一つの構文木を返した3,326文
（全体の98.63$\%$にあたる）に対する正解率を測ったものである。
また、参考のためにコーパス中の「すべての文」に対しての精度も測っている。
SLUNGでの構文解析が失敗した文に関しては、
各係り元文節に対して最も高い確率が割り振られた候補を決定的に係り先と判定し、
どの候補にも係り得ないとされた文節は隣の文節を修飾すると仮定して正解率を測った。

表\ref{tab:result}~は学習コーパスの約19万文を全て用いた時の値である。
学習コーパスの量を変えた時の解析成功文に対する文節正解率を図\ref{fig:graph}~に示す。

\begin{table}
	\begin{center}
	\begin{tabular}{|l|l|rc|}
	\hline
	\smash{\lower3.0ex\hbox{解析成功文}} & 
	文節正解率 & {\bf 88.55$\%$} & (23078/26062) \\
	& 　　　（後ろから二番目の文節を除く場合） & 86.88$\%$ & (19752/22736) \\
	\cline{2-4}
	& 文正解率   & 46.90$\%$ & (1560/3326) \\
	\hline
	\smash{\lower3.0ex\hbox{すべての文}} & 
	文節正解率 & 88.33$\%$ & (23350/26436) \\
	& 　　　（後ろから二番目の文節を除く場合） & $86.62\%$ & (19978/23064) \\
	\cline{2-4}
	& 文正解率   & 46.35$\%$ & (1563/3372) \\
	\hline
	\end{tabular}
	\caption{学習に19万文を用いたときの解析精度}
	\label{tab:result}
	\end{center}
\end{table}

\begin{figure}[t]
	\begin{center}
	\small
	\setlength{\unitlength}{.15mm}
	\begin{picture}(600,270)
	\put(30,30){\vector(1,0){600}}
	\put(30,30){\vector(0,1){260}}
	\put(60,49){\circle*{7}}
	\put(90,91){\circle*{7}}
	\put(120,120){\circle*{7}}
	\put(150,142){\circle*{7}}
	\put(180,146){\circle*{7}}
	\put(210,166){\circle*{7}}
	\put(240,177){\circle*{7}}
	\put(270,185){\circle*{7}}
	\put(300,184){\circle*{7}}
	\put(330,185){\circle*{7}}
	\put(360,186){\circle*{7}}
	\put(390,182){\circle*{7}}
	\put(420,181){\circle*{7}}
	\put(450,188){\circle*{7}}
	\put(480,198){\circle*{7}}
	\put(510,195){\circle*{7}}
	\put(540,203){\circle*{7}}
	\put(570,209){\circle*{7}}
	\put(600,205){\circle*{7}}
	\path(60,49)(90,91)(120,120)(150,142)(180,146)(210,166)
		(240,177)(270,185)(300,184)(330,185)(360,186)
		(390,182)(420,181)(450,188)(480,198)(510,195)
		(540,203)(570,209)(600,205)
 	\multiput(30,50)(10,0){59}{\line(1,0){3}}
 	\multiput(30,150)(10,0){59}{\line(1,0){3}}
 	\multiput(30,250)(10,0){59}{\line(1,0){3}}
	\put(-10,45){\makebox(30,10){87.0}}
	\put(-10,145){\makebox(30,10){88.0}}
	\put(-10,245){\makebox(30,10){89.0}}
	\put(-10,265){\makebox(30,10){($\%$)}}
	\put(160,10){\makebox(40,10){5}}
	\put(310,10){\makebox(40,10){10}}
	\put(460,10){\makebox(40,10){15}}
	\put(600,10){\makebox(40,10){（万文）}}
	\end{picture}
	\caption{学習コーパスの量と文節正解率の関係}
	\label{fig:graph}
	\end{center}
\end{figure}

\subsection{対照実験}\label{subsec:control_exp}

\ref{sec:ourmodel}~節で述べた３つ組／４つ組モデルの有効性を示すために、
以下のような対照実験を行った。
これらのモデルでは、
他の統計的係り受け解析モデル\cite{Fujio99}~\cite{Haruno98}~\cite{Uchimoto99}と同様に、
二つの文節及び文節間の属性から、二文節間の係りやすさを独立に計算する。
また、係り先候補の中での位置を出力とする代わりに、
係り元と係り先の文節間の距離（「１」「２から５」「６以上」の３値）を導入している。
ME法による推定において\ref{subsec:env}~節に示した素性と同じ素性を使っており、
その全てに対して上記の距離の属性を組み合わせている。

\begin{description}
\item[文法なしモデル]
文法を用いて候補を絞ることをせず、係り元文節より右側の全ての文節に対して統計値を求める。
係り元・係り先文節の属性と文節間距離などを用いて、
二文節があった時にそれが係り受け関係にある確率を計算する。
これは概ね、他の研究と同様のモデルである。
\item[候補限定なしモデル]
構文解析の結果文法が許した係り先に対してのみ、
文法なしモデルと同様、係り元・係り先属性と文節間距離から係る確率を求める。
\item[２つ組モデル]
文法が許す係り先候補を、
\ref{subsec:restrict}~節で述べた方法で３つに絞って、その３つに対してのみ統計値を求める。
上記のモデルと同様、係り元・係り先属性と文節間距離から、係る確率を求める。
なお、考慮する係り先候補は３つ組／４つ組モデルの時と同じになる。
\end{description}

対照実験の結果は表\ref{tab:control_exp}~の通りである。
「３つ組／４つ組モデル」は「２つ組モデル」と比べて
精度が0.9$\%$ほど向上している。
このデータから、３つ組／４つ組モデルが有効であることを
次節にて論じる。

\begin{table}[t]
	\begin{center}
	\begin{tabular}{|l|cccc|rc|rc|}
	\hline
	 & G & H & T & D &
	   \multicolumn{2}{c|}{解析成功文} & 
	   \multicolumn{2}{c|}{すべての文} \\
	\hline \hline
	文法なしモデル & $-$ & $-$ & $-$ & $+$ & 86.70$\%$ & (22594/26062) & 86.61$\%$ & (22895/26436) \\
	\hline
	候補限定なしモデル & $+$ & $-$ & $-$ & $+$ & 87.37$\%$ & (22770/26062) & $87.18\%$ & (23046/26436) \\
	\hline
	２つ組モデル & $+$ & $+$ & $-$ & $+$ & 87.67$\%$ & (22849/26062) & $87.49\%$ & (23128/26436) \\ 
	\hline
	３つ組／４つ組モデル & + & + & + & $-$ & 88.55$\%$ & (23078/26062) 
		& 88.33$\%$ & (23350/26436) \\
	\hline
	\end{tabular}
	\caption{対照実験の結果（文節正解率）\\
	{\footnotesize G, H, T, D はそれぞれ「文法の利用」「候補を３つに限定」「３つ組／４つ組モデル」} \\
	{\footnotesize 「文節間距離属性の利用」の有無を表す。}}
	\label{tab:control_exp}
	\end{center}
\end{table}


