
自然発話旅行会話データベース[CITE]を用いて形態素解析の評価実験を行った．
本データベースには，間投詞や感動詞のほか，ら抜き表現，助詞落ち等の自然発話特有の言語現象が頻出する．
また，本データベースは旅行会話という限定された内容の言語データであるが，実際のアプリケーションを想定した連続音声認識システムとしては，情報案内システム[CITE]・予約システム[CITE]等用途を限定し音声認識の精度を向上させている例が多く，このような内容の限定されたデータで評価を行うことは適切であると考えられる．
データベースは，1,334対話，44,091文，559,711形態素から成り，語いは7,724語である．
このうち，約４分の１(334対話, 11,321文，137,691形態素)を評価用データとし，残り(1, 000対話，32,770文，402,020形態素)を言語モデル学習に使用した．
形態素解析精度の比較対象として，複合N-gramと形態素N-gram，および品詞N-gramを構築した．
複合N-gramは，活用形，および活用型を含めた234品詞を初期状態とし，最大2,000クラスまで分離を行い，500分離おきにデータを採取した．
また，形態素N-gram，品詞N-gram，複合N-gramともに，形態素および品詞クラスの遷移確率をback-off Smoothing [CITE]により学習データに出現しない形態素および品詞クラス遷移に対して[MATH]でない確率を与えた．
また，本節の実験では，辞書には学習データ，評価データに出現する全ての形態素が登録されており，未知語は存在しない．
ただし，学習データに出現しない形態素に対する遷移確率は，全てのモデルにおいて1/(100*語数)という確率を与えた．
これは，他に候補が無い場合はこの形態素を割り当てるために，０でない小さい値を与えることを目的としている．
形態素の正解率の評価には，音声認識で広く用いられている単語正解率(Accuracy)にならい形態素Accuracyを用いた．
形態素Accuracy(%)は下式で表される．
ただし，W:正解の形態素数，S:置換誤り形態素数，D:削除誤り形態素数，I:挿入誤り形態素数を表す．
通常，形態素解析では，形態素の分割が正しく，かつ付与された品詞が正しければ，正解とみなされれる．
この場合の形態素Accuracy(%)を表[REF_tbl:ModelComparison1]に示す．
また，形態素解析結果を音声認識に用いることを考えると，同一品詞の形態素でも読みが異なるものは，別単位として扱うことが好ましい．
形態素に読みまで考慮した場合のた場合の形態素Accuracy(%)を表[REF_tbl:ModelComparison2]に示す．
ただし，読みの推定は，表記が同一の形態素でも読みが異なるものは別の形態素として扱い，異なる単位としてN-gramを構築し形態素解析を行うことにより実現している．
表中で下線を付した値が，その次数の複合N-gramの最高の形態素正解率を示す．
表[REF_tbl:ModelComparison1]および[REF_tbl:ModelComparison2]より，いずれの評価の場合も，複合N-gramの最も高い形態素正解率は，同次数の形態素N-gramおよび品詞N-gramよりも高い正解率を得ることができ，複合N-gramの他のモデルに対する優位性が実験的に示された．
形態素正解率最高の値を与える分離クラス数は，品詞のみの評価の場合は分離クラス数500，読みも含めた評価の場合は分離クラス1000であり，それ以上増やしても逆に形態素正解率は低下する傾向にある．
これは，クラス数が増加すると共に，パラメータ数も増加するため，各パラメータの確率推定が正しく行われないことに起因すると考えられる．
このため，適切なクラス数を決定する必要があるが，これは，ニューラルネットワークの学習回数の決定等で用いられるCross Validationの手法を用いることにより，適切なクラス数を実験的に求めることができる．
以下に手順を示す．
学習データの一部を仮想的なテストデータとする
クラス数を徐々に増加させながらN-gramを学習する
仮想的なテストデータに対し形態素解析を行い，形態素解析の性能が頭打ちになる所をクラス数とする
３種類のモデルを比較すると，品詞N-gramは読みを含めた評価の場合に他のモデルと比較して形態素正解率が著しく低下している．
これは，ある形態素の読みはその前後の形態素の読みに影響されると考えられるが，品詞という枠組みでは，前後の読みの関係が表現できないためと考えられる．
形態素N-gramと複合N-gramでは，読みまで含めた形態素を単位として扱うことができるため，このような大きな低下は見られない．
また，複合N-gramと形態素N-gramとの正解率の差は大きくはないが，５章で示した未知語処理の容易さとを考えると，複合N-gramが有利である．
また，山本らの手法[CITE]では，タグなしコーパスから形態素ネットワークを生成する際に，ノイズを調整するための信頼性係数なるパラメータを変化させると，隠れマルコフモデルと品詞BigramおよびTrigramの形態素解析の精度は同等であると報告されている．
しかし本実験の結果では，品詞Bigram，品詞Trigram，形態素Bigram，形態素Trigramの順に精度が向上しており，正解形態素列を学習させることにより，モデル化能力が形態素解析の正解率に反映されていると考えられる．
また，複合N-gramは，複合Bigramでさえ隠れマルコフモデルよりもモデル化能力が高いとされる品詞Trigramよりも形態素の精度が高くなっている．
従って，山本らの手法と比較し，正解形態素列を与えること，および複合N-gramを使用することにより，精度の高い形態素解析が可能であることが示せた．
前節の実験で，約40万語のデータより構築した複合N-gramモデルは，読みまで考慮した形態素解析率が98%以上の，高い解析率が得られることが分かった．
しかし，40万語の形態素データを集めることはそれほど容易ではなく，連続音声認識に使用するN-gramを学習するための，大量の形態素データを容易に集めるという本研究の目的と矛盾する．
従って，データ量が少ない時にどの程度の形態素解析率が得られるかは，本論文の趣旨において重要なことである．
これを調査するため，前節の実験で用いたデータを量を1/2,1/4から最小1/64とした時の形態素正解率を調べた．
言語モデルには，複合Bigramの分離クラス数500と1000を用い，形態素正解率は読みも含めた場合の形態素Accuracyで評価した．
実験結果を[REF_tbl:DataAmount]に示す．
表[REF_tbl:DataAmount]より，データ量が減少するに比例して，形態素正解率は低下することが分かる．
しかし，データ量が全体の1/64の場合は，形態素数がわずか6,306であるが，このような非常に少ない量の学習データから構築したモデルでも，94%程度の比較的高い正解率が得られる．
94%の形態素正解率は自動で形態素解析を行うには高い精度とは言えないが，自動形態素解析の結果を見て，人手で誤り個所を修正するような，半自動の形態素解析としては，使用に耐える性能であると考える．
全学習データを使用した場合は，複合Bigramの分離クラス数1000の場合が分離クラス数500の場合よりも正解率が高いが，データ量が減少するにつれて，正解率は逆転している．
これは，パラメータ数の多い分離クラス1000のモデルでは，データ量が少ない場合では，正確なパラメータ値を推定することが困難になることが原因であると考えられる．
以上より，大量の形態素データを得るためには，まず，数千形態素程度のデータを人手で作成し，クラス数の少ない複合N-gramを構築して半自動の形態素解析を行い，数十万形態素程度のデータが集まった段階で，クラス数の大きい複合N-gramを構築し，その後は自動で形態素解析を行う，というのが効果的な手段であると考えられる．
以下に，この作業に必要なコストについて検討した．
まず，最初のN-gram学習用の形態素データを作成する必要があるが，これは，１形態素のデータ作成に１分あれば十分であるとして，6,000形態素のデータ作成にかかる時間は，１分×6,000＝6000分＝100時間である．
これを基にして作成した複合N-gramで95%程度の正解率が得られるため，形態素解析したデータの修正には，1形態素あたりでは形態素データ作成時の1/20の3秒程度で可能であると考えられる．
40万形態素のデータを作成するためには，40万×3秒＝120万秒＝2万分＝約333時間となる．
一日８時間労働としても，２ヶ月程度で正解率98%以上の形態素解析システムの構築が可能であることになる．
また，修正を行うだけなら比較的単純な作業であり，多数の人間で平行して行うことができるため，さらにシステム構築の期間を短縮することが可能である．
なお，以上の議論では文章データ収集のためのコストを無視している．
しかし，英語・日本語に限らず音声認識システムを構築するためには文章データを収集することは必須の作業であり，この部分のコストに関してし議論するのは無意味である．
このため形態素解析の作業量のみを議論した．
形態素解析システムJUMAN [CITE] (Version 3.5)との比較により，従来のルールベースの形態素解析に対する有効性を示す．
ただし，我々の形態素解析とJUMANとでは，用いている形態素の体系や辞書に登録されている形態素の語数等が異なるため，できるだけ公平になるよう次のような方法で比較を行った．
辞書サイズの均等化
辞書サイズが，本論文の実験では約7千語であるのに対しJUMANでは約58万語あり，さらに，本論文の実験では評価データの全ての形態素が登録されている等，条件はJUMANが圧倒的に不利である．
このため，名詞，動詞，形容詞等の自立語の語彙を我々のシステムと同一にした．
ただし，「えー」「あのー」等の語は我々のシステムでは間投詞としているが，JUMANには間投詞という品詞は存在しないため感動詞とした．
評価方法
我々のシステムとJUMANとでは形態素の体系が異なり，評価データに対してJUMANの形態素体系の正解は存在しない．
このため，提案方法よびJUMAN共に，形態素解析結果を目視して正誤の判定を行った．
ただし，形態素の切り分けや品詞の判断は専門家でも困難な部分もあるため，明らかに誤りであると判断できる個所のみを誤りと判断している．
また，評価データ約1万文を，目視により全て検査するのは時間を要するため，最初の200文のみを評価の対象とした．
6.1節の実験で，最も正解率の高かった複合Trigram（クラス数1000）とJUMANに関し，形態素数と形態素解析の品詞付与および読み付与正解率とで比較した結果を表[REF_tbl:RuleComparison]に示す．
表より，形態素数はほぼ同じであり，両システムの形態素体系はは同程度の長さであることがわかる．
形態素解析の精度に関しては，品詞付与で約4%，読み付与で約5%と本論文の提案手法の方が優れている．
JUMANの誤り個所を調べると，大部分は感動詞と，数字の読みに関する誤りである．
以下に代表例を示す．
「たぶんえー大丈夫だと思います」
→「たぶん(副詞)え(動詞)ー(記号)大丈夫だ(形容詞)と(助詞)思い(動詞)ます(接尾辞)」
「九月十一日ご一泊」→「きゅうつきじゅういちにちごいちはく」
これらの誤りの大部分は，接続ルールや重みを変更することで対応できると考えられる．
しかし，そのためには，相当数のルールの追加・変更が必要になると考えられる．
このような，修正を行うためには，試験的に形態素解析を行って形態素解析の誤り個所を見つけ，誤りの個所が修正でき，かつ正解個所の解析結果は変化しないように接続ルールや重みを変更する必要があると予想される．
この作業を行うためにはルールの作成において相応の経験・知識を持つ人が，相当な時間をかける必要があると考えられる．
これに対してN-gramでは，前節の実験でデータ量が増えるに比例して形態素解析率は向上していることから，形態素解析の誤り部分を修正するだけで形態素解析精度が向上でき，日本語において多少の文法的知識を持つ人なら容易に作業が可能であり，ルールベースの方法より精度の改善が容易であると考えられる．
次に，未知語を含む文の形態素解析実験を行った．
学習・評価には，6.1節の実験と同一データを使用した．
ただし，辞書には学習データに出現した形態素しか登録しておらず，評価データのみにしか出現しない形態素が未知語となる．
このような未知語は632語存在し，評価データ中の137,691形態素中の859形態素(約0.6%)を占める．
ただし，形態素N-gramは，この処理は行えないため，品詞N-gramと複合N-gramのみで比較実験を行った．
ただし，処理時間の都合上，両モデル共にBigramのみを用いた．
形態素解析の評価は，品詞付与の形態素Accuracy(%)のみで評価した．
これは，現在の我々の形態素解析システムでは，未知語に対し読みを付与する機能がないためである．
未知語に読みを付与するためには漢字毎の読みの情報があることが最低条件となるが，現在そのようなデータを持ちあわせていないことがその理由である．
また，未知語，特に固有名詞の読みは人間でも間違う場合が多く，これを自動で行うのは技術的にも困難であると考えられる．
表[REF_tbl:UnknownWord]に結果を示す．
未知語処理を行った場合でも，複合Bigramが品詞Bigramよりも高い正解率を得た．
辞書に全語いが登録されている6.1節の実験では正解率が99.13%であったから，0.8%程度低下はしているものの，98%以上の比較的高い正解率が得られた．
また，未知語の形態素解析誤りを分析したところ，「防音」が「防」と「音」のように，１形態素が複数の形態素に分割された例が多数見られた．
これは，「音」という形態素が辞書に登録されているため「防」という文字のみが未知語として解析された結果生じた現象である．
「防」も「音」も両方普通名詞であるから，これらの語を結合させることにより，誤りを低減することが可能であると考え
られる．
