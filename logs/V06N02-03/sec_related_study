以上より，大量の形態素データを得るためには，まず，数千形態素程度のデータを人手で作成し，クラス数の少ない複合N-gramを構築して半自動の形態素解析を行い，数十万形態素程度のデータが集まった段階で，クラス数の大きい複合N-gramを構築し，その後は自動で形態素解析を行う，というのが効果的な手段であると考えられる．
以下に，この作業に必要なコストについて検討した．
まず，最初のN-gram学習用の形態素データを作成する必要があるが，これは，１形態素のデータ作成に１分あれば十分であるとして，6,000形態素のデータ作成にかかる時間は，１分×6,000＝6000分＝100時間である．
これを基にして作成した複合N-gramで95%程度の正解率が得られるため，形態素解析したデータの修正には，1形態素あたりでは形態素データ作成時の1/20の3秒程度で可能であると考えられる．
40万形態素のデータを作成するためには，40万×3秒＝120万秒＝2万分＝約333時間となる．
一日８時間労働としても，２ヶ月程度で正解率98%以上の形態素解析システムの構築が可能であることになる．
また，修正を行うだけなら比較的単純な作業であり，多数の人間で平行して行うことができるため，さらにシステム構築の期間を短縮することが可能である．
なお，以上の議論では文章データ収集のためのコストを無視している．
しかし，英語・日本語に限らず音声認識システムを構築するためには文章データを収集することは必須の作業であり，この部分のコストに関してし議論するのは無意味である．
このため形態素解析の作業量のみを議論した．
形態素解析システムJUMAN [CITE] (Version 3.5)との比較により，従来のルールベースの形態素解析に対する有効性を示す．
ただし，我々の形態素解析とJUMANとでは，用いている形態素の体系や辞書に登録されている形態素の語数等が異なるため，できるだけ公平になるよう次のような方法で比較を行った．
辞書サイズの均等化
辞書サイズが，本論文の実験では約7千語であるのに対しJUMANでは約58万語あり，さらに，本論文の実験では評価データの全ての形態素が登録されている等，条件はJUMANが圧倒的に不利である．
このため，名詞，動詞，形容詞等の自立語の語彙を我々のシステムと同一にした．
ただし，「えー」「あのー」等の語は我々のシステムでは間投詞としているが，JUMANには間投詞という品詞は存在しないため感動詞とした．
評価方法
我々のシステムとJUMANとでは形態素の体系が異なり，評価データに対してJUMANの形態素体系の正解は存在しない．
このため，提案方法よびJUMAN共に，形態素解析結果を目視して正誤の判定を行った．
ただし，形態素の切り分けや品詞の判断は専門家でも困難な部分もあるため，明らかに誤りであると判断できる個所のみを誤りと判断している．
また，評価データ約1万文を，目視により全て検査するのは時間を要するため，最初の200文のみを評価の対象とした．
6.1節の実験で，最も正解率の高かった複合Trigram（クラス数1000）とJUMANに関し，形態素数と形態素解析の品詞付与および読み付与正解率とで比較した結果を表[REF_tbl:RuleComparison]に示す．
