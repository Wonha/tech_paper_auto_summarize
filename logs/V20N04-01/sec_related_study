2つの異なる表現が同義か否かを判別する研究のひとつとして，述部を対象にした言い換え研究がある．
藤田・降幡・乾・松本(2004)は，語彙概念構造（Lexical Conceptual Structure; Jackendoff 1992;竹内，乾，藤田2006）を用いて，「株価の変動が為替に影響を与えた」のような述部が機能動詞構造で構成されている文を，「株価の変動が為替に影響した」といった単純な述部に変換する言い換えを行っている．
同様に，鍜治・黒橋(2004)は，「名詞＋格助詞＋動詞」の構造をもつ述部を対象に，「非難を浴びる」と言った迂言表現や，「貯金をためる」と言った重複表現の認識と言い換えを，国語辞典からの定義文を手掛かりに行っている．
松吉・佐藤(2008)は，階層構造化された日本語の機能表現辞書(松吉，佐藤，宇津呂2007)をもとに，「やるしか／ない」の機能表現にあたる「しか／ない」を，「やらざる／を／得ない」という別の表現に自動で言い換える方法を提案している．
述部を対象とした言い換えの研究を用いて，複数の言い換え表現をあらかじめ生成することで，本稿が目的とする同義述部のまとめ上げが可能である．
しかし，語彙概念辞書などの特殊な言語リソースを用いて言い換えを生成する場合，リソースの規模が十分でなければ，ブログなどの幅広い表現を扱う際にカバレッジが問題となる．
2つの異なる表現の意味が似ているか否かを判定する研究に，大量のコーパスを用いた分布類似度の研究がある(Curran 2004; Dagan, Lee, and Pereira 1999; Lee 1999; Lin 1998)．
分布類似度とは，文脈が似ている単語は意味も似ているという分布仮説(Firth 1957)に基づき，対象の単語の周辺に現れる単語（文脈）を素性として計算される単語の類似度である．
Szpektor and Dagan (2008)は，``X takes a nap''と``X sleeps''の関係のように，述部と1つの変数を単位として分布類似度計算を行い，述部を対象に含意ルールの獲得を行った．
柴田・黒橋(2010)は，「景気が冷え込む」の「冷え込む」と「景気が悪化する」の「悪化する」のように組み合わさる項によって同義になる表現をも考慮し，大規模コーパスから項と述部（e.g.,景気が‐悪化）を単位にした分布類似度ベクトルを用いて同義語獲得を行った．
大規模コーパスから周辺単語を用いて単語の意味類似度を測る分布類似度計算は，WordNetなどの特定の言語リソースを用いる手法に比べてバリエーションに富んだ表現を獲得することが可能である．
しかし，分布類似度計算には柴田・黒橋(2010)で述べられているように，2つの問題がある．
1つ目は，反義関係にある単語の類似度が高くなってしまう問題である．
「泳ぎが得意だ」と「泳ぎが苦手だ」のように，反義関係の単語は同一の文脈で現れることができ，結果として類似度が高くなる．
2つ目は，時間経過を表す述部同士の類似度が高くなる問題である．
たとえば，「（小鼻の脇などの狭い場所には）ブラシを使って粉を取って，（粉を）つけます」の「粉を取る」と「粉をつける」のような時間経過の関係にある述部の場合，下記のように類似した文脈で出現しやすい．
\enumsentence{「粉を取る」と「粉をつける」の文脈の例
\left.
{l} \text{ブラシを使う}
\text{パフを使う}
\text{水で洗う}
\cdots
\right}\text{粉を取る} \left{
{l} \text{袋に入れる}
\text{肌に乗せる}
\text{粉をつける}
\cdots
\right.
\left.
{l} \text{ブラシを使う}
\text{パフを使う}
\text{形を整える}
\cdots
\right}\text{粉をつける} \left{
{l} \text{卵に通す}
\text{肌に乗せる}
\text{粉を落とす}
\cdots
\right.
} 2つの文があった場合，双方とも「ブラシを使う」や「パフを使う」という「項‐述部」を共有しているため，「粉を取る」と「粉をつける」という時間経過を表す述部同士の類似度が高くなってしまう．
Yih and Qazvinian (2012)は，WikipediaとWebスニペットを用いて計算した分布類似度や，WordNetなどのシソーラスで計算された類似度を統合することで，語の関連度を計算している．
しかし，複数の類似度の平均値をとっているだけであり，それぞれの類似度に重みづけがされていない．
また，類似度のみを手掛かりとしているため，反義表現と同義表現の識別は困難である．
教師あり学習として同義表現の識別や獲得を行っている研究としてHashimoto, Torisawa, De Saeger, Kazama, and Kurohashi (2011)がある．
Hashimoto et al. (2011)では，Webコーパスから定義文を自動で抽出し，同じコンセプトを表している定義文ペアから大量の言い換え表現を獲得している．
例えば，``Osteoporosis（骨粗鬆症）''というコンセプトを定義している文のペアから，``makes bones fragile（骨がもろくなる）''と``increases the risk of bone fracture（骨折リスクを高める）''といった言い換え表現を獲得している．
しかし，Hashimoto et al. (2011)では，言い換え表現の獲得に定義文を用いているため，獲得される表現は必ず何らかのコンセプトを説明している表現（もしくはその一部）になる．
そのため，対象の同義表現によって説明されるコンセプトが存在しない場合は，定義文からそれら同義表現を獲得することが不可能である．
例えば，「食パン‐が‐出来上がった」と「食パン‐が‐焼けた」のような表現で定義されるコンセプトは想像が難しいため，定義文にも出現しづらい表現であると考えられる．
本稿が目的とする意見集約などのマイニングにおけるまとめ上げを行うためには，定義文に出てこない表現（すなわち，それらの表現によって説明されるコンセプトが存在しない場合）に対するカバレッジを補う必要がある．
つまり，定義文という制約を加えずにブログなどの多様な表現を含む幅広い言語リソースを用いて，高い精度で同義表現の識別をする必要がある．
Hagiwara (2008)は，分布類似度の素性と文中の単語ペアの統語構造を組み合わせて，教師あり学習の識別問題として，分布類似度単体よりも高精度に同義識別を行った．
しかし，Hagiwara (2008)の手法では，コーパスからの言語情報のみしか用いておらず，分布類似度が不得意とする反義単語と同義単語の識別の有効性については述べられていない．
Turney (2008)は，同義語(synonym)・反義語(antonym)・関連語(association)という3つの異なる意味関係を表す単語ペアを対象に，コーパスの周辺単語情報を素性とした識別学習を行った．
Turney (2008)の手法は，あらゆる意味関係もひとつのアルゴリズムで分類できるという点で有益だが，彼が述べているように，同義を認識するタスクに特化した場合，複数のアルゴリズムや言語情報を組み合わせた手法(Turney, Littman, Bigham, and Shnayder, 2003)に対して精度が劣ってしまう．
Weisman, Berant, Szpektor, and Dagan (2012)は，``snore（いびきをかく）''と``sleep（寝る）''といった含意関係（snoreはsleepを含意する）にある動詞ペアを対象に，文，文書，文書全体それぞれにおける動詞ペアの共起情報を用いて含意関係の認識を行った．
含意関係を認識するうえで必要な情報を言語学的に分析し，動詞のクラスや，副詞を素性とした分布類似度など新しい言語情報を入れることで，既存の手法に比べて高精度に含意関係の認識を行った．
しかし，Weisman et al. (2012)は英語の動詞を対象としており，素性も英語に特化したものがある．
例えば，``cover up''のようなphrasal verbs（句動詞）に対して，``up''などのparticleと共起しやすいかを手掛かりに，動詞の意味の一般性を計測しており，英語のような句動詞をもたない日本語で同様の事を行うのは困難である．
また，日本語のように動詞以外の単語が述部に現れたり，複数の文末表現と組み合わさって述部を構成する言語を対象にする場合には，それらの意味を表現する素性を工夫する必要がある．
2つの異なる表現が同義か否かを判別する研究のひとつとして，述部を対象にした言い換え研究がある．
藤田・降幡・乾・松本(2004)は，語彙概念構造（Lexical Conceptual Structure; Jackendoff 1992;竹内，乾，藤田2006）を用いて，「株価の変動が為替に影響を与えた」のような述部が機能動詞構造で構成されている文を，「株価の変動が為替に影響した」といった単純な述部に変換する言い換えを行っている．
同様に，鍜治・黒橋(2004)は，「名詞＋格助詞＋動詞」の構造をもつ述部を対象に，「非難を浴びる」と言った迂言表現や，「貯金をためる」と言った重複表現の認識と言い換えを，国語辞典からの定義文を手掛かりに行っている．
松吉・佐藤(2008)は，階層構造化された日本語の機能表現辞書(松吉，佐藤，宇津呂2007)をもとに，「やるしか／ない」の機能表現にあたる「しか／ない」を，「やらざる／を／得ない」という別の表現に自動で言い換える方法を提案している．
述部を対象とした言い換えの研究を用いて，複数の言い換え表現をあらかじめ生成することで，本稿が目的とする同義述部のまとめ上げが可能である．
しかし，語彙概念辞書などの特殊な言語リソースを用いて言い換えを生成する場合，リソースの規模が十分でなければ，ブログなどの幅広い表現を扱う際にカバレッジが問題となる．
2つの異なる表現の意味が似ているか否かを判定する研究に，大量のコーパスを用いた分布類似度の研究がある(Curran 2004; Dagan, Lee, and Pereira 1999; Lee 1999; Lin 1998)．
分布類似度とは，文脈が似ている単語は意味も似ているという分布仮説(Firth 1957)に基づき，対象の単語の周辺に現れる単語（文脈）を素性として計算される単語の類似度である．
Szpektor and Dagan (2008)は，``X takes a nap''と``X sleeps''の関係のように，述部と1つの変数を単位として分布類似度計算を行い，述部を対象に含意ルールの獲得を行った．
柴田・黒橋(2010)は，「景気が冷え込む」の「冷え込む」と「景気が悪化する」の「悪化する」のように組み合わさる項によって同義になる表現をも考慮し，大規模コーパスから項と述部（e.g.,景気が‐悪化）を単位にした分布類似度ベクトルを用いて同義語獲得を行った．
大規模コーパスから周辺単語を用いて単語の意味類似度を測る分布類似度計算は，WordNetなどの特定の言語リソースを用いる手法に比べてバリエーションに富んだ表現を獲得することが可能である．
しかし，分布類似度計算には柴田・黒橋(2010)で述べられているように，2つの問題がある．
1つ目は，反義関係にある単語の類似度が高くなってしまう問題である．
「泳ぎが得意だ」と「泳ぎが苦手だ」のように，反義関係の単語は同一の文脈で現れることができ，結果として類似度が高くなる．
2つ目は，時間経過を表す述部同士の類似度が高くなる問題である．
たとえば，「（小鼻の脇などの狭い場所には）ブラシを使って粉を取って，（粉を）つけます」の「粉を取る」と「粉をつける」のような時間経過の関係にある述部の場合，下記のように類似した文脈で出現しやすい．
\enumsentence{「粉を取る」と「粉をつける」の文脈の例
\left.
{l} \text{ブラシを使う}
\text{パフを使う}
\text{水で洗う}
\cdots
\right}\text{粉を取る} \left{
{l} \text{袋に入れる}
\text{肌に乗せる}
\text{粉をつける}
\cdots
\right.
\left.
{l} \text{ブラシを使う}
\text{パフを使う}
\text{形を整える}
\cdots
\right}\text{粉をつける} \left{
{l} \text{卵に通す}
\text{肌に乗せる}
\text{粉を落とす}
\cdots
\right.
} 2つの文があった場合，双方とも「ブラシを使う」や「パフを使う」という「項‐述部」を共有しているため，「粉を取る」と「粉をつける」という時間経過を表す述部同士の類似度が高くなってしまう．
Yih and Qazvinian (2012)は，WikipediaとWebスニペットを用いて計算した分布類似度や，WordNetなどのシソーラスで計算された類似度を統合することで，語の関連度を計算している．
しかし，複数の類似度の平均値をとっているだけであり，それぞれの類似度に重みづけがされていない．
また，類似度のみを手掛かりとしているため，反義表現と同義表現の識別は困難である．
教師あり学習として同義表現の識別や獲得を行っている研究としてHashimoto, Torisawa, De Saeger, Kazama, and Kurohashi (2011)がある．
Hashimoto et al. (2011)では，Webコーパスから定義文を自動で抽出し，同じコンセプトを表している定義文ペアから大量の言い換え表現を獲得している．
例えば，``Osteoporosis（骨粗鬆症）''というコンセプトを定義している文のペアから，``makes bones fragile（骨がもろくなる）''と``increases the risk of bone fracture（骨折リスクを高める）''といった言い換え表現を獲得している．
しかし，Hashimoto et al. (2011)では，言い換え表現の獲得に定義文を用いているため，獲得される表現は必ず何らかのコンセプトを説明している表現（もしくはその一部）になる．
そのため，対象の同義表現によって説明されるコンセプトが存在しない場合は，定義文からそれら同義表現を獲得することが不可能である．
例えば，「食パン‐が‐出来上がった」と「食パン‐が‐焼けた」のような表現で定義されるコンセプトは想像が難しいため，定義文にも出現しづらい表現であると考えられる．
本稿が目的とする意見集約などのマイニングにおけるまとめ上げを行うためには，定義文に出てこない表現（すなわち，それらの表現によって説明されるコンセプトが存在しない場合）に対するカバレッジを補う必要がある．
つまり，定義文という制約を加えずにブログなどの多様な表現を含む幅広い言語リソースを用いて，高い精度で同義表現の識別をする必要がある．
Hagiwara (2008)は，分布類似度の素性と文中の単語ペアの統語構造を組み合わせて，教師あり学習の識別問題として，分布類似度単体よりも高精度に同義識別を行った．
しかし，Hagiwara (2008)の手法では，コーパスからの言語情報のみしか用いておらず，分布類似度が不得意とする反義単語と同義単語の識別の有効性については述べられていない．
Turney (2008)は，同義語(synonym)・反義語(antonym)・関連語(association)という3つの異なる意味関係を表す単語ペアを対象に，コーパスの周辺単語情報を素性とした識別学習を行った．
Turney (2008)の手法は，あらゆる意味関係もひとつのアルゴリズムで分類できるという点で有益だが，彼が述べているように，同義を認識するタスクに特化した場合，複数のアルゴリズムや言語情報を組み合わせた手法(Turney, Littman, Bigham, and Shnayder, 2003)に対して精度が劣ってしまう．
Weisman, Berant, Szpektor, and Dagan (2012)は，``snore（いびきをかく）''と``sleep（寝る）''といった含意関係（snoreはsleepを含意する）にある動詞ペアを対象に，文，文書，文書全体それぞれにおける動詞ペアの共起情報を用いて含意関係の認識を行った．
含意関係を認識するうえで必要な情報を言語学的に分析し，動詞のクラスや，副詞を素性とした分布類似度など新しい言語情報を入れることで，既存の手法に比べて高精度に含意関係の認識を行った．
しかし，Weisman et al. (2012)は英語の動詞を対象としており，素性も英語に特化したものがある．
例えば，``cover up''のようなphrasal verbs（句動詞）に対して，``up''などのparticleと共起しやすいかを手掛かりに，動詞の意味の一般性を計測しており，英語のような句動詞をもたない日本語で同様の事を行うのは困難である．
また，日本語のように動詞以外の単語が述部に現れたり，複数の文末表現と組み合わさって述部を構成する言語を対象にする場合には，それらの意味を表現する素性を工夫する必要がある．
