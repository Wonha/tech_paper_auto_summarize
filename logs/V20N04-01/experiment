実験

5節で作成した同義述部コーパスを用いて提案手法の評価を行った．辞書定義文素性の抽出には，金田一・池田(1988)の「学研国語大辞典 
第二版」を，抽象的な意味属性の抽出には，日本語語彙大系(池原 他 1999)の「用言属性」を用いる．分布類似度計算には，柴田・黒橋(2010)と同様の手法で作成された「項‐述部」の分布類似度モデルと，「述部」のみを単位とした分布類似度モデルを用いる．素性ベクトルの構築には，Web10億ページから抽出し，重複を除いた約69億文を用いた．機能表現の特徴抽出に関しては，松吉 他(2007)の日本語機能表現辞書にある機能表現の意味カテゴリーのラベルを用いる．この意味ラベルの付与には，今村, 泉, 菊井, 佐藤 (2011)のタガーを用いる．


\subsection{学習データ}

5節で作成した同義述部コーパスから，本稿で使用するリソースである学研国語大辞典と語彙大系の用言属性にエントリがあり，かつ分布類似度計算の「項‐述部」の出現頻度10以上のデータのみを選出した．項が422種類からなる「同義」，「含意」，「反義」，「その他」の述部ペアのうち，91種類の項に対する述部ペアは，本提案手法の言語的特徴を分析するための考察用データ（372ペア，held out data）として用い，実験には使用しなかった．残りを学習データ（3,503ペア）とし，「同義」と「含意」の述部ペアを正例，「反義」と「その他」のペアを負例として同義判定モデルの学習を行った．学習にはLIBSVM (Chang {\&} Lin 2011)を使用し，実験の評価には，5分割交差検定を行い，学習データの4/5を用いてトレーニングを行い，残りの1/5で評価し，これを5回繰り返した\footnote{SVMの学習には線形カーネルを用い，パラメータはデフォルト値を用いた．}．学習データに属する「同義」，「含意」，「反義」，「その他」の述部ペアの数は下記のとおりである．

\begin{itemize}
\item 学習データの内訳
	\begin{itemize}
	\item 同義ペア（956ペア）
	\item 含意ペア（669ペア）
	\item 反義ペア（758ペア）
	\item その他ペア（1,120ペア）
	\end{itemize}
\end{itemize}


\subsection{比較手法}

Baselineとして，次にあげる手法と比較した．1つ目が，既存の大規模語彙シソーラスである日本語WordNet (Bond, Isahara, Fujita, Uchimoto, Kuribayashi, and Kanzaki 2009)を用いた方法である．2節で述べたように，既存の言い換え研究ではシソーラスなどの特定の言語資源を用いて言い換えを行う．そこで，本稿では大規模シソーラスであるWordNetを用いて，入力された述部が同じSynsetに属していれば，同義とみなす方法で同義判定を行った．2つ目，3つ目は分布類似度のみを用いて同義判定を行う手法である．Baseline2 (DistPAVerb-$\theta)$は，提案手法の素性のひとつである項‐述部と述部単体の分布類似度を用いて，これらが特定の閾値以上の場合は，正例とみなす方法である．Baseline3 (DistMultiAve-$\theta$)\footnote{Yih and Qazvinian (2012)で提案された複数の類似度の平均値という意味で，Dist(ributional similarity) Multi(model) Ave(rage)と呼ぶ．}は，Yih and Qazvinian (2012)の方法をもとに，本提案手法で用いた言語資源である大規模コーパスからの分布類似度（項‐述部と述部），辞書定義文を用いた分布類似度，語彙大系の属性から生成した分布類似度をそれぞれ計算し，その平均値を用いて，特定の閾値以上のものを正例とみなした．辞書定義文に関しては，対象の単語の定義文内にある内容語とその出現頻度をベクトルの素性とした．用言属性に関しては，対象の単語が持つ用言属性を用いてベクトルを構築した．Baseline2とBaseline3の閾値調整には，提案手法同様に，5分割交差検定を行い，学習データの4/5を用いてF値が最大になる閾値を求め，その閾値を用いて残りの1/5の評価を行うという方法を5回繰り返した．Baseline4〜Baseline7は，本提案手法で提案した特徴である「辞書定義文素性 (Definition-SVM)」，「用言属性素性 (PredClass-SVM)」，「分布類似度素性 (DistPAVerb-SVM)」，「機能表現素性 (Func-SVM)」それぞれ単体を用いてSVMで同義判定を行う手法である．これらも，5分割交差検定を行う．


・比較手法
\begin{itemize}
\item Baseline1 (WordNet)\\
 日本語WordNet (Bond et al. 2009) のSynsetにあれば「正例」
\item Baseline2 (DistPAVerb-$\theta)$\\
 項‐述部もしくは述部単体の分布類似度が閾値以上のものを「正例」
\item Baseline3 (DistMultiAve-SVM)\\
 大規模コーパス，辞書定義文，用言属性から個別に計算した分布類似度の平均を用いて閾値以上のものを「正例」
\item Baseline4〜7 (Definition-SVM, PredClass-SVM, DistPAVerb-SVM, Func-SVM) \\
 提案手法の素性単体を用いてSVMで同義判定を行う
\end{itemize}
評価は，Precision（精度），Recall（再現率），F値を用いて行う．なお，精度の比較には5分割交差検定の平均値を用いる．

・精度評価の指標
\begin{gather*}
 \text{Precision（精度）}= \frac{|\text{正解の同義の集合} \cap \text{システムが同義と判別した集合}|}{|\text{システムが同義と判別した集合}|} \\
 \text{Recall（再現率）} = \frac{|\text{正解の同義の集合} \cap \text{システムが同義と判別した集合}|}{|\text{正解の同義の集合}|} \\
 \mathrm{F}値 = \frac{2 * \text{Precision} * \text{Recal}l}{\text{Precision} + \text{Recall}}
\end{gather*}


\subsection{結果}

\begin{table}[b]
\caption{実験結果}
\input{01table02.txt}
\end{table}

表2が示すように，提案手法が最も高いF値を示した．BL1 (WordNet)の場合，Precisionが0.873と一番高いが，Recallが0.331と一番低い．一方，Yih and Qazvinian (2012)をもとに複数の類似度計算の平均を取るBL3 (DistMultiAve-$\theta)$の場合，Recallがすべての手法の中で一番高いものの，Precisionが0.537と最も低い値を出しており，提案手法のように教師あり識別問題として同義述部の判定を行う事の有効性が確認できた．また，本提案手法の素性を単体で用いるよりも（BL4〜BL7），すべての素性を用いた方が精度が高いことから，複数の言語的特徴を組み合わせた同義判定の有効性が確認できた．なお，比較手法と提案手法とのF値には $\mathrm{p} < 0.01$ で統計的な有意差があった\footnote{F値の結果をもとに，t検定を行った．}．


次に，どの素性が有効であるかを調べるために，提案手法から各素性を除いたAblationテストを行った．すべての素性において，それぞれの素性を抜いた場合にF値が低下し，分布類似度と用言属性の素性を抜いた場合にはF値に統計的な有意差が出た．特に，分布類似度の素性を抜いた場合，Precision，Recall，F値すべてが低下したため，大規模コーパスから計算した分布類似度が同義判定の素性として一番効果があった．


