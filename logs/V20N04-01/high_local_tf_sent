================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[3538] 本稿では，同じ出来事を表している述部表現をまとめ上げるため，「メモリを消費している」と「メモリを食っている」の「消費している」と「食っている」のような述部表現を対象に，異なる2つの述部が同義か否かを認識する同義判定を行う．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[3582] そこで本稿では，述部の言語的構造を分析し，同義述部の認識という観点で必要な「述部の語義（辞書定義文）」，「抽象的な意味属性（用言属性）」，「文脈（分布類似度）」，「時制・否定・モダリティ（機能表現）」といった言語情報を複数の言語リソースから抽出することで，精度と再現率の双方のバランスをとった述部のまとめ上げを行う．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[2619] 大量のテキストから有益な情報を抽出するテキストマイニング技術では，ユーザの苦情や要望を表す述部表現の多様性が大きな問題となる．
-----------------------------------------------------
  [subsection title : 辞書を用いた言い換え研究]
-----------------------------------------------------
  [3343] 藤田・降幡・乾・松本(2004)は，語彙概念構造（Lexical Conceptual Structure; Jackendoff 1992;竹内，乾，藤田2006）を用いて，「株価の変動が為替に影響を与えた」のような述部が機能動詞構造で構成されている文を，「株価の変動が為替に影響した」といった単純な述部に変換する言い換えを行っている．
-----------------------------------------------------
  [subsection title : コーパスからの分布類似度計算]
-----------------------------------------------------
  [3537] 柴田・黒橋(2010)は，「景気が冷え込む」の「冷え込む」と「景気が悪化する」の「悪化する」のように組み合わさる項によって同義になる表現をも考慮し，大規模コーパスから項と述部（e.g.,景気が‐悪化）を単位にした分布類似度ベクトルを用いて同義語獲得を行った．
-----------------------------------------------------
  [subsection title : 教師あり学習を用いた同義判定]
-----------------------------------------------------
  [3166] Turney (2008)の手法は，あらゆる意味関係もひとつのアルゴリズムで分類できるという点で有益だが，彼が述べているように，同義を認識するタスクに特化した場合，複数のアルゴリズムや言語情報を組み合わせた手法(Turney, Littman, Bigham, and Shnayder, 2003)に対して精度が劣ってしまう．

================================================================
[section type  : proposed_method]
[section title : 述部の言語的特徴]
================================================================
[2933] 我々が知らない単語に出くわした場合，その単語の意味を理解するために，辞書を引いたり(Lexical-Encyclopedic information)，周辺単語を手掛かりに推測したり(Syntax, Context)，また見覚えのある単語であればその本来の意味から派生されそうな意味(Semantic)を考え，対象単語の言語情報をできるだけ集めて意味を理解する．

================================================================
[section type  : proposed_method]
[section title : 提案手法：複数の言語的特徴を用いた同義判定]
================================================================
[3094] 本稿では，述部の同義判定を行うために，4つの言語情報を素性とし，識別学習を用いて同義か否かを判定する．
-----------------------------------------------------
  [subsection title : 辞書定義文を用いた相互補完性・定義文類似性]
-----------------------------------------------------
  [2979] また，「プリンターが‐動かない」といった「項‐述部」の単位で同義判定を行うため，項（プリンター）もしくは項と同様の名詞クラスが相手の定義文に現れたか否かも素性として用いる．
-----------------------------------------------------
  [subsection title : 用言属性を用いた述部の抽象的意味属性]
-----------------------------------------------------
  [2543] そこで，同義判定に必要なSemanticレベルの素性として，日本語語彙大系(池原他1999)の用言属性を用いて，述部同士の抽象的な意味の重なりを抽出する．
-----------------------------------------------------
  [subsection title : 分布類似度]
-----------------------------------------------------
  [3090] JACCARD係数は，分布類似度を計算する対象(u)（項‐述部もしくは述部）が共通して持つ素性(f)を，それぞれがもつ素性の和集合で割った値である．
-----------------------------------------------------
  [subsection title : 述部の機能表現]
-----------------------------------------------------
  [3241] 以上のように，提案手法では，「辞書定義文」，「用言属性」，「分布類似度」，「機能表現」という4つの異なる言語的特徴を用いて，述部の同義判定を行う．

================================================================
[section type  : proposed_method]
[section title : 同義述部コーパスの作成]
================================================================
[2957] 述部は，Izumi, Imamura, Kikui, and Sato (2010)を用いて，述部の機能表現から終助詞など出来事の意味に影響を与えない表現を自動で削除し，単純な述部表現に正規化した．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[2908] 分布類似度計算には，柴田・黒橋(2010)と同様の手法で作成された「項‐述部」の分布類似度モデルと，「述部」のみを単位とした分布類似度モデルを用いる．
-----------------------------------------------------
  [subsection title : 学習データ]
-----------------------------------------------------
  [3348] 5節で作成した同義述部コーパスから，本稿で使用するリソースである学研国語大辞典と語彙大系の用言属性にエントリがあり，かつ分布類似度計算の「項‐述部」の出現頻度10以上のデータのみを選出した．
-----------------------------------------------------
  [subsection title : 比較手法]
-----------------------------------------------------
  [3632] Baseline3 (DistMultiAve-[MATH])は，Yih and Qazvinian (2012)の方法をもとに，本提案手法で用いた言語資源である大規模コーパスからの分布類似度（項‐述部と述部），辞書定義文を用いた分布類似度，語彙大系の属性から生成した分布類似度をそれぞれ計算し，その平均値を用いて，特定の閾値以上のものを正例とみなした．
-----------------------------------------------------
  [subsection title : 結果]
-----------------------------------------------------
  [3323] 一方，Yih and Qazvinian (2012)をもとに複数の類似度計算の平均を取るBL3 (DistMultiAve-[MATH]の場合，Recallがすべての手法の中で一番高いものの，Precisionが0.537と最も低い値を出しており，提案手法のように教師あり識別問題として同義述部の判定を行う事の有効性が確認できた．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[3577] 一方，提案手法でうまく同義と識別できなかった述部ペアは，片方の内容語が「入れる」のように多義性の高い述部ペアや，内容語と機能表現の意味の組み合わせを考慮しなくてはいけない同義述部ペアであった．

================================================================
[section type  : conclusion]
[section title : 結論]
================================================================
[3703] 本稿では，「メモリを消費している」と「メモリを食っている」の「消費している」と「食っている」といった内容語と機能表現からなる述部を対象に，異なる2つの述部が同義か否かを判定する同義判定手法を提案した．

