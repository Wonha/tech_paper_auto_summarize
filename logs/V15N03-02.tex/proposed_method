接続関係の分類

本論文で用いた接続関係について述べる．接続関係の種類に関しては多くの研究者が個々の案を提示している 
(市川 1978; Wolf et al. 2005)．例えば，古くから知られているMann and 
Thompson のRST (Rhetorical Structure Theory) (Lochbaum et al. 2000)においてはnucleusとsatelliteの関係として21種類を定義している\footnote{
	Evidence, Concession, Elaboration, Motivation, Condition, Evaluation, 
	Justify, Circumstance, Background, Volitional Cause, Non-volitional Cause, 
	Volitional Result, Non-volitional Result, Otherwise, Restatement, 
	Antithesis, Solutionhood, Enablement, Purpose, Interpretation, 
	Summaryの21種類．これ以外に複数のnucleus間の関係として Sequence, Contrast, 
	Jointの3種を定義している．
}．日本語では，市川が文の接続関係を，「順接」，「逆接」，「添加」，「対比」，「転換」，「同列」，「補足」，「連鎖」の8つの類型に分類している．

我々は，形態素解析器「茶筌」$^{(1)}$の辞書(IPADIC, Ver.~2.7.0)に登録されている167個の接続詞を，概ね市川の類型によって分類を試みた．ただし以下の理由から若干の変更を行い，最終的に表1のように分類した．また完全な表を付録に示す．

\begin{itemize}
\item
「同列」と「補足」，「逆接」と「対比」を区別するのは容易ではなかったため一緒にした

\item
「例示」は市川の類型にはないが，文自体に特徴があったため，別に分類したほうがよいと考えた

\item
「連鎖」は市川の分類で定義だけはあるものの，具体的には触れられていないため分類として削除した
\end{itemize}

\begin{table}[b]
\caption{接続関係の分類とコーパス中の出現割合}
\input{02table01.txt}
\end{table}

この結果，市川の分類における「順接」は概ね「累加」または「因果」に該当する．同様に市川の分類における「添加」も「累加」または「因果」に，「対比」は「並列」（一部「逆接」）に，「同列」は「並列」に，「補足」は「累加」に該当する．

この他「なかんずく」，「わけても」など，以下の6分類のどれにも属さない「その他」の分類も存在するが，非常にまれであるためここではこれらは扱わない．表1では，接続関係の分類と共に，本研究で使用したコーパス中での出現割合も示す．コーパスは，接続詞でつながった2文を1事例として，我々がWeb文書から約120万事例を収集した．HutchinsonはWebから自動的に接続詞を含む文を抽出する方法を提案している(Hutchinson 2004a)が，ここでは使用したコーパスからIPADICによる接続詞でつながっている2文の組を自動的に抽出した．

ところで，接続詞によっては一意に接続関係を決められないものもある．例1，例2の接続詞「したがって」はそれぞれ，「なので」と同様な因果関係，「つまり」と同様な並列関係にそれぞれ分類可能である．本論文では，複数の接続関係に分類される接続詞は取り得る全接続関係の中に分類しているが，テストセットではこれらは除外した．なお，このように多義性により除外された接続詞は167種類のうち1割程度である．

\hangafter=1\hangindent=4zw
\noindent　\hbox to3zw{例1)\hfill}
理系の人間だって科学のごく一部しか勉強できない。\ul{したがって}、文系の人がたくさんの理系の授業を受ける必要はない。

\hangafter=1\hangindent=4zw
\noindent　\hbox to3zw{例2)\hfill}
高気圧におおわれた地域は、天気がよくなります。\ul{したがって}、雨が降らないのです。



人手による接続関係の推定

人間は接続関係をどのように判断しているのか，人間は接続関係の同定をどの程度の精度で行うことができるか，などを検証することを目的に被験者実験を行った．本節ではこの実験について報告する．

青空文庫$^{(4)}$ から旧字体のものを除き，ランダムに選んだ23テキストを3人の被験者(A, B, C)に与え，文頭に接続詞をもつ文を対象に300個の接続部分を空欄として穴埋め形式で適当な接続関係を選んでもらった．被験者には前節で述べた接続関係と，各接続関係に属するいくつかの代表的な接続詞を提示した．テキストの長さにはかなりばらつきがあり，短いテキストでは1テキスト中に穴埋め箇所は2箇所，長いテキストでは43箇所あるものもある．被験者が選ぶ接続関係は指定した6種類のうちいくつ選んでもかまわないが，複数選択する場合には優先順位をつけるよう指示した．

実験は，同一の問題に対してテキスト全体を与えた場合と穴埋め箇所の前後1文ずつを取り出した2文だけを与えた場合の2通り行った．最初にテキスト全体での推定をしてもらい，その3日後に2文だけを用いた場合の実験を行った．2文だけを用いた実験では，テキスト全体での出力結果を被験者が思い出さないように全てのテキストから取り出した2文の組を無作為に並べ替えて提示した．

\subsection{正解率の比較と一致率}

各被験者の，テキスト全体を見て判断した場合（全文）と2文の情報のみで判断した場合（2文）での正解率と2種類の出力の一致率を表2に示す．被験者には優先順位をつけて複数選択してもらっているので，それを考慮するため，質問応答でよく使われているMRR (Mean Reciprocal Rank)の評価手法を応用して正解率を求めた．具体的にはN番目の出力が正解した場合に1/Nのポイントを与え，その合計を全問題数300で割った値を正解率としている．

\begin{table}[b]
\caption{各正解率と二つの出力の一致率}
\input{02table02.txt}
\end{table}

表2から3件の考察を行う．まず，正解率を見ると全文，2文のどちらの場合も5割〜6割程度である．これは，人間にとっても接続関係を同定することが容易ではないか，もしくは正解が一意ではなく複数の解釈，若干の自由度があるかのどちらか，もしくは両方を示している．いずれにしても，実際に記述された正解との単純比較だけでは人間との感覚にずれがあり，注意が必要である．

次に，直感ではテキスト全体を見たときの方が2文だけを見て判断するより精度が良くなる，と誰しもが考えるであろう．しかし，表2が示すように，人間が接続関係を推定する際は両者の正解率にあまり差はない．これについては3.3節でさらに議論する．

最後に，テキスト全体を見て判断した場合の人間の出力と2文のみで判断した場合の出力の一致率は共に約6割と高くない．つまり，正解率は変わらないが正解している問題は少なからず異なっている．このことから，テキスト全体を見た方が正しく判断できるものと逆に情報を2文に限定したほうがよい場合がそれぞれ存在することを示唆している．

\subsection{接続関係ごとの正解率}

テキスト全体を見た場合と2文だけを見た場合の正解率の異なりを接続関係ごとに分析し，接続関係の持つ特徴を考える．図1，図2にそれぞれ3人の被験者の平均による接続関係毎の正解率と適合率を示す．

\begin{figure}[b]
\centerline{\includegraphics{15-3ia2f1.eps}}
\caption{接続関係ごとの正解率の平均}
\end{figure}

図1，図2より「転換」においては2文だけで判断するよりテキスト全体を見たほうが正解率と適合率が高い．特に「転換」という接続関係は話題の移り変わりを表すので，直前の1文だけでは判断できないと考えられる．また，「加反」や「例示」はテキスト全体でも2文でもほとんど差がなく，しかも他の接続関係に比べて正解率，適合率共に高い．このことから，「加反」や「例示」は直前の文とのつながりを表しやすいといえる．

\begin{figure}[t]
\centerline{\includegraphics{15-3ia2f2.eps}}
\caption{接続関係ごとの適合率の平均}
\end{figure}


\subsection{テキストと2文の出力の一致度と正解の関係}

テキスト全体を見て選んだ接続関係と2文だけを見て選んだ接続関係が一致した問題数と，そのときの正解率から考察を行う．ここでは，簡単のため優先順位の最も高い接続関係を被験者の唯一の出力としている．

表3は各被験者の出力結果の内訳である．表中の○，×はそれぞれ正解，不正解を示している．この表から，全文を見なければ正解が出来ない項目b 
(122)は全体(900)の13.5{\%}であることが分かる．この結果から，全文入力することと比較して入力文を2文に制限することで条件が極端に不利になることはないと考え，本論文の入力を連続する2文とした．

表4は2文だけ見たときには誤っているがテキスト全体を見た場合では正解している問題と，逆にテキスト全体では誤っているが2文だけで判断したときには正解している問題の接続関係ごとの割合を示している．表4より，テキスト全体を見た場合に正解した問題と2文だけを見た場合に正解した問題に多少の偏りは見られる．しかし，この結果からは接続関係によってテキスト全体を見た方が正しく判断できるものと情報を2文に限定した方がよいものに分けることはできない．

\begin{table}[t]
\begin{minipage}[t]{190pt}
\caption{出力の一致からみた人間と正解の関係}
\input{02table03.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{200pt}
\caption{一方でのみ正解している問題}
\input{02table04.txt}
\end{minipage}
\end{table}

今回のようなタスクで長いテキストから接続関係を判断するとき，まず人は2文だけを見て決めようとする．そこでうまく接続関係が決められない場合には見る範囲を広げていく．しかし全文が見れる以上，2文だけで判断可能な場合でも人は他の文章の影響を受けずにはいられない．そのため，もし2文だけで接続関係を判断するための情報が十分含まれているとしたら，テキスト全体を与えることでかえって判断を迷わす結果となっている可能性がある．また，接続関係を決めるための情報が2文では不十分であるときは，人間の判断も自信のないものとなっている可能性が高い．

また，表3においてテキスト全体を見た場合と2文だけを見た場合の出力が一致した問題(a, b)中での正解率(a/(a$+$b))は62〜77{\%}であり，3人の平均では71{\%}であった．表2に示す3人の被験者それぞれの正解率と比較するとおよそ1割強高い．これは，全体の正解率と比べて出力が一致している問題中での正解率の方が高くなるであろうという人間の直感とも一致する．しかし全体の17\%の問題(b)については正解とは異なった関係を選んでいるにもかかわらず，テキスト全体を見て判断した接続関係と2文だけで判断した接続関係が一致していることから，人は迷いなくその関係を選んでいると考えられる．出力がどちらも同じであるということは，接続関係を判断するためには2文の情報だけで十分であるといえるのではないか．


類似用例による接続関係の推定

本節では，入力の2文に対してコーパス中で2文間の接続関係が同一と判断される類似用例文の検索手法の大まかな流れについて述べる．処理の概要を図3に示す．

入力文と類似した2文の組を探すといっても，単純に文が似ているものを探せばよいというものではない．例えば「雨が降った。試合は中止になった。（因果）」と「雨が降った。試合は中止にならなかった。（逆接）」は，単語の一致率などを用いた一般的な類似度計算によって非常によく似た2文の組とされるものであるが，それぞれの文間の接続関係はまったく逆である．反対に，「本を読んだ。つまらなかった。（逆接）」と「評判の映画を観た。僕には退屈で眠くなった。（逆接）」では，一致する単語や一般的に類義語や上位語，下位語とされるものが存在しないにもかかわらず，人間が見ると直感的にこの2つの例文は似ている文であり，接続関係も同じであるといえる．本論文ではこのように，入力に対して同じ接続関係を持つと思われる類似用例文を大量のコーパス中から探し，その用例によって接続関係を推定する手法を提案する．以下に大まかな処理の流れを示す．

\noindent
\textbf{Step 1.} 
前処理として，クラスタリング用に別のコーパスを用意し，接続関係を決定すると考えられる主要な単語を，GETA$^{(3)}$を用いてクラスタリングする．「本を読んだ。つまらなかった。」と「評判の映画を観た。僕には退屈で眠くなった。」の例では，「本を--映画を」，「読んだ--観た」，「つまらない--眠い」などの単語ごとにクラスタリングされることが理想である．クラスタリングの際，1文目と2文目から抽出する単語は区別される．詳しくは6節で説明する．

\noindent
\textbf{Step 2.} 
入力の2文から動的に構文パタンを生成し，構文的に似ている文を候補として抽出する．パタンの生成，候補文の抽出に関しては5節で詳しく述べる．Step 1のクラスタリングの際にも構文パタンを素性として用いるため，本論文では先にこちらを説明する．

\noindent
\textbf{Step 3.} 
抽出した候補文に対して，単語や構文パタンによるスコア付けを行い，スコアの高い順に出力する．

\begin{figure}[t]
\centerline{\includegraphics{15-3ia2f3.eps}}
\caption{類似用例による接続関係の推定}
\end{figure}

用例利用型(example-based)による解法は主に機械翻訳の分野で使用されてきた．例えば，(Sumita 1998) 
で議論されているように，日本語の「AのB」と記述される際の助詞ノには多義性があり，その結果英語などに翻訳する際には多訳性が生じる．これに対して入力表現の「AのB」に最も類似している表現がどのように翻訳されているかを模倣することによって多義性解消を行う（すなわち翻訳結果を得る）というのが用例利用型翻訳の基本的な考え方である．本論文では，上記のAやBが文であり，助詞ノが接続詞であると仮に見做せばちょうど「AのB」の翻訳と同一の考え方ができるのではないかと考え，用例利用型による解法を目指した．

用例利用型手法は万能ではない．我々は，用例利用型を有効に機能させるためには二つの重要なポイントがあると考える．すなわち，

(a)広範な用例を収集すること

(b)適切な類似度を設定すること

の2点である．(a)はコーパスを利用する他手法と同様であるが，「大量」である必要がない点は統計的手法などと異なる．すなわち用例利用型は用例の類似度を用い，出現頻度を利用しないため，各事例の出現比率は考慮する必要がない．このため，いくら重要事例であっても同一の事例が複数ある必要はなく，用例が広範に収集されていることのみが性能に影響する．(b)は統計的手法における統計量，規則を用いた手法の条件部に相当する処理を類似度によって制御しているため，類似度をどのように定義するかが制御部の核心である．本研究でどのように類似度を設定したかについては7節で議論する．

パタンによる候補文の抽出

本研究では入力文に最も類似した文をコーパス中の文に対するスコア付けによって求めるが，コーパス中の全ての文に対してスコア付けをすると計算量が膨大となるため，入力文から生成した構文パタンに一致したコーパス中の文のみを対象とする．これらコーパス中から抽出された文を入力文に対する候補文と呼ぶ．本節では入力文からの構文パタン生成手法および候補文の抽出について説明する．また，この構文パタンは6節で述べる単語のクラスタリングの素性としても使用する．

\subsection{構文パタンの生成}

例3のように入力の2文が与えられたとき，まず入力の1文目，2文目それぞれから構文パタンを作成する．ここで，入力の各文から生成される構文パタンを基本パタンと呼ぶ．図4は例3の入力に対する構文解析結果である．構文解析器には「南瓜」$^{(2)}$を用いた．

\noindent　\hbox to3zw{例3)\hfill}
1文目：上海の新生活はサンディにとって心地よいものとなるはずだった。

\noindent　\hbox to3zw{　\hfill}
2文目：しかし、最愛の母親の死は彼女に大きな打撃と計り知れない心痛を与えた。

\begin{figure}[t]
\centerline{\includegraphics{15-3ia2f4.eps}}
\caption{例3の構文解析結果}
\end{figure}

\subsubsection{パタン要素の抽出}

入力の各文から基本パタンを生成するために必要な要素を文節ごとに抽出する．ここで，「未知語」は全て「名詞」として扱い，句点以外の記号はあらかじめ全て削除しておく．以下に各文節からのパタン要素の抽出方法を説明する．

\noindent
\ul{\mbox{i) 文末文節以外の文節からのパタン要素の抽出}}

パタンを構成する要素を文節単位で抽出する．1文節から生成される要素をパタンの一要素とする．文節内の助詞，助動詞を抽出し，さらに全ての品詞で「非自立」であるものと，動詞の「ある」を無条件にパタン要素として採用する．同じ文節内のものを連結し，パタンの一要素とする．

文節末が名詞または動詞の場合は，それぞれ``NOUN''，``VERB''に一般化し，それで一要素とする．また，文節末尾以外の名詞でNE（固有表現）タグがついているものはNEタグに変換する．例3では「上海」は``LOCATION''になる．

「AのB」，「A（し）たB」などの「Aの」や「A（し）た」といった連体修飾節はパタンの要素には採用しない．ただし，NEタグの要素を含む場合を除く．例えば，例3の「最愛の」，「母の」はパタンの要素として採用しないが，「上海の」は「LOCATIONの」という形で採用する．

\noindent
\ul{\mbox{ii) 文末文節からのパタン要素の抽出}}

文末文節に関しては他の文節とは異なり，複数のパタン要素が生成される．文末文節の末尾から一形態素ずつ付与して複数のパタンの要素を作成する．ここで，抽出対象となるものは助詞，助動詞，感動詞，および全ての品詞で「非自立」であるもの，動詞の「ある」である．ただし，文末の「助詞」または「助動詞」の連続は切り離さない．例3の1文目の文末文節の「なるはずだった。」からは「はずだった。」と「だった。」の2種類のパタン要素が生成され，これらをそれぞれ末尾として構文パタンを生成する．つまり，ここでは助動詞「た。」の要素は作成されない．

また，文末の形態素が形容詞ならば，その「形容詞の出現形+『。』」の要素を作成し，文末が名詞および動詞の場合は i) と同じくそれぞれ``NOUN''，``VERB''に一般化して一要素とする．

\subsubsection{基本パタンの生成}

\begin{figure}[b]
\centerline{\includegraphics{15-3ia2f5.eps}}
\caption{各パタン要素と係り受け}
\end{figure}
\begin{figure}[b]
\centerline{\includegraphics{15-3ia2f6.eps}}
\caption{例3の1文目，2文目から生成される各基本パタンと要素数}
\end{figure}


このようにして，各文節からパタン要素を取り出し，それぞれの文節から係り先の文節のパタン要素をつなげて構文パタンを作成する．つまり，同じ文節に係っているものどうしは同時にひとつの構文パタンの中には存在しないことになる．文末については要素が複数存在するので，それぞれの要素について構文パタンを作成する．図5に例3の各文節から抽出したパタン要素と文節ごとの係り受けを，図6には例3の1文目，2文目から生成した全ての基本パタンを示す．また，``＊''は任意の文字列を意味している．

各基本パタンにはそのときのパタンの要素数が付与される．文末文節以外の文節からは1文節から抽出された要素に対して一要素とし，文末文節から抽出された要素に対しては，一形態素で一要素として計算している．ただし，句点はカウントしない．例えば，例3の1文目の基本パタン「＊は＊ものと＊はずだった。」では，文末文節以外の文節から抽出された要素が「＊は」，「＊ものと」の2つであり，文末文節から抽出された要素「＊はずだった。」は句点を除いて三形態素からなるので，この基本パタンの要素数は5となる．

\subsubsection{基本パタンの組み合わせによる構文パタンの生成}

生成した1文目と2文目の基本パタンのすべての組み合わせを，入力に対する構文パタンとする．各構文パタンの要素数は組み合わせた基本パタンの要素数の合計となる．例えば，図6から1文目の基本パタン「LOCATIONの＊は＊ものと＊はずだった。」と2文目の基本パタン「＊に＊ない＊を＊た。」を組み合わせて，要素数$10(6+4)$の構文パタン「LOCATIONの＊は＊ものと＊はずだった。＊に＊ない＊を＊た。」ができる．図6では，1文目と2文目からの基本パタンがそれぞれ9パタンと6パタンであるため，最終的に全ての組み合わせで54個の構文パタンが生成されることになる．

\subsection{候補文の抽出}

5.1.3節で生成したパタンに適合する2文の組をコーパスから探す．ここで，パタンに適合したコーパス中の2文の組を候補文と呼ぶ．入力に対して最も類似した文はこの候補文の中から探す．パタンの照合に使用したコーパスはWeb文書から抽出した約120万事例である．

生成したパタンを要素数の多いものから順に同じ要素数のパタンを一組として照合させる．ここでは120万事例から入力に最も近い1文を探すための絞込みをすることが目的であるので，ある程度の閾値で候補を絞る必要がある．しかしここで絞りすぎるのも問題である．ここでは実験的に，抽出された候補文が100セットを超えたときパタンの照合を終了するとした．つまり，例えば例3の入力文から得られるパタンのうち最も多い要素数をもつパタンは「LOCATIONの＊は＊ものと＊はずだった。＊に＊ない＊を＊た。」と「LOCATIONの＊は＊ものと＊はずだった。＊と＊ない＊を＊た。」である．これらを使って抽出してきた候補文の累計が100に満たない場合，さらに次の要素数9のパタン群（「LOCATIONの＊は＊ものと＊だった。＊に＊ない＊を＊た。」，「＊にとって＊ものと＊はずだった。＊に＊ない＊を＊た。」，…）を用いて候補文を増やす．

ここで，抽出した候補文に対して7節の単語によるスコア付けによって入力に最も近い文を探す．


単語のクラスタリング

本節では，単語のクラスタリングについて説明する．本節で生成した単語のクラスタは入力文と候補文との類似度を測る際に使用する．なお，本研究ではクラスタリングのためのツールとしてGETA$^{(3)}$を用いた．GETAは大規模で疎な行列の行間あるいは列間の類似度を高速計算する類似度計算ツールであり，クラスタリングライブラリが提供されているように，クラスタリングとして利用することが可能である．

\subsection{クラスタリングに用いた素性}

1文目，および2文目の述語と，1文目，2文目それぞれの述語に係る格要素のそれぞれについて接続関係が同じ文で用いられやすい単語のクラスタを作成する．すなわち，ここでは4種類のクラスタリングを行うことになる．単語のクラスタリングではGETAの処理時間との兼ね合いもあり，データセット1万セットで分類を行った．クラスタと単語は一対一ではなく，ある単語が複数のクラスタに属す場合も存在する．



\vspace{\baselineskip}
\begin{minipage}{183pt}
例4) \\
\includegraphics{15-3ia2-4.eps}
\end{minipage}
\hspace{2zw}
\begin{minipage}{165pt}
例5)\\
\includegraphics{15-3ia2-5.eps}
\end{minipage}
\vspace{\baselineskip}



\noindent
\ul{\mbox{i) 述語の同定}}

本節で述べる述語とは，茶筌の品詞体系で「動詞」（基本形が「する」，「ある」，「なる」，「せる」，「れる」，「られる」であるものを除く）と「名詞--サ変」および「形容詞」となるもので，文末文節中で最も文末に近いものをいう．ここで，品詞が動詞，及び形容詞であるものは全て基本形にしている\footnote{
	実際には，今回のテストデータにおいては形容詞は全て基本形で出現していた．
}．また，品詞が「動詞」で，基本形が「する」，「ある」，「なる」，「せる」，「れる」，「られる」となるもののみが文末文節にある場合はその係り元文節内で同様にして探す．

すなわち，例4では「読む」が述語となり，例5では「勉強」が述語となる．ここで，サ変名詞に他の名詞が後続する場合，例えば「勉強方法にある」のような場合も「勉強」を述語とした．

\noindent
\ul{\mbox{ii) 述語に係る格要素の抽出}}

述語に係る格要素とは，i) で抽出した述語を含む文節に係る格文節で，文節末が「名詞\footnote{
	ここでいう「名詞」はIPADICにおける「名詞--一般」および「名詞--サ変」を指す．
	固有名詞は個別性が高いため，ここでの対象とはしなかった．
}＋助詞」となるもの全てを指す．さらに名詞が連続している場合は末尾の名詞のみを使用する．「名詞＋の」は格要素として使用していない．また，述語が抽出されなかった場合は文末文節に係る格要素をここでいう述語に係る格要素として使用している．

例4では述語「読む」に係る「本＋を」が格要素となる．例5では「勉強」に係る文節が「数学の」のみであるが，これは「名詞＋の」の形であるため採用されない．よって，この例からは格要素は抽出されない．

以下では，例えば，1文目の述語をクラスタリングする場合，1文目をtarget, 2文目をsourceと呼ぶことにする．2文目の述語をクラスタリングする場合は2文目がtarget, 1文目がsourceとなる．述語に係る格要素のクラスタリング素性に関しても同様である．また，今回「述語が無い」または「格要素が無い」という情報は，クラスタリングの素性としては与えていない．

本研究では，対象を述語とそれに係る格要素に限定した．これ以外の要素，例えば修飾語などの語句が接続関係の決定に影響する可能性は完全には否定できないが，我々はこれらを考慮することによる利得よりも素性数が増加して統計的な有意性を生じない損失のほうが大きいと考え，クラスタリングの対象素性からは除外した．

\begin{table}[t]
\caption{述語のクラスタリングに用いた素性と重み}
\input{02table05.txt}
\end{table}
\begin{table}[t]
\caption{述語に係る格要素のクラスタリングに用いた素性と重み}
\input{02table06.txt}
\end{table}


表5，表6に述語と述語に係る格要素のクラスタリングに用いた素性と重みを示す．これらを素性として，GETAでは文書分類や単語シソーラスの自動構築に用いられている階層的ベイズクラスタリング(Iwayama et al. 1995)での分類を行っている．階層的クラスタリングとは，多次元のデータセットに対して，要素間の類似度に基づいて比較的「近い」要素群をクラスタとして発見する分析手法の1つである．GETAでは各アイテム（ここでは述語および格要素）の中で最も「近い」ものから順にボトムアップで各アイテムをまとめあげていく．一般的な木構造とは違い，同じ階層は存在せず，指定したクラスタ数になるように分割点を決定する（図7）．

\begin{figure}[t]
\centerline{\includegraphics{15-3ia2f7.eps}}
\caption{GETAによるクラスタリング構造}
\end{figure}

\subsection{クラスタ数の決定}

クラスタリングを行う際，クラスタ数をどのように設定すればよいか．本論文ではクラスタ中のエントロピーを用いて自動的にクラスタ数を決定する．

あるデータDのエントロピーは次式で求められる．
\begin{equation}
H(D) = -\sum_{接続関係 i} P_{i} \log_{2} P_{i}
\end{equation}

ここで，$P_{i}$ はデータ中の接続関係 $i$ の割合を示す．

また，分割後のエントロピーは各クラスタ中のエントロピーの加重平均で表される．例えばクラスタ数2の場合，分割前のデータを $D_{0}$，分割後のデータをそれぞれ $D_{1}$, $D_{2}$ とし，データ $D_{i}$ のデータの個数を$|D_{i}|$，エントロピーを $H(D_{i})$ とすると分割後のエントロピー $H (D_{1}+D_{2})$ は以下の式で求められる．
\begin{equation}
 H(D_{1} + D_{2}) = \frac{|D_{1}|}{|D_{0}|} H(D_{1}) + \frac{|D_{2}|}{|D_{0}|} H(D_{2})
\end{equation}


さらに，次の条件のいずれかを満たす場合にはクラスタリングを行わないとした．

［条件1］任意の単語Aがすべてのクラスに属す場合

［条件2］1種類の単語だけで構成されているクラスが存在する場合

本論文では，単語のクラスタを単語の汎化の目的で使用するため，1種類の単語しか存在しないクラスタは汎化の意味をもたないと考え2番目の条件を加えた．したがって，1つのクラスタに複数の単語が存在するという条件の下でエントロピーの小さいクラスタを生成する．

1文目の述語 $(V_{1})$, 2文目の述語 $(V_{2})$, 1文目の述語に係る格要素 $(N_{1})$, 2文目の述語に係る格要素 $(N_{2})$ の4種類のクラスタリングについて，それぞれ指定したクラスタ数と分割後のエントロピーの関係を図8に示す．

\begin{figure}[t]
\centerline{\includegraphics{15-3ia2f8.eps}}
\caption{指定したクラスタ数と分割後のエントロピーの変化}
\end{figure}
\begin{table}[t]
\caption{各分類器で設定したクラスタ数}
\input{02table07.txt}
\end{table}


1種類の単語しか持たないクラスタが出現した時点で分割を停止している（条件2）．そのため実験では，図8に示す範囲で最も小さいエントロピーを持つクラスタ数を利用している．表7に各分類器で設定したクラスタ数を示す．例えば，コーパスから抽出してきた1文目の述語1万単語をGETAでクラスタリングする際のクラスタ数は711である．


候補文のスコア付け

本章では，5節で抽出してきたコーパス中に存在する候補文に対してスコア付けを行い，入力文に最も類似した候補文を探す．

\subsection{構文パタンによるスコア}

5.2節の構文パタンによる候補文の抽出では要素数の多いパタン順に照合を行った．しかし，要素数はパタン生成に使用した文節数，および形態素数であるため，単に要素が多いというだけでは特徴的なパタンであるとはいえない．そこで，入力文$i$から生成した候補文$c$ をコーパスから抽出する際に使用したパタン $PT(i,c)$が特徴的なパタンであるかどうかを表す尺度として，パタン$PT(i,c)$の尤もらしさをパタン$PT(i,c)$がコーパス中で一致した2文の組（候補文）の数の逆数で表す．つまり，例えば構文パタンAに一致して抽出された候補文が$a$, $b$, $c$の3セットだったとする．このとき，パタンAの尤もらしさは1/3となる．さらに，このときの構文パタンの尤もらしさを，その構文パタンによって得られた候補文$c$のパタンスコア$S_{PT}(i,c)$とする．すなわち候補文$a$, $b$, $c$のパタンスコアは全て1/3となる．

また，構文パタンAに一致する候補文は，構文パタンAから一要素だけ減らした構文パタンBにも一致する．つまり，コーパス中の2文の組Xが構文パタン「＊は＊ものと＊はずだった。＊は＊た。」に一致するならば，Xは構文パタン「＊は＊ものと＊だった。＊は＊た。」にも一致する．しかし，照合の際に使用した構文パタンが違うため，これらは区別して扱う．すなわち，候補文aについて，構文パタンAによって得られた$a$: A（候補文：使用した構文パタン）と構文パタンBによって得られた$a$: Bは別物であり，それぞれの構文パタンがコーパス中で一致した2文の組数によってパタンスコアは異なる．
\begin{equation}
 S_{PT}(i,c) = \frac{1}{PT(i,c)にマッチするコーパス中の候補文の数}
\end{equation}


\subsection{単語スコア}

はじめに，5.1節と同様にして入力文から1文目，および2文目の述語($V_{1i}$, $V_{2i}$)と，1文目，2文目それぞれの述語に係る格要素($N_{1i}$, $N_{2i}$)を抽出する．候補文からも同様に取り出し($V_{1c}$, $V_{2c}$, $N_{1c}$, $N_{2c}$), 4種類の単語に対してそれぞれ単語スコアを計算する．

\noindent
\ul{\mbox{i) 述語による単語スコア}}

入力文$i$が与えられたときの，1文目の述語による候補文$c$のスコアと，2文目の述語による候補文$c$のスコアをそれぞれ$S_{V1}(i,c)$，$S_{V2}(i,c)$とする．$S_{V1}(i,c)$の初期値を0.001とし，図9の条件に従ってそれぞれのスコアを加算する．$S_{V2}(i,c)$も同様に計算する．

\noindent
\ul{\mbox{ii) 述語に係る格要素による単語スコア}}

入力文$i$が与えられたときの，1文目の述語に係る格要素による候補文$c$のスコアと，2文目の述語に係る格要素による候補文$c$のスコアをそれぞれ$S_{N1}(i,c)$，$S_{N2}(i,c)$とする．また，述語に係る格要素は全て「A（名詞）+B（助詞）」の形になっているが，「助詞」を一般化して「A（名詞）+助詞」にしたものを$N'_{1}$, $N'_{2}$としている．この場合，参照するクラスタは「助詞」を一般化する前のものと同一のものを使用し，クラスタを参照する際に全ての「助詞」を対象としている．$S_{N1}(i,c)$の初期値を0.001とし，図10の条件に従ってそれぞれのスコアを加算する．$S_{N2}(i,c)$も同様に計算する．


\begin{figure}[b]
\centerline{\includegraphics{15-3ia2f9.eps}}
\caption{述語による単語スコアの加算方法}
\end{figure}
\begin{figure}[b]
\centerline{\includegraphics{15-3ia2f10.eps}}
\caption{述語に係る格要素による単語スコアの加算方法}
\end{figure}


\subsection{候補文に対するスコア計算}

7.1節と7.2節で求めたパタンスコアと単語スコアを用いて(4)の計算式により候補文$c$の入力文に対する類似度を計算した．
\begin{equation}
 \mathit{Sim}(i,c) = S_{PT}(i,c) \times \{(S_{V1}(i,c)\times S_{V2}(i,c)) \times (S_{N1}(i,c)\times S_{V1}(i,c)) \times (S_{N1}(i,c)\times S_{V2}(i,c))\}
\end{equation}

1文目の述語が入力文の1文目の述語と同一もしくは類似であったとしても，2文目の述語がまったく異なるものでは入力文と候補文が類似であるとはいえないため，$S_{V1}(i,c)$と$S_{V2}(i,c)$を掛け合わせている．また，述語が同一もしくは類似であるときに格要素の類似性が重要になってくるため，1文目と2文目でそれぞれ述語と格要素のスコアを掛け合わせている．式(4)はパタンスコアとそれらを全て掛け合わせたものである．式(4)を簡略化したものを式(5)に示す．
\begin{equation}
 \mathit{Sim}(i,c) = S_{PT}(i,c) \times \{S_{N1}(i,c)\times S_{V1}(i,c)^{2} \times S_{N2}(i,c)\times S_{V1}(i,c)^{2}\}
\end{equation}

この類似度が最も高い候補文の接続関係を入力の2文間の接続関係として出力する．


