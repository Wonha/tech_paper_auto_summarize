
「[MATH]乗する」あるいは「相対確率密度比を取る」という手法は，元の確率密度比が1以下である全てのデータに対してその値を上方に修正するが，提案手法は一部のデータに対してはNB法の確率密度比が1以下であっても，それらを上方に修正できない．
提案手法により確率密度比の値が大きくならず，逆に小さくなったデータの個数を表[REF_tab:down]に示す．
ほとんどのデータに対して，その確率密度比を上方に修正しているが，修正できていないデータが極端に多いケースも存在する．
例えば，PB→PNに関しては「言う」「自分」「見る」「やる」「ゆく」，OC→PNに関しては「書く」「見る」「やる」「ゆく」である．
これらに関してのみBaseとNBと提案手法の正解率の比較を表[REF_tab:down-pre]に示す．
表[REF_tab:down-pre]からわかるように，上方修正ができないデータが多くなると，提案手法はNB法よりも正解率が下がっている．
ただし，下方に修正した場合には必ず正解率が下がるとも言えないことに注意したい．
例えば，確率密度比の値を下げないようにするには提案手法を修正し，「NB法の値を上方に修正できなければ，NB法の値をそのまま使う」という形にすれば良い．
この修正案の手法も試した結果を表[REF_tab:resultsyuusei]に示す．
修正案の手法の平均正解率は，提案手法よりも若干悪かった．
上記の実験はNB法による確率密度比が1以下かどうかは考慮していない．
「p乗する」や「相対確率密度比を取る」手法では，確率密度比が1以上の場合に，その値を逆に小さくしている．
確率密度比が1以上の場合に，上方修正する方がよいのか下方修正する方がよいのかは未解決である．
参考として上記の修正案の手法を更に修正し，「NB法の値が1以上の場合，あるいはNB法の値を上方に修正できな場合にはNB法の値をそのまま使う」という形の実験も行った．
結果，平均正解率は72.14と若干改善はされたが，提案手法よりも若干悪いことに変化はなかった．
データの確率密度比（重み）はその値の大きさが重要ではなく，他データとの重みとの関係が本質的である．
例えば全てのデータの重みを10倍して，値自体を増やしても，推定できるパラメータが変化しないのは，重み付き対数尤度（式[REF_eq:2]）の最大化する部分が変化しないことから明らかである．
データの重みはタスクの背景知識から，その重要度を設定していくか，そのデータを数値化した後に確率密度比という観点から設定していくしか方法はないと考える．
提案手法は後者であり，コーパスのスパース性への対処からNB法を改良した手法と考えている．
上方修正することに，どのような意味があるかを調べることは今後の課題である．
提案手法は，確率密度比を上方修正する手法と組み合わせて利用することで更なる精度改善も可能である．
提案手法の確率密度比を[MATH]乗した場合の平均正解率の変化を図[REF_zu1]に示す．
[MATH]のとき最大値72.54%をとった．
また提案手法の確率密度比に対してパラメータ[MATH]の相対確率密度比をとった場合の平均正解率の変化を図[REF_zu2]に示す．
[MATH]のとき最大値72.30%をとった．
ともに確率密度比を上方修正することで平均正解率は改善されている．
本論文の以降の記述において，提案手法の重みを[MATH]乗した値を重みにする手法を「P-提案手法」，提案手法の重みを相対確率密度比により上方修正した値を重みにする手法を「A-提案手法」と名付ける．
ここで[MATH]，[MATH]である．
また前節で行った有意差の検定を「P-提案手法」と「A-提案手法」に対しても行った．
結果，「P-提案手法」はP-NBや提案手法を含む全ての手法に対して有意に優れていた．
ただし「A-提案手法」はP-NBや提案手法とに有意な差はなかった．
本論文で提案した確率密度比（重み）はNB法やuLSIFによる確率密度比よりも，有効に機能していた．
ただし真の確率密度比の値は未知であるために，真の値に近いかどうかという観点での評価は不可能である．
また重みの設定だけで，どの程度まで平均正解率が向上できるのかも未知である．
一方，Misleadingデータを削除してから学習を行うことでかなりの精度向上が可能であることが論文[CITE]により示されている．
Misleadingデータを削除してから学習することは，Misleadingデータの重みを0，それ以外のデータの重みを1とした重み付き学習と見なせる．
この重み付けが真の確率密度比と類似しているかどうかは不明だが，Misleadingデータに対してはできるだけ小さな重みを与える手法が優れているとみなせる．
そこでここでは各手法においてMisleadingデータに付与された重みを調べることで手法を評価する．
まず論文[CITE]で行ったように，しらみつぶしにMisleadingを見つけ出す．
領域[MATH]から領域[MATH]の領域適応において，対象単語[MATH]の[MATH]上のラベル付きデータ[MATH]が存在する．
まず[MATH]で学習した識別器の[MATH]に対する正解率[MATH]を測る．
次に[MATH]から1つデータ[MATH]を取り除き，[MATH]から学習した識別器の[MATH]に対する正解率[MATH]を測る．
[MATH]となった場合，データ[MATH]をMisleadingデータと見なす．
これを[MATH]内のすべてのデータに対して行い，[MATH]から[MATH]の領域適応における対象単語[MATH]のMisleadingデータを見つける．
この処理によって見つけ出されたMisleadingデータの個数を表[REF_tab:mislead]示す．
括弧内の数値は全データ数である．
またMisleadingによる重みを用いた学習の識別結果を表[REF_tab:resultmis]に示す．
表中のMisleadがそれにあたる．
本論文の実験で得られている平均正解率よりもかなり高い．
つまり重みの設定のみでもBaseの平均正解率71.71%を少なくとも75.42%まで改善可能である．
次に各手法がMisleadingデータに付与した重みにより手法を評価する．
領域[MATH]から領域[MATH]の領域適応において，対象単語[MATH]の[MATH]上のラベル付きデータを[MATH]とする．
まず[MATH]内のデータの重みの平均値[MATH]を調べる．
次に[MATH]内のMisleadingデータを[MATH]とする．
各[MATH]の重み[MATH]が[MATH]と比較して小さな値であればよいので，対象単語[MATH]に関するMisleadingデータを用いた評価値[MATH]を以下で測る．
[MATH]は対象単語[MATH]の訓練データの重みの平均値[MATH]に対して，Misleadingデータ[MATH]の重み[MATH]の比を取り，その比の平均を取ったものである．
このため[MATH]の値が小さいほど，適切に重み付けできていると考えられる．
そして[MATH]の各単語に関して平均を取った値を，その手法における[MATH]から[MATH]のMisleadingデータを用いた評価値（小さいほど良い）とする．
これをまとめたものが表[REF_tab:miseval]である．
表[REF_tab:miseval]が示すように，Misleadingデータを用いた評価では，NB法，uLSIF及び提案手法の3つの中でuLSIFが最も優れている．
ただし提案手法はNB法よりも優れていた．
更に全ての手法において「[MATH]乗する」，あるいは「相対確率密度比を取る」ことで評価値は改善されており，重みを上方修正する効果があることがわかる．
また「[MATH]乗する」と「相対確率密度比を取る」を比較すると，「[MATH]乗する」方が効果があることもわかる．
NB法やuLSIFはBaseよりも平均正解率が低い．
これは確率密度比からの重み付き学習が効果がなかったことを示している．
この原因として，WSDの領域適応では，領域の変化はあるが，実際には領域適応の問題が生じていない，つまり負の転移[CITE]が生じていない対象単語がかなり存在するからだと考える．
負の転移が生じていなければ，訓練データを全て利用して学習する方が有利であることは明らかであり，重みをつけると逆効果になると考えられる．
この点を確認するために，負の転移が生じているものと生じていないものに分けて，各手法の平均正解率を測ってみる．
まず負の転移が生じている単語の判定であるが，これは表[REF_tab:mislead]で示したMisleadingデータの個数から行う．
ここではMisleadingデータが全データの1割以下の場合，負の転移が生じないと判定した．
結果を表[REF_tab:mislead2]に示す．
チェックが付いているものが「負の転移が生じない」と判定したものである．
表[REF_tab:mislead2]でチェックがついていない対象単語に限定して，各手法の平均正解率を測った結果が表[REF_tab:del-fu-kekka]である．
また逆に表[REF_tab:mislead2]でチェックがついている対象単語に限定して，各手法の平均正解率を測った結果が表[REF_tab:del-fu-kekka2]である．
表[REF_tab:del-fu-kekka]と表[REF_tab:del-fu-kekka2]からわかるように，NB法やuLSIFは負の転移が生じる，生じないに関わらず，Baseよりも平均正解率が低く，本実験においては有効ではなかった．
一方，提案手法は負の転移が生じる場合でも，生じない場合でもBaseよりも平均正解率が高く，どちらの場合でも有効であることがわかる．
また負の転移が生じる場合，提案手法の平均正解率はNB法の平均正解率の1.09倍であり，uLSIFの平均正解率1.05倍である．
一方，負の転移が生じない場合，提案手法の平均正解率はNB法の平均正解率の1.02倍であり，uLSIFの平均正解率1.03倍である．
つまり負の転移が生じるケースで提案手法と既存手法（NB法，uLSIF）との差が大きくなる．
更に確率密度比を上方修正する効果をみてみる．
負の転移が生じる場合，NB法は平均正解率60.69%が[MATH]乗することで65.19%，相対確率密度比を取ることで65.35%まで向上しているので，平均的には7.5%平均正解率が向上している．
同様に計算してuLSIFの平均正解率は3.6%，提案手法の平均正解率は0.5%向上している．
負の転移が生じない場合，NB法は1.4%，uLSIFは2.8%平均正解率が向上している．
また提案手法では平均正解率はほとんど変化しない．
つまり確率密度比を上方修正する効果は負の転移が生じるケースで顕著になっている．
今後の課題としてはMisleadingデータの検出方法を考案することである．
Misleadingデータを検出し，そのデータに重みを0にすることはかなりの精度向上が期待できる．
またMisleadingデータの割合から負の転移の有無を判定し，負の転移が生じる問題にだけ，重み付け学習手法を適用するアプローチも効果があると考えられる．
論文[CITE]は本論文と同じタスクに対して一部同じデータを用いた実験結果を示している．
ここではそこでの実験結果の値と本論文の実験結果の値を比較し，手法間の違いを考察する．
論文[CITE]の核となるアイデアは，ターゲット領域[MATH]のトピックモデルを作成し，ターゲット領域に特有のシソーラスを構築することである．
このシソーラスの情報を素性として組み込むことで，識別精度を上げることを狙っている．
実験はOC→PBとPB→OCの2方向である．
また対象単語は本論文の16単語の他「来る」が含まれている．
OC→PBとPB→OCの領域適応における，本論文の対象単語16単語についての識別精度の比較を表[REF_tm-hikaku1]と表[REF_tm-hikaku2]に示す．
なお表中のSVM-TM-kNNは論文[CITE]の手法を意味する．
対象単語に応じて最も高い正解率の手法は異なるが，平均的にはSVM-TM-kNNが最も高い正解率を示している．
ただしSVM-TM-kNNはトピックモデルを構築するために，ターゲット領域のコーパスを利用していることに注意したい．
本論文の提案手法はターゲット領域の対象単語の用例を用いているが，コーパスは利用していない．
つまり利用しているリソースが異なるために，単純にSVM-TM-kNNが提案手法よりも優れているとは結論できない．
またSVM-TM-kNNにおけるトピックモデルは素性構築の際に利用されているだけであり，提案手法と競合するものではない．
つまりSVM-TM-kNNの手法を利用して，WSDでの素性を構築し，それに対して本論文の提案手法を適用することも可能である．
今後はこの方向での改良も試みたい．
本論文では，WSDの領域適応に対して，共変量シフト下の学習を試みた．
共変量シフト下の学習では確率密度比を重みとした重み付き学習を行うが，WSDのタスクでは算出される確率密度比が小さくなる傾向があるため，ソース領域のコーパスとターゲット領域のコーパスとを合わせたコーパスをソース領域のコーパスと見なしてNB法を用いる手法を提案した．
BCCWJの3つの領域OC（Yahoo!知恵袋），PB（書籍）及びPN（新聞）に共通して出現する多義語16単語を対象にして，WSDの領域適応の実験を行った．
NB法，uLSIF及び提案手法を比較すると，提案手法が最も高い平均正解率を出した．
また「[MATH]乗する」や「相対確率密度比を取る」といった確率密度比を上方修正する手法も試し，提案手法のように確率密度比を上方修正する効果を確認した．
またMisleadingデータをしらみつぶし的に取り出し，Misleadingデータを用いた手法の評価も行った．
Misleadingデータを利用した評価ではuLSIFが優れていたが，提案手法はNB法の改良になっていることを確認できた．
WSDの領域適応の場合，Misleadingデータの検出あるいは負の転移の有無を判定することが，精度改善に大きく寄与できる．
今後はこの点の研究を進めたい．
またトピックモデルの利用も検討したい．
