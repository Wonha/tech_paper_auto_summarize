考察

\subsection{確率密度比を上方修正しないケース}

「$p$乗する」あるいは「相対確率密度比を取る」という手法は，
元の確率密度比が 1 以下である全てのデータに対
してその値を
上方に修正するが，
提案手法は一部のデータに対しては
NB 法の確率密度比が 1 以下であっても，それらを
上方に修正できない．
提案手法により確率密度比の値が大きくならず，逆に小さくなったデータの個数を\mbox{表\ref{tab:down}}に示す．

\begin{table}[b]
\caption{上方修正できなかったデータの個数}
\label{tab:down}
\input{02table04.txt}
\end{table}

ほとんどのデータに対して，その確率密度比を上方に修正しているが，修正できていないデータが極端に多い
ケースも存在する．例えば，PB→PN に関しては「言う」「自分」「見る」「やる」「ゆく」，
OC→PN に関しては「書く」「見る」「やる」「ゆく」である．
これらに関してのみ Base と NB と提案手法の正解率の比較を\mbox{表\ref{tab:down-pre}}に示す．

\mbox{表\ref{tab:down-pre}}からわかるように，上方修正ができないデータが多くなると，
提案手法は NB 法よりも正解率が下がっている．
ただし，下方に修正した場合には必ず正解率が下がるとも言えないことに注意したい．
例えば，確率密度比の値を下げないようにするには提案手法を修正し，
「 NB 法の値を上方に修正できなければ，NB 法の値をそのまま使う」という形にすれば良い．
この修正案の手法も試した結果を\mbox{表\ref{tab:resultsyuusei}}に示す．
修正案の手法の平均正解率は，提案手法よりも若干悪かった．

\begin{table}[t]
\caption{上方修正できなかったデータの正解率(\%)}
\label{tab:down-pre}
\input{02table05.txt}
\end{table}
\begin{table}[t]
\caption{修正版提案手法の平均正解率(\%)}
\label{tab:resultsyuusei}
\input{02table06.txt}
\end{table}

上記の実験は NB 法による確率密度比が 1 以下かどうかは考慮していない．
「p 乗する」や「相対確率密度比を取る」手法では，確率密度比が 1 以上の場合に，
その値を逆に小さくしている．確率密度比が 1 以上の場合に，上方修正する方がよいのか
下方修正する方がよいのかは未解決である．参考として上記の修正案の手法
を更に修正し，「 NB 法の値が 1 以上の場合，あるいは NB 法の値を上方に修正できな場合には
NB 法の値をそのまま使う」という形の実験も行った．結果，平均正解率は 72.14 と
若干改善はされたが，提案手法よりも若干悪いことに変化はなかった．

データの確率密度比（重み）はその値の大きさが重要ではなく，他データとの重みとの関係が本質的である．
例えば全てのデータの重みを 10倍して，値自体を増やしても，推定できるパラメータが
変化しないのは，重み付き対数尤度（\mbox{式\ref{eq:2}}）の最大化する部分が
変化しないことから明らかである．

データの重みは
タスクの背景知識から，その重要度を
設定していくか，
そのデータを数値化した後に
確率密度比という観点から設定していくしか方法はないと考える．
提案手法は後者であり，コーパスのスパース性への対処から NB 法を改良した手法と考えている．
上方修正することに，どのような意味があるかを調べることは今後の課題である．


\subsection{提案手法の重みの上方修正}

\begin{figure}[b]
\begin{center}
\includegraphics{21-5ia2f1.eps}
\end{center}
\caption{$p$ 乗による提案手法値の上方修正}\label{zu1}
\end{figure} 
\begin{figure}[tb]
\begin{center}
\includegraphics{21-5ia2f2.eps}
\end{center}
\caption{相対確率密度比による提案手法値の上方修正}\label{zu2}
\end{figure} 

提案手法は，確率密度比を上方修正する手法と組み合わせて利用することで更なる精度改善も可能である．
提案手法の確率密度比を$p$乗した場合の平均正解率の変化を\mbox{図\ref{zu1}}に示す．
$p = 0.6$のとき最大値 72.54\% をとった．
また提案手法の確率密度比に対してパラメータ$\alpha$の相対確率密度比をとった場合の
平均正解率の変化を\mbox{図\ref{zu2}}に示す．
$\alpha = 0.6$のとき最大値 72.30\% をとった．
ともに確率密度比を上方修正することで平均正解率は改善されている．

本論文の以降の記述において，
提案手法の重みを$p$乗した値を重みにする手法を「P-提案手法」，
提案手法の重みを相対確率密度比により上方修正した値を重みにする手法を「A-提案手法」と名付ける．
ここで$p = 0.6$，$\alpha = 0.6$である．

また前節で行った有意差の検定を「P-提案手法」と「A-提案手法」に対しても行った．
結果，「P-提案手法」は P-NB や提案手法を含む全ての手法に対して有意に優れていた．
ただし「A-提案手法」は P-NB や提案手法とに有意な差はなかった．


\subsection{Misleading データからの評価}

本論文で提案した確率密度比（重み）は NB 法や uLSIF による確率密度比よりも，有効に機能していた．
ただし真の確率密度比の値は未知であるために，真の値に近いかどうかという観点での評価は
不可能である．また重みの設定だけで，どの程度まで平均正解率が向上できるのかも未知である．
一方，Misleading データを削除してから学習を行うことでかなりの精度向上が可能であることが
論文\cite{yoshida}により示されている．Misleading データを削除してから学習することは，
Misleading データの重みを 0，
それ以外のデータの重みを 1 とした重み付き学習と見なせる．
この重み付けが真の確率密度比と類似しているかどうかは不明だが，
Misleading データに対してはできるだけ小さな重みを与える手法が優れているとみなせる．
そこでここでは各手法において Misleading データに付与された重みを調べることで手法を評価する．

まず論文\cite{yoshida}で行ったように，しらみつぶしに Misleading を見つけ出す．
領域$S$から領域$T$の領域適応において，対象単語$w$の
$S$上のラベル付きデータ$D$が存在する．
まず$D$で学習した識別器の$T$に対する正解率$p_0$を測る．
次に$D$から 1 つデータ$x$を取り除き，$D - \{x\}$
から学習した識別器の$T$に対する正解率$p_1$を測る．
$p_1 > p_0$となった場合，データ$x$を Misleading データと見なす．
これを$D$内のすべてのデータに対して行い，
$S$から$T$の領域適応における対象単語$w$の Misleading データを見つける．
この処理によって見つけ出された Misleading データの個数を\mbox{表\ref{tab:mislead}}示す．
括弧内の数値は全データ数である．

また Misleading による重みを用いた学習の
識別結果を\mbox{表\ref{tab:resultmis}}に示す．表中の Mislead がそれにあたる．
本論文の実験で得られている平均正解率よりもかなり高い．
つまり重みの設定のみでも Base の平均正解率 71.71\% を少なくとも 75.42\% まで改善可能である．

\begin{table}[t]
\caption{Misleading データの個数}
\label{tab:mislead}
\input{02table07.txt}
\end{table}
\normalsize
\begin{table}[t]
\caption{Misleading による重みを用いた学習の平均正解率(\%)}
\label{tab:resultmis}
\input{02table08.txt}
\end{table}

次に各手法が Misleading データに付与した重みにより手法を評価する．
領域$S$から領域$T$の領域適応において，対象単語$w$の
$S$上のラベル付きデータを$D = \{ x_i \}_{i=1}^{N_w}$とする．
まず$D$内のデータの重みの平均値$m_w$を調べる．
\[
m_w = \frac{1}{N_w} \sum_{i=1}^{N_w} w(x_i)
\]
次に$D$内の Misleading データを
$\{ x'_j \}_{j=1}^{M_w}$とする．各$x'_j$の重み$w(x'_j)$が$m_w$と比較して
小さな値であればよいので，対象単語$w$に関する Misleading データを用いた評価値$d_w$を以下で測る．
\[
d_w = \frac{1}{M_w} \sum_{j=1}^{M_w} \frac{w(x'_j)}{m_w}
\]
$d_w$は対象単語$w$の訓練データの重みの平均値$m_w$に対して，
Misleading データ$x'_j$の重み$w(x'_j)$の比を取り，
その比の平均を取ったものである．このため$d_w$の値が小さいほど，
適切に重み付けできていると考えられる．
そして
$d_w$の各単語に関して平均を取った値を，
その手法における$S$から$T$の Misleading  データを用いた評価値（小さいほど良い）とする．
これをまとめたものが\mbox{表\ref{tab:miseval}}である．
\mbox{表\ref{tab:miseval}}が示すように，
Misleading  データを用いた評価では，NB法，uLSIF 及び提案手法の3つの中で uLSIF が最も優れている．
ただし提案手法は NB法よりも優れていた．
更に全ての手法において「$p$乗する」，あるいは「相対確率密度比を取る」ことで評価値は改善されており，
重みを上方修正する効果があることがわかる．
また「$p$乗する」と「相対確率密度比を取る」を比較すると，「$p$乗する」方が効果が
あることもわかる．

\begin{table}[t]
\caption{Misleading データからの評価値}
\label{tab:miseval}
\input{02table09.txt}
\end{table}



\subsection{負の転移の有無}

NB法や uLSIF は Base よりも平均正解率が低い．これは確率密度比からの重み付き学習が効果が
なかったことを示している．この原因として，WSD の領域適応では，領域の変化はあるが，
実際には領域適応の問題が生じていない，つまり負の転移\cite{rosenstein2005transfer}が生じていない対象単語が
かなり存在するからだと考える．負の転移が生じていなければ，訓練データを全て利用して
学習する方が有利であることは明らかであり，重みをつけると逆効果になると考えられる．

この点を確認するために，負の転移が生じているものと生じていないものに分けて，
各手法の平均正解率を測ってみる．
まず負の転移が生じている単語の判定であるが，これは\mbox{表\ref{tab:mislead}}で
示した Misleading データの個数から行う．ここでは Misleading データが全データの 1割以下の場合，
負の転移が生じないと判定した．結果を\mbox{表\ref{tab:mislead2}}に示す．
チェックが付いているものが「負の転移が生じない」と判定したものである．

\mbox{表\ref{tab:mislead2}}でチェックがついていない対象単語に限定して，
各手法の平均正解率を測った結果が\mbox{表\ref{tab:del-fu-kekka}}である．
また逆に\mbox{表\ref{tab:mislead2}}でチェックがついている対象単語に限定して，
各手法の平均正解率を測った結果が\mbox{表\ref{tab:del-fu-kekka2}}である．

\begin{table}[t]
\caption{負の転移が生じない単語}
\label{tab:mislead2}
\input{02table10.txt}
\end{table}
\begin{table}[t]
\caption{負の転移が生じる単語に限定した平均正解率(\%)}
\label{tab:del-fu-kekka}
\input{02table11.txt}
\end{table}

\mbox{表\ref{tab:del-fu-kekka}}と\mbox{表\ref{tab:del-fu-kekka2}}からわかるように，
NB 法や uLSIF は負の転移が生じる，生じないに関わらず，Base よりも平均正解率が低く，
本実験においては有効ではなかった．一方，提案手法は負の転移が生じる場合でも，生じない場合でも
Base よりも平均正解率が高く，どちらの場合でも有効であることがわかる．

また負の転移が生じる場合，提案手法の平均正解率は NB 法の平均正解率の 1.09 倍であり，
uLSIF の平均正解率 1.05 倍である．
一方，負の転移が生じない場合，
提案手法の平均正解率は NB 法の平均正解率の 1.02 倍であり，
uLSIF の平均正解率 1.03 倍である．
つまり負の転移が生じるケースで提案手法と既存手法（NB法，uLSIF）との差が大きくなる．

更に確率密度比を上方修正する効果をみてみる．負の転移が生じる場合，NB 法は 
平均正解率 60.69\% が$p$乗することで  65.19\%，相対確率密度比を取ることで 65.35\% まで向上しているので，
平均的には 7.5\% 平均正解率が向上している
\footnote{$((65.19 + 65.35)/2)/60.69 \approx 1.075$ から算出した．}．
同様に計算して uLSIF の平均正解率は 3.6\%，提案手法の平均正解率は 0.5\% 向上している．
負の転移が生じない場合，NB 法は 1.4\%，uLSIF は 2.8\% 平均正解率が向上している．
また提案手法では平均正解率はほとんど変化しない．
つまり確率密度比を上方修正する効果は負の転移が生じるケースで顕著になっている．

\begin{table}[t]
\caption{負の転移が生じない単語に限定した平均正解率(\%)}
\label{tab:del-fu-kekka2}
\input{02table12.txt}
\end{table}

今後の課題としては Misleading データの検出方法を考案することである．
Misleading データを検出し，そのデータに重みを 0 にすることは
かなりの精度向上が期待できる．また Misleading データの割合から負の転移の有無を判定し，
負の転移が生じる問題にだけ，重み付け学習手法を適用するアプローチも効果があると考えられる．


\subsection{トピックモデルの利用}

論文\cite{shinnou-gengo-13}は本論文と同じタスクに対して一部同じデータを用いた
実験結果を示している．ここではそこでの実験結果の値と本論文の実験結果の
値を比較し，手法間の違いを考察する．

論文\cite{shinnou-gengo-13}の核となるアイデアは，ターゲット領域$T$の
トピックモデルを作成し，ターゲット領域に特有のシソーラスを構築することである．
このシソーラスの情報を素性として組み込むことで，識別精度を上げることを狙っている．
実験は OC → PB と
\mbox{PB → OC}の2方向である． また対象単語は
本論文の 16 単語の他「来る」が含まれている
\footnote{本論文では「来る」は PN の領域において曖昧性がないため対象単語から外した．}．

\begin{table}[p]
\caption{正解率(\%)の比較 (OC → PB)}
\label{tm-hikaku1}
\input{02table13.txt}
\end{table}
\begin{table}[p]
\caption{正解率(\%)の比較 (PB → OC)}
\label{tm-hikaku2}
\input{02table14.txt}
\end{table}

OC → PB と PB → OC の領域適応における，本論文の対象単語 16 単語についての識別精度の
比較を\mbox{表\ref{tm-hikaku1}}と\mbox{表\ref{tm-hikaku2}}に示す．
なお表中の SVM-TM-kNN は論文\cite{shinnou-gengo-13}の手法を意味する．

対象単語に応じて最も高い正解率の手法は異なるが，平均的には SVM-TM-kNN が最も高い正解率を
示している．ただし  SVM-TM-kNN はトピックモデルを構築するために，ターゲット領域のコーパスを
利用していることに注意したい．本論文の提案手法はターゲット領域の対象単語の
用例を用いているが，コーパスは利用していない．つまり利用しているリソースが異なるために，
単純に SVM-TM-kNN が提案手法よりも優れているとは結論できない．

また SVM-TM-kNN におけるトピックモデルは素性構築の際に利用されているだけであり，
提案手法と競合するものではない．つまり SVM-TM-kNN の手法を利用して，
WSD での素性を構築し，それに対して本論文の提案手法を適用することも可能である．
今後はこの方向での改良も試みたい．


おわりに

本論文では，WSD の領域適応に対して，共変量シフト下の学習を試みた．
共変量シフト下の学習では確率密度比を重みとした重み付き学習を行うが，
WSD のタスクでは算出される確率密度比が小さくなる傾向があるため，
ソース領域のコーパスとターゲット領域のコーパスとを合わせたコーパスを
ソース領域のコーパスと見なして NB 法を用いる手法を提案した．

BCCWJ の3つの領域 OC（Yahoo! 知恵袋），PB（書籍）及び PN（新聞）に
共通して出現する多義語 16単語を対象にして，WSD の領域適応の実験を行った．
NB法，uLSIF 及び提案手法を比較すると，提案手法が最も高い平均正解率を出した．
また「$p$乗する」や「相対確率密度比を取る」といった確率密度比を上方修正する手法も試し，
提案手法のように確率密度比を上方修正する効果を確認した．

また Misleading データをしらみつぶし的に取り出し，Misleading データを用いた
手法の評価も行った．Misleading データを利用した評価では uLSIF が優れていたが，
提案手法は NB法の改良になっていることを確認できた．
WSD の領域適応の場合，Misleading データの検出あるいは負の転移の有無を判定することが，
精度改善に大きく寄与できる．今後はこの点の研究を進めたい．
またトピックモデルの利用も検討したい．


\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Chan \BBA\ Ng}{Chan \BBA\ Ng}{2005}]{chan2005word}
Chan, Y.~S.\BBACOMMA\ \BBA\ Ng, H.~T. \BBOP 2005\BBCP.
\newblock \BBOQ Word Sense Disambiguation with Distribution Estimation.\BBCQ\
\newblock In {\Bem Proceedings of IJCAI-2005}, \mbox{\BPGS\ 1010--1015}.

\bibitem[\protect\BCAY{Chan \BBA\ Ng}{Chan \BBA\ Ng}{2006}]{chan2006estimating}
Chan, Y.~S.\BBACOMMA\ \BBA\ Ng, H.~T. \BBOP 2006\BBCP.
\newblock \BBOQ Estimating Class Priors in Domain Adaptation for Word Sense
  Disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of COLING-ACL-2006}, \mbox{\BPGS\ 89--96}.

\bibitem[\protect\BCAY{Chapelle, Sch{\"o}lkopf, \BBA\ Zien}{Chapelle
  et~al.}{2006}]{chapelle2006semi}
Chapelle, O., Sch{\"o}lkopf, B., \BBA\ Zien, A. \BBOP 2006\BBCP.
\newblock {\Bem Semi-Supervised Learning}, \lowercase{\BVOL}~2.
\newblock MIT press Cambridge.

\bibitem[\protect\BCAY{Daum{\'{e}}}{Daum{\'{e}}}{2007}]{daume0}
Daum{\'{e}}, H.~I. \BBOP 2007\BBCP.
\newblock \BBOQ Frustratingly Easy Domain Adaptation.\BBCQ\
\newblock In {\Bem Proceedings of ACL-2007}, \mbox{\BPGS\ 256--263}.

\bibitem[\protect\BCAY{Jiang \BBA\ Zhai}{Jiang \BBA\
  Zhai}{2007}]{jiang2007instance}
Jiang, J.\BBACOMMA\ \BBA\ Zhai, C. \BBOP 2007\BBCP.
\newblock \BBOQ Instance Weighting for Domain Adaptation in NLP.\BBCQ\
\newblock In {\Bem Proceedings of ACL-2007}, \mbox{\BPGS\ 264--271}.

\bibitem[\protect\BCAY{Joachims}{Joachims}{1999}]{joachims1999transductive}
Joachims, T. \BBOP 1999\BBCP.
\newblock \BBOQ Transductive Inference for Text Classification using Support
  Vector Machines.\BBCQ\
\newblock In {\Bem ICML}, \lowercase{\BVOL}~99, \mbox{\BPGS\ 200--209}.

\bibitem[\protect\BCAY{神嶌}{神嶌}{2010}]{kamishima}
神嶌敏弘 \BBOP 2010\BBCP.
\newblock 転移学習.\
\newblock \Jem{人工知能学会誌}, {\Bbf 25}  (4), \mbox{\BPGS\ 572--580}.

\bibitem[\protect\BCAY{Kanamori, Hido, \BBA\ Sugiyama}{Kanamori
  et~al.}{2009}]{kanamori2009least}
Kanamori, T., Hido, S., \BBA\ Sugiyama, M. \BBOP 2009\BBCP.
\newblock \BBOQ A Least-Squares Approach to Direct Importance Estimation.\BBCQ\
\newblock {\Bem The Journal of Machine Learning Research}, {\Bbf 10},
  \mbox{\BPGS\ 1391--1445}.

\bibitem[\protect\BCAY{古宮\JBA 奥村}{古宮\JBA 奥村}{2012}]{komiya-nlp2012}
古宮嘉那子\JBA 奥村学 \BBOP 2012\BBCP.
\newblock 語義曖昧性解消のための領域適応手法の決定木学習による自動選択.\
\newblock \Jem{自然言語処理}, {\Bbf 19}  (3), \mbox{\BPGS\ 143--166}.

\bibitem[\protect\BCAY{古宮\JBA 小谷\JBA 奥村}{古宮 \Jetal
  }{2013}]{komiya-nenji2013}
古宮嘉那子\JBA 小谷善行\JBA 奥村学 \BBOP 2013\BBCP.
\newblock 語義曖昧性解消の領域適応のための訓練事例集合の選択.\
\newblock \Jem{言語処理学会第 19 回年次大会}, \mbox{\BPGS\ C6{--}2}.

\bibitem[\protect\BCAY{Komiya \BBA\ Okumura}{Komiya \BBA\
  Okumura}{2011}]{komiya3}
Komiya, K.\BBACOMMA\ \BBA\ Okumura, M. \BBOP 2011\BBCP.
\newblock \BBOQ Automatic Determination of a Domain Adaptation Method for Word
  Sense Disambiguation using Decision Tree Learning.\BBCQ\
\newblock In {\Bem Proceedings of IJCNLP-2011}, \mbox{\BPGS\ 1107--1115}.

\bibitem[\protect\BCAY{Komiya \BBA\ Okumura}{Komiya \BBA\
  Okumura}{2012}]{komiya2}
Komiya, K.\BBACOMMA\ \BBA\ Okumura, M. \BBOP 2012\BBCP.
\newblock \BBOQ Automatic Domain Adaptation for Word Sense Disambiguation Based
  on Comparison of Multiple Classifiers.\BBCQ\
\newblock In {\Bem Proceedings of PACLIC-2012}, \mbox{\BPGS\ 75--85}.

\bibitem[\protect\BCAY{Maekawa}{Maekawa}{2007}]{bccwj}
Maekawa, K. \BBOP 2007\BBCP.
\newblock \BBOQ Design of a Balanced Corpus of Contemporary Written
  Japanese.\BBCQ\
\newblock In {\Bem Symposium on Large-Scale Knowledge Resources (LKR2007)},
  \mbox{\BPGS\ 55--58}.

\bibitem[\protect\BCAY{森}{森}{2012}]{mori}
森信介 \BBOP 2012\BBCP.
\newblock 自然言語処理における分野適応.\
\newblock \Jem{人工知能学会誌}, {\Bbf 27}  (4), \mbox{\BPGS\ 365--372}.

\bibitem[\protect\BCAY{Okazaki}{Okazaki}{2009}]{Classias}
Okazaki, N. \BBOP 2009\BBCP.
\newblock \BBOQ Classias: A Collection of Machine-Learning Algorithms for
  Classification.\BBCQ.

\bibitem[\protect\BCAY{Okumura, Shirai, Komiya, \BBA\ Yokono}{Okumura
  et~al.}{2010}]{semeval-2010}
Okumura, M., Shirai, K., Komiya, K., \BBA\ Yokono, H. \BBOP 2010\BBCP.
\newblock \BBOQ SemEval-2010 Task: Japanese WSD.\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Workshop on Semantic
  Evaluation}, \mbox{\BPGS\ 69--74}.

\bibitem[\protect\BCAY{Rosenstein, Marx, Kaelbling, \BBA\
  Dietterich}{Rosenstein et~al.}{2005}]{rosenstein2005transfer}
Rosenstein, M.~T., Marx, Z., Kaelbling, L.~P., \BBA\ Dietterich, T.~G. \BBOP
  2005\BBCP.
\newblock \BBOQ To Transfer or Not to Transfer.\BBCQ\
\newblock In {\Bem Proceedings of the NIPS 2005 Workshop on Inductive Transfer:
  10 Years Later}.

\bibitem[\protect\BCAY{齋木\JBA 高村\JBA 奥村}{齋木 \Jetal
  }{2008}]{saiki-2008-03-27}
齋木陽介\JBA 高村大也\JBA 奥村学 \BBOP 2008\BBCP.
\newblock 文の感情極性判定における事例重み付けによるドメイン適応.\
\newblock \Jem{情報処理学会第 184 回自然言語処理研究会, NL-184-10}.

\bibitem[\protect\BCAY{新納\JBA 佐々木}{新納\JBA
  佐々木}{2013}]{shinnou-gengo-13}
新納浩幸\JBA 佐々木稔 \BBOP 2013\BBCP.
\newblock k 近傍法とトピックモデルを利用した語義曖昧性解消の領域適応.\
\newblock \Jem{自然言語処理}, {\Bbf 20}  (5), \mbox{\BPGS\ 707--726}.

\bibitem[\protect\BCAY{新納\JBA 佐々木}{新納\JBA
  佐々木}{2014}]{shinnou-gengo-14}
新納浩幸\JBA 佐々木稔 \BBOP 2014\BBCP.
\newblock 共変量シフトの問題としての語義曖昧性解消の領域適応.\
\newblock \Jem{自然言語処理}, {\Bbf 21}  (1), \mbox{\BPGS\ 61--79}.

\bibitem[\protect\BCAY{新納\JBA 國井\JBA 佐々木}{新納 \Jetal
  }{2014}]{shinnou-jws5}
新納浩幸\JBA 國井慎也\JBA 佐々木稔 \BBOP 2014\BBCP.
\newblock 語義曖昧性解消を対象とした領域固有のシソーラスの構築.\
\newblock \Jem{第 5 回コーパス日本語学ワークショップ}, \mbox{\BPGS\ 199--206}.

\bibitem[\protect\BCAY{Sogaard}{Sogaard}{2013}]{da-book}
Sogaard, A. \BBOP 2013\BBCP.
\newblock {\Bem Semi-Supervised Learning and Domain Adaptation in Natural
  Language Processing}.
\newblock Morgan \& Claypool.

\bibitem[\protect\BCAY{杉山}{杉山}{2006}]{sugiyama-2006-09-05}
杉山将 \BBOP 2006\BBCP.
\newblock 共変量シフト下での教師付き学習.\
\newblock \Jem{日本神経回路学会誌}, {\Bbf 13}  (3), \mbox{\BPGS\ 111--118}.

\bibitem[\protect\BCAY{杉山}{杉山}{2010}]{sugiyama-2010}
杉山将 \BBOP 2010\BBCP.
\newblock 密度比に基づく機械学習の新たなアプローチ.\
\newblock \Jem{統計数理}, {\Bbf 58}  (2), \mbox{\BPGS\ 141--155}.

\bibitem[\protect\BCAY{Sugiyama \BBA\ Kawanabe}{Sugiyama \BBA\
  Kawanabe}{2011}]{sugiyama-book}
Sugiyama, M.\BBACOMMA\ \BBA\ Kawanabe, M. \BBOP 2011\BBCP.
\newblock {\Bem Machine Learning in Non-Stationary Environments: Introduction
  to Covariate Shift Adaptation}.
\newblock MIT Press.

\bibitem[\protect\BCAY{高村}{高村}{2010}]{takamura}
高村大也 \BBOP 2010\BBCP.
\newblock \Jem{言語処理のための機械学習入門}.
\newblock コロナ社.

\bibitem[\protect\BCAY{Yamada, Suzuki, Kanamori, Hachiya, \BBA\
  Sugiyama}{Yamada et~al.}{2011}]{yamada2011relative}
Yamada, M., Suzuki, T., Kanamori, T., Hachiya, H., \BBA\ Sugiyama, M. \BBOP
  2011\BBCP.
\newblock \BBOQ Relative Density-ratio Estimation for Robust Distribution
  Comparison.\BBCQ\
\newblock {\Bem Neural Computation}, {\Bbf 25}  (5), \mbox{\BPGS\ 1370--1370}.

\bibitem[\protect\BCAY{吉田\JBA 新納}{吉田\JBA 新納}{2014}]{yoshida}
吉田拓夢\JBA 新納浩幸 \BBOP 2014\BBCP.
\newblock 外れ値検出手法を利用した Misleading データの検出.\
\newblock \Jem{第 5 回コーパス日本語学ワークショップ}, \mbox{\BPGS\ 49--56}.

\end{thebibliography}



\begin{biography}

\bioauthor{新納　浩幸}{
1985年東京工業大学理学部情報科学科卒業．
1987年同大学大学院理工学研究科情報科学専攻修士課程修了．
同年富士ゼロックス，翌年松下電器を経て，
1993年4月茨城大学工学部システム工学科助手．
1997年10月同学科講師，2001年4月同学科助教授，
現在，茨城大学工学部情報工学科准教授．博士（工学）．
機械学習や統計的手法による自然言語処理の研究に従事．
言語処理学会，情報処理学会，人工知能学会 各会員．
}
\bioauthor{佐々木　稔}{
1996年徳島大学工学部知能情報工学科卒業．
2001年同大学大学院博士後期課程修了．博士（工学）．
2001年12月茨城大学工学部情報工学科助手．
現在，茨城大学工学部情報工学科講師．
機械学習や統計的手法による情報検索，自然言語処理等に関する研究に従事．
言語処理学会，情報処理学会 各会員．
}

\end{biography}

\biodate



