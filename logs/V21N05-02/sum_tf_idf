================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.48562] 本論文では語義曖昧性解消(Word Sense Disambiguation，WSD)の教師なし領域適応の問題に対して，共変量シフト下の学習を試みる．
[i:1, score:0.52134] 共変量シフト下の学習では確率密度比[MATH]を重みとした重み付き学習を行うが，WSDの場合，推定される確率密度比の値が小さくなる傾向がある．
[i:3, score:0.51372] BCCWJの3つの領域OC（Yahoo!知恵袋），PB（書籍）及びPN（新聞）を選び，SemEval-2の日本語WSDタスクのデータを利用して，多義語16種類を対象に，WSDの領域適応の実験を行った．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:8, score:0.51203] 共変量シフト下の学習では確率密度比を重みとした重み付き学習を行うが，WSDのタスクでは算出される確率密度比が小さくなる傾向がある．
[i:25, score:0.45667] 一般に共変量シフト下の学習では確率密度比[MATH]を重みとした以下の重み付き対数尤度を最大にするパラメータ[MATH]を求めることで，[MATH]を構築する．
[i:31, score:0.50982] 本論文では[MATH]と[MATH]をそれぞれ求める手法を用いる際に，ターゲット領域のコーパスとソース領域のコーパスを合わせたコーパスを，新たにソース領域のコーパス[MATH]と見なして確率密度比を求めることを提案する．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:57, score:0.45779] このためWSDの領域適応の場合，半教師付き学習を利用しようとすれば，Transductive学習[CITE]に近い形となるが，ソース領域とターゲット領域が異なる領域適応の形にTransductive学習が利用できるかどうかは明らかではない．
[i:68, score:0.49776] また新納はWSDの領域適応に共変量シフト下の学習を用いているが[CITE]，そこではDaum{e}が提案した素性空間拡張法(Feature Augmentation)[CITE]を組み合わせて利用しているために，これも教師なし領域適応手法ではない．
[i:73, score:0.46632] これはWSDの教師なし領域適応手法であるが，Misleadingデータの検出は困難であり，精度の改善には至っていない．

================================================================
[section type  : proposed_method]
[section title : 期待損失最小化に基づく共変量シフト下の学習]
================================================================
[i:81, score:0.24260] [MATH]をターゲット領域上の分布とすれば，本タスクにおける期待損失[MATH]は以下で表せる．
[i:82, score:0.21144] また[MATH]をソース領域上の分布とすると以下が成立する．
[i:89, score:0.47771] つまり，分類問題の解決に[MATH]のモデルを導入するアプローチを取る場合，共変量シフト下での学習では，確率密度比を重みとした以下に示す重み付き対数尤度[MATH]を最大化するパラメータ[MATH]を求める形となる．

================================================================
[section type  : proposed_method]
[section title : 確率密度比の算出]
================================================================
[i:95, score:0.28161] 確率密度比[MATH]の算出法は大きく2つに分類できる．
[i:96, score:0.16112] 1つは[MATH]と[MATH]を各々推定し，その比を取る手法であり，もう1つは[MATH]を直接モデル化する手法である．
[i:99, score:0.19720] また後者の方法としては論文[CITE]において提案された拘束無し最小二乗重要度適合法(unconstrained Least-Squares Importance Fitting, uLSIF)を利用する．
-----------------------------------------------------
  [subsection title : NB 法]
-----------------------------------------------------
  [i:lead, score:0.04806] 対象単語[MATH]の用例[MATH]の素性リストを[MATH]とする．
.....
  [i:101, score:0.16294] 求めるのは領域[MATH]上の[MATH]の分布[MATH]である．
  [i:104, score:0.19287] 領域[MATH]のコーパス内の[MATH]の全ての用例について素性リストを作成しておく．
  [i:108, score:0.44103] 以上より，ソース領域[MATH]の用例[MATH]に対して，確率密度比[MATH]が計算できる．
-----------------------------------------------------
  [subsection title : uLSIF]
-----------------------------------------------------
  [i:lead, score:0.57390] ソース領域内のデータを[MATH]，ターゲット領域内のデータを[MATH]とするuLSIFでは確率密度比[MATH]を以下の式でモデル化する．
.....
  [i:109, score:0.57390] ソース領域内のデータを[MATH]，ターゲット領域内のデータを[MATH]とするuLSIFでは確率密度比[MATH]を以下の式でモデル化する．
  [i:136, score:0.30085] 以上より，確率密度比を求めるために残されているパラメータは正則化項の係数[MATH]とガウシアンカーネルの幅[MATH]の2つである．
  [i:138, score:0.27245] まずソース領域のデータとターゲット領域のデータをそれぞれ交わりのない[MATH]個の部分集合に分割する．
-----------------------------------------------------
  [subsection title : $P_S({\bm x]
-----------------------------------------------------
  [i:lead, score:0.65104] WSDのタスクではNB法あるいはuLSIFで算出される確率密度比は小さい値を取る傾向があり，実際の学習で用いる際には，少し上方に修正した値を取る方が最終の識別結果が改善されることが多い．
.....
  [i:144, score:0.65104] WSDのタスクではNB法あるいはuLSIFで算出される確率密度比は小さい値を取る傾向があり，実際の学習で用いる際には，少し上方に修正した値を取る方が最終の識別結果が改善されることが多い．
  [i:160, score:0.65212] 本論文では確率密度比を上方に修正するために，ソース領域のデータとターゲット領域のデータを合わせたデータを新たにソース領域のデータとみなし，NB法を用いて[MATH]を補正することを提案する．
  [i:166, score:0.54080] 提案手法の新たなソース領域を[MATH]で表せば，[MATH]が成立していると考えるのは自然であり，この不等式が成立していれば，提案手法により確率密度比は上方に修正される．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[i:177, score:0.36824] 領域適応の方向としてはOC→PB，PB→PN，PN→OC，OC→PN，PN→PB，PB→OCの計6通りの方向が存在する．
[i:187, score:0.66504] (1)重みを考慮しない（重みを1で固定する）手法(Base)，(2) NB法による重みをつけた手法(NB)，(3) NB法の重みを[MATH]乗した値を重みにする手法(P-NB)，(4) NB法の重みを相対確率密度比により上方修正した値を重みにする手法(A-NB)，(5) uLSIFによる重みをつけた手法(uLISF)，(6) uLSIFの重みを[MATH]乗した値を重みにする手法(P-uLSIF)，(7) uLSIFの重みを相対確率密度比により上方修正した値を重みにする手法(A-uLSIF)，(8)提案手法，またすべての手法において学習アルゴリズムとしては最大エントロピー法を用いた．
[i:195, score:0.37127] つまり確率密度比を上方に修正する手法が有効であったことがわかる．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
-----------------------------------------------------
  [subsection title : 確率密度比を上方修正しないケース]
-----------------------------------------------------
  [i:lead, score:0.54023] 「[MATH]乗する」あるいは「相対確率密度比を取る」という手法は，元の確率密度比が1以下である全てのデータに対してその値を上方に修正するが，提案手法は一部のデータに対してはNB法の確率密度比が1以下であっても，それらを上方に修正できない．
.....
  [i:208, score:0.54023] 「[MATH]乗する」あるいは「相対確率密度比を取る」という手法は，元の確率密度比が1以下である全てのデータに対してその値を上方に修正するが，提案手法は一部のデータに対してはNB法の確率密度比が1以下であっても，それらを上方に修正できない．
  [i:210, score:0.37336] ほとんどのデータに対して，その確率密度比を上方に修正しているが，修正できていないデータが極端に多いケースも存在する．
  [i:215, score:0.48069] 例えば，確率密度比の値を下げないようにするには提案手法を修正し，「NB法の値を上方に修正できなければ，NB法の値をそのまま使う」という形にすれば良い．
-----------------------------------------------------
  [subsection title : 提案手法の重みの上方修正]
-----------------------------------------------------
  [i:lead, score:0.37910] 提案手法は，確率密度比を上方修正する手法と組み合わせて利用することで更なる精度改善も可能である．
.....
  [i:228, score:0.37910] 提案手法は，確率密度比を上方修正する手法と組み合わせて利用することで更なる精度改善も可能である．
  [i:233, score:0.38884] ともに確率密度比を上方修正することで平均正解率は改善されている．
  [i:234, score:0.48853] 本論文の以降の記述において，提案手法の重みを[MATH]乗した値を重みにする手法を「P-提案手法」，提案手法の重みを相対確率密度比により上方修正した値を重みにする手法を「A-提案手法」と名付ける．
-----------------------------------------------------
  [subsection title : Misleading データからの評価]
-----------------------------------------------------
  [i:lead, score:0.49258] 本論文で提案した確率密度比（重み）はNB法やuLSIFによる確率密度比よりも，有効に機能していた．
.....
  [i:239, score:0.49258] 本論文で提案した確率密度比（重み）はNB法やuLSIFによる確率密度比よりも，有効に機能していた．
  [i:244, score:0.43867] この重み付けが真の確率密度比と類似しているかどうかは不明だが，Misleadingデータに対してはできるだけ小さな重みを与える手法が優れているとみなせる．
  [i:269, score:0.47487] 更に全ての手法において「[MATH]乗する」，あるいは「相対確率密度比を取る」ことで評価値は改善されており，重みを上方修正する効果があることがわかる．
-----------------------------------------------------
  [subsection title : 負の転移の有無]
-----------------------------------------------------
  [i:lead, score:0.27659] NB法やuLSIFはBaseよりも平均正解率が低い．
.....
  [i:282, score:0.41726] 表[REF_tab:del-fu-kekka]と表[REF_tab:del-fu-kekka2]からわかるように，NB法やuLSIFは負の転移が生じる，生じないに関わらず，Baseよりも平均正解率が低く，本実験においては有効ではなかった．
  [i:288, score:0.51519] 負の転移が生じる場合，NB法は平均正解率60.69%が[MATH]乗することで65.19%，相対確率密度比を取ることで65.35%まで向上しているので，平均的には7.5%平均正解率が向上している．
  [i:292, score:0.43319] つまり確率密度比を上方修正する効果は負の転移が生じるケースで顕著になっている．
-----------------------------------------------------
  [subsection title : トピックモデルの利用]
-----------------------------------------------------
  [i:lead, score:0.03797] 論文[CITE]は本論文と同じタスクに対して一部同じデータを用いた実験結果を示している．
.....
  [i:302, score:0.37338] OC→PBとPB→OCの領域適応における，本論文の対象単語16単語についての識別精度の比較を表[REF_tm-hikaku1]と表[REF_tm-hikaku2]に示す．
  [i:305, score:0.26920] ただしSVM-TM-kNNはトピックモデルを構築するために，ターゲット領域のコーパスを利用していることに注意したい．
  [i:306, score:0.24974] 本論文の提案手法はターゲット領域の対象単語の用例を用いているが，コーパスは利用していない．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:312, score:0.74359] 共変量シフト下の学習では確率密度比を重みとした重み付き学習を行うが，WSDのタスクでは算出される確率密度比が小さくなる傾向があるため，ソース領域のコーパスとターゲット領域のコーパスとを合わせたコーパスをソース領域のコーパスと見なしてNB法を用いる手法を提案した．
[i:313, score:0.49192] BCCWJの3つの領域OC（Yahoo!知恵袋），PB（書籍）及びPN（新聞）に共通して出現する多義語16単語を対象にして，WSDの領域適応の実験を行った．
[i:318, score:0.48860] WSDの領域適応の場合，Misleadingデータの検出あるいは負の転移の有無を判定することが，精度改善に大きく寄与できる．

