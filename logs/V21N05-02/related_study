自然言語処理における領域適応は，帰納学習手法を利用する全てのタスクで生じる問題であるために，その研究は多岐にわたる．
利用手法をおおまかに分類すると，ターゲット領域のラベル付きデータを利用するかしないかで分類できる．
利用する場合を教師付き領域適応手法，利用しない場合を教師なし領域適応手法と呼ぶ．
提案手法は教師なし領域適応手法の範疇に入るので，ここでは教師なし領域適応手法を中心に関連研究を述べる．
領域適応の問題は，一般の教師付き学習手法における訓練事例のスパース性の問題だと捉えることもできる．
そのためターゲット領域のデータにラベルを付与しないという条件では，半教師付き学習[CITE]が教師なし領域適応手法として使えることは明らかである．
ただし半教師付き学習では大量のラベルなしデータを必要とする．
半教師付き学習をWSDに利用する場合，対象単語毎に用例を集める必要があり，しかもターゲット領域のコーパスは新規であることが多いため，対象単語毎の用例を大量に集めることは困難である．
このためWSDの領域適応の場合，半教師付き学習を利用しようとすれば，Transductive学習[CITE]に近い形となるが，ソース領域とターゲット領域が異なる領域適応の形にTransductive学習が利用できるかどうかは明らかではない．
WSDの領域適応をタスクとした教師なし領域適応の研究としては，論文[CITE]の研究がある．
そこでの基本的なアイデアはWSDで使うシソーラスをターゲット領域のコーパスから構築することであるが，WSDで使うシソーラスが分野依存になっているかどうかは明らかではない[CITE]．
またChanはターゲット領域上の語義分布をEMアルゴリズムで推定している[CITE]．
これも教師なし領域適応手法であるが，本論文で扱う領域適応では語義分布の違いは顕著ではなく，効果が期待できない．
本論文は，WSDの領域適応では共変量シフトの仮定が成立していると考え，共変量シフト下の学習を利用する．
共変量シフト下の学習を領域適応に応用した研究としてはJiangの研究[CITE]と齋木の研究[CITE]がある．
Jiangは確率密度比を手動で調整し，モデルにはロジステック回帰を用いている．
また齋木は[MATH]と[MATH]をunigramでモデル化することで確率密度比を推定し，モデルには最大エントロピー法を用いている．
ただしどちらの研究もタスクはWSDではない．
しかもターゲット領域のラベル付きデータを利用しているために，教師なし領域適応手法でもない．
また新納はWSDの領域適応に共変量シフト下の学習を用いているが[CITE]，そこではDaum{e}が提案した素性空間拡張法(Feature Augmentation)[CITE]を組み合わせて利用しているために，これも教師なし領域適応手法ではない．
一方，共変量シフト下の学習は，事例への重み付き学習の一種である．
Jiangは識別精度を悪化させるようなデータをMisleadingデータとして訓練データから取り除いて学習することを試みた[CITE]．
これはMisleadingデータの重みを0にした学習と見なせるため，この手法も重み付き学習手法と見なせる．
吉田はソース領域内の訓練データ[MATH]がターゲット領域から見て外れ値と見なせた場合，[MATH]をMisleadingと判定し，それらを訓練データから取り除いて学習している[CITE]．
これはWSDの教師なし領域適応手法であるが，Misleadingデータの検出は困難であり，精度の改善には至っていない．
またWSDの領域適応をタスクとした古宮の手法[CITE]も重み付き学習と見なせる．
そこでは複数のソース領域のコーパスを用意し，そこから訓練事例をランダムに選択し，選択された訓練データセットの中で，ターゲット領域のテストデータを識別するのに最も適した訓練データセットを選ぶ．
これは全ソース領域のコーパスの訓練データから選択された訓練データの重みを1，それ以外を重み0としていることを意味する．
ただし複数のソース領域のコーパスから対象単語のラベル付き訓練データを集めるのは実際は困難である．
また古宮は上記の研究以外にもWSDの領域適応の研究[CITE]を行っているが，これらは教師付き学習手法となっている．
