期待損失最小化に基づく共変量シフト下の学習

対象単語$w$の語義の集合を$C$，また
$w$の用例${\bm x}$内の$w$の語義を$c$と識別したときの
損失関数を$l({\bm x},c,d)$で表す．$d$は$w$の語義を識別する分類器である．
$P_T({\bm x},c)$ をターゲット領域上の分布とすれば，
本タスクにおける期待損失$L_0$は以下で表せる．
\[
L_0 = \sum_{{\bm x},c} l({\bm x},c,d) P_T({\bm x},c)
\]
また$P_S({\bm x},c)$ をソース領域上の分布とすると以下が成立する．
\[
L_0 = \sum_{{\bm x},c} l({\bm x},c,d) \frac{P_T({\bm x},c)}{P_S({\bm x},c)} P_S({\bm x},c)
\]
ここで共変量シフトの仮定から
\[
\frac{P_T({\bm x},c)}{P_S({\bm x},c)} = \frac{P_T({\bm x})P_T(c|{\bm x})}{P_S({\bm x})P_S(c|{\bm x})} = \frac{P_T({\bm x})}{P_S({\bm x})}
\]
となり，$w({\bm x}) = P_T({\bm x})/P_S({\bm x})$とおくと以下が成立する．
\[
L_0 = \sum_{{\bm x},c} w({\bm x}) l({\bm x},c,d) P_S({\bm x},c)
\]

訓練データを$D = \{ ({\bm x_i},c_i) \}_{i = 1}^N$とし，
$P_S({\bm x},c)$を経験分布で近似すれば，
\[
 L_0 \approx  \frac{1}{N} \sum_{i=1}^N w({\bm x_i}) l({\bm x_i},c_i,d) 
\]
となるので，期待損失最小化の観点から考えると，共変量シフトの問題は以下の式$L_1$を
最小にする$d$を求めればよいことがわかる．
\begin{equation}
    \label{eq:1}
L_1 = \sum_{i=1}^N w({\bm x_i}) l({\bm x_i},c_i,d) 
\end{equation}

分類器$d$として以下の事後確率最大化推定に基づく識別を考える．
\[
d({\bm x}) = \arg \max_{c} P_T(c|{\bm x})
\]
また損失関数として対数損失$- \log P_T(c|{\bm x})$を用いれば，
\mbox{式(\ref{eq:1})}は以下となる．
\[
L_1 = - \sum_{i=1}^N w({\bm x_i}) \log P_T(c_i|{\bm x_i}) 
\]
つまり，分類問題の解決に$P_T(c|{\bm x},{\bm \lambda})$のモデルを導入するアプローチを取る場合，
共変量シフト下での学習では，確率密度比を重みとした以下に示す
重み付き対数尤度$L({\bm \lambda})$を最大化する
パラメータ${\bm \lambda}$を求める形となる．
\begin{equation}
     \label{eq:2}
    L({\bm \lambda}) = \sum_{i=1}^N w({\bm x_i}) \log P_T(c_i|{\bm x_i},{\bm \lambda})        
\end{equation}


ここではモデルとして以下の式で示される最大エントロピー法を用いる．
\begin{equation}
     \label{eq:3}
P_T(c|{\bm x},{\bm \lambda}) = \frac{1}{Z({\bm x},{\bm \lambda})} \exp \left(
\sum_{j=1}^M \lambda_j f_j({\bm x},c)
\right)
\end{equation}
${\bm x} = (x_1,x_2,\cdots,x_M)$が入力，$c$がクラスである．
関数$f_j({\bm x},c)$は素性関数であり，実質${\bm x}$の真のクラスが
$c$のときに$x_j$を返し，そうでないとき 0 を返す関数に設定される．
$Z({\bm x},{\bm \lambda})$は正規化項であり，以下で表せる．
\begin{equation}
     \label{eq:4}
  Z({\bm x},{\bm \lambda}) = \sum_{c \in C} \exp \left(
\sum_{j=1}^M \lambda_j f_j({\bm x},c) 
\right)
\end{equation}
\noindent
そして${\bm \lambda} = (\lambda_1,\lambda_2,\cdots,\lambda_M)$が
素性に対応する重みパラメータとなる．


確率密度比の算出

確率密度比$w({\bm x}) =  P_T({\bm x})/P_S({\bm x})$の算出法は大きく2つに分類できる．
1つは$P_S({\bm x})$と$P_T({\bm x})$を各々推定し，その比を取る手法であり，
もう1つは$w({\bm x})$を直接モデル化する手法である．
ここでは前者の方法として論文\cite{shinnou-gengo-14}において提案された手法を利用する．
簡単化のために本論文ではこの手法を NB 法と名付ける．
また後者の方法としては論文\cite{kanamori2009least}において
提案された拘束無し最小二乗重要度適合法 (unconstrained Least-Squares Importance Fitting, uLSIF)
を利用する．


\subsection{NB 法}

対象単語$w$の用例${\bm x}$の素性リストを$\{ f_1,f_2,\cdots, f_n \}$ とする．
求めるのは領域$R \in \{S, T\}$上の${\bm x}$の分布$P_R ({\bm x})$である．
ここで Naive Bayes で使われるモデルを用いる．Naive Bayes のモデルでは以下を仮定する．
\[
P_R ({\bm x}) = \prod_{i=1}^{n} P_R (f_i) 
\]

領域$R$のコーパス内の$w$の全ての用例について素性リストを作成しておく．
ここで用例の数を$N(R)$とおく．
また$N(R)$個の用例の中で，素性$f$が現れた用例数を$n(R,f)$とおく．
MAP 推定でスムージングを行い，$P_R (f)$を以下で定義する\cite{takamura}．
\[
P_R (f) = \frac{n(R,f) + 1}{N(R) + 2}
\]

以上より，ソース領域$S$の用例${\bm x}$に対して，
確率密度比$w({\bm x}) = P_T ({\bm x})/P_S ({\bm x})$が計算できる．
\[
w({\bm x}) = \frac{P_T ({\bm x})}{P_S ({\bm x})} = \prod_{i=1}^n \left( \frac{n(T,f_i) + 1}{N(T) + 2}\cdot\frac{N(S) + 2}{n(S,f_i) + 1} \right)
\]


\subsection{uLSIF}

ソース領域内のデータを$\{{\bm x_i^s}\}_{i=1}^{N_s}$，
ターゲット領域内のデータを$\{{\bm x_i^t}\}_{i=1}^{N_t}$とする
uLSIF では確率密度比$w({\bm x})$を以下の式でモデル化する．
\begin{align*}
w({\bm x}) & = \sum_{l = 1}^b \alpha_l \psi_l ({\bm x}) \\
           & = {\bm \alpha}\cdot {\bm \psi}({\bm x})
\end{align*}
ただしここで，
$
{\bm \alpha} = (\alpha_1, \alpha_2, \cdots, \alpha_b) 
$，
$
{\bm \psi}({\bm x}) = (\psi_1 ({\bm x}), \psi_2 ({\bm x}), \cdots, \psi_b ({\bm x})) 
$ である．
また$\alpha_l$は正の実数であり，$\psi_l ({\bm x})$は基底関数と呼ばれる
ソース領域のデータ${\bm x}$から正の実数値への関数である．
uLSIF では，概略，自然数$b$と基底関数${\bm \psi}({\bm x}) $を定めた後に，
パラメータ${\bm \alpha}$を推定する手順をとる．

説明の都合上，$b$ と ${\bm \psi}({\bm x})$が定まった後の${\bm \alpha}$の推定を
先に説明する．
$w({\bm x})$のモデルを$\hat{w}({\bm x})$とおくと，
パラメータ$\alpha_l$を推定するには，
$w({\bm x})$と$\hat{w}({\bm x})$の平均2乗誤差$J_0({\bm \alpha})$を
最小にするような${\bm \alpha}$を求めれば良い．
$w({\bm x}) = P_T ({\bm x})/P_S ({\bm x})$に注意すると，$J_0({\bm \alpha})$
は以下のように変形できる．
\begin{align*}
J_0({\bm \alpha}) & = \frac{1}{2} \int (\hat{w}({\bm x})  - w({\bm x}))^2 P_S({\bm x}) d{\bm x} \\
 & = \frac{1}{2} \int \hat{w}({\bm x})^2 P_S({\bm x}) d{\bm x}
	- \int \hat{w}({\bm x}) w({\bm x}) P_S({\bm x}) d{\bm x}
	+ \frac{1}{2} \int w({\bm x})^2 P_S({\bm x}) d{\bm x} \\
 & = \frac{1}{2} \int \hat{w}({\bm x})^2 P_S({\bm x})  d{\bm x}
	- \int \hat{w}({\bm x}) P_T({\bm x}) d{\bm x}
  + \frac{1}{2} \int w({\bm x})^2 P_S({\bm x}) d{\bm x} 
\end{align*}

3項目の式は定数なので，$J_0({\bm \alpha})$を最小にするには，
以下の$J({\bm \alpha})$を最小にすればよい．
\[
J({\bm \alpha}) =  \frac{1}{2} \int \hat{w}({\bm x})^2 P_S({\bm x})  d{\bm x}
  - \int \hat{w}({\bm x}) P_T({\bm x}) d{\bm x} 
\]

$J({\bm \alpha})$を経験分布で近似した$\widehat{J}({\bm \alpha})$は
以下となる．
\begin{equation}
\begin{aligned}[b]
\widehat{J}({\bm \alpha}) & = \frac{1}{2 N_s} \sum_{i=1}^{N_s} \widehat{w}({\bm x_i^s})^2 
  -  \frac{1}{N_t} \sum_{j=1}^{N_t} \widehat{w}({\bm x_j^t}) \\
 & = \frac{1}{2} \sum_{l,l'=1}^b \alpha_l \alpha_{l'} 
	 \left( \frac{1}{N_s} \sum_{i=1}^{N_s} \psi_l({\bm x_i^s}) \psi_{l'}({\bm x_i^s}) \right) 
	 - \sum_{l=1}^b  \alpha_l \left( \frac{1}{N_t} \sum_{j=1}^{N_t} \psi_l({\bm x_j^t})  \right) \\
 & =  \frac{1}{2} {\bm \alpha}^T \widehat{H} {\bm \alpha} - \widehat{h}^T {\bm \alpha}
\end{aligned}
\label{jhatalpha}
\end{equation}

ここで$\widehat{H}$は$b \times b$の行列であり，その$l$行$l'$列の要素
$\widehat{H}_{l,l'}$は以下である．
\[
\widehat{H}_{l,l'} = \frac{1}{N_s} \sum_{i=1}^{N_s}  \psi_l({\bm x_i^s}) \psi_{l'}({\bm x_i^s}) 
\]
また$\widehat{h}$は$b$次元のベクトルであり，その$l$次元目の要素
$\widehat{h}_l$は以下である．
\[
\widehat{h}_l = \frac{1}{N_t} \sum_{j=1}^{N_t} \psi_l({\bm x_j^t}) 
\]

$\widehat{J}({\bm \alpha})$の最小値を求める際に正則化を行う．このとき
付加する正則化項を L2 ノルムに設定し，${\bm \alpha} > 0$の条件を外して，
以下の最小化問題を解く．ここでパラメータ$\lambda$が導入されることに
注意する．$\lambda$は基底関数を設定する際に決められる．
\[
\min_{{\bm \alpha}} \left[ \frac{1}{2} {\bm \alpha}^T \widehat{H} {\bm \alpha}
-\widehat{h}^T {\bm \alpha} + \frac{\lambda}{2} {\bm \alpha}^T {\bm \alpha}
\right]
\]
この最小化問題は制約のない凸2次計画問題であるために，唯一の大域解が得られる．
その解は以下である．
\begin{equation}
    \label{eq:alp-kai1}
\tilde{{\bm \alpha}} = (\widehat{H} + \lambda I_b)^{-1} \widehat{h}^T    
\end{equation}
最後に${\bm \alpha} > 0$の条件に合わせるように，以下の調整を行う．
\begin{equation}
\begin{aligned}[b]
 \widehat{{\bm \alpha}} & = \left( (\max(0,\tilde{\alpha_1}),\max(0,\tilde{\alpha_2}), 
	\cdots, \max(0,\tilde{\alpha_b})            \right) \\
  & = \max( 0_b, \tilde{{\bm \alpha}})
\end{aligned}
\label{eq:alp-kai2}
\end{equation}

パラメータ$b$と基底関数の設定であるが，まず，$b$については以下で設定する
\footnote{本実験では$b$の値は最大 100 となるが，この 100 という数値は
オリジナルの論文\cite{kanamori2009least}で使われた値であり，
本論文でのなんらかの予備実験から得た値ではない．
uLSIF の実験結果はこの値を調整することで多少の向上があったかもしれない．}．
\[
b = \min (100, N_t)
\]
次にターゲット領域のデータから重複を許さずに$b$個の点をランダムに取り出す．
それらの点を$\{ {\bm x_j^t} \}_{j=1}^b$ とおく．
そして基底関数$\psi_l ({\bm x})$を以下のガウシアンカーネルで定義する．
\[
\psi_l ({\bm x}) = K({\bm x},{\bm x_l^t}) = \exp \left( - \frac{|| {\bm x} - {\bm x_l^t} ||^2}{\sigma^2} \right)
\]

以上より，確率密度比を求めるために残されているパラメータは正則化項の係数$\lambda$と
ガウシアンカーネルの幅$\sigma$の2つである．これらのパラメータはグリッドサーチの交差検定で求める．
まずソース領域のデータとターゲット領域のデータをそれぞれ交わりのない$R$個の
部分集合に分割する．それらの部分集合の中で$r$番目の部分集合を除き，残りを結合した
集合を作る．それらを新たなソース領域のデータとターゲット領域のデータと見なす．
そして$\lambda$と$\sigma$をある値に設定し，\mbox{式(\ref{eq:alp-kai1})}と
\mbox{式(\ref{eq:alp-kai2})}より${\bm \alpha}$を求め，
\mbox{式(\ref{jhatalpha})}より$\widehat{J}({\bm \alpha})^{(r)}$の値を求める．$r$を 1 から$R$まで
変化させることで，$R$個の$\widehat{J}({\bm \alpha})^{(r)}$の値が求まり，
それらを平均した値を$\lambda$と$\sigma$に対する
$\widehat{J}({\bm \alpha})$の値とする．次に$\lambda$と$\sigma$を変化させ，
上記手順で得られる$\widehat{J}({\bm \alpha})$の値が最小となる
$\hat{\lambda}$と$\hat{\sigma}$を求め，これを
$\lambda$と$\sigma$の推定値とする．


\subsection{$P_S({\bm x})$の補正による確率密度比の算出}

WSD のタスクでは NB 法あるいは uLSIF で算出される確率密度比は小さい値を取る傾向があり，
実際の学習で用いる際には，少し上方に修正した値を取る方が
最終の識別結果が改善されることが多い．
これは以下の2点から生じていると考えられる．
\begin{itemize}
      \item $T$に${\bm x}$が入っているかは確率的であるが，$S$には必ず${\bm x}$が入っている．
      \item $P_S({\bm x})$を推定するために${\bm x} \in S$を用いるため，訓練データである
${\bm x}$に過学習した結果$P_S({\bm x})$は $P_T({\bm x})$に比べて高く見積もられてしまう．
\end{itemize}

このため，求まった確率密度比を上方に修正する手法が存在する．
論文\cite{sugiyama-2006-09-05}では確率密度比$w({\bm x})$を$p$乗($0 < p < 1$)することを
提案している．また論文\cite{yamada2011relative}では以下で示される相対確率密度比$w'({\bm x})$を
確率密度比として利用することを提案している．
\[
w'({\bm x}) = \frac{P_T({\bm x})}{\alpha P_S({\bm x}) + (1-\alpha) P_T({\bm x})}
\]
ここで$0 < \alpha < 1$である．

確率密度比$w({\bm x})$が 1 以下である場合，
$w({\bm x})$を$p$乗すると上方に修正できることは，それらの比の対数を取れば，
\mbox{$\log w({\bm x}) < 0$}であることから明らかである．
\[
\log \frac{w({\bm x})^p}{w({\bm x})} = (p - 1) \log w({\bm x}) > 0
\]
また相対確率密度比$w'({\bm x})$は以下の変形から
$w({\bm x})$を上方に修正していると見なせる．
\begin{align*}
w'({\bm x}) & = \frac{P_T({\bm x})}{\alpha P_S({\bm x}) + (1-\alpha) P_T({\bm x})}    \\
             & = \frac{1}{\alpha  + (1-\alpha) w({\bm x})} w({\bm x})\\
             & > \frac{1}{\alpha  + (1-\alpha)} w({\bm x})\\
             & = w({\bm x})
\end{align*}

確率密度比が 1 以上である場合，これらの手法は確率密度比を下方に修正するので，
正確には確率密度比を 1 に近づける手法である．しかし，ほとんどの訓練データの確率密度比は
1 以下であるために，ここではこれらの手法を上方修正する手法と呼び，提案手法と対比させる．

本論文では確率密度比を上方に修正するために，
ソース領域のデータとターゲット領域のデータを合わせたデータを新たにソース領域のデータとみなし，
NB 法を用いて$P_S({\bm x})$を補正することを提案する．
これは$S$のスパース性を緩和させることを狙ったものである．
確率密度比が真の値よりも低く見積もられる原因の 1 つは，
$P_S({\bm x})$が真の値よりも高く見積もられるからだと考える．
さらにその原因が$S$のスパース性なので，スパース性を緩和するために
$S$にデータを追加するというアイデアである．ただし追加するデータは$S$
と類似の領域のデータであることが望ましい．
WSD の領域適応の場合，$S$と$T$は完全に異なることはなく，
比較的似ているために，追加するデータとして$T$のデータが利用できると考えた．

提案手法の新たなソース領域を$S+T$で表せば，
$P_S ({\bm x}) >  P_{S+T} ({\bm x})$が成立していると考えるのは自然であり，
この不等式が成立していれば，提案手法により確率密度比は上方に修正される．
ただし，ここで提案手法は必ずしも NB 法の確率密度比を上方に修正できるとは限らないことに注意する．
また提案手法は NB 法の確率密度比が 1 以下かどうかには無関係であることにも注意する．
NB 法の確率密度比が 1 以上であっても，上方に修正する可能性がある．
また$P_{S+T} ({\bm x})$は以下の式を利用して求められる．
\begin{align*}
P_{S+T} (f) & = \frac{n(S+T,f) + 1}{N(S+T) + 2}  \\
           & = \frac{n(S,f) +n(T,f) + 1}{N(S) + N(T) + 2}
 \end{align*}


