
[REF_sec:SVMdict]節において提案した手法の有効性を確認するために，日本経済新聞社英文ビジネスレター文例大事典[CITE]を対訳コーパスとして用いた実験を行った．
コーパスに含まれる対訳文のうち，訓練コーパスとして4,000文，テストコーパスとして1,000文を用い，[REF_sec:learn]節に従い対訳対候補を生成した．
その結果，本論文における実験の対象となった対訳対候補の数は表[REF_tab:candidates]の通りとなった．
また，対訳対候補に含まれる形態数の平均値とコーパス中における対訳対候補の出現頻度の平均値を表[REF_tab:avg_length_count]に示す．
得られた事例から[REF_sec:feature]節に従って素性を生成する．
素性(1a)(1b)のために使用する対訳辞書としてEDICT に含まれる対訳単語対のうち，訓練コーパス中に出現した2,879個を用いた．
素性(4a)(4b)(5a)(5b)のために使用する語として，訓練コーパス中に3回以上出現する語を用いた．
その結果，用意した素性の個数は表[REF_tab:features]の通りとなった．
対訳モデルの学習では，カーネル関数を用いない場合(linear)と2次，3次，4次の多項式型カーネル関数(poly2, poly3, poly4)を用いた場合の実験を行った．
訓練コーパスから得られた事例を用いて対訳モデルの学習を行い，テストコーパスから得られた事例から対訳対の抽出を行った．
それぞれの対訳モデルにおいて抽出アルゴリズムの閾値[MATH]の値を0.1，0.5，0.7，0.9と変化させた時の適合率と再現率を図[REF_fig:result]
に示す．
各点の右に示した数字が閾値[MATH]である．
もっとも良い抽出精度を示した2次多項式型カーネル関数を用いた場合の適合率と再現率を表[REF_tab:result]
に示す．
また2次多項式型カーネル関数を用い，抽出時の閾値[MATH]の時の対訳対の抽出例を表[REF_tab:success]
に示す．
以上の結果から，本論文で提案した手法によって1,000文という比較的小規模なコーパスから低頻度の対訳対でも高い精度で抽出できることが示された．
SVMは使用するカーネル関数とそれに付随するパラメータに自由度があり，それらは実験的に決定する必要がある．
そこで本論文で行った実験においてもカーネル関数を使わない場合(linear)と2次，3次，4次の多項式型カーネル関数(poly2, poly3, poly4)を用いた場合の実験を行った．
linearによる抽出精度は多項式型カーネル関数を使用した場合よりも低い．
[REF_sec:feature]節で述べた素性が，素性同士の依存関係がカーネル関数によって自動的に学習されることを期待しているためであると考えられる．
多項式型カーネル関数を用いた場合には2次(poly2)がもっとも良い抽出精度となった．
本論文で行った実験における訓練事例の数や素性の構成では，2次多項式型カーネル関数によって2個の素性の依存関係を学習することが最適であることを示している．
SVMは，より高次元の多項式型カーネル関数を用いることによってより多くの素性の依存関係を考慮した複雑なモデルを学習することが可能であるが，あまりに多くの素性の依存関係を学習してしまうと，その中には学習する必要のないものも含まれることになり，過学習によってモデルの性能を悪化させる結果になることが予想される．
本論文における実験でも同様の現象が起こっていると考えられる．
訓練コーパスの文数が抽出精度に与える影響を調べるために，訓練コーパスの文数を200文から4,000文まで200文ずつ増やしながら対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率を求める実験を行った結果を図[REF_fig:size_dict] (左)に示す．
使用したカーネル関数は2次多項式型カーネル関数であり，抽出時の閾値[MATH]は0.5とした．
適合率，再現率ともに訓練コーパスの文数にほぼ比例して上昇しており，訓練コーパスの文数が精度に大きな影響を及ぼしていることがわかる．
このため本手法は，対訳モデルの学習において比較的大規模なコーパスを用いる必要がある．
しかし，抽出時には処理を1文単位で行うので，一旦学習が完了してしまえば抽出対象となるコーパスは小規模なものでもよく，たとえ1文からでもそこに含まれる対訳対を抽出することができる．
素性(1a)(1b)で用いている既存の対訳辞書の大きさが抽出精度に与える影響を調べるために，使用する対訳単語対の数を0個から2,800個まで100個ずつ増やしながら対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率を求める実験を行った結果を図[REF_fig:size_dict] (右)に示す．
使用したカーネル関数は2次多項式型カーネル関数であり，抽出時の閾値[MATH]は0.5とした．
適合率，再現率ともに使用する対訳単語対の数にほぼ比例して上昇しており，本手法において使用する対訳辞書は可能なかぎり多くの対訳単語対を含むものを用いた方が良いことがわかる．
素性の重要度を調べるために，[REF_sec:feature]節において述べた素性を1種類ずつ削除して対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率の増減を求める実験を行った結果を表[REF_tab:important_features]に示す．
使用したカーネル関数は2次多項式型カーネル関数であり，抽出時の閾値[MATH]は0.5とした．
適合率と再現率における括弧内の値は素性1個あたりの増減である．
素性1個あたりの精度の増減では，語数による素性(2a)(2b)と品詞による素性(3a)(3b)を削除した時の下落が特に大きい．
(2a)(2b)に属する素性は全ての事例に存在し，(3a)(3b)に属する素性も他の素性に比べるとはるかに多くの事例に存在する素性である．
したがって，モデル構築におけるこれらの役割は大きく，ゆえに削除した時の精度の下落が大きくなると考えられる．
その他では，対訳辞書による素性(1a)(1b)を削除した時の下落が大きい．
素性(1a)は日英両言語の句の中で既存の対訳辞書によって辞書引きできるものがあるかどうかを表しており，この情報が句の対訳関係を推定する際には極めて重要であるという我々の直感と合致する．
また素性(1b)の仮定である「対訳関係にある表現は近傍に出現している語の出現文脈も(言語の違いこそあれ)似ている」という考えが対訳モデルの構築において効果が大きいことが示された．
その他の素性を削除した時も抽出精度の下落を引き起こしており，対訳モデルの構成において有効であることが示された．
認識誤りの原因を調べるために，テストコーパスにおいて正しく認識された事例と正しく認識されなかった事例における素性の出現個数(素性値が0以外となる要素の個数)の平均値を計算した(表[REF_tab:avg_features])．
使用したカーネル関数は2次多項式型カーネル関数であり，抽出時の閾値[MATH]は0.5とした．
出力と記された行において[MATH]と記されている列はシステムが対訳対であると認識した事例を表し，[MATH]と記されている列は対訳対でないと認識した事例を表す．
素性(1b)の行に注目すると，対訳対でないと識別された負事例に対して，対訳対として識別されてしまった負事例における素性(1b)の出現個数の平均値がかなり大きく，正事例の場合の値とあまり差のない値となっている．
このことは，対訳対として識別されてしまった負事例の近傍に対訳単語対がよく現れていることを表している．
本論文における実験では，同一文に現れる語を近傍とし，素性(1b)は辞書中の対訳単語対が近傍に出現するか否かを表しているので，特に頻出する対訳単語対に関する素性(1b)の出現個数は増えやすく，それが認識誤りを招いていると考えられる．
したがって近傍の定義を「同一文内」ではなく，「日本語句・英語句から[MATH]語以内」のように近傍の範囲を狭くしたり「日本語句・英語句と係り受け関係にある」のようにより関連性が強いものだけを素性にすることによってこのような誤りは減らすことができると思われる．
しかし，表[REF_tab:important_features]からわかるように，近傍の範囲を狭くすることによって素性(1b)が減りすぎると精度が下落するので，今回の実験では近傍を「同一文内」とした．
