================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:182] 本論文では，機械学習の一手法であるサポートベクタマシンを用いて文対応付き対訳コーパスから対訳表現を抽出する手法を提案する．
[i:2, score:249] 本手法では対訳モデルの素性として，対訳辞書による素性，語数による素性，品詞による素性，構成語による素性，近傍に出現する語による素性を使用し，サポートベクタマシンに基づく対訳表現の対応度を用いて対訳表現を抽出する．
[i:3, score:248] 既存の手法は対訳表現の対応度の計算に単語の共起関係を利用しているためにデータスパースネスに陥りやすく，低頻度の対訳表現の抽出は困難であるのに対して，本手法は，訓練コーパスによって対訳モデルをあらかじめ学習する必要があるが，一旦モデルを学習してしまえば低頻度の対訳表現でも抽出が可能であるという特徴を持つ．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:8, score:186] しかし，これらの研究の多くは対訳表現の対応度の計算に単語の共起関係を利用しているためにデータスパースネスに陥りやすく，そのため小規模なコーパスから対訳表現を抽出することは難しい．
[i:14, score:213] 我々の手法は，訓練コーパスによって対訳モデルをあらかじめ学習する必要があるが，一旦モデルを学習してしまえば，訓練コーパスにおいて出現回数が少ない対訳表現あるいは訓練コーパスにおいて出現しなかった対訳表現でさえも抽出することができる．
[i:15, score:200] したがってある程度大規模な対訳コーパスから優れた対訳モデルを学習しておけば，サポートベクタマシンの高い汎化能力によって低頻度の対訳表現でも抽出が可能であるという特徴を持つ．

================================================================
[section type  : proposed_method]
[section title : サポートベクタマシン]
================================================================
[i:21, score:122] サポートベクタマシン(Support Vector Machine,以下SVM) [CITE]は，[MATH]個の素性を持つ事例を[MATH]次元ベクトルによって表し，[MATH]において2つのクラスに線形分離する二値分類器である．
[i:36, score:93] よく使われるカーネル関数の例としては多項式型カーネル関数([REF_eq:poly_kernel])などが知られている．
[i:37, score:134] [MATH]次の多項式型カーネル関数による非線形分離は，元の空間[MATH]においては[MATH]個の素性の依存関係を考慮していることに相当する．

================================================================
[section type  : proposed_method]
[section title : SVM を用いた対訳表現の抽出]
================================================================
[i:38, score:197] 本論文で提案する手法は，対訳文となっている日本語文と英語文から，その中に含まれる句の対訳関係を抽出する．
[i:40, score:255] 訓練コーパスにおいて対訳関係となっている表現(対訳対)とそうでない表現を人手によって分類，前者を正事例，後者を負事例とし，これらからSVMによって対訳モデルを学習する([REF_sec:learn]節)．
[i:41, score:208] 対訳文となっている日英両言語の文を構文解析し，得られた句構造から対訳対と成り得る候補(対訳対候補)の集合を作成する．
-----------------------------------------------------
  [subsection title : 使用する素性]
-----------------------------------------------------
  [i:lead, 227] SVMを対訳関係の抽出に用いるためには，対訳対候補から素性ベクトルを作成する必要がある．
.....
  [i:53, score:260] 辞書に含まれる対訳単語対を素性ベクトルの次元に割り当て，対訳対候補の近傍に対訳単語対が現れた場合は対応する次元の値を1とし，そうでなければ0とする．
  [i:61, score:270] 素性(5a)(5b)は，対訳対候補の近傍に現れた内容語に素性ベクトルの次元を割り当て，語が出現すれば対応する次元の値を1とし，そうでなければ0とする素性である．
  [i:64, score:283] カーネル関数によって素性(4a)と(4b)の依存関係，素性(5a)と(5b)の依存関係をモデルに組み込むことによって，既存の対訳辞書に現れない対訳単語対における素性(1a)(1b)と同じ役割を期待することができる．
-----------------------------------------------------
  [subsection title : 対訳モデルの学習]
-----------------------------------------------------
  [i:lead, 199] 訓練コーパス中の各対訳文において対訳関係となっている表現とそうでない表現を人手によって作成する．
.....
  [i:70, score:242] 英文ビジネスレター文例大事典の各対訳文は対訳対となる部分があらかじめマークアップされており，対訳表現として抽出すべき句の制約(部分構文木の高さが5以下の名詞句，動詞句)を満たす対訳対を正事例とした．
  [i:72, score:220] 具体的には，各対訳文に1対ずつある対訳対[MATH] ([MATH]は日本語句，[MATH]は英語句)に対して，日英各文を構文解析することによって得られた句[MATH]や[MATH]を用いた[MATH]や[MATH]を負事例とした．
  [i:74, score:213] これを訓練データとして[REF_sec:svm]節で述べたSVMによって対訳モデルの学習を行い，式([REF_eq:hyperplain])における最適な分離平面[MATH]を得る．
-----------------------------------------------------
  [subsection title : 対訳対の抽出]
-----------------------------------------------------
  [i:lead, 170] まず，抽出の対象となる対訳対の候補を作成する．
.....
  [i:78, score:231] 生成した対訳対候補から[REF_sec:feature]節で述べた方法によって素性ベクトルを作成する．
  [i:80, score:241] 対訳対候補[MATH]に対応する素性ベクトルを[MATH]とした時，最適な分離平面[MATH]を用いて[MATH]の「対訳対らしさ」を以下の式によって表す．
  [i:94, score:241] そのため[REF_sec:learn]節によって対訳モデルを一旦学習してしまえば抽出対象となるコーパスは小規模なものでもよく，たとえ1文からでもそこに含まれる対訳対を抽出することができる．

================================================================
[section type  : experiment_result]
[section title : 実験および考察]
================================================================
[i:95, score:0] 
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, 190] [REF_sec:SVMdict]節において提案した手法の有効性を確認するために，日本経済新聞社英文ビジネスレター文例大事典[CITE]を対訳コーパスとして用いた実験を行った．
.....
  [i:101, score:256] 素性(1a)(1b)のために使用する対訳辞書としてEDICT に含まれる対訳単語対のうち，訓練コーパス中に出現した2,879個を用いた．
  [i:104, score:234] 対訳モデルの学習では，カーネル関数を用いない場合(linear)と2次，3次，4次の多項式型カーネル関数(poly2, poly3, poly4)を用いた場合の実験を行った．
  [i:111, score:247] また2次多項式型カーネル関数を用い，抽出時の閾値[MATH]の時の対訳対の抽出例を表[REF_tab:success]
-----------------------------------------------------
  [subsection title : 対訳モデルと抽出精度]
-----------------------------------------------------
  [i:lead, 55] SVMは使用するカーネル関数とそれに付随するパラメータに自由度があり，それらは実験的に決定する必要がある．
.....
  [i:117, score:118] [REF_sec:feature]節で述べた素性が，素性同士の依存関係がカーネル関数によって自動的に学習されることを期待しているためであると考えられる．
  [i:119, score:162] 本論文で行った実験における訓練事例の数や素性の構成では，2次多項式型カーネル関数によって2個の素性の依存関係を学習することが最適であることを示している．
  [i:120, score:153] SVMは，より高次元の多項式型カーネル関数を用いることによってより多くの素性の依存関係を考慮した複雑なモデルを学習することが可能であるが，あまりに多くの素性の依存関係を学習してしまうと，その中には学習する必要のないものも含まれることになり，過学習によってモデルの性能を悪化させる結果になることが予想される．
-----------------------------------------------------
  [subsection title : 訓練コーパスの大きさと抽出精度]
-----------------------------------------------------
  [i:lead, 220] 訓練コーパスの文数が抽出精度に与える影響を調べるために，訓練コーパスの文数を200文から4,000文まで200文ずつ増やしながら対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率を求める実験を行った結果を図[REF_fig:size_dict] (左)に示す．
.....
  [i:122, score:220] 訓練コーパスの文数が抽出精度に与える影響を調べるために，訓練コーパスの文数を200文から4,000文まで200文ずつ増やしながら対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率を求める実験を行った結果を図[REF_fig:size_dict] (左)に示す．
  [i:125, score:162] このため本手法は，対訳モデルの学習において比較的大規模なコーパスを用いる必要がある．
  [i:126, score:220] しかし，抽出時には処理を1文単位で行うので，一旦学習が完了してしまえば抽出対象となるコーパスは小規模なものでもよく，たとえ1文からでもそこに含まれる対訳対を抽出することができる．
-----------------------------------------------------
  [subsection title : 辞書の大きさと抽出精度]
-----------------------------------------------------
  [i:lead, 301] 素性(1a)(1b)で用いている既存の対訳辞書の大きさが抽出精度に与える影響を調べるために，使用する対訳単語対の数を0個から2,800個まで100個ずつ増やしながら対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率を求める実験を行った結果を図[REF_fig:size_dict] (右)に示す．
.....
  [i:127, score:301] 素性(1a)(1b)で用いている既存の対訳辞書の大きさが抽出精度に与える影響を調べるために，使用する対訳単語対の数を0個から2,800個まで100個ずつ増やしながら対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率を求める実験を行った結果を図[REF_fig:size_dict] (右)に示す．
  [i:128, score:82] 使用したカーネル関数は2次多項式型カーネル関数であり，抽出時の閾値[MATH]は0.5とした．
  [i:129, score:195] 適合率，再現率ともに使用する対訳単語対の数にほぼ比例して上昇しており，本手法において使用する対訳辞書は可能なかぎり多くの対訳単語対を含むものを用いた方が良いことがわかる．
-----------------------------------------------------
  [subsection title : 素性と抽出精度]
-----------------------------------------------------
  [i:lead, 262] 素性の重要度を調べるために，[REF_sec:feature]節において述べた素性を1種類ずつ削除して対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率の増減を求める実験を行った結果を表[REF_tab:important_features]に示す．
.....
  [i:130, score:262] 素性の重要度を調べるために，[REF_sec:feature]節において述べた素性を1種類ずつ削除して対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率の増減を求める実験を行った結果を表[REF_tab:important_features]に示す．
  [i:137, score:228] 素性(1a)は日英両言語の句の中で既存の対訳辞書によって辞書引きできるものがあるかどうかを表しており，この情報が句の対訳関係を推定する際には極めて重要であるという我々の直感と合致する．
  [i:138, score:226] また素性(1b)の仮定である「対訳関係にある表現は近傍に出現している語の出現文脈も(言語の違いこそあれ)似ている」という考えが対訳モデルの構築において効果が大きいことが示された．
-----------------------------------------------------
  [subsection title : 認識誤りと素性]
-----------------------------------------------------
  [i:lead, 105] 認識誤りの原因を調べるために，テストコーパスにおいて正しく認識された事例と正しく認識されなかった事例における素性の出現個数(素性値が0以外となる要素の個数)の平均値を計算した(表[REF_tab:avg_features])．
.....
  [i:143, score:249] 素性(1b)の行に注目すると，対訳対でないと識別された負事例に対して，対訳対として識別されてしまった負事例における素性(1b)の出現個数の平均値がかなり大きく，正事例の場合の値とあまり差のない値となっている．
  [i:144, score:208] このことは，対訳対として識別されてしまった負事例の近傍に対訳単語対がよく現れていることを表している．
  [i:145, score:267] 本論文における実験では，同一文に現れる語を近傍とし，素性(1b)は辞書中の対訳単語対が近傍に出現するか否かを表しているので，特に頻出する対訳単語対に関する素性(1b)の出現個数は増えやすく，それが認識誤りを招いていると考えられる．

================================================================
[section type  : related_study]
[section title : 関連研究との比較]
================================================================
[i:154, score:240] それに対して本手法は対訳表現の抽出を統計的機械学習のアプローチで捉えており，対訳モデルの学習において対訳対の出現回数に依存しない素性を用いて対訳対を特徴づける．
[i:155, score:257] したがって，本手法は訓練コーパスによって対訳モデルをあらかじめ学習する必要がある反面，一旦モデルを学習してしまえば訓練コーパスにおいて出現回数が少ない対訳対あるいは出現しなかった対訳対でさえもデータスパースネスに陥ることなく抽出することができるという特徴がある．
[i:161, score:267] 対訳対候補[MATH]に対応する素性ベクトル[MATH]が正事例である確率[MATH]をME法によって推定し，これを式([REF_eq:sim])の代わりに用いて対訳表現の抽出を行った．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:179, score:238] 対訳モデルの素性として，対訳辞書による素性，語数による素性，品詞による素性，構成語による素性，近傍に出現する語による素性を使用し，SVMに基づく対訳表現の対応度を用いて対訳表現を抽出する．
[i:184, score:262] 対訳モデルの学習に2次多項式型カーネル関数を使用し，抽出時の閾値[MATH]とした時には，1,000文という比較的小規模なコーパスから適合率80.8 %，再現率77.6 %の精度で抽出できることを示した．
[i:186, score:251] しかし，対訳対候補の近傍に現れる語を対訳辞書によって辞書引きして得た素性において近傍の範囲を「同一文内」としていることが認識誤りを増やす原因となっている．

