本論文では[MATH]を仮定したアプローチは取らず，[MATH]を仮定する．この仮定があったとしても，領域[MATH]の訓練データだけから[MATH]を推定するのは困難である．ここではこれをスパース性の問題と考える．つまり領域[MATH]の訓練データ[MATH]は領域[MATH]においてスパースになっていると考える．スパース性の問題だと考えれば，半教師あり学習や能動学習を領域適応に応用するのは自然である (Rai, Saha, Daum{e}, and Venkatasubramanian 2010)[CITE]．また半教師あり学習や能動学習のアプローチを取った場合，[MATH]の訓練データが増えるので語義の分布の違い自体も同時に解消されていく[CITE]．

ここで指摘したいのは[MATH]が成立しており[MATH]の推定を困難にしているのがスパース性の問題だとすれば，領域[MATH]の訓練データ[MATH]は多いほどよい推定が行えるはずで，[MATH]が大きくなったとしても推定が悪化するはずがない点である．しかし現実には[MATH]を大きくするとWSD自体の精度が悪くなる場合もあることが報告されている（例えば[CITE]）．これは一般に負の転移現象[CITE]と呼ばれている．WSDの場合[MATH]を推定しようとして，逆に語義の分布[MATH]の推定が悪化することから生じる．つまり領域[MATH]におけるWSDの解決には[MATH]におけるデータスパースネスの問題に対処しながら，同時に[MATH]の推定が悪化することを避けることが必要となる．

また領域適応ではアンサンブル学習も有効な手法である．アンサンブル学習自体はかなり広い概念であり，実際，バギング，ブースティングまた混合分布もアンサンブル学習の一種である．Daum{e}らは領域適応のための混合モデルを提案している(Daum{e} and Marcu 2006)[CITE]．そこでは，ソース領域のモデル，ターゲット領域のモデル，そしてソース領域とターゲット領域を共有したモデルの3つを混合モデルの構成要素としている．Daiらは代表的なブースティングアルゴリズムのAdaBoostを領域適応の問題に拡張したTrAdaBoostを提案している[CITE]．またKamishimaらはバギングを領域適応の学習用に拡張したTrBaggを提案している[CITE]．WSDの領域適応については古宮の一連の研究[CITE]があるが，そこではターゲット領域のラベルデータの使い方に応じて学習させた複数の分類器を用意しておき，単語や事例毎に最適な分類器を使い分けることで，WSDの領域適応を行っている．これらの研究もアンサンブル学習の一種と見なせる．

paragraph score: 1.00798387289598
