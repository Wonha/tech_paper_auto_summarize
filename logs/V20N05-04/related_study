 本論文では\( P_S (c|x) = P_T (c|x)\)を仮定したアプローチは取らず，
 \( P_S (x|c) = P_T (x|c)\)を仮定する．この仮定があったとしても，
 領域\( S \)の訓練データだけから\( P_T (x|c)\)を推定するのは困難である．
 ここではこれをスパース性の問題と考える．
 つまり領域\( S \)の訓練データ\( D \)は領域\( T \)においてスパースになっていると考える．
 スパース性の問題だと考えれば，半教師あり学習や能動学習を領域適応に応用するのは自然である
 \footnote{ただし\( D \)は領域\( T \)内のサンプルではなく不均衡な訓練データという点には注意すべきであり，この点を考慮した半教師あり学習や能動学習が必要である．}
     (Rai, Saha, Daum{\'e}, and Venkatasubramanian 2010)\nocite{rai2010domain}．
 また半教師あり学習や能動学習のアプローチを取った場合，
 \( T \)の訓練データが増えるので語義の分布の違い自体も同時に解消されていく\cite{chan2007domain}．

 ここで指摘したいのは\( P_S (x|c) = P_T (x|c)\)が成立しており\( P_T (x|c)\)の推定を
 困難にしているのがスパース性の問題だとすれば，領域\( S \)の訓練データ\( D \)は
 多いほどよい推定が行えるはずで，\( D \)が大きくなったとしても推定が悪化するはずがない点である．
 しかし現実には\( D \)を大きくすると WSD 自体の精度が悪くなる場合もあることが報告されている
 （例えば\cite{komiya-nenji2013}）．
 これは一般に負の転移現象\cite{rosenstein2005transfer}と呼ばれている．
 WSD の場合\( P_T (x|c)\)を推定しようとして，逆に語義の分布\( P_T (c)\)の推定が悪化することから
 生じる．
 つまり領域\( T \)における WSD の解決には\( T \)におけるデータスパースネスの問題に対処しながら，
 同時に\( P_T (c)\)の推定が悪化することを避けることが必要となる．

 また領域適応ではアンサンブル学習も有効な手法である．
 アンサンブル学習自体はかなり広い概念であり，
 実際，バギング，ブースティングまた混合分布もアンサンブル学習の一種である．
     Daum{\'e}らは領域適応のための混合モデルを提案している(Daum{\'e} and Marcu 2006)\nocite{daume2006domain}．
 そこでは，ソース領域のモデル，ターゲット領域のモデル，そして
 ソース領域とターゲット領域を共有したモデルの3つを混合モデルの構成要素としている．
 Dai らは代表的なブースティングアルゴリズムの AdaBoost を領域適応の
 問題に拡張した TrAdaBoost を提案している\cite{Dai2007}．
 また Kamishima らはバギングを領域適応の学習用に拡張した TrBagg を提案している\cite{kamishima2009trbagg}．
 WSD の領域適応については古宮の一連の研究\cite{komiya2,komiya3,komiya-nlp2012}があるが，
 そこではターゲット領域のラベルデータの使い方に応じて学習させた複数の分類器を用意しておき，
 単語や事例毎に最適な分類器を使い分けることで，WSD の領域適応を行っている．
 これらの研究もアンサンブル学習の一種と見なせる．
score of this paragraph is 4
