自然言語処理の処理単位としては，単語を基本とするものが一般的である．
しかし，単語は多義性を持つものも多く，文脈の中では一意に意味を決められる場合でも単語ごとに分割した時点でその語の持つ意味を特定できなくなる場合があり，単語が最適な処理単位と言えるかには疑問が残る[CITE]．
処理の単位として意味的な塊としての語句をとった場合，このような多義性の問題等はある程度抑えることができる．
従って，意味的な塊としての語句の認識は，自然言語処理の精度の向上の点で，重要な課題である．
現在研究されている語句抽出システムは，ほとんどが名詞句を対象としたものである．
構文情報を基に名詞句を推定する方法および大規模コーパスからのドメイン固有の語句の抽出とが主に研究されている．
Argamonらは，サブパターンの概念を利用して名詞句をパターンとして認識する，記憶ベースの手法を提案している[CITE]．
また，Ananiadouは語句の組成についての形態論的ルールを利用して語句の認識を行なう手法を提案している[CITE]．
英語のように単語間に区切りを置く言語では，語句の認識は，区切りによって分けられた語を連結する作業となる．
それに対し，日本語は単語間に区切りを置かない言語であるため，日本語においては，単語の抽出プロセスは，文の切り分け作業となる．
日本語は日常的に利用される文字が数千文字と非常に多い．
また，数種類の字種を同時に利用するという点でも，日本語は特徴的である．
文字の共起情報を利用する手法としては，[MATH]-gramの画期的な抽出法を提案した長尾らによるもの[CITE]やOdaらの[MATH]-gramを利用した手法[CITE]が挙げられる．
また，Kashiokaらは，文字の相互情報量を利用した文字クラスタリングシステムを提案し，これを利用した切り分け処理およびタグ付け処理を行なっている[CITE]．
Kashiokaらの手法では処理に必要な情報を得るため，事前に訓練コーパスの単語への切り分けが必要とされる．
単語の共起情報を利用する手法として，Borthwickは，最大エントロピ法に基づく固有名詞抽出の手法を提案している[CITE]．
Borthwickの手法ではあらかじめJumanを用いて切り分けおよびタグ付けを行なっている．
本システムは入力として日本語文一文を採り，訓練コーパスから事前に抽出した文字共起情報を基に文中に含まれる文字列を調べ，意味のある文字列と認めたものを出力する．
以下にシステムの処理の流れを示す(図[REF_fig:flo])．
本システムは入力されたテストコーパスを一文単位で処理する．
入力文中の隣り合う文字ペアそれぞれについて，訓練コーパスから抽出された文字単位共起情報を基に，その二文字の繋がりやすさを示す有繋評価値を算出し，これに基づいてこの二文字が同じ文字列に含まれるものであるかを推測する．
この結果一繋がりと判断された文字列について，その有繋評価値が十分に高いものを統計情報に基づいて意味がある文字列と判断し，これを抽出結果として出力する．
本システムの処理単位は文である．
従って，訓練コーパスから文字単位共起情報を取得する際も，余分な情報を取得しないよう文単位で処理を行なう．
文末は，原則として，文末記号によって決める．
文末記号としては「．
」「！」「？」の他，「……」や「♪」，「★」等文末を示すと認められるものはすべて認める．
また，複数の文末記号が続く場合，その最後の文末記号までを一文とする．
文末記号が現れても，それが引用中である等，文の途中であると認められるような場合にはそこで文を切らない．
e.g.「こんにちは．
」と言った．
また，文末記号がない場合でも，明らかに文の区切り目であると考えられる場合は，文末記号を置かないまま文末とした．
隣接bigramだけでは，AXYBに現れる事象XYとCXYDに現れるXYとを区別することはできない．
日本語のように形態素間の区切り目が明らかでない言語では，単純隣接bigramを利用することで捨てられるこれらの文脈情報が重要な役割を果たすことがある．
本稿では，共起情報を取得する際の確率モデルとしてd-bigramを採用した．
d-bigramとは，事象間の距離を考慮したbigramモデルである[CITE]．
d-bigramモデルは，2つの事象および事象間の距離の3つのパラメータから成っている．
2事象間の距離は，この2事象が隣接して並んでいる時1とする．
例えば，ABBCという事象列からは6種類のd-bigramが取得できる．
距離を考慮しない通常のbigramモデルでは(A, B)が2回カウントされるが，d-bigramモデルの場合，隣り合って出現している(A, B; 1)と一事象間に置いて出現している(A, B; 2)は別の事象として扱われる．
Nobesawaらは文中のある文字の並びが意味のある塊を成すことの起こりやすさを算出するシステムを提案している[CITE]．
この手法は語彙についての知識を一切必要とせず，文字間共起情報のみで文を意味のある塊に切り分けることが可能であることを示した．
実験は日本語について行なわれ，日本語の各文字の共起関係の情報は文中での文字の繋がり方を示すのに十分な情報を持っていることを示した．
本稿ではこの点に着目し，文字間の共起関係を利用して意味のある文字列を推測し自動抽出するシステムを提案することで，辞書等の語彙を非常に小さい労力で補う手法を提案する．
本システムは，有繋評価値と呼ばれる評価値[CITE]を導入する．
有繋評価値とは，隣り合った二文字が一塊の文字列に属する事象の起こりやすさを示す値であり，この値が高いほど，対象となっている隣接二文字ペアが同じ文字列に属する可能性が高い．
有繋評価値は統計情報のみに基づいて算出する値である．
Nobesawaらは有繋評価値の計算にd-bigramを利用することで文脈情報を影響させている．
文中の[MATH]番目の文字と[MATH]番目の文字の間の有繋評価値の算出式を式([REF_exp:uk])に示す．
ただし，[MATH]はある事象(本システムでは，文[MATH]の[MATH]番目の文字)，[MATH]は2事象間の距離(d-bigramの定義による距離)，[MATH]は有繋評価値の算出に利用されるd-bigramの距離[MATH]の最大値(本稿で紹介する実験では[MATH]とした)，[MATH]は距離の影響に対する重み付け関数とする．
また，2事象間の相互情報量の計算式をd-bigramに対応するよう拡張したものとして式([REF_exp:mid])を利用した．
ただし，[MATH]，[MATH]は各事象，[MATH]は2事象間の距離，[MATH]は事象[MATH]が起こる確率，[MATH]はd-bigram ([MATH], [MATH]; [MATH])が起こる確率とする．
図[REF_fig:scoring]に文脈情報の影響のイメージを示す．
ある隣接2文字[MATH]と[MATH]の間の有繋評価値の算出には，この2文字ペアの共起情報だけでなく，その周りに現れる文字ペアの共起情報(例えば([MATH], [MATH]; 3)等)が影響する．
[htb]
本稿で用いるシステムは文字間共起情報を利用して算出する有繋評価値を基に抽出すべき文字列の選択を行なう．
図[REF_fig:scoregraph]に有繋評価値のグラフの例を挙げる．
「ABCDEFGHIJK!」という12文字から成る文字列を入力文としたとし，グラフ中のX軸上のアルファベットはそれぞれ文中の各文字を示す．
末尾の「!」は文末記号を表す．
[htb]
有繋評価値は隣り合う文字ペアそれぞれについて算出される．
グラフ中では，各文字ペア間の有繋評価値をY軸で表している．
有繋評価値は文字間共起情報を基にしており，共起する確率が高い場合ほど値が高くなる．
スコアグラフが山状になっている部分は文字間の繋がりの強い文字の並びであり，この部分は一塊の意味を成すとみなすことが可能である．
有繋評価値の算出には該当文字ペアだけでなくその周りの文字との共起情報も利用されるため，長い文字列では，その文字列に含まれる文字それぞれの共起関係の相乗効果により，文字列の有繋評価値が高くなる傾向がある．
偶然隣り合って並んだ文字ペアの場合，有繋評価値は相対的に低くなり，スコアグラフ上では谷を成す．
本システムでは，スコアグラフで言うところの山状の部分に相当する文字列を有繋文字列(有繋評価値に基づいて一塊と判断された文字列[CITE])として抽出する．
図[REF_fig:scoregraph]の例では，AB，CDEFおよびHIJKがそれぞれ一塊の文字列として出力される．
この手法では，どこまでを山とするかの基準が必要になる．
抽出に際しての基準として，有繋評価値に閾値を設けこの値を越えたものを山とみなす方法と，山の部分の勾配について閾値を設けて前後の文字列との区切り目が明らかなものを山とみなす方法が挙げられる．
この閾値を操作することで，抽出する文字列の種類や精度をある程度調節することが可能である．
確実に一塊となる文字列のみを抽出したい場合には，抽出対象を選出する際の基準を高く設定すればよい．
閾値が高い場合，有繋文字列として出力される文字列の長さが短くなる傾向がある．
これは，例えば複合語等が単語に切り分かれる等，確実に一塊となる部分のみを残そうとする作用が強くなるためである．
自然言語処理の処理単位としては，単語を基本とするものが一般的である．
しかし，単語は多義性を持つものも多く，文脈の中では一意に意味を決められる場合でも単語ごとに分割した時点でその語の持つ意味を特定できなくなる場合があり，単語が最適な処理単位と言えるかには疑問が残る[CITE]．
処理の単位として意味的な塊としての語句をとった場合，このような多義性の問題等はある程度抑えることができる．
従って，意味的な塊としての語句の認識は，自然言語処理の精度の向上の点で，重要な課題である．
現在研究されている語句抽出システムは，ほとんどが名詞句を対象としたものである．
構文情報を基に名詞句を推定する方法および大規模コーパスからのドメイン固有の語句の抽出とが主に研究されている．
Argamonらは，サブパターンの概念を利用して名詞句をパターンとして認識する，記憶ベースの手法を提案している[CITE]．
また，Ananiadouは語句の組成についての形態論的ルールを利用して語句の認識を行なう手法を提案している[CITE]．
英語のように単語間に区切りを置く言語では，語句の認識は，区切りによって分けられた語を連結する作業となる．
それに対し，日本語は単語間に区切りを置かない言語であるため，日本語においては，単語の抽出プロセスは，文の切り分け作業となる．
日本語は日常的に利用される文字が数千文字と非常に多い．
また，数種類の字種を同時に利用するという点でも，日本語は特徴的である．
文字の共起情報を利用する手法としては，[MATH]-gramの画期的な抽出法を提案した長尾らによるもの[CITE]やOdaらの[MATH]-gramを利用した手法[CITE]が挙げられる．
また，Kashiokaらは，文字の相互情報量を利用した文字クラスタリングシステムを提案し，これを利用した切り分け処理およびタグ付け処理を行なっている[CITE]．
Kashiokaらの手法では処理に必要な情報を得るため，事前に訓練コーパスの単語への切り分けが必要とされる．
単語の共起情報を利用する手法として，Borthwickは，最大エントロピ法に基づく固有名詞抽出の手法を提案している[CITE]．
Borthwickの手法ではあらかじめJumanを用いて切り分けおよびタグ付けを行なっている．
本システムは入力として日本語文一文を採り，訓練コーパスから事前に抽出した文字共起情報を基に文中に含まれる文字列を調べ，意味のある文字列と認めたものを出力する．
以下にシステムの処理の流れを示す(図[REF_fig:flo])．
本システムは入力されたテストコーパスを一文単位で処理する．
入力文中の隣り合う文字ペアそれぞれについて，訓練コーパスから抽出された文字単位共起情報を基に，その二文字の繋がりやすさを示す有繋評価値を算出し，これに基づいてこの二文字が同じ文字列に含まれるものであるかを推測する．
この結果一繋がりと判断された文字列について，その有繋評価値が十分に高いものを統計情報に基づいて意味がある文字列と判断し，これを抽出結果として出力する．
本システムの処理単位は文である．
従って，訓練コーパスから文字単位共起情報を取得する際も，余分な情報を取得しないよう文単位で処理を行なう．
文末は，原則として，文末記号によって決める．
文末記号としては「．
」「！」「？」の他，「……」や「♪」，「★」等文末を示すと認められるものはすべて認める．
また，複数の文末記号が続く場合，その最後の文末記号までを一文とする．
文末記号が現れても，それが引用中である等，文の途中であると認められるような場合にはそこで文を切らない．
e.g.「こんにちは．
」と言った．
また，文末記号がない場合でも，明らかに文の区切り目であると考えられる場合は，文末記号を置かないまま文末とした．
隣接bigramだけでは，AXYBに現れる事象XYとCXYDに現れるXYとを区別することはできない．
日本語のように形態素間の区切り目が明らかでない言語では，単純隣接bigramを利用することで捨てられるこれらの文脈情報が重要な役割を果たすことがある．
本稿では，共起情報を取得する際の確率モデルとしてd-bigramを採用した．
d-bigramとは，事象間の距離を考慮したbigramモデルである[CITE]．
d-bigramモデルは，2つの事象および事象間の距離の3つのパラメータから成っている．
2事象間の距離は，この2事象が隣接して並んでいる時1とする．
例えば，ABBCという事象列からは6種類のd-bigramが取得できる．
距離を考慮しない通常のbigramモデルでは(A, B)が2回カウントされるが，d-bigramモデルの場合，隣り合って出現している(A, B; 1)と一事象間に置いて出現している(A, B; 2)は別の事象として扱われる．
Nobesawaらは文中のある文字の並びが意味のある塊を成すことの起こりやすさを算出するシステムを提案している[CITE]．
この手法は語彙についての知識を一切必要とせず，文字間共起情報のみで文を意味のある塊に切り分けることが可能であることを示した．
実験は日本語について行なわれ，日本語の各文字の共起関係の情報は文中での文字の繋がり方を示すのに十分な情報を持っていることを示した．
本稿ではこの点に着目し，文字間の共起関係を利用して意味のある文字列を推測し自動抽出するシステムを提案することで，辞書等の語彙を非常に小さい労力で補う手法を提案する．
本システムは，有繋評価値と呼ばれる評価値[CITE]を導入する．
有繋評価値とは，隣り合った二文字が一塊の文字列に属する事象の起こりやすさを示す値であり，この値が高いほど，対象となっている隣接二文字ペアが同じ文字列に属する可能性が高い．
有繋評価値は統計情報のみに基づいて算出する値である．
Nobesawaらは有繋評価値の計算にd-bigramを利用することで文脈情報を影響させている．
文中の[MATH]番目の文字と[MATH]番目の文字の間の有繋評価値の算出式を式([REF_exp:uk])に示す．
ただし，[MATH]はある事象(本システムでは，文[MATH]の[MATH]番目の文字)，[MATH]は2事象間の距離(d-bigramの定義による距離)，[MATH]は有繋評価値の算出に利用されるd-bigramの距離[MATH]の最大値(本稿で紹介する実験では[MATH]とした)，[MATH]は距離の影響に対する重み付け関数とする．
また，2事象間の相互情報量の計算式をd-bigramに対応するよう拡張したものとして式([REF_exp:mid])を利用した．
ただし，[MATH]，[MATH]は各事象，[MATH]は2事象間の距離，[MATH]は事象[MATH]が起こる確率，[MATH]はd-bigram ([MATH], [MATH]; [MATH])が起こる確率とする．
図[REF_fig:scoring]に文脈情報の影響のイメージを示す．
ある隣接2文字[MATH]と[MATH]の間の有繋評価値の算出には，この2文字ペアの共起情報だけでなく，その周りに現れる文字ペアの共起情報(例えば([MATH], [MATH]; 3)等)が影響する．
[htb]
本稿で用いるシステムは文字間共起情報を利用して算出する有繋評価値を基に抽出すべき文字列の選択を行なう．
図[REF_fig:scoregraph]に有繋評価値のグラフの例を挙げる．
「ABCDEFGHIJK!」という12文字から成る文字列を入力文としたとし，グラフ中のX軸上のアルファベットはそれぞれ文中の各文字を示す．
末尾の「!」は文末記号を表す．
[htb]
有繋評価値は隣り合う文字ペアそれぞれについて算出される．
グラフ中では，各文字ペア間の有繋評価値をY軸で表している．
有繋評価値は文字間共起情報を基にしており，共起する確率が高い場合ほど値が高くなる．
スコアグラフが山状になっている部分は文字間の繋がりの強い文字の並びであり，この部分は一塊の意味を成すとみなすことが可能である．
有繋評価値の算出には該当文字ペアだけでなくその周りの文字との共起情報も利用されるため，長い文字列では，その文字列に含まれる文字それぞれの共起関係の相乗効果により，文字列の有繋評価値が高くなる傾向がある．
偶然隣り合って並んだ文字ペアの場合，有繋評価値は相対的に低くなり，スコアグラフ上では谷を成す．
本システムでは，スコアグラフで言うところの山状の部分に相当する文字列を有繋文字列(有繋評価値に基づいて一塊と判断された文字列[CITE])として抽出する．
図[REF_fig:scoregraph]の例では，AB，CDEFおよびHIJKがそれぞれ一塊の文字列として出力される．
この手法では，どこまでを山とするかの基準が必要になる．
抽出に際しての基準として，有繋評価値に閾値を設けこの値を越えたものを山とみなす方法と，山の部分の勾配について閾値を設けて前後の文字列との区切り目が明らかなものを山とみなす方法が挙げられる．
この閾値を操作することで，抽出する文字列の種類や精度をある程度調節することが可能である．
確実に一塊となる文字列のみを抽出したい場合には，抽出対象を選出する際の基準を高く設定すればよい．
閾値が高い場合，有繋文字列として出力される文字列の長さが短くなる傾向がある．
これは，例えば複合語等が単語に切り分かれる等，確実に一塊となる部分のみを残そうとする作用が強くなるためである．
