実験


SENSEVAL2 の日本語翻訳タスクで課題として出題された全名詞 20 単語に対して
本手法を適用する．

翻訳タスクのコンテストでは，手作業で訓練データを作成し，それを用いて学習するという
オーソドックスな戦略を用いたシステムは Ibaraki だけであった．
ここではそこで用意された訓練データを借用し，Ibaraki の結果と比較することで
本手法を評価する．
Ibaraki では，TM の他に毎日新聞'95年度版から該当単語を含む文を適当な数だけ取りだし，
ラベルを付けることで訓練データを増やしている．名詞に対しては各単語に対して約 50 事例を
追加している．結果として，各単語に対して平均 70 事例がラベル付き訓練データとして用意された．
そのラベル付き訓練データから決定リスト\cite{Yarowsky1}を作成し，
課題の曖昧性解消問題を解いている．
名詞 20 単語に対する Ibaraki の翻訳タスクに対する公式成績を\mbox{表 \ref{result}}に示す
\cite{shinnou-sen2}．


\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{Ibaraki（決定リスト）の正解率}\label{result}
    \begin{tabular}{|c|c|c|c|} \hline
見出し & 訓練事例数      & 決定リストのサイズ & 正解率  \\ \hline
ippan     &   87     &   174    &    0.467       \\ 
ippou     &   63     &   101    &    0.567        \\ 
ima       &   67     &   135    &    0.267        \\ 
imi       &   69     &   181    &    0.700        \\ 
kaku\_n    &  58     &   121       &   0.800         \\ 
kiroku    &   65     &   159       &    0.467        \\ 
kokunai   &   62     &   144       &    0.733        \\ 
kotoba    &   79     &   183       &    0.800        \\ 
shimin    &   64     &   157       &    0.733        \\ 
jigyou    &   66     &   186       &    0.400        \\ 
jidai     &   89     &   249       &    0.800        \\ 
sugata    &   77     &   206       &    0.367        \\ 
chikaku   &   64     &   165        &    0.600        \\ 
chushin   &   61     &   157        &    0.500        \\ 
hana      &   64     &   139       &    0.533        \\ 
hantai    &   73     &   176       &    0.733        \\ 
baai      &   73     &   194       &    0.733        \\ 
mae       &   62     &   161       &    0.700        \\ 
mune      &   79     &   179       &    0.567        \\ 
mondai    &   81     &   204       &    0.500        \\  \hline
    \end{tabular}
  \end{center}
\end{table}

Ibaraki で利用した訓練データを借用し，それを本手法のラベル付き訓練データとした．
次に，毎日新聞'96年度版から該当単語を含む文を取りだし，それを
ラベルなし訓練データとした．

\mbox{表 \ref{result2}}に，名詞 20 単語の各単語に対するラベル付き訓練データ L の数，
ラベルなし訓練データ U の数，ラベル付き訓練データから学習できた決定リスト（DL と略す）による
正解率（Ibaraki の結果），ラベル付き訓練データのみから学習できた Naive Bayes （NB と略す）による
正解率，NB を EM アルゴリズムにより改善させた分類器（NB＋EM と略す）の正解率を示す．

\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{実験結果}\label{result2}
    \begin{tabular}{|c|c|c|c|c|c|} \hline
見出し    &  L    &  U  &  DL      & NB  & NB+EM \\ \hline
ippan     &   87  & 2170  &   0.467  & 0.467    &  0.400      \\ 
ippou     &   63  & 4033  &   0.567  & 0.633    &  0.700     \\ 
ima       &   67  & 5081  &   0.267  & 0.200    &  0.033     \\ 
imi       &   69  & 1761  &   0.700  & 0.467    &  0.467     \\ 
kaku\_n   &   58  & 1135  &   0.800  & 0.767    &  0.700     \\ 
kiroku    &   65  & 1726  &   0.467  & 0.233    &  0.500     \\ 
kokunai   &   62  & 2468  &   0.733  & 0.700    &  0.967     \\ 
kotoba    &   79  & 2225  &   0.800  & 0.900    &  0.967     \\ 
shimin    &   64  & 2069  &   0.733  & 0.567    &  0.500     \\ 
jigyou    &   66  & 3500  &   0.400  & 0.367    &  0.467     \\ 
jidai     &   89  & 4397  &   0.800  & 0.867    &  0.833     \\ 
sugata    &   77  & 1971  &   0.367  & 0.367    &  0.333     \\ 
chikaku   &   64  & 1944  &   0.600  & 0.600    &  0.667     \\ 
chushin   &   61  & 3194  &   0.500  & 0.600    &  0.633     \\ 
hana      &   64  &  851  &   0.533  & 0.633    &  0.667     \\ 
hantai    &   73  & 2103  &   0.733  & 0.900    &  0.967     \\ 
baai      &   73  & 3413  &   0.733  & 0.833    &  0.900     \\ 
mae       &   62  & 10931 &   0.700  & 0.633    &  0.667     \\ 
mune      &   79  &   676 &   0.567  & 0.633    &  0.500     \\ 
mondai    &   81  & 11424 &   0.500  & 0.500    &  0.500     \\  \hline
平均      &   70  &  3354    &   0.589  & 0.582    &  0.618     \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\mbox{表 \ref{result2}}から分るようにラベル付き訓練データ L のみから学習できた
DL も NB もほぼ同等の正解率（58.9\,\% と 58.2\,\%）である．
一方，NB+EM の正解率は 61.8\,\% であり，本手法の効果が確認できる．
特に教師なし学習が効果的に行えた kokunai と kiroku の2単語について，
その学習のグラフを\mbox{図 \ref{kokunai-fig}}と\mbox{図 \ref{kiroku-fig}}に示す．
このグラフの横軸は EM アルゴリズムの繰り返しの回数，縦軸はテスト文に対する正解率を示す．

\begin{figure}[htbp]
\begin{minipage}[t]{70mm}
  \begin{center}
	\epsfxsize=63.5mm
	\epsfbox{kokunai.eps}
  \end{center}
\caption{kokunai の学習}\label{kokunai-fig}
\end{minipage}
\hfill
\begin{minipage}[t]{70mm}
  \begin{center}
	\epsfxsize=63.5mm
	\epsfbox{kiroku.eps}
  \end{center}
\caption{kiroku の学習}\label{kiroku-fig}
\end{minipage}
\end{figure}

\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{大きく精度が下がる単語}\label{badword}
    \begin{tabular}{|c|c|c|} \hline
見出し    &  NB  & NB+EM \\ \hline
ima       &  0.200    &  0.033     \\ 
mune      &  0.633    &  0.500     \\ \hline
    \end{tabular}
  \end{center}
\end{table}

ラベルなし訓練データを用いることで全体の正解率は向上したが，
個々の単語をみると，本手法を利用することで精度が大きく下がる単語が存在する．
具体的には\mbox{表 \ref{badword}}に示す 2 単語である．
調査したところ，これは最初に用意しているラベル付き訓練データ中の誤りが原因であった．
Ibaraki で用意されたラベル付き訓練データは，一部の単語で必要以上に語義を細かく分けている．
上記の2単語はその例であり，特に ima では UNASSIGNABLE のラベル（適切な例文がないことを意味する
ラベル）を付けている事例が 67 事例中 20 事例も存在する．
実際は UNASSIGNABLE のラベルを与えた事例には 
default の語義（この場合，『重要性』の意味で使われている例文番号）を与えるべきであった．
mune でも慣用的な表現が多く細かく語義を分けすぎている．
正解を見れば，『体の一部としての胸』と『心の中』の2つに分類できればよいだけである．
これらを考慮して，この2単語に関しては，ラベル付き訓練データを修正した．
具体的には，ima に対しては UNASSIGNABLE を default の語義に変更し，
mune では語義を2値に変更した．
修正して得られた訓練データに対して，本手法をもう一度試した．
またこれらの2単語に対しては，修正したラベル付き訓練データを利用した
Ibaraki による決定リスト DL の正解率も調べた．
修正して得られた結果を\mbox{表 \ref{result3}}に示す．
結果的にラベル付き訓練データ L  のみから学習できた NB の正解率 62.3\,\% を
本手法により 68.2\,\% まで高めることができた．

\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{一部修正後の実験結果}\label{result3}
    \begin{tabular}{|c|c|c|c|c|c|} \hline
見出し    &  L    &  U  &  DL      & NB  & NB+EM \\ \hline
ippan     &  87   & 2170  &  0.467   & 0.467    &  0.400      \\ 
ippou     &  63   & 4033  &  0.567   & 0.633    &  0.700     \\ 
ima       &  67   & 5081  &  \underline{0.700}    & \underline{0.833}    &  \underline{1.000}     \\ 
imi       &  69   & 1761  &  0.700   & 0.467    &  0.467     \\ 
kaku\_n   &  58   & 1135  &  0.800   & 0.767    &  0.700     \\ 
kiroku    &  65   & 1726  &  0.467   & 0.233    &  0.500     \\ 
kokunai   &  62   & 2468  &  0.733   & 0.700    &  0.967     \\ 
kotoba    &  79   & 2225  &  0.800   & 0.900    &  0.967     \\ 
shimin    &  64   & 2069  &  0.733   & 0.567    &  0.500     \\ 
jigyou    &  66   & 3500  &  0.400   & 0.367    &  0.467     \\ 
jidai     &  89   & 4397  &  0.800   & 0.867    &  0.833     \\ 
sugata    &  77   & 1971  &  0.367   & 0.367    &  0.333     \\ 
chikaku   &  64   & 1944  &  0.600   & 0.600    &  0.667     \\ 
chushin   &  61   & 3194  &  0.500   & 0.600    &  0.633     \\ 
hana      &  64   &  851  &  0.533   & 0.633    &  0.667     \\ 
hantai    &  73   & 2103  &  0.733   & 0.900    &  0.967     \\ 
baai      &  73   & 3413  &  0.733   & 0.833    &  0.900     \\ 
mae       &  62   & 10931 &  0.700   & 0.633    &  0.667     \\ 
mune      &  79   &   676 &  \underline{0.800}    & \underline{0.633}    &  \underline{0.800}     \\ 
mondai    &  81   & 11424 &  0.500   & 0.500    &  0.500     \\  \hline
平均      &  70   &  3354  &  \underline{0.632}  & \underline{0.623}    &  \underline{0.682}     \\ \hline
    \end{tabular}
  \end{center}
\end{table}


