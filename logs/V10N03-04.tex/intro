\section{はじめに}


本論文では，Nigam らによって提案された EM アルゴリズムを利用した
教師なし学習の手法\cite{nigam00}を，SENSEVAL2 の日本語翻訳タスク\cite{sen2}で出題された
名詞の語義の曖昧性解消問題に適用する．
その結果，通常の教師付き学習で得られる分類規則の精度を向上させ得ることを示す．

自然言語処理では個々の問題を分類問題として定式化し，帰納学習の手法を利用して，
その問題を解決するというアプローチが大きな成功をおさめている．
しかしこのアプローチには帰納学習で必要とされる訓練データを用意しなければ
ならないという大きな問題がある．
この問題に対して，近年，少量のラベル付き訓練データから得られる分類器の精度を，
大量のラベルなし訓練データによって高めてゆく教師なし学習が散見される．
代表的な手法として，Co-training\cite{blum98} と，EM アルゴリズムを利用した手法\cite{nigam00}がある．
Co-training は2つの独立した属性 A と B を設定し，一方の属性 A から構築される
分類器を利用して，ラベルなしデータにラベル（クラス）を付与する．その中から信頼性のある
ラベルが付与されたデータをラベル付き訓練データに加える．このようにして追加されたラベル付き訓練データは，
もう一方の属性 B から見るとランダムなサンプルにラベル付けされたデータとして振る舞うので，
属性 B から構築される分類器の精度が高まる．これをお互いに作用し合うことで，
分類器の精度が高められる．一方，
EM アルゴリズムは，部分的に欠損値のある不完全な観測データ\( x_1, x_2, \cdots, x_N \)から，
そのデータを発生する確率モデル\( P_{\theta}(x) \)を推定する手法である．
\( P_{\theta}(x) \)は未知パラメータ\( \theta \)を含み，
\( P_{\theta}(x) \)の推定は，\( \theta \)の推定に帰着される．
分類問題の教師なし学習では，ラベル付き訓練データが完全な観測データ，
ラベルなし訓練データがラベルを欠損値とした不完全な観測データとなる．
EM アルゴリズムは，現時点での\( \theta \)を使って，
モデル\( P_{\theta}(c|x_i) \) のもとでの\( \log P_{\hat{\theta}}(x_i,c) \)の
期待値を取る（E-step）．次に，この期待値を最大にするような\( \hat{\theta} \)を求める（M-Step）．
\( \hat{\theta} \)を新たな\( \theta\)として先の E-step と M-step を繰り返す．
ここで\( c \)は欠損値となるラベルである．
EM アルゴリズムはパラメータ\( \theta \)とモデル\( P_\theta (x) \)を
適切に設定することで，隠れマルコフモデルや文脈自由文法のパラメータ推定，
あるいは名詞と動詞間の関係クラスの教師なし学習\cite{rooth}\cite{torisawa}などに利用できる．
そして，Nigam らは文書分類を題材にモデル\( P_\theta (x) \)を Naive Bayes のモデル，
\( \theta \)をラベル\( c \)のもとで素性\( f \)が起る条件付き確率\( p(f | c) \)に設定
することで，教師なし学習を試みている\cite{nigam00}．

Nigam らの EM アルゴリズムを利用した手法や Co-training は，どちらも本来は文書分類に対して
考案されており，多義語の曖昧性解消に利用できるかどうかは明らかではない．
多義語の曖昧性解消は自然言語処理の中心的な課題であり，これらの手法が
適用できることが望ましい．
ここでは SENSEVAL2 の日本語翻訳タスクで出題された名詞を題材に，
EM アルゴリズムを利用した教師なし学習の手法が名詞の語義の曖昧性解消に適用可能であることを示す．

翻訳タスクの出題形式はある単語\( w \)がマークされた（日本語）文書である．
翻訳タスクでは予め，単語\( w \)に関する Translation Memory（以下 TM と略す）と
呼ばれる日英の対訳例文の集合が
解答者に配られている．そして翻訳タスクの解答形式は，出題された文書内において
注目する単語\( w \)を英訳する際に利用できる TM の例文番号である
\footnote{厳密には，翻訳システムも参加できるように，
英訳自身を返す解答形式も認められているが，
ここでは例文番号を返す解答形式のみを考える．}．
つまり，翻訳タスクは単語\( w \)の訳を語義と考えた多義語の曖昧性解消問題となっている．
また同時に，翻訳タスクは TM の例文番号をクラスと考えた場合の分類問題として扱える．
ここで注意すべきは，翻訳タスクは訓練データを作るのが困難な点である．
TM は1つの単語に対して平均して 21.6 例文がある．
今仮にある単語 \( w \) の例文として\( id_1 \) から \( id_{20} \)までの20例文が 
TM に記載されていたとする．
新たに訓練データを作成する場合，単語 \( w \)を含む新たな文を持ってきて，
\( id_1 \) から \( id_{20} \) のどれか1つのラベルを与える必要がある．
〇か×かの二者択一は比較的容易であるが，20個のラベルの中から
最も適切な1つを選ぶのは非常に負荷のかかる作業である．
このように，翻訳タスクは訓練データを新たに作るのが困難であるために，
教師なし学習を適用する格好のタスクになっている．

実験では SENSEVAL2 の日本語翻訳タスクで出題された全名詞 20 単語を用いて，本手法の評価を行う．
各単語に対して，平均 70事例（TM の例文も含む）からなるラベル付き訓練データと，
新聞記事1年分から取り出した平均 3,354事例からなるラベルなし訓練データを作成し，
本手法を適用した．
ラベル付き訓練データだけから学習できた決定リストの正解率は
58.9\,\% (コンテストでの Ibaraki の成績)であり，Naive Bayes による分類器の正解率は 58.2\,\% であった．
そして本手法を用いて Naive Bayes による分類器の精度を高めた結果 61.8\,\% まで改善された．
また一部，訓練データの不具合を修正することで，Naive Bayes による分類器の正解率を 62.3\,\%，
決定リストでの正解率を 63.2\,\% に向上できた．更に，本手法を用いて Naive Bayes による
分類器の正解率（62.3\,\%）を 68.2\,\% まで高めることができた．


