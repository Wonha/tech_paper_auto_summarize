



\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setcounter{page}{61}
\setcounter{巻数}{10}
\setcounter{号数}{3}
\setcounter{年}{2003}
\setcounter{月}{4}
\受付{2002}{4}{9}
\再受付{2002}{7}{10}
\再々受付{2002}{8}{20}
\採録{2002}{8}{20}

\setcounter{secnumdepth}{2}

\title{EM アルゴリズムを用いた教師なし学習の\\
日本語翻訳タスクへの適用}
\author{新納 浩幸\affiref{ibaraki}}
\headauthor{新納}

\headtitle{EM アルゴリズムを用いた教師なし学習の日本語翻訳タスクへの適用}
\affilabel{ibaraki}{茨城大学工学部システム工学科}
{Department of Systems Engineering, Ibaraki University}

\jabstract{
本論文では，Nigam らによって提案された EM アルゴリズムを利用した教師なし学習の手法を，
SENSEVAL2 の日本語翻訳タスクで出題された名詞の語義の曖昧性解消問題に適用する．
この手法は，ラベルなしデータをラベルを欠損値とする観測データ，
その観測データを発生させるモデルを Naive Bayes モデル，このモデルの未知パラメータを
ラベル\( c \)のもとで素性\( f \)が起る条件付き確率\( p(f|c) \)に設定して，
EM アルゴリズムを用いる．結果として，モデルの識別精度が向上する．
ここでは識別のための素性として，対象単語の前後数単語の原型や表記という簡易なものに設定した．
実験では，ラベル付き訓練データのみから学習した Naive Bayes の正解率が 58.2\,\%，
同データから学習した決定リストの正解率が 58.9\,\%（Ibaraki の公式成績）であったのに対し，
ラベル付き訓練データの他にラベルなし訓練データを用いた本手法では，
61.8\,\% の正解率を得た．また訓練データの一部の不具合を修正することで，
Naive Bayes の正解率を 62.3\,\% に改善できた．更に本手法によりそれを 
68.2\,\% に向上させることができた．
}

\jkeywords{EM アルゴリズム，教師なし学習，多義語の曖昧性解消，翻訳タスク，SENSEVAL2}

\etitle{Application of unsupervised learning using EM\\ 
algorithm to Japanese Translation Task}
\eauthor{Hiroyuki Shinnou\affiref{ibaraki}}

\eabstract{
In this paper, we apply an unsupervised learning method using the EM
algorithm which Nigam et al. have proposed for text classification, 
to disambiguation problems involving noun meanings taken up 
in Japanese Translation Task of SENSEVAL2.
This method uses the EM algorithm, setting up hidden labels of 
unlabeled data as missing values of observational data,
the Naive Bayes model as the generating model, and 
the conditional probabilities \( p(f|c) \) (where \( f \) is a feature and \( c \) is a label)  
as parameters of the model. As the result, the learned classifier is improved.
In this study, we use only simple features for the  classification, 
which are some words surrounding a target word.
In the experiments, the precision of Naive Bayes classifier learned through
only labeled data was 58.2\,\%.  The precision of the decision list learned
through the same data was 58.9\,\%, which is the Ibaraki record in the Translation Task
contest.  
Our unsupervised learning method improved the precision to
61.8\,\% by using unlabeled data in addition to labeled data.  Furthermore, by
revising a small part of labeled data, the precision levels of the Naive Bayes
classifier and our unsupervised learning method were improved to 62.3\,\% and
68.2\,\% respectively.
}

\ekeywords{EM algorithm, unsupervised learning, word sense disambiguation, Translation Task, SENSEVAL2}

\begin{document}
\maketitle
\thispagestyle{empty} 


\section{Naive Bayes による多義語の曖昧性解消}


まず，用語の混乱を避けるため，本論文で用いる「属性」と「素性」の区別をしておく．
本論文では，例えば，「対象単語の直前の単語」といった識別のための観点を「属性」と呼び，
属性に具体的な値が与えられたものを「素性」と呼んでいる．
例えば「対象単語の直前の単語」といった属性を\verb| e1 |などで表し，
対象単語の直前の単語が，例えば，「日本」であった場合に，\verb| 'e1=日本' |と表された
ものを素性と呼ぶ．

ある事例\( x \)が素性のベクトルとして，以下のように表現されたとする．
\[
x = (f_1,f_2,\cdots,f_n )
\]
\( x \)の分類先のクラスの集合を\( C = \{ c_1,c_2, \cdots, c_m \} \)と置く．
分類問題は\( P(c|x) \)の分布を推定することで解決できる．
実際に，\( x \)のクラス\( c_x \)は以下の式で求まる．
\[
c_x = arg \max_{c \in C} P(c|x)
\]

ベイズの定理を用いると，
\[
P(c|x) = \frac{P(c)P(x|c)}{P(x)}
\]
\noindent
なので，結局，以下が成立する．
\[
c_x = arg \max_{c \in C} P(c)P(x|c)
\]
ここで，\( P(c) \)は比較的簡単に推定できる．問題は，\( P(x|c) \) の推定だが，
これは現実的には難しい．Naive Bayes のモデルは，この推定に以下の仮定を導入する．
\begin{equation}
  \label{siki1}
P(x|c) = \prod_{i = 1}^{n} P(f_i|c)  
\end{equation}
\( P(f_i|c) \)の推定は比較的容易であるために，結果として\( P(x|c) \)が推定できる\cite{ml-text}．
Naive Bayes を使った分類がうまくゆくかどうかは，\mbox{式\ref{siki1}} の仮定をできるだけ満たすような
素性を選択することである．文書分類であれば，各素性を各単語の生起に設定することで，
Naive Bayes が有効であることが知られている．

多義語の曖昧性解消でも\mbox{式\ref{siki1}}の仮定をできるだけ満たすような素性を選択すれば
Naive Bayes が利用できる．本論文では以下の4つの属性を利用することにした．

\bigskip
\begin{verbatim}
      e1 :  直前の単語，
      e2 :  直後の単語，
      e3 :  前方の内容語（2つまで）
      e4 :  後方の内容語（2つまで）
\end{verbatim}
\bigskip

例えば，「胸」の語義は『体の一部としての胸』という語義と『心の中』という語義がある．
そして，「その無力感は今も原告たちの胸に染み付いている」という文中の「胸」の語義は
『心の中』なので，この事例のクラスは『心の中』となる．また，この文は以下のように
形態素解析される．
各行が分割された単語であり，第1列が表記，第2列が原型，第3列が品詞を表す．

\bigskip
\begin{verbatim}
                  その      その         連体詞           
                  無力      無力         名詞-形容動詞語幹                
                  感        感           名詞-接尾-一般           
                  は        は           助詞-係助詞              
                  今        今           名詞-副詞可能            
                  も        も           助詞-係助詞              
                  原告      原告         名詞-一般                
                  たち      たち         名詞-接尾-一般           
                  の        の           助詞-連体化              
                  胸        胸           名詞-一般                
                  に        に           助詞-格助詞-一般         
                  染み付い   染み付く     動詞-自立
                  て        て           助詞-接続助詞            
                  いる      いる         動詞-非自立
\end{verbatim}
\bigskip

この結果から以下の4つの素性が抽出できる．

\bigskip
\begin{verbatim}
                  e1=の， e2=に， e3 ={原告, たち}， e4={染み付く，いる}
\end{verbatim}
\bigskip

属性\verb|e3| と \verb|e4| の値は集合になるが，学習の際に以下のように分割して，素性として表す．

\begin{verbatim}
                  e3=原告,  e3=たち,  e4=染み付く,  e4=いる
\end{verbatim}



\section{EM アルゴリズムによる教師なし学習}


分類問題の解決に Naive Bayes が使えれば，Nigam らが提案した教師なし学習が利用できる．
そこでは EM アルゴリズムを用いることで，ラベルなし訓練データを用いて，
ラベル付き訓練データから学習された分類器の精度を向上させる．

ここではポイントとなる式とアルゴリズムだけを示す\cite{nigam00}．

基本となるのは，あるクラス\( c_j \)のもとで，素性\( f_i \)が発生する確率\( P(f_i|c_j) \)を求める
ことである．これは以下の式で求まる．この式は頻度 0 の部分を考慮したスムージングを行っている．

\begin{equation}
  \label{siki6}
P(f_i|c_j) = \frac{1 + \sum_{k = 1}^{|D|}N(f_i,d_k)P(c_j|d_k)}{|F| + \sum_{m = 1}^{|F|}\sum_{k = 1}^{|D|}N(f_m,d_k)P(c_j|d_k)}
\end{equation}

式\ref{siki6} の\( D \) はラベル付けされた訓練データとラベル付けされていない訓練データを
合わせた訓練データ全体を示す．\( D \) の各要素を\( d_k \) で表す．
\( F \) は素性全体の集合である．\( F \) の各要素を\( f_m \) で表す．
また，\( N(f_i,d_k) \) は，訓練事例\( d_k \)に含まれる素性\( f_i \)の個数を
表す．ここでの設定では，\( N(f_i,d_k) \)は 0 か 1 の値であり，ほとんどの場合 0 である．
\( P(c_j|d_k) \) は訓練データがクラス\( c_j \)を持つ確率である．
ラベル付けされた訓練データに対しては，0 か 1 の値をとる．
ラベル付けされていない訓練データに対しては，最初は 0 であるが，EM アルゴリズムの
繰り返しによって，徐々に適切な値に更新されてゆく．

式\ref{siki6} を利用して，以下の分類器が作成できる．

\begin{equation}
    \label{siki8}
P(c_j|d_i) = \frac{P(c_j) \prod_{f_n \in K_{d_i}}P(f_n|c_j)}{\sum_{r = 1}^{|C|} P(c_r)\prod_{f_n \in K_{d_i}}P(f_n|c_r)}
\end{equation}
\noindent
ここで，\( C \) はクラスの集合である．
\( K_{d_i} \) は訓練事例\( d_i \)に含まれる素性の集合を示す．
\( P(c_j) \)はクラス\( c_j \)の発生確率であり，以下の式で
計算する．

\[
P(c_j) = \frac{1 + \sum_{k = 1}^{|D|} P(c_j|d_k)}{|C| + |D|}
\]

EM アルゴリズムは\mbox{式\ref{siki8}}を利用して，
ラベル付けされていない事例\( d_i \)に対して，\( P(c_j|d_i) \) を求める(E-step)．
次に\mbox{式\ref{siki6}}を利用して，\( P(f_i|c_j) \) を求める(M-step)．
この E-step と M-step を交互に繰り返して，\( P(f_i|c_j) \) と\( P(c_j|d_i) \) を
収束するまで更新してゆく．

最終的には収束した\( P(f_i|c_j) \)を使って，\mbox{式\ref{siki8}}から分類が行える．


\section{考察}


ここでは本手法を名詞のみに適用した．
同じ処理によって，動詞に対しても適用することができるが，ここではその実験を行わなかった．
教師なし学習を利用するには，本質的に，識別のための冗長性のある情報が必要である．
名詞の場合，その名詞を修飾する語句（左文脈）は，その名詞の語義を特定できる可能性が高いし，
その名詞を格にもつ動詞（右文脈）もその名詞の語義を特定できる可能性が高いので，
一方の文脈から名詞の語義が識別できれば，もう一方の文脈は識別のための冗長性のある情報となる．
このため，設定した属性は教師なし学習に適していると考えられる．
一方，動詞の語義を識別するのは，格要素になる名詞，つまり左文脈が重要であり，
右文脈は語義の識別の助けになることは少ない．連体修飾の用法にしても，左右が逆になるだけである．
つまり，どちらかの文脈を利用して語義を識別した場合に，もう一方の文脈は識別に寄与する情報に
ならない．このため，動詞に対しては，本手法を利用する効果は低いと考えた\cite{shinnou-lrec02}．
ただし「効果がない」ということでもないことを注意しておく．
本手法はラベル付き訓練データのみから得られた分類器の精度を必ずしも向上するとは言えず，
逆に精度を落す危険性もある．そのために，本手法を利用する効果があまり期待できない
場合には，危険性を犯してまで本手法を試みる必要はないと判断した．
動詞に対して実際にどの程度の精度向上，あるいは精度低下があるのか，
あるいは動詞に対してはどのような属性を設定するのが良いのかを調べることは
今後の課題である．

先ほども述べたが，本手法により必ずしも精度が向上するとは限らない．
実際に，実験では\mbox{表 \ref{badword2}}の5単語に関して，
わずかではあるが精度が低下している．

\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{精度が下がる単語}\label{badword2}
    \begin{tabular}{|c|c|c|} \hline
見出し    &    NB       & NB+EM \\ \hline
ippan     &    0.467    &  0.400      \\ 
kaku\_n   &    0.767    &  0.700     \\ 
shimin    &    0.567    &  0.500     \\ 
jidai     &    0.867    &  0.833     \\ 
sugata    &    0.367    &  0.333     \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\noindent
精度低下の原因を一般的に論じるのは難しい．
この実験の場合，偶然的な要素が強かった．
NB による分類器では正解したが，NB+EM による分類器では誤るようなテスト文を調査すると，
NB による分類器で正解したのは，たまたま default の規則が適用できて，
正解になったというように，偶然的な要素が強い．
EM による学習が進むと，default から少しずれてくるために，誤ってしまう．
精度低下の原因に関しては，ラベル付き訓練データ，ラベルなし訓練データおよびテストデータの
関係を詳しく調査する必要がある．

本手法による更なる精度向上をはかるための最も有効な手段は，最初のラベル付き訓練データを
見直すことである．今回利用したラベル付き訓練データは，
コンテストの正解が提示される以前に作成されたものであり，出題者が想定した語義と
微妙に違う部分がある．概して，出題者が想定した語義は荒く，Ibaraki で用意された
語義は細かい．語義が細かいと，結果として訓練データが小さいものになり，
学習から得られる規則の精度が悪く，無用な部分で識別が誤る．
ima や mune でもラベル付きの訓練データを見直すことで精度が改善された．

またラベルなし訓練データの量の問題が指摘されるかも知れない．
ラベルなし訓練データは多ければ多いほど精度が向上すると言われている．
今回，精度低下のあった ippan，shimin, jidai の3単語に関して，
ラベルなし訓練データの量を約4倍に増やして実験を行った．
このデータは別年度の毎日新聞記事から取り出した\footnote{ただしテスト文が94年度版から取られることが
分っているので，94年度版は利用していない．}．
結果を\mbox{表 \ref{muchunlabel}}に示す．

\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{ラベルなし訓練データを増やした実験}\label{muchunlabel}
    \begin{tabular}{|c|c|c|c|c|c|c|} \hline
見出し    &  L    &  U    &  new U    & NB      & NB+EM (using L+U)  & NB+EM (using L+ new U)  \\ \hline
ippan     &   87  & 2170  &  8048     & 0.467    &  0.400  &  0.400           \\ 
shimin    &   64  & 2069  &  7912     & 0.567    &  0.500  &  0.533           \\ 
jidai     &   89  & 4397  & 15858     & 0.867    &  0.833  &  0.833           \\  \hline
    \end{tabular}
  \end{center}
\end{table}

精度は悪くなることはなかったが，ほとんど変化は生じなかった．
おそらく今回実験で利用した程度のラベルなし訓練データの量でも，
このタスクでは十分であったと考えられる．

またもう一つの代表的な教師なし学習の手法である Co-training\cite{blum98}との
比較について述べておく．Co-training は独立な2つの属性させ設定できれば，
ベースとなる学習手法を問わないために，応用範囲が広い．
また完全に独立な2つの属性が設定できた場合，
Co-training は EM アルゴリズムを利用した手法よりも優れていることが
報告されている\cite{nigam00-2}．しかし Co-training には独立な2つの属性という条件の他に，
属性の一貫性という条件も必要になる．
この条件のために，実際は Co-training を多値の分類問題に適用することは難しい\cite{shinnou-sen2}．
一方，本手法は Naive Bayes の学習を基本とするという制限はあるが，
分類問題が多値であっても，原理的に問題はない．
そのために，より頑健性の高い現実的な手法と言える．

また多義語の曖昧性解消問題に教師なし学習を利用した Yarowsky の研究\cite{Yarowsky2}との
比較についても述べておく．
Yarowsky の教師なし学習も，実は Co-training の特殊ケースと見なせる\cite{blum98}．
2つの独立した属性として，1つは前後の文脈，もう1つは
「同じ文書内で使われている曖昧な単語の語義は1つに固定される」
というヒューリスティクスである．
このヒューリスティクスが翻訳タスクで設定している語義の細かさに対して，
どれほど成立しているかは未知である．
またこの手法では，必要とされるラベルなし訓練データは文書，
しかも対象単語が複数含まれているような文書となる．
これはいかにラベルなしと言えども収集は容易ではない．
このため比較対象の実験も困難である．
一方，本手法はその対象単語を含む文が訓練データとなるので，収集は容易であり，
より現実的な手法と言える．

今後の課題としては2つある．1つは名詞以外の単語への適用である．
教師なし学習が機能するような属性をどのように設定するかが課題である．
2つ目は教師なし学習による精度低下の原因の調査，およびその回避策の検討である．
これによってより頑健な教師なし学習が可能となる．


\end{document}

