本論文では，日本語固有表現抽出の問題において，複数のモデルの出力を混合する手法を提案した．
まず，最大エントロピー法に基づく統計的学習による固有表現抽出モデルにおいて，現在位置の形態素が，いくつの形態素から構成される固有表現の一部であるかを考慮して学習を行なう可変長モデルと，常に現在位置の形態素の前後数形態素ずつまでを考慮して学習を行なう固定長モデルとの間のモデルの挙動の違いに注目し，なるべく挙動が異なり，かつ，適度な性能を保った複数のモデルの出力の混合を行なった．
混合の方式としては，複数のシステム・モデルの出力(および訓練データそのもの)を入力とする第二段の学習器を用いて，複数のシステム・モデルの出力の混合を行なう規則を学習するという混合法(stacking法)を採用した．
第二段の学習器として決定リスト学習を用いて，固定長モデルおよび可変長モデルの出力を混合する実験を行なった結果，最大エントロピー法に基づく固有表現抽出モデルにおいてこれまで得られていた最高の性能を上回る性能が達成された．
今回の実験では，固定長モデル同士は出力される固有表現の分布がお互いに似通っており，可変長モデル同士も使用する素性の集合に包含関係があることから，出力する固有表現の傾向が大きく異なるモデルは，固定長モデルと可変長モデルの二種類だけであると仮定した．
そのため，評価実験においても，二つのモデルの出力の混合の結果のみを報告したが，今後は、傾向の大きく異なる三種類以上のモデルの出力に対して，本論文の混合手法の有効性を評価したいと考えている．
また，本論文の手法は，個々の単独システムに何らかの固有表現候補を出力させて，それらの固有表現候補を取捨選択するという方法であるので，再現率の観点からは，個々の単独システムの出力の和の再現率が上限となってしまう．
したがって，本論文の方法によってより高い性能の固有表現抽出を実現するためには，個々の単独システムが少しでも多くの固有表現候補を出力することが不可欠である．
今後は，既存のどの固有表現抽出モデルを用いても抽出が失敗する固有表現の特性を分析し，できるだけ網羅的に固有表現候補を出力し，その結果を本論文の混合法で利用する方式について検討を行なう予定である．
その際，網羅的に固有表現候補を出力するためには，まず，何らかの方法によって，広範なテキストから固有表現候補を収集して蓄積する必要があるが，ここでは，新聞記事やWWW上のテキスト等の大規模テキストから未知語を獲得する，あるいは専門用語を抽出するなどの手法の適用が有効であると考えている．
