1  これ まで  機械 学習 など の 分野 を 中心 として  複数 の モデル  システム の 出力 を 混合 する 手法 が いくつ か 提案 さ れ  その 効果 が 報告 さ れ て いる  
1  それら の 成果 を 背景 として  近年  統計 的 手法 に 基づく 自然 言語 処理 において も  複数 の モデル  システム の 出力 を 混合 する 手法 を 様々 な 問題 に 適用 する こと が 試み られ  品詞 付け  CITE  名詞 句 等 の 句 の まとめ 上げ  CITE  構文 解析  前置詞 句 付加 含む   CITE  など へ の 適用 事例 が 報告 さ れ て いる  
1  一般 に  複数 の モデル  システム の 出力 を 混合 する こと の 利点 は  単一 の モデル  システム で は  全て の 現象 に対して 網羅 的 かつ 高 精度 に 対処 でき ない 場合 でも  個々 の モデル  システム が それぞれ 得意 と する 部分 を 選択 的 に 組み合わせる こと で  全体 として 網羅 的 かつ 高 精度 な モデル  システム を 実現 できる という 点 に ある  
1  本 論文 で は  日本語 固有 表現 抽出 の 問題 に対して  複数 の モデル の 出力 を 混合 する 手法 を 適用 し  個々 の 固有 表現 抽出 モデル が それぞれ 得意 と する 部分 を 選択 的 に 組み合わせる こと で  全体 として 網羅 的 かつ 高 精度 な モデル を 実現 し  その 効果 を 実験 的 に 検証 する  
0  一般 に  日本語 固有 表現 抽出 において は  前 処理 として 形態素 解析 を 行ない  形態素 解析 結果 の 形態素 列 に対して  人手 で 構築 さ れ た パターンマッチング 規則 や 統計 的 学習 によって 得 られ た 固有 表現 抽出 規則 を 適用 する こと により  固有 表現 が 抽出 さ れる  CITE  
0  特に  統計 的 学習 によって 得 られ た 固有 表現 抽出 規則 を 用いる 場合 に は  形態素 解析 結果 の 形態素 列 に対して  一つ もしくは 複数 の 形態素 を まとめ 上げる 処理 を 行ない  同時に まとめ 上げ られ た 形態素 列 が どの 種類 の 固有 表現 を 構成 し て いる か を 同定 する という 手順 が 一般 的 で ある  CITE  
1  この とき  実際 の まとめ 上げ の 処理 は  現在 注目 し て いる 位置 に ある 形態素 および その 周囲 の 形態素 の 語彙  品詞  文字種 など の 属性 を 考慮 し ながら  現在 位置 の 形態素 が 固有 表現 の 一部 と なり うる か どう か を 判定 する こと の 組合 わせ によって 行なわ れる  
1  一方  一般 に  複数 の モデル  システム の 出力 を 混合 する 過程 は  大きく 以下 の 二つ の 部分 に 分け て 考える こと が できる  
1  できるだけ 振る舞い の 異なる 複数 の モデル  システム を 用意 する  
1   通常  振る舞い の 酷似 し た 複数 の モデル  システム を 用意 し て も  複数 の モデル  システム の 出力 を 混合 する こと による 精度 向上 は 望め ない こと が 予測 さ れる  
0   
1  用意 さ れ た 複数 の モデル  システム の 出力 を 混合 する 方式 を 選択  設計 し  必要 で あれ ば 学習 等 を 行ない  与え られ た 現象 に対して  用意 さ れ た 複数 の モデル  システム の 出力 を 混合 する こと を 実現 する  
1  複数 の 日本語 固有 表現 抽出 モデル の 出力 を 混合 する にあたって も  これら の  REF _ enum  sub 1  および  REF _ enum  sub 2  の 過程 を どう 実現 する か を 決める 必要 が ある  
1  本 論文 で は  まず   REF _ enum  sub 1  について は  統計 的 学習 を 用いる 固有 表現 抽出 モデル を とりあげ  まとめ 上げ の 処理 を 行なう 際 に  現在 位置 の 周囲 の 形態素 を 何 個 まで 考慮 する か を 区別 する こと により  振る舞い の 異なる 複数 の モデル を 学習 する  
1  そして  複数 の モデル の 振る舞い の 違い を 調査 し  なるべく 振る舞い が 異なり  かつ  適度 な 性能 を 保っ た 複数 の モデル の 混合 を 行なう  
1  特に  これ まで の 研究 事例  CITE  で やら れ た よう に  現在 位置 の 形態素 が どれ だけ の 長 さ の 固有 表現 を 構成 する の か を 全く 考慮 せ ず に  常に 現在 位置 の 形態素 の 前後 二 形態素  または 一 形態素  ずつ まで を 考慮 し て 学習 を 行なう モデル  固定 長 モデル  REF _ subsubsec  3 gram  節 参照  だけ で は なく  現在 位置 の 形態素 が  いくつ の 形態素 から 構成 さ れる 固有 表現 の 一部 で ある か を 考慮 し て 学習 を 行なう モデル  可変長 モデル  CITE  REF _ subsubsec  vgram  節 参照  も 用い て 複数 モデル の 出力 の 混合 を 行なう  
0  次に   REF _ enum  sub 2  について は  重み 付 多数決 や モデル の 切り替え など  これ まで 自然 言語 処理 の 問題 に よく 適用 さ れ て き た 混合 手法 を 原理 的 に 包含 し 得る 方法 として  stacking 法  CITE  と 呼ば れる 方法 を 用いる  
1  stacking 法 と は  何らかの 学習 を 用い た 複数 の システム  モデル の 出力  および 訓練 データ そのもの  を 入力 と する 第 二 段 の 学習 器 を 用い て  複数 の システム  モデル の 出力 の 混合 を 行なう 規則 を 学習 する という 混合 法 で ある  
1  本 論文 で は  具体 的 に は  複数 の モデル による 固有 表現 抽出 結果  および それぞれ の 固有 表現 が どの モデル により 抽出 さ れ た か  固有 表現 の タイプ  固有 表現 を 構成 する 形態素 の 数 と 品詞 など を 素性 として  各 固有 表現 が 正しい か 誤っ て いる か を 判定 する 第 二 段 の 判定 規則 を 学習 し  この 正誤 判定 規則 を 用いる こと により 複数 モデル の 出力 の 混合 を 行なう  
0  以下 で は  まず   REF _ sec  JNE  節 で  本 論文 の 実験 で 使用 し た IREX  Information Retrieval and Extraction Exercise  ワークショップ  CITE  の 日本語 固有 表現 抽出 タスク の 固有 表現 データ について 簡単 に 説明 する  
0  次に   REF _ sec  NEchunk  節 で は  個々 の 固有 表現 抽出 モデル の ベース と なる 統計 的 固有 表現 抽出 モデル について 述べる  
1  本 論文 で は  統計 的 固有 表現 抽出 モデル として  最大 エントロピー 法 を 用い た 日本語 固有 表現 抽出 モデル  CITE  を 採用 する  
0  最大 エントロピー 法 は  自然 言語 処理 の 様々 な 問題 に 適用 さ れ その 性能 が 実証 さ れ て いる が  日本語 固有 表現 抽出 において も 高い 性能 を 示し て おり  IREX ワークショップ の 日本語 固有 表現 抽出 タスク において も  統計 的 手法 に 基づく システム の 中 で 最も 高い 成績 を 達成 し て いる  CITE  
1   REF _ sec  combi  節 で は  複数 の モデル の 出力 の 正誤 判別 を 行なう 規則 を 学習 する こと により  複数 モデル 出力 の 混合 を 行なう 手法 を 説明 する  
0  本 論文 で は  正誤 判別 規則 の 学習 モデル として は  決定 リスト 学習 を 用い  その 性能 を 実験 的 に 評価 する  
0  以上 の 手法 を 用い て   REF _ sec  experi  節 で  複数 の 固有 表現 抽出 結果 の 混合 法 の 実験 的 評価 を 行ない  提案 手法 の 有効 性 を 示す  
1   CITE  に も 示さ れ て いる よう に  固定 長 モデル に 基づく 単一 の 日本語 固有 表現 抽出 モデル の 場合 は  現在 位置 の 形態素 の 前後 二 形態素 ずつ を 考慮 し て 学習 を 行なう 場合 が 最も 性能 が よい  
1  また   REF _ sec  experi  節 の 結果 から わかる よう に  この  常に 前後 二 形態素 ずつ を 考慮 する 固定 長 モデル の 性能 は  可変長 モデル に 基づく 単一 の モデル の 性能 を も 上回っ て いる  なお   CITE  で は  最大 エントロピー 法 を 学習 モデル として 可変長 モデル を 用い た 場合 に は  常に 前後 二 形態素 ずつ を 考慮 する 固定 長 モデル より も 高い 性能 が 得 られる と 報告 し て いる が  この 実験 結果 に は 誤り が あり  本 論文 で 示す 実験 結果 の 方 が 正しい  
0   
1  ところが  可変長 モデル と  現在 位置 の 形態素 の 前後 二 形態素 ずつ を 考慮 する 固定 長 モデル と を 比較 する と  モデル が 出力 する 固有 表現 の 分布 が ある程度 異なっ て おり  実際  これら の 二つ の モデル の 出力 を 用い て 複数 モデル 出力 の 混合 を 行なう と  個々 の モデル を 上回る 性能 が 達成 さ れ た  
0   REF _ sec  experi  節 で は  これら の 実験 について 詳細 に 述べ  本 論文 で 提案 する 混合 法 が 有効 で ある こと を 示す  
