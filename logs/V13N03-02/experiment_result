
我々はReuters-21578データセットを提案手法の有効性の検証に使った．
このデータセットには，訓練事例とテスト事例の分け方(split)にいくつかのバリエーションがある．
今回我々は``ModApte''と呼ばれる分け方を用いた．
文書分類の文献で最も広く使われているものである．
``ModApte''では，訓練事例9,603，テスト事例3,299と分けられている．
Reuters-21578には100以上のカテゴリが含まれているが，他の多くの文献と同様，我々も最も頻度が高い10カテゴリのみ利用した．
表[REF_tbl:numcat]に，その10カテゴリと，カテゴリごとの訓練事例数とテスト事例数を示す．
本研究では，F値(F-measure) [CITE]を実験結果を評価する第一の尺度として用いる．
F値は次のように定義される:
ここで[MATH]は適合率(precision)，[MATH]は再現率(recall)，[MATH]は適合率と再現率の相対的な重みを決めるをパラメータである．
[MATH]と[MATH]は次のように定義される:
式([REF_eq:f-measure])では通常[MATH]が用いられる．
これは適合率と再現率に等しく重みを置くことを意味する．
複数のカテゴリを持つデータセットに対して，分類器の性能を評価しようとするとき，F値を計算する方法としては二つある．
マクロ平均(macro-averaging)とマイクロ平均(micro-averaging)である[CITE]．
前者はまずそれぞれのカテゴリに対してF値を計算し，平均する方法である．
後者は全てのカテゴリ全体に対して適合率と再現率をまず計算し，それを使ってF値を計算する方法である．
実験には我々が作成したSVMのツールを用いた．
線形SVMを用い，誤分類のコスト[MATH]は[MATH]に設定した．
この値は[MATH]により決めた．
ここで[MATH]は事例数9603の訓練事例に含まれる素性ベクタである．
実験を単純にするため，[MATH]の値は全ての実験において固定した．
表[REF_tbl:numcat]で示した10のカテゴリそれぞれに対して2値分類を行なう分類器を構築した．
まず，\GenerateByDeletionと\GenerateByAdditionをそれぞれ独立に用いて仮想事例を作って実験を行なった．
なお，このときサポートベクタに対してのみ仮想事例を作った．
全ての実験に対して，\GenerateByDeletionと\GenerateByAdditionのいずれに対しても，パラメータ[MATH]は[MATH]とした．
仮想事例を使ったSVMを学習して得るための手順は次の通り:
(仮想事例を使わずに) SVMを訓練する．
サポートベクタを抽出する．
それらサポートベクタから仮想事例を生成する．
元々の訓練事例と仮想事例とを合わせて使って新たなSVMを訓練する．
訓練事例のサイズを変えて，\GenerateByDeletionと\GenerateByAdditionの二つの手法の性能を評価した．
7つのサイズ(9603, 4802, 2401, 1200, 600, 300, 150)を用意した\<．
この二つの手法を用いた場合のマイクロ平均F値を表[REF_tbl:pretest]に示す．
表[REF_tbl:pretest]の手法Bが\GenerateByDeletion{}，手法Cが\GenerateByAddition{}である．
この表から両手法ともオリジナルのSVM (手法A)よりも性能が良いことが分かる．
訓練事例の事例数が少ないほうが，性能の向上が大きい．
事例数9603の訓練事例の場合，\GenerateByDeletionによるF値向上は0.75 ([MATH])であるが，一方，事例数150の訓練事例では，F値向上は6.88 ([MATH])となっている．
これらの結果から，事例数が少ない訓練事例には，よりよい決定境界を与えるのに十分なだけの事例のバリエーションが存在しておらず，それゆえ，事例数が少ない訓練事例では，仮想事例の効果が大きくなったと考えられる．
上記結果より，\GenerateByDeletionと\GenerateByAdditionの両手法が本タスクに対してはよい仮想事例を生成しており，それが精度向上につながったと結論付けてよいだろう．
仮想事例を作り出す簡単な二つの方法\GenerateByDeletionと\GenerateByAdditionが効果的なことが分かったが，次にこれらを組み合わせた方法についても調べた．
1つのサポートベクタにつき，2つの仮想事例を作ることにする．
つまり，\GenerateByDeletionで1事例を作り，\GenerateByAdditionでもう1事例を作る．
この組み合わせた手法を手法Dとし，そのマイクロ平均F値を表[REF_tbl:pretest]に示す．
この手法によるF値向上は，\GenerateByDeletion{}，\GenerateByAdditionそれぞれを単独で用いた場合よりも大きい．
さらに，1つの事例から\GenerateByDeletionで2つ，\GenerateByAdditionで2つ事例を作り出す手法についても実験を行なった．
つまり，1つのサポートベクタから4つの仮想事例を作る．
この手法を手法Eとし，そのF値を表[REF_tbl:pretest]に示す．
1つのサポートベクタから4つの仮想事例を作り出す手法が最もよい結果を得た．
本節の以下の議論では，オリジナルのSVMと，1つのサポートベクタから生成された4つの仮想事例を使うSVM (以降\SVMFourVSVsと記す)の実験結果の比較に焦点をあてる．
オリジナルSVMと\SVMFourVSVsの学習曲線を図[REF_fig:micro-f1]，図[REF_fig:macro-f1]に示す．
マイクロ平均F値，マクロ平均F値の両方で，\SVMFourVSVsがオリジナルSVMより明らかに性能が良い．
\SVMFourVSVsは，あるレベルのF値を得るのに，オリジナルSVMに比べて概ね半分以下の訓練事例数で済んでいる．
例えば，オリジナルSVMでは，マイクロ平均F値64.44を得るのに300事例必要である(表[REF_tbl:pretest]参照)．
一方，\SVMFourVSVsでは150事例で65.05を得ている．
F値の改善は，ただ再現率が大きく改善したせいで実現され，その裏でエラー率が上昇している可能性もある．
これを確認するため，32990のテスト(3299のテストを10カテゴリそれぞれについて)に対してのエラー率の変化を図[REF_fig:error]にプロットした．
エラー率においても，\SVMFourVSVsがオリジナルSVMよりも優れている．
10カテゴリそれぞれに対する性能の変化を表[REF_tbl:sv-each]，表[REF_tbl:vsv-each]に示す．
\SVMFourVSVsは殆どの場合でオリジナルSVMよりもよい．
事例数9603での``interest''と``wheat''の場合のみ，\SVMFourVSVsが下回っているが，理由は不明である．
頻度が小さい``ship''や``wheat''，``corn''といったカテゴリに対して，オリジナルSVMの性能は良くない．
分類器が決して[MATH]を出力しなかった場合，つまり再現率ゼロの場合も多い．
これは，ラベルとして[MATH]を持つ事例が非常に少ないバランスの悪い訓練事例のために，オリジナルSVMがよい超平面を見つけられなかったことを示している．
これに対し，\SVMFourVSVsはそういうバランスの悪い訓練事例のような難しい場合でもよりよい結果を得ている．
