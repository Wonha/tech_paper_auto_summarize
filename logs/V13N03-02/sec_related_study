自然言語処理においてSVMsを仮想事例とともに用いている研究として，Yiらの研究[CITE]がある．
ここで彼らの研究との違いをまとめておく．
違いは大きく二つある．
対象タスクと，仮想事例の元となる事例の選び方である．
彼らは固有表現認識を対象とし，全ての事例から仮想事例を作っている．
一方，我々の研究では，文書分類を対象とし，サポートベクタとなる事例からのみ仮想事例を作っている．
サポートベクタ以外から仮想事例を作っても精度向上にはあまり影響せず，また事例数増加による学習時間増加のデメリットがあるので，本研究ではサポートベクタのみから仮想事例を作っている．
なお，対象タスクが異なるので，仮想事例の作り方が異なるのは言うまでもない．
彼らは，ある文中に現れた固有表現を，同じクラスを持つ別の固有表現で置き換えて新しい文を作り，これを仮想事例としている．
自然言語処理においてSVMsを仮想事例とともに用いている研究として，Yiらの研究[CITE]がある．
ここで彼らの研究との違いをまとめておく．
違いは大きく二つある．
対象タスクと，仮想事例の元となる事例の選び方である．
彼らは固有表現認識を対象とし，全ての事例から仮想事例を作っている．
一方，我々の研究では，文書分類を対象とし，サポートベクタとなる事例からのみ仮想事例を作っている．
サポートベクタ以外から仮想事例を作っても精度向上にはあまり影響せず，また事例数増加による学習時間増加のデメリットがあるので，本研究ではサポートベクタのみから仮想事例を作っている．
なお，対象タスクが異なるので，仮想事例の作り方が異なるのは言うまでもない．
彼らは，ある文中に現れた固有表現を，同じクラスを持つ別の固有表現で置き換えて新しい文を作り，これを仮想事例としている．
