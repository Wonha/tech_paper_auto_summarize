================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:167] 本論文では，サポートベクタマシン(SVMs)を使った文書分類において仮想事例(virtual examples)がどのように性能を改善するかを調べる．
[i:1, score:170] ある文書から少量の単語を追加したり削除したりしても，その文書が属するカテゴリは変化しないとの仮定を置いて，文書分類のために仮想事例を作る方法を提案する．
[i:3, score:145] 実験により，仮想事例はサポートベクタマシンを使った文書分類の性能向上に役立つことが確認できた．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:12, score:149] 同じ考え方に沿う別の手法として，ラベル付き事例から生成された仮想事例(virtual examples)を使う手法がある．
[i:33, score:149] もう一つには，ラベル付き事例から仮想事例を作り出す方法として，単純だが効果的なものが考えられるからである(第[REF_sec:vx]節で詳細に述べる)．
[i:34, score:165] 本論文では，仮想事例がSVMを使う文書分類の精度をどのように向上させるか，特に少量の学習事例を使った場合にどうなるかを示す．

================================================================
[section type  : proposed_method]
[section title : サポートベクタマシン]
================================================================
[i:36, score:58] 訓練事例が以下のように与えられるとする:
[i:41, score:83] ゼロでない[MATH]を持つ事例[MATH]はサポートベクタと呼ばれる．
[i:48, score:58] 図[REF_fig:sv]に最適超平面とサポートベクタの例を示す．

================================================================
[section type  : proposed_method]
[section title : 仮想事例と仮想サポートベクタ]
================================================================
[i:50, score:145] ターゲットとなるタスクの事前知識に基づいて，元になった事例のラベルと同じものを，仮想事例として生成された事例のラベルに設定する．
[i:51, score:154] 例えば，手書き数字の認識では，上下左右の方向に1ピクセル移動させても事例に対するラベルは変化しないとの仮定を置いて，仮想事例を作ることができる[CITE]．
[i:52, score:161] 特にサポートベクタから作られた仮想事例は，仮想サポートベクタ(virtual support vectors)と呼ばれる．

================================================================
[section type  : proposed_method]
[section title : 文書分類のための仮想事例]
================================================================
[i:88, score:155] Document 1からアルゴリズム\GenerateByDeletionで生成される仮想事例としては[MATH]や[MATH]，[MATH]などが考えられる．
[i:95, score:183] 表[REF_tbl:sample]のDocument 2からアルゴリズム\GenerateByAdditionを用いて仮想事例を作ろうとするとき，まず配列[MATH]を作る．
[i:96, score:152] このとき，アルゴリズム\GenerateByAdditionで作られる仮想事例として，[MATH]や[MATH]，[MATH]などが考えられる．

================================================================
[section type  : experiment_result]
[section title : 評価実験と議論]
================================================================
[i:99, score:0] 
-----------------------------------------------------
  [subsection title : 対象データ]
-----------------------------------------------------
  [i:lead, 20] 我々はReuters-21578データセットを提案手法の有効性の検証に使った．
.....
  [i:101, score:70] このデータセットには，訓練事例とテスト事例の分け方(split)にいくつかのバリエーションがある．
  [i:104, score:69] ``ModApte''では，訓練事例9,603，テスト事例3,299と分けられている．
  [i:106, score:88] 表[REF_tbl:numcat]に，その10カテゴリと，カテゴリごとの訓練事例数とテスト事例数を示す．
-----------------------------------------------------
  [subsection title : 性能評価尺度]
-----------------------------------------------------
  [i:lead, 15] 本研究では，F値(F-measure) [CITE]を実験結果を評価する第一の尺度として用いる．
.....
  [i:113, score:38] 複数のカテゴリを持つデータセットに対して，分類器の性能を評価しようとするとき，F値を計算する方法としては二つある．
  [i:114, score:27] マクロ平均(macro-averaging)とマイクロ平均(micro-averaging)である[CITE]．
  [i:116, score:30] 後者は全てのカテゴリ全体に対して適合率と再現率をまず計算し，それを使ってF値を計算する方法である．
-----------------------------------------------------
  [subsection title : SVM の設定]
-----------------------------------------------------
  [i:lead, 17] 実験には我々が作成したSVMのツールを用いた．
.....
  [i:118, score:23] 線形SVMを用い，誤分類のコスト[MATH]は[MATH]に設定した．
  [i:120, score:83] ここで[MATH]は事例数9603の訓練事例に含まれる素性ベクタである．
  [i:122, score:33] 表[REF_tbl:numcat]で示した10のカテゴリそれぞれに対して2値分類を行なう分類器を構築した．
-----------------------------------------------------
  [subsection title : 実験結果と考察]
-----------------------------------------------------
  [i:lead, 185] まず，\GenerateByDeletionと\GenerateByAdditionをそれぞれ独立に用いて仮想事例を作って実験を行なった．
.....
  [i:139, score:195] 上記結果より，\GenerateByDeletionと\GenerateByAdditionの両手法が本タスクに対してはよい仮想事例を生成しており，それが精度向上につながったと結論付けてよいだろう．
  [i:140, score:191] 仮想事例を作り出す簡単な二つの方法\GenerateByDeletionと\GenerateByAdditionが効果的なことが分かったが，次にこれらを組み合わせた方法についても調べた．
  [i:149, score:210] 本節の以下の議論では，オリジナルのSVMと，1つのサポートベクタから生成された4つの仮想事例を使うSVM (以降\SVMFourVSVsと記す)の実験結果の比較に焦点をあてる．

================================================================
[section type  : related_study]
[section title : 関連研究との比較]
================================================================
[i:165, score:136] 自然言語処理においてSVMsを仮想事例とともに用いている研究として，Yiらの研究[CITE]がある．
[i:170, score:169] 一方，我々の研究では，文書分類を対象とし，サポートベクタとなる事例からのみ仮想事例を作っている．
[i:171, score:162] サポートベクタ以外から仮想事例を作っても精度向上にはあまり影響せず，また事例数増加による学習時間増加のデメリットがあるので，本研究ではサポートベクタのみから仮想事例を作っている．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:174, score:154] 我々は仮想事例がSVMsを使った文書分類においてどのように性能を改善するかについて調べた．
[i:175, score:172] 文書分類において，ある文書のラベルは少量の単語を追加あるいは削除しても変化しないとの仮定を置いて，仮想事例を作り出す方法を提案した．
[i:178, score:147] 提案手法が文書分類以外の自然言語処理タスクにすぐに適用可能というわけではないが，今回，今まで自然言語処理の分野で十分に議論されていなかった仮想事例の利用について実験的に評価したことは意味があると言える．

