================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:2, score:0.24313] このため，入力の一部に誤りのある状況下における格要素補完問題を考え，以前に提案した決定木を使用した補完手法を改良したモデルを提案する．
[i:3, score:0.41989] このモデルは，複数の決定木を使用することで複数解候補を出力し，その中から学習時の終端節点事例数によって解の選好を行なうことで入力誤りに対する頑健性を強化した．
[i:4, score:0.25194] 音声認識の実誤りと人工的な誤りの2種類で評価実験を行なった結果，提案手法が誤りを含む入力に対し頑健であることを確認した．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:23, score:0.29615] 以上のように，音声対話処理における入力誤りへの頑健性を考慮した主語補完処理は音声対話処理の実現のための重要な処理の一つである．
[i:32, score:0.21468] また，属性として使用している言語外情報も，音声認識結果とは無関係の情報であるので，これも誤りはないと仮定する．
[i:33, score:0.25602] 本論文ではまず，本問題に関係する文献の紹介を行なった後，既提案の決定木学習に基づく主語補完手法[CITE]を概観し，この頑健性について考察する．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:36, score:0.24739] 前述したように，音声認識誤りを含む要素列を入力とした主語補完{}手法は，これまで知られていない．
[i:37, score:0.21964] 最近では，河原らが音声言語処理における頑健性について[CITE]，丸山が話し言葉の諸相について[CITE]，それぞれ議論を行なっているが，本論文で取り扱う音響レベル，すなわち不正確な音声認識結果に対する自然言語処理の頑健性に関しては議論されていない．
[i:40, score:0.19793] 脇田らは，本研究と同様，誤りを含む入力に対して機械翻訳させるという問題に対し，音声認識誤りを訂正するのではなく，翻訳結果の意味的な尤度を計算することで音声認識の誤り部分を特定し，その部分を翻訳結果からはずすことで翻訳する手法を提案している．

================================================================
[section type  : proposed_method]
[section title : 主語補完手法]
================================================================
[i:50, score:0.10000] 本節では，日本語の格要素省略を補完する問題に対して我々が文献[CITE]において提案した手法の概要を紹介する．
[i:51, score:0.38256] 本論文では，このモデルをSDT(Single Decision Tree)モデルと呼び，入力の不確かさに対する頑健性という観点から，SDTモデルがどの程度の頑健性を持つのかについて定性的な議論を行なう．
[i:52, score:0.25959] さらに，入力の誤りに対して頑健な主語補完モデルを作成するためにはどうすればよいかについて検討する．
-----------------------------------------------------
  [subsection title : 決定木を用いた補完手法]
-----------------------------------------------------
  [i:lead, score:0.40859] SDTモデルでは，決定木(Decision Tree)による知識表現手法を用いて主語補完知識の構築を行なう．
.....
  [i:53, score:0.40859] SDTモデルでは，決定木(Decision Tree)による知識表現手法を用いて主語補完知識の構築を行なう．
  [i:54, score:0.31971] 決定木の学習では，(誤りのない)入力と正解となる主語情報を持った事例から，事前に用意した属性の有無によって質問を行ない，エントロピー基準によって事例の分類を行なっていく．
  [i:60, score:0.29885] この決定木では，木の根にあたる節点[1-1]で:sem-code :here 43すなわち対象とする述語の意味属性(角川類語新辞典における分類番号上位2けた)が43かどうかによって学習事例が分岐し，これを満たす場合は[2-1]へ，満たさない場合は[2-2]へ進む．
-----------------------------------------------------
  [subsection title : 属性集合]
-----------------------------------------------------
  [i:lead, score:0.08825] 本論文では論文[CITE]と同様に，以下の3種類の属性を用いた．
.....
  [i:67, score:0.10905] 内容語の意味属性としては角川類語新辞典[CITE]における中分類(100属性)を使用した．
  [i:68, score:0.12222] 後述する照合位置が:hereと:beforeの2種類あるため，属性数は200である．
  [i:78, score:0.13732] 全属性を用いて決定木を作成した場合，属性数は367となる．
-----------------------------------------------------
  [subsection title : 属性の照合方法]
-----------------------------------------------------
  [i:lead, score:0.17815] 決定木学習時に行なう属性照合は，形態素列とのマッチングによって属性の照合を行なう．
.....
  [i:79, score:0.17815] 決定木学習時に行なう属性照合は，形態素列とのマッチングによって属性の照合を行なう．
  [i:80, score:0.19638] すなわち，補完対象の用言を中心にして，表[REF_表:照合位置]に示す5種類のうちどの位置に出現するかという情報をすべての属性に予め与えておく．
  [i:82, score:0.12026] 意味属性に関しては，ある位置にある意味属性を持つ語が含まれているかどうかによって照合を行なう．
-----------------------------------------------------
  [subsection title : SDTモデルの頑健性]
-----------------------------------------------------
  [i:lead, score:0.31138] 以上のSDTモデルの頑健性を考えた場合，以下の点において頑健性があると予想される．
.....
  [i:83, score:0.31138] 以上のSDTモデルの頑健性を考えた場合，以下の点において頑健性があると予想される．
  [i:85, score:0.36494] 例えば，間投詞や言い淀みなど，音声言語に頻出する冗長語が入力の途中に挿入された場合に，SDTモデルにおいては全く悪影響を与えない．
  [i:86, score:0.30748] あるいは，音声認識の誤りにより内容語や機能語が挿入された場合であっても，それが偶然に決定木で照合される語句である場合以外は，補完結果が変化することはない．

================================================================
[section type  : proposed_method]
[section title : 複数決定木モデル]
================================================================
[i:91, score:0.00000] 
-----------------------------------------------------
  [subsection title : 頑健性を強化するための方策]
-----------------------------------------------------
  [i:lead, score:0.19991] 前節に示した省略補完モデルに対し，入力の不正確性に対して頑健なモデルにするにはどうすればいいかを考える．
.....
  [i:92, score:0.19991] 前節に示した省略補完モデルに対し，入力の不正確性に対して頑健なモデルにするにはどうすればいいかを考える．
  [i:93, score:0.15978] 既存のモデルがある場合，このモデルに頑健性を持たせる手段として，本論文では複数の解答候補を用意し，そのうちの一つを何らかの方法によって最終的に選択する，という方策を取る．
  [i:100, score:0.07877] 複数の解答候補からどのように最終解を選択するか
-----------------------------------------------------
  [subsection title : 複数決定木モデル]
-----------------------------------------------------
  [i:lead, score:0.22346] 本論文では入力の不正確性に対する頑健性を持った主語補完モデルを提案する．
.....
  [i:104, score:0.57425] このモデルは，我々が文献[CITE]で提案した格要素省略補完モデルSDTを拡張したものであり，複数決定木モデルまたはMDT (Multiple Decision Tree)モデルと呼ぶ．
  [i:106, score:0.36675] MDTモデルは，複数の決定木を使用することによって頑健性を持たせたモデルである．
  [i:109, score:0.37489] これに対し，本論文で提案するMDTモデルでは，複数の解，例えば([MATH], [MATH], [MATH], [MATH])の解を得ることでき，この中から最も信頼性の高い解を選択することによって，MDTモデル全体としての頑健性が増す．
-----------------------------------------------------
  [subsection title : 属性集合の組合せ]
-----------------------------------------------------
  [i:lead, score:0.17139] 複数決定木モデルにおいては，各決定木の作成時に使用する属性を変化させる必要がある．
.....
  [i:113, score:0.24214] 我々は文献[CITE]における実験で，属性の種類が減少して同一種類の属性のみで決定木を作成した場合，補完精度の劣化が大きいことを確認した．
  [i:115, score:0.28503] このため表[REF_表:属性]で使用した3種類の属性をそのまま使用して各種類ごとに決定木を作成しても，(入力の不正確性とは関係なく)補完精度の劣化が大きいことが容易に予想される．
  [i:118, score:0.28077] これにより，使用属性数の減少による各決定木の補完精度の劣化を抑えることができ，同時に複数解候補を作成することが可能になる．
-----------------------------------------------------
  [subsection title : 補完候補の選好基準]
-----------------------------------------------------
  [i:lead, score:0.12770] 前節に示すように複数の属性を用意して複数の解答候補が得られたとき，このうちどれを最終的な解答とするかが第二の問題である．
.....
  [i:138, score:0.34658] 入力に誤りがあるために本来の属性の照合ができなかった場合には，学習事例数のより少ない節点に到達する確率がより高いため，例のように学習事例数の多い節点に到達した場合には，確率的に解の信頼性が高いと見做すことができる．
  [i:140, score:0.44318] これにより，各決定木が出力した解答候補のうち，決定木が出力した終端節点の学習時事例数が最大の解答をMDTにおける解答とする．
  [i:141, score:0.50141] 例えば図[REF_fig:mdt-model]では属性集合[MATH]における解答の学習時終端節点事例数が最も多いので，[MATH]をMDTとしての解答とする．
-----------------------------------------------------
  [subsection title : 提案手法の頑健性]
-----------------------------------------------------
  [i:lead, score:0.01267] 本手法の挙動を定性的に考察する．
.....
  [i:144, score:0.17467] ただし選好基準から明らかなように，本手法は学習時において事例が集中した「大きな」節点に対してのみ有効に機能する．
  [i:146, score:0.28797] この一方，学習時に事例数が1であった節点は，属性に誤りがあった場合に本手法では本来の正しい解を出力することが期待できない．
  [i:147, score:0.19598] すなわち，本手法はすべての事例に対して頑健になるわけではないが，事例が集中した節点を対象にしていることから多くの事例に対して頑健になることが予想できる．

================================================================
[section type  : experiment_result]
[section title : 主語補完実験]
================================================================
[i:149, score:0.16863] 本論文で提案したモデルの有効性を議論するため，主語補完実験を行なった．
[i:150, score:0.27206] 実験は，実際の音声認識結果を入力とした実誤りに対する精度と，人工的に誤りを作成した人工誤りに対する主語補完精度を評価した．
[i:151, score:0.16342] 本論文では6種類のクラスによる補完精度の違いを議論するのが目的ではないため，以下の実験結果ではクラス別の補完精度を示さず，全評価事例に対する平均を示す．
-----------------------------------------------------
  [subsection title : 音声認識結果に対する頑健性]
-----------------------------------------------------
  [i:lead, score:0.25288] 本稿で提案したモデルの有効性を確認するため，実際の音声認識結果を入力とした実誤りに対する補完精度を測定した．
.....
  [i:168, score:0.40199] また，誤りのない入力に対しても，MDTは最も高い主語補完性能を示した．
  [i:169, score:0.56870] 実験は，単独の決定木を使用して補完を行なうSDTモデルによる実験と，本稿の提案するMDTモデルの両者について行なった．
  [i:172, score:0.52847] また，MDTモデルは，上記の属性集合A，C，Fの三つからSDTを構成した．
-----------------------------------------------------
  [subsection title : 人工誤りに対する実験]
-----------------------------------------------------
  [i:lead, score:0.18408] 次に，モデルの頑健性と誤りの傾向との関連を議論するために，以下のような人工誤りに対してモデルがどのような特性を示すのかを実験した．
.....
  [i:188, score:0.56696] また，MDTモデルにほとんど性能劣化がないのは，上記SDTが持つ頑健性に加え，意思決定を複数行なった後に選択する本手法が有効に機能しているためと考えられる．
  [i:196, score:0.48131] 図からわかるように，MDTモデルは三種類のSDTのうち最も高精度であるSDT/Cよりも常に高精度である．
  [i:199, score:0.53331] これに対し，SDT/Cモデルの精度が相対的に優れているという情報をMDTは何ら持たないにもかかわらずMDTがSDT/Cの出力する解を比較的多く採用している点から，本論文で提案した選好の有効性を確認することができる．
-----------------------------------------------------
  [subsection title : 考察]
-----------------------------------------------------
  [i:lead, score:0.15223] まず，入力誤りに対する頑健性を議論する．
.....
  [i:216, score:0.53364] 図[REF_fig:insert]〜図[REF_fig:mix]より，本論文で提案するMDTモデルが比較手法(SDT)よりも頑健であることがわかる．
  [i:221, score:0.56364] 本研究では3種類の属性集合を用意したが，これは3種類である必要はなく，むしろ高性能であると予想されるSDTをできるだけ多く用意することで，MDT全体としてより頑健性が増すことが期待できる．
  [i:226, score:0.53017] 表[REF_表:認識器]から，3種類のSDTの中で最も良好なSDT/AはP2よりもP1のほうが補完精度が高いが，MDTの補完精度はP2がP1を上回っている．

================================================================
[section type  : proposed_method]
[section title : シミュレーション]
================================================================
[i:229, score:0.50261] 前節の評価実験で，誤りを含む入力に対して[REF_節:属性]節の属性集合からなるMDTモデルが主語補完問題に対し有効に機能することを確認した．
[i:230, score:0.36545] しかし，以上の結果はいかなる問題に対してもMDTモデルが有効なのか，あるいは本論文における属性集合の組み合わせ方が偶然有効に機能したのかは明確でない．
[i:231, score:0.42743] そこで，MDTモデルの問題依存性，並びに属性集合の組み合わせ方がモデルの精度にどのような影響を与えるのか，の2点を検証，議論するため，人工的な問題を設定してMDTモデルのシミュレーションを行なった[CITE]．
-----------------------------------------------------
  [subsection title : 問題設定とMDTの設定]
-----------------------------------------------------
  [i:lead, score:0.00440] 問題は以下のように設定した．
.....
  [i:252, score:0.52922] 例えば，MDT(9)は9属性の全組み合わせ(10種類)と10属性の全組み合わせ(1種類)に対してそれぞれ作成した11個のSDTを組み合わせたモデルである．
  [i:253, score:0.45406] 同様にMDT(8)は56個，MDT(7)は176個のSDTからなり，最多のMDT(1)は1023個のSDTから構成される．
  [i:257, score:0.52621] 実験は，10属性以下で構成される全組み合わせのSDT (1023個)に対して精度を測定し，これをもとに10種類のMDT([MATH]) ([MATH])の精度を計算した．
-----------------------------------------------------
  [subsection title : シミュレーション結果]
-----------------------------------------------------
  [i:lead, score:0.10795] ある乱数におけるシミュレーションの結果を図[REF_図:1誤り]に示す．
.....
  [i:262, score:0.59275] 任意の1属性に誤りがある入力に対し，使用可能な全10属性からなるSDTは10.4%，9属性以上のSDTによる多数決基準は16.0%の正解率であるのに対し，MDT(9)は57.6%の正解率を得ることができ，MDTの優位性を確認した．
  [i:263, score:0.55731] またMDT(9)は9属性以上で可能な全組み合わせに対して作成したSDTを用いていることより，どうやって不要な属性を減らすか，あるいはどのような組み合わせが適当かを考慮する必要がないため，MDTモデルはこの点において，SDTモデルで使用属性を吟味して精度向上を目指すアプローチよりも優位である．
  [i:271, score:0.65133] 一般的に，終端節点の学習事例数は，多数属性で作成した決定木のそれよりも少数属性のほうが平均的に多いためこのように少数属性のSDTが選択されやすくなるのであろうが，相対的に精度の高い少数属性のSDTを選択してもMDTの精度が低下する理由は不明である．
-----------------------------------------------------
  [subsection title : 事例集合との関係]
-----------------------------------------------------
  [i:lead, score:0.51106] [REF_節:定性議論]節で議論したように，MDTモデルは事例が集中した節点を得るのに用いた属性に誤りがある場合に有効に機能すると予想される．
.....
  [i:273, score:0.51106] [REF_節:定性議論]節で議論したように，MDTモデルは事例が集中した節点を得るのに用いた属性に誤りがある場合に有効に機能すると予想される．
  [i:276, score:0.37013] 事例集合[MATH]に誤りを含めた場合に，図[REF_図:1誤り]に示すようにMDT(9)は全体で57.6%の精度が得られたが，これを事例集合別に分類して集計すると，[MATH]は96.5%，[MATH]は15.5%の精度であり，極端に精度が異なる．
  [i:279, score:0.52475] すなわち，決定木において一部の終端節点に事例が集中するような構造を持つ場合ほど，MDTは誤りを含む入力に対して頑健であることが予想される．
-----------------------------------------------------
  [subsection title : 誤り数との関係]
-----------------------------------------------------
  [i:lead, score:0.41733] 図[REF_図:1誤り]においてMDT(9)の精度が最も高いのは，各事例に対して1個の属性値に誤りを起こしているためである可能性がある．
.....
  [i:280, score:0.41733] 図[REF_図:1誤り]においてMDT(9)の精度が最も高いのは，各事例に対して1個の属性値に誤りを起こしているためである可能性がある．
  [i:284, score:0.37830] 図が示すように，各属性に無作為に2誤りを与えた場合はMDT(8)が，3誤りの場合はMDT(7)が最も高い精度を示していることがわかる．
  [i:286, score:0.56127] すなわち，図[REF_図:1誤り]，図[REF_図:2誤り]，図[REF_図:3誤り]から類推すると，属性数が[MATH]で誤りが高々[MATH]ならば属性数が([MATH])以上のすべてのSDTでMDTを構成するのが最善であろう．
-----------------------------------------------------
  [subsection title : 正解入力での特性]
-----------------------------------------------------
  [i:lead, score:0.29473] 最後に，誤りがない場合にMDTがどのような挙動を示すのかを検証する．
.....
  [i:287, score:0.29473] 最後に，誤りがない場合にMDTがどのような挙動を示すのかを検証する．
  [i:290, score:0.28959] ただし，正解入力は誤り0の入力であるので，これを前節で議論した誤り数と使用属性数の関係にあてはめると，全属性数で決定木を作成するのが最も適切であろうという予想が得られ，シミュレーション結果と一致する．
  [i:291, score:0.28614] 本シミュレーションでは矛盾のないように属性を作成しているので，このような状況においては全属性による決定木が一つあれば十分で，入力に誤りのない場合は複数決定木モデルを使用する必要がない．

================================================================
[section type  : conclusion]
[section title : 結論と今後の課題]
================================================================
[i:297, score:0.43079] 本論文では，対話に頻出する主語省略の補完問題を取り上げ，複数の決定木を用いたモデル(MDTモデル)による問題解決手法を提案した．
[i:302, score:0.39897] 本論文で行なった主語補完実験とシミュレーションにより，MDTモデルの特性が明らかになった．
[i:309, score:0.39904] また，主語補完実験においては無誤りでもMDTのほうが高性能であったが，これがどのような状況であったためかは明確でなく，実験においても結論を出すに至らなかった．

