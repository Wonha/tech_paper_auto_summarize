本節では，日本語の格要素省略を補完する問題に対して我々が文献[CITE]において提案した手法の概要を紹介する．
本論文では，このモデルをSDT(Single Decision Tree)モデルと呼び，入力の不確かさに対する頑健性という観点から，SDTモデルがどの程度の頑健性を持つのかについて定性的な議論を行なう．
さらに，入力の誤りに対して頑健な主語補完モデルを作成するためにはどうすればよいかについて検討する．
SDTモデルでは，決定木(Decision Tree)による知識表現手法を用いて主語補完知識の構築を行なう．
決定木の学習では，(誤りのない)入力と正解となる主語情報を持った事例から，事前に用意した属性の有無によって質問を行ない，エントロピー基準によって事例の分類を行なっていく．
論文[CITE]においては，一般的な決定木学習手法の一つであるC4.5[CITE]のアルゴリズムによって二分木を作成した．
本論文の設定する問題では，補完すべき主語を6種類に分類した．
すなわち，一人称単数<1sg>，一人称複数<1pl>，二人称単数<2sg>，二人称複数<2pl>，照応的省略<a>，一般<g>である．
決定木は，与えられた入力に対して当該省略がこのどのクラスに属するかを決定する．
[1-1]:sem-code :here 43 [2-1]:sem-code :here 78 [3-1]:regexp :after (ておる助動詞) [4-1]:regexp :after (する補助動詞) [5-1]:speaker :here情報提供者[6-1]:regexp :before (を格助詞) .
..
[6-2]<1pl> (5) [5-2]<1pl> (12) [4-2]:regexp :after (てる助動詞) [5-3]<1sg> (2) [5-4]:regexp :forward (ている助動詞) .
..
[3-2]:regexp :after (か終助詞) [4-3]:regexp :before (に格助詞) [5-5]<1sg> (1) [5-6]:regexp :after (できる補助動詞) .
..
[4-4]:regexp :after (できる補助動詞) [5-7]<1pl> (9) [5-8]:sem-code :before 93 .
..
[2-2]:sem-code :here 41 [3-3]:regexp :after (た助動詞) [4-5]:regexp :before (を格助詞) .
..
表[REF_表:決定木]に，本問題に対して作成された決定木の例を示す．
この決定木では，木の根にあたる節点[1-1]で:sem-code :here 43すなわち対象とする述語の意味属性(角川類語新辞典における分類番号上位2けた)が43かどうかによって学習事例が分岐し，これを満たす場合は[2-1]へ，満たさない場合は[2-2]へ進む．
節点[6-2]は終端節点であり，解が<1pl>すなわち一人称複数であり，学習事例は5であったことを示す．
表[REF_表:決定木]の各属性に見られるように，各属性は(属性の種類,照合位置,属性値)の三つ組によって表現される．
以下の節では，属性の種類，照合位置について簡単に述べる．
本論文では論文[CITE]と同様に，以下の3種類の属性を用いた．
省略の対象となる文において，どのような内容語が含まれているかに関する情報．
内容語は大きく，用言に関する情報と格要素(体言)に関する情報に分かれる．
内容語の意味属性としては角川類語新辞典[CITE]における中分類(100属性)を使用した．
後述する照合位置が:hereと:beforeの2種類あるため，属性数は200である．
用言に後接する付属語群や終助詞，及び格助詞や接頭辞などの機能語の出現に関する情報．
前述の内容語と異なり，これらの機能語は当該品詞に属する単語を直接参照した．
属性数は166である．
言語外情報としては，発話された文の話者情報を利用した．
本論文で使用するコーパスは話者が情報提供者か情報享受者の二者による対話を仮定している．
例えば，ホテルにおける対話では，情報提供者であるフロントと情報享受者の客の二者による対話となる．
話者によって主語省略の振る舞いが影響すると考えたため使用した．
属性数は1である．
以上をまとめたものを表[REF_表:属性]に示す．
全属性を用いて決定木を作成した場合，属性数は367となる．
決定木学習時に行なう属性照合は，形態素列とのマッチングによって属性の照合を行なう．
すなわち，補完対象の用言を中心にして，表[REF_表:照合位置]に示す5種類のうちどの位置に出現するかという情報をすべての属性に予め与えておく．
例えば，用言に関する属性は:here，格助詞に対しては:before，接頭辞に対しては:latestの位置情報を与える．
意味属性に関しては，ある位置にある意味属性を持つ語が含まれているかどうかによって照合を行なう．
以上のSDTモデルの頑健性を考えた場合，以下の点において頑健性があると予想される．
すなわち，入力に対して，本来の入力にはない形態素列が誤って挿入された場合における頑健性である．
例えば，間投詞や言い淀みなど，音声言語に頻出する冗長語が入力の途中に挿入された場合に，SDTモデルにおいては全く悪影響を与えない．
あるいは，音声認識の誤りにより内容語や機能語が挿入された場合であっても，それが偶然に決定木で照合される語句である場合以外は，補完結果が変化することはない．
以上の頑健性は，属性照合の際に，ある照合範囲における特定の語句の有無のみを考慮しているために生じる．
これにより，照合範囲に対象と無関係の語句が挿入された場合にも影響はなく，また照合対象である語句が照合範囲に偶然挿入される可能性は，一般には低い．
ただし，以上は挿入誤りに対するある程度の頑健性のみであり，欠落誤り，置換誤りに対しては影響が出る可能性が高い．
なぜなら，前述の照合方法は照合に不要な要素をいくら含んでも影響は少ないが，照合に必要な要素が欠落した場合には対応できないからである．
前節に示した省略補完モデルに対し，入力の不正確性に対して頑健なモデルにするにはどうすればいいかを考える．
既存のモデルがある場合，このモデルに頑健性を持たせる手段として，本論文では複数の解答候補を用意し，そのうちの一つを何らかの方法によって最終的に選択する，という方策を取る．
複数の解答候補を生成するには，解答に至るための情報源を別個にすればよい．
すなわち，同一のモデルを使用してそのモデルの入力となる情報源を変化させることによって，各モデルに独自の判断をさせることが可能になる．
これはちょうど，ある事象に対して，同一の道具で観察する視点を変化させることに相当する．
ここで，以上の方策を取るためには以下の二つの問題を解決しなければならない．
すなわち，
どのように別個の情報源を用意するか
複数の解答候補からどのように最終解を選択するか
である．
以上の問題点については，次節以降で述べる．
本論文では入力の不正確性に対する頑健性を持った主語補完モデルを提案する．
このモデルは，我々が文献[CITE]で提案した格要素省略補完モデルSDTを拡張したものであり，複数決定木モデルまたはMDT (Multiple Decision Tree)モデルと呼ぶ．
概要を図{}[REF_fig:mdt-model]に示す．
MDTモデルは，複数の決定木を使用することによって頑健性を持たせたモデルである．
このモデルでは，決定木学習の際に使用する属性集合を変化させることによって決定木を作成し，複数の解答候補を得る．
図{}[REF_fig:mdt-model]に示すように，従来SDTでは単一の解[MATH]のみが得られるため，この解の信頼性が低い場合にも代替解を得ることができなかった．
これに対し，本論文で提案するMDTモデルでは，複数の解，例えば([MATH], [MATH], [MATH], [MATH])の解を得ることでき，この中から最も信頼性の高い解を選択することによって，MDTモデル全体としての頑健性が増す．
ここで，各決定木の学習は，全く同一の学習事例集合に対して行なう．
以下，どのように使用属性を変化させるかについては{}[REF_節:組合せ]節で，複数の解候補の中からどのようにして最終解を選択するかについては，{}[REF_節:選好]節で述べる．
複数決定木モデルにおいては，各決定木の作成時に使用する属性を変化させる必要がある．
我々は文献[CITE]における実験で，属性の種類が減少して同一種類の属性のみで決定木を作成した場合，補完精度の劣化が大きいことを確認した．
すなわち主語補完のためには，様々な属性を総合的に考慮して補完する必要がある．
このため表[REF_表:属性]で使用した3種類の属性をそのまま使用して各種類ごとに決定木を作成しても，(入力の不正確性とは関係なく)補完精度の劣化が大きいことが容易に予想される．
そこで本論文では，これら属性集合を組み合わせることによって各決定木の属性集合を構成することにした．
本論文の使用する属性は前述したように3種類であるので，図[REF_図:属性集合]に示すようにこれらの組合せによって3種類の属性集合を作成した．
これにより，使用属性数の減少による各決定木の補完精度の劣化を抑えることができ，同時に複数解候補を作成することが可能になる．
前節に示すように複数の属性を用意して複数の解答候補が得られたとき，このうちどれを最終的な解答とするかが第二の問題である．
本節では，この問題について検討する．
複数の解から一つの解を選択する際には多数決基準などが一般的であるが，本問題のように属性の組合せによって決定木を作成している場合に，多数決基準を使用するのは適当ではない．
なぜなら，仮に図[REF_図:属性集合]のような状況で言語外情報が誤りを含んでいると仮定すると，3種類の決定木すべてが誤った解を出力する可能性があるからである．
このように一属性が複数の解に影響するような組み合わせ方を行なった場合，解の多数決を取ることは適当ではないと考えた．
そこで本論文では，各解答に対して信頼性を計算し，それの比較によって行なう選好基準を提案する．
この際，解の信頼性に相当する値として，以下に述べる理由により，決定木学習時に解と同一の終端節点に辿り着いた事例数を用い，これが最多である解を選択する．
いま，決定木のある属性において属性照合を誤ったと仮定する．
この場合，本来到達すべき終端節点には到達せずに別の節点に到達する．
この際，どの節点に到達したかは，これ以上の情報がない場合，一般にすべての節点が同一の確率である．
ここで，誤って到達した節点の学習時の事例数を予想すると，全節点への到達可能性が同等なのだから，終端節点の学習事例数に関して最も頻出する事例数が最も可能性が高い．
例えば，学習事例数[MATH]の終端節点が最も多い場合には，誤って到達した節点の学習時事例数は[MATH]の可能性が最も高いと予想するのが自然である．
それでは実際にどのような事例数の終端節点が多いのかを調査したのが図[REF_fig:freq]である．
図[REF_fig:freq]では，次節で述べる3種類の決定木それぞれについて，終端節点の事例数別に統計をとったものである．
この図から明らかなように，どの決定木においても，学習時の事例数が1の節点が最も多く，その後漸減の傾向にある．
すなわちこれらの決定木に関しては，学習時の事例数が少ない節点ほど誤って辿り着く確率が高い．
次に，図[REF_fig:mdt-model]に示すように，同一の学習事例集合に対して属性集合を([MATH], [MATH], [MATH], [MATH])の[MATH]種類に変化させ，複数の決定木を作成することを考える．
図[REF_fig:mdt-model]において，属性集合[MATH]による補完結果候補[MATH]よりも，属性集合[MATH]による補完結果候補[MATH]のほうが解の信頼性が高いと考えるのは自然である．
なぜならば，これまでの議論により，属性照合を誤って解候補[MATH]に到達する可能性よりも属性照合を誤って解候補[MATH]に到達する可能性のほうが高いからである．
入力に誤りがあるために本来の属性の照合ができなかった場合には，学習事例数のより少ない節点に到達する確率がより高いため，例のように学習事例数の多い節点に到達した場合には，確率的に解の信頼性が高いと見做すことができる．
以上の理由により，我々は決定木学習時の終端節点の事例数によって解の選好を行なう．
これにより，各決定木が出力した解答候補のうち，決定木が出力した終端節点の学習時事例数が最大の解答をMDTにおける解答とする．
例えば図[REF_fig:mdt-model]では属性集合[MATH]における解答の学習時終端節点事例数が最も多いので，[MATH]をMDTとしての解答とする．
本手法の挙動を定性的に考察する．
本論文の提案する手法によって入力に若干の誤りがあり，誤り箇所を特定できない場合に対して本手法は有効に機能することが予想できる．
ただし選好基準から明らかなように，本手法は学習時において事例が集中した「大きな」節点に対してのみ有効に機能する．
あるいはある節点に極端に事例が集中するような場合に，本論文の選好がより有効に機能する．
この一方，学習時に事例数が1であった節点は，属性に誤りがあった場合に本手法では本来の正しい解を出力することが期待できない．
すなわち，本手法はすべての事例に対して頑健になるわけではないが，事例が集中した節点を対象にしていることから多くの事例に対して頑健になることが予想できる．
以上の議論の定量的な検証は[REF_節:定量議論]節において行なう．
前節の評価実験で，誤りを含む入力に対して[REF_節:属性]節の属性集合からなるMDTモデルが主語補完問題に対し有効に機能することを確認した．
しかし，以上の結果はいかなる問題に対してもMDTモデルが有効なのか，あるいは本論文における属性集合の組み合わせ方が偶然有効に機能したのかは明確でない．
そこで，MDTモデルの問題依存性，並びに属性集合の組み合わせ方がモデルの精度にどのような影響を与えるのか，の2点を検証，議論するため，人工的な問題を設定してMDTモデルのシミュレーションを行なった[CITE]．
本節ではこの内容及び結果について述べる．
問題は以下のように設定した．
まず，問題の全属性数は10，分類すべきクラス数は10とした．
属性値は二値としたため作成される決定木は二分木であり，枝刈りは行なわない．
学習事例は，以下の2種類の方法で順に作成した．
まず1事例を無作為に作成する．
ただし既作成の事例と矛盾しないようにする．
すなわち各属性の値はすべて同一であるがクラスが異なる事例は新規事例に追加しない．
この事例と属性値及びクラスが全く同一のコピー事例を(1〜100)事例の範囲で作成する．
(1〜100)のうちいくつ重複させるかは無作為に決定する．
以上の処理を，[MATH]全体で1000事例を越えるまで繰り返す．
無作為に1事例を作成する．
ただし，作成される事例は[MATH]と[MATH]内のどの事例とも矛盾しない．
以上の処理を1000回繰り返す．
以上のような方法で，本シミュレーションでは[MATH]が1084事例，[MATH]が1000事例の合計([MATH]) 2084事例を作成した．
各決定木は，事例集合[MATH]を用いて作成する．
次に，使用したMDTについて述べる．
MDTは以下のようにSDTを組み合わせて構成した．
すなわち，使用属性数が[MATH]以上の全属性組み合わせについてSDTをすべて作成し，これを組み合わることで構成した．
以下ではこれをMDT([MATH])と記述する．
例えば，MDT(9)は9属性の全組み合わせ(10種類)と10属性の全組み合わせ(1種類)に対してそれぞれ作成した11個のSDTを組み合わせたモデルである．
同様にMDT(8)は56個，MDT(7)は176個のSDTからなり，最多のMDT(1)は1023個のSDTから構成される．
実験は以下のように行なった．
学習時に使用した事例集合[MATH]に対し，各事例について1ヶ所(後述の[REF_節:誤り数との関係]節では2または3ヶ所，{}[REF_節:正解入力]節では0ヶ所)の属性を無作為に選び，その属性値に誤りを起こさせたものを入力とした．
すなわち，今回作成する二分木は属性が2値であるため，無作為に選ばれた属性の属性値を反転させたものを入力とした．
実験は，10属性以下で構成される全組み合わせのSDT (1023個)に対して精度を測定し，これをもとに10種類のMDT([MATH]) ([MATH])の精度を計算した．
また比較対象として，多数決基準，すなわち[MATH]属性以上のすべてのSDTが返す解のうち最多のものを解とする選考基準での精度も測定した．
ある乱数におけるシミュレーションの結果を図[REF_図:1誤り]に示す．
異なる乱数でシミュレーションを行なった場合も全く同様の傾向が見られた．
図で，実線はMDT，点線は多数決基準の精度を示し，SDT単独の精度は点で表した．
任意の1属性に誤りがある入力に対し，使用可能な全10属性からなるSDTは10.4%，9属性以上のSDTによる多数決基準は16.0%の正解率であるのに対し，MDT(9)は57.6%の正解率を得ることができ，MDTの優位性を確認した．
またMDT(9)は9属性以上で可能な全組み合わせに対して作成したSDTを用いていることより，どうやって不要な属性を減らすか，あるいはどのような組み合わせが適当かを考慮する必要がないため，MDTモデルはこの点において，SDTモデルで使用属性を吟味して精度向上を目指すアプローチよりも優位である．
ただし，図が示す通り，MDTモデルは少数属性のSDTを追加していくに従い精度が低下する．
逆に多数決基準は精度が向上し7属性以下の決定木を使用した場合には両者の精度が逆転した．
このことから，MDTはどのような属性数の決定木を加えても精度向上するわけではないことがわかる．
最高の精度は5属性以上による多数決基準によって得られた(58.7%)が，現実的には少数属性の決定木を大量に作成して多数決を取ることは計算量の面で有利ではないため，1誤りの場合はMDT(9)が最も実用的なモデルであると言える．
図において各SDTがどのような精度であるかを観察すると，属性数が減少するに伴い，平均的に徐々に精度は向上している．
一方，MDT([MATH])が選択するSDTを観察すると，SDTの中で最少属性のもののうちから選択されている場合が圧倒的に多い．
例えば，MDT(6)は6属性のSDTのうちの一つの解を選択している場合が圧倒的に多い．
一般的に，終端節点の学習事例数は，多数属性で作成した決定木のそれよりも少数属性のほうが平均的に多いためこのように少数属性のSDTが選択されやすくなるのであろうが，相対的に精度の高い少数属性のSDTを選択してもMDTの精度が低下する理由は不明である．
これは今後の課題としたい．
[REF_節:定性議論]節で議論したように，MDTモデルは事例が集中した節点を得るのに用いた属性に誤りがある場合に有効に機能すると予想される．
ここではこれを検証する．
本シミュレーションでは，終端節点に集中する事例[MATH]とそれ以外の事例[MATH]の2種類の方法で事例集合[MATH]を作成した．
事例集合[MATH]に誤りを含めた場合に，図[REF_図:1誤り]に示すようにMDT(9)は全体で57.6%の精度が得られたが，これを事例集合別に分類して集計すると，[MATH]は96.5%，[MATH]は15.5%の精度であり，極端に精度が異なる．
この結果は，頻出する現象に対しては入力に誤りがあってもかなり高い精度で正解を得ることができるのに対し，稀に出現する現象は正解を得ることが期待できないことを示し，[REF_節:定性議論]節で行なった議論が正しいことを確認した．
以上の結果から本手法が有効に機能する状況が推測できる．
すなわち，決定木において一部の終端節点に事例が集中するような構造を持つ場合ほど，MDTは誤りを含む入力に対して頑健であることが予想される．
図[REF_図:1誤り]においてMDT(9)の精度が最も高いのは，各事例に対して1個の属性値に誤りを起こしているためである可能性がある．
ではもし誤りが1ではなく，2もしくは3である場合，MDTはどのような傾向を示すであろうか．
これを示したのが図[REF_図:2誤り](2誤りの場合)および図[REF_図:3誤り] (3誤りの場合)である．
このシミュレーションにおいては，誤り数以外の条件は全く同じであり，誤りを含める対象の事例集合[MATH]も，図[REF_図:1誤り]と全く同一のものを使用した．
図が示すように，各属性に無作為に2誤りを与えた場合はMDT(8)が，3誤りの場合はMDT(7)が最も高い精度を示していることがわかる．
すなわち，誤りの数と用意するSDTとの間には相関関係がありそうである．
すなわち，図[REF_図:1誤り]，図[REF_図:2誤り]，図[REF_図:3誤り]から類推すると，属性数が[MATH]で誤りが高々[MATH]ならば属性数が([MATH])以上のすべてのSDTでMDTを構成するのが最善であろう．
最後に，誤りがない場合にMDTがどのような挙動を示すのかを検証する．
図[REF_図:正解入力]に，事例集合[MATH]に誤りを与えずに各モデルに入力した場合，すなわち学習事例と入力が全く同一の場合のテスト(closed test)を行なった結果を示す．
この図から明らかなように，一般に属性数の減少に伴い精度は低下していくが，本提案モデルの精度の低下が最も激しい．
ただし，正解入力は誤り0の入力であるので，これを前節で議論した誤り数と使用属性数の関係にあてはめると，全属性数で決定木を作成するのが最も適切であろうという予想が得られ，シミュレーション結果と一致する．
本シミュレーションでは矛盾のないように属性を作成しているので，このような状況においては全属性による決定木が一つあれば十分で，入力に誤りのない場合は複数決定木モデルを使用する必要がない．
ただし，主語補完問題のようにこのような状況が成立しない場合には，実験結果が示すように誤りが0であっても複数決定木モデルが有効に機能する可能性がある．
これがどのような場合に有効なのかはシミュレーションでも究明することができなかった．
今後の課題としたい．
本節では，日本語の格要素省略を補完する問題に対して我々が文献[CITE]において提案した手法の概要を紹介する．
本論文では，このモデルをSDT(Single Decision Tree)モデルと呼び，入力の不確かさに対する頑健性という観点から，SDTモデルがどの程度の頑健性を持つのかについて定性的な議論を行なう．
さらに，入力の誤りに対して頑健な主語補完モデルを作成するためにはどうすればよいかについて検討する．
SDTモデルでは，決定木(Decision Tree)による知識表現手法を用いて主語補完知識の構築を行なう．
決定木の学習では，(誤りのない)入力と正解となる主語情報を持った事例から，事前に用意した属性の有無によって質問を行ない，エントロピー基準によって事例の分類を行なっていく．
論文[CITE]においては，一般的な決定木学習手法の一つであるC4.5[CITE]のアルゴリズムによって二分木を作成した．
本論文の設定する問題では，補完すべき主語を6種類に分類した．
すなわち，一人称単数<1sg>，一人称複数<1pl>，二人称単数<2sg>，二人称複数<2pl>，照応的省略<a>，一般<g>である．
決定木は，与えられた入力に対して当該省略がこのどのクラスに属するかを決定する．
[1-1]:sem-code :here 43 [2-1]:sem-code :here 78 [3-1]:regexp :after (ておる助動詞) [4-1]:regexp :after (する補助動詞) [5-1]:speaker :here情報提供者[6-1]:regexp :before (を格助詞) .
..
[6-2]<1pl> (5) [5-2]<1pl> (12) [4-2]:regexp :after (てる助動詞) [5-3]<1sg> (2) [5-4]:regexp :forward (ている助動詞) .
..
[3-2]:regexp :after (か終助詞) [4-3]:regexp :before (に格助詞) [5-5]<1sg> (1) [5-6]:regexp :after (できる補助動詞) .
..
[4-4]:regexp :after (できる補助動詞) [5-7]<1pl> (9) [5-8]:sem-code :before 93 .
..
[2-2]:sem-code :here 41 [3-3]:regexp :after (た助動詞) [4-5]:regexp :before (を格助詞) .
..
表[REF_表:決定木]に，本問題に対して作成された決定木の例を示す．
この決定木では，木の根にあたる節点[1-1]で:sem-code :here 43すなわち対象とする述語の意味属性(角川類語新辞典における分類番号上位2けた)が43かどうかによって学習事例が分岐し，これを満たす場合は[2-1]へ，満たさない場合は[2-2]へ進む．
節点[6-2]は終端節点であり，解が<1pl>すなわち一人称複数であり，学習事例は5であったことを示す．
表[REF_表:決定木]の各属性に見られるように，各属性は(属性の種類,照合位置,属性値)の三つ組によって表現される．
以下の節では，属性の種類，照合位置について簡単に述べる．
本論文では論文[CITE]と同様に，以下の3種類の属性を用いた．
省略の対象となる文において，どのような内容語が含まれているかに関する情報．
内容語は大きく，用言に関する情報と格要素(体言)に関する情報に分かれる．
内容語の意味属性としては角川類語新辞典[CITE]における中分類(100属性)を使用した．
後述する照合位置が:hereと:beforeの2種類あるため，属性数は200である．
用言に後接する付属語群や終助詞，及び格助詞や接頭辞などの機能語の出現に関する情報．
前述の内容語と異なり，これらの機能語は当該品詞に属する単語を直接参照した．
属性数は166である．
言語外情報としては，発話された文の話者情報を利用した．
本論文で使用するコーパスは話者が情報提供者か情報享受者の二者による対話を仮定している．
例えば，ホテルにおける対話では，情報提供者であるフロントと情報享受者の客の二者による対話となる．
話者によって主語省略の振る舞いが影響すると考えたため使用した．
属性数は1である．
以上をまとめたものを表[REF_表:属性]に示す．
全属性を用いて決定木を作成した場合，属性数は367となる．
決定木学習時に行なう属性照合は，形態素列とのマッチングによって属性の照合を行なう．
すなわち，補完対象の用言を中心にして，表[REF_表:照合位置]に示す5種類のうちどの位置に出現するかという情報をすべての属性に予め与えておく．
例えば，用言に関する属性は:here，格助詞に対しては:before，接頭辞に対しては:latestの位置情報を与える．
意味属性に関しては，ある位置にある意味属性を持つ語が含まれているかどうかによって照合を行なう．
以上のSDTモデルの頑健性を考えた場合，以下の点において頑健性があると予想される．
すなわち，入力に対して，本来の入力にはない形態素列が誤って挿入された場合における頑健性である．
例えば，間投詞や言い淀みなど，音声言語に頻出する冗長語が入力の途中に挿入された場合に，SDTモデルにおいては全く悪影響を与えない．
あるいは，音声認識の誤りにより内容語や機能語が挿入された場合であっても，それが偶然に決定木で照合される語句である場合以外は，補完結果が変化することはない．
以上の頑健性は，属性照合の際に，ある照合範囲における特定の語句の有無のみを考慮しているために生じる．
これにより，照合範囲に対象と無関係の語句が挿入された場合にも影響はなく，また照合対象である語句が照合範囲に偶然挿入される可能性は，一般には低い．
ただし，以上は挿入誤りに対するある程度の頑健性のみであり，欠落誤り，置換誤りに対しては影響が出る可能性が高い．
なぜなら，前述の照合方法は照合に不要な要素をいくら含んでも影響は少ないが，照合に必要な要素が欠落した場合には対応できないからである．
前節に示した省略補完モデルに対し，入力の不正確性に対して頑健なモデルにするにはどうすればいいかを考える．
既存のモデルがある場合，このモデルに頑健性を持たせる手段として，本論文では複数の解答候補を用意し，そのうちの一つを何らかの方法によって最終的に選択する，という方策を取る．
複数の解答候補を生成するには，解答に至るための情報源を別個にすればよい．
すなわち，同一のモデルを使用してそのモデルの入力となる情報源を変化させることによって，各モデルに独自の判断をさせることが可能になる．
これはちょうど，ある事象に対して，同一の道具で観察する視点を変化させることに相当する．
ここで，以上の方策を取るためには以下の二つの問題を解決しなければならない．
すなわち，
どのように別個の情報源を用意するか
複数の解答候補からどのように最終解を選択するか
である．
以上の問題点については，次節以降で述べる．
本論文では入力の不正確性に対する頑健性を持った主語補完モデルを提案する．
このモデルは，我々が文献[CITE]で提案した格要素省略補完モデルSDTを拡張したものであり，複数決定木モデルまたはMDT (Multiple Decision Tree)モデルと呼ぶ．
概要を図{}[REF_fig:mdt-model]に示す．
MDTモデルは，複数の決定木を使用することによって頑健性を持たせたモデルである．
このモデルでは，決定木学習の際に使用する属性集合を変化させることによって決定木を作成し，複数の解答候補を得る．
図{}[REF_fig:mdt-model]に示すように，従来SDTでは単一の解[MATH]のみが得られるため，この解の信頼性が低い場合にも代替解を得ることができなかった．
これに対し，本論文で提案するMDTモデルでは，複数の解，例えば([MATH], [MATH], [MATH], [MATH])の解を得ることでき，この中から最も信頼性の高い解を選択することによって，MDTモデル全体としての頑健性が増す．
ここで，各決定木の学習は，全く同一の学習事例集合に対して行なう．
以下，どのように使用属性を変化させるかについては{}[REF_節:組合せ]節で，複数の解候補の中からどのようにして最終解を選択するかについては，{}[REF_節:選好]節で述べる．
複数決定木モデルにおいては，各決定木の作成時に使用する属性を変化させる必要がある．
我々は文献[CITE]における実験で，属性の種類が減少して同一種類の属性のみで決定木を作成した場合，補完精度の劣化が大きいことを確認した．
すなわち主語補完のためには，様々な属性を総合的に考慮して補完する必要がある．
このため表[REF_表:属性]で使用した3種類の属性をそのまま使用して各種類ごとに決定木を作成しても，(入力の不正確性とは関係なく)補完精度の劣化が大きいことが容易に予想される．
そこで本論文では，これら属性集合を組み合わせることによって各決定木の属性集合を構成することにした．
本論文の使用する属性は前述したように3種類であるので，図[REF_図:属性集合]に示すようにこれらの組合せによって3種類の属性集合を作成した．
これにより，使用属性数の減少による各決定木の補完精度の劣化を抑えることができ，同時に複数解候補を作成することが可能になる．
前節に示すように複数の属性を用意して複数の解答候補が得られたとき，このうちどれを最終的な解答とするかが第二の問題である．
本節では，この問題について検討する．
複数の解から一つの解を選択する際には多数決基準などが一般的であるが，本問題のように属性の組合せによって決定木を作成している場合に，多数決基準を使用するのは適当ではない．
なぜなら，仮に図[REF_図:属性集合]のような状況で言語外情報が誤りを含んでいると仮定すると，3種類の決定木すべてが誤った解を出力する可能性があるからである．
このように一属性が複数の解に影響するような組み合わせ方を行なった場合，解の多数決を取ることは適当ではないと考えた．
そこで本論文では，各解答に対して信頼性を計算し，それの比較によって行なう選好基準を提案する．
この際，解の信頼性に相当する値として，以下に述べる理由により，決定木学習時に解と同一の終端節点に辿り着いた事例数を用い，これが最多である解を選択する．
いま，決定木のある属性において属性照合を誤ったと仮定する．
この場合，本来到達すべき終端節点には到達せずに別の節点に到達する．
この際，どの節点に到達したかは，これ以上の情報がない場合，一般にすべての節点が同一の確率である．
ここで，誤って到達した節点の学習時の事例数を予想すると，全節点への到達可能性が同等なのだから，終端節点の学習事例数に関して最も頻出する事例数が最も可能性が高い．
例えば，学習事例数[MATH]の終端節点が最も多い場合には，誤って到達した節点の学習時事例数は[MATH]の可能性が最も高いと予想するのが自然である．
それでは実際にどのような事例数の終端節点が多いのかを調査したのが図[REF_fig:freq]である．
図[REF_fig:freq]では，次節で述べる3種類の決定木それぞれについて，終端節点の事例数別に統計をとったものである．
この図から明らかなように，どの決定木においても，学習時の事例数が1の節点が最も多く，その後漸減の傾向にある．
すなわちこれらの決定木に関しては，学習時の事例数が少ない節点ほど誤って辿り着く確率が高い．
次に，図[REF_fig:mdt-model]に示すように，同一の学習事例集合に対して属性集合を([MATH], [MATH], [MATH], [MATH])の[MATH]種類に変化させ，複数の決定木を作成することを考える．
図[REF_fig:mdt-model]において，属性集合[MATH]による補完結果候補[MATH]よりも，属性集合[MATH]による補完結果候補[MATH]のほうが解の信頼性が高いと考えるのは自然である．
なぜならば，これまでの議論により，属性照合を誤って解候補[MATH]に到達する可能性よりも属性照合を誤って解候補[MATH]に到達する可能性のほうが高いからである．
入力に誤りがあるために本来の属性の照合ができなかった場合には，学習事例数のより少ない節点に到達する確率がより高いため，例のように学習事例数の多い節点に到達した場合には，確率的に解の信頼性が高いと見做すことができる．
以上の理由により，我々は決定木学習時の終端節点の事例数によって解の選好を行なう．
これにより，各決定木が出力した解答候補のうち，決定木が出力した終端節点の学習時事例数が最大の解答をMDTにおける解答とする．
例えば図[REF_fig:mdt-model]では属性集合[MATH]における解答の学習時終端節点事例数が最も多いので，[MATH]をMDTとしての解答とする．
本手法の挙動を定性的に考察する．
本論文の提案する手法によって入力に若干の誤りがあり，誤り箇所を特定できない場合に対して本手法は有効に機能することが予想できる．
ただし選好基準から明らかなように，本手法は学習時において事例が集中した「大きな」節点に対してのみ有効に機能する．
あるいはある節点に極端に事例が集中するような場合に，本論文の選好がより有効に機能する．
この一方，学習時に事例数が1であった節点は，属性に誤りがあった場合に本手法では本来の正しい解を出力することが期待できない．
すなわち，本手法はすべての事例に対して頑健になるわけではないが，事例が集中した節点を対象にしていることから多くの事例に対して頑健になることが予想できる．
以上の議論の定量的な検証は[REF_節:定量議論]節において行なう．
前節の評価実験で，誤りを含む入力に対して[REF_節:属性]節の属性集合からなるMDTモデルが主語補完問題に対し有効に機能することを確認した．
しかし，以上の結果はいかなる問題に対してもMDTモデルが有効なのか，あるいは本論文における属性集合の組み合わせ方が偶然有効に機能したのかは明確でない．
そこで，MDTモデルの問題依存性，並びに属性集合の組み合わせ方がモデルの精度にどのような影響を与えるのか，の2点を検証，議論するため，人工的な問題を設定してMDTモデルのシミュレーションを行なった[CITE]．
本節ではこの内容及び結果について述べる．
問題は以下のように設定した．
まず，問題の全属性数は10，分類すべきクラス数は10とした．
属性値は二値としたため作成される決定木は二分木であり，枝刈りは行なわない．
学習事例は，以下の2種類の方法で順に作成した．
まず1事例を無作為に作成する．
ただし既作成の事例と矛盾しないようにする．
すなわち各属性の値はすべて同一であるがクラスが異なる事例は新規事例に追加しない．
この事例と属性値及びクラスが全く同一のコピー事例を(1〜100)事例の範囲で作成する．
(1〜100)のうちいくつ重複させるかは無作為に決定する．
以上の処理を，[MATH]全体で1000事例を越えるまで繰り返す．
無作為に1事例を作成する．
ただし，作成される事例は[MATH]と[MATH]内のどの事例とも矛盾しない．
以上の処理を1000回繰り返す．
以上のような方法で，本シミュレーションでは[MATH]が1084事例，[MATH]が1000事例の合計([MATH]) 2084事例を作成した．
各決定木は，事例集合[MATH]を用いて作成する．
次に，使用したMDTについて述べる．
MDTは以下のようにSDTを組み合わせて構成した．
すなわち，使用属性数が[MATH]以上の全属性組み合わせについてSDTをすべて作成し，これを組み合わることで構成した．
以下ではこれをMDT([MATH])と記述する．
例えば，MDT(9)は9属性の全組み合わせ(10種類)と10属性の全組み合わせ(1種類)に対してそれぞれ作成した11個のSDTを組み合わせたモデルである．
同様にMDT(8)は56個，MDT(7)は176個のSDTからなり，最多のMDT(1)は1023個のSDTから構成される．
実験は以下のように行なった．
学習時に使用した事例集合[MATH]に対し，各事例について1ヶ所(後述の[REF_節:誤り数との関係]節では2または3ヶ所，{}[REF_節:正解入力]節では0ヶ所)の属性を無作為に選び，その属性値に誤りを起こさせたものを入力とした．
すなわち，今回作成する二分木は属性が2値であるため，無作為に選ばれた属性の属性値を反転させたものを入力とした．
実験は，10属性以下で構成される全組み合わせのSDT (1023個)に対して精度を測定し，これをもとに10種類のMDT([MATH]) ([MATH])の精度を計算した．
また比較対象として，多数決基準，すなわち[MATH]属性以上のすべてのSDTが返す解のうち最多のものを解とする選考基準での精度も測定した．
ある乱数におけるシミュレーションの結果を図[REF_図:1誤り]に示す．
異なる乱数でシミュレーションを行なった場合も全く同様の傾向が見られた．
図で，実線はMDT，点線は多数決基準の精度を示し，SDT単独の精度は点で表した．
任意の1属性に誤りがある入力に対し，使用可能な全10属性からなるSDTは10.4%，9属性以上のSDTによる多数決基準は16.0%の正解率であるのに対し，MDT(9)は57.6%の正解率を得ることができ，MDTの優位性を確認した．
またMDT(9)は9属性以上で可能な全組み合わせに対して作成したSDTを用いていることより，どうやって不要な属性を減らすか，あるいはどのような組み合わせが適当かを考慮する必要がないため，MDTモデルはこの点において，SDTモデルで使用属性を吟味して精度向上を目指すアプローチよりも優位である．
ただし，図が示す通り，MDTモデルは少数属性のSDTを追加していくに従い精度が低下する．
逆に多数決基準は精度が向上し7属性以下の決定木を使用した場合には両者の精度が逆転した．
このことから，MDTはどのような属性数の決定木を加えても精度向上するわけではないことがわかる．
最高の精度は5属性以上による多数決基準によって得られた(58.7%)が，現実的には少数属性の決定木を大量に作成して多数決を取ることは計算量の面で有利ではないため，1誤りの場合はMDT(9)が最も実用的なモデルであると言える．
図において各SDTがどのような精度であるかを観察すると，属性数が減少するに伴い，平均的に徐々に精度は向上している．
一方，MDT([MATH])が選択するSDTを観察すると，SDTの中で最少属性のもののうちから選択されている場合が圧倒的に多い．
例えば，MDT(6)は6属性のSDTのうちの一つの解を選択している場合が圧倒的に多い．
一般的に，終端節点の学習事例数は，多数属性で作成した決定木のそれよりも少数属性のほうが平均的に多いためこのように少数属性のSDTが選択されやすくなるのであろうが，相対的に精度の高い少数属性のSDTを選択してもMDTの精度が低下する理由は不明である．
これは今後の課題としたい．
[REF_節:定性議論]節で議論したように，MDTモデルは事例が集中した節点を得るのに用いた属性に誤りがある場合に有効に機能すると予想される．
ここではこれを検証する．
本シミュレーションでは，終端節点に集中する事例[MATH]とそれ以外の事例[MATH]の2種類の方法で事例集合[MATH]を作成した．
事例集合[MATH]に誤りを含めた場合に，図[REF_図:1誤り]に示すようにMDT(9)は全体で57.6%の精度が得られたが，これを事例集合別に分類して集計すると，[MATH]は96.5%，[MATH]は15.5%の精度であり，極端に精度が異なる．
この結果は，頻出する現象に対しては入力に誤りがあってもかなり高い精度で正解を得ることができるのに対し，稀に出現する現象は正解を得ることが期待できないことを示し，[REF_節:定性議論]節で行なった議論が正しいことを確認した．
以上の結果から本手法が有効に機能する状況が推測できる．
すなわち，決定木において一部の終端節点に事例が集中するような構造を持つ場合ほど，MDTは誤りを含む入力に対して頑健であることが予想される．
図[REF_図:1誤り]においてMDT(9)の精度が最も高いのは，各事例に対して1個の属性値に誤りを起こしているためである可能性がある．
ではもし誤りが1ではなく，2もしくは3である場合，MDTはどのような傾向を示すであろうか．
これを示したのが図[REF_図:2誤り](2誤りの場合)および図[REF_図:3誤り] (3誤りの場合)である．
このシミュレーションにおいては，誤り数以外の条件は全く同じであり，誤りを含める対象の事例集合[MATH]も，図[REF_図:1誤り]と全く同一のものを使用した．
図が示すように，各属性に無作為に2誤りを与えた場合はMDT(8)が，3誤りの場合はMDT(7)が最も高い精度を示していることがわかる．
すなわち，誤りの数と用意するSDTとの間には相関関係がありそうである．
すなわち，図[REF_図:1誤り]，図[REF_図:2誤り]，図[REF_図:3誤り]から類推すると，属性数が[MATH]で誤りが高々[MATH]ならば属性数が([MATH])以上のすべてのSDTでMDTを構成するのが最善であろう．
最後に，誤りがない場合にMDTがどのような挙動を示すのかを検証する．
図[REF_図:正解入力]に，事例集合[MATH]に誤りを与えずに各モデルに入力した場合，すなわち学習事例と入力が全く同一の場合のテスト(closed test)を行なった結果を示す．
この図から明らかなように，一般に属性数の減少に伴い精度は低下していくが，本提案モデルの精度の低下が最も激しい．
ただし，正解入力は誤り0の入力であるので，これを前節で議論した誤り数と使用属性数の関係にあてはめると，全属性数で決定木を作成するのが最も適切であろうという予想が得られ，シミュレーション結果と一致する．
本シミュレーションでは矛盾のないように属性を作成しているので，このような状況においては全属性による決定木が一つあれば十分で，入力に誤りのない場合は複数決定木モデルを使用する必要がない．
ただし，主語補完問題のようにこのような状況が成立しない場合には，実験結果が示すように誤りが0であっても複数決定木モデルが有効に機能する可能性がある．
これがどのような場合に有効なのかはシミュレーションでも究明することができなかった．
今後の課題としたい．
