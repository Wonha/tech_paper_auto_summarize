実験
\label{sec:evaluation}

\subsection{比較したシステム}

本節では，大規模な文字列データセットに対して，種々の類似文字列検索アルゴリズムの性能を比較し，提案手法の有用性を示す．
実験に用いたシステムは，以下の通りである．
なお，先行研究の詳細については，\ref{sec:related-work}節を参照されたい．
\begin{itemize}
	\item {\bf 提案手法}：$\tau$オーバーラップ問題をCPMerge（図\ref{alg:t-overlap-cpmerge}）で解くもの
	\item {\bf 提案手法-opt}: CPMergeを図\ref{alg:t-overlap-cpmerge-post}の擬似コードで高速化したもの
	\item {\bf 総当たり法}：検索クエリが与えられる毎に，データベース内の全ての文字列と類似度を計算し，閾値以上の文字列を見つけ出す方法
	\item {\bf AllScan}: $\tau$オーバーラップ問題をAllScanアルゴリズム（図\ref{alg:t-overlap-naive}）で解くもの
	\item {\bf Signature}: $\tau$オーバーラップ問題をCPMerge（図\ref{alg:t-overlap-cpmerge}）で解くが，解候補の枝刈りを行わないもの（図\ref{alg:t-overlap-cpmerge}の17〜18行目を削除）
	\item {\bf SkipMerge}: $\tau$オーバーラップ問題をSkipMergeアルゴリズム~\cite{Li:08}で解く
	\item {\bf DivideSkip}: $\tau$オーバーラップ問題をDivideSkipアルゴリズム~\cite{Li:08}で解く\footnote{今回の実験では，パラメータ$\mu \in \{0.01, 0.02, 0.04, 0.1, 0.2, 0.4, 1, 2, 4, 10, 20, 40, 100\}$を試し，最も検索レスポンスが速かった$\mu = 40$を採用した．}
	\item {\bf MergeOpt}: $\tau$オーバーラップ問題をMergeOptアルゴリズム~\cite{Sarawagi:04}で解く．ただし，MergeOptは重み付きの類似度を用いた類似文字列検索アルゴリズムであり，本論文と実験設定を揃えるため，次のような修正を行った．(1) 文字列の特徴の重みはすべて等しいこととする．(2) 提案手法と同様に，転置リストはサイズの昇順でソートする．(3) 転置リストを候補生成用$S$と検証用$L$に分割するときは，提案手法と同様に$S$をシグニチャの転置リストとする．
	\item {\bf Locality Sensitive Hashing (LSH)}~\cite{Andoni:08,Ravichandran:06}:
	文字列のtri-gramを特徴とし，64ビットの局所鋭敏ハッシュ (LSH) 値を計算する関数を$h(x)$とする．2 つのハッシュ値$v_1$と$v_2$の，ビット単位でのハミング距離（ビットの異なり数）を，${\rm hdist}(v_1, v_2)$と書く．
	このシステムは，クエリ文字列$x$が与えられると，そのハッシュ値$h(x)$とのハミング距離が$\delta$以内の文字列を$V$から探し，解候補となる文字列集合$C$ ($|C| \ll |V|$) を求める．
	\begin{equation}
		C = \{y \in V \bigm| {\rm hdist}\left(h(x), h(y)\right) \leq \delta \} \label{equ:LSH-candidate}
	\end{equation}
	解候補のそれぞれの文字列$y \in C$に対して，実際に$x$との類似度を計算し，閾値以上の文字列を解とする．

	式\ref{equ:LSH-candidate}の正確な解を求めることは難しいため，Ravichandranら~\cite{Ravichandran:06}の手順を参考に，近似解を求める．
	基本的なアイディアは，データベース中の文字列のハッシュ値のビット列を並び替え，検索クエリの（ビット列を並び替えられた）ハッシュ値の近傍を探すという試行を繰り返せば，式\ref{equ:LSH-candidate}の近似解が求まるというものである．
	ある文字列のハッシュ値$h(y)$のビット列を，置換$\sigma_p$で並び替えたものを$\sigma_p(h(y))$で表し，そのような置換をランダムに$P$種類用意し，$\Sigma = \{\sigma_p\}$とする．
	置換$\sigma_p$を用いて，データベースに含まれている全ての文字列$y \in V$のハッシュ値のビット列を並び替え，辞書順にソートしたハッシュ値リストを$a_p$とする．
	置換を$P$種類別々に適用すると，ハッシュ値のリストも$P$種類作られる．

	すると，$a_p$の中でクエリの（置換が適用された）ハッシュ値$\sigma_p(h(x))$に近い要素を二分探索で求め，その近傍の$W$個の文字列の中でハミング距離が$\delta$以内のものを見つけ出すことで，式\ref{equ:LSH-candidate}を近似的に求めることができる．
	この処理を，準備しておいた$P$個の置換と，対応する$P$個のハッシュ値リストに対して行い，式\ref{equ:LSH-candidate}の近似解の精度を向上させる．
	
	LSHは，類似文字列検索の解の近似解を高速に求める手法であるため，検索漏れ（類似文字列が検索されない状況）が生じることがある．
	LSHでは，ハミング距離の閾値 ($\delta$)，並び替えハッシュ値リストの数 ($P$)，近傍探索の幅 ($W$) の 3 つのパラメータで検索速度と再現率のトレードオフを調整する．
	今回の実験では，実験的に$\delta = 24$，$P = 24$と決定し\footnote{パラメータ$P$は，並び替えたハッシュ値リストが全てメモリ上に載るようにするため，$24$と決定した．パラメータ$\delta$として，$\delta \in \{8, 16, 24\}$を試し，検索速度と再現率のバランスが良かった$24$を採用した．}，$W$を$W \in \{16, 32, 64\}$と変えながら性能を測定した．
\end{itemize}

総当たり法とLSH以外のすべてのシステムは，図\ref{alg:approximate-string-matching}の実装を共有しており，$\tau$オーバーラップ問題の解法が性能差となって現れる．
ハッシュ・データベースとしては，
CDB++\footnote{http://www.chokkan.org/software/cdbpp/}
を用い，提案手法をC++で実装したライブラリとして，
SimString\footnote{http://www.chokkan.org/software/simstring/}
を公開している．
すべての実験は，Intel Xeon 5140 CPU (2.33~GHz) と8~GBの主記憶を搭載したDebian GNU/Linux 4.0のアプリケーション・サーバー上で行った．
転置インデックスはファイル上に構築し，実験時には必要に応じて主記憶に読み込んでいる．



\subsection{実験に用いたデータセット}

実験に用いたデータセットは，以下の 3 つである．
\begin{itemize}
	\item {\bf IMDB}:
	IMDBデータベース\footnote{ftp://ftp.fu-berlin.de/misc/movies/database/}のファイル\texttt{actors.list.gz}から抜き出した
\pagebreak
	すべての俳優名（1,098,022文字列，18~MB）．
	1 つの文字列当たりの文字tri-gramの特徴数は17.2，
	データセット全体における文字tri-gramの種類数は42,180である．
	SimString
	は，このデータセットから83~MBのインデックスファイル群を，56.6秒で構築した．
	\item {\bf 日本語ユニグラム}：Web日本語Nグラム第1版\footnote{http://www.gsk.or.jp/catalog/GSK2007-C/catalog.html}に収録されている単語ユニグラム\linebreak
	（2,565,424文字列，49~MB）．
	1 つの文字列当たりの文字tri-gramの特徴数は20.8，
	データセット全体における文字tri-gramの種類数は137,675である\footnote{実験では日本語の文字列をUTF-8で表現し，UTF-8の 1 バイトを 1 文字とみなしてtri-gramを作っている．}．
	SimString
は，このデータセットから220~Mのインデックスファイル群を，134.0秒で構築した．
	\item {\bf UMLS}:
	Unified Medical Language System (UMLS)\footnote{http://www.nlm.nih.gov/research/umls/} に収録されている生命医学分野の英語の概念や記述（5,216,323文字列，212~MB）．
	評価に用いる文字列は，UMLS Release 2009AA (April 6, 2009) の\texttt{MRCONSO.RRF.aa.gz}及び\texttt{MRCONSO.RRF.ab.gz}というファイルに含まれる全ての英語の概念名である．
	一つの文字列当たりの文字tri-gramの特徴数は43.6，
	データセット全体における文字tri-gramの種類数は171,596である．
	SimString
	は，このデータセットから1.1~GBのインデックスファイル群を，1216.8秒で構築した．
\end{itemize}

それぞれのデータセットにおいて，1,000個の文字列をランダムに選び，テスト用のクエリ文字列とした．
完全には一致しない文字列で検索する状況をシミュレートするため，1,000個の文字列のうち，1/3の文字列はそのまま，1/3の文字列には 1 文字をランダムな文字に置換，残りの1/3の文字列には 2 文字をランダムな文字に置換している．



\subsection{1 クエリあたりの平均レスポンス時間}

\begin{figure}[b]
\vspace{-1\baselineskip}
    \begin{center}
\includegraphics{18-2ia2f6.eps}
    \end{center}
    \caption{1 クエリ当たりの平均レスポンス時間（横軸はデータセットのサイズ）}
\label{fig:query-time}
\end{figure}

図\ref{fig:query-time}に，各データセットでコサイン係数が0.7以上の類似文字列を検索するときの，1 クエリあたりの平均レスポンス時間を示した．
グラフの横軸は，データベースに登録する文字列の数 ($|V|$) で，データセット全体の10\%から100\%まで変化させた．
また，表\ref{tbl:response}に，各データセットをすべて (100\%) 利用したときのシステム性能として，検索の再現率 (Recall)，1 クエリあたりの平均レスポンス時間 (Mean)，1 クエリに対する最遅レスポンス時間 (Max) をまとめた．
実験したシステムの中ではLSH ($W=16$) が最も高速に文字列を検索でき，データサイズが100\%の時の平均レスポンス時間は，0.53~ms (IMDB)，1.61~ms（日本語ユニグラム），2.11~ms (UMLS) であった．
また，平均レスポンス時間に対して最遅レスポンス時間がどのくらい遅くなるのかに着目すると，LSHは入力クエリの影響を受けにくいことが分かる\footnote{LSH (W=16) に関しては，最遅レスポンス時間が平均レスポンス時間と比べてかなり遅くなっているが，これは 1 クエリ当たりの処理時間が非常に短いため，実行時間の測定値の誤差が出やすくなるためと考えられる．}．
これは，LSHでは探索範囲が$\delta$，$P$，$W$などのパラメータで一定に保たれるからである．
一方，LSH以外の手法（総当たり法を除く）は，クエリ文字列に応じて$|Y|$の探索範囲が変化し，さらに，クエリ文字列に応じて転置リストのサイズが異なる（つまり，処理すべきSIDの数が変化する）ため，レスポンス時間のばらつきが大きくなる．


\begin{table}[b]
\hangcaption{各データセットを100\%利用したときのシステムの性能（Recall: 再現率，Mean: 平均レスポンス時間[ms/query]，Max: 最遅レスポンス時間[ms/query]）．総当たり法に対しては，平均レスポンス時間のみを掲載した．}
\label{tbl:response}
\input{02table05.txt}
\end{table}

しかし，LSH ($W=16$) は検索漏れが非常に多い．
総当たり法で検索される類似文字列を正解とみなし，そのどのくらいをカバーできているか（再現率）を測定すると，LSH ($W=16$) の再現率は，15.4\% (IMDB)，7.5\%（日本語ユニグラム），4.0\% (UMLS) であった．
これは，式\ref{equ:LSH-candidate}の近似解の精度が悪いためである．
LSHの再現率を改善するには，周辺探索の幅 ($W$) を大きくすればよいが，レスポンス時間を犠牲にしなければならない．
例えば，LSH ($W=64$) では，再現率は25.8\% (IMDB)，15.4\%（日本語ユニグラム），11.1\% (UMLS) に改善されるが，レスポンス時間は29.72~ms (IMDB9，38.07~ms（日本語ユニグラム），79.73~ms (UMLS) まで遅くなる．
これに対し，提案手法では調整するパラメータもなく，正確な解（100\%の再現率）が保証されている．
したがって，類似文字列検索の再現率を重視する場合は，提案手法の方が優れている．

提案手法-optは，正確な解が得られるシステムの中で最もレスポンスが速く，データサイズが100\%の時の平均レスポンス時間は，1.07~ms (IMDB)，26.99~ms（日本語ユニグラム），20.37~ms (UMLS) であった．
提案手法と提案手法-optを比較すると，図\ref{alg:t-overlap-cpmerge-post}の実装上の工夫を利用することで，レスポンス時間が1.7〜2.1倍高速になった．
そこで，以降の説明では単に「提案手法」というと，図\ref{alg:t-overlap-cpmerge-post}の工夫を適用した「提案手法-opt」を指すこととする．

総当たり法のレスポンス時間は図\ref{fig:query-time}にプロットできないくらい遅く，32.8~s (IMDB)，92.7~s （日本語ユニグラム），416.3~s (UMLS) であった．
提案手法は，総当たり法よりも3,400〜20,000倍高速に動作し，類似文字列検索を実用的な速度で実現している．
提案手法は，AllScanアルゴリズムよりもかなり高速に動作し，検索速度は65.3倍 (IMDB)，24.8倍（日本語ユニグラム），19.2倍 (UMLS) 高速であった．
提案手法とSignatureシステムを比較すると，提案手法の方がSignatureよりも115.9倍 (IMDB)，237.0倍（日本語ユニグラム），2323倍 (UMLS) 高速であった．
Signatureシステムと提案手法の差は，解候補の枝刈り（図\ref{alg:t-overlap-cpmerge}の17〜18行目）のみであるが，この処理を省くと大幅にレスポンスが低下し，AllScanアルゴリズムよりも遅くなる．
これらのシステムの比較から，$\tau$オーバーラップ問題を解く際に解候補を絞り込んでおくこと，二分探索の回数を減らすために解候補の枝刈りをすることが，非常に重要であることが伺える．
先行研究であるMergeOpt，SkipMerge，DivideSkipは，各転置リストの先頭（SIDの小さい方）からSIDを優先順位付きキューに挿入するアルゴリズムを採用しており，$\tau$オーバーラップ問題の解き方が提案手法と全く異なる．
このため，レスポンス時間の差の要因を分析することは難しいが，提案手法はMergeOptよりも6.47〜9.68倍，SkipMergeよりも5.14〜6.15倍，DivideSkipよりも11.1〜24.1倍高速であった．

IMDBデータセットにおいて，提案手法が検索に最も時間を要したクエリ文字列は，``Morales, Michael (VIII)''で，11.8~ms を要した．以下，``Reiner, Robert (I)'' (9.2~ms)，``Dore, Michael (I)'' (9.2~ms)，``Dow, Christopher (III)'' (8.6~ms)，``Cain, William (II)'' (8.0~ms) と続く．
これらのクエリが遅いのは，データセット中に似ている文字列（例えば``Morales, Michael (III)''や``Morales, Rafael (VIII)''など）が多く，$\tau$-オーバーラップ問題を解くときに多くの解候補を抱えるためである．
例えば，``Morales, Michael (VIII)''というクエリに対し，データセット中の72,375個の文字列が解候補となり，最終的に解になったのは42文字列であった．
一方，提案手法とSkipMergeアルゴリズムのレスポンス時間の差を計算したとき，提案手法の改善が最も顕著に表れたクエリの上位 3 件は，``Morales, Michael (VIII)'' ($-44.4$~ms)，``Pittman, Robert (III)'' ($-39.0$~ms)，``Richards, Jon (VII)'' ($-36.6$~ms) であった．
ここでも，``Morales, Michael (VIII)''というクエリが登場し，その他の 2 つのクエリも解候補が非常に多い（40,000個以上）ことから，データセット中にクエリ文字列と似ている文字列が多く存在するとき，提案手法の優位性が際立つと考えられる．

逆に，提案手法がSkipMergeアルゴリズムよりも遅くなったクエリは無かったものの，改善が全く見られなかったクエリとして，``Zhao,lSh@nqiu'' ($\pm 0$~ms)，``Peral9a,dStacy'' ($\pm 0$~ms)，``Sen]g[renqing'' ($\pm 0$~ms) などが見つかった．
これらのクエリは，元々``Zhao, Shenqiu'', ``Peralta, Stacy'', ``Senggerenqing'' の文字列にノイズが加わったものと考えられるが，転置リストに含まれる文字列の種類数が非常に少なく，それぞれ3個，108個，18個であった．
したがって，転置リストにおいて処理すべき文字列の数が圧倒的に少ないため，アルゴリズム間の差が出にくくなったと考えられる．
このような場合でも，提案手法はSkipMergeアルゴリズムよりも遅くならず，同程度のレスポンス時間を出していた．

\begin{figure}[b]
    \begin{center}
\includegraphics{18-2ia2f7.eps}
    \end{center}
    \caption{1 クエリ当たりの平均レスポンス時間（横軸は類似度閾値）}
\label{fig:query-time-sim}
\end{figure}

図\ref{fig:query-time-sim}は，異なる類似度関数と閾値を用いたときの，提案手法のレスポンス時間を示している．
類似度の閾値を低く設定すると，類似文字列検索の解となる文字列の数$|\mathcal{Y}|$が大きくなるので，提案手法のレスポンス時間が遅くなる．
類似度関数の良さはタスク依存で決めることであるが，同じ閾値を用いた場合はジャッカード係数が最も速く，ダイス係数とコサイン係数が同程度，オーバーラップ係数が最も遅いという傾向が見られる．
この傾向は，類似度関数の性質（どの程度文字列を類似していると見なすか）によって，類似文字列検索の解の数が異なることから説明できる．
例えば，日本語ユニグラムコーパスにおいて閾値0.7で類似文字列検索を行った場合，ジャッカード係数，ダイス係数，コサイン係数，オーバーラップ係数が返す解文字列数の平均は，それぞれ，1.2個，14.8個，16.2個，1036.4個であった．
したがって，類似文字列検索では，最も多い解を返すオーバーラップ係数が遅く，最も少ない解を返すジャッカード係数が速くなる．
また，表\ref{tbl:conditions}の必要条件から求まる$|Y|$の探索範囲が，ジャッカード係数では最も狭く\footnote{$0 \leq \alpha \leq 1$であるから，$|Y|$の探索範囲の下限に関して，$\alpha^2|X| \leq \alpha |X|$，$\frac{\alpha}{2 - \alpha}|X| \leq \alpha |X|$が成立する．$|Y|$の探索範囲の上限に関しても，$|X|/\alpha \leq |X|/\alpha^2$，$|X|/\alpha \leq \frac{2 - \alpha}{\alpha}|X|$であり，ダイス係数やコサイン係数よりもジャッカード係数の方が，同じ閾値$\alpha$を用いたとき，$|Y|$の探索範囲が狭くなる．}，オーバーラップ係数では$|Y|$の探索範囲に制約が付かないことから，類似度関数による検索速度の違いを推察できる．


\subsection{提案手法の動作統計}
\label{sect:cpmerge-stat}

\begin{table}[b]
\caption{提案手法が各データセットで類似文字列検索を行うときの動作統計}
\label{tbl:stats}
\input{02table06.txt}
\end{table}

表\ref{tbl:stats}は，提案手法が各データセットにおいて類似文字列検索を行うときの，様々な統計情報をまとめたものである（類似度にコサイン係数を用い，閾値は0.7とした）．
この表の見方をIMDBデータセットで説明すると，提案手法はサイズが8.74から34.06までの文字列を検索対象とし，1 クエリあたり4.63文字列を解として返した．
提案手法の候補生成フェーズでは，平均4.6個の転置リストに含まれる279.7個のSIDを走査し，232.5個の解候補を得た．
提案手法の候補検証フェーズでは，平均4.3個の転置リストに対して二分探索を行い，7,561.8個のSIDが二分探索の対象となった．
これに対し，AllScanアルゴリズムは，17.7個の転置リストに含まれる16,155.1個のSIDを走査しなければならず，平均4.63個の解を求めるのに，9,788.7個の文字列を候補として考慮する必要があった．

この表は，提案手法の 3 つの特筆すべき特徴を表している．
\begin{itemize}
\item 提案手法はAllScanアルゴリズムと比較すると，走査するSIDの数を格段に減らしている．
例えば，IMDBデータセットにおいて解候補を得るために，AllScanアルゴリズムは16,155.1個のSIDを走査する必要があったが，提案手法は279.7個のSIDを走査するだけで済んだ．
別の言い方をすれば，提案手法はAllScanアルゴリズムと比較すると，1.1\%〜3.5\%の文字列を走査すれば，解候補が得られることを示している．
\item 提案手法はAllScanアルゴリズムと比較すると，解候補の数を9,788.7から232.5に減らしている．
すなわち，解候補の数は提案手法により1.2\%〜6.6\%まで削減された．
\item 提案手法はAllScanアルゴリズムと比較すると，主記憶上に展開すべき転置リストの数を減らすことができる．
提案手法は，$\tau$オーバーラップ問題を解くために，8.9 (IMDB)，18.8（日本語ユニグラム），31.7 (UMLS) 個の転置リストを使っている\footnote{これらの値は，4.6 + 4.3，7.0 + 11.8，14.3 + 17.4 として計算される．}．
AllScanアルゴリズムが用いる転置リストの数と比べると，提案手法は50.3\% (IMDB)，53.6\%（日本語ユニグラム），51.9\% (UMLS) の転置リストしかアクセスしないことを意味する．
これは，図\ref{alg:t-overlap-cpmerge}のアルゴリズムで，$k \approx 0.5 |X|$付近で解候補の検証・枝刈りが完了し，解の候補が0になっているからである．
提案手法では，$k$が大きくなるにつれ，転置リストのサイズが大きくなるが，サイズの大きい転置リストをメモリ上に展開することなく，$\tau$オーバーラップ問題を解けるのは，提案手法の大きなアドバンテージである．
\end{itemize}



