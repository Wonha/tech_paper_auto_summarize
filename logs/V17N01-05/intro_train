1 日本語 と 英語 の よう に 言語構造 が 著しく 異なり 語順変化 が 大きな 言語対 において 対訳文 を アライメント する 際 に 重要 な こと は 二つ ある 
0 一つ は 構文解析 や 依存構造解析 など の 言語情報 を アライメント に 組み込み 語順変化 を 克服 する こと で あり もう 一つ は アライメント の 手法 が 1対1 の 単語対応 だけ で なく 1対多 や 多 対多 など の 句対応 を 生成 できる こと で ある 
0 これ は 一方 の 言語 で は 1語 で 表現 さ れ て いる もの が 他方 で は 2語以上 で 表現 さ れる こと が 少なく ない から で ある 
0 しかしながら 既存 の アライメント手法 の 多く は 文 を 単純 に 単語列 として しか 扱っ て おら ず CITE句対応 は 単語対応 を 行っ た 後 に ヒューリスティック な ルール により 生成 する といった 方法 を 取っ て いる 
0 QuirkらCITE や CowanらCITE は アライメント に 構造情報 を 統合 しよ う と し た が 前述 の 単語列アライメント を 行っ た 後 に 用いる に 留まっ て いる 
0 単語列アライメント手法そのもの の 精度 が 高く ない ため この よう な 方法 で は 十分 な 精度 で アライメント が 行える と は 言い 難い 
0 一方 で アライメント の 最初 から 構造情報 を 利用 する 手法 も いくつ か 提案 さ れ て いる 
0 WatanabeらCITE や Menezes と RichardsonCITE は 構文解析結果 を 利用 し た アライメント手法 を 提案 し て いる が 対応 の 曖昧性解消 の 際 に ヒューリスティック な ルール を 用い て いる 
0 Yamada と KnightCITE や GildeaCITE は 木構造 を 利用 し た 確率的 な アライメント手法 を 提案 し て いる 
0 これら の 手法 は 一方 の 文 の 木構造 に対して 葉 の 並べ 替え 部分木 の 挿入削除 といった 操作 を 行っ て 他方 の 文構造 を 再現 する もの で ある が 構文情報 の 利用 が 逆 に 強い 制約 と なっ て しまい 文構造 の 再現 が 難しい こと が 問題 と なっ て いる 
0 Yamada と Knight は いったん 木構造 を 崩す こと によって Gildea は 部分木 を 複製 する こと によって この 問題 に 対処 し て いる 
0 我々 は この よう な 木構造 に対する 操作 は 不要 で あり 依存構造木中 の 部分木 を そのまま アライメント すれ ば よい と 考え た 
0 また Cherry と LinCITE は 原 言語側 の 依存構造木 を 利用 し た 識別モデル を 提案 し て いる 
0 しかしながら この 手法 は アライメント単位 が 単語 のみ で あり 一対一対応 しか 扱え ない という 欠点 が ある 
0 phrasebasedSMT で いう ところ の 句 は ただ の 単語列 に 過ぎ ない が Nakazawa と KurohashiCITE は 言語的 な 句 を アライメント の 最小単位 と し 句 の 依存関係 に 着目 し た モデル を 提案 し て いる が そこ で は 内容語 は 内容語 のみ 機能語 は 機能語 のみ に しか 対応 し ない という 制約 が あり また 複数 の 機能語 を ひと まとまり に 扱っ て いる という 問題 も あり これら が しばしば 誤っ た アライメント を 生成 し て いる 
1 本 論文 で は Nakazawa と Kurohashi の 手法 の 問題点 を 改善 し 単語 や 句 の 依存関係 に 注目 し た 句アライメントモデル を 提案 する 
0 提案手法 の ポイント は 以下 の 3 つ で ある 
0 両 言語 とも 依存構造解析 し アライメント の 最初 から 言語 の 構造情報 を 利用 する 
0 アライメント の 最小単位 は 単語 だ が モデル学習時 に 句 と なる べき 部分 を 自動的 に 推定 し 句アライメント を 行う 
0 各 方向原言語MATH目的言語 と 目的言語MATH 原 言語 の 生成モデル を 二つ 同時に 利用 する こと により より 高 精度 な アライメント を 行う 
0 本 モデル は 二つ の 依存構造木 において 一方 の 依存構造木 で 直接 の 親子関係 に ある 一組 の 対応 について 他方 の それぞれ の 対応先 の 依存関係 を モデル化 し て おり 単語列アライメント で 扱う の が 困難 な 距離 の 大きな 語順変化 に も 対応 する こと が できる 
1 言い替えれ ば 本 モデル は 木構造上 で の reorderingモデル という こと が できる 
1 また 本 モデル は ヒューリスティック な ルール を 用い ず に 句 と なる べき 部分 を 自動的 に 推定 する こと が できる 
0 ここ で いう 句 と は 必ずしも 言語的 な 句 で ある 必要 は なく 任意 の 単語 の まとまり で ある 
0 ただし PhrasebasedSMT における 句 の 定義 と の 重要 な 違い は 我々 は 木構造 を 扱っ て おり 単語列 として は 連続 で なく て も 木構造上 で 連続 なら ば 句 として 扱っ て いる という 点 で ある 
0 また 我々 の モデル は IBMモデル の よう な 各 方向 の 生成モデル を 両方向分 同時に 用い て アライメント を 行う 
0 これ は アライメント の 良 さ を 両方向 から 判断 する 方 が 自然 で あり LiangらCITE による 報告 に も ある よう に そうした 方 が 精度 よい アライメント が 行える から で ある 
0 ただし Liangら の 手法 が IBMモデル と 同様 に 単語列 を 扱う もの で ある の に対し 提案手法 は 木構造 を 扱っ て いる という 重要 な 違い が ある 
0 また Liangら の 手法 で は 部分的 に 双方向 の モデル を 結合 する に 留まっ て おり アライメント の 結果 として は 各 方向それぞれ独立 に 生成 さ れる が 我々 の 方法 で は ただ 一つ の アライメント を 生成 する という 違い も ある 
0 最近 の 報告 で は 生成モデル より も 識別モデル を 用い た 方 が より 高 精度 な アライメント が 行える という 報告 が なさ れ て いる が 学習用 に アライメント の 正解セット を 用意 する コスト が かかっ て しまう 
0 そこで 我々 は 教師 なし で モデル学習 が 行える 生成モデル を 用い た 
0 モデル は 2 つ の ステップ を 経 て 学習 さ れる 
0 Step1 で は 単語翻訳確率 を 学習 し Step2 で は 句翻訳確率 と 依存関係確率 が 推定 さ れる 
0 さらに Step2 で は 単語対応 が 句対応 に 拡張 さ れる 
0 各 Step は EMアルゴリズム により 反復的 に 実行 さ れる 
0 次 章 で は 我々 の 提案 する アライメントモデル を IBMモデル と 比較 し ながら 定義 する 
