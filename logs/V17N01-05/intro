はじめに
\label{Introduction}

日本語と英語のように言語構造が著しく異なり，語順変化が大きな言語対におい
て，対訳文をアライメントする際に重要なことは二つある．一つは構文解析や依
存構造解析などの言語情報をアライメントに組み込み，語順変化を克服すること
であり，もう一つはアライメントの手法が1対1の単語対応だけでなく，1対多や
多対多などの句対応を生成できることである．これは一方の言語では1語で表現
されているものが，他方では2語以上で表現されることが少なくないからである．
しかしながら，既存のアライメント手法の多くは文を単純に単語列としてしか扱っ
ておらず\cite{Brown93}，句対応は単語対応を行った後にヒューリスティックな
ルールにより生成するといった方法を取っている
\cite{koehn-och-marcu:2003:HLTNAACL}．Quirkら
\cite{quirk-menezes-cherry:2005:ACL}やCowanら
\cite{cowan-kuucerova-collins:2006:EMNLP}はアライメントに構造情報を統合
しようとしたが，前述の単語列アライメントを行った後に用いるに留まっている．
単語列アライメント手法そのものの精度が高くないため，このような方法では十
分な精度でアライメントが行えるとは言い難い．


一方で，アライメントの最初から構造情報を利用する手法もいくつか提案されて
いる．Wata\-nabeら\cite{Watanabe00}やMenezesとRichardson \cite{Menezes01}は
構文解析結果を利用したアライメント手法を提案しているが，対応の曖昧性解消
の際にヒューリスティックなルールを用いている．Yamadaと
Knight \cite{yamada_ACL_2001}やGildea \cite{Gildea03} は木構造を利用した確
率的なアライメント手法を提案している．これらの手法は一方の文の木構造に対
して葉の並べ替え，部分木の挿入・削除といった操作を行って，他方の文構造を
再現するものであるが，構文情報の利用が逆に強い制約となってしまい，文構造
の再現が難しいことが問題となっている．YamadaとKnight はいったん木構造を
崩すことによって，Gildeaは部分木を複製することによってこの問題に対処して
いる．我々はこのような木構造に対する操作は不要であり，依存構造木中の部分
木をそのままアライメントすればよいと考えた．またCherry と
Lin \cite{Cherry03}は原言語側の依存構造木を利用した識別モデルを提案してい
る．しかしながらこの手法はアライメント単位が単語のみであり，一対一対応し
か扱えないという欠点がある．phrase-based SMTでいうところの“句”はただの
単語列に過ぎないが，NakazawaとKurohashi \cite{nakazawa:2008:AMTA} は言語
的な句をアライメントの最小単位とし，句の依存関係に着目したモデルを提案し
ているが，そこでは内容語は内容語のみ，機能語は機能語のみにしか対応しない
という制約があり，また複数の機能語をひとまとまりに扱っているという問題も
あり，これらがしばしば誤ったアライメントを生成している．


本論文ではNakazawaとKurohashiの手法の問題点を改善し，単語や句の依存関係
に注目した句アライメントモデルを提案する．提案手法のポイントは以下の3つ
である．
\begin{enumerate}
 \item 両言語とも依存構造解析し，アライメントの最初から言語の構造情報を
       利用する \label{point1}
 \item アライメントの最小単位は単語だが，モデル学習時に句となるべき部分
       を自動的に推定し，句アライメントを行う \label{point2}
 \item 各方向（原言語$\rightarrow$目的言語と目的言語$\rightarrow$原言語）
       の生成モデルを二つ同時に利用することにより，より高精度なアライメ
       ントを行う \label{point3}
\end{enumerate}

本モデルは二つの依存構造木において，一方の依存構造木で直接の親子関係にあ
る一組の対応について，他方のそれぞれの対応先の依存関係をモデル化しており，
単語列アライメントで扱うのが困難な距離の大きな語順変化にも対応することが
できる．言い替えれば，本モデルは木構造上でのreorderingモデルということが
できる．また本モデルはヒューリスティックなルールを用いずに，句となるべき
部分を自動的に推定することができる．ここでいう句とは必ずしも言語的な句で
ある必要はなく，任意の単語のまとまりである．ただし，Phrase-based SMTにお
ける句の定義との重要な違いは，我々は木構造を扱っており，単語列としては連
続でなくても，木構造上で連続ならば句として扱っているという点である．

また我々のモデルはIBMモデルのような各方向の生成モデルを両方向分同時に用
いてアライメントを行う．これはアライメントの良さを両方向から判断する方が
自然であり，Liangら\cite{liang-taskar-klein:2006:HLT-NAACL06-Main}による
報告にもあるように，そうした方が精度よいアライメントが行えるからである．
ただし，Liangらの手法がIBMモデルと同様に単語列を扱うものであるのに対し，
提案手法は木構造を扱っているという重要な違いがある．またLiangらの手法で
は部分的に双方向のモデルを結合するに留まっており，アライメントの結果とし
ては各方向それぞれ独立に生成されるが，我々の方法ではただ一つのアライメン
トを生成するという違いもある．

最近の報告では生成モデルよりも識別モデルを用いた方がより高精度なアライメ
ントが行えるという報告がなされているが，学習用にアライメントの正解セット
を用意するコストがかかってしまう．そこで我々は教師なしでモデル学習が行え
る生成モデルを用いた．モデルは2つのステップを経て学習される．Step 1では
単語翻訳確率を学習し，Step 2では句翻訳確率と依存関係確率が推定される．さ
らにStep 2では単語対応が句対応に拡張される．各StepはEMアルゴリズムにより
反復的に実行される．

次章では我々の提案するアライメントモデルを，IBMモデルと比較しながら定義
する．\ref{training}章ではモデルのトレーニングについて説明し，
\ref{result}章では提案手法の有効性を示すために行った実験の結果と結果の考
察を述べ，最後に結論と今後の課題を述べる．


