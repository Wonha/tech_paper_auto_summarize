\section{関連研究}
\label{sec-related-work}

日本語学習者の助詞誤り検出・訂正は従来より研究されてきた．{\kern-0.5zw}近年では，
\shortciteA{suzuki-toutanova:2006:COLACL}が，最大エントロピー法 (ME) 
による分類器を用いて，助詞（主に格助詞）が欠落した文からの復元を行って
いる．この入力文は形態素・構文解析済みであり，基本的に誤り箇所が既に分
かっているとき，挿入操作だけで修正を行う．
\shortciteA{Ohki:ParticleError2011j}は，形態素・構文解析済みの入力文
（誤りを含む）に対して，周辺の形態素や係り先を素性として，SVMで助詞の
誤用検出する方法を提案している．ここでは，助詞の欠落も対象としている．
検出を行うのみで修正までは行わない．

英語の前置詞・冠詞誤り訂正では，\shortciteA{HAN10.821}が，前置詞周辺単
語や構文解析の主辞などを素性としたME分類器を用いて，前置詞の誤り訂正を
行った．\shortciteA{gamon:2010:NAACLHLT}は前置詞と冠詞誤りを対象に，ME
分類器による誤り検出，決定木による誤り訂正を行った．また，
\shortciteA{rozovskaya-roth:2010:EMNLP}は平均化パーセプトロンに基づく
分類器で前置詞の誤り訂正を行っている．これらの研究は，いずれも誤りの
種類を助詞や前置詞・冠詞に限定することで，分類器による誤り訂正を可能と
している．

一方，\shortciteA{mizumoto-EtAl:2011:IJCNLP-2011}は，誤りを助詞に限定
せず，すべての誤りを対象とした自動訂正法を提案した．ここでは，対訳文に
相当する学習者作文と日本人による修正文のペアを大量にSNSから収集し，句
に基づく統計翻訳の仕組みを利用して訂正を行う．誤りを含む入力の形態素解
析は行わず，文字単位で翻訳を行う．本稿で使用した系列変換は，基本的には
統計翻訳と同等な手法である．そのため，誤りの種類を助詞に限定する必要が
なく，他の誤りにも拡張できる．しかし，本稿の方式はあらかじめ学習者作文
が単語に分割されていることを前提としている．誤りを含む文を形態素解析，
構文解析した場合の精度は，一般的には日本語母語話者が記述した文の解析精
度より落ちると考えられるため，単語分割法も併せて検討する
必要がある\shortcite{Fujino:ErrorMorphAnalysis2012j}．

母語話者の記述したテキスト（日本語修正文相当）のモデル化という観点で上
記研究を俯瞰すると，
\shortciteA{suzuki-toutanova:2006:COLACL,Ohki:ParticleError2011j,HAN10.821,rozovskaya-roth:2010:EMNLP} 
はn-gram二値素性として利用している．
\shortciteA{gamon:2010:NAACLHLT,mizumoto-EtAl:2011:IJCNLP-2011}は，
n-gram確率という形でモデル化している．本稿では，識別モデルの枠組みで両
者を併用し，マッピング素性を含んで全体最適化を行うことにより，再現率を
向上することができた．

学習者作文の利用という観点で俯瞰すると，いずれの研究も，学習者の誤り傾
向をモデルとして組み込むことにより，母語話者の記述したテキストのみを用
いて誤り訂正を行う場合に比べ，訂正精度が向上したと報告している
\shortcite{HAN10.821,gamon:2010:NAACLHLT,rozovskaya-roth:2010:EMNLP,Kasahara:CaseParticleCorrection2012j} 
．本稿の方式は，マッピング素性という形で学習者の誤り傾向をモデル化して
おり，従来研究の成果を取り込んでいる．

学習者作文を模した擬似誤り文に関しては，
\shortciteA{rozovskaya-roth:2010:NAACLHLT}が提案を行っている．そこで
は，学習者の実誤りと同じ分布を持つ擬似誤り文を追加することにより，精度
が向上したと報告している．ただ，データ（論文では学習者の母語別）によっ
て最適な擬似誤り生成方法が異なっており，擬似誤り生成を制御する必要があ
る．本稿では，擬似誤りと実誤りのずれをドメイン適応技術を用いて修正する
ことで安定した精度向上ができた．

さまざまな種類の誤りの同時訂正は，
\shortciteA{dahlmeier-ng:2012:EMNLP-CoNLL}も行い，前置詞・冠詞誤りだけ
でなく，スペルミス，句読点，名詞の数の誤りも含めて訂正を行っている．誤
りの種別ごとに分類器やルールを用いて訂正仮説を生成し，山登り的に書き換
えを繰り返すことで 1 文中の複数の誤りを訂正する．彼らは，複数の仮説を保
持することで，山登り時に局所解に陥る可能性を軽減しているが，本稿の方式
はすべての仮説をフレーズラティスに持ち，Viterbiアルゴリズムで最適な組
み合わせを探索しているので，モデル上は最適な訂正結果であることが保証さ
れている．

本タスクは，訂正すべき助詞に比べ訂正不要な助詞が圧倒的に多く，安易な再
現率の向上は誤り訂正精度（相対向上数）の改善に直結しないと述べた．これ
はデータ不平衡問題 (Imbalanced Data Problem) と呼ばれ，機械学習を実タ
スクに適用するときの主要な問題の一つと認識されている（たとえば，サーベ
イ論文\shortcite{He:Imbalanced2009}を参照）．この問題の解決方法には，
少数派と多数派のデータを増減させることで平衡させる方法（サンプリング法）
や，少数派の分類誤り（本タスクの場合，訂正誤り）と多数派の分類誤りに異
なるコストを与えて学習する方法（ベイズリスク最小法）など，さまざまなも
のが提案されており，本タスクに適用できるか検討する必要がある．なお，本
稿で提案した疑似誤り文は，実誤りの分布を変えないようにデータを増やすの
が目的であるので，少数派データを増やすover-sampling 法とは異なる位置づ
けである．


