================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:2, score:0.66878] 従来の手法では、２つの文節間が依存関係にある確率をそれぞれの文節の組に対して計算するが、本研究で提案する「３つ組／４つ組モデル」は、係り元の文節と係り先の文節の候補となる全ての文節に関する情報を確率の条件部として、ある文節が係り先として選択される確率を求める。
[i:3, score:0.42910] なお、係り先の候補は、HPSGに基づいた文法及びヒューリスティクスによって高々３つに絞られる。
[i:4, score:0.27569] 確率の推定には最大エントロピー法を用いており、我々の構文解析器はEDRコーパスに対して文節正解率88.6[MATH]という高い解析精度を達成した。

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:15, score:0.62184] 文法により絞った係り先候補が４つ以上存在する場合、それを係り元から見て(1)最も近い文節、(2)二番目に近い文節、(3)最も遠い文節の３つに制限する。
[i:18, score:0.62241] 係り元文節がそれぞれの候補に係る確率を、３つ組／４つ組モデルを用いて求める。
[i:23, score:0.65877] これに対し、本研究で用いる３つ組／４つ組モデルでは、係り元文節[MATH]の候補[MATH]に関して、[MATH]の属性を[MATH]、[MATH]及び[MATH]と[MATH]の文節間の属性を[MATH]とするとき、[MATH]と全ての[MATH]に対する[MATH]を前件として、[MATH]番目の候補が選ばれる条件付き確率

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:31, score:0.26387] 本節では、これまでに提案されてきた日本語構文解析のための統計的アプローチと、本研究で構文解析に用いる日本語文法SLUNG、及び確率モデルの推定に用いる最大エントロピー法を紹介する。
-----------------------------------------------------
  [subsection title : 従来の統計的構文解析手法]
-----------------------------------------------------
  [i:lead, score:0.28274] 日本語の係り受け解析のための統計的手法として、様々なモデルが考案されており、次の２つに大別される。
.....
  [i:44, score:0.54766] 決定木を用いたモデル[CITE]、最大エントロピー法を用いたモデル[CITE]、距離確率と語彙確率を用いたモデル[CITE]では、係り元文節[MATH]の品詞や語彙や読点の有無など、係り先文節[MATH]の品詞や語彙、そして二文節間の距離・読点や副助詞「は」の数などを属性として、ある属性を持った二文節が存在する時にそれが係り受け関係にある確率を二文節[MATH]間の係り受けのしやすさとしている。
  [i:47, score:0.43733] 係り元・係り先とそのまわりの文節を考慮するモデル[CITE]では、係り元文節[MATH]の係り先文節[MATH]への係りやすさの計算に、[MATH]より右側にある全ての文節の情報を用いている。
  [i:52, score:0.56584] 本研究で用いる３つ組／４つ組モデル[CITE]では、２つまたは３つの係り先候補の属性を同時に考慮できるため、文脈情報が扱えるうえ、さまざまな望ましい点がある。
-----------------------------------------------------
  [subsection title : 日本語文法SLUNG]
-----------------------------------------------------
  [i:lead, score:0.09179] 本論文で提案する手法では、人手で書かれた文法で候補を絞ることが必須である。
.....
  [i:55, score:0.16897] 我々が用いるSLUNG[CITE]は、HPSG[CITE]の枠組みで記述された日本語文法であり、8つのスキーマと、48個の語彙項目テンプレート、105個の語彙項目からなる。
  [i:57, score:0.20573] 文法自体は曖昧性解消の機構を持っていないため、SLUNGを用いて構文解析した場合、文法的に許される全ての構文木が出力される。
  [i:58, score:0.41134] 本研究では、文節係り受けの統計モデルを用いることにより、出力された構文木から最も優先度の高いものを選び出すことができるようになる。
-----------------------------------------------------
  [subsection title : 最大エントロピー法]
-----------------------------------------------------
  [i:lead, score:0.10159] 統計モデルの推定に、最大エントロピー法(ME法)[CITE]を用いる。
.....
  [i:60, score:0.17724] ME法では、「学習コーパス中の履歴の特定の条件を満たし、かつ特定の出力値を得る場合」（素性）の頻度を得て、様々な素性に対するパラメータを、出力値の確率分布が最も一様分布に近づくように調整して求める。
  [i:62, score:0.27660] 日本語係り受け解析でもME法は非常に有用で[CITE]、品詞の情報だけでなく、頻度の高い単語に対しては語彙的情報も加えるといった柔軟な素性の追加が容易である。
  [i:63, score:0.39273] 本稿での実験における精度は、単純な相対頻度で推定した３つ組／４つ組モデル[CITE]よりも約1.9[MATH]向上しているが、その要因として、ME法を用いることで以前よりも多くの素性を追加できたことが挙げられる。

================================================================
[section type  : proposed_method]
[section title : 本研究の手法]
================================================================
[i:64, score:0.47363] 本節では、「３つ組／４つ組モデル」を用いて係り受け解析をする手順を解説する。
[i:66, score:0.63183] ３つ組／４つ組モデルの準備として、[REF_subsec:restrict]節で述べる手法により、各文節の係り先候補を３つ以下に制限する。
[i:69, score:0.65681] そして、係り先の候補の集合の中で、ある要素が係り先として選択される確率を、係り元文節と全ての係り先の候補の属性を同時に考慮するモデル（３つ組／４つ組モデル）で推定する。
-----------------------------------------------------
  [subsection title : 準備：係り受け候補の制限]
-----------------------------------------------------
  [i:lead, score:0.16334] 本システムでは、文を入力とし、JUMAN[CITE]で形態素解析をした後、文法SLUNG[CITE]で構文解析する。
.....
  [i:74, score:0.45435] これを係り先候補の制限に使うために、それぞれの構文木中の部分木を、図[REF_fig:transform]のようにして、文節単位の係り受け構造に帰着させる。
  [i:87, score:0.45540] この性質を利用して、係り先の候補が４つ以上存在する場合にも上記の３文節だけを考え、その他の文節を無視することにする。
  [i:88, score:0.49898] この制限によって、係り受け精度の上限は98.6[MATH]となるが、わずか1.4[MATH]の犠牲により問題を大幅に単純化することができ、次節で述べる３つ組／４つ組モデルの構成が可能になる。
-----------------------------------------------------
  [subsection title : ３つ組／４つ組モデル]
-----------------------------------------------------
  [i:lead, score:0.51355] ３つ組／４つ組モデルは、文節[MATH]が文節[MATH]に係る確率[MATH]を式([REF_equ:triplet2]),式([REF_equ:quadruplet2])で計算する。
.....
  [i:91, score:0.57826] \refstepcounter{enums}このモデルの特徴は、上記の式から推測される通り、「係り元文節と、係り先の候補となる全ての文節の属性を同時に考慮すること」、そして「それぞれの係り先の候補の係りやすさを求めるのではなく、各候補が選ばれる確率を求める」ことである。
  [i:108, score:0.57486] \refstepcounter{equation} \vskip 2mm係り元文節と係り先文節、及び文節間距離を考えるモデルでは、a, bにおける「私の→娘に」は区別されることなく、全く同じ係り受け確率が付与される。
  [i:119, score:0.56381] 従って、３つ組／４つ組モデルにおいて推定する条件付き確率は、係り元とその係り先候補がある文脈において、それぞれの係り先候補が選ばれる確率に一致することになる。
-----------------------------------------------------
  [subsection title : 最適な係り受けの選択]
-----------------------------------------------------
  [i:lead, score:0.45207] 各文節間の係りやすさ[MATH]を求めるにあたって、係り元文節に対する係り先文節の候補の数に依って、次のようなモデルを用いることにする。
.....
  [i:123, score:0.45207] 各文節間の係りやすさ[MATH]を求めるにあたって、係り元文節に対する係り先文節の候補の数に依って、次のようなモデルを用いることにする。
  [i:125, score:0.57373] 係り先候補が２つの場合：係り元と２つの係り先の文節の情報を考慮する「３つ組モデル」を用いる。
  [i:126, score:0.64375] 係り先候補が３つ以上の場合：係り先の候補のうち、係り元に最も近い文節、二番目に近い文節、最も遠い文節の３つだけを考え、係り元とその３つの文節の情報を考慮する「４つ組モデル」を用いる。

================================================================
[section type  : experiment_result]
[section title : 実験結果]
================================================================
[i:136, score:0.34147] さらに、学習コーパスの量を変えた実験や、３つ組／４つ組モデルを導入したことの効用を確かめるための対照実験の結果を載せる。
-----------------------------------------------------
  [subsection title : 実験環境]
-----------------------------------------------------
  [i:lead, score:0.07722] EDR日本語コーパス[CITE]の208,157文のうち、192,778文を学習、3,372文をテストに用いた。
.....
  [i:141, score:0.67428] 学習コーパス中の文をSLUNGで構文解析して、係り先候補が２つである文節に対して、係り元文節と２つの係り先候補の属性の組を履歴として「３つ組モデル」を構成する。
  [i:142, score:0.66712] そして、係り先候補が３つ以上である文節に対しては、[REF_subsec:restrict]節で述べた方法で候補を３つに制限し、係り元文節と３つの係り先候補の属性の組を履歴として「４つ組モデル」を構成する。
  [i:158, score:0.55721] また、係り先に関する素性（素性番号8〜27）は、それぞれの係り先候補（３つ組モデルでは２つ、４つ組モデルでは３つ）に対して素性が割り振られる。
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, score:0.11393] [REF_subsec:env]に記したコーパスに対する、次の２つの精度を測定した結果を表[REF_tab:result]に示す。
.....
  [i:161, score:0.34390] 文中の最後の文節を除く全ての文節に対して、その係り先が正解と一致する割合。
  [i:162, score:0.38799] 表[REF_tab:result]においてのみ、後ろから二番目の文節（可能な係り先が最後の文節のみであるので、必ず正解する）を除外した値を参考のために載せてある。
  [i:167, score:0.53172] SLUNGでの構文解析が失敗した文に関しては、各係り元文節に対して最も高い確率が割り振られた候補を決定的に係り先と判定し、どの候補にも係り得ないとされた文節は隣の文節を修飾すると仮定して正解率を測った。
-----------------------------------------------------
  [subsection title : 対照実験]
-----------------------------------------------------
  [i:lead, score:0.34362] [REF_sec:ourmodel]節で述べた３つ組／４つ組モデルの有効性を示すために、以下のような対照実験を行った。
.....
  [i:177, score:0.51467] 構文解析の結果文法が許した係り先に対してのみ、文法なしモデルと同様、係り元・係り先属性と文節間距離から係る確率を求める。
  [i:179, score:0.46785] 上記のモデルと同様、係り元・係り先属性と文節間距離から、係る確率を求める。
  [i:180, score:0.51075] なお、考慮する係り先候補は３つ組／４つ組モデルの時と同じになる。

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[i:184, score:0.04741] ここでは、本稿で提案する手法がどのように精度向上に寄与しているかの観察、及び他研究との比較を行う。
-----------------------------------------------------
  [subsection title : 「３つ組／４つ組モデル」の効用]
-----------------------------------------------------
  [i:lead, score:0.34359] 表[REF_tab:control_exp]にある対照実験の結果は、以下の理由から３つ組／４つ組モデルの有効性を示しているといえる。
.....
  [i:187, score:0.44919] 両者とも、文法とヒューリスティクスにより係り先候補を３つ以下に限定しているが、それらの係り先候補を同時に考慮するモデルを用いた方が精度が上がることが確認された。
  [i:189, score:0.56333] 従って、文法を用いることや係り先候補を３つに限定することは妥当な措置であり、「２つ組モデル」は「３つ組／４つ組モデル」の比較対象として適当である。
  [i:195, score:0.59778] \refstepcounter{equation} \vskip 2mm各候補への係りやすさを２つ組モデル・４つ組モデルで推定する際のME法のパラメータ[MATH]のうち主な（[MATH]が大きい）ものを、それぞれ表[REF_tab:pair_me] ,表[REF_tab:quad_me]に示す。
-----------------------------------------------------
  [subsection title : 他研究との比較]
-----------------------------------------------------
  [i:lead, score:0.23614] 係り受けの精度判定にEDRコーパスを用いている他研究と比較してみる。
.....
  [i:223, score:0.34502] 文法SLUNGがEDRコーパスの括弧付けの方針に従って作られており、京大コーパスにあるような係り方を許さない場合がある。
  [i:227, score:0.56234] 一般に、ME法を用いることにより学習量を減らすことができると考えられているが、３つ組／４つ組モデルでは、複数の係り先に関する属性を同時に捉える条件付き確率を用いているため、区別される事象の数が大きくなり、多くの学習量が必要になっている。
  [i:230, score:0.37158] 文末から決定的に係り先を決定するモデル[CITE]では、一文当たり平均0.03秒（Sun Ultra10, 300MHz）で解析できるのに対し、一方、我々のシステムではEDRコーパスの文に対して平均約0.5秒（Pentium III, 500MHz :経験的に、上記の計算機の約３倍の速度）を要する。

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[i:234, score:0.27875] 本稿では、文法を用いて係り受け解析をする際に望ましい統計モデルについて論じた。
[i:235, score:0.47075] 係り先の候補を文法が許すものに制限した後、係り元から最も近い文節・二番目に近い文節・最も遠い文節のみに絞る。
[i:236, score:0.58986] これにより、係り元と全ての係り先候補の属性を同時に考慮する「３つ組／４つ組モデル」を用いることができるようになり、88.6[MATH]という高い係り受け精度を達成した。

