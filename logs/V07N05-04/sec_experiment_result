３つ組／４つ組モデルを用いた係り受け解析の実験環境と用いた素性、及び実験結果を示す。
さらに、学習コーパスの量を変えた実験や、３つ組／４つ組モデルを導入したことの効用を確かめるための対照実験の結果を載せる。
EDR日本語コーパス[CITE]の208,157文のうち、192,778文を学習、3,372文をテストに用いた。
[REF_subsec:restrict]節で述べたような観察や、次節で述べる考察などにはその他の6,744文を用いている。
これは、テストコーパスの解析結果を人が見てモデルを修正することによるコーパスへの特化を防ぐためである。
前節で述べた通り、係り先の候補が２つの場合のための「３つ組モデル」と候補が３つ以上の場合のための「４つ組モデル」の二つのモデルを別個に作る。
学習コーパス中の文をSLUNGで構文解析して、係り先候補が２つである文節に対して、係り元文節と２つの係り先候補の属性の組を履歴として「３つ組モデル」を構成する。
そして、係り先候補が３つ以上である文節に対しては、[REF_subsec:restrict]節で述べた方法で候補を３つに制限し、係り元文節と３つの係り先候補の属性の組を履歴として「４つ組モデル」を構成する。
これらは最大エントロピー法のツールChoiceMaker Maximum Entropy Estimator[CITE]を使って推定される。
推定の際に用いた素性を表[REF_tab:features]に示す。
素性の値は[CITE] [CITE]に倣っており、品詞の分類などにはJUMANの出力結果を用いている。
但し、京大コーパスを用いた実験と違って、形態素解析の正解は与えられておらず、誤りを含む場合がある。
以下で各素性について解説する。
なお、主辞とは、品詞大分類が「特殊」「助動詞」「助詞」「接尾辞」「判定詞」のいずれかであるものを除いて、文節内で最も右側にある語、語形とは、品詞大分類が「特殊」であるものを除いて、文節内で最も右側にある語である。
語形・主辞ともに、JUMANの品詞細分類が用いられる。
頻度の高い26種の助詞と69種の副詞。
品詞に依らず、主辞として現れる語のうち頻度の高い294種の語彙。
品詞が「助動詞」「接尾辞」のうち、頻度の高い70種の語彙。
JUMANの出力する活用形を、「基本形」「連用形」「連体形」「テ形」「タ形」「その他」の６種に分類したもの。
係り元と係り先の文節間にある読点の数を、「0」「1」「2」「3以上」の４値で表す。
同様に、副助詞「は」の数を「0」「1」「2以上」の３値で表す。
表[REF_tab:features]中の「異なり数」とは各素性の取りうる値の総数であり、素性番号19〜27の組み合わせ素性に関しては、それぞれの要素の積を記してある。
実際には、履歴の数と出力値の数（2または3）の積だけの素性が用いられる。
また、係り先に関する素性（素性番号8〜27）は、それぞれの係り先候補（３つ組モデルでは２つ、４つ組モデルでは３つ）に対して素性が割り振られる。
このうち、コーパス中で３回以上出現したものが有効素性となる。
[REF_subsec:env]に記したコーパスに対する、次の２つの精度を測定した結果を表[REF_tab:result]に示す。
文中の最後の文節を除く全ての文節に対して、その係り先が正解と一致する割合。
表[REF_tab:result]においてのみ、後ろから二番目の文節（可能な係り先が最後の文節のみであるので、必ず正解する）を除外した値を参考のために載せてある。
一文中の係り受けが全て正解する文の割合。
なお、テストコーパスの平均文節数は8.82である。
なお、「解析成功文」とは、テストコーパスのうち構文解析が成功した文、即ちSLUNGが少なくとも一つの構文木を返した3,326文（全体の98.63[MATH]にあたる）に対する正解率を測ったものである。
また、参考のためにコーパス中の「すべての文」に対しての精度も測っている。
SLUNGでの構文解析が失敗した文に関しては、各係り元文節に対して最も高い確率が割り振られた候補を決定的に係り先と判定し、どの候補にも係り得ないとされた文節は隣の文節を修飾すると仮定して正解率を測った。
表[REF_tab:result]は学習コーパスの約19万文を全て用いた時の値である。
学習コーパスの量を変えた時の解析成功文に対する文節正解率を図[REF_fig:graph]に示す。
[REF_sec:ourmodel]節で述べた３つ組／４つ組モデルの有効性を示すために、以下のような対照実験を行った。
これらのモデルでは、他の統計的係り受け解析モデル[CITE] [CITE] [CITE]と同様に、二つの文節及び文節間の属性から、二文節間の係りやすさを独立に計算する。
また、係り先候補の中での位置を出力とする代わりに、係り元と係り先の文節間の距離（「１」「２から５」「６以上」の３値）を導入している。
ME法による推定において[REF_subsec:env]節に示した素性と同じ素性を使っており、その全てに対して上記の距離の属性を組み合わせている。
文法を用いて候補を絞ることをせず、係り元文節より右側の全ての文節に対して統計値を求める。
係り元・係り先文節の属性と文節間距離などを用いて、二文節があった時にそれが係り受け関係にある確率を計算する。
これは概ね、他の研究と同様のモデルである。
構文解析の結果文法が許した係り先に対してのみ、文法なしモデルと同様、係り元・係り先属性と文節間距離から係る確率を求める。
文法が許す係り先候補を、[REF_subsec:restrict]節で述べた方法で３つに絞って、その３つに対してのみ統計値を求める。
上記のモデルと同様、係り元・係り先属性と文節間距離から、係る確率を求める。
なお、考慮する係り先候補は３つ組／４つ組モデルの時と同じになる。
対照実験の結果は表[REF_tab:control_exp]の通りである。
「３つ組／４つ組モデル」は「２つ組モデル」と比べて精度が0.9[MATH]ほど向上している。
このデータから、３つ組／４つ組モデルが有効であることを次節にて論じる。
３つ組／４つ組モデルを用いた係り受け解析の実験環境と用いた素性、及び実験結果を示す。
さらに、学習コーパスの量を変えた実験や、３つ組／４つ組モデルを導入したことの効用を確かめるための対照実験の結果を載せる。
EDR日本語コーパス[CITE]の208,157文のうち、192,778文を学習、3,372文をテストに用いた。
[REF_subsec:restrict]節で述べたような観察や、次節で述べる考察などにはその他の6,744文を用いている。
これは、テストコーパスの解析結果を人が見てモデルを修正することによるコーパスへの特化を防ぐためである。
前節で述べた通り、係り先の候補が２つの場合のための「３つ組モデル」と候補が３つ以上の場合のための「４つ組モデル」の二つのモデルを別個に作る。
学習コーパス中の文をSLUNGで構文解析して、係り先候補が２つである文節に対して、係り元文節と２つの係り先候補の属性の組を履歴として「３つ組モデル」を構成する。
そして、係り先候補が３つ以上である文節に対しては、[REF_subsec:restrict]節で述べた方法で候補を３つに制限し、係り元文節と３つの係り先候補の属性の組を履歴として「４つ組モデル」を構成する。
これらは最大エントロピー法のツールChoiceMaker Maximum Entropy Estimator[CITE]を使って推定される。
推定の際に用いた素性を表[REF_tab:features]に示す。
素性の値は[CITE] [CITE]に倣っており、品詞の分類などにはJUMANの出力結果を用いている。
但し、京大コーパスを用いた実験と違って、形態素解析の正解は与えられておらず、誤りを含む場合がある。
以下で各素性について解説する。
なお、主辞とは、品詞大分類が「特殊」「助動詞」「助詞」「接尾辞」「判定詞」のいずれかであるものを除いて、文節内で最も右側にある語、語形とは、品詞大分類が「特殊」であるものを除いて、文節内で最も右側にある語である。
語形・主辞ともに、JUMANの品詞細分類が用いられる。
頻度の高い26種の助詞と69種の副詞。
品詞に依らず、主辞として現れる語のうち頻度の高い294種の語彙。
品詞が「助動詞」「接尾辞」のうち、頻度の高い70種の語彙。
JUMANの出力する活用形を、「基本形」「連用形」「連体形」「テ形」「タ形」「その他」の６種に分類したもの。
係り元と係り先の文節間にある読点の数を、「0」「1」「2」「3以上」の４値で表す。
同様に、副助詞「は」の数を「0」「1」「2以上」の３値で表す。
表[REF_tab:features]中の「異なり数」とは各素性の取りうる値の総数であり、素性番号19〜27の組み合わせ素性に関しては、それぞれの要素の積を記してある。
実際には、履歴の数と出力値の数（2または3）の積だけの素性が用いられる。
また、係り先に関する素性（素性番号8〜27）は、それぞれの係り先候補（３つ組モデルでは２つ、４つ組モデルでは３つ）に対して素性が割り振られる。
このうち、コーパス中で３回以上出現したものが有効素性となる。
[REF_subsec:env]に記したコーパスに対する、次の２つの精度を測定した結果を表[REF_tab:result]に示す。
文中の最後の文節を除く全ての文節に対して、その係り先が正解と一致する割合。
表[REF_tab:result]においてのみ、後ろから二番目の文節（可能な係り先が最後の文節のみであるので、必ず正解する）を除外した値を参考のために載せてある。
一文中の係り受けが全て正解する文の割合。
なお、テストコーパスの平均文節数は8.82である。
なお、「解析成功文」とは、テストコーパスのうち構文解析が成功した文、即ちSLUNGが少なくとも一つの構文木を返した3,326文（全体の98.63[MATH]にあたる）に対する正解率を測ったものである。
また、参考のためにコーパス中の「すべての文」に対しての精度も測っている。
SLUNGでの構文解析が失敗した文に関しては、各係り元文節に対して最も高い確率が割り振られた候補を決定的に係り先と判定し、どの候補にも係り得ないとされた文節は隣の文節を修飾すると仮定して正解率を測った。
表[REF_tab:result]は学習コーパスの約19万文を全て用いた時の値である。
学習コーパスの量を変えた時の解析成功文に対する文節正解率を図[REF_fig:graph]に示す。
[REF_sec:ourmodel]節で述べた３つ組／４つ組モデルの有効性を示すために、以下のような対照実験を行った。
これらのモデルでは、他の統計的係り受け解析モデル[CITE] [CITE] [CITE]と同様に、二つの文節及び文節間の属性から、二文節間の係りやすさを独立に計算する。
また、係り先候補の中での位置を出力とする代わりに、係り元と係り先の文節間の距離（「１」「２から５」「６以上」の３値）を導入している。
ME法による推定において[REF_subsec:env]節に示した素性と同じ素性を使っており、その全てに対して上記の距離の属性を組み合わせている。
文法を用いて候補を絞ることをせず、係り元文節より右側の全ての文節に対して統計値を求める。
係り元・係り先文節の属性と文節間距離などを用いて、二文節があった時にそれが係り受け関係にある確率を計算する。
これは概ね、他の研究と同様のモデルである。
構文解析の結果文法が許した係り先に対してのみ、文法なしモデルと同様、係り元・係り先属性と文節間距離から係る確率を求める。
文法が許す係り先候補を、[REF_subsec:restrict]節で述べた方法で３つに絞って、その３つに対してのみ統計値を求める。
上記のモデルと同様、係り元・係り先属性と文節間距離から、係る確率を求める。
なお、考慮する係り先候補は３つ組／４つ組モデルの時と同じになる。
対照実験の結果は表[REF_tab:control_exp]の通りである。
「３つ組／４つ組モデル」は「２つ組モデル」と比べて精度が0.9[MATH]ほど向上している。
このデータから、３つ組／４つ組モデルが有効であることを次節にて論じる。
