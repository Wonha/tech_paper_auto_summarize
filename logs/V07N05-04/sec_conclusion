ここでは、本稿で提案する手法がどのように精度向上に寄与しているかの観察、及び他研究との比較を行う。
表[REF_tab:control_exp]にある対照実験の結果は、以下の理由から３つ組／４つ組モデルの有効性を示しているといえる。
「３つ組／４つ組モデル」の精度は「２つ組モデル」の精度よりも約0.9[MATH]上回っている。
両者とも、文法とヒューリスティクスにより係り先候補を３つ以下に限定しているが、それらの係り先候補を同時に考慮するモデルを用いた方が精度が上がることが確認された。
「２つ組モデル」は、「文法なしモデル」より1.0[MATH]、「候補限定なしモデル」よりも0.3[MATH]高い精度を出している。
従って、文法を用いることや係り先候補を３つに限定することは妥当な措置であり、「２つ組モデル」は「３つ組／４つ組モデル」の比較対象として適当である。
次に、両者のモデルで実際に解析を行う時の、具体的なMEのパラメータを観察してみる。
例として、文([REF_sent:kodomo])の「子供たちの」の各候補への係りやすさを計算する。
「子供たちの」の係り先候補は、「甲高い」「声で」「騒然となる。
」の３文節で、正解は「声で」である。
\vskip 2mm \refstepcounter{enums} (\theenums)そんなとき、子供たちの甲高い声で騒然となる。
\refstepcounter{equation} \vskip 2mm
各候補への係りやすさを２つ組モデル・４つ組モデルで推定する際のME法のパラメータ[MATH]のうち主な（[MATH]が大きい）ものを、それぞれ表[REF_tab:pair_me] ,表[REF_tab:quad_me]に示す。
パラメータ[MATH]のうち、履歴[MATH]、出力値[MATH]に対応する素性のものを掛け合わせるので、[MATH]の値が1.0より大きいものは出力値を[MATH]にすることを助長するパラメータ、1.0より小さいものは[MATH]にすることを抑制するパラメータである。
「[MATH]の積」の項は、表に載せていないものも含め、対応する出力値に関する全てのパラメータの積である。
このモデルでは、係り先ごとに別々の条件で係りやすさを計算する。
各係り先への係りやすさ[MATH]は、出力値Ｔに対する[MATH]の積を、出力値Ｔ,Ｆに対する[MATH]の積の和で割ったものである。
例えば、[MATH]は、[MATH]となる。
「声で」に係る場合のパラメータに注目すると、係り元助詞「の」は隣の文節に係る傾向が強いことから、文節間距離が「２から５」に対するパラメータが小さくなっている。
そのため、「甲高い」に係る確率の方が高くなってしまう。
全ての係り先への係りやすさを共通の確率分布を用いて計算する。
出力値[MATH]は[MATH]の３値をとり、第一候補への係りやすさ[MATH]は出力値１に対する[MATH]の積を、３つの出力値に対する[MATH]の積の和で割ったものであり、表[REF_tab:quad_me]の例では[MATH]となる。
出力値が2となる場合のパラメータに着目する。
係り元が「の」で、第一候補が「形容詞」であること、第二候補が「名詞」であること、第三候補が「形容詞」であることの全てが第二候補に係るパラメータを高めており、第二候補に係る確率が第一候補に係る確率を上回っている。
特に、出力値[MATH]と異なる候補（この場合、第一・第三候補）に関係する素性も強い影響を及ぼしていることが興味深い。
係り受けの精度判定にEDRコーパスを用いている他研究と比較してみる。
決定木を用いた手法[CITE]での精度は84〜85[MATH]、語の共起確率を用いた手法[CITE]では、86.8[MATH]となっている。
我々の手法はこれらを上回っており、EDRコーパスに対してテストした中では最も高い水準といえよう。
また、[CITE]では、３つ組／４つ組モデルを単純な相対頻度を用いて構成している。
そこでの精度は86.7[MATH]であり、ME法の利用によって約1.9[MATH]精度が向上したことになる。
精度向上の要因は、ME法によってデータスパースネスの問題が軽減でき、従来は入れられなかった語彙や活用に関する素性を追加できたことであると思われる。
いくつかの研究では、京大コーパス[CITE]を用いて精度を測っている。
構文的・語彙的情報を統合して構文木の生起確率を求めている手法[CITE]での精度は85〜86[MATH]である。
本研究と同様に、ME法を用いた研究[CITE], [CITE]では、京大コーパスの1月9日分の1,246文を用いている。
比較のために、同じコーパスでテストした結果は、表[REF_tab:accuracy_kc]のようになった。
{|l|l|rc|} \hline\smash\hbox{解析成功文} &文節正解率& 87.08[MATH] & (8299/9530)
\cline{2-4}
&文正解率& 44.70[MATH] & (493/1103)
\hline
文末から決定的に係り先を決定するモデル[CITE]の精度は87.14[MATH]で我々と同程度、後方文脈を考慮するモデル[CITE]は87.93[MATH]で我々の精度よりも高くなっている。
その原因として、以下のことが考えられる。
我々は、学習データとしてEDRコーパスを用いている。
[CITE]などと比べて約24倍の学習データがあるとはいえ、括弧付けの方針の違いなどから、京大コーパスでの解析の誤りを引き起こすことが多い。
関根ら、内元らは京大コーパス中にある形態素解析・文節区切りの結果を用いているのに対し、我々はJUMANで解析したものを用いているため、形態素解析の誤りを含み、解析誤りの原因となっている。
文法SLUNGがEDRコーパスの括弧付けの方針に従って作られており、京大コーパスにあるような係り方を許さない場合がある。
現在のところ、京大コーパスの解析には被覆率・精度ともに充分でないが、文法やシステムの改変により対処した上で本論文で提案する手法を有効に適用できるようにすれば、より高い精度が得られると考えている。
図[REF_fig:graph]より、最高値に近い精度を得るためには、10〜15万文の学習コーパスを要している。
この学習量は、EDRコーパスを用いている研究[CITE]と同程度であり、[CITE]などの京大コーパスを用いた場合より、20倍程度の学習量になっている。
一般に、ME法を用いることにより学習量を減らすことができると考えられているが、３つ組／４つ組モデルでは、複数の係り先に関する属性を同時に捉える条件付き確率を用いているため、区別される事象の数が大きくなり、多くの学習量が必要になっている。
我々のモデルは、EDRコーパスのような多くの学習データを有効に利用できるモデルであるといえる反面、京大コーパスのように学習データ量が限られている時には、より効率のよい素性選択などが要求されるであろう。
本研究での係り受け解析は、あくまで詳細な構文構造を得るという目標の前段階であるため、速度に焦点を当ててはいないが、参考のために比較しておく。
文末から決定的に係り先を決定するモデル[CITE]では、一文当たり平均0.03秒（Sun Ultra10, 300MHz）で解析できるのに対し、一方、我々のシステムではEDRコーパスの文に対して平均約0.5秒（Pentium III, 500MHz :経験的に、上記の計算機の約３倍の速度）を要する。
両者には大きな差があるものの、我々の速度も非実用的なものではない。
また、そのほとんどはHPSGパーザによる部分木の生成の時間である。
単に係り受け構造を求めるだけなら速度を向上する余地は多分にあるうえ、HPSGパーザ自体の高速化も研究されており[CITE]、速度の問題は深刻であるとは考えていない。
本稿では、文法を用いて係り受け解析をする際に望ましい統計モデルについて論じた。
係り先の候補を文法が許すものに制限した後、係り元から最も近い文節・二番目に近い文節・最も遠い文節のみに絞る。
これにより、係り元と全ての係り先候補の属性を同時に考慮する「３つ組／４つ組モデル」を用いることができるようになり、88.6[MATH]という高い係り受け精度を達成した。
また、このモデルが精度向上に確かに寄与していることを示した。
