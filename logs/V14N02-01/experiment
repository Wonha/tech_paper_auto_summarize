評価 


\subsection{評価実験の概要と正解セットの作成}

シソーラスを評価する手法として，
WordNetやEDRなど人手で構築された既存のシソーラスと比
較する方法\cite{Jarmasz03,Curran02}，
綿密に作られたアンケートや語の分類タスクを人が行い，
その結果と比較することでシソーラスの適切さを評価する方法\cite{Croft99,Hodge02}がある．
前者の手法はWordNetに出現する語しか評価できないため語の範囲が限ら
れてしまい，後者はコストがかかるのが問題である．


本研究では，提案手法で構築されたシソーラスと，2種類のシソーラスを比較することで，提案手法の評価を行う．
1つ目はWebより収集したコーパスから作成したシソーラスであり，
これを関連語の正解セット作成用のデータとして用いることで提案手法と従来のコーパスを用いた手法との比較を行う．
2つ目は既存のシソーラスであり，これから作成した関連語の正解セットを用いて，
人手によって構築されたシソーラスと提案手法との比較を行う．

また，1つ目の正解セットにはWebに特徴的な語が多く含まれるのに対し，
2つ目の正解セットでは，既存のシソーラスに含まれるような，いわゆる汎用
的な語が多く含まれる．そのため，それぞれの正解セットを評価実験に用いることで，
Webに特徴的な語に対する提案手法の有効性，汎用的な語に対する提案手法の
有効性を検証することにもなる．

\subsubsection{OpenDirectoryを用いた正解セットの作成}
シソーラスを作成するコーパスとしてOpenDirectory\footnote{http://dmoz.org/World/Japanese/}を用い，あらかじめ各カテゴリに特徴的な語を抽出することで，
正解となるシソーラスを模擬的に作成する．
OpenDirectoryは，ボランティア方式で運営される世界最大のウェブディレクトリであり，
各カテゴリは，担当のエディタによって管理されている．Webディレクトリの中では，カテゴリ分類の信頼性が高いもののひとつである．
各カテゴリに特徴的に出現する語は互いに関連しているという仮定のもとで，
提案手法および比較手法による語の関連性の適切さを評価する．


OpenDirectoryの14個のカテゴリの中から，「アート」，「スポーツ」，「コンピュータ」，「ゲーム」，「社会」，
「家族」，「科学」，「健康」，「レクリエーション」の9つのカテゴリを用い\linebreak
た\footnote{なお，「ニュース」，
    「キッズ＆ティーンズ」，「ビジネス」，「オンラインショップ」，
「各種資料」は，他のカテゴリとの重複が大きいため除いた．}．
各カテゴリ内に含まれるWebページを用い，次のようにカテゴリに特徴的な語を抽出する．


\begin{enumerate}
\item 各カテゴリ$C_i(i=1...9)$ごとに登録順に1000ページの文書を取得する．
\item 全ての文書に形態素解析\footnote{茶筌．http://chasen.aist-nara.ac.jp/.}を行う．そして連接する名詞5-gramまでを単語として取り出す\cite{Manning99}．
\item カテゴリ$C_i$内で，単語$w_a$が含まれる文書の数を$f^i_{w_a}$とする．
また，全てのカテゴリで語$w_a$が含まれる文書数を$f^{all}_{w_a}$とする．
\item カテゴリ$C_i$における語$w_a$の重みを次のように計算する．
\begin{equation}
score^i_{w_a} = f^i_{w_a} \times \log (N/f^{all}_{w_a})
\label{tfidf}
\end{equation}
ただし，$N$は全文書数である．
\item カテゴリ$C_i$ごとにscoreの高い語$w_a$を取り出し，それらをそのカテゴリに特徴的な語群$R_{C_i}$とする．
すなわち，$R_{C_i} = \{w_k | rank_i(w_k) \leq 10\}$である（$rank_i(w_k)は，カテゴリC_i内での語w_kのscoreの順位を表す$）．
また，$A=\{w| w \in R_{C_i}, i=1...9\}$とする．
\end{enumerate}
ここでは，各カテゴリごとに特徴的に現れる語を，tfidfの考え方を用いて重み付けしている．
また上記説明の(1)において「登録順に」とあるが，これはOpenDirectoryのサイ
トから文書データを収集する際に，
データが得られる順番を意味している．この順番は，文書の内容に関係なく無作為に並んでおり，
特定のルールはないと考えられるため，ランダムな順番と考えても問題ないと言える．




\begin{table}[b]
\caption{OpenDirectoryから取り出した関連語群}
\label{wordlist}
\begin{center}
\begin{tabular}{l l}
\hline
カテゴリー & 関連語群 \\ \hline
アート & 画廊，作品，劇場，サックス，短歌，ライブ，ギター，披露，バレエ，個展 \\
コンピュータ & 掲示板，ソースコード，無料レンタル，アクセス数，文字コード，初期値，拡張子 \\
科学 & 情報処理，実証，方法論，社会科学，研究対象，格差，研究員，専門，専攻，討論
 \\ \hline
\end{tabular}
\end{center}
\end{table}


得られた語の一部を表\ref{wordlist}に示す．
例えば「アート」カテゴリから取り出された語に注目すれば，
「画廊」「作品」「個展」は絵画関連の語，「サックス」「ライブ」「ギター」は音楽関連の語，
「バレエ」「披露」「劇場」はパフォーミングアート関連の語，「短歌」は文芸関連の語となっており，
いずれも「アート」に関連した語が取り出されている．
こうして得られたカテゴリごとの特徴的な語を用いて，
\begin{itemize}
\item ある2語が同一カテゴリ内に含まれれば，関連している
\item ある2語が異なるカテゴリであれば，関連していない
\end{itemize}
と見なす．

ここでの評価法は，カテゴリごとの特徴語の抽出に基づいている．
各カテゴリに特徴的に現れる語を重み付けする方法は，\cite{Nagao76}や
\cite{Xu02}で用いられている．後者では，
各カテゴリに特徴的な語をtfidfで重み付けし，tfidf値の高い語を
カテゴリに特徴的な語として抽出している．
さらに\cite{Chang05}では，OpenDirectoryのカテゴリ分類を用いて各カテゴリに特徴的な語を取得し，
その結果，人手による評価で平均65\%，最大で81\%の正解率を得ている．
もちろん，ここでの関連語の正解セットは完全ではなく，異なるカテゴリに含まれていても関連している場合もあるかもしれないし，同一カテゴリ内であっても，
その関連の度合いは程度の差が大きいかもしれない．
しかし，本研究では，このデータを手法の比較を行うための目安として用いており，比較手法の優劣を示すには十分であると考えている．


\begin{figure}[b]
\begin{center}
  \includegraphics[width=8cm,clip]{evaluate.eps}
\end{center}
 \caption{評価実験の概略図}
 \label{evaluate}
\end{figure}


図\ref{evaluate}に全体の概要を図示する．OpenDirectoryから獲得したカテゴ
リ分類されたコーパスを用いて関連語の正解セットを作成する．
その正解セットの語を用いて提案手法および比較手法によって
関連語を出力する．その際，比較手法はコーパス内の共起情報を用いて
関連度の算出を行う．そして出力結果と正解セットを比較し，手法の評価を行う．

図\ref{evaluate}に示すとおり，本評価実験では
正解セット作成用コーパス，比較手法で用いる関連度学習用コーパス
の2種類のコーパスが必要となる．
そこで，全部で各カテゴリから5000ページずつ計4万5千ページの文書をコーパスとして用意し，
$1/5$を正解セット作成用に，$4/5$を関連度の学習用に用いて5分割交差検定を行った
\footnote{ただし，関連度の学習を行う際はコーパスの持つカテゴリ分類は無視し，flatなコーパスとして扱った．}．
正解セット作成用のコーパスを変えたそれぞれの正解セットを$Ao_i(i=1,2,3,4,5)$とする．

関連度の評価は，適合率，再現率，Inverse Rank Scoreによって測る．
Inverse Rank Scoreとは正解とマッチした語の順位の逆数の合計値であり，
正解となる語が上位にランクされる程大きい値となる．
この値を用いることで，順位を考慮した比較を行うことができる．

\begin{table}[t]
\caption{評価実験の例（ヴァイオリン）}
\label{ex-experiment}
\begin{center}
\begin{tabular}{l|c|c|c|c}
	& 関連語   & 適合率 & 再現率 & InvR \\ \hline
正解セット & ビオラ，チェロ，笛，ギター & &  & \\ \hline
手法1 & 1位:ビオラ  2位:チェロ 3位:ビール 4位:ピック & 0.5 & 0.5 & 1.50 \\ \hline
手法2 & 1位:ピック 2位:ビール  3位:ビオラ 4位:チェロ 5位:ギター & 0.6 &
 0.75 & 0.78 \\ \hline
\end{tabular}
\end{center}
\end{table}

簡単な算出例を表\ref{ex-experiment}に示す．この場合，手法1による出力は
4語中2語が正解であるので$適合率=\frac{2}{4}=0.50$，正解セット4語のうち2語が
手法1により出力に含まれているので，$再現率=\frac{2}{4}=0.50$となる．
同様に手法2では$適合率=\frac{3}{5}=0.60$，$再現率=\frac{3}{4}=0.75$とな
り，手法2の方が優位となる．しかし，正解の語が上位にランクされている手法1の方が
手法としての実用性が高い，とも考えられる．このような場合に各手法の
Inverse Rank Scoreを求めると手法1では，$\frac{1}{1}+\frac{1}{2}=1.50$，
手法2では$\frac{1}{3}+\frac{1}{4}+\frac{1}{5}=0.78$となり，
手法1の方が優位となる．

このように適合率，再現率に加え，Inverse Rank Scoreを用いることで，
順位を加味した評価を行うことができる．\cite{Widdows02,Curran02}．



\subsubsection{既存シソーラスを用いた正解セットの作成}
本論文では，Curranら\cite{Curran02}の手法を元にして，
提案手法と既存のシソーラスを比較を行う．そのために，正解セット作成用シソーラ
スと比較用シソーラス，2種類のシソーラスを用意する．
まず，正解セット作成用シソーラスから関連語を取り出し，正解セットを作成する．
この正解セットの語群に対して提案手法と比較用シソーラスを適用して関連語の
分類を行う．その結果，どの程度正しく語群が関連語群に分類されるかによって
提案手法と既存シソーラスとの比較を行う．
本論文では，Curranらが用いたRoget's Thesaurusの最新版である
Roget's Millenium Thesaurus~\cite{RogetMillenium}を正解セット作成用のシソー
ラスとして用い，
WordNet及びMoby Thesaurus~\cite{MobyThesaurus}を比較用のシソーラスとして
用いる．

Roget's Millenium Thesaurusは見出語を持ち，その見出語がそれぞれ関連語
群を持つ，という2層構造をしたシソーラスである．
本実験においては，1つの見出語から取り出される関連語群をそのまま正解の関
連語群とした．ただし，比較用シソーラスに含まれない語は除くものとする．
関連語の例は表\ref{WordNetExample}のようになる．
今回，見出語としてはTOEIC最頻出英単語リスト
    \footnote{http://www.linkage-club.co.jp/ExamInfo\&Data/toeic.htm}に含まれ
る名詞の計220語を用いる．
これらの見出語から無作為に10語選び，その10語からそれぞれ関連語群を取り出
し，1組の関連語正解セットとする．
本実験では，計10組の正解セット$Aw_i(i=1,2,...,10)$を作成した．


また比較用のシソーラスを用いた関連語群の分類では，算出した関連度に基づい
て行うのではなく，各2語が比較用シソーラスで関連語とされているか，いないかの
2値的な判定によって行うものとする\footnote{WordNetを用いて2語の関連度を算出する方法もあるが，
予備実験により関連語の分類には適さないことが判明したので，
本論文では採用しなかった．}．
この際，どの2語を関連語とみなすかは，シソーラスの構造によって違う方法を
用いた．
Roget's Thesaurusと同様に見出語と関連語群の2層構造を持つ
Moby Thesaurusにおいては，見出語とその関連語群同士，
及び同じ見出語を持つ語同士を関連語とみなす．
木構造を持つWordNetにおいては，見出語とHyponyms（下位語），
見出語とHypernyms（上位語）
及び見出語とCoordinate Terms（共通の上位語を持つ語）同士を関連語とみなす．

関連度の評価指標としては，OpenDirectoryを用いる場合と同様に，
適合率とInverse Rank Scoreを用いる．



\begin{table}[t]
\caption{正解用シソーラスから取り出した関連語群}
\label{WordNetExample}
\begin{center}
\begin{tabular}{l l}
\hline
見出語 & 関連語群 \\ \hline
access & admission, contact, door, entrance, entree, \\
	& ingress, introduction, open door, road, route,  \\
election & acclamation, appointment, by-election, referendum \\
		 & polls, primary , selection, voting \\
pollution & abuse, contamination, corruption, decomposition, uncleanness\\
	 & dirtying, impurity, infection, rottenness, spoliation\\ 
agriculture & agronomy, culture, horticulture, tillage, husbandry \\ \hline
\end{tabular}
\end{center}
\end{table}

\subsection{関連度の指標の評価}


関連度の指標に関する評価を行う．
提案手法では，関連度の計算に$\chi^2$値を用いているが，この有効性を示すた
め，相互情報量，Jaccard係数を用いた関連度と比較する．
検索エンジンを利用する際，日本語のみを扱うOpenDirectoryによる正解セットでは，
検索時のオプションとして「日本語のページを検索」を選択した値を用い，
英語のみを扱う既存のシソーラスによる正解セットでは検索時のオプションとし
て「ウェブ全体から検索」を選択した値を用いる\footnote{Googleではオプショ
ンによって検索するページの対象範囲をコントロールできる．}．

また，コーパスを用いて学習する手法との比較も行う．コーパスを用いる手法で
は，tfidf値を要素とする単語ベクトルを用い，計算指標としてはcosineを用いた．実験の手順を以下に示す．

\begin{enumerate}
\item 正解セット$A_i$に含まれる全ての語について，各指標ごとに2語の関連度
      を計算する（比較用シソーラスを用いる際はこの手順は省略）．
\item 各指標ごとに語$w_i$と関連度の高い上位9語を$A_i$から選び，それを語
      $w$の関連語群$G_{w}$とする（比較用のシソーラスを用いる場合は，
      比較用シソーラスにおいて語$w_i$の関連語とされる語を全て取り出し，
      $G_{w}$とする）．$G_{w}$と正解セットを比較し，適合率を計算する．
\item (2)を語$w_i \in A_i$全てについて行い，指標ごとに適合率の平均値を算出する．
\item (1)から(3)を正解セット$A_i(i=1〜n)$について行う．
\end{enumerate}

OpenDirectoryから作成した正解セットの適合率の平均値を表\ref{result-word}に，
Inverse Rank Scoreの平均値を表\ref{result-word-inv}に示す．

\begin{table}[b]
	\begin{center}
	 \caption{OpenDirectoryを用いた正解セットでの適合率}
	 \label{result-word}
	 \begin{tabular}{c|c|c|c|c}
	  正解セット/指標 & cosine & 相互情報量 & Jaccard係数 & $\chi^2$値 \\ \hline
	セット$Ao_1$ & 0.557 & 0.447 & 0.424 & 0.567 \\ 
	セット$Ao_2$ & 0.513 & 0.406 & 0.389 & 0.493 \\ 
	セット$Ao_3$ & 0.519 & 0.396 & 0.376 & 0.539 \\ 
	セット$Ao_4$ & 0.561 & 0.404 & 0.417 & 0.569 \\ 
	セット$Ao_5$ & 0.529 & 0.421 & 0.404 & 0.519 \\ \hline
	  平均 & 0.535 & 0.415 & 0.402 & 0.538 \\ 
	 \end{tabular}
    \vspace{\baselineskip}

	 \caption{OpenDirectoryを用いた正解セットでのInverse Rank}
	 \label{result-word-inv}
	 \begin{tabular}{c|c|c|c|c}
	  正解セット/指標 & cosine & 相互情報量 & Jaccard係数 & $\chi^2$値 \\ \hline
	セット$Ao_1$ & 2.42 & 1.58 & 1.63 & 2.36 \\ 
	セット$Ao_2$ & 2.41 & 1.90 & 1.43 & 2.75 \\ 
	セット$Ao_3$ & 1.97 & 1.09 & 1.02 & 1.64 \\ 
	セット$Ao_4$ & 2.29 & 2.04 & 1.84 & 2.52 \\ 
	セット$Ao_5$ & 1.70 & 2.17 & 1.83 & 2.20 \\ \hline
	  平均 & 2.16  & 1.76 & 1.55 & 2.29 \\ 
	 \end{tabular}
	\end{center}
\end{table}
まず，検索エンジンを用いた手法同士で比較すると，
どの正解セットにおいても$\chi^2$値が
他の2つの計算指標よりもよい適合率，Inverse Rank Scoreを示している．
これより，$\chi^2$値が検索エンジンを用いる手法の関連度の指標として
有効であることが分かる．
また，コーパスを用いて学習した手法であるcosineと検索エンジンを用いた手法を比較すると
Jaccard係数，相互情報量はcosineよりも低い適合率，Inverse Rank Scoreである．
cosineと$\chi^2$値を比較すると正解セットによって2つの評価指標の優劣が変化している．
しかし，平均ではほとんど
差がないことから，$\chi^2$値とcosineはほぼ同じ適合率であると考えられる．
ただし，コーパスから学習する手法ではコーパス中に出現する語しか扱えないという欠点を持つのに対し，
検索エンジンを用いる手法ではWeb上に出現するほとんどの語を扱うことができる．
そのため同じ適合率ならば，$\chi^2$値を計算指標として検索エンジンを用いる手法の方が優れていると言える．

また，表\ref{result-word}, \ref{result-word-inv}において，
5つの正解セットにおける標準偏差（式\ref{hensa}）を求める．

\begin{equation}
\label{hensa}
\sigma^2=\frac{1}{n} \sum_{i=1}^{n}\left(x_i - \bar{x}\right) 
\left(\bar{x} :x_iの平均値\right)
\end{equation}

すると適合率の標準偏差は0.014，
Inverse Rank Scoreの標準偏差は0.12であり，いずれも
標準偏差は10\%以内に収まっている．
このことから，正解セットによる
ばらつきによる影響はあまり大きくないと考えられる．


次にRoget's Thesaurusから作成した正解セットを用いた既存シソーラスと提
案手法の比較実験の結果を表\ref{result-wordnet}と
    \ref{result-wordnet-inv}に示す．
ただし，比較用シソーラスにおいては，全ての関連語が等価に
扱われており順位が存在しないため，Inverse Rank Scoreの算出は省略する．

\begin{table}[b]
	\begin{center}
	 \caption{既存シソーラスを用いた正解セットでの適合率}
	 \label{result-wordnet}
	 \begin{tabular}{c|c|c|c|c}
	  正解セット/指標 & シソーラス & 相互情報量 & Jaccard係数 & $\chi^2$値 \\ \hline
	  セット$Aw_1$ & 0.385 & 0.324 & 0.374 & 0.405 \\
	  セット$Aw_2$ & 0.375 & 0.322 & 0.311 & 0.353 \\
	  セット$Aw_3$ & 0.342 & 0.365 & 0.402 & 0.411 \\
	  セット$Aw_4$ & 0.370 & 0.291 & 0.295 & 0.320 \\
	  セット$Aw_5$ & 0.438 & 0.459 & 0.487 & 0.515 \\
	  セット$Aw_6$ & 0.339 & 0.390 & 0.369 & 0.374 \\
	  セット$Aw_7$ & 0.391 & 0.287 & 0.335 & 0.345 \\
	  セット$Aw_8$ & 0.290 & 0.337 & 0.330 & 0.339 \\
	  セット$Aw_9$ & 0.468 & 0.295 & 0.279 & 0.316 \\
	  セット$Aw_{10}$ & 0.444 & 0.375 & 0.368 & 0.390 \\ \hline
	  平均  & 0.392 & 0.345 & 0.349 & 0.369 \\
	 \end{tabular}
    \vspace{\baselineskip}

	 \caption{既存シソーラスを用いた正解セットでのInverse Rank}
	 \label{result-wordnet-inv}
	 \begin{tabular}{c|c|c|c}
	  正解セット/指標 & 相互情報量 & Jaccard係数 & $\chi^2$値 \\
	  \hline
	  セット$Aw_1$ & 1.260 & 1.277 & 1.441 \\
	  セット$Aw_2$ & 1.145 & 1.263 & 1.290 \\
	  セット$Aw_3$ & 1.329 & 1.390 & 1.477 \\
	  セット$Aw_4$ & 1.184 & 1.006 & 1.144 \\
	  セット$Aw_5$ & 1.526 & 1.453 & 1.572 \\
	  セット$Aw_6$ & 1.498 & 1.273 & 1.241 \\
	  セット$Aw_7$ & 1.250 & 1.183 & 1.255 \\
	  セット$Aw_8$ & 1.337 & 1.354 & 1.432 \\
	  セット$Aw_9$ & 1.033 & 1.101 & 1.298 \\
	  セット$Aw_{10}$ & 1.320 & 1.313 & 1.301 \\ \hline
	  平均  & 1.288 & 1.255 & 1.3321 \\ 
	 \end{tabular}
	\end{center}
\end{table}



まず，Webを用いる手法同士を比較すると，OpenDirectoryを用いた正解セットと
比べて適合率の差が小さくなってはいるが，
シソーラスを用いた正解セットにおいても，
$\chi^2$値が他の計算指標よりよい数値を示している．
これより，提案手法の優位性は小さくなるものの，
Web上での出現頻度にばらつきの少ない汎用的な語に対しても，
提案手法が有効であることがわかる．


次に$\chi^2$値と既存のシソーラスを比較すると，
既存のシソーラスの精度の方が若干高い数値を出してはいるものの，
ほぼ同程度の精度・適合率が得られている．
これより，関連語を同定するタスクにおいて，
提案手法を用いることで既存シソーラスと同程度の効果が得られると言える．

以上より，提案手法を用いることで，検索エンジンを用いた既存手法やコーパスから学習する手法よりも
適切に関連度を算出することができていると考えられる．
ただし，コーパスから学習する手法ではcosine以外の計算指標を用いた手法があるため，
今後それらの指標とも比較する必要がある．


\subsection{クラスタリングの評価}

次に，クラスタリングの評価を行う．
提案手法ではNewton法を用いているが，
比較手法としては，群平均法を距離関数とする階層的クラスタリングを用いる．

クラスタリング手法の評価手法を以下に示す．

\begin{enumerate}
\item 正解セット$A_i$に含まれる全ての語について，2語の関連度を計算する．
\item 関連度をもとに関連語ネットワークを構築する．その際，ネットワークの密度が$0.3$
\footnote{$\chi^2$値による関連度を用いた関連語ネットワークの密度の平均値が約$0.3$であるため．}になるように
関連度の低いエッジを切る．ネットワークの密度とは，エッジ数を存在し得る最大のエッジ数（ノード数を$n$とすると$_n C_2$）で割ったものである\cite{Scott00}．
\item 提案手法及び比較手法により，クラスタリングを行う．今回は，使用したカテゴリ数が$9$であるため，
群平均法はクラスタ数が$9$になった時点でクラスタリングを終了とする．
また，本実験では条件を均一化するためにNewman法においても終了条件を
    $\Delta Q < 0$ではなくクラスタ数9とする．
\item 同一クラスタに属する2語は関連語，異なるクラスタに属する2語は非関連語とする．
この結果を正解セットと比較し，適合率・再現率・F値を求める．
\item (1)から(4)を正解セット$A_i(i=1〜n)$について行う．
\end{enumerate}



\begin{table}[b]
	\begin{center}
	 \caption{関連語抽出実験結果（上段：適合率 \ 中段：再現率
	\  下段：F値）　OpenDirectory使用}
	\label{result-cluster}
	 \begin{tabular}{c|c|cccc}
	  クラスタリング &  & cosine  & 相互情報量 & Jaccard係数 & $\chi^2$値 \\ \hline
	  群平均法 & 適合率  & 0.772 & 0.864 & 0.848 & 0.812 \\ 
	           & 再現率  & 0.209 & 0.222 & 0.208 & 0.221 \\     
	           & F値     & 0.328 & 0.353 & 0.333 & 0.347 \\ \hline
	  Newman法 & 適合率  & 0.815 & 0.792 & 0.797 & 0.738 \\ 
	           & 再現率  & 0.344 & 0.332 & 0.346 & 0.631 \\ 
	            & F値    & 0.483 & 0.465 & 0.482 & 0.680 \\ \hline
	 \end{tabular}
    \vspace{\baselineskip}

	 \caption{関連語抽出実験結果（上段：適合率 \ 中段：再現率
	\  下段：F値）　Roget's Thesaurus使用}
	\label{result-cluster-wordnet}
	 \begin{tabular}{c|c|ccc}
	  クラスタリング &  & 相互情報量 & Jaccard係数 & $\chi^2$値 \\ \hline 
	  群平均法 
	  & 適合率 & 0.887 & 0.861 & 0.852 \\ 
	  & 再現率 & 0.174 & 0.186 & 0.184 \\ 
	  & F値    & 0.291 & 0.305 & 0.302 \\ \hline
	  Newman法 
	  & 適合率 & 0.688 & 0.705 & 0.598 \\ 
	  & 再現率 & 0.329 & 0.302 & 0.411 \\ 
	  & F値    & 0.440 & 0.419 & 0.485 \\ \hline
	 \end{tabular}
	\end{center}
\end{table}

OpenDirectoryによる正解セットを用いた評価結果を表\ref{result-cluster}に，
Roget's Thesaurusによる正解セットを用いた評価結果を表\ref{result-cluster-wordnet}に示す．
示されている値はそれぞれ，5個のOpenDirectory正解セット$Ao_i(i=1〜5)$と
10個のRoget's Thesaurus正解セット$Aw_i(i=1〜10)$について
実験を行った結果の平均値である．
各計算指標の群平均法とNewman法の結果を比較すると，いずれも群平均法では適
合率が高く，再現率が低い．
クラスタリングの評価では一般的なことであるが，
これは1つのクラスタにほとんどの語が含まれ，残り8つのクラスタにそれぞれ1〜3語程度の語が含まれている状態と考えられる．
例えば，極端な例ではクラスタ内の語数が1であれば適合率が$\frac{1}{1}=1.0$
になる．そのため，
含まれている語数の少ないクラスタが多数できる手法の方が精度が上がりやすい．
しかし，再現率やF値で見ると，各クラスタに含まれる語数が均等に近くなるようなクラスタリング手法の評価が高くなる．


表\ref{result-cluster}, 表\ref{result-cluster-wordnet}から群平均法の代わりにNewman法を用いることで，
いずれの指標においてもF値が高くなっている．
このことから，提案手法を用いることでより適切に語がクラスタリングされていると言える．
ただし，群平均法がこの実験に適していない可能性も考えられるので，
今後他の手法との比較を行う必要がある．
Newman法を用いた場合の各指標を比較すると，表\ref{result-cluster}, 表\ref{result-cluster-wordnet}いずれにおいても，
$\chi^2$値が最も良いF値を示している．これより，語のクラスタリングを行う関連語ネットワークの構築には
$\chi^2$値による関連度を用いることが適切であると言える．

次に評価手法(3)におけるNewman法の終了条件を「クラスタ数9」とした場合と
「$\Delta Q<0 $」とした場合の評価実験結果を表\ref{final-condition}
に示す．
またその際の正解セットごとのクラスタ数のグラフを図\ref{cluster-num}に示
す．

\begin{table}[b]
	\begin{center}
	 \caption{終了条件による比較($\chi^2$)（上段：適合率 \ 中段：再現率
	\  下段：F値）}
	\label{final-condition}
	 \begin{tabular}{c|cc|cc}
	  & \multicolumn{2}{c|}{OpenDirectory} &
	  \multicolumn{2}{c}{WordNet} \\ \hline
	  & クラスタ数指定 & 自動終了($\Delta Q<0 $) & クラスタ数指定 &
	  自動終了($\Delta Q<0 $) \\ \hline 
	 
	  適合率 & 0.738 & 0.601 & 0.598 & 0.470 \\ 
	  再現率 & 0.631 & 0.911 & 0.411 & 0.591 \\ 
	  F値    & 0.680 & 0.722 & 0.485 & 0.520 \\ \hline
	 \end{tabular}
	\end{center}
\end{table}

表\ref{final-condition}より，終了条件を「$\Delta Q<0$」とした方が
「クラスタ数指定」とした場合よりも高いF値を示している．
しかし，その差は4ポイント程度であり，精度に大きな違いはないといえる．
これより，提案手法においては，条件としてクラスタ数を与えない場合でも，
与えた場合とほぼ同程度の精度で
関連語のクラスタリングを行うことができることがわかる．

\begin{figure}[b]
 \begin{center}
  \includegraphics[width=8cm,clip]{cluster.eps}
 \end{center}
 \caption{クラスタ数　横軸：正解セット　縦軸：クラスタ数}
  \label{cluster-num}
\end{figure}
\begin{table}[b]
\caption{クラスタリング結果の具体例}
\label{cluster-example}
\begin{center}
\begin{tabular}{l|c|c}
終了条件 & クラスタ名   &  \\ \hline
クラスタ数指定 & クラスタ$A_1$ & 情報処理，方法論，実証，ソースコード，文字コード，初期値 \\ 
\cline{2-3}
              & クラスタ$A_2$ & 無料レンタル，掲示板，アクセス数 \\ \hline
$\Delta Q<0$ & クラスタ$B$ & 情報処理，方法論，実証，ソースコード，文字コード \\ 
 & &  初期値，無料レンタル，掲示板，アクセス \\ \hline
\end{tabular}
\end{center}
\end{table}



ただし，今回の実験ではそれぞれの終了条件によって違う傾向を持っている．
「クラスタ数指定」では，$適合率 > 再現率$となっているが，
「$\Delta Q<0$」では，$適合率 < 再現率$となっている．
これは，終了条件によるクラスタ数の違いと
Webを用いて関連度を算出する際に必ずしも目的とする語の関連性が得られないた
めである，
これに関して，クラスタリング結果の具体例を
表\ref{cluster-example}に示す．
ここに用いられている語は表\ref{ex-experiment}に示されている語である．

本実験では，表\ref{ex-experiment}より，表\ref{cluster-example}の正解セッ
トでは「科学」及び「コンピュータ」という関連性によっ
てクラスタリングされることが想定されている．
しかし，実際には
「クラスタ数指定」のクラスタ$A_1$に含まれる語は，「情報科学」及び
「プログラミング」という共通の関連性を持っていると考えられる．
クラスタ$A_2$に含まれる語は「Web掲示板」という共通の関連性を持っていると
考えられる．
また「$\Delta Q<0$」では，クラスタ$A_1, A_2$が1つにマージされ
$クラスタB$を構成している．

このように提案手法では，正解セットで目的としている関連性とは
異なる関連性に基づいてクラスタリングされる場合が多い．
これはクラスタリング手法によるものではなく，主に算出された関連度による
ものである．
実際には，クラスタ$A_1$のように2つ以上のカテゴリの語で構成されるクラスタ
やクラスタ$A_2$のように1つのカテゴリの語の一部のみで構成されるクラスタな
ど，正解セットのカテゴリ分けとは異なるクラスタができてしまっている．
今回の実験においては，「クラスタ数指定」ではクラスタ$A_2$のような
クラスタが多かったために$適合率 > 再現率$となっている．
また，クラスタ数の少なかった「$\Delta Q <0$」では
クラスタ$B$のようなクラスタが多かったために$適合率 < 再現率$となっている．

以上より，提案手法の精度を高めていくためには，
目的にあわせた関連度を取得する手法と
より適切にクラスタ数を自動取得する手法が必要となってくる．



また，ネットワークのノード数とクラスタリングの実行時間の関係を図\ref{scalable}に示す\footnote{実行環境　CPU:Pentium4 3.0Ghz　メモリ:1GB}．
基準線は，$x$をノード数，$z$をエッジ数とするとき，式$y=1.8 \times 10^{-8} x(z+x)$のあらわす曲線である（$1.8 \times 10^{-8}は比例定数）$．
図\ref{scalable}で実測値と基準線を比較するとほぼ一致しており，確かにNewman法の計算量が
$O(n(m+n))$に比例している．そして，$n=4029$, $m=7146169$のとき実行時間は$532$秒であり，
$n,m$が大きい大規模ネットワークにも提案手法が適用可能であると考えられる．


\begin{figure}[t]
 \begin{center}
  \includegraphics[width=8cm,clip]{scale.eps}
 \end{center}
 \caption{ノード数と実行時間　横軸：ノード数　縦軸：実行時間（秒）}
  \label{scalable}
\end{figure}


以上の評価実験の結果より，提案手法について以下の3点を述べることができる．
\begin{itemize}
\item 既存手法よりも適切に関連語のクラスタリングを行うことができる
\item クラスタ数が未知の場合でも，クラスタ数が既知の場合と同程度の精度で
      関連語のクラスタリングを行うことができる
\item 大規模なネットワークにも適用可能である
\end{itemize}



