関連研究


語の関連性を自動的に得る方法は，これまでにさまざまな研究が行われている．
コーパス中での語の共起情報をもとに語の関連度を測る指標として，様々なものが提案され用いられており
\cite{Church90,Wettler93,Croft99,Curran02-2}，それらは大きく2つに分けられる．
1つは単語ベクトルを用いたベクトル空間手法である．
これは，単語を多次元ベクトル空間の単語ベクトルで表現し，
それぞれの単語ベクトルを比較することで関連度を測る手法である．
ベクトル空間手法では，表\ref{CompareMethod}のようにベクトルの内積をもとにした計算指標が用いられている．
表\ref{CompareMethod}において，$x_i,y_i$はそれぞれ単語ベクトル$\vec{x},\vec{y}$の$i$番目の要素を表す．
なお，overlap係数はバイナリベクトルにしか用いることはできない．
単語ベクトルの要素の取り方は研究によって様々であり，
各文書への出現頻度を要素とするベクトルや
各単語との共起頻度を要素とするベクトルなどが考えられる．
ただし，独立な事象の確率は足し合わせることができないため，
内積を用いる関連度では，語の出現確率を単語ベクトルの要素とすることは不適切と考えられる．


もう1つはコーパス中での確率を用いる確率手法である．
この手法では，2語がコーパス中で共起する確率をもとに
関連度を算出している．確率手法で用いられている計算指標を表\ref{CompareMethod}に示す．
表\ref{CompareMethod}において，$p(w \cap w')$は語$w,w'$の共起確率を表し，
$p(w \cup w')$は語$w,w'$のどちらかが出現する確率を表す．
また$f$は\cite{Lin98a}で定義されている関数であり，$f(w,r,w')$は語$w,w'$が$r$の関係を持って
出現する頻度を，$f(*,r,w')$は語$w'$がいずれかの語と$r$の関係を持って出現する頻度を表す．
これらの計算指標は，ベクトル空間手法で用いられている指標を書き換えたものが多い．
また，単語同士の共起確率ではなく，
各単語が他の語と共起する確率の確率分布関数の類似性を
用いて関連度を算出する研究も数多く行われている\cite{Brown92,Baker98,Slonim00}．
確率分布関数を用いた類似度は，確率分布類似度(Distributional Similarity)と呼ばれる．
類似した名詞は共通した動詞と共起すると仮定し，動詞との共起分布の類似性
から関連度を算出している．

\begin{table}[b]
 \begin{center}
  \caption{類似度の計算指標}
    \label{CompareMethod}
  \begin{tabular}{|c|c|c|c|}
   \hline
    \multicolumn{2}{|c|}{ベクトル空間手法} & \multicolumn{2}{|c|}{確率手法} \\ \hline
   cosine &
       $\frac{\vec{x} \cdot \vec{y}}{\sqrt{|\vec{x}||\vec{y}|}}$ &
   相互情報量 & 
   $\log \left( \frac{p(w \cap w')}{p(w)p(w')}\right)$  \\ \hline

   dice & 
   $\frac{2(\vec{x} \cdot \vec{y})}{\sum(x_i+y_i)}$ &
   dice & 
   $\frac{2p(w \cap w')}{p(w \cup w')}$ \\ \hline

   Jaccard & 
   $\frac{\vec{x} \cdot \vec{y}}{\sum(x_i+y_i)}$ &
   Jaccard & 
   $\frac{p(w \cap w')}{p(w \cup w')}$  \\ \hline

   overlap & 
   $\frac{|\vec{x} \cap  \vec{y}|}{min(|\vec{x}|,|\vec{y}|)} $ &
   T検定 & 
   $\frac{p(w \cap w')-p(w')p(w)}{\sqrt{p(w')p(w)}}$ \\ \hline

       Lin$^{*1}$ & 
   $\frac{\sum(x_i+y_i)}{|\vec{x}| + |\vec{y}|}$ & 
       Lin98A$^{*2}$\footnotemark &
   $\log \left(\frac{f(w,r,w')f(*,r,*)}{f(*,r,w')f(w,r,*)}\right)$ \\   \hline   
\multicolumn{4}{l}{$^{*1}$ \cite{Lin98a}で提案されている手法．}\\
\multicolumn{4}{l}{$^{*2}$ \cite{Lin98a}で提案されている手法．}
   \end{tabular}
  \end{center}
\end{table}


語の関連度が得られれば，関連度に基づいて語をクラスタリングすることで関連語が得られる．
実際には，同じクラスタに分類された語同士を関連語や同義語であるとしている．
語のクラスタリングには分布クラスタリング(Distributional Clustering)が用いられることが多い．
分布クラスタリングとは，類似した名詞は共通した動詞と共起すると仮定し，
各語の動詞との確率分布の類似度に基づいて，
データを結合もしくは分割していくクラスタリング手法である\cite{Pereira93,HangLi98,Dhillon02}．

これらコーパスから関連度を自動的に算出する手法では，コーパス内に出現する
語しか扱えないという欠点がある．
そのため，広範囲の語をカバーするためには，広範囲の内容をカバーする
コーパスが必要となる．

近年では，より広範囲の語をカバーするためにWebをコーパスとして用いることが提案されている．
しかしWeb上の文書は莫大であり，直接収集し，解析するためには非常に大きな時間コストと
設備コストがかかる．そのため，Web全体での語の出現頻度や2語の共起頻度を獲得するためには
従来のコーパスを用いたシソーラス構築とは異なる工夫が必要である．
そのような工夫の一つとしてKilgarriffらは検索エンジンを用いた
手法を紹介している\cite{Kilgarriff03}．「語$w_a$」をクエリーとして検索エンジンを利用すると，
語$w_a$のWeb上でのヒット件数が得られる．検索エンジンは非常に多くのページを
クローリングしているため，このヒット件数を語$w_a$のWeb全体での出現頻度と近似できる．
同様にして，「語$w_a$ and 語$w_b$」をクエリーとすれば，
Web上での語$w_a$と語$w_b$の共起頻度を獲得することができる．

検索エンジンから獲得できる頻度情報を用いて関連度を算出する手法としては，次のようなものがある．
Heylighenは検索エンジンのヒット件数を用いた語の関連度の尺度により，語の分類や語の曖昧性解消，より優れた検索エンジンの開発
の可能性を示唆している\cite{Heylighen01}．
BaroniやTuerneyは，類義語を同定するために，検索エンジンを用いた語の関連性の尺度を提案している\cite{Baroni04,Turney01}．
Turneyはその結果を用いることでTOEFLのシソーラスの問題で平均的な学生よりもよい得点を挙げたことを報告している．
佐々木らは検索エンジンの上位ページとヒット件数を利用した専門用語集の自動構築を行っている\cite{Sasaki05}．
Szpektorは名詞ではなく動詞の関連度を検索エンジンを用いて定義している\cite{Szpektor04}．
これら検索エンジンを用いて関連度の計算を行っている研究では，条件付き確率や表\ref{CompareMethod}の確率手法で定義されているような
相互情報量，Jaccard係数が計算指標として用いられている．


