\section{関連研究} \label{Sec:関連研究}

領域適応は，学習に使用する情報により，supervised，semi-supervised，unsupervisedの
三種に分けられる．まずsupervisedの領域適応は，訓練事例として
少量のターゲットドメインだけでなく大量のソースドメインのデータを加えて
学習を行うもので，
訓練事例としてソースデータまたは少量のターゲットデータだけを利用する場合よりも，分類器を改良することを目指す．
次のsemi-supervisedの領域適応は，ラベルつきのソースデータに加え，
ラベルなしのターゲットデータを利用し，
訓練事例としてソースデータだけを利用する場合よりも，分類器を改良することを目指す．
また，最後のunsupervisedの領域適応は，ラベルつきのソースデータで学習後，ターゲットデータで実行する．
本研究で扱うのは，supervisedの領域適応である．

領域適応の研究は様々な分野で研究が行われており，
ここではその一部を紹介する．まず，\cite{article2}は，EMアルゴリズムによる
語義の事前確率推定によりWSDの領域適応を行っている．
\cite{article3}も，EMアルゴリズムによる事前確率推定を行っているが，
これは能動学習により事例をターゲットドメインから加えるsupervisedの領域適応である．
Count-mergingにより重要文に重みをつけることで，性能を向上させている．

また，
\cite{article4}はシーケンスラベリングを例にsupervisedの領域適応を行っている．
素性空間の次元を「ソースデータの素性空間」「ターゲットデータの素性空間」
「ソースデータとターゲットデータ共通の素性空間」に相当する三倍にし，モデルを三倍に拡張して実験を行うというもので，
様々なsupervisedの領域適応に併用できる手法である．利点として，上記の併用可能性に加え，
実装が簡単で処理が速いこと，マルチドメインに拡張が簡単（素性空間の次元をドメイン数+1倍にすればよい）
であることが挙げられる．

さらに，\cite{article12}は\cite{article4}をsemi-supervisedのために拡張した．
この手法がなぜ有効なのかはまだ解き明かされていないが，拡張前の利点を引き継いでいるだけでなく，
ラベルなしのターゲットデータを利用することでよりよい性能が得られる．

\cite{article5}は，semi-supervisedのWSDの領域適応を行った．大量のラベルなしのソースデータに，
ラベルなしのターゲットデータを加えて行列を作り，特異値分解 (SVD) により素性圧縮をして分類器を学習する手法である．
また\cite{article6}は，大量のラベルなしのソースデータの代わりに，少量のラベルつきのソースデータを使用して，
同様の手法でsupervisedの領域適応を行っている．

\cite{article7}は領域適応を行う際，事例の重み付けにより性能が向上することを示した．
この手法は様々なsupervisedまたはsemi-supervisedの領域適応との併用が可能である．
また，領域適応に悪影響を及ぼすソースデータを特定して削除することも試みているが，
ソースデータの削除は事例の重み付けを
行わなければ有効であるが，事例の重み付けを行った場合には有効ではないと結論づけている．

\cite{article14}はターゲットデータとソースデータの周辺確率を似せるようにカーネル空間を学習した後，条件確率が
ターゲットデータに似ているソースデータの事例をクラスタリングベースの事例選択を用いて選び，その事例を利用して
領域適応を行っている．


\cite{article15}はWeb上からランダムに取得したラベルなしデータを利用して，より高いレベルの素性を作成するために
スパースコーディングを利用したself-taught learningを提案している．これはunsupervisedの領域適応の一種である．

\cite{article16}はco-trainingにおいて領域適応を行ったco-adaptationの研究である．boostingによる線形補完により
領域適応を行い，両方の分類器においてエラー率が低下したことを報告している．

また\cite{article17}はsemi-supervisedの領域適応である．この研究では，ソースデータ中とターゲットデータ中の単語の類似度を
計算するために，pivot feature（ソースデータとターゲットデータの
両方でよく出てくる単語）の周りの単語の重みを計算する．この重みの行列にSVDを適用して新しい素性空間を作り，
オリジナルの素性に新しい素性を加えて使用するという手法をとっている．

本稿に最も近い研究は，\cite{article20}である．この研究では，多様なドメインからなる文書を構文解析する際，最も良いモデルは
異なるという問題に注目している．彼らは様々な混合モデルによる構文解析の正解率を回帰分析で予測し，それぞれのターゲットデータに対して，
最も高い正解率を出すと予測されたモデルを利用して構文解析を行っている．本研究との最も大きな違いは，対象のタスクが構文解析ではなく
語彙曖昧性解消である点である．そのため，本論文ではケースという単位ごとに最適な領域適応を行う．
また，彼らは複数のソースドメインから抽出した用例を混合して訓練事例とした領域適応を想定して
いるが，我々は想定していない．
本研究では決定木学習を用いることで，どのような性質が最適な領域適応の決定に影響を与えるのかについて考察する．

本稿では，ソースデータとターゲットデータの性質をもとに領域適応に用いる手法を自動選択する手法について述べる．
これに関連した研究として \cite{article10}や \cite{article11}
がある．\cite{article10}は，構文解析において，分野間距離をはかり，より適切なコーパスを利用して
領域適応を行えるようにした．また，\cite{article11}は，構文解析において，
自動的にタグ付けされたコーパスを用いて，ソースデータとターゲットデータの類似度から性能を予測できることを示した．
これらの研究では，領域間の距離からソースデータとして利用できるコーパスを選択するという立場をとっているが，
本研究では領域間の距離などの性質から，手法を選択するという立場をとる．



