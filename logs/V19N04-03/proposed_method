WSDは語義を識別するタスクなので，WSDシステムを利用すれば新語義を検出できると考えるのは自然である．
WSDの対象単語[MATH]の語義のクラスを[MATH]とする．
関数[MATH]はあるWSDシステムが出力する用例[MATH]中の[MATH]の語義が[MATH]となる信頼度とする．
このWSDシステムは[MATH]により語義を識別する．
新語義の検出はある閾値[MATH]を定め，
のときに[MATH]を新語義の用例と判定することで，新語義を検出できる．
ただし適切な[MATH]の値は単語毎に異なるはずであり，その設定は困難である．
またWSDは識別のタスクであり，一般にWSDシステムはSVMのような識別モデルをもとに構築される．
そのためシステムは語義の識別精度が上がるように最適化されており，[MATH]の値は[MATH]との相対的なものである．
つまり式([REF_eq:1])により新語義が検出できる保証はない．
例えば図[REF_fig1]のような状況を考えてみる．
図[REF_fig1]のクラス1とクラス2を分離する直線が，分類器に対応する識別境界とする．
データがクラスに属する信頼度は，一般に，識別境界までの距離で測るので，図[REF_fig1]のデータaとデータbはクラス1と識別され，その信頼度は等しくなる．
識別の場合はデータが識別境界のどちら側に属するかだけが重要なので，それで十分であるが，データaとデータbを比べると，明らかにデータbの方がクラス1に属する信頼度が低い．
従来，新語義の検出はWord Sense Induction (WSI)というタスクの一部として行われてきた[CITE]．
WSIは本質的には対象単語の用例を語義に基づいてクラスタリングするタスクである[CITE]．
用例集合中に新語義の用例があれば，それらも語義のクラスターとして出現するために新語義の検出として利用できる．
ただし陽に新語義を検出するには，得られたクラスターに語義のラベルを付与する必要がある[CITE]．
Shiraiは辞書に記述された語義の定義文を利用して，得られたクラスターに語義のラベルを付けることで新語義を検出しようとしている[CITE]．
またSugiyamaは既存語義の用例を種用例として，用例集合を半教師なしクラスタリングによりクラスタリングした[CITE]．
種用例のないクラスターが新語義のクラスターとなる．
ただしどちらもクラスタリング自体の精度が悪く，新語義の検出までには至っていない．
本来，クラスターに語義のラベルを付けるためには，語義のラベル集合が必要である．
語義のラベル集合を定めた場合に，WSIとWSDとの違いはほとんどなくなる．
WSDを行う前に教師なし学習であるクラスタリングを行うアプローチが，新語義の検出に有効かどうかは不明である．
また用例を語義に基づいてクラスタリングする場合，クラスターの数の決め方が大きな問題になる[CITE]．
また新語義がクラスターを形成するという仮定は，多くの新語義に対して当てはまらない．
クラスターを形成するくらいに，その語義の用例が存在するのであれば，その語義は新語義ではなく既に一般的な語義と考えられる．
新語義の用例を用例集合内の外れ値と見なし，外れ値検出の手法を利用して新語義を検出するアプローチがある．
Erkは外れ値検出手法の最近傍法を利用して新語義の検出を試みた[CITE]．
対象単語[MATH]の語義が付与された用例集を[MATH]とし，用例[MATH]の外れ値の度合い[MATH]を式([REF_eq:siki1])で測り，この値が1以上の[MATH]を新語義の用例とした．
ここで[MATH]は用例[MATH]と用例[MATH]間の距離である．
この式は[MATH]の中で[MATH]と最も距離が近いデータ[MATH]を選び，更にその[MATH]と最も距離が近い[MATH]内のデータ[MATH]を選んで，[MATH]と[MATH]の比を取ったものである（図[REF_fig-erk]参照）．
ただし最近傍法が妥当な精度を出すには，大量の訓練データを必要とするという問題がある．
データマイニング分野の外れ値検出手法は非常に多岐にわたるが，その多くは変化点検出の手法に位置づけられる[CITE]．
つまり時系列的にデータが生起するオンラインでのタスクに対する手法が中心である．
新語義検出のようなバッチ的なタスクに対する手法としては，密度ベースの手法，One Class SVM，生成モデルによる手法が代表的な手法である．
ここではこの3つの手法を本論文の提案手法との比較手法とする．
外れ値検出は古典的にはマハラノビス距離を用いた距離ベースの手法が中心だが，それを改良したのが密度ベースの手法であり，密度ベースの代表的な手法がLOFである．
LOFは，データの近傍の密度を利用することで，そのデータの外れ値の度合いを測り，その値によって外れ値を検出する．
LOFにおけるデータ[MATH]における外れ値の度合いを[MATH]と表記する．
ここで[MATH]はデータ全体の集合である．
[MATH]を定義するために，いくつかの式を定義しておく．
まず[MATH]は[MATH]に対する[MATH]距離と呼ばれる値で，以下の条件を満たすデータ[MATH]との距離[MATH]として定義される．
少なくとも[MATH]個のデータ[MATH]に対して[MATH]が成立する．
高々[MATH]個のデータ[MATH]に対してのみ[MATH]が成立する．
直感的には，上記のデータ[MATH]はデータ[MATH]からの[MATH]番目に近いデータとなる．
データ[MATH]から同じ距離を持つデータが複数存在する場合を考慮して，上記のようなテクニカルな定義になっている．
次に[MATH]を利用して，[MATH]，[MATH]及び[MATH]を定義してゆく．
これは[MATH]の[MATH]近傍と呼ばれる集合であり，[MATH]との距離が[MATH]以下になるようなデータの集合である．
これは[MATH]から[MATH]への距離を表すが，[MATH]が[MATH]の[MATH]近傍内に入る場合に，その距離を[MATH]で置き換えている．
直感的にはデータ間の距離が近い場合に，[MATH]距離で補正している．
これは[MATH]の[MATH]近傍内のデータ[MATH]の[MATH]の平均の逆数であり，これが[MATH]の密度を表している．
これらの式を用いて，[MATH]は以下で定義される．
つまり[MATH]の[MATH]近傍内のデータの密度と[MATH]の密度の比の平均を外れ値の度合いとしている．
直感的には近くのデータの密度は高く，自身の密度が低い場合に外れ値の度合いが高くなる．
また「近くのデータの密度は高く，自身の密度が低い」というのは，ある密度の高いクラスターがあり，そこから離れている独立のデータであるような場合である．
例えば図[REF_lof-ex]では，データaとデータbが外れ値である．
距離ベースの手法では，データbは外れ値として検出できるが，データaはクラスターAとの距離が近いために検出できない．
一方LOFでは，クラスターAの密度が高く，データaの近辺にはデータがなく孤立しているので，外れ値として検出できる．
またLOFではパラメータとして[MATH]が存在する．
本論文では[MATH]としている．
One Class SVMは[MATH]SVM [CITE]を利用した外れ値検出の手法である[CITE]．
すべてのデータは[MATH]のクラスに属し，原点のみが[MATH]のクラスに属するとして，[MATH]SVMを使って2つのクラスを分離する超平面を求める．
原点はすべての点に対して類似度が0となるために，外れ値とみなせる．
また[MATH]SVMはソフトマージンを利用するので，[MATH]のクラス側に属するデータを外れ値と判定する．
図[REF_ocs-ex]で概略を説明する．
図の星形の点が外れ値である．
原点は全ての点と内積が0となる，つまり類似度が0であるために外れ値と考える．
図の星形の点（外れ値）も含め，原点以外のすべての点を正常値と考え，外れ値と正常値を分離する超平面を[MATH]SVMで求める．
[MATH]SVMはソフトSVMであり，教師データのすべての点を正確に分離するわけではなく，少数の誤りを認める．
図では原点付近に超平面（この場合，直線）を近づければ，識別の精度は向上するが，その場合，最大マージンが小さくなる．
最大マージンを大きくしようとすると，識別の精度は下がる．
このバランスをうまくとるような超平面を求めるのが[MATH]SVMである．
最終的に原点側に属するデータが外れ値と判断される．
One Class SVMを利用する際には，用いるカーネル関数やどの程度のマージンの誤りを認めるかのパラメータの設定が結果に大きく影響する．
本論文の実験ではOne Class SVMのプログラムとしてLIBSVMを用いた．
カーネルは線形カーネルを利用し，マージンの誤りはパラメータ[MATH]に対応するが，[MATH]で固定した．
データ[MATH]の生成過程を確率モデル[MATH]でモデル化したものを生成モデルと呼ぶ．
一般に潜在変数[MATH]を導入し，ある確率モデル[MATH]の混合分布により[MATH]をモデル化する．
モデル化の後に，与えられたデータからEM法などを利用して，[MATH]と[MATH]のパラメータを推定することで[MATH]を構成する．
データ[MATH]の外れ値の度合いとしては[MATH]が用いられる．
この値が大きいほど外れ値と見なせる．
一般に外れ値検出のタスクでは外れ値の定義が不可能である．
これは外れ値にラベルをつける意味がないことを示している．
なぜなら仮にあるデータが外れ値であり，その外れ値にラベルをつけることができたとしても，他の外れ値がそのラベル付きの外れ値と類似している保証がないからである．
また検出元となるデータ集合は，ほぼすべて正常値である．
仮にデータにラベルをつけるとすれば，正常値のラベルだけになり，教師データに意味はない．
これらのことから外れ値検出の手法は教師なしの枠組みにならざるをえない．
しかし新語義の用例を外れ値と見なした新語義検出のタスクの場合，一般の外れ値検出とは異なった2つの特徴がある．
1つは外れ値の定義が明確という点である．
ここでの外れ値は新語義の用例であるが，新語義とは「辞書に記載されていない語義」というように明確に定義できる．
もう1つは正常値のデータは語義のクラスターに分割されるという点である．
しかもクラスターの数も明確である．
一方，通常の外れ値検出では正常値の集合がクラスターに分割されるのか，されるとしてもいくつのクラスターに分割されるのかは不明である．
ここではこれらの特徴を利用して外れ値検出を行う．
つまり，検出元となる対象単語の用例集の一部に，対象単語の語義のラベルを付与し，その設定のもとで外れ値検出を行う．
教師データをLOFで利用するには単純に教師データをテストデータに加えればよい．
しかしその場合，教師データからも外れ値が検出される可能性がある．
ここでは教師データを[MATH]倍してからテストデータに加えてデータセットを作り，そのデータセットに対してLOFを適用する．
ただし[MATH]はLOFにおける[MATH]で使われる[MATH]である．
LOFの場合，教師データ[MATH]を[MATH]倍すると[MATH]となり，教師データ[MATH]が外れ値として検出されることはなくなる．
教師データを[MATH]倍することで，テストデータに対して，外れ値検出の精度が高まるという保証はないが，いくつかの予備実験により経験的に精度が向上することは確認している．
一般に教師データを増やせば検出の精度は高まる．
また，教師データを増やせば既存の教師データに対する密度が高まるはずなので，教師データを[MATH]倍することは精度を高める方向に作用する．
またLOFは確率的な手法ではないので，明確には教師データの独立同一性分布を仮定していない．
この点で同じデータを増やしても精度を落とす方向へ作用しないと考える．
また注記として，教師なしのLOFも教師付きLOFも[MATH]の値が特に精度に影響を与えている．
この点は考察の章で述べる．
本論文では教師なしのLOFにおいて[MATH]としたが，教師付きのLOFでも[MATH]とする．
対象単語[MATH]の用例[MATH]に対する生成モデル[MATH]を教師データを利用して構成する．
[MATH]の語義を[MATH]([MATH])としたとき，全確率の公式から以下が成立する．
[MATH]の教師データが[MATH]個あり，その中で語義[MATH]のデータが[MATH]個あれば，[MATH]であり，
と推定できる．
問題は[MATH]の推定である．
[MATH]は以下のような素性リストで表現されている．
ここではNaive Bayesで使われる素性間の独立性を仮定して，
と近似する．
教師データの中の語義が[MATH]となっているデータの中で[MATH]が出現した個数を[MATH]と書くことにする．
このとき，
と推定できる．
ただし式([REF_eq:seisei1])や式([REF_eq:seisei2])は頻度が0の部分があると不具合が生じる．
そこでMAP推定でスムージングを行い，以下の補正式を用いる[CITE]．
P(z_i) = \frac{n_i + 1}{N + K}
[0.5em] P(f_j | z_i) = \frac{n(z_i,f_j) + 1}{n_i + 2}
以上より[MATH]の値が求まる．
外れ値の度合いは[MATH]で測り，この値の大きなものを外れ値の候補とする．
ここである閾値を定めて外れ値を検出することも考えられるが，単語毎に[MATH]の値は大きく異なるために，固定した閾値を定めることはできない．
そこでここでは単語毎に，検出対象のデータ（テストデータ）に対して[MATH]を計算し，それらの値に対する平均[MATH]と分散[MATH]を求める．
[MATH]の分布を正規分布と考え，以下の式の値（正規化した値）に対して閾値[MATH]を設けることにした．
上記の正規化した値が[MATH]以上の[MATH]を外れ値とする．
ここでは予備実験を行い[MATH]とした．
本論文の提案手法は，前述した教師付きLOFによる出力と，教師データを利用して構築した生成モデルの出力の共通部分（積集合）を出力するものである．
一般に外れ値検出のタスクは難しく，単一の手法ではなかなか高い検出能力が得られない．
その1つの原因は誤検出が多いことである．
提案手法の狙いは，異なったタイプの手法の出力の積集合を取ることで，誤検出を減らし，全体の検出能力を向上させることである．
LOFと生成モデルは外れ値の捉え方が異なるために，出力の積集合を取る効果が期待できる．
