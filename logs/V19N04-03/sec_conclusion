S-LOFは教師データを[MATH]倍したLOFであるが，この倍率を1から[MATH]まで変化させた結果を表[REF_tab:jikken2-tuika]に示す．
なお倍率1倍は通常のLOFである．
正解の検出数及び教師データからの検出（誤検出）は[MATH]倍まではほぼ変化ないが，[MATH]倍することで急激に改善される．
これにより教師データを[MATH]倍する効果が確認できる．
WSDの教師データが利用できるのであれば，WSDの分類器を学習し，その識別の信頼度を利用して新語義が検出できると考えるのは自然である．
ただし単純にそのアプローチだけでは新語義の検出は困難である．
前述した素性を使いSVMを学習し，SemEval-2日本語WSDタスクのテストデータ50単語全てを対象に語義の曖昧性解消を行ったところ，平均正解率は0.7664であった．
上記タスクの参加システム中最高の正解率はRALI-2の0.7636であり[CITE]，ここで学習できたSVMは十分能力が高いことがわかる．
上記SVMの学習にはLIBSVMを用いたが，そこでは-bのオプションで識別の信頼度（その語義に属する確率値）を求めることができる．
このオプションを用いて，閾値[MATH]以下の信頼度のときに，その用例を新語義の用例とすることで新語義の検出を試みた．
閾値[MATH]の設定であるが，まず単純に0.51から0.99までの値を0.01刻みで設定し，その値を用いた場合の検出結果に対するF値を求めた．
そのグラフを図[REF_k-zettai]に示す．
[MATH]のときに検出数388正解数4となりF値が最大の0.0198を取る．
また語義数が[MATH]の場合，SVMが出力する識別の信頼度は明らかに[MATH]以上の値になるので，語義数の影響を受けている可能性がある．
そこで閾値を[MATH]と設定し，[MATH]を0.01刻みで0.99まで試したときのグラフを図[REF_k-soutai]に示す．
[MATH]のときに検出数39正解数2となりF値が最大の0.0727を取る．
F値0.0727は表[REF_tab:jikken2]で示された外れ値検出手法と比較すると，それほど悪いとも言えないが，WSDシステム単独では新語義の検出が困難であることがわかる．
また平均適合率の評価も行っておく．
システムが識別した語義の信頼度によって，全体のデータを（昇順に）ソートすることで，平均適合率を調べたところ0.00638となった．
この値は表[REF_tab:ap]に示した外れ値検出手法による平均適合率と比べると高い値とは言えない．
平均適合率の観点からも，WSDシステム単独では新語義の検出が困難であることがわかる．
上記では語義の識別の信頼度により新語義を検出するアプローチであったが，ここではSVMを利用しているので，one-vs-rest法を利用して，語義毎にSVMを学習し，すべての語義について否と判定されたものを新語義とするアプローチも考えられる．
このアプローチによる評価も行っておく．
語義毎にSVMを学習する際にもLIBSVMの-bのオプションを用いる．
語義毎の各SVMが否と識別した信頼度を集め，その最小値[MATH]をそのデータの新語義の度合いとする．
[MATH]が閾値[MATH]よりも大きい場合に，新語義と判定する．
[MATH]は語義毎のSVM全てが否と判定したものを新語義と判定することを意味する．
出力結果の分析から[MATH]のときに検出数33正解数1となりF値が最大の0.0408を取る．
またone-vs-rest法を利用した場合の平均適合率も調べた．
[MATH]の値を新語義の度合いとし，全データに対して新語義の度合いの順位を出力することで平均適合率が求まる．
結果，平均適合率は0.0132であった．
F値にしても平均適合率にしても，表[REF_tab:jikken2]や図[REF_fig-ap]と比較すると，通常の教師付きの外れ値検出手法と同程度である．
one-vs-rest法を利用した場合でも，WSDシステム単独では新語義の検出が困難であることがわかる．
SemEval-2日本語WSDタスクでは，教師データ中には現れないが，テストデータには出現する語義が存在する．
このような教師データ中の未出現語義は，新語義と見なすこともできる．
このような用例は「あう」で1用例，「すすめる」で1用例，「出す」で3用例，「立つ」で1用例，「とる」で3用例，「ひとつ」で1用例，「見る」で6用例，「持つ」で1用例，「大きい」で2用例，「与える」で1用例の合計20用例存在する．
これらも新語義の用例と見なした場合の検出結果を表[REF_tab:jikken3]に示す．
F値の括弧内の数値は正解を新語義のみにした場合の正解数とF値（表[REF_tab:jikken2]の値）である．
また平均適合率の評価も行っておく．
各手法の平均適合率の求め方は前述した方法で行う．
結果を表[REF_tab:ap2]に示す．
表[REF_tab:ap2]の「新語義のみ」の列は正解を新語義のみにした場合であり，「未出現語義を含む」の列は正解を新語義と未出現語義を合わせたものにした場合である．
F値の評価でも平均適合率の評価でも本手法が最も高い値を出しており，本手法の効果は確認できる．
ただし全体的な傾向として，未出現語義を正解に含めた場合の方が，F値も平均適合率も若干高くなるが，本手法に関しては値が下がっている．
S-LOFやG-modelは未出現語義を正解に含めると，検出できる正解数は増えるが，共通して検出できる部分がなかったために，このような結果になった．
この対策としては，後述するアンサンブル手法の導入により改良していきたい．
また，前節のWSDシステムを用いた場合の評価を表[REF_tab:wsd+]に示す．
F値と平均適合率の括弧内の数値は正解を「新語義のみ」にしたものである．
未出現語義を正解に含めた場合でも，前節同様，WSDシステム単独では新語義の検出が困難であるといえる．
本手法の誤検出の原因について述べる．
1つは固有表現や熟語内の単語である．
例えば以下のような表現が検出されている．
未来科学技術共同研究センターの中の研究施設
昔話の「千代ごこ出やっせ」のように
中小零細企業の取材は数多く手がかかる割りに
固有表現や熟語内の単語に通常の意味があるとは考えづらく，新語義の検出という観点では，このような表現を抽出しても完全に誤りとは言えない．
本来，新語義の検出するためには，固有表現や熟語を予め抽出しておくことが必要だと考える．
また誤検出のその他の原因は多様であるが，全体として，対象単語の直前や直後に自立語が現れる複合語の用法や動詞の連体形の用法などが目立った．
わが国が最も重要な貿易相手国の一つ
人間性を疑ってしまう人とは男女関係なく，
夏休み等に行って来た時の経験＝古き良き時代を，
複合語が専門性の高い用語である場合は意味のある検出とも見なせるが，ここでは複合語を単なる名詞連続で認識しているために，専門用語との区別は付けられない．
新語義の検出に関しては，熟語や固有表現と同様，専門用語も通常の表現とは，区別した方がよいと考える．
本手法の未検出の原因としては，突き詰めれば，用例間の距離の測定方法に帰着される．
ある新語義の用例と他の正常値の用例との距離がある程度，離れていたとしても，正常値の用例間の距離も同程度は離れているという状況である．
これは動詞や形容詞における検出では顕著である．
この問題に注目して距離学習を新語義発見に応用した研究も存在する[CITE]．
ただしこの問題は本質的に語義曖昧性解消の場合と同じであり，語義曖昧性解消の精度向上の試みが本研究に応用できる．
オリジナルのLOFではパラメータ[MATH]が存在し，この値が精度に大きく影響することが指摘されている．
ここで提案した教師付きLOFでは更に[MATH]の設定はシビアである．
教師付きLOFでは，テストデータ[MATH]と最も近い点が教師データ[MATH]であった場合，[MATH]の密度が非常に高いために[MATH]の値も高くなり，一見，不都合に感じる．
ただしテストデータ[MATH]の場合も，最も近い点が教師データ[MATH]であり，[MATH]となっている場合は，[MATH]となるために，[MATH]の外れ値の程度は[MATH]よりも下がる（図[REF_kou1]参照）．
つまり極端に言えば，教師付きLOFは，最も近い点が教師データであり，しかもその点までの距離が大きい場合に外れ値の程度が大きくなる．
これは外れ値の性質としては妥当である．
現実的にはテストデータ[MATH]の[MATH]近傍[MATH]の中に教師データ[MATH]が入るかどうか，[MATH]から[MATH]までの距離[MATH]，[MATH]の中にテストデータがいくつ入るか及びそれらの位置関係が[MATH]の値に影響している．
もしも[MATH]の中に教師データが入らない場合は，入る場合と比較して極端に[MATH]の値は小さいので，[MATH]が外れ値として検出されることはない（図[REF_kou2]参照）．
「[MATH]近傍内に教師データが入らない場合は外れ値ではない」という設定が妥当かどうかは不明である．
当然，そうではない場合も想定することは可能だが，実験結果をみると本タスクにおいては上記設定が有効に機能していた．
おそらく[MATH]近傍内に教師データが入らない場合は，そのデータ近辺の密度が低いためだと考えられる．
ここで提案した教師付きLOFでは，[MATH]近傍内に教師データが入るかどうかで，外れ値かどうかの最初の判定がされていると見なすこともできるので，パラメータ[MATH]の値は，通常のLOFよりも更に精度に影響を与えていると言える．
外れ値検出手法は数多く提案されており，本論文で利用したLOFについてもいくつかの改良手法が提案されている[CITE]．
これらの手法をどのようにして教師付きの枠組みへ拡張するかは不明であるが，これらを利用することで本手法の改善も可能である．
また，新たに外れ値検出手法を考案するのではなく，既存の手法を組み合わせる戦略も有効である．
Lazavicは複数の外れ値検出の手法を適用して，それら出力結果を総合的に判断して最終的に外れ値候補を出力するという外れ値検出手法のアンサンブル(ensemble)を提案した[CITE]．
ここで提案したLOFと生成モデルの組み合わせも，外れ値検出手法のアンサンブルの一種と考えられる．
ここでは単純に出力の積により最終の出力を決めたが，重みを付けて判断するなどの工夫も考えられる．
あるいは他の外れ値検出の手法の組み合わせることも有効であろう．
表[REF_tab:jikken3]からもわかるとおり，LOFの出力と生成モデルの出力はかなり異なる．
単純に出力の和を取ると，検出数が多くなりすぎてF値の評価は下がってしまうが，第1段目の候補としては取り出せているので，そこからの選別に工夫することで改善が可能である．
ここらが今後の課題である．
また，本論文ではS-LOFとG-modelのアンサンブルを提案したが，実験の結果をみるとNNとG-modelのアンサンブルやS-LOFとNNのアンサンブルも有望に見える．
それらの実験結果を表7に示す．
表7が示すとおり，提案手法のS-LOFとG-modelのアンサンブルが最も優れている．
また組み合わせる手法によっては，個々の手法よりも精度が劣化することもありえるので，アンサンブルに用いる手法の選択も重要であることがわかる．
本論文では対象単語の用例集合から，その単語の語義が新語義となっている用例を検出する手法を提案した．
基本的に新語義の用例を用例集合中の外れ値と考え，外れ値検出の手法を利用する．
ただし従来の外れ値検出では教師なしの枠組みであるが，ここではタスクの性質を考慮し，教師付きの枠組みで行った．
まずLOFを教師データを利用する形に改良した教師付きLOFを提案し，次に教師データを利用することで生成モデルを構築した．
提案手法は上記2つの手法それぞれの出力の共通部分（積集合）を取るものである．
これは2つの異なったタイプの外れ値検出の手法の積集合を取ることで誤検出を減らし，結果的に検出能力を高めることを狙いとしている．
タスクの一部として新語義識別を含むSemEval-2の日本語WSDタスクのデータを利用して，LOF, One Class SVM,最近傍法，教師付きLOF，生成モデルおよび提案手法による新語義の検出実験を行った．
それぞれの手法のF値と平均適合率を求めることで，提案手法の有効性を示した．
また教師なしの手法(LOF, OCS, [MATH])，単純に教師データを検出結果から除く手法(LOF-e, OCS-e, [MATH])及び教師付きの手法(NN, S-LOF, G-model)のF値と平均適合率を比較することで，新語義検出を目的とした外れ値検出では，教師データを積極的に利用することが精度向上に効果があることが確認できた．
またWSDシステムの識別の信頼度を利用した新語義を検出実験も行った．
十分なパフォーマンスを示すWSDシステムを用いても，WSDシステム単独では新語義の検出が困難であることも示した．
提案手法は外れ値検出手法のアンサンブルの手法と位置づけられる．
提案手法における出力結果のアンサンブルは，積集合をとるという単純なものであるため，この部分に工夫を入れることで更に検出能力が高まると予想している．
出力結果の統合方法を工夫することが今後の課題である．
{}
\bibitem[\protect\BCAY{Agirre \BBA Soroa}{Agirre \BBA Soroa}{2007}]{agirre} Agirre, E.\BBACOMMA \BBA Soroa, A. \BBOP 2007\BBCP. \newblock\BBOQ{Semeval-2007 task 02: Evaluating word sense induction and discrimination systems}.
\BBCQ \newblock In SemEval-2007.
\bibitem[\protect\BCAY{赤穂}{赤穂}{2008}]{akaho}赤穂昭太郎\BBOP 2008\BBCP. \newblock\Jem{カーネル多変量解析}.
\newblock岩波書店.
\bibitem[\protect\BCAY{Bordag}{Bordag}{2006}]{stefan} Bordag, S. \BBOP 2006\BBCP. \newblock\BBOQ{Word sense induction: Triplet-based clustering and automatic evaluation}.
\BBCQ \newblock In {EACL-2006}, \BPGS 137--144.
\bibitem[\protect\BCAY{Breuning, Kriegel, Ng, \BBA Sander}{Breuning et al.}{2000}]{lof} Breuning, M. M., Kriegel, H.-P., Ng, R. T., \BBA Sander, J. \BBOP 2000\BBCP. \newblock\BBOQ{LOF: Identifying Density-Based Local Outliers}.
\BBCQ \newblock In {ACM SIGMOD 2000}, \BPGS 93--104.
\bibitem[\protect\BCAY{Denkowski}{Denkowski}{2009}]{denkowski} Denkowski, M. \BBOP 2009\BBCP. \newblock\BBOQ{Survey of Techniques for Unsupervised Word Sense Induction}.
\BBCQ
\bibitem[\protect\BCAY{Erk}{Erk}{2006}]{erk} Erk, K. \BBOP 2006\BBCP. \newblock\BBOQ{Unknown word sense detection as outlier detection}.
\BBCQ \newblock In {NAACL-2006}, \BPGS 128--135.
\bibitem[\protect\BCAY{Jin, Tung, Han, \BBA Wang}{Jin et al.}{2006}]{jin} Jin, W., Tung, A. K. H., Han, J., \BBA Wang, W. \BBOP 2006\BBCP. \newblock\BBOQ{Ranking outliers using symmetric neighborhood relationship}.
\BBCQ \newblock In The 10th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining(PAKDD '06), \BPGS 577--593.
\bibitem[\protect\BCAY{九岡\JBA白井\JBA中村}{九岡\Jetal}{2008}]{kuoka}九岡佑介\JBA白井清昭\JBA中村誠\BBOP 2008\BBCP. \newblock複数の特徴ベクトルのクラスタリングに基づく単語の意味の弁別.
\newblock\Jem{第14回言語処理学会年次大会}, \BPGS 572--575.
\bibitem[\protect\BCAY{Lazarevic \BBA Kumar}{Lazarevic \BBA Kumar}{2005}]{lazavic} Lazarevic, A.\BBACOMMA \BBA Kumar, V. \BBOP 2005\BBCP. \newblock\BBOQ Feature bagging for outlier detection.\BBCQ \newblock In The eleventh ACM SIGKDD international conference on Knowledge discovery in data mining(KDD '05), \BPGS 157--166.
\bibitem[\protect\BCAY{Okumura, Shirai, Komiya, \BBA Yokono}{Okumura et al.}{2010}]{semeval-2010} Okumura, M., Shirai, K., Komiya, K., \BBA Yokono, H. \BBOP 2010\BBCP. \newblock\BBOQ{SemEval-2010 Task: Japanese WSD}.
\BBCQ \newblock In {The 5th International Workshop on Semantic Evaluation}, \BPGS 69--74.
\bibitem[\protect\BCAY{Papadimitriou, Kitagawa, Gibbons, \BBA Faloutsos}{Papadimitriou et al.}{2003}]{papadimitriou} Papadimitriou, S., Kitagawa, H., Gibbons, P. B., \BBA Faloutsos, C. \BBOP 2003\BBCP. \newblock\BBOQ{LOCI: Fast Outlier Detection Using the Local Correlation Integral}.
\BBCQ \newblock In ICDE-2003, \BPGS 315--326.
\bibitem[\protect\BCAY{Sasaki \BBA Shinnou}{Sasaki \BBA Shinnou}{2012}]{msasaki} Sasaki, M.\BBACOMMA \BBA Shinnou, H. \BBOP 2012\BBCP. \newblock\BBOQ{Detection of Peculiar Word Sense by Distance Metric Learning with Labeled Examples}.
\BBCQ \newblock In LREC-2012, \BPGS Session--P6.
\bibitem[\protect\BCAY{Scholkopf, Platt, Shawe-Taylor, Smola, \BBA Williamson}{Scholkopf et al.}{2001}]{oc-svm} Scholkopf, B., Platt, J. C., Shawe-Taylor, J., Smola, A. J., \BBA Williamson, R. C. \BBOP 2001\BBCP. \newblock\BBOQ Estimating the support of a high-dimensional distribution.\BBCQ \newblockNeural Computation, 13 (7), \BPGS 1443--1471.
\bibitem[\protect\BCAY{Schutze}{Schutze}{1998}]{shutze} Schutze, H. \BBOP 1998\BBCP. \newblock\BBOQ Automatic word sense discrimination.\BBCQ \newblockComputational Linguistics, 24 (1), \BPGS 97--123.
\bibitem[\protect\BCAY{Shinnou \BBA Sasaki}{Shinnou \BBA Sasaki}{2010}]{shinnou-lrec2010} Shinnou, H.\BBACOMMA \BBA Sasaki, M. \BBOP 2010\BBCP. \newblock\BBOQ{Detection of Peculiar Examples using LOF and One Class SVM}.
\BBCQ \newblock In {LREC-2010}.
\bibitem[\protect\BCAY{Shirai \BBA Nakamura}{Shirai \BBA Nakamura}{2010}]{shirai-semeval2} Shirai, K.\BBACOMMA \BBA Nakamura, M. \BBOP 2010\BBCP. \newblock\BBOQ{JAIST: Clustering and Classification Based Approaches for Japanese WSD}.
\BBCQ \newblock In {The 5th International Workshop on Semantic Evaluation}, \BPGS 379--382.
\bibitem[\protect\BCAY{Sugiyama \BBA Okumura}{Sugiyama \BBA Okumura}{2009}]{sugiyama} Sugiyama, K.\BBACOMMA \BBA Okumura, M. \BBOP 2009\BBCP. \newblock\BBOQ{Semi-supervised Clustering for Word Instances and Its Effect on Word Sense Disambiguation}.
\BBCQ \newblock In {The 10th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing 2009)}, \BPGS 266--279.
\bibitem[\protect\BCAY{高村}{高村}{2010}]{takamura}高村大也\BBOP 2010\BBCP. \newblock\Jem{言語処理のための機械学習入門}.
\newblockコロナ社.
\bibitem[\protect\BCAY{田中\JBA中村\JBA白井}{田中\Jetal}{2009}]{tanaka-h}田中博貴\JBA中村誠\JBA白井清昭\BBOP 2009\BBCP. \newblock新語義発見のための用例クラスタと辞書定義文の対応付け.
\newblock\Jem{第15回言語処理学会年次大会}, \BPGS 590--593.
\bibitem[\protect\BCAY{山西}{山西}{2009}]{yamanishi}山西健司\BBOP 2009\BBCP. \newblock\Jem{データマイニングによる異常検知}.
\newblock共立出版.
S-LOFは教師データを[MATH]倍したLOFであるが，この倍率を1から[MATH]まで変化させた結果を表[REF_tab:jikken2-tuika]に示す．
なお倍率1倍は通常のLOFである．
正解の検出数及び教師データからの検出（誤検出）は[MATH]倍まではほぼ変化ないが，[MATH]倍することで急激に改善される．
これにより教師データを[MATH]倍する効果が確認できる．
WSDの教師データが利用できるのであれば，WSDの分類器を学習し，その識別の信頼度を利用して新語義が検出できると考えるのは自然である．
ただし単純にそのアプローチだけでは新語義の検出は困難である．
前述した素性を使いSVMを学習し，SemEval-2日本語WSDタスクのテストデータ50単語全てを対象に語義の曖昧性解消を行ったところ，平均正解率は0.7664であった．
上記タスクの参加システム中最高の正解率はRALI-2の0.7636であり[CITE]，ここで学習できたSVMは十分能力が高いことがわかる．
上記SVMの学習にはLIBSVMを用いたが，そこでは-bのオプションで識別の信頼度（その語義に属する確率値）を求めることができる．
このオプションを用いて，閾値[MATH]以下の信頼度のときに，その用例を新語義の用例とすることで新語義の検出を試みた．
閾値[MATH]の設定であるが，まず単純に0.51から0.99までの値を0.01刻みで設定し，その値を用いた場合の検出結果に対するF値を求めた．
そのグラフを図[REF_k-zettai]に示す．
[MATH]のときに検出数388正解数4となりF値が最大の0.0198を取る．
また語義数が[MATH]の場合，SVMが出力する識別の信頼度は明らかに[MATH]以上の値になるので，語義数の影響を受けている可能性がある．
そこで閾値を[MATH]と設定し，[MATH]を0.01刻みで0.99まで試したときのグラフを図[REF_k-soutai]に示す．
[MATH]のときに検出数39正解数2となりF値が最大の0.0727を取る．
F値0.0727は表[REF_tab:jikken2]で示された外れ値検出手法と比較すると，それほど悪いとも言えないが，WSDシステム単独では新語義の検出が困難であることがわかる．
また平均適合率の評価も行っておく．
システムが識別した語義の信頼度によって，全体のデータを（昇順に）ソートすることで，平均適合率を調べたところ0.00638となった．
この値は表[REF_tab:ap]に示した外れ値検出手法による平均適合率と比べると高い値とは言えない．
平均適合率の観点からも，WSDシステム単独では新語義の検出が困難であることがわかる．
上記では語義の識別の信頼度により新語義を検出するアプローチであったが，ここではSVMを利用しているので，one-vs-rest法を利用して，語義毎にSVMを学習し，すべての語義について否と判定されたものを新語義とするアプローチも考えられる．
このアプローチによる評価も行っておく．
語義毎にSVMを学習する際にもLIBSVMの-bのオプションを用いる．
語義毎の各SVMが否と識別した信頼度を集め，その最小値[MATH]をそのデータの新語義の度合いとする．
[MATH]が閾値[MATH]よりも大きい場合に，新語義と判定する．
[MATH]は語義毎のSVM全てが否と判定したものを新語義と判定することを意味する．
出力結果の分析から[MATH]のときに検出数33正解数1となりF値が最大の0.0408を取る．
またone-vs-rest法を利用した場合の平均適合率も調べた．
[MATH]の値を新語義の度合いとし，全データに対して新語義の度合いの順位を出力することで平均適合率が求まる．
結果，平均適合率は0.0132であった．
F値にしても平均適合率にしても，表[REF_tab:jikken2]や図[REF_fig-ap]と比較すると，通常の教師付きの外れ値検出手法と同程度である．
one-vs-rest法を利用した場合でも，WSDシステム単独では新語義の検出が困難であることがわかる．
SemEval-2日本語WSDタスクでは，教師データ中には現れないが，テストデータには出現する語義が存在する．
このような教師データ中の未出現語義は，新語義と見なすこともできる．
このような用例は「あう」で1用例，「すすめる」で1用例，「出す」で3用例，「立つ」で1用例，「とる」で3用例，「ひとつ」で1用例，「見る」で6用例，「持つ」で1用例，「大きい」で2用例，「与える」で1用例の合計20用例存在する．
これらも新語義の用例と見なした場合の検出結果を表[REF_tab:jikken3]に示す．
F値の括弧内の数値は正解を新語義のみにした場合の正解数とF値（表[REF_tab:jikken2]の値）である．
また平均適合率の評価も行っておく．
各手法の平均適合率の求め方は前述した方法で行う．
結果を表[REF_tab:ap2]に示す．
表[REF_tab:ap2]の「新語義のみ」の列は正解を新語義のみにした場合であり，「未出現語義を含む」の列は正解を新語義と未出現語義を合わせたものにした場合である．
F値の評価でも平均適合率の評価でも本手法が最も高い値を出しており，本手法の効果は確認できる．
ただし全体的な傾向として，未出現語義を正解に含めた場合の方が，F値も平均適合率も若干高くなるが，本手法に関しては値が下がっている．
S-LOFやG-modelは未出現語義を正解に含めると，検出できる正解数は増えるが，共通して検出できる部分がなかったために，このような結果になった．
この対策としては，後述するアンサンブル手法の導入により改良していきたい．
また，前節のWSDシステムを用いた場合の評価を表[REF_tab:wsd+]に示す．
F値と平均適合率の括弧内の数値は正解を「新語義のみ」にしたものである．
未出現語義を正解に含めた場合でも，前節同様，WSDシステム単独では新語義の検出が困難であるといえる．
本手法の誤検出の原因について述べる．
1つは固有表現や熟語内の単語である．
例えば以下のような表現が検出されている．
未来科学技術共同研究センターの中の研究施設
昔話の「千代ごこ出やっせ」のように
中小零細企業の取材は数多く手がかかる割りに
固有表現や熟語内の単語に通常の意味があるとは考えづらく，新語義の検出という観点では，このような表現を抽出しても完全に誤りとは言えない．
本来，新語義の検出するためには，固有表現や熟語を予め抽出しておくことが必要だと考える．
また誤検出のその他の原因は多様であるが，全体として，対象単語の直前や直後に自立語が現れる複合語の用法や動詞の連体形の用法などが目立った．
わが国が最も重要な貿易相手国の一つ
人間性を疑ってしまう人とは男女関係なく，
夏休み等に行って来た時の経験＝古き良き時代を，
複合語が専門性の高い用語である場合は意味のある検出とも見なせるが，ここでは複合語を単なる名詞連続で認識しているために，専門用語との区別は付けられない．
新語義の検出に関しては，熟語や固有表現と同様，専門用語も通常の表現とは，区別した方がよいと考える．
本手法の未検出の原因としては，突き詰めれば，用例間の距離の測定方法に帰着される．
ある新語義の用例と他の正常値の用例との距離がある程度，離れていたとしても，正常値の用例間の距離も同程度は離れているという状況である．
これは動詞や形容詞における検出では顕著である．
この問題に注目して距離学習を新語義発見に応用した研究も存在する[CITE]．
ただしこの問題は本質的に語義曖昧性解消の場合と同じであり，語義曖昧性解消の精度向上の試みが本研究に応用できる．
オリジナルのLOFではパラメータ[MATH]が存在し，この値が精度に大きく影響することが指摘されている．
ここで提案した教師付きLOFでは更に[MATH]の設定はシビアである．
教師付きLOFでは，テストデータ[MATH]と最も近い点が教師データ[MATH]であった場合，[MATH]の密度が非常に高いために[MATH]の値も高くなり，一見，不都合に感じる．
ただしテストデータ[MATH]の場合も，最も近い点が教師データ[MATH]であり，[MATH]となっている場合は，[MATH]となるために，[MATH]の外れ値の程度は[MATH]よりも下がる（図[REF_kou1]参照）．
つまり極端に言えば，教師付きLOFは，最も近い点が教師データであり，しかもその点までの距離が大きい場合に外れ値の程度が大きくなる．
これは外れ値の性質としては妥当である．
現実的にはテストデータ[MATH]の[MATH]近傍[MATH]の中に教師データ[MATH]が入るかどうか，[MATH]から[MATH]までの距離[MATH]，[MATH]の中にテストデータがいくつ入るか及びそれらの位置関係が[MATH]の値に影響している．
もしも[MATH]の中に教師データが入らない場合は，入る場合と比較して極端に[MATH]の値は小さいので，[MATH]が外れ値として検出されることはない（図[REF_kou2]参照）．
「[MATH]近傍内に教師データが入らない場合は外れ値ではない」という設定が妥当かどうかは不明である．
当然，そうではない場合も想定することは可能だが，実験結果をみると本タスクにおいては上記設定が有効に機能していた．
おそらく[MATH]近傍内に教師データが入らない場合は，そのデータ近辺の密度が低いためだと考えられる．
ここで提案した教師付きLOFでは，[MATH]近傍内に教師データが入るかどうかで，外れ値かどうかの最初の判定がされていると見なすこともできるので，パラメータ[MATH]の値は，通常のLOFよりも更に精度に影響を与えていると言える．
外れ値検出手法は数多く提案されており，本論文で利用したLOFについてもいくつかの改良手法が提案されている[CITE]．
これらの手法をどのようにして教師付きの枠組みへ拡張するかは不明であるが，これらを利用することで本手法の改善も可能である．
また，新たに外れ値検出手法を考案するのではなく，既存の手法を組み合わせる戦略も有効である．
Lazavicは複数の外れ値検出の手法を適用して，それら出力結果を総合的に判断して最終的に外れ値候補を出力するという外れ値検出手法のアンサンブル(ensemble)を提案した[CITE]．
ここで提案したLOFと生成モデルの組み合わせも，外れ値検出手法のアンサンブルの一種と考えられる．
ここでは単純に出力の積により最終の出力を決めたが，重みを付けて判断するなどの工夫も考えられる．
あるいは他の外れ値検出の手法の組み合わせることも有効であろう．
表[REF_tab:jikken3]からもわかるとおり，LOFの出力と生成モデルの出力はかなり異なる．
単純に出力の和を取ると，検出数が多くなりすぎてF値の評価は下がってしまうが，第1段目の候補としては取り出せているので，そこからの選別に工夫することで改善が可能である．
ここらが今後の課題である．
また，本論文ではS-LOFとG-modelのアンサンブルを提案したが，実験の結果をみるとNNとG-modelのアンサンブルやS-LOFとNNのアンサンブルも有望に見える．
それらの実験結果を表7に示す．
表7が示すとおり，提案手法のS-LOFとG-modelのアンサンブルが最も優れている．
また組み合わせる手法によっては，個々の手法よりも精度が劣化することもありえるので，アンサンブルに用いる手法の選択も重要であることがわかる．
本論文では対象単語の用例集合から，その単語の語義が新語義となっている用例を検出する手法を提案した．
基本的に新語義の用例を用例集合中の外れ値と考え，外れ値検出の手法を利用する．
ただし従来の外れ値検出では教師なしの枠組みであるが，ここではタスクの性質を考慮し，教師付きの枠組みで行った．
まずLOFを教師データを利用する形に改良した教師付きLOFを提案し，次に教師データを利用することで生成モデルを構築した．
提案手法は上記2つの手法それぞれの出力の共通部分（積集合）を取るものである．
これは2つの異なったタイプの外れ値検出の手法の積集合を取ることで誤検出を減らし，結果的に検出能力を高めることを狙いとしている．
タスクの一部として新語義識別を含むSemEval-2の日本語WSDタスクのデータを利用して，LOF, One Class SVM,最近傍法，教師付きLOF，生成モデルおよび提案手法による新語義の検出実験を行った．
それぞれの手法のF値と平均適合率を求めることで，提案手法の有効性を示した．
また教師なしの手法(LOF, OCS, [MATH])，単純に教師データを検出結果から除く手法(LOF-e, OCS-e, [MATH])及び教師付きの手法(NN, S-LOF, G-model)のF値と平均適合率を比較することで，新語義検出を目的とした外れ値検出では，教師データを積極的に利用することが精度向上に効果があることが確認できた．
またWSDシステムの識別の信頼度を利用した新語義を検出実験も行った．
十分なパフォーマンスを示すWSDシステムを用いても，WSDシステム単独では新語義の検出が困難であることも示した．
提案手法は外れ値検出手法のアンサンブルの手法と位置づけられる．
提案手法における出力結果のアンサンブルは，積集合をとるという単純なものであるため，この部分に工夫を入れることで更に検出能力が高まると予想している．
出力結果の統合方法を工夫することが今後の課題である．
{}
\bibitem[\protect\BCAY{Agirre \BBA Soroa}{Agirre \BBA Soroa}{2007}]{agirre} Agirre, E.\BBACOMMA \BBA Soroa, A. \BBOP 2007\BBCP. \newblock\BBOQ{Semeval-2007 task 02: Evaluating word sense induction and discrimination systems}.
\BBCQ \newblock In SemEval-2007.
\bibitem[\protect\BCAY{赤穂}{赤穂}{2008}]{akaho}赤穂昭太郎\BBOP 2008\BBCP. \newblock\Jem{カーネル多変量解析}.
\newblock岩波書店.
\bibitem[\protect\BCAY{Bordag}{Bordag}{2006}]{stefan} Bordag, S. \BBOP 2006\BBCP. \newblock\BBOQ{Word sense induction: Triplet-based clustering and automatic evaluation}.
\BBCQ \newblock In {EACL-2006}, \BPGS 137--144.
\bibitem[\protect\BCAY{Breuning, Kriegel, Ng, \BBA Sander}{Breuning et al.}{2000}]{lof} Breuning, M. M., Kriegel, H.-P., Ng, R. T., \BBA Sander, J. \BBOP 2000\BBCP. \newblock\BBOQ{LOF: Identifying Density-Based Local Outliers}.
\BBCQ \newblock In {ACM SIGMOD 2000}, \BPGS 93--104.
\bibitem[\protect\BCAY{Denkowski}{Denkowski}{2009}]{denkowski} Denkowski, M. \BBOP 2009\BBCP. \newblock\BBOQ{Survey of Techniques for Unsupervised Word Sense Induction}.
\BBCQ
\bibitem[\protect\BCAY{Erk}{Erk}{2006}]{erk} Erk, K. \BBOP 2006\BBCP. \newblock\BBOQ{Unknown word sense detection as outlier detection}.
\BBCQ \newblock In {NAACL-2006}, \BPGS 128--135.
\bibitem[\protect\BCAY{Jin, Tung, Han, \BBA Wang}{Jin et al.}{2006}]{jin} Jin, W., Tung, A. K. H., Han, J., \BBA Wang, W. \BBOP 2006\BBCP. \newblock\BBOQ{Ranking outliers using symmetric neighborhood relationship}.
\BBCQ \newblock In The 10th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining(PAKDD '06), \BPGS 577--593.
\bibitem[\protect\BCAY{九岡\JBA白井\JBA中村}{九岡\Jetal}{2008}]{kuoka}九岡佑介\JBA白井清昭\JBA中村誠\BBOP 2008\BBCP. \newblock複数の特徴ベクトルのクラスタリングに基づく単語の意味の弁別.
\newblock\Jem{第14回言語処理学会年次大会}, \BPGS 572--575.
\bibitem[\protect\BCAY{Lazarevic \BBA Kumar}{Lazarevic \BBA Kumar}{2005}]{lazavic} Lazarevic, A.\BBACOMMA \BBA Kumar, V. \BBOP 2005\BBCP. \newblock\BBOQ Feature bagging for outlier detection.\BBCQ \newblock In The eleventh ACM SIGKDD international conference on Knowledge discovery in data mining(KDD '05), \BPGS 157--166.
\bibitem[\protect\BCAY{Okumura, Shirai, Komiya, \BBA Yokono}{Okumura et al.}{2010}]{semeval-2010} Okumura, M., Shirai, K., Komiya, K., \BBA Yokono, H. \BBOP 2010\BBCP. \newblock\BBOQ{SemEval-2010 Task: Japanese WSD}.
\BBCQ \newblock In {The 5th International Workshop on Semantic Evaluation}, \BPGS 69--74.
\bibitem[\protect\BCAY{Papadimitriou, Kitagawa, Gibbons, \BBA Faloutsos}{Papadimitriou et al.}{2003}]{papadimitriou} Papadimitriou, S., Kitagawa, H., Gibbons, P. B., \BBA Faloutsos, C. \BBOP 2003\BBCP. \newblock\BBOQ{LOCI: Fast Outlier Detection Using the Local Correlation Integral}.
\BBCQ \newblock In ICDE-2003, \BPGS 315--326.
\bibitem[\protect\BCAY{Sasaki \BBA Shinnou}{Sasaki \BBA Shinnou}{2012}]{msasaki} Sasaki, M.\BBACOMMA \BBA Shinnou, H. \BBOP 2012\BBCP. \newblock\BBOQ{Detection of Peculiar Word Sense by Distance Metric Learning with Labeled Examples}.
\BBCQ \newblock In LREC-2012, \BPGS Session--P6.
\bibitem[\protect\BCAY{Scholkopf, Platt, Shawe-Taylor, Smola, \BBA Williamson}{Scholkopf et al.}{2001}]{oc-svm} Scholkopf, B., Platt, J. C., Shawe-Taylor, J., Smola, A. J., \BBA Williamson, R. C. \BBOP 2001\BBCP. \newblock\BBOQ Estimating the support of a high-dimensional distribution.\BBCQ \newblockNeural Computation, 13 (7), \BPGS 1443--1471.
\bibitem[\protect\BCAY{Schutze}{Schutze}{1998}]{shutze} Schutze, H. \BBOP 1998\BBCP. \newblock\BBOQ Automatic word sense discrimination.\BBCQ \newblockComputational Linguistics, 24 (1), \BPGS 97--123.
\bibitem[\protect\BCAY{Shinnou \BBA Sasaki}{Shinnou \BBA Sasaki}{2010}]{shinnou-lrec2010} Shinnou, H.\BBACOMMA \BBA Sasaki, M. \BBOP 2010\BBCP. \newblock\BBOQ{Detection of Peculiar Examples using LOF and One Class SVM}.
\BBCQ \newblock In {LREC-2010}.
\bibitem[\protect\BCAY{Shirai \BBA Nakamura}{Shirai \BBA Nakamura}{2010}]{shirai-semeval2} Shirai, K.\BBACOMMA \BBA Nakamura, M. \BBOP 2010\BBCP. \newblock\BBOQ{JAIST: Clustering and Classification Based Approaches for Japanese WSD}.
\BBCQ \newblock In {The 5th International Workshop on Semantic Evaluation}, \BPGS 379--382.
\bibitem[\protect\BCAY{Sugiyama \BBA Okumura}{Sugiyama \BBA Okumura}{2009}]{sugiyama} Sugiyama, K.\BBACOMMA \BBA Okumura, M. \BBOP 2009\BBCP. \newblock\BBOQ{Semi-supervised Clustering for Word Instances and Its Effect on Word Sense Disambiguation}.
\BBCQ \newblock In {The 10th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing 2009)}, \BPGS 266--279.
\bibitem[\protect\BCAY{高村}{高村}{2010}]{takamura}高村大也\BBOP 2010\BBCP. \newblock\Jem{言語処理のための機械学習入門}.
\newblockコロナ社.
\bibitem[\protect\BCAY{田中\JBA中村\JBA白井}{田中\Jetal}{2009}]{tanaka-h}田中博貴\JBA中村誠\JBA白井清昭\BBOP 2009\BBCP. \newblock新語義発見のための用例クラスタと辞書定義文の対応付け.
\newblock\Jem{第15回言語処理学会年次大会}, \BPGS 590--593.
\bibitem[\protect\BCAY{山西}{山西}{2009}]{yamanishi}山西健司\BBOP 2009\BBCP. \newblock\Jem{データマイニングによる異常検知}.
\newblock共立出版.
