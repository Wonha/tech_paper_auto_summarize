================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.61185] ここでのアプローチの基本は，新語義の用例が用例集合中の外れ値になると考え，データマイニング分野の外れ値検出の手法を利用することである．
[i:2, score:0.68222] ただし外れ値検出のタスクは教師なしの枠組みになるが，新語義検出という本タスクの性質を考慮すると，一部のデータ（用例）にラベル（対象単語の語義）が付与されているという枠組みで考える方が適切である．
[i:3, score:0.45657] そのため本論文では一部のデータにラベルがついているという教師付きの枠組みで外れ値検出を行う．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:12, score:0.73205] 新語義検出は一般にWord Sense Disambiguation (WSD)の一種として行う方法，新語義の用例をクラスターとして集めるWord Sense Induction (WSI)のアプローチで行う方法[CITE]，及び新語義の用例を用例集合中の外れ値とみなし，外れ値検出の手法を用いる方法[CITE]がある．
[i:14, score:0.64391] ただしデータマイニングで用いられる外れ値検出の手法は教師なしであるが，本タスクの場合，少量の用例に語義のラベルが付いているという教師付きの枠組みで行う方が自然であり，ここでは教師付き外れ値検出の手法を提案する．
[i:16, score:0.64705] 第1の手法は代表的な外れ値検出手法であるLocal Outlier Factor (LOF) [CITE]を教師付きの枠組みに拡張したものである．

================================================================
[section type  : proposed_method]
[section title : 従来の新語義検出手法]
================================================================
-----------------------------------------------------
  [subsection title : WSD の信頼度の利用]
-----------------------------------------------------
  [i:lead, score:0.45057] WSDは語義を識別するタスクなので，WSDシステムを利用すれば新語義を検出できると考えるのは自然である．
.....
  [i:24, score:0.45057] WSDは語義を識別するタスクなので，WSDシステムを利用すれば新語義を検出できると考えるのは自然である．
  [i:28, score:0.35813] 新語義の検出はある閾値[MATH]を定め，
  [i:29, score:0.41118] のときに[MATH]を新語義の用例と判定することで，新語義を検出できる．
-----------------------------------------------------
  [subsection title : WSI による検出]
-----------------------------------------------------
  [i:lead, score:0.40780] 従来，新語義の検出はWord Sense Induction (WSI)というタスクの一部として行われてきた[CITE]．
.....
  [i:40, score:0.48450] 用例集合中に新語義の用例があれば，それらも語義のクラスターとして出現するために新語義の検出として利用できる．
  [i:42, score:0.45355] Shiraiは辞書に記述された語義の定義文を利用して，得られたクラスターに語義のラベルを付けることで新語義を検出しようとしている[CITE]．
  [i:48, score:0.51630] WSDを行う前に教師なし学習であるクラスタリングを行うアプローチが，新語義の検出に有効かどうかは不明である．
-----------------------------------------------------
  [subsection title : 外れ値検出による検出]
-----------------------------------------------------
  [i:lead, score:0.59807] 新語義の用例を用例集合内の外れ値と見なし，外れ値検出の手法を利用して新語義を検出するアプローチがある．
.....
  [i:52, score:0.59807] 新語義の用例を用例集合内の外れ値と見なし，外れ値検出の手法を利用して新語義を検出するアプローチがある．
  [i:53, score:0.56248] Erkは外れ値検出手法の最近傍法を利用して新語義の検出を試みた[CITE]．
  [i:54, score:0.55203] 対象単語[MATH]の語義が付与された用例集を[MATH]とし，用例[MATH]の外れ値の度合い[MATH]を式([REF_eq:siki1])で測り，この値が1以上の[MATH]を新語義の用例とした．

================================================================
[section type  : proposed_method]
[section title : 外れ値検出手法]
================================================================
[i:58, score:0.36604] データマイニング分野の外れ値検出手法は非常に多岐にわたるが，その多くは変化点検出の手法に位置づけられる[CITE]．
[i:59, score:0.05466] つまり時系列的にデータが生起するオンラインでのタスクに対する手法が中心である．
[i:60, score:0.46198] 新語義検出のようなバッチ的なタスクに対する手法としては，密度ベースの手法，One Class SVM，生成モデルによる手法が代表的な手法である．
-----------------------------------------------------
  [subsection title : 密度ベースの手法]
-----------------------------------------------------
  [i:lead, score:0.59294] 外れ値検出は古典的にはマハラノビス距離を用いた距離ベースの手法が中心だが，それを改良したのが密度ベースの手法であり，密度ベースの代表的な手法がLOFである．
.....
  [i:62, score:0.59294] 外れ値検出は古典的にはマハラノビス距離を用いた距離ベースの手法が中心だが，それを改良したのが密度ベースの手法であり，密度ベースの代表的な手法がLOFである．
  [i:63, score:0.61028] LOFは，データの近傍の密度を利用することで，そのデータの外れ値の度合いを測り，その値によって外れ値を検出する．
  [i:83, score:0.64499] 一方LOFでは，クラスターAの密度が高く，データaの近辺にはデータがなく孤立しているので，外れ値として検出できる．
-----------------------------------------------------
  [subsection title : One Class SVM]
-----------------------------------------------------
  [i:lead, score:0.40872] One Class SVMは[MATH]SVM [CITE]を利用した外れ値検出の手法である[CITE]．
.....
  [i:86, score:0.40872] One Class SVMは[MATH]SVM [CITE]を利用した外れ値検出の手法である[CITE]．
  [i:89, score:0.31525] また[MATH]SVMはソフトマージンを利用するので，[MATH]のクラス側に属するデータを外れ値と判定する．
  [i:93, score:0.33414] 図の星形の点（外れ値）も含め，原点以外のすべての点を正常値と考え，外れ値と正常値を分離する超平面を[MATH]SVMで求める．
-----------------------------------------------------
  [subsection title : 生成モデルによる手法]
-----------------------------------------------------
  [i:lead, score:0.04254] データ[MATH]の生成過程を確率モデル[MATH]でモデル化したものを生成モデルと呼ぶ．
.....
  [i:104, score:0.04983] モデル化の後に，与えられたデータからEM法などを利用して，[MATH]と[MATH]のパラメータを推定することで[MATH]を構成する．
  [i:105, score:0.27304] データ[MATH]の外れ値の度合いとしては[MATH]が用いられる．
  [i:106, score:0.23336] この値が大きいほど外れ値と見なせる．

================================================================
[section type  : proposed_method]
[section title : 提案手法]
================================================================
-----------------------------------------------------
  [subsection title : 教師付き外れ値検出]
-----------------------------------------------------
  [i:lead, score:0.34321] 一般に外れ値検出のタスクでは外れ値の定義が不可能である．
.....
  [i:113, score:0.59465] しかし新語義の用例を外れ値と見なした新語義検出のタスクの場合，一般の外れ値検出とは異なった2つの特徴がある．
  [i:115, score:0.50860] ここでの外れ値は新語義の用例であるが，新語義とは「辞書に記載されていない語義」というように明確に定義できる．
  [i:120, score:0.53737] つまり，検出元となる対象単語の用例集の一部に，対象単語の語義のラベルを付与し，その設定のもとで外れ値検出を行う．
-----------------------------------------------------
  [subsection title : 教師付き LOF]
-----------------------------------------------------
  [i:lead, score:0.38361] 教師データをLOFで利用するには単純に教師データをテストデータに加えればよい．
.....
  [i:122, score:0.41995] しかしその場合，教師データからも外れ値が検出される可能性がある．
  [i:125, score:0.63908] LOFの場合，教師データ[MATH]を[MATH]倍すると[MATH]となり，教師データ[MATH]が外れ値として検出されることはなくなる．
  [i:126, score:0.46896] 教師データを[MATH]倍することで，テストデータに対して，外れ値検出の精度が高まるという保証はないが，いくつかの予備実験により経験的に精度が向上することは確認している．
-----------------------------------------------------
  [subsection title : 教師データを利用した生成モデルの構築]
-----------------------------------------------------
  [i:lead, score:0.20789] 対象単語[MATH]の用例[MATH]に対する生成モデル[MATH]を教師データを利用して構成する．
.....
  [i:136, score:0.27126] [MATH]の教師データが[MATH]個あり，その中で語義[MATH]のデータが[MATH]個あれば，[MATH]であり，
  [i:142, score:0.27544] 教師データの中の語義が[MATH]となっているデータの中で[MATH]が出現した個数を[MATH]と書くことにする．
  [i:151, score:0.36546] ここである閾値を定めて外れ値を検出することも考えられるが，単語毎に[MATH]の値は大きく異なるために，固定した閾値を定めることはできない．
-----------------------------------------------------
  [subsection title : 教師付き LOF と生成モデルの積集合]
-----------------------------------------------------
  [i:lead, score:0.44518] 本論文の提案手法は，前述した教師付きLOFによる出力と，教師データを利用して構築した生成モデルの出力の共通部分（積集合）を出力するものである．
.....
  [i:156, score:0.44518] 本論文の提案手法は，前述した教師付きLOFによる出力と，教師データを利用して構築した生成モデルの出力の共通部分（積集合）を出力するものである．
  [i:157, score:0.35891] 一般に外れ値検出のタスクは難しく，単一の手法ではなかなか高い検出能力が得られない．
  [i:160, score:0.52379] LOFと生成モデルは外れ値の捉え方が異なるために，出力の積集合を取る効果が期待できる．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
-----------------------------------------------------
  [subsection title : 実験データ]
-----------------------------------------------------
  [i:lead, score:0.20636] SemEval-2は語義曖昧性解消に関する評価型の国際会議であり，いくつかのタスクが設定されている．
.....
  [i:165, score:0.47946] そのため，このタスクで用意された教師データとテストデータを用いることで，教師付きの枠組みでの新語義の検出手法の評価が可能である．
  [i:167, score:0.42579] この中で「可能」「入る」は教師データ内に新語義の用例があるので，それらを外して残り48単語を実験対象とした．
  [i:173, score:0.33401] 新語義は「意味」で1用例，「手」で3用例，「前」で7用例，「求める」で1用例，「あげる」で2用例，「はじめる」で2用例の計16用例存在する．
-----------------------------------------------------
  [subsection title : 素性の設定]
-----------------------------------------------------
  [i:lead, score:0.09792] 本手法を利用するためには，用例を素性ベクトルで表現しなくてはならない．
.....
  [i:205, score:0.63200] <sentence> <mor pos="名詞-固有名詞-組織名" rd="デンツー">電通</mor> <mor pos="補助記号-読点" rd="，">，</mor> <mor pos="名詞-固有名詞-組織名" rd="ハクホー">博報</mor> <mor pos="接尾辞-名詞的-一般" rd="ドー">堂</mor> <mor pos="助詞-格助詞" rd="オ">を</mor> <mor pos="名詞-普通名詞-副詞可能" rd="ハジメ">はじめ</mor> <mor pos="名詞-普通名詞-一般" rd="ジョーイ">上位</mor> <mor pos="名詞-数詞" rd="ゴ">五</mor> <mor pos="接尾辞-名詞的-助数詞" rd="シャ">社</mor> <mor pos="助詞-副助詞" rd="クライ">くらい</mor> <mor pos="助動詞" rd="ナラ" bfm="ダ">なら</mor> <mor pos="名詞-普通名詞-一般" rd="エイチピー">HP</mor> <mor pos="助詞-格助詞" rd="オ">を</mor> <mor pos="動詞-一般" rd="ツクル" bfm="ツクル" >作る</mor> <mor pos="形状詞-一般" rd="ジンテキ">人的</mor> <mor pos="名詞-普通名詞-一般" rd="ケーザイ" sense="X">経済</mor> <mor pos="接尾辞-形状詞的" rd="テキ">的</mor> <mor pos="名詞-普通名詞-一般" rd="ヨユー">余裕</mor> <mor pos="助詞-係助詞" rd="モ">も</mor> <mor pos="動詞-非自立可能" rd="アル" bfm="アル" >ある</mor> <mor pos="助動詞" rd="デショー" bfm="デス">でしょう</mor> <mor pos="助詞-接続助詞" rd="ガ">が</mor> <mor pos="補助記号-読点" rd="，">，</mor> <mor pos="名詞-普通名詞-一般" rd="チューショー">中小</mor> <mor pos="助詞-格助詞" rd="ノ">の</mor> <mor pos="名詞-普通名詞-サ変可能" rd="ダイリ">代理</mor> <mor pos="接尾辞-名詞的-一般" rd="テン">店</mor> <mor pos="助詞-格助詞" rd="デ">で</mor> <mor pos="助詞-係助詞" rd="ワ">は</mor> <mor pos="連体詞" rd="ソンナ">そんな</mor> <mor pos="名詞-普通名詞-一般" rd="ヨユー">余裕</mor> <mor pos="助詞-係助詞" rd="ワ">は</mor> <mor pos="動詞-非自立可能" rd="アリ" bfm="アル" >あり</mor> <mor pos="助動詞" rd="マセ" bfm="マス">ませ</mor> <mor pos="助動詞" rd="ン" bfm="ヌ">ん</mor> <mor pos="補助記号-句点" rd="．
  [i:207, score:0.20833] </mor> </sentence>
  [i:211, score:0.16780] e0=経済，e1=名詞-普通名詞-一般，e2=人的，e3=形状詞，e4=的，e5=接尾辞，e6=人的，e6=作る，e6=HP，e6=余裕，e6=ある，e6=中小，e7=2386，e7=1197，e7=11972
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, score:0.07553] まずF値による評価実験の結果を表[REF_tab:jikken2]に示す．
.....
  [i:234, score:0.69092] この6つとS-LOFとG-modelの出力の積集合を出力とする本手法の7つが教師付きの外れ値検出に相当する．
  [i:247, score:0.60087] 本手法[MATH]の場合，基本的にG-modelの出力の値を外れ値の度合いとするが，本来のS-LOFにおける出力のデータ（単語毎のLOF値の上位3件）に対しては，G-modelでの出力の値に100を加えた後に，全体をソートした．
  [i:257, score:0.75216] また教師なしの手法にあたるLOF, OCS, [MATH]の3つは0.005前後の値となり，教師ラベルを使わずに単純に出力結果から教師データを除く手法LOF-e, OCS-e, [MATH]の3つは0.010弱の値になり，教師付き外れ値検出手法にあたるNN, S-LOF, G-modelの3つは0.010強の値になる．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
-----------------------------------------------------
  [subsection title : 教師データを $k+1$ 倍する効果]
-----------------------------------------------------
  [i:lead, score:0.43633] S-LOFは教師データを[MATH]倍したLOFであるが，この倍率を1から[MATH]まで変化させた結果を表[REF_tab:jikken2-tuika]に示す．
.....
  [i:259, score:0.43633] S-LOFは教師データを[MATH]倍したLOFであるが，この倍率を1から[MATH]まで変化させた結果を表[REF_tab:jikken2-tuika]に示す．
  [i:260, score:0.28516] なお倍率1倍は通常のLOFである．
  [i:261, score:0.26628] 正解の検出数及び教師データからの検出（誤検出）は[MATH]倍まではほぼ変化ないが，[MATH]倍することで急激に改善される．
-----------------------------------------------------
  [subsection title : WSD による新語義検出]
-----------------------------------------------------
  [i:lead, score:0.53077] WSDの教師データが利用できるのであれば，WSDの分類器を学習し，その識別の信頼度を利用して新語義が検出できると考えるのは自然である．
.....
  [i:263, score:0.53077] WSDの教師データが利用できるのであれば，WSDの分類器を学習し，その識別の信頼度を利用して新語義が検出できると考えるのは自然である．
  [i:275, score:0.64321] F値0.0727は表[REF_tab:jikken2]で示された外れ値検出手法と比較すると，それほど悪いとも言えないが，WSDシステム単独では新語義の検出が困難であることがわかる．
  [i:290, score:0.51325] F値にしても平均適合率にしても，表[REF_tab:jikken2]や図[REF_fig-ap]と比較すると，通常の教師付きの外れ値検出手法と同程度である．
-----------------------------------------------------
  [subsection title : 未出現語義を含めた評価]
-----------------------------------------------------
  [i:lead, score:0.37932] SemEval-2日本語WSDタスクでは，教師データ中には現れないが，テストデータには出現する語義が存在する．
.....
  [i:295, score:0.43414] これらも新語義の用例と見なした場合の検出結果を表[REF_tab:jikken3]に示す．
  [i:303, score:0.55409] S-LOFやG-modelは未出現語義を正解に含めると，検出できる正解数は増えるが，共通して検出できる部分がなかったために，このような結果になった．
  [i:307, score:0.43757] 未出現語義を正解に含めた場合でも，前節同様，WSDシステム単独では新語義の検出が困難であるといえる．
-----------------------------------------------------
  [subsection title : 誤検出・未検出の原因]
-----------------------------------------------------
  [i:lead, score:0.12458] 本手法の誤検出の原因について述べる．
.....
  [i:314, score:0.37422] 固有表現や熟語内の単語に通常の意味があるとは考えづらく，新語義の検出という観点では，このような表現を抽出しても完全に誤りとは言えない．
  [i:321, score:0.36483] 新語義の検出に関しては，熟語や固有表現と同様，専門用語も通常の表現とは，区別した方がよいと考える．
  [i:323, score:0.36316] ある新語義の用例と他の正常値の用例との距離がある程度，離れていたとしても，正常値の用例間の距離も同程度は離れているという状況である．
-----------------------------------------------------
  [subsection title : 教師付き LOF とパラメータ\( k \)]
-----------------------------------------------------
  [i:lead, score:0.31102] オリジナルのLOFではパラメータ[MATH]が存在し，この値が精度に大きく影響することが指摘されている．
.....
  [i:331, score:0.58488] つまり極端に言えば，教師付きLOFは，最も近い点が教師データであり，しかもその点までの距離が大きい場合に外れ値の程度が大きくなる．
  [i:334, score:0.45808] もしも[MATH]の中に教師データが入らない場合は，入る場合と比較して極端に[MATH]の値は小さいので，[MATH]が外れ値として検出されることはない（図[REF_kou2]参照）．
  [i:338, score:0.60612] ここで提案した教師付きLOFでは，[MATH]近傍内に教師データが入るかどうかで，外れ値かどうかの最初の判定がされていると見なすこともできるので，パラメータ[MATH]の値は，通常のLOFよりも更に精度に影響を与えていると言える．
-----------------------------------------------------
  [subsection title : 外れ値検出手法のアンサンブル]
-----------------------------------------------------
  [i:lead, score:0.56678] 外れ値検出手法は数多く提案されており，本論文で利用したLOFについてもいくつかの改良手法が提案されている[CITE]．
.....
  [i:339, score:0.56678] 外れ値検出手法は数多く提案されており，本論文で利用したLOFについてもいくつかの改良手法が提案されている[CITE]．
  [i:342, score:0.38525] Lazavicは複数の外れ値検出の手法を適用して，それら出力結果を総合的に判断して最終的に外れ値候補を出力するという外れ値検出手法のアンサンブル(ensemble)を提案した[CITE]．
  [i:343, score:0.58547] ここで提案したLOFと生成モデルの組み合わせも，外れ値検出手法のアンサンブルの一種と考えられる．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:359, score:0.76687] タスクの一部として新語義識別を含むSemEval-2の日本語WSDタスクのデータを利用して，LOF, One Class SVM,最近傍法，教師付きLOF，生成モデルおよび提案手法による新語義の検出実験を行った．
[i:361, score:0.84401] また教師なしの手法(LOF, OCS, [MATH])，単純に教師データを検出結果から除く手法(LOF-e, OCS-e, [MATH])及び教師付きの手法(NN, S-LOF, G-model)のF値と平均適合率を比較することで，新語義検出を目的とした外れ値検出では，教師データを積極的に利用することが精度向上に効果があることが確認できた．
[i:393, score:0.72433] \bibitem[\protect\BCAY{Shinnou \BBA Sasaki}{Shinnou \BBA Sasaki}{2010}]{shinnou-lrec2010} Shinnou, H.\BBACOMMA \BBA Sasaki, M. \BBOP 2010\BBCP. \newblock\BBOQ{Detection of Peculiar Examples using LOF and One Class SVM}.

