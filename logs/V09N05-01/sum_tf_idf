================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.29458] 本稿では，Support Vector Machine (SVM)に基づく一般的なchunk同定手法を提案し，その評価を行う．
[i:1, score:0.22649] SVMは従来からある学習モデルと比較して，入力次元数に依存しない高い汎化能力を持ち，Kernel関数を導入することで効率良く素性の組み合わせを考慮しながら分類問題を学習することが可能である．
[i:3, score:0.34171] さらに，chunkの表現手法が異なる複数のモデルの重み付き多数決を行うことでさらなる精度向上を示すことができた．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:18, score:0.38296] 本稿ではchunk同定問題として，英語の単名詞句のまとめ上げ(base NP chunking)および英語の任意の句の同定(chunking)を例にとりながら学習手法としてSVMを用いた手法を述べる．
[i:19, score:0.36086] さらに，chunkの表現方法が異なる複数の学習データから独立に学習し，それらの重み付き多数決を行うことでさらなる精度向上を試みる．
[i:22, score:0.34786] 2章でSVMの概要を説明し，3章で一般的なchunk同定モデルおよびSVMの具体的な適用方法，重み付け多数決の方法について述べる．

================================================================
[section type  : proposed_method]
[section title : Support Vector Machine]
================================================================
-----------------------------------------------------
  [subsection title : 最適分離平面]
-----------------------------------------------------
  [i:lead, score:0.06967] 分類問題において，正例，負例の2つのクラスに属す学習データのベクトル集合を，
.....
  [i:36, score:0.14976] この2つの破線間の距離をマージンと呼び，SVMはマージンが最大となる分離平面を求める戦略を採用している．
  [i:37, score:0.13703] 図[REF_fig:hyperplane]の例では，右の分離平面が左の分離平面にくらべて大きなマージンを持っており，精度よくテスト事例を分離できることを意味している．
  [i:49, score:0.17657] この点を生かし，各事例間の内積を任意のKernel関数におきかえることで，SVMは低次元中の非線形分類問題を高次元中の線形分離問題としてみなし分類を行うことが可能となっている．
-----------------------------------------------------
  [subsection title : SVM の汎化能力]
-----------------------------------------------------
  [i:lead, score:0.04275] ここで，汎化能力に関する一般的な理論について考察する．
.....
  [i:55, score:0.20848] [Vapnik]学習データの事例数を[MATH]，モデルのVC次元を[MATH]とする時，汎化誤差[MATH]は，[MATH]の確率で以下の上限値を持つ．
  [i:57, score:0.25340] 式([REF_eq:svm_gen])の右辺をVC boundと呼び，汎化誤差を小さくするには，VC boundをできるだけ小さくすればよい．
  [i:65, score:0.21134] [Vapnik]事例の次元数を[MATH]，マージンを[MATH]，全事例を囲む球面の最小直径を[MATH]とすると，SVMのVC次元[MATH]は，以下の上限値を持つ．

================================================================
[section type  : proposed_method]
[section title : SVM に基づく Chunk 同定]
================================================================
-----------------------------------------------------
  [subsection title : Chunk の表現方法]
-----------------------------------------------------
  [i:lead, score:0.23265] Chunk同定の際，各chunkの状態をどう表現するかが問題となる．
.....
  [i:79, score:0.26804] 一つの手法として，各chunk同定を分割問題とみなし，各単語の間(ギャップ)にタグを付与する手法が考えられる．
  [i:87, score:0.33289] さらにTjong Kim Sangらは，上記のモデルをIOB1と呼び，このモデルを基にIOB2/IOE1/IOE2の3種類の表現方法を提案している[CITE]．
  [i:91, score:0.26891] 各chunkに対し，そのchunkの役割を示すタグを付与する場合は，B/E/I/O/Sといったchunkの状態を示すタグと，役割を示すタグを'-'で連結し新たなタグを導入することによって表現する．
-----------------------------------------------------
  [subsection title : SVM による Chunk 同定]
-----------------------------------------------------
  [i:lead, score:0.06533] 基本的にSVMは2値分類器である．
.....
  [i:94, score:0.29290] そのため，chunkのタグ表現のように多値の分類問題を扱うためにはSVMに対し何らかの拡張を行う必要がある．
  [i:105, score:0.27602] chunkタグの学習に用いる素性としては，現在の単語およびその周辺の単語や品詞といった文脈を用いる．
  [i:110, score:0.32904] 一般に，左2つ(後ろ向きの場合は右2つ)のchunkタグは学習データに対しては付与されているが，テストデータに対しては付与されていない．
-----------------------------------------------------
  [subsection title : 重み付き多数決]
-----------------------------------------------------
  [i:lead, score:0.21533] 重み付き多数決とは，1つの学習器で出力を得るのではなく，学習データ，学習データの表現方法，素性の選択手法，学習アルゴリズム，あるいは学習アルゴリズムのパラメータ等の異なる複数の学習器を線形結合して出力を得るアルゴリズムのことを指す．
.....
  [i:132, score:0.54645] 例えば，Tjong Kim Sangらは，base NP同定の問題に対し，弱学習アルゴリズムにMBL，ME，IGTree等の7種類のアルゴリズム，さらにIOB1/IOB2/IOE1/IOE2の4種類の表現を用いて独立に学習した複数のモデルの重み付き多数決を行うことで，個々のモデルのどれよりも高精度の結果が得られたと報告している[CITE]．
  [i:133, score:0.51722] 本稿では，弱学習アルゴリズムにSVMを用い，IOB1/IOB2/IOE1/IOE2の4種類の表現，さらに解析方向(前向き/後ろ向き)の合計[MATH]種類の重み付け多数決を行うことで精度向上を試みる．
  [i:175, score:0.52362] その理由として，推定すべきクラスの数がIOB1，IOB2，IOE1，IOE2モデルは3に対し，IOBESモデルは5と異なり，VC boundや，Leave-One-Out boundを同じ条件で比較することが困難なことが挙げられる．

================================================================
[section type  : experiment_result]
[section title : 実験と考察]
================================================================
-----------------------------------------------------
  [subsection title : 実験環境，設定]
-----------------------------------------------------
  [i:lead, score:0.05618] 実験には以下の2種類のタグ付きデータを用いた．
.....
  [i:182, score:0.13295] base NP標準データセットと基本的に同一であるが，base NP以外に{ VP, PP, ADJP, ADVP, CONJP, INITJ, LST, PRT, SBAR}の合計10種類の英語の句を表現するタグが付与されている．
  [i:186, score:0.19415] このツールは，本実験のようなバイナリの素性表現に特化して高速化が施されており，VC boundを自動的に推定する機能を持っている．
  [i:189, score:0.22270] これはchunk同定において一般的に用いられる評価方法である．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, score:0.35571] 表[REF_fg:ind]に，各chunkの表現方法，および解析方向が異なる計8種のモデルで独立に学習した実験結果(テストデータに対する精度，推定された重み)をまとめた．
.....
  [i:191, score:0.35571] 表[REF_fg:ind]に，各chunkの表現方法，および解析方向が異なる計8種のモデルで独立に学習した実験結果(テストデータに対する精度，推定された重み)をまとめた．
  [i:192, score:0.07118] また，比較対象として，Start/End法を用いた学習結果についても示している．
  [i:193, score:0.38953] さらに，表[REF_fg:voting]に，これらを均一重み， 交差検定([MATH])，   VC bound，  Leave on Out boundの4種類の重み付けで多数決を行った際の結果をまとめた．
-----------------------------------------------------
  [subsection title : Chunkの表現方法と解析精度]
-----------------------------------------------------
  [i:lead, score:0.34493] 表[REF_fg:ind]から，Inside/Outsideに基づく8つの手法を比較すると，「IOE2 +後ろ向き」が最良の精度を，「IOE1 +前向き」が最低の精度を示すことが分かる．
.....
  [i:200, score:0.51229] IOEは，主辞となりやすいchunkの末尾に特化した学習が行われるため，先頭に特化するIOBに比べ優位となる．
  [i:202, score:0.48902] IOBは，chunkの先頭を，IOEは，chunkの末尾に特化して学習が行われる．
  [i:209, score:0.47889] そのため，chunkが連続する場合は，chunkの先頭に特化するIOB1がIOE1に比べ優位となる．
-----------------------------------------------------
  [subsection title : モデル選択能力]
-----------------------------------------------------
  [i:lead, score:0.16206] 重み付き多数決を行う際の重みは，各システムの未知データに対する精度の予測値であるため，これらの大小を比較することでモデル選択が行える．
.....
  [i:223, score:0.49063] 表[REF_fg:ind]から，VC bound，交差検定，それぞれが「IOE2 +後ろ向き」に対し最高の重みを，「IOE1 +前向き」に最低の重みを算出しており，テストデータに対する精度をうまく予想してる．
  [i:226, score:0.22881] その一方で，VC boundは学習と同時にモデル選択が行え，交差検定に比べ効率的であると考える．
  [i:227, score:0.31357] Leave-One-Out boundは他に比べ計算コストの小さいモデル選択手法であるが，その能力はVC boundや交差検定よりも劣ることが分かった．
-----------------------------------------------------
  [subsection title : 多数決の効果]
-----------------------------------------------------
  [i:lead, score:0.16956] 表[REF_fg:voting]から，多数決を行うことで，重みの付与方法によらず，単独のどのモデルよりも精度が向上することが確認できる．
.....
  [i:228, score:0.16956] 表[REF_fg:voting]から，多数決を行うことで，重みの付与方法によらず，単独のどのモデルよりも精度が向上することが確認できる．
  [i:229, score:0.12396] 重み付き多数決の手法間の精度差には，多くの場合，顕著な差は見られなかった．
  [i:230, score:0.27579] 特にVC bound，交差検定，Leave-One-Out boundは，ほぼ同等の精度となった．
-----------------------------------------------------
  [subsection title : 関連研究との比較]
-----------------------------------------------------
  [i:lead, score:0.51063] Tjong Kim Sangらは，弱学習アルゴリズムにMBL，ME，IGTree等の7種類のアルゴリズム，さらにIOB1/IOB2/IOE1/IOE2の4種類の表現を用いて独立に学習した複数のモデルの重み付き多数決を行うことで，baseNPデータセットに対し93.86の精度が得られたと報告している[CITE]．
.....
  [i:232, score:0.51063] Tjong Kim Sangらは，弱学習アルゴリズムにMBL，ME，IGTree等の7種類のアルゴリズム，さらにIOB1/IOB2/IOE1/IOE2の4種類の表現を用いて独立に学習した複数のモデルの重み付き多数決を行うことで，baseNPデータセットに対し93.86の精度が得られたと報告している[CITE]．
  [i:235, score:0.39696] 一方，従来手法は7種類の学習アルゴリズム，及び4つのchunk表現の異なるシステムの多数決の結果であり，個々の学習器の学習，及びテストの計算量は，SVM単独のシステムに比べ大きい．
  [i:245, score:0.25374] CoNLL-2000 Shared Taskにおいて我々はSVMとIOB2と前向き解析の単独システム用いて93.48の精度を報告している[CITE]．
-----------------------------------------------------
  [subsection title : 今後の課題]
-----------------------------------------------------
  [i:lead, score:0.00592] 他の分野への応用
.....
  [i:249, score:0.25421] 我々の提案する手法は，日本語の文節まとめ上げや固有名詞，専門用語抽出と一般的なchunk同定問題に応用可能である．
  [i:253, score:0.26211] しかし実際には，個々のchunkを同定に必要な文脈長は可変であり，個々のchunkに対し最適な文脈長を選択することでさらなる精度向上が期待できる．
  [i:257, score:0.38854] 本稿では，重み付き多数決の重みとして，SVMに固有の概念--- VC bound，Leave-One-Out boundを提案した．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[i:260, score:0.33765] 本稿では，Support Vector Machine (SVM)に基づく一般的なchunk同定問題の解析手法を提案し，実際のタグ付きコーパスを用いて実験を行った．
[i:262, score:0.41218] また，chunkの表現方法や解析方向の異なる複数のシステムの中から最適なものを選択するための「モデル選択基準」として，本稿で採用したVC boundは，従来からある交差検定と同程度の予測性能があることが確認された．
[i:264, score:0.34851] さらに，chunkの表現方法や解析方向の異なる複数のシステムの重み付き多数決を行うことで，個々のどのモデルよりも高い精度を示した．

