実験には以下の2種類のタグ付きデータを用いた．
base NP標準データセット(baseNP)
Penn Tree-bank/WSJの15-18を学習データ，00-14，19-24をテストデータとし，Brill Tagger[CITE]を用いてpart-of-speech (POS)を付与したデータである．
テストデータのサイズ以外は，base NP抽出に用いられるデータとして一般的なものである．
Chunkingデータセット(chunking)
base NP標準データセットと基本的に同一であるが，base NP以外に{ VP, PP, ADJP, ADVP, CONJP, INITJ, LST, PRT, SBAR}の合計10種類の英語の句を表現するタグが付与されている．
テストデータのサイズを除けば，CoNLL-2000 Shead Task[CITE]と同一のデータである．
それぞれのデータのサイズを表[REF_fg:env]に示す．
実験にはSVM学習パッケージTinySVMを用いた．
このツールは，本実験のようなバイナリの素性表現に特化して高速化が施されており，VC boundを自動的に推定する機能を持っている．
また，すべての実験において，Kernel関数は2次の多項式Kernelを使用した．
評価方法としては，適合率と再現率の調和平均で与えられるF値([MATH])を用いた．
これはchunk同定において一般的に用いられる評価方法である．
以後，特にことわらない限りF値のことを精度と呼ぶ．
表[REF_fg:ind]に，各chunkの表現方法，および解析方向が異なる計8種のモデルで独立に学習した実験結果(テストデータに対する精度，推定された重み)をまとめた．
また，比較対象として，Start/End法を用いた学習結果についても示している．
さらに，表[REF_fg:voting]に，これらを均一重み， 交差検定([MATH])，   VC bound，  Leave on Out boundの4種類の重み付けで多数決を行った際の結果をまとめた．
表[REF_fg:best]には，各の重み付け手法の中の最良の結果について，その適合率と再現率を示す．
表[REF_fg:ind]から，Inside/Outsideに基づく8つの手法を比較すると，「IOE2 +後ろ向き」が最良の精度を，「IOE1 +前向き」が最低の精度を示すことが分かる．
これは，以下に述べる我々の直観と合致する．
多くの場合，chunk中の主辞は末尾の単語となる．
すなわち，後ろ向きからから解析すると，主辞を最初に決定できるため優位となる．
[MATH] (後ろ向き[MATH]前向き)
IOEは，主辞となりやすいchunkの末尾に特化した学習が行われるため，先頭に特化するIOBに比べ優位となる．
[MATH] (IOE [MATH] IOB)
IOBは，chunkの先頭を，IOEは，chunkの末尾に特化して学習が行われる．
そのため，IOBは，前向き，IOEは後ろ向きから解析すると特化して学習される単語が先に推定されるため，優位となる．
[MATH] (IOB +前向き[MATH] IOB +後ろ向き，IOE前向き[MATH] IOE後ろ向き)
同一のchunkが連続することは稀である．
すなわち，chunkの連続に特化するIOB1/IOE1は，chunkの先頭/末尾に特化するIOB2/IOE2に比べ劣る．
[MATH] ({IOB1 IOE1}[MATH] {IOB2 IOE2})
同一chunkが連続する場合は，前のchunkの末尾の単語(主辞)よりはむしろ，後続するchunkの先頭の単語が境界の認定に役割を果たす場合が多い．
そのため，chunkが連続する場合は，chunkの先頭に特化するIOB1がIOE1に比べ優位となる．
[MATH] (IOB1 [MATH] IOE1 )
次にInside/Outside法(IOB1/IOB2/IOE1/IOE2の各手法)とStart/End法の精度を比較する．
颯々野らは，各学習アルゴリズムの特徴を考察しながら，決定リストについては細かい組み合せを考慮するStart/End法が，最大エントロピー方についてはより粗い情報を考慮するInside/Outside法が精度が良いと報告している[CITE]．
SVMを用いた本手法では，全体的にInside/Outside法の法が，Start/Endに比べ高い精度を示している．
SVMは，決定リストのように単独の素性(ルール)で分類するのではなく，最大エントロピーと同じく複数の素性の線型結合で分類するために，この結果は，颯々野らの分析と合致する．
さらに，別の要因として以下が考えられる．
まず，Start/Endは，5種類のタグを使い表現するため，Inside/Outsideと比較して，データスパースネスの問題を助長してしまう恐れがある．
また，5種類のタグを使うことで，矛盾のあるタグのシーケンスの数が増えてしまう．
具体的には，S→E，I→B，O→Iといったタグの連続は，タグ付けとしては不適切である．
一方，IOB1は，O→Bのみ，IOB2はO→Iのみが不適切な連続である．
タグ付けに関する指針，制約といった「タグ付けスキーマ」は，それらを明示的な形で与えない本手法では，システム自身がデータから学習する必要があり，それだけ余計なコストが生じてしまう．
つまり，矛盾のあるタグ列が少ない表現方法が優位であると考える．
重み付き多数決を行う際の重みは，各システムの未知データに対する精度の予測値であるため，これらの大小を比較することでモデル選択が行える．
表[REF_fg:ind]から，VC bound，交差検定，それぞれが「IOE2 +後ろ向き」に対し最高の重みを，「IOE1 +前向き」に最低の重みを算出しており，テストデータに対する精度をうまく予想してる．
これらの結果から，VC bound，交差検定がモデル選択基準として良好に機能していることが分かる．
交差検定はモデル選択に用いられる一般的な手法であるが，分割数が多くなると推定に多くの計算量を必要とする．
その一方で，VC boundは学習と同時にモデル選択が行え，交差検定に比べ効率的であると考える．
Leave-One-Out boundは他に比べ計算コストの小さいモデル選択手法であるが，その能力はVC boundや交差検定よりも劣ることが分かった．
表[REF_fg:voting]から，多数決を行うことで，重みの付与方法によらず，単独のどのモデルよりも精度が向上することが確認できる．
重み付き多数決の手法間の精度差には，多くの場合，顕著な差は見られなかった．
特にVC bound，交差検定，Leave-One-Out boundは，ほぼ同等の精度となった．
しかし，均一重みと比較して，上記の3つ手法で重みを推定するほうが，若干ながら優位であることが分かる．
Tjong Kim Sangらは，弱学習アルゴリズムにMBL，ME，IGTree等の7種類のアルゴリズム，さらにIOB1/IOB2/IOE1/IOE2の4種類の表現を用いて独立に学習した複数のモデルの重み付き多数決を行うことで，baseNPデータセットに対し93.86の精度が得られたと報告している[CITE]．
我々は単独の表現を用いた場合でも93.91 - 94.23の精度を得ている．
テストデータが異なるため，厳密な比較は行えないが，SVM単独の結果は，従来手法と同等だと考える．
一方，従来手法は7種類の学習アルゴリズム，及び4つのchunk表現の異なるシステムの多数決の結果であり，個々の学習器の学習，及びテストの計算量は，SVM単独のシステムに比べ大きい．
システムの複雑さという観点から見れば，SVM単独のシステムは，従来手法に比べ優位であると考える．
さらに，従来手法と同様に，各表現の重み付き多数決を行うことで94.40の精度を得ることができた．
これは，従来法の精度93.86に比べ優れていると考える．
多数決を実行することは，全体としてシステムが複雑になることが一つの問題点である．
Tjong Kim Sangらによる手法は，MBL，ME，IGTreeといった，7種類のアルゴリズムを用いており，全体として複雑になっている．
さらに，個々の学習器のパラメータは恣意的に設定されており，これらの最適なパラメータを考慮すると，設定すべきパラメータの数が多く，制御が困難であると考える．
一方，本手法は，単一のSVMのみを用い，それ以外の学習アルゴリズムを用いていない．
重み付き多数決を行うという観点から見れば，本手法は，従来手法に比べシステム全体の設計が，簡潔であり，設定すべきパラメータ数が少ない．
この点も，本手法の優位な点と考える．
CoNLL-2000 Shared Taskにおいて我々はSVMとIOB2と前向き解析の単独システム用いて93.48の精度を報告している[CITE]．
本実験結果から，多数決を行うことで，「IOB2 +前向き」に限らず，どの単独システムに比べても精度が向上している．
またCoNLL-2000で報告された重み付き多数決に基づく他の手法[CITE]よりも高い精度を示すことができた．
他の分野への応用
我々の提案する手法は，日本語の文節まとめ上げや固有名詞，専門用語抽出と一般的なchunk同定問題に応用可能である．
我々の提案する手法がこれらの他の分野でも有効であるか実際に検証を行う予定である．
可変長モデル
本稿では，左右2つの文脈のみを考慮する単純な固定長モデルを採用した．
しかし実際には，個々のchunkを同定に必要な文脈長は可変であり，個々のchunkに対し最適な文脈長を選択することでさらなる精度向上が期待できる．
颯々野らは日本語の固有名詞抽出において可変長モデルを提案し単純な固定長のモデルより高い精度が得られたと報告している[CITE]．
今後このような可変長のモデルを取りいれたいと考えている．
より予測能力の高いboundの採用
本稿では，重み付き多数決の重みとして，SVMに固有の概念--- VC bound，Leave-One-Out boundを提案した．
その一方でChapelleらは，これらより予測能力の高いboundを提案し，Kernel関数の選択やSoft Marginパラメータの選択に極めて有効であるとこを示している[CITE]．
これらの予測能力の高いboundを重みとして採用することでさらなる精度向上が期待できる．
実験には以下の2種類のタグ付きデータを用いた．
base NP標準データセット(baseNP)
Penn Tree-bank/WSJの15-18を学習データ，00-14，19-24をテストデータとし，Brill Tagger[CITE]を用いてpart-of-speech (POS)を付与したデータである．
テストデータのサイズ以外は，base NP抽出に用いられるデータとして一般的なものである．
Chunkingデータセット(chunking)
base NP標準データセットと基本的に同一であるが，base NP以外に{ VP, PP, ADJP, ADVP, CONJP, INITJ, LST, PRT, SBAR}の合計10種類の英語の句を表現するタグが付与されている．
テストデータのサイズを除けば，CoNLL-2000 Shead Task[CITE]と同一のデータである．
それぞれのデータのサイズを表[REF_fg:env]に示す．
実験にはSVM学習パッケージTinySVMを用いた．
このツールは，本実験のようなバイナリの素性表現に特化して高速化が施されており，VC boundを自動的に推定する機能を持っている．
また，すべての実験において，Kernel関数は2次の多項式Kernelを使用した．
評価方法としては，適合率と再現率の調和平均で与えられるF値([MATH])を用いた．
これはchunk同定において一般的に用いられる評価方法である．
以後，特にことわらない限りF値のことを精度と呼ぶ．
表[REF_fg:ind]に，各chunkの表現方法，および解析方向が異なる計8種のモデルで独立に学習した実験結果(テストデータに対する精度，推定された重み)をまとめた．
また，比較対象として，Start/End法を用いた学習結果についても示している．
さらに，表[REF_fg:voting]に，これらを均一重み， 交差検定([MATH])，   VC bound，  Leave on Out boundの4種類の重み付けで多数決を行った際の結果をまとめた．
表[REF_fg:best]には，各の重み付け手法の中の最良の結果について，その適合率と再現率を示す．
表[REF_fg:ind]から，Inside/Outsideに基づく8つの手法を比較すると，「IOE2 +後ろ向き」が最良の精度を，「IOE1 +前向き」が最低の精度を示すことが分かる．
これは，以下に述べる我々の直観と合致する．
多くの場合，chunk中の主辞は末尾の単語となる．
すなわち，後ろ向きからから解析すると，主辞を最初に決定できるため優位となる．
[MATH] (後ろ向き[MATH]前向き)
IOEは，主辞となりやすいchunkの末尾に特化した学習が行われるため，先頭に特化するIOBに比べ優位となる．
[MATH] (IOE [MATH] IOB)
IOBは，chunkの先頭を，IOEは，chunkの末尾に特化して学習が行われる．
そのため，IOBは，前向き，IOEは後ろ向きから解析すると特化して学習される単語が先に推定されるため，優位となる．
[MATH] (IOB +前向き[MATH] IOB +後ろ向き，IOE前向き[MATH] IOE後ろ向き)
同一のchunkが連続することは稀である．
すなわち，chunkの連続に特化するIOB1/IOE1は，chunkの先頭/末尾に特化するIOB2/IOE2に比べ劣る．
[MATH] ({IOB1 IOE1}[MATH] {IOB2 IOE2})
同一chunkが連続する場合は，前のchunkの末尾の単語(主辞)よりはむしろ，後続するchunkの先頭の単語が境界の認定に役割を果たす場合が多い．
そのため，chunkが連続する場合は，chunkの先頭に特化するIOB1がIOE1に比べ優位となる．
[MATH] (IOB1 [MATH] IOE1 )
次にInside/Outside法(IOB1/IOB2/IOE1/IOE2の各手法)とStart/End法の精度を比較する．
颯々野らは，各学習アルゴリズムの特徴を考察しながら，決定リストについては細かい組み合せを考慮するStart/End法が，最大エントロピー方についてはより粗い情報を考慮するInside/Outside法が精度が良いと報告している[CITE]．
SVMを用いた本手法では，全体的にInside/Outside法の法が，Start/Endに比べ高い精度を示している．
SVMは，決定リストのように単独の素性(ルール)で分類するのではなく，最大エントロピーと同じく複数の素性の線型結合で分類するために，この結果は，颯々野らの分析と合致する．
さらに，別の要因として以下が考えられる．
まず，Start/Endは，5種類のタグを使い表現するため，Inside/Outsideと比較して，データスパースネスの問題を助長してしまう恐れがある．
また，5種類のタグを使うことで，矛盾のあるタグのシーケンスの数が増えてしまう．
具体的には，S→E，I→B，O→Iといったタグの連続は，タグ付けとしては不適切である．
一方，IOB1は，O→Bのみ，IOB2はO→Iのみが不適切な連続である．
タグ付けに関する指針，制約といった「タグ付けスキーマ」は，それらを明示的な形で与えない本手法では，システム自身がデータから学習する必要があり，それだけ余計なコストが生じてしまう．
つまり，矛盾のあるタグ列が少ない表現方法が優位であると考える．
重み付き多数決を行う際の重みは，各システムの未知データに対する精度の予測値であるため，これらの大小を比較することでモデル選択が行える．
表[REF_fg:ind]から，VC bound，交差検定，それぞれが「IOE2 +後ろ向き」に対し最高の重みを，「IOE1 +前向き」に最低の重みを算出しており，テストデータに対する精度をうまく予想してる．
これらの結果から，VC bound，交差検定がモデル選択基準として良好に機能していることが分かる．
交差検定はモデル選択に用いられる一般的な手法であるが，分割数が多くなると推定に多くの計算量を必要とする．
その一方で，VC boundは学習と同時にモデル選択が行え，交差検定に比べ効率的であると考える．
Leave-One-Out boundは他に比べ計算コストの小さいモデル選択手法であるが，その能力はVC boundや交差検定よりも劣ることが分かった．
表[REF_fg:voting]から，多数決を行うことで，重みの付与方法によらず，単独のどのモデルよりも精度が向上することが確認できる．
重み付き多数決の手法間の精度差には，多くの場合，顕著な差は見られなかった．
特にVC bound，交差検定，Leave-One-Out boundは，ほぼ同等の精度となった．
しかし，均一重みと比較して，上記の3つ手法で重みを推定するほうが，若干ながら優位であることが分かる．
Tjong Kim Sangらは，弱学習アルゴリズムにMBL，ME，IGTree等の7種類のアルゴリズム，さらにIOB1/IOB2/IOE1/IOE2の4種類の表現を用いて独立に学習した複数のモデルの重み付き多数決を行うことで，baseNPデータセットに対し93.86の精度が得られたと報告している[CITE]．
我々は単独の表現を用いた場合でも93.91 - 94.23の精度を得ている．
テストデータが異なるため，厳密な比較は行えないが，SVM単独の結果は，従来手法と同等だと考える．
一方，従来手法は7種類の学習アルゴリズム，及び4つのchunk表現の異なるシステムの多数決の結果であり，個々の学習器の学習，及びテストの計算量は，SVM単独のシステムに比べ大きい．
システムの複雑さという観点から見れば，SVM単独のシステムは，従来手法に比べ優位であると考える．
さらに，従来手法と同様に，各表現の重み付き多数決を行うことで94.40の精度を得ることができた．
これは，従来法の精度93.86に比べ優れていると考える．
多数決を実行することは，全体としてシステムが複雑になることが一つの問題点である．
Tjong Kim Sangらによる手法は，MBL，ME，IGTreeといった，7種類のアルゴリズムを用いており，全体として複雑になっている．
さらに，個々の学習器のパラメータは恣意的に設定されており，これらの最適なパラメータを考慮すると，設定すべきパラメータの数が多く，制御が困難であると考える．
一方，本手法は，単一のSVMのみを用い，それ以外の学習アルゴリズムを用いていない．
重み付き多数決を行うという観点から見れば，本手法は，従来手法に比べシステム全体の設計が，簡潔であり，設定すべきパラメータ数が少ない．
この点も，本手法の優位な点と考える．
CoNLL-2000 Shared Taskにおいて我々はSVMとIOB2と前向き解析の単独システム用いて93.48の精度を報告している[CITE]．
本実験結果から，多数決を行うことで，「IOB2 +前向き」に限らず，どの単独システムに比べても精度が向上している．
またCoNLL-2000で報告された重み付き多数決に基づく他の手法[CITE]よりも高い精度を示すことができた．
他の分野への応用
我々の提案する手法は，日本語の文節まとめ上げや固有名詞，専門用語抽出と一般的なchunk同定問題に応用可能である．
我々の提案する手法がこれらの他の分野でも有効であるか実際に検証を行う予定である．
可変長モデル
本稿では，左右2つの文脈のみを考慮する単純な固定長モデルを採用した．
しかし実際には，個々のchunkを同定に必要な文脈長は可変であり，個々のchunkに対し最適な文脈長を選択することでさらなる精度向上が期待できる．
颯々野らは日本語の固有名詞抽出において可変長モデルを提案し単純な固定長のモデルより高い精度が得られたと報告している[CITE]．
今後このような可変長のモデルを取りいれたいと考えている．
より予測能力の高いboundの採用
本稿では，重み付き多数決の重みとして，SVMに固有の概念--- VC bound，Leave-One-Out boundを提案した．
その一方でChapelleらは，これらより予測能力の高いboundを提案し，Kernel関数の選択やSoft Marginパラメータの選択に極めて有効であるとこを示している[CITE]．
これらの予測能力の高いboundを重みとして採用することでさらなる精度向上が期待できる．
