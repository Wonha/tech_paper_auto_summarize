学習には，代表的な識別モデルの一つであり，ラベルありデータを用いて教師あり学習を行う最大エントロピーモデル(Maximum Entropy Method: \MEM, [CITE])を用いた．
これは，Fujitaら(2010)によると，Support Vector Machine (\SVM, [CITE])より，\MEM{}の精度がはるかに良かったためである．
[基本素性]まず，語義曖昧性解消タスクで一般的に利用される素性を，基本素性として利用する．
各対象語[MATH]に対し，出現形，基本形，品詞，品詞大分類（名詞，動詞，形容詞など）を利用する．
また，対象語が[MATH]番目の語だとすると，前後2語( [MATH], [MATH], [MATH], [MATH])の同じ情報も利用する．
更に，前後3語以内のbigrams, trigrams, skipbigramsも利用する．
これらの素性を利用したモデルを\bl{}とする．
[Bag-of-Words]各対象語[MATH]に対し，同一文内に出現する全内容語の基本形を素性として利用する．
これらの素性を利用したモデルを\bows{}とする．
[トピック素性] SemEval-2007 English WSDタスクでは，トピック情報を利用したシステムが，最も高い精度を得ている[CITE]．
Caiら(2007)の研究を参考に，トピック情報を利用した素性を導入した．
Caiらは，Bayesian topic models (Latent Dirichlet Allocation: LDA)を用いて教師なし状態でトピック分類を行い，推定したトピックを素性として利用している．
本稿では，訓練データと評価データにgibbslda++を適用し，文書（ファイル）単位でトピック分類を行った．
但し，新聞(\PN)の場合のみ，記事毎に分類した．
これは，新聞の場合は，記事毎に，内容ががらりと変わることがあるが，それ以外の文書（書籍やYahoo!知恵袋，白書など）では，がらりと変わると思われなかったためである．
また，一つの文書，あるいは記事は，複数のトピックに含まれることがある．
本稿では，対象語が属する文書，あるいは記事の含まれるトピック分類を素性として利用し，これらの素性を利用したモデルを\tp{X}とする．
ここで，Xは，トピック数であり，Xが多ければ多いほど，分類が細かいことになる．
本節では，[REF_sec:bccwj]章の訓練データの自動獲得方法で獲得した訓練データに正しい語義が付与されているかどうかを評価した．
評価対象には，前節（[REF_sec:result-lc]節）で利用した\BK{}において，追加できる最大文数を5文とした場合に獲得されたデータを用いた．
この条件では，47語，114語義に対し，1,038文が獲得されている．
人手評価の結果，正しい訓練データだったものは979文(94.3%)，誤っていたものは59文(5.7%)だった．
このように5.7%の誤りを含んでいたものの，表[REF_tb:result-lc-BK]によると，全体で1.4%の精度の向上が見られており追加の効果は高い．
誤った訓練データを獲得した原因で最も多かったのは，慣用表現である．
例えば，語義ID 20676-0-0-1「ある時刻と他の時刻との間（の長さ）．
」の例文「時間の問題」は慣用的な表現である．
しかし，獲得された5文のうち，1文は，文([REF_s:toru:error3])であり，語義ID 20676-0-0-3「空間と共に，物体界を成り立たせる基礎形式と考えるもの．
」の方がふさわしいだろう．
\exこの本はむずかしい\ul{時間の問題}を、抽象的な時間論というかたちではなく、.
..
慣用表現かどうかの判定は非常に難しく[CITE]，本稿の手法で，慣用表現による誤りを取り除くことは困難である．
すべての誤りを取り除くには，慣用表現辞書[CITE]などを利用し，慣用表現と思しき表現を利用しないことにするか，最終的に人手による判断が必要だろう．
次に多かった誤りは，対象語以外の形態素区切りの不一致によるものだった．
例えば，37713-0-0-6の例文「数を取る」の場合，文([REF_s:toru:error1])が獲得されている．
しかし，37713-0-0-6は「数える」という意味なので，文([REF_s:toru:error1])は誤りである．
\exペーパーテストではいい点\ul{数を取る}のかもしれませんがね。
[REF_sec:bccwj]節で述べたように，訓練データの追加条件は，例文を完全に含むこと以外にも，「対象例文の見出し語と，基本形，および，品詞大分類が一致する形態素に，該当する例文の語義IDを付与する．
」という条件がある．
しかし，見出し語以外は，形態素解析結果が一致するかは確認していない．
だが，文([REF_s:toru:error1])の場合，動詞「取る」の目的語部分（「数」と「点数」）は異なっているため，例文側も形態素解析し，前後の形態素も含めて一致する文だけを訓練データに追加すれば，排除できる誤りである．
ここまで述べたように，自動獲得した訓練データには誤りが含まれる．
しかし，1,038文の正誤評価には1日とかからなかったので，慣用表現のような，人手判断が必要な表現であっても，1日の人手作業で，正しい訓練データを4割近く増やすことができることになる．
また，自動獲得では間違いやすい部分のみ，人手作業を行うことも可能である．
そのようにして，効率的に正確な訓練データを増やすことも，今後，選択肢の一つになると考えられる．
