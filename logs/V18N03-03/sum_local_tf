================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[1940] 本稿では，まず，配布された訓練データのみを利用して学習した場合の結果を紹介する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[2401] 教師なし学習法も，クラスタリングに基づく手法[CITE]や，辞書定義文を利用した手法[CITE]などが提案されているが，一般に訓練データが存在する場合には，教師あり学習法による精度の方が高い[CITE]．

================================================================
[section type  : proposed_method]
[section title : データ]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : SemEval-2010: Japanese WSD タスク配布データ]
-----------------------------------------------------
  [1831] これは，各形態素の基本形を示しており，カタカナによる基本形(bfm)や，出現形から推測し，我々がほぼ自動的に付与したものである．
-----------------------------------------------------
  [subsection title : 岩波国語辞典の例文]
-----------------------------------------------------
  [1887] また，例文([REF_s:toru:ex1])--([REF_s:toru:ex6])において, ``—''によって見出し語を補完した部分（\ul{下線部}）には，例文を抽出した語義のIDを付与する．
-----------------------------------------------------
  [subsection title : センスバンク：檜]
-----------------------------------------------------
  [1942] そのため，リンクが存在する語義なら，檜で付与されている\lxd{}の語義を岩波国語辞典の語義に置き換えて，訓練データとして利用することができる．
-----------------------------------------------------
  [subsection title : 現代日本語書き言葉均衡コーパス]
-----------------------------------------------------
  [1775] このデータから，[REF_sec:iwanami-ex]章で抽出した岩波国語辞典の例文を利用し，訓練データを獲得する．
-----------------------------------------------------
  [subsection title : 未知語義数，および，獲得データサイズ]
-----------------------------------------------------
  [2356] なお，表[REF_tb:get:size]は，獲得傾向を確認するために，評価データに出現する語義かどうかを分けて表示しているが，実験では当然，評価データに出現しない語義の例文であっても区別せずに利用している．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : 学習器]
-----------------------------------------------------
  [1661] 学習には，代表的な識別モデルの一つであり，ラベルありデータを用いて教師あり学習を行う最大エントロピーモデル(Maximum Entropy Method: \MEM, [CITE])を用いた．
-----------------------------------------------------
  [subsection title : 素性]
-----------------------------------------------------
  [1765] 本稿では，対象語が属する文書，あるいは記事の含まれるトピック分類を素性として利用し，これらの素性を利用したモデルを\tp{X}とする．

================================================================
[section type  : proposed_method]
[section title : 結果と議論]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : 配布データのみを利用]
-----------------------------------------------------
  [2057] そのため，SENSEVAL-2の日本語辞書タスクと同様に，訓練データにおける語義の頻度分布のエントロピー[MATH]（式([REF_s:entropy])）を，単語の難易度の目安として利用し，対象語を，高難易度([MATH], [MATH])，中難易度([MATH], [MATH])，低難易度([MATH], [MATH])の3つにわけた[CITE]．
-----------------------------------------------------
  [subsection title : 自動獲得した訓練データも利用]
-----------------------------------------------------
  [2314] これは，例文そのものは非常に短いものが多く，切れ切れになってしまうが，例文を含む文全体を追加することで，もう少し広い前後の語などの情報も利用できるために，精度が向上したのだと考えられる．
-----------------------------------------------------
  [subsection title : 学習曲線]
-----------------------------------------------------
  [2462] 但し，本稿の手法の利点の一つは，訓練データに出現しなかった語義にも訓練データを獲得できることであるため，訓練データに出現していない語義に対しては，低難易語であっても訓練データを5文を上限として追加している．

================================================================
[section type  : experiment_result]
[section title : 自動獲得した訓練データの評価]
================================================================
[2494] だが，文([REF_s:toru:error1])の場合，動詞「取る」の目的語部分（「数」と「点数」）は異なっているため，例文側も形態素解析し，前後の形態素も含めて一致する文だけを訓練データに追加すれば，排除できる誤りである．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[2251] 本稿では，辞書の例文に完全一致する語を訓練データとして追加したが，本手法の場合，そもそも辞書に全く例文がない場合には，新しい訓練データは獲得できない．

