[REF_sec:intro]章で述べたように，SemEval-2010: Japanese WSDタスクは，対象コーパスの分野が多岐にわたるという特徴がある．
訓練データは，白書（以下，\OW{}），新聞(\PN)，本や雑誌(\PB)の分野から成り，評価データは，更に，Web上のQ&Aサイトである，Yahoo!知恵袋（以下，\OC{}）のデータも含んでいる．
これらのデータは，現代日本語書き言葉均衡コーパス(\bccwj)のうち，形態素解析の誤りを人手で修正したコアデータと呼ばれる部分から抽出されている．
なお，形態素解析は，\unidicに基づいて行われている．
また，本データには，岩波国語辞典[CITE]の語義を元に，語義IDが付与されている．
岩波国語辞典に定義されていない新語義（以下，\X{}）も付与されている場合があり，それらの新語義を推定することも，課題の一つである．
対象語は50語で，辞典に定義された語義数は219だった．
訓練データでは，2種類の新語義(\X)が出現している．
訓練データと評価データは，各語50文ずつ与えられた．
図[REF_fig:iwanami]は，本タスクで配布された岩波国語辞典の例である．
図[REF_fig:iwanami]に示すように，各エントリは，表記，品詞，定義文や例文などの情報を含んでいる．
図[REF_fig:trnORG]は，訓練データの例である．
ここで，sense=""で示される部分が，付与されている語義IDを示している．
例えば，図[REF_fig:trnORG]，6行めの形態素「取っ」の場合，語義ID '37713-0-0-1-1'が付与されている．
但し，図[REF_fig:trnORG]において，lemma=""の部分は，配布データには存在していなかった．
これは，各形態素の基本形を示しており，カタカナによる基本形(bfm)や，出現形から推測し，我々がほぼ自動的に付与したものである．
また，図[REF_fig:trnORG]において，各行頭に付与した番号は，参照用に便宜的に付与したものである．
本稿では，まず，岩波国語辞典の例文を抽出する．
図[REF_fig:iwanami]の例のように，「」で囲まれた部分は，各語義の例文になっている．
そこで，「」で囲まれた部分を例文として抽出する．
ここで，``—''の部分は，見出し語を補完することができる．
それにより，例えば，図[REF_fig:iwanami]に示した見出し語「とる」の場合，37713-0-0-1-1の例文として([REF_s:toru:ex1])，37713-0-0-3-1の例文として([REF_s:toru:ex3])，37713-0-0-6-3の例文として([REF_s:toru:ex6])などが獲得できる．
また，岩波国語辞典の場合，例文の前方や後方が，``…''という記号によって省略される場合がある．
例えば，「…に—って」のような形（図[REF_fig:iwanami]の37713-0-0-3-3）である．
こうした``…''は，取り除き，([REF_s:toru:ex3-3])のような形にした．
\ex手を\ul{取}って導く(37713-0-0-1-1) \ex責任を\ul{取る} (37713-0-0-3-1) \ex数を\ul{取る} (37713-0-0-6-3) \exに\ul{とっ}て(37713-0-0-3-3)
こうして抽出した例文は，形態素解析器Mecabの\unidic{}バージョンで解析する．
また，例文([REF_s:toru:ex1])--([REF_s:toru:ex6])において, ``—''によって見出し語を補完した部分（\ul{下線部}）には，例文を抽出した語義のIDを付与する．
但し，本タスクで推定する語義の粒度は，中語義（-で区切られた数字の，最後の部分を除いたもの．
37713-0-0-1, 37713-0-0-3等）なので，実際には，中語義に集約して抽出している．
つまり，例文([REF_s:toru:ex1])は37713-0-0-1，([REF_s:toru:ex3]), ([REF_s:toru:ex3-3])は37713-0-0-3，([REF_s:toru:ex6])は37713-0-0-6の例文として利用する．
本稿では，更に数種類の言語資源を利用した．
まず，基本語意味データベース\lxd[CITE]，および，センスバンク「檜」[CITE]を利用する．
\lxd{}は，日本人にとって最も馴染みの深い28,270語を収録した辞書である．
収録語は，心理実験によって選定されており，語義毎に語義文と例文がある．
また，各語義文と例文の内容語には，\lxd{}自身の語義が付与されている．
更に，京都大学テキストコーパスの内容語に対しても，\lxd{}の語義が付与されている．
これらの，\lxd{}によって語義付与されたセンスバンクを「檜」[CITE]と呼んでいる．
檜のサイズを表[REF_tab:words-counts]に示す．
なお，檜には構文情報も付与されているが，本稿では利用していない．
ここで，\lxd{}と岩波国語辞典の語義は，語義文の類似度の高いもの同士がリンクされている[CITE]．
そのため，リンクが存在する語義なら，檜で付与されている\lxd{}の語義を岩波国語辞典の語義に置き換えて，訓練データとして利用することができる．
例えば，岩波国語辞典の「とる」37713-0-0-6-3の語義文は「数える．
測る．
」であり，\lxd{}の19036420-49の語義文「数える．
測定する．
」と，非常に類似しており，リンクされている．
このリンクを用いることで，例えば，\lxd{}の19036420-49の例文([REF_s:toru:lxd])を，岩波国語辞典の37713-0-0-6(-3)の訓練データに追加できる．
但し，檜はIPA品詞体系に基づいた形態素解析が行われているため，\unidic{}によって形態素解析をやりなおし，語義IDのみを\ul{対応箇所}に付与しなおした．
\exそこで、医者は患者の顔色を診ながら脈を\ul{取っ}た。
[REF_sec:jwsd]章で述べたように，本タスクのデータは，現代日本語書き言葉均衡コーパス(\bccwj)のコアデータから抽出されている．
\bccwjのデータは，モニター公開データとして利用可能である．
但し，コアデータには，人手修正された形態素解析結果が付与されているが，コアデータ以外の\bccwjには形態素解析結果は付与されていない．
本稿では，\bccwjの2009年度版モニター公開データを利用する．
Readmeによると，\bccwj 2009年度版モニター公開データには4,300万語が含まれている．
このデータから，[REF_sec:iwanami-ex]章で抽出した岩波国語辞典の例文を利用し，訓練データを獲得する．
まず，[REF_sec:iwanami-ex]章で獲得した例文を文字の列として完全に含む文を抽出し，形態素解析を行う．
更に，対象例文の見出し語と，基本形，および，品詞大分類が一致する形態素に，該当する例文の語義IDを付与する．
例えば，37713-0-0-3-3の例文「にとって」（図[REF_fig:iwanami]参照）を含む文として，Yahoo!知恵袋(\OC{})から，文([REF_s:toru:oc])を獲得できる．
文([REF_s:toru:oc])の\ul{下線部}は，[REF_sec:iwanami-ex]章で抽出した例文([REF_s:toru:ex3-3])と一致した部分である．
また，これを形態素解析したものが，図[REF_fig:getOC]である．
\ex地運の相性を見ても彼はあなた\ul{にとって}最高の相手ですが、
このように，本手法によって獲得した文はラベルあり訓練データとして追加する．
但し，\bccwj{}には，評価対象文が含まれるので，評価対象文と同一の文は利用しないという制限を設けた．
また，新聞データ2年分（日本経済新聞（以下，\NIK{}），毎日新聞(\MAI)）からも，同様に訓練データを抽出した．
表[REF_tb:wsnum-test]に，評価データに出現する語義のうち，訓練データにも出現する語義と，評価データにのみ出現する語義の数を示す．
辞書に定義された全語義は219語義だが，評価データに出現する語義は，新語義(\X)を除くと，142語義([MATH])であり，辞書に定義された全語義の64.8%だった．
また，評価データにのみ出現する語義は9語義([MATH])，18例([MATH])だった．
また，[REF_sec:iwanami-ex]章から[REF_sec:bccwj]章で紹介した方法で獲得した訓練データのサイズを，表[REF_tb:get:size]に示す．
表[REF_tb:get:size]から，評価データにのみ出現する9語義に対しても，例文(\EX)，檜の両方から訓練データが獲得できることがわかる．
また，表[REF_tb:get:size]には，参考のため，訓練データの数値も表示している．
本提案手法では，新語義(\X)の訓練データは獲得できない．
また，それ以外の語義に対しても，評価データに出現する語義の異なりに対して，訓練データほどのカバー率はない．
但し，すべてのコーパスを利用すれば，ほぼ，訓練データに近いカバー率を得ることができている．
なお，表[REF_tb:get:size]は，獲得傾向を確認するために，評価データに出現する語義かどうかを分けて表示しているが，実験では当然，評価データに出現しない語義の例文であっても区別せずに利用している．
Fujitaら(2010)によると，対象語毎に訓練データの分野の組合せを変えて学習するより，分野に関係なくすべての訓練データを学習に用いる方が精度が良い．
学習器は，前述のように\MEM{}を用いる．
表[REF_tb:result-given]に，すべての訓練データを学習に用い，素性の組合せを変えた場合の結果を示す．
パラメータは，訓練データにおける対象語毎の交差検定で最も良い精度を出したものを用いている．
また，表[REF_tb:result-given]には，参考として，SemEval-2010でのBest result (RALI-2 [CITE])も掲載している．
更に，対象語を難易度毎に分けて傾向を分析する．
そのため，SENSEVAL-2の日本語辞書タスクと同様に，訓練データにおける語義の頻度分布のエントロピー[MATH]（式([REF_s:entropy])）を，単語の難易度の目安として利用し，対象語を，高難易度([MATH], [MATH])，中難易度([MATH], [MATH])，低難易度([MATH], [MATH])の3つにわけた[CITE]．
式([REF_s:entropy])において，[MATH]は，単語[MATH]の語義が[MATH]となる確率を表している．
各難易度に含まれる対象語の数は，それぞれ，[MATH]で9語，[MATH]で20語，[MATH]で21語だった．
対象語の詳細を，表[REF_tb:wd-diff]に示す．
表[REF_tb:result-given]によると，基本素性(\bl)だけを利用した場合でも，SemEval-2010のBest result (76.4%)より高い精度(77.7%)が得られた．
最も精度が高かったのは，トピック素性を利用した場合(\bl +\tp{200}) (78.0%)だった．
\bow{}を素性として利用する場合は，精度はかえって低下する傾向にある．
なお，\bl+\tp{200}で最も精度が高かった対象語は，「外」（精度100%），「経済」(98%)，「考える」(98%)，「大きい」(98%)，「文化」(98%)などである．
一方，最も精度の低かった語は，「取る」(36%)，「良い」(48%)，「上げる」(48%)，「出す」(50%)，「立つ」(54%)などである．
本節では，自動獲得した訓練データ（表[REF_tb:get:size]参照）を利用した場合の結果について紹介する（表[REF_tb:result-add]）．
表[REF_tb:result-add]では，素性は基本素性(\bl)のみ利用し，学習器は\MEM{}を利用した．
基本素性(\bl)を用いて，配布された訓練データのみで学習した場合の精度を基準とすると，難易度別に傾向が非常に異なることがわかる．
低難易語の場合，訓練データを追加すると，ほとんどの場合で精度が低下している．
それどころか，精度が最も高いのは，最頻語義を利用したBase Lineである．
しかし，中難易語では，精度向上する場合の方が多くなり，高難易語では，すべての場合で，精度が向上している．
特に，自動獲得したすべての訓練データを追加した場合，低難易語では最も精度が低くなり，高難易語では最も精度が高くなっている．
これはつまり，そもそも低難易語の場合には，誤りを含むかもしれない訓練データの追加は，むしろマイナスに働く可能性が高いが，中・高難易語の場合，訓練データに含まれる誤りによる悪影響より，訓練データが増えることによる好影響の方が強いことが伺える．
また，表[REF_tb:result-add]には，配布訓練データを用いず，自動獲得したすべての訓練データだけを用いた場合の実験結果も載せている．
それによると，低・中難易度では，配布訓練データを用いた精度に及ばないが，高難易度では，配布訓練データのみを用いる場合より高い精度を得ることができた．
このように，自動獲得した訓練データのみを利用した場合も善戦はしているが，配布訓練データも利用した場合の方が相当精度が高い（最大11.1ポイント差）．
この原因は，(1)特に\bccwjと新聞データは，岩波の例文を含む文のみを抽出しているため，訓練データのバリエーションに乏しい，(2)例文によって，獲得できる訓練データ数に非常にばらつきがあり，自然な分布にならない，(3)自動獲得しているため誤りが含まれる，などが考えられる．
また，岩波の例文そのものを追加した場合，精度は若干低下する．
しかし，例文を用いて訓練データを追加した，\bccwj{}も新聞も，\OW{}を除いて，精度向上が見られる．
これは，例文そのものは非常に短いものが多く，切れ切れになってしまうが，例文を含む文全体を追加することで，もう少し広い前後の語などの情報も利用できるために，精度が向上したのだと考えられる．
また，本手法の利点の一つに，訓練データで出現しない語義に対しても，訓練データを追加できることがある．
そこで，評価データにしか出現しなかった未知語義（9語義18例，[REF_sec:get-size]節参照）に対する精度のみを確認した．
訓練データに出現しない語義なので，訓練データのみ利用した場合，精度は0%である．
表[REF_tb:result-unseen]に，改良があった結果のみ表示する．
表[REF_tb:result-unseen]によると，すべて追加した場合でも，2例正解しただけであるが，訓練データだけでは絶対に正解できなかった部分であり，意義は大きい．
前節では，各コーパスから追加可能な文はすべて追加して学習した．
本節では，過学習していないか調べるため，追加する文数と精度との関連を調べた．
\bccwj{}や新聞データの場合，岩波の例文を完全に含む文を追加するため，例文毎に追加できる最大の文数を設定し，精度との関係を調べた．
つまり例えば，最大追加文数を5文と設定する場合，例文([REF_s:toru:ex1])--([REF_s:toru:ex3-3])のそれぞれに対し，条件を満たす文のうち，最初に出てきた5文までを訓練データとして追加する．
但し，当然，最大の文数まで獲得できない場合もある．
表[REF_tb:result-lc-BK]は，表[REF_tb:result-add]で最も良い精度を出した\PB{}を用いた場合の結果である．
また，参考までに，図[REF_fig:result-lc-BK]に学習曲線を示した．
表[REF_tb:result-lc-BK]および図[REF_fig:result-lc-BK]から，難易度によって，学習曲線が大きく異なることがわかる．
低難易語の場合，10文追加までは，かろうじて精度が向上している．
しかし，その後は，訓練データを追加すればするほど，精度が低下している．
一方で，中・高難易語に対しては，訓練データを追加した方が精度は向上する．
特に，高難易語での精度向上が大きい．
この結果から，低難易語には訓練データをほとんど追加せず，中・高難易語には訓練データを追加する方がいいことがわかる．
表[REF_tb:result-lc-BK]の「参考」に，中・高難易語にのみ，300文を上限に訓練データを追加した場合の結果を示す．
但し，本稿の手法の利点の一つは，訓練データに出現しなかった語義にも訓練データを獲得できることであるため，訓練データに出現していない語義に対しては，低難易語であっても訓練データを5文を上限として追加している．
この場合，低難易語の精度は下がらず，全体精度は80.0%を達成，未知語義も1例正解できた．
[REF_sec:intro]章で述べたように，SemEval-2010: Japanese WSDタスクは，対象コーパスの分野が多岐にわたるという特徴がある．
訓練データは，白書（以下，\OW{}），新聞(\PN)，本や雑誌(\PB)の分野から成り，評価データは，更に，Web上のQ&Aサイトである，Yahoo!知恵袋（以下，\OC{}）のデータも含んでいる．
これらのデータは，現代日本語書き言葉均衡コーパス(\bccwj)のうち，形態素解析の誤りを人手で修正したコアデータと呼ばれる部分から抽出されている．
なお，形態素解析は，\unidicに基づいて行われている．
また，本データには，岩波国語辞典[CITE]の語義を元に，語義IDが付与されている．
岩波国語辞典に定義されていない新語義（以下，\X{}）も付与されている場合があり，それらの新語義を推定することも，課題の一つである．
対象語は50語で，辞典に定義された語義数は219だった．
訓練データでは，2種類の新語義(\X)が出現している．
訓練データと評価データは，各語50文ずつ与えられた．
図[REF_fig:iwanami]は，本タスクで配布された岩波国語辞典の例である．
図[REF_fig:iwanami]に示すように，各エントリは，表記，品詞，定義文や例文などの情報を含んでいる．
図[REF_fig:trnORG]は，訓練データの例である．
ここで，sense=""で示される部分が，付与されている語義IDを示している．
例えば，図[REF_fig:trnORG]，6行めの形態素「取っ」の場合，語義ID '37713-0-0-1-1'が付与されている．
但し，図[REF_fig:trnORG]において，lemma=""の部分は，配布データには存在していなかった．
これは，各形態素の基本形を示しており，カタカナによる基本形(bfm)や，出現形から推測し，我々がほぼ自動的に付与したものである．
また，図[REF_fig:trnORG]において，各行頭に付与した番号は，参照用に便宜的に付与したものである．
本稿では，まず，岩波国語辞典の例文を抽出する．
図[REF_fig:iwanami]の例のように，「」で囲まれた部分は，各語義の例文になっている．
そこで，「」で囲まれた部分を例文として抽出する．
ここで，``—''の部分は，見出し語を補完することができる．
それにより，例えば，図[REF_fig:iwanami]に示した見出し語「とる」の場合，37713-0-0-1-1の例文として([REF_s:toru:ex1])，37713-0-0-3-1の例文として([REF_s:toru:ex3])，37713-0-0-6-3の例文として([REF_s:toru:ex6])などが獲得できる．
また，岩波国語辞典の場合，例文の前方や後方が，``…''という記号によって省略される場合がある．
例えば，「…に—って」のような形（図[REF_fig:iwanami]の37713-0-0-3-3）である．
こうした``…''は，取り除き，([REF_s:toru:ex3-3])のような形にした．
\ex手を\ul{取}って導く(37713-0-0-1-1) \ex責任を\ul{取る} (37713-0-0-3-1) \ex数を\ul{取る} (37713-0-0-6-3) \exに\ul{とっ}て(37713-0-0-3-3)
こうして抽出した例文は，形態素解析器Mecabの\unidic{}バージョンで解析する．
また，例文([REF_s:toru:ex1])--([REF_s:toru:ex6])において, ``—''によって見出し語を補完した部分（\ul{下線部}）には，例文を抽出した語義のIDを付与する．
但し，本タスクで推定する語義の粒度は，中語義（-で区切られた数字の，最後の部分を除いたもの．
37713-0-0-1, 37713-0-0-3等）なので，実際には，中語義に集約して抽出している．
つまり，例文([REF_s:toru:ex1])は37713-0-0-1，([REF_s:toru:ex3]), ([REF_s:toru:ex3-3])は37713-0-0-3，([REF_s:toru:ex6])は37713-0-0-6の例文として利用する．
本稿では，更に数種類の言語資源を利用した．
まず，基本語意味データベース\lxd[CITE]，および，センスバンク「檜」[CITE]を利用する．
\lxd{}は，日本人にとって最も馴染みの深い28,270語を収録した辞書である．
収録語は，心理実験によって選定されており，語義毎に語義文と例文がある．
また，各語義文と例文の内容語には，\lxd{}自身の語義が付与されている．
更に，京都大学テキストコーパスの内容語に対しても，\lxd{}の語義が付与されている．
これらの，\lxd{}によって語義付与されたセンスバンクを「檜」[CITE]と呼んでいる．
檜のサイズを表[REF_tab:words-counts]に示す．
なお，檜には構文情報も付与されているが，本稿では利用していない．
ここで，\lxd{}と岩波国語辞典の語義は，語義文の類似度の高いもの同士がリンクされている[CITE]．
そのため，リンクが存在する語義なら，檜で付与されている\lxd{}の語義を岩波国語辞典の語義に置き換えて，訓練データとして利用することができる．
例えば，岩波国語辞典の「とる」37713-0-0-6-3の語義文は「数える．
測る．
」であり，\lxd{}の19036420-49の語義文「数える．
測定する．
」と，非常に類似しており，リンクされている．
このリンクを用いることで，例えば，\lxd{}の19036420-49の例文([REF_s:toru:lxd])を，岩波国語辞典の37713-0-0-6(-3)の訓練データに追加できる．
但し，檜はIPA品詞体系に基づいた形態素解析が行われているため，\unidic{}によって形態素解析をやりなおし，語義IDのみを\ul{対応箇所}に付与しなおした．
\exそこで、医者は患者の顔色を診ながら脈を\ul{取っ}た。
[REF_sec:jwsd]章で述べたように，本タスクのデータは，現代日本語書き言葉均衡コーパス(\bccwj)のコアデータから抽出されている．
\bccwjのデータは，モニター公開データとして利用可能である．
但し，コアデータには，人手修正された形態素解析結果が付与されているが，コアデータ以外の\bccwjには形態素解析結果は付与されていない．
本稿では，\bccwjの2009年度版モニター公開データを利用する．
Readmeによると，\bccwj 2009年度版モニター公開データには4,300万語が含まれている．
このデータから，[REF_sec:iwanami-ex]章で抽出した岩波国語辞典の例文を利用し，訓練データを獲得する．
まず，[REF_sec:iwanami-ex]章で獲得した例文を文字の列として完全に含む文を抽出し，形態素解析を行う．
更に，対象例文の見出し語と，基本形，および，品詞大分類が一致する形態素に，該当する例文の語義IDを付与する．
例えば，37713-0-0-3-3の例文「にとって」（図[REF_fig:iwanami]参照）を含む文として，Yahoo!知恵袋(\OC{})から，文([REF_s:toru:oc])を獲得できる．
文([REF_s:toru:oc])の\ul{下線部}は，[REF_sec:iwanami-ex]章で抽出した例文([REF_s:toru:ex3-3])と一致した部分である．
また，これを形態素解析したものが，図[REF_fig:getOC]である．
\ex地運の相性を見ても彼はあなた\ul{にとって}最高の相手ですが、
このように，本手法によって獲得した文はラベルあり訓練データとして追加する．
但し，\bccwj{}には，評価対象文が含まれるので，評価対象文と同一の文は利用しないという制限を設けた．
また，新聞データ2年分（日本経済新聞（以下，\NIK{}），毎日新聞(\MAI)）からも，同様に訓練データを抽出した．
表[REF_tb:wsnum-test]に，評価データに出現する語義のうち，訓練データにも出現する語義と，評価データにのみ出現する語義の数を示す．
辞書に定義された全語義は219語義だが，評価データに出現する語義は，新語義(\X)を除くと，142語義([MATH])であり，辞書に定義された全語義の64.8%だった．
また，評価データにのみ出現する語義は9語義([MATH])，18例([MATH])だった．
また，[REF_sec:iwanami-ex]章から[REF_sec:bccwj]章で紹介した方法で獲得した訓練データのサイズを，表[REF_tb:get:size]に示す．
表[REF_tb:get:size]から，評価データにのみ出現する9語義に対しても，例文(\EX)，檜の両方から訓練データが獲得できることがわかる．
また，表[REF_tb:get:size]には，参考のため，訓練データの数値も表示している．
本提案手法では，新語義(\X)の訓練データは獲得できない．
また，それ以外の語義に対しても，評価データに出現する語義の異なりに対して，訓練データほどのカバー率はない．
但し，すべてのコーパスを利用すれば，ほぼ，訓練データに近いカバー率を得ることができている．
なお，表[REF_tb:get:size]は，獲得傾向を確認するために，評価データに出現する語義かどうかを分けて表示しているが，実験では当然，評価データに出現しない語義の例文であっても区別せずに利用している．
Fujitaら(2010)によると，対象語毎に訓練データの分野の組合せを変えて学習するより，分野に関係なくすべての訓練データを学習に用いる方が精度が良い．
学習器は，前述のように\MEM{}を用いる．
表[REF_tb:result-given]に，すべての訓練データを学習に用い，素性の組合せを変えた場合の結果を示す．
パラメータは，訓練データにおける対象語毎の交差検定で最も良い精度を出したものを用いている．
また，表[REF_tb:result-given]には，参考として，SemEval-2010でのBest result (RALI-2 [CITE])も掲載している．
更に，対象語を難易度毎に分けて傾向を分析する．
そのため，SENSEVAL-2の日本語辞書タスクと同様に，訓練データにおける語義の頻度分布のエントロピー[MATH]（式([REF_s:entropy])）を，単語の難易度の目安として利用し，対象語を，高難易度([MATH], [MATH])，中難易度([MATH], [MATH])，低難易度([MATH], [MATH])の3つにわけた[CITE]．
式([REF_s:entropy])において，[MATH]は，単語[MATH]の語義が[MATH]となる確率を表している．
各難易度に含まれる対象語の数は，それぞれ，[MATH]で9語，[MATH]で20語，[MATH]で21語だった．
対象語の詳細を，表[REF_tb:wd-diff]に示す．
表[REF_tb:result-given]によると，基本素性(\bl)だけを利用した場合でも，SemEval-2010のBest result (76.4%)より高い精度(77.7%)が得られた．
最も精度が高かったのは，トピック素性を利用した場合(\bl +\tp{200}) (78.0%)だった．
\bow{}を素性として利用する場合は，精度はかえって低下する傾向にある．
なお，\bl+\tp{200}で最も精度が高かった対象語は，「外」（精度100%），「経済」(98%)，「考える」(98%)，「大きい」(98%)，「文化」(98%)などである．
一方，最も精度の低かった語は，「取る」(36%)，「良い」(48%)，「上げる」(48%)，「出す」(50%)，「立つ」(54%)などである．
本節では，自動獲得した訓練データ（表[REF_tb:get:size]参照）を利用した場合の結果について紹介する（表[REF_tb:result-add]）．
表[REF_tb:result-add]では，素性は基本素性(\bl)のみ利用し，学習器は\MEM{}を利用した．
基本素性(\bl)を用いて，配布された訓練データのみで学習した場合の精度を基準とすると，難易度別に傾向が非常に異なることがわかる．
低難易語の場合，訓練データを追加すると，ほとんどの場合で精度が低下している．
それどころか，精度が最も高いのは，最頻語義を利用したBase Lineである．
しかし，中難易語では，精度向上する場合の方が多くなり，高難易語では，すべての場合で，精度が向上している．
特に，自動獲得したすべての訓練データを追加した場合，低難易語では最も精度が低くなり，高難易語では最も精度が高くなっている．
これはつまり，そもそも低難易語の場合には，誤りを含むかもしれない訓練データの追加は，むしろマイナスに働く可能性が高いが，中・高難易語の場合，訓練データに含まれる誤りによる悪影響より，訓練データが増えることによる好影響の方が強いことが伺える．
また，表[REF_tb:result-add]には，配布訓練データを用いず，自動獲得したすべての訓練データだけを用いた場合の実験結果も載せている．
それによると，低・中難易度では，配布訓練データを用いた精度に及ばないが，高難易度では，配布訓練データのみを用いる場合より高い精度を得ることができた．
このように，自動獲得した訓練データのみを利用した場合も善戦はしているが，配布訓練データも利用した場合の方が相当精度が高い（最大11.1ポイント差）．
この原因は，(1)特に\bccwjと新聞データは，岩波の例文を含む文のみを抽出しているため，訓練データのバリエーションに乏しい，(2)例文によって，獲得できる訓練データ数に非常にばらつきがあり，自然な分布にならない，(3)自動獲得しているため誤りが含まれる，などが考えられる．
また，岩波の例文そのものを追加した場合，精度は若干低下する．
しかし，例文を用いて訓練データを追加した，\bccwj{}も新聞も，\OW{}を除いて，精度向上が見られる．
これは，例文そのものは非常に短いものが多く，切れ切れになってしまうが，例文を含む文全体を追加することで，もう少し広い前後の語などの情報も利用できるために，精度が向上したのだと考えられる．
また，本手法の利点の一つに，訓練データで出現しない語義に対しても，訓練データを追加できることがある．
そこで，評価データにしか出現しなかった未知語義（9語義18例，[REF_sec:get-size]節参照）に対する精度のみを確認した．
訓練データに出現しない語義なので，訓練データのみ利用した場合，精度は0%である．
表[REF_tb:result-unseen]に，改良があった結果のみ表示する．
表[REF_tb:result-unseen]によると，すべて追加した場合でも，2例正解しただけであるが，訓練データだけでは絶対に正解できなかった部分であり，意義は大きい．
前節では，各コーパスから追加可能な文はすべて追加して学習した．
本節では，過学習していないか調べるため，追加する文数と精度との関連を調べた．
\bccwj{}や新聞データの場合，岩波の例文を完全に含む文を追加するため，例文毎に追加できる最大の文数を設定し，精度との関係を調べた．
つまり例えば，最大追加文数を5文と設定する場合，例文([REF_s:toru:ex1])--([REF_s:toru:ex3-3])のそれぞれに対し，条件を満たす文のうち，最初に出てきた5文までを訓練データとして追加する．
但し，当然，最大の文数まで獲得できない場合もある．
表[REF_tb:result-lc-BK]は，表[REF_tb:result-add]で最も良い精度を出した\PB{}を用いた場合の結果である．
また，参考までに，図[REF_fig:result-lc-BK]に学習曲線を示した．
表[REF_tb:result-lc-BK]および図[REF_fig:result-lc-BK]から，難易度によって，学習曲線が大きく異なることがわかる．
低難易語の場合，10文追加までは，かろうじて精度が向上している．
しかし，その後は，訓練データを追加すればするほど，精度が低下している．
一方で，中・高難易語に対しては，訓練データを追加した方が精度は向上する．
特に，高難易語での精度向上が大きい．
この結果から，低難易語には訓練データをほとんど追加せず，中・高難易語には訓練データを追加する方がいいことがわかる．
表[REF_tb:result-lc-BK]の「参考」に，中・高難易語にのみ，300文を上限に訓練データを追加した場合の結果を示す．
但し，本稿の手法の利点の一つは，訓練データに出現しなかった語義にも訓練データを獲得できることであるため，訓練データに出現していない語義に対しては，低難易語であっても訓練データを5文を上限として追加している．
この場合，低難易語の精度は下がらず，全体精度は80.0%を達成，未知語義も1例正解できた．
