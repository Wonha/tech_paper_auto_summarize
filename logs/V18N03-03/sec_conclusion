本稿では，訓練データの自動拡張による語義曖昧性解消の精度向上方法について述べた．
評価対象として，SemEval-2010日本語語義曖昧性解消タスクを利用した．
本稿では，辞書の例文，配布データ以外のセンスバンク（檜），ラベルなしコーパス(\bccwj),新聞データなど，さまざまなコーパスを利用して，訓練データの自動拡張を試みた．
配布データ以外のセンスバンク（檜）を利用する場合，語義が定義された辞書同士のリンクを経由して，訓練データを獲得した．
辞書同士のリンクは，定義文同士の類似度によって構築されている．
檜を追加した場合，78.8%の精度を得ることができた．
これは，配布データのみを利用した場合の結果(77.7%)より，+1.2%の改良である．
このように，異なる品詞体系，異なる辞書（語義）に基づいて構築されたセンスバンクであっても，自動的に訓練データに追加し，精度向上に寄与できることを示した．
人手で構築する言語資源は，構築のための時間と費用が非常にかかるため，こうした既存言語資源の有効利用は，ますます重要になると考えれられる．
また，センスバンク以外のラベルなしデータを用いる場合，辞書の例文を文字の列として完全に含み，かつ，形態素解析の結果，対象語と，基本形，および，品詞大分類が一致するものを訓練データとして追加した．
最も良い精度を出したラベルなしデータは，書籍（\bccwj{}の\BK{}）であり，79.5%(+1.8%)の精度を得た．
ここで，追加した例文のうち，1,038文をサンプリング評価したところ，94.3%に正しい語義が付与されていた．
このように，自動獲得した訓練データには誤りも含まれるものの，例文そのものを追加するより，本稿の提案手法のように，例文を完全に含む，より自然な文を利用する方が効果が高いことを示した．
難易度に基づいて傾向を分析した結果，低難易語には訓練データを追加せず，中・高難易語には訓練データを追加する方がいいことがわかった．
そのため，中・高難易語と未知語義にのみ訓練データを追加した場合，最高80.0%の精度を得た．
このように，本稿で紹介したような訓練データの追加は，非常に有効であると言える．
最後に，今後の課題として以下の3点を挙げる．
訓練データを追加する場合（[REF_sec:result-add]章参照）も，トピック素性を利用して実験を行う．
配布データのみを利用した場合には，トピック素性を利用した場合がもっとも良かった（[REF_sec:result-given]章参照）ためである．
辞書定義文から同義語を獲得し，[CITE]らと同様に，同義語を用いた訓練データの拡張も行う．
本稿では，辞書の例文に完全一致する語を訓練データとして追加したが，本手法の場合，そもそも辞書に全く例文がない場合には，新しい訓練データは獲得できない．
同義語も利用すれば，例文のみでは訓練データを新たに獲得できなかった語義についても新しい訓練データを追加できるかもしれない．
また，例文に完全一致する文のみの追加では，訓練データに偏りが出る恐れがあるが，その点を補完できると期待できる．
ラベルなしデータを利用した半教師あり学習法[CITE]による精度向上を図る．
半教師あり学習を適用する場合でも，始めに与える訓練データにない語義は，ラベルなしデータをいくら与えたところで推定できない．
そのため，本稿のようにあらかじめ低頻度語の訓練データを追加しておくことは重要だと思われる．
本稿では，訓練データの自動拡張による語義曖昧性解消の精度向上方法について述べた．
評価対象として，SemEval-2010日本語語義曖昧性解消タスクを利用した．
本稿では，辞書の例文，配布データ以外のセンスバンク（檜），ラベルなしコーパス(\bccwj),新聞データなど，さまざまなコーパスを利用して，訓練データの自動拡張を試みた．
配布データ以外のセンスバンク（檜）を利用する場合，語義が定義された辞書同士のリンクを経由して，訓練データを獲得した．
辞書同士のリンクは，定義文同士の類似度によって構築されている．
檜を追加した場合，78.8%の精度を得ることができた．
これは，配布データのみを利用した場合の結果(77.7%)より，+1.2%の改良である．
このように，異なる品詞体系，異なる辞書（語義）に基づいて構築されたセンスバンクであっても，自動的に訓練データに追加し，精度向上に寄与できることを示した．
人手で構築する言語資源は，構築のための時間と費用が非常にかかるため，こうした既存言語資源の有効利用は，ますます重要になると考えれられる．
また，センスバンク以外のラベルなしデータを用いる場合，辞書の例文を文字の列として完全に含み，かつ，形態素解析の結果，対象語と，基本形，および，品詞大分類が一致するものを訓練データとして追加した．
最も良い精度を出したラベルなしデータは，書籍（\bccwj{}の\BK{}）であり，79.5%(+1.8%)の精度を得た．
ここで，追加した例文のうち，1,038文をサンプリング評価したところ，94.3%に正しい語義が付与されていた．
このように，自動獲得した訓練データには誤りも含まれるものの，例文そのものを追加するより，本稿の提案手法のように，例文を完全に含む，より自然な文を利用する方が効果が高いことを示した．
難易度に基づいて傾向を分析した結果，低難易語には訓練データを追加せず，中・高難易語には訓練データを追加する方がいいことがわかった．
そのため，中・高難易語と未知語義にのみ訓練データを追加した場合，最高80.0%の精度を得た．
このように，本稿で紹介したような訓練データの追加は，非常に有効であると言える．
最後に，今後の課題として以下の3点を挙げる．
訓練データを追加する場合（[REF_sec:result-add]章参照）も，トピック素性を利用して実験を行う．
配布データのみを利用した場合には，トピック素性を利用した場合がもっとも良かった（[REF_sec:result-given]章参照）ためである．
辞書定義文から同義語を獲得し，[CITE]らと同様に，同義語を用いた訓練データの拡張も行う．
本稿では，辞書の例文に完全一致する語を訓練データとして追加したが，本手法の場合，そもそも辞書に全く例文がない場合には，新しい訓練データは獲得できない．
同義語も利用すれば，例文のみでは訓練データを新たに獲得できなかった語義についても新しい訓練データを追加できるかもしれない．
また，例文に完全一致する文のみの追加では，訓練データに偏りが出る恐れがあるが，その点を補完できると期待できる．
ラベルなしデータを利用した半教師あり学習法[CITE]による精度向上を図る．
半教師あり学習を適用する場合でも，始めに与える訓練データにない語義は，ラベルなしデータをいくら与えたところで推定できない．
そのため，本稿のようにあらかじめ低頻度語の訓練データを追加しておくことは重要だと思われる．
