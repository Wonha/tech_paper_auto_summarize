固有表現抽出
\label{sec-ner}

固有表現抽出とは，テキストに含まれる人名，地名，組織名などの固有表現を
抽出するタスクである．本稿では，表\ref{tbl-irex-tags}に示すとおり，
IREX \cite{IREX1999}で定義される8種の固有表現を抽出対象とし，
IOB2方式\cite{Sang:IOB1999} に基づいて17種類のタグを使用する．


\begin{table}[b]
\caption{固有表現タイプとタグ}
\label{tbl-irex-tags}
\input{02table01.txt}
\end{table}


例えば，``東京/都/に''という文は次のようにタグ付けされる：

\begin{center}
``東京/B-$<$LOC$>$ 都/I-$<$LOC$>$ に/O''
\end{center}


このタスクは単語列$W = w_1 \ldots w_n$に対して固有表現の種類を表す固有
表現タグ列$T = t_1 \ldots t_n$を付与する系列ラベリング問題として考える
ことができる．近年，系列ラベリング問題では
CRF\cite{Lafferty:CRF2001,suzuki-mcdermott-isozaki:2006:COLACL}などの
識別モデルが成功を収めている．本稿ではlinear-chain CRFを利用し，固有表
現タグ列の事後確率を以下の式で算出する．
\begin{align}
P(T|W) & =  \frac{1}{Z(W)} 
\exp \left\{ \sum_{i=1}^{n} \left( \sum_{a} \lambda_{a} \cdot f_{a}(t_i,w_i) +
\sum_{b} \lambda_{b} \cdot f_{b}(t_{i-1},t_{i}) \right) \right\} 
\label{eqn-sentence-prob}\\
Z(W) & =  \sum_{T}
\exp \left\{ \sum_{i=1}^{n} \left( \sum_{a} \lambda_{a} \cdot f_{a}(t_i,w_i) +
\sum_{b} \lambda_{b} \cdot f_{b}(t_{i-1},t_{i}) \right) \right\}
\end{align}

$w_i$と$t_i$は位置$i$に置ける単語（周辺単語を含む）と固有表現タグ，
$f_{a}(t_i,w_i)$，$f_{b}(t_{i-1},t_{i})$は当該単語及び固有表現タグがあ
る条件を満たす時に1となる素性関数
\footnote{本稿では素性として，windowサイズ5単語での表記と品詞に関するn 
グラム (n=1, 2, 3)と，固有表現タグの2グラムを利用する．} である．
$\lambda_{a}$，$\lambda_{b}$は素性関数の重みであり，正解データから推定
される．$Z(W)$は正規化項である．(\ref{eqn-sentence-prob}) 式を最大化す
るタグ列が最尤タグ列であり，Viterbiアルゴリズムを利用して求められる．



タグ信頼度に基づく解析誤り検出
\label{sec-confidence-measure}


\subsection{タグ事後確率}

(\ref{eqn-sentence-prob})式から，文全体の事後確率をタグ列全体の信頼度
として利用することは自然であり，従来の能動学習では，通常，文全体の事後
確率からデータ選択のための信頼度を算出していた．本稿では，文ではなくタ
グ単位の事後確率に着目し，この値をタグ自体の信頼度とみなす．そしてタグ
信頼度の値を利用して解析誤りであるタグを自動的に判定する．

\begin{figure}[b]
\begin{center}
\includegraphics{17-4ia2f2.eps}
\end{center}
\caption{タグ信頼度計算の模式図}
\label{fig-confidence-measure}
\end{figure}


図\ref{fig-confidence-measure}はタグ信頼度計算の模式図である．単語
$w_i$のタグ候補$t_{i,j}$についての信頼度は，次式のように計算される．
\begin{equation}
P(t_{i,j}|W)  =  \sum_{T} P(t_{i,j},T|W)
\label{eqn-tag-prob}
\end{equation}

ここで$\sum_{T} P(t_{i,j},T|W)$はタグ候補$t_{i,j}$を通る全てのタグ列の
事後確率を総和したものであり，周辺確率 (marginal probability) とも呼ば
れる．なお，$j=1,\ldots,k$は表\ref{tbl-irex-tags}に示す固有表現タグの
全種類に対応するものであり，本稿では$k=17$である．タグ候補 の信頼度は，
前向きおよび後向きアルゴリズム\cite{FSNLP1999}により以下のように効率的
に算出することができる．
\begin{equation}
P(t_{i,j}|W)  =  \frac{1}{Z(W)} \alpha_{i,j} \cdot \beta_{i,j}
\end{equation}

ここで
{\allowdisplaybreaks
\begin{align}
\alpha_{i,j} & = 
\sum_{k} \left\{ \alpha_{i-1,k} \cdot \exp 
\left( \sum_{a} \lambda_{a} \cdot f_{a}(t_i,w_i) + 
\sum_{b} \lambda_{b} \cdot f_{b}(t_{i-1},t_{i}) \right) \right\} \\
\beta_{i,j} & = 
\sum_{k} \left\{ \beta_{i+1,k} \cdot \exp 
\left( \sum_{a} \lambda_{a} \cdot f_{a}(t_{i+1},w_{i+1}) + 
\sum_{b} \lambda_{b} \cdot f_{b}(t_{i},t_{i+1}) \right) \right\} \\
\alpha_{0,j} & = 1 \\
\beta_{n+1,j} & = 1
\end{align}
}

以上のようにして，文中の各単語に付与されうる全てのタグに関して信頼度が
得られる．


\subsection{リジェクター}
\label{sec-rejector}

リジェクターは，タグ信頼度を参照し，システム出力の解析誤りを自動で検出
する．各単語において，デコーダが出力した最尤タグ$t_d$と信頼度1位タグ
$t_1$を参照し，以下のような手順で各固有表現タグが正解か不正解かを判定
する．なお，最尤タグ$t_d$は，(\ref{eqn-sentence-prob})式を最大化するタ
グであり，信頼度1位タグ$t_1$は(\ref{eqn-tag-prob})式を最大化するタグで
ある．

\begin{stepenumerate}
\item 最尤タグ $t_d$ が信頼度1位タグ$t_1$と不一致ならば，最尤タグ$t_d$
を解析誤りとしてリジェクトする
\footnote{最尤タグ$t_d$ は稀に信頼度1位タグ$t_1$と一致しない．これは
CRFの特徴に由来する．}
\label{step-reject1}
\item {[\ref{step-reject1}]}でアクセプトされた場合，信頼度1位タグ$t_1$
の信頼度$cs_1$が閾値$\theta$以下ならば最尤タグ$t_d$ を解析誤りとしてリ
ジェクトする
\item それ以外であれば最尤タグ$t_d$ を正解としてアクセプトする
\end{stepenumerate}

閾値が高ければリジェクトされるタグ数が増え，人手のチェック・修正コスト
が増加する．実際の運用では，開発データにてリジェクト・アクセプトの判定
誤り率が最小となるような閾値を設定すればよい．このようにして，タグ信頼
度を利用することにより，タグを単位として解析誤りを検出することが可能と
なる．


能動学習
\label{sec-active-learning}

タグ単位での誤り検出は能動学習のデータセレクションに有効である．もし，
文中にリジェクトタグが1つでも含まれれば，その文は，現在のモデル（ベー
スモデル）が確信を持って解析できない，何か新しい事象が存在していること
を意味する．すなわち，このような文を優先的にモデル学習の対象とすること
で高い学習効果を期待できる．そこでここでの能動学習では，文中にリジェク
トタグを含むか否かに基づいたデータセレクションを採用する．また，選別さ
れた文について，全てのタグを人手でチェック・修正する必要は無く，リジェ
クトされたタグのみを対象としてチェック・修正すればよい．図
\ref{fig-active-learning}は本稿で提案する能動学習のスキームを示したも
のである．固有表現抽出デコーダでは，初期正解データから学習したベースモ
デルに基づいて最尤タグが出力される．続いて\ref{sec-confidence-measure} 
章で示した手順で最尤タグの解析誤りを検出する．このステップでは，同じベー
スモデルを利用してタグ信頼度を計算し，その結果を参照してリジェクターで
誤り検出を実行する．データセレクションにて少なくとも1つ以上のリジェク
トタグを含む文のみを選別し，検出された誤りタグ（リジェクトタグ）のみを
人手でチェック・修正する．最終的に，人手修正済みデータを初期正解データ
に追加し，モデルを再学習して更新する．

\begin{figure}[b]
\begin{center}
\includegraphics{17-4ia2f3.eps}
\end{center}
\caption{提案する能動学習スキーム}
\label{fig-active-learning}
\end{figure}


\subsection{評価実験}

\begin{table}[b]
\caption{能動学習でのデータ構成}
\label{tbl-al-corpus}
\input{02table02.txt}
\end{table}

今回，本稿で提案する能動学習の効果を学習コストの面から評価した．実験用
にブログデータ（45,694文）をWebから収集し，表\ref{tbl-al-corpus}に示す
とおり4つのセグメントに分割した．全データに対して予め人手で正解となる
固有表現タグを付与したが，追加平文データに関しては，これらの正解タグは
隠しておき，プレーンテキストとして扱う．そして人手修正を模する際にこの
正解タグの情報を利用する．開発データは\ref{sec-rejector}節で述べたリジェ
クター判定に利用する閾値を最適化する際に利用した．

学習コストは人手でタグをチェック・修正した単語の割合 (WCR: Word Check
Rate) とみなした．WCRは，追加平文データに含まれる総単語数に対するチェッ
クされた単語数の割合であり，次式で表される．
\begin{displaymath}
WCR = チェックした単語数 / 総単語数
\end{displaymath}

本方式は，リジェクターの閾値に依存して，検出されるリジェクトタグ数が変
化するため，閾値を0.1から1.0の範囲で0.1ずつ段階的に変更し，リジェクト
タグを含む文のみをデータセレクションで選別して，誤り検出済みデータとし
た．それぞれの閾値で得られた誤り検出済みデータのうち，リジェクトタグだ
けを予め付与していた正解タグと変換した．この手順は，人手修正を模したも
のである．修正後のデータを初期正解データに追加し，ベースモデルを再学習
する．

この能動学習と比較するため，タグ単位ではなく文単位の信頼度に基づくデー
タセレクションによる能動学習と比較した．文全体の事後確率を信頼度とみな
し，低信頼度の文を優先的に選択する能動学習である．本稿で提案するタグ単
位の信頼度に基づく能動学習と異なり，文単位の信頼度の能動学習では，選択
された文は全ての単語についてタグのチェックが必要であるとみなされる．

以上，2つの能動学習について，再学習したモデルの精度と学習コスト (WCR) 
の関係を評価した．モデルの精度は評価データにおけるF値を利用した．
\begin{equation}
F  =  \frac{2 \times recall \times precision}{recall + precision}
\end{equation}



\subsection{結果と考察}

\subsubsection{学習曲線と精度：}

図\ref{fig-learning-curve}に提案手法でのタグ単位のデータセレクションに
よる能動学習と，文単位のデータセレクションによる能動学習での学習曲線を
示す．再学習後のモデルの精度がF値で0.76となるために，文単位での能動学
習では全データの60\%を人手でチェックするコストが必要だが，タグ単位での
能動学習では，わずか20\%で済む．言い換えると，タグ単位の能動学習は従来
の文単位の能動学習と比較して学習コストを1/3に低減したことを意味する．

また，図\ref{fig-learning-curve} に，追加平文データのタグをまったく修
正しないで，モデルを再学習して測定した精度も併せて示す．ベースモデルで
はF値0.612であったものが，タグ修正なしの追加平文データをすべて加えた場
合はF値0.602に若干低下した．タグ修正なしデータには誤りタグが多く残存し
ており，そのためF値が低下したと考えられる．このように，ベースモデルに
よるデコード結果を単純に加えただけでは，学習データ量が増えても精度向上
には寄与せず，悪化する場合もある．


\begin{figure}[b]
\begin{center}
\includegraphics{17-4ia2f4.eps}
\end{center}
\caption{能動学習の学習曲線}
\label{fig-learning-curve}
\end{figure}


\subsubsection{タグ修正内容の分析：}

更にタグ単位の能動学習の効果を調べるために，リジェクトタグに対して実施
されたタグ修正の内容を以下の4タイプに分類して内訳を分析した．

\begin{itemize}
\item {\bf No Change:} リジェクトタグが修正不要
\item {\bf OtoBI:} リジェクトタグがOタグであり，B-又はI-タグに置換
\item {\bf BItoO:} リジェクトタグがB-又はI-タグであり，Oタグに置換
\item {\bf BItoBI:} リジェクトタグがB-又はI-タグであり，別のB-又はI-タグに置換
\end{itemize}

\begin{table}[b]
\caption{リジェクトタグの置換タイプ分布}
\label{tbl-rejected-tags}
\input{02table03.txt}
\end{table}


表\ref{tbl-rejected-tags}はリジェクター閾値が0.5の時のリジェクトタグに
ついて，上記4タイプの分類の分布を示している．この閾値は開発データで，
リジェクターの判定誤り率が最低となる値である．

表からわかるとおり，{\bf No Change}タイプの割合が最も多い．これはリジェ
クターが本来修正の必要の無いタグまで過剰にリジェクトしていることを意味
する．この結果は，更新するモデルの精度そのものには悪影響を及ぼさないが，
学習コストの面では無駄が含まれていることを示している．

続いて{\bf OtoBI}タイプが2番目に割合が多く，全体の1/3を占める．実質的
な変化のなかった{\bf No Change}タイプを除き，何かしらの修正が加わった3
つのタイプ ({\bf OtoBI}，{\bf BItoO}，{\bf BItoBI}) だけを考慮すると，
{\bf OtoBI}タイプは全修正の約60\%を占める．つまり，ベースモデルでは固
有表現として認識できなかったものが，固有表現に修正されたケースが最も多
い．このことは，誤り検出済みデータ中には，初期正解データにはない，新し
い固有表現が多く含まれていることを示唆している．


ブートストラップ型固有表現抽出
\label{sec-bootstrapping}

\ref{sec-active-learning}章で述べた通り，実際の修正では約60\%がOタグ
をB-またはI-タグに変更する必要がある．この事実は固有表現抽出タスクの特
徴に由来するものと推察される．つまり，固有表現抽出タスクでは，全コーパ
スの殆どはOタグで占められている．実際，\ref{sec-active-learning}章で
我々が整備した追加平文データにおいても，91\%がOタグであった．そのため
固有表現の新語が文中に出現すると，ベースモデルではOタグが付与されてし
まうことが多い．

\begin{table}[b]
\caption{上位2位のタグ精度}
\label{tbl-second-accuracy}
\input{02table04.txt}
\end{table}


このようにOタグが支配的であるという傾向があるならば，OタグではないB-
またはI-タグの候補の可能性を考慮することが必要である．即ち，Oタグがリ
ジェクトされたときに，次に信頼度の高いタグは何かを調べることは意味があ
ると考えられる．

そこで，閾値0.5の時のタグ信頼度が上位2位までのタグについて，その精度を
分析したものを表\ref{tbl-second-accuracy}に示す．信頼度1位のタグ（1位
タグ）がアクセプトとされた時，その精度は94\%と高い．一方，1位タグがリ
ジェクトされた時，1位タグの精度はわずか43\%であった．しかし，信頼度2位
のタグ（2位タグ）の精度は29\%であり，1位タグと2位タグをどちらも考慮す
ると，いずれかに正解タグが存在する可能性が72\%まで高まる．このことから，
上位2位のタグまでを考慮することにより，システム出力のリジェクト箇所を
自動的に修正できる可能性があることがわかる．

図\ref{fig-tag-graph}に，閾値0.5で1位タグがリジェクトされる場合は2位タ
グまで考慮するときのタグの状況を示す．以後，本稿ではこのラティス構造
をタググラフと呼ぶ．``3丁目の夕日''という映画タイトル（固有物名ART）を1
位タグだけでは正しく固有表現として認識できていない．しかし，2位タグま
で考慮すると，正しいタグ列が存在していることがわかる．もしこの正解のタ
グ列を自動的にシステムが発見できれば，この正しいタグ列情報を人手修正し
た正解データと同等のものとして利用できる．

\begin{figure}[t]
\begin{center}
\includegraphics{17-4ia2f5.eps}
\end{center}
\caption{タググラフ}
\label{fig-tag-graph}
\end{figure}


\subsection{半自動自己更新型固有表現抽出}

以上の考察をふまえ，新しい学習スキームである半自動自己更新型固有表現抽
出 (UpdateNER) を提案する．これは，予め用意する固有表現リストをシード
とし，そのシードを利用してタググラフから正解のタグ列を発見する方式であ
り，シードを利用して新しいインスタンスを取得するブートストラップ型の学
習に類似している．図\ref{fig-update-ner}にUpdateNERの概要を示す．リジェ
クターでは，タグ信頼度に基づいてリジェクト／アクセプト判定をした後，適
宜2位までのタグを考慮したタググラフを出力する．ここでリジェクターは
\ref{sec-active-learning}章で述べた処理手続きを以下のように変更して動
作する．

\begin{stepenumerate}
\item 1位タグの信頼度スコア$cs_1$が閾値以上であれば，1位タグ$t_1$のみ
をアクセプトする．それ以外は[\ref{step-second-accept}]の処理へ進む
\item $cs_1$ が閾値より小さければ，1位タグ$t_1$と更に2位タグ$t_2$をア
クセプトする
\label{step-second-accept}
\end{stepenumerate}

後続のデータセレクションでは，2位までのタグ候補を有するタググラフ構造
を持つ文を抽出する．そして，コンテキスト抽出にて以下の手順で正解タグ列
が存在するかを調べ，該当するタグ列が存在すればそのタグ列を抽出する．

\begin{stepenumerate}
\item タググラフ内で最長となる固有表現が成立するタグ列を選択する
\label{step-longest-match}
\item 該固有表現が別途準備するシードリストである固有表現リストに存在し
ていれば文全体のタグ列を正解タグ列として抽出する
\label{step-seed-comparison}
\end{stepenumerate}

\begin{figure}[t]
\begin{center}
\includegraphics{17-4ia2f6.eps}
\end{center}
\caption{UpdateNERの概要}
\label{fig-update-ner}
\end{figure}


ステップ[\ref{step-longest-match}]では，タググラフの中から最も有望と思
われるタグ列を選ぶことを意図して，最長となる固有表現が成立するルートを
選択する．例えば，図\ref{fig-tag-graph}で示すタググラフの場合，``3''，
``丁目''，``の''，``夕日''の4単語が2位タグまでの候補を有しているため，
16通りのタグ列が存在する．例えば，``B I I I''，``B I I O''，``B I O
O''，``O O O I''，``O O O O'' などである．しかし，ここでは``B I I I''
のタグ列で最長の固有表現（``3丁目の夕日''で固有物名ART）が構成できるた
め，このタグ列を選択する．他の部分文字列からなる固有表現，例えば，
``3''， ``3丁目''，``3丁目の''でいずれも固有物名ARTとなるようなタグ列
は全て無視される．

ステップ[\ref{step-seed-comparison}]では，ステップ
[\ref{step-longest-match}]で選択した有望なタグ列が本当に正解であるとみ
なしてよいかを判定する．タグ列の確からしさを判定するための手がかりが必
要となるので，ここではシードとなる固有表現リストを準備し，表記と対応す
る固有表現タイプを記載しておく．このリストは，人手で必要な固有表現を登
録しても良いし，辞書のような外部DBを利用して自動的に構築しても良い．も
し同じ固有表現がステップ[\ref{step-longest-match}]で選択されたタグ列お
よび固有表現リストに存在していれば，このタグ列は正解であると判断されて
正解データとして抽出される．そして，このようにして抽出されたデータを初
期正解データに追加し，モデルを再学習する．

以上のようにUpdateNERでは，シードを与えるだけで学習データの収集・構築
を実行できるため，日々増大する固有表現にモデルを追随させることが可能と
なる枠組みを備えている．


\subsection{評価実験}

UpdateNERで1週間分のブログテキストからどの程度効果的にモデル更新ができ
るか評価した．表\ref{tbl-update-corpus}に実験でのデータ内訳を示す．モ
デルの性能評価を行う評価データは2006年12月のブログを利用する．また，ベー
スモデルの学習に利用する初期正解データは評価データより半年以上古いもの
である．そのため，評価データにはベースモデルでは未知の固有表現が存在す
ることが予想される．評価データと同時期の2006年12月から1週間分のブログ
を収集して追加平文データとし，ここからシードを使ってブートストラップ的
に正解データを収集する．なお，評価データのうち，追加平文データと重複す
るものは予め削除してある．

\begin{table}[b]
\caption{UpdateNER評価実験でのデータ内訳}
\label{tbl-update-corpus}
\input{02table05.txt}
\end{table}

リジェクターの閾値を0.5に設定し，追加平文データから2位までのタググラフ
を含む文を選別した．シードとなる固有表現リストは日本語Wikipediaのエン
トリから自動的に収集した．Wikipediaには，世間で注目される人や固有物が
次々とエントリに登場するため，話題語や新語を獲得する上では貴重な言語資
源であると言える．本実験では，Wikipediaの記事タイトルを表記とし，固有
表現タイプは各記事のカテゴリー情報から予め設定したルールにより自動的に
推定した．最終的に104,296エントリの固有表現リストを得た．

UpdateNERではこのシードを利用して，ブログ記事からシードの固有表現を含
むタグ列を自動的に探索する．もし同じ固有表現を発見したら，そのタグ列を
正解データとして抽出する．このようにして自動修正したデータを初期正解デー
タに追加し，モデルの再学習を行う．なお，タググラフ探索時には，5.1節で
述べた最長固有表現列を採用したが，異なるタイプの固有表現列に展開可能な
場合は，複数の候補を別の文として扱い，追加データとした．

今回，比較のために，シードそのものの効果を調査した．ここでは，シードと
同じ単語列を文中に発見したら必ず固有表現と認識するような固有表現抽出シ
ステムを想定する．なお他の単語列の部分はベースモデルに基づいて確率的に
固有表現を抽出する．このシステムは，ベースモデルの他に，ユーザが固有表
現として認識したいリストをユーザ辞書（シード）として装備したシステムと
捉えることができるため，以後，ユーザ辞書システム (user dic.) と呼ぶ．

更新後のモデルの精度を再現率 (rec.) と適合率 (prec.) で評価した．



\subsection{結果}

実験の結果，のべ2,100文が追加データとして抽出された．このデータのうち，
6,125タグが誤りと推定されたリジェクトタグで，その中で2,038個は信頼度2 
位のタグが採用された．タググラフ付きデータが73,563文あったことを考える
と，得られた文数は少ない．

表\ref{tbl-update-results}に，人名(PSN)，地名(LOC)，組織名(ORG)，固有
物名(ART)での解析精度について，ベースモデル，ユーザ辞書システム (user
dic.)，UpdateNERの結果をそれぞれ示す．


\begin{table}[b]
\caption{解析精度}
\label{tbl-update-results}
\input{02table06.txt}
\end{table}


シードをユーザ辞書として扱う場合，再現率は向上するが，適合率は殆ど変化
しないか，むしろARTでは0.667から0.620へと低下
している．これはユーザ辞書を単に追加するだけでは固有表現抽出システムの
性能を向上するには十分ではないことを示唆している．ユーザ辞書の枠組みで
は，周囲のコンテキストを利用せず単に同一の単語列（表記）を発見すれば一
意に固有表現と認定してしまうため，過剰に固有表現を抽出する危険があるか
らである．

一方，UpdateNERでは再現率と適合率ともに向上している．例えば，ARTでは再
現率が0.321から0.370，適合率が
0.667から0.698へと向上している．この結果から，
シードに存在する固有表現だけでなく，その固有表現の周囲の文全体のタグ列
の情報がモデルの再学習には必須であると解釈できる．UpdateNERでは，シー
ドの固有表現が出現する文全体でのタグ列，即ち，固有表現とそのコンテキス
トのうち，有望で確からしいものを自動的に発見して抽出すると言う点で優れ
ている．シードを準備するには多少の人手コストが必要ではあるが，そのコス
トは正解データそのものを作成するコストと比較すれば極めて小さい．そのた
め，このUpdateNERの学習スキームは，実際に固有表現抽出システムを運用す
る場面においては学習コストを抑える1つの有望な手法であると考える．

表\ref{tbl-update-results}で示す通り，ユーザ辞書システムもUpdateNERも
ORGに対しては効果が見られなかった．これはシードに含まれる固有表現の分
布によるものと考えられる．Wikipediaから自動作成したシードでは，PSNの固
有表現が74\%と最も多かった．一方ORGはわずか11\%しか存在せず，UpdateNER
ではORGについての正解データを抽出する機会が十分になかったものと考えら
れる．また，同じ表記でもORGとPSNの曖昧性が生じるケースはもともと多いた
め，PSNが支配的なシードを利用したUpdateNERではORGをPSNに過剰に学習して
しまっている可能性もある．今後，シードの分布とその学習効果への影響は検
討を進めたい．

なお，UpdateNERでは，初期正解データへの追加データには誤りが含まれる可
能性があることを指摘しておく．実験では，追加したデータにどの程度の誤り
が含まれていたかは調査できていない．ただし，第
\ref{sec-active-learning} 章の実験では誤りタグを含むデータを追加して再
学習することは精度を若干低下させることが示されていることと，本実験にお
いて精度の低下があまり見られないことを考え合わせると，本手法で追加する
データには，モデルの性能に悪影響を与えるような誤りはほとんど含まれない
と推察される．


\subsection{考察}

従来の機械学習の手法と比較して，UpdateNERの一番の特徴は1位タグが信頼で
きない時に2位タグまで考慮する点にある．これにより特に固有表現抽出タス
クのようにベースモデルではOタグであると認識されたとき，次点の候補が何
であるかを考慮することが可能となった．

しかしUpdateNERには，2つの大きな制約がある．1つは2位タグまでに正解が存
在しなければ自動的に正解データとして抽出することができない，という点で
ある．もう1つはその固有表現がシードにも存在していなければならない，と
いう点である．これらの2つの制約があるため，UpdateNERが自動的に収集・修
正できる正解データの範囲は狭いと考えられる．

この弱点を克服するには，実運用にてUpdateNERとタグ単位でのデータセレク
ションによる能動学習を組み合わせる手法が有望であると考えている．能動学
習の場合，2位までに正解が存在しなければならないという制約はないため，
単純に解析誤りを人手で優先的に修正して学習対象とすることが可能である．
即ち，能動学習ではベースモデルが解析誤りをするデータ全般を学習対象とす
ることとなり，その学習範囲はUpdateNERよりも広い．そのため，能動学習で
はベースモデルの精度を底上げするような学習に向いていると考えられる．一
方，UpdateNERは日々増大する膨大なテキストから半自動で正解データを収集
できるという利点があり，新語への追随学習には向いていると言える．そこで，
例えば，短期的にはUpdateNERで毎週モデルの新語追随学習を実行し，中期的
には1ヵ月或いは半年といった間隔で能動学習を行ってベースモデルの底上げ
をする，というような運用形態が考えられる．今後，実際のシステム運用上で
の本手法の効果について，評価を実施したい．


