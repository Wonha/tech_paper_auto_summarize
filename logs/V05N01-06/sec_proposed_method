クラスタ検索に限らず，文書対文書の比較を行うには，まず文書間の距離を定義する必要がある．
本論文では，条件付き確率[MATH]を用い，文書[MATH]から文書集合[MATH]への方向性のある類似性を定義する．
ある文書集合を検索する際は，[MATH]が入力文書(検索要求)となり，[MATH]がこれから検索しようとする文書集合の部分集合となる．
最も極端な例が網羅検索であり，[MATH]は文書集合の各文書それ自身になる(図[REF_fig:search_strategies] (a)参照)．
一方，クラスタ検索では，[MATH]は何らかの指針により自動/人手で作られたクラスタである．
[MATH]を推定する方法は幾つか提案されているが[CITE]，本論文ではIwayama等の推定法[CITE]を用いることにする．
付録[REF_app:SVMV]に[MATH]の推定法を記す．
図[REF_fig:search_strategies] (b)が典型的なクラスタ検索を図式化したものである．
本論文で扱うクラスタ検索では，文書集合を二分木として自動的に構成し(このステップをクラスタリングまたは訓練と呼ぶ)，検索要求を各クラスタ(ノード)と比較することによって，検索要求と類似する文書を指定した数だけとりだす(このステップを検索またはテストと呼ぶ)．
最も単純な検索法は二分木検索であり(図[REF_fig:search_strategies] (b)参照)，クラスタ木の根からトップダウンに木をたどり，指定した数の文書を含むクラスタを探す．
木をたどる際は，各ノードでそれぞれの子ノードについて[MATH]を計算し，どちらに進むかを決定する．
二分木検索は，平均[MATH]の検索時間しか必要とせず，網羅検索([MATH])に比べ高速な検索が可能である．
一般に，網羅検索はその検索コストのため大規模な文書集合の検索/ランキングには適用しづらい．
事実，現実に運用されている検索システムのほとんどは，ランク付きの検索出力が提供されていないか，提供されていても近似計算[CITE]である場合が多い．
連想検索のように検索要求が長い場合は，ランク付けの計算に検索要求の全情報を使わないこともある[CITE]．
検索コストを軽減する効果的な方法は，キーワードから文書への逆インデクス(inverted file) [CITE]を使い，検索要求に含まれているキーワードを全く含まない文書を検索対象から除外することである[CITE]．
残った文書集合を網羅検索することで計算量も幾分軽減できる．
しかし，逆インデクスの導入は問題の本質的解決ではなく，原理的には依然として[MATH]の検索コストが必要である．
クラスタ木上をトップダウンに二分木検索する方法とは逆に，葉からボトムアップにクラスタ木を検索する方法もある．
この検索法はボトムアップクラスタ検索と呼ばれ，二分木検索よりも精度的に有効であることが実証されている[CITE]．
ところが，ボトムアップクラスタ検索では，まず検索の出発点となる葉ノードを決める必要がある．
既に何らかの方法で出発点がわかっている場合はよいが，そうでない場合はゼロからこのノードを見つけるため，網羅検索に近い計算量が必要となる．
本論文では，その簡素さと高速性のため，トップダウンな二分木検索を使うことにする．
また，二分木検索にも，ビーム幅内を並行して検索する，検索の出発ノードを葉に近いノードにするなど様々な拡張が考えられるが，本論文では，断わりのない限り単純な二分木検索に限ることにする．
クラスタ検索におけるクラスタリングの目的は，検索を行った際に高い精度を与えるようなクラスタ木を構築することである．
不適切なクラスタ木は，検索要求に対して関連の低い文書を出力してしまう．
特に，クラスタ木の根に近い部分は，与えられたほとんどの文書集合を含むため漠然性が高く，二分木検索もこの部分での比較で誤りを起しやすい．
従来のクラスタ検索において二分木検索の精度が悪かったのは主にこの理由である．
以下では，二分木検索でも高い精度を与えるような確率的クラスタリングを提案する．
核となるアイデアは，クラスタリング(訓練)にも検索(テスト)にも前節で説明した確率[MATH]を用いることである．
まず，クラスタリングで使う尺度として自己再現率(self recall)を定義する．
あるクラスタ[MATH]に関する自己再現率[MATH]を以下のように定義する．
自己再現率は，クラスタ内の各文書が自分自身を含むクラスタを見つけることができる確率，と解釈することができる．
あるクラスタ[MATH]にとって，[MATH]の値が大きいということは，[MATH]内の各文書を検索入力とした時，それらが[MATH]を見つける確率が高いということである．
文書集合[MATH]がクラスタの集合[MATH]に分割されているとすると，その文書集合[MATH]に対する自己再現率は以下のように定義できる．
これは，文書集合全体に関する自己検索の精度に関連する．
ここまでで，クラスタリングの目的は「文書集合[MATH]が与えられた時，[MATH]が最大となる分割を見付けること」と詳細化できる．
ただし，通常は山登り法になどにより局所的な最大分割を求めることが多い．
例えば，[MATH]を評価関数として非階層的クラスタリングアルゴリズム[CITE]を適用すると，文書集合を平坦なグループに分割することができる．
また，文書集合[MATH]に対して階層的な二分クラスタ木を構築するには，以下に示す凝集型アルゴリズムを適用すればよい．
初期クラスタ集合を，[MATH]内の各文書それ自身のみからなるクラスタの集合とする．
マージにより[MATH]の増分が最大になるようなクラスタのペアを見つけ実際にマージする．
残りのクラスタの数が1でなければステップ2に戻る．
以上のアルゴリズムを階層的ベイズクラスタリング(HBC: Hierarchical Bayesian Clustering)と呼ぶ．
HBCの詳細については，[CITE]を参照されたい．
そこでは，HBCと従来のクラスタリング手法との比較実験も行われている．
また，付録[REF_app:hbc]にHBCの形式的な記述を示す．
従来のクラスタ検索における実験では，二分木検索に関して否定的な結果がでていた．
考えられる理由は，クラスタリング(訓練)と検索(テスト)で異なった尺度(原理)を用いていたことである．
従来の実験では，単一リンク法やWard法をクラスタリングの方法として用いていたが，これらの方法は，検索に使う尺度とは直接関係のない尺度を使いクラスタ木を構築している．
例えば単一リンク法では，二つのクラスタ間の距離として，それらのクラスタを構成する要素(文書)間の最も近い距離を使う．
よって，クラスタ内の他の構成要素の情報は無視されてしまう．
また，構成要素(文書)とクラスタ全体との関係が考慮されていない．
検索で用いるのは文書とクラスタとの距離である．
これらの欠点は，完全リンク法や平均リンク法にもあてはまる．
Ward法は，群内誤差の平方和によりクラスタ間の距離を計算するため，上記の欠点はない．
しかし，群内誤差の平方和は，検索時に用いる距離尺度とは直接関係がない．
それに対しHBCは，文書集合が与えられると，それらを自己検索した時の精度(具体的には自己再現率)を最大化するようなクラスタ木を構築する．
つまり，訓練例に対する検索精度の最大化を行っているため，クラスタ検索という用途に直接関連した手法である．
次節では，HBCをクラスタ検索に用いた場合の有効性を実験により検証する．
なお，単一リンク法やWard法も統計解析という元々の用途には有効な手法である．
クラスタ検索に限らず，文書対文書の比較を行うには，まず文書間の距離を定義する必要がある．
本論文では，条件付き確率[MATH]を用い，文書[MATH]から文書集合[MATH]への方向性のある類似性を定義する．
ある文書集合を検索する際は，[MATH]が入力文書(検索要求)となり，[MATH]がこれから検索しようとする文書集合の部分集合となる．
最も極端な例が網羅検索であり，[MATH]は文書集合の各文書それ自身になる(図[REF_fig:search_strategies] (a)参照)．
一方，クラスタ検索では，[MATH]は何らかの指針により自動/人手で作られたクラスタである．
[MATH]を推定する方法は幾つか提案されているが[CITE]，本論文ではIwayama等の推定法[CITE]を用いることにする．
付録[REF_app:SVMV]に[MATH]の推定法を記す．
図[REF_fig:search_strategies] (b)が典型的なクラスタ検索を図式化したものである．
本論文で扱うクラスタ検索では，文書集合を二分木として自動的に構成し(このステップをクラスタリングまたは訓練と呼ぶ)，検索要求を各クラスタ(ノード)と比較することによって，検索要求と類似する文書を指定した数だけとりだす(このステップを検索またはテストと呼ぶ)．
最も単純な検索法は二分木検索であり(図[REF_fig:search_strategies] (b)参照)，クラスタ木の根からトップダウンに木をたどり，指定した数の文書を含むクラスタを探す．
木をたどる際は，各ノードでそれぞれの子ノードについて[MATH]を計算し，どちらに進むかを決定する．
二分木検索は，平均[MATH]の検索時間しか必要とせず，網羅検索([MATH])に比べ高速な検索が可能である．
一般に，網羅検索はその検索コストのため大規模な文書集合の検索/ランキングには適用しづらい．
事実，現実に運用されている検索システムのほとんどは，ランク付きの検索出力が提供されていないか，提供されていても近似計算[CITE]である場合が多い．
連想検索のように検索要求が長い場合は，ランク付けの計算に検索要求の全情報を使わないこともある[CITE]．
検索コストを軽減する効果的な方法は，キーワードから文書への逆インデクス(inverted file) [CITE]を使い，検索要求に含まれているキーワードを全く含まない文書を検索対象から除外することである[CITE]．
残った文書集合を網羅検索することで計算量も幾分軽減できる．
しかし，逆インデクスの導入は問題の本質的解決ではなく，原理的には依然として[MATH]の検索コストが必要である．
クラスタ木上をトップダウンに二分木検索する方法とは逆に，葉からボトムアップにクラスタ木を検索する方法もある．
この検索法はボトムアップクラスタ検索と呼ばれ，二分木検索よりも精度的に有効であることが実証されている[CITE]．
ところが，ボトムアップクラスタ検索では，まず検索の出発点となる葉ノードを決める必要がある．
既に何らかの方法で出発点がわかっている場合はよいが，そうでない場合はゼロからこのノードを見つけるため，網羅検索に近い計算量が必要となる．
本論文では，その簡素さと高速性のため，トップダウンな二分木検索を使うことにする．
また，二分木検索にも，ビーム幅内を並行して検索する，検索の出発ノードを葉に近いノードにするなど様々な拡張が考えられるが，本論文では，断わりのない限り単純な二分木検索に限ることにする．
クラスタ検索におけるクラスタリングの目的は，検索を行った際に高い精度を与えるようなクラスタ木を構築することである．
不適切なクラスタ木は，検索要求に対して関連の低い文書を出力してしまう．
特に，クラスタ木の根に近い部分は，与えられたほとんどの文書集合を含むため漠然性が高く，二分木検索もこの部分での比較で誤りを起しやすい．
従来のクラスタ検索において二分木検索の精度が悪かったのは主にこの理由である．
以下では，二分木検索でも高い精度を与えるような確率的クラスタリングを提案する．
核となるアイデアは，クラスタリング(訓練)にも検索(テスト)にも前節で説明した確率[MATH]を用いることである．
まず，クラスタリングで使う尺度として自己再現率(self recall)を定義する．
あるクラスタ[MATH]に関する自己再現率[MATH]を以下のように定義する．
自己再現率は，クラスタ内の各文書が自分自身を含むクラスタを見つけることができる確率，と解釈することができる．
あるクラスタ[MATH]にとって，[MATH]の値が大きいということは，[MATH]内の各文書を検索入力とした時，それらが[MATH]を見つける確率が高いということである．
文書集合[MATH]がクラスタの集合[MATH]に分割されているとすると，その文書集合[MATH]に対する自己再現率は以下のように定義できる．
これは，文書集合全体に関する自己検索の精度に関連する．
ここまでで，クラスタリングの目的は「文書集合[MATH]が与えられた時，[MATH]が最大となる分割を見付けること」と詳細化できる．
ただし，通常は山登り法になどにより局所的な最大分割を求めることが多い．
例えば，[MATH]を評価関数として非階層的クラスタリングアルゴリズム[CITE]を適用すると，文書集合を平坦なグループに分割することができる．
また，文書集合[MATH]に対して階層的な二分クラスタ木を構築するには，以下に示す凝集型アルゴリズムを適用すればよい．
初期クラスタ集合を，[MATH]内の各文書それ自身のみからなるクラスタの集合とする．
マージにより[MATH]の増分が最大になるようなクラスタのペアを見つけ実際にマージする．
残りのクラスタの数が1でなければステップ2に戻る．
以上のアルゴリズムを階層的ベイズクラスタリング(HBC: Hierarchical Bayesian Clustering)と呼ぶ．
HBCの詳細については，[CITE]を参照されたい．
そこでは，HBCと従来のクラスタリング手法との比較実験も行われている．
また，付録[REF_app:hbc]にHBCの形式的な記述を示す．
従来のクラスタ検索における実験では，二分木検索に関して否定的な結果がでていた．
考えられる理由は，クラスタリング(訓練)と検索(テスト)で異なった尺度(原理)を用いていたことである．
従来の実験では，単一リンク法やWard法をクラスタリングの方法として用いていたが，これらの方法は，検索に使う尺度とは直接関係のない尺度を使いクラスタ木を構築している．
例えば単一リンク法では，二つのクラスタ間の距離として，それらのクラスタを構成する要素(文書)間の最も近い距離を使う．
よって，クラスタ内の他の構成要素の情報は無視されてしまう．
また，構成要素(文書)とクラスタ全体との関係が考慮されていない．
検索で用いるのは文書とクラスタとの距離である．
これらの欠点は，完全リンク法や平均リンク法にもあてはまる．
Ward法は，群内誤差の平方和によりクラスタ間の距離を計算するため，上記の欠点はない．
しかし，群内誤差の平方和は，検索時に用いる距離尺度とは直接関係がない．
それに対しHBCは，文書集合が与えられると，それらを自己検索した時の精度(具体的には自己再現率)を最大化するようなクラスタ木を構築する．
つまり，訓練例に対する検索精度の最大化を行っているため，クラスタ検索という用途に直接関連した手法である．
次節では，HBCをクラスタ検索に用いた場合の有効性を実験により検証する．
なお，単一リンク法やWard法も統計解析という元々の用途には有効な手法である．
