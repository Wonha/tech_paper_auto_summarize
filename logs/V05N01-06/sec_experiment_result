実験では，連想検索の精度を評価するためにトピック割り付けを行った．
トピック割り付けとは，あらかじめ定義されたトピックの中から1個以上のトピックを文書に割り付けるタスクである．
例えば，ある文書に[MATH]という3個のトピックが付いているとする．
これらの正解トピックは，通常，専門家によって割り付けられる．
そして，自動的な方法により，同じ文書に[MATH]という2個のトピックが割り付けられたとする．
ここで，[MATH]という1つのトピックのみが3個の正解トピックから再現されたという意味で，再現率(recall)は[MATH]となる．
また，[MATH]という1つのトピックのみが，自動的に割り付けられた2個のトピックのなかで正解であったという意味で，適合率(precision)は[MATH]となる．
自動的なトピック割り付け法としては，[MATH]-NN法([MATH]-Nearest Neighbor classifiers) [CITE]を用いた．
[MATH]-NN法では，ある文書[MATH]にトピックを割り付ける際，あらかじめ専門家によりトピックが割り付けられている文書集合(訓練データ)の中から[MATH]に近いものを[MATH]個検索する．
この検索法に，文書連想検索の手法(網羅検索，クラスタ検索)を用い比較した．
検索した[MATH]個の訓練データには既にトピックが付いているため，それぞれのトピックを重み付きで集計し，あるしきい値以上になるトピックを[MATH]に割り付ける．
重みとしては，[MATH]と各々の訓練データとの距離(条件付き確率)を用いた．
ここで，[MATH]に割り付けられるべき正解トピックが既にわかっているため，再現率/適合率が計算できる．
また，自動割り付けにおけるしきい値を変化させることで，再現率/適合率のトレードオフ曲線が描ける．
実験データには，「現代用語の基礎知識(92年版) [CITE](GK)」と「Wall Street Journal [CITE](WSJ)」を用いた．
それぞれの特徴は以下のとおりである．
日本語の辞書データ．
[MATH]個の辞書見出しを持ち，それぞれ[MATH]の小カテゴリいずれかに分類されている．
この小カテゴリをトピックとして用いた．
つまり，各辞書見出しは単一の正解トピックを持っていることになる．
各辞書見出しの説明文は，[MATH]から[MATH]，平均[MATH]の文字長を持つ．
短い説明文の影響を除くため，説明文中に名詞，未知語(抽出法については後述)を[MATH]個以下しか含まない辞書見出しを除去した．
また，辞書見出しを少数しか持たないカテゴリの影響を除くため，辞書見出しを[MATH]個以下しか含まないカテゴリを除去した．
この結果，残った辞書見出し数は[MATH]，カテゴリ数は[MATH]となった．
英語の新聞記事データ．
'89/7/25から'89/11/2までの[MATH]記事を使った．
各記事には，[MATH]個のトピックの中から複数のトピックが割り付けられている．
一つもトピックを持たない記事は取り除いた．
記事に割り付けられている平均トピック数は[MATH]個である．
これら二つのデータセットには，日本語と英語という大きな相違点の他に，以下の特筆すべき相違点がある．
GKの各文書が単一のトピックしか持たないのに対し，WSJは複数(平均[MATH]個)のトピックを持つ．
GKは，文書長，および各トピックが持つ文書数が比較的均一なデータセットであるのに対し，WSJは非均一なデータセットである．
GKには各トピックを担当する編集者が存在し，その編集者が担当トピックの辞書見出しを管理しているからである.
それに加え，GKでは，短い辞書見出し，辞書見出し数が少ないトピックを上記の方法により強制的に除去している．
よって，WSJに比べ，GKはよりノイズの少ないデータセットであると言える．
逆の視点から見ると，WSJはより現実データに近いと言える．
実験の前処理として，まず，文書表現として用いるタームを抽出する必要がある．
両データセットとも，名詞と未知語をタームとして用いた．
タガーとして，GKではJUMAN [CITE]を，WSJではXerox Part-of-Speech Tagger [CITE]を用いた．
WSJに関しては，ispell [CITE]を用いて語尾処理を行ない，単語の原形のみ用いた．
また，トピック割り付けを行うには，データセットを訓練データとテストデータに分割する必要がある．
GKは文書数が少ないため，4分割のクロスバリデーションを行った．
WSJでは，'89/7/25から'89/9/29までの[MATH]記事を訓練データとして，'89/10/2から'89/11/2までの[MATH]記事をテストデータとして使った．
まず，比較的ノイズの少ないGKを用いて，HBCを用いたクラスタ検索と従来から行われていたクラスタ検索を比較する．
従来法としては，クラスタリングにWard法[CITE]を，検索に確率モデルを用いた．
よって，両者はクラスタリングの手法のみが異なる．
また，比較対象として，網羅検索による実験も行った．
網羅検索における文書間の距離尺度には，クラスタ検索と同じ確率モデルを用いた．
以上は[MATH]-NN法によるトピック割り付けであるが，この他にトピック割り付けの代表的な方法(以下，トピック検索法と呼ぶ)も比較対象として実験に用いた．
トピック検索法では，まず，各トピック毎にそのトピックが割り付けられている文書を集め，トピックを表現する文書集合とする．
次に，トピックを割り当てようとする文書と，各トピックを表現している文書集合との間の距離を計算して，距離が近いトピックを文書に割り当てる．
距離尺度としては，上記手法と同じ確率モデルを用いた．
GKでは，割り当てられるべきトピックが一つであるため，実験に用いた手法でも，上位1位のトピックを割り付け，それが正解となっている割合で精度を測定した．
実験結果を図[REF_fig:gk]に示す．
図中，X軸は，[MATH]-NN法でいうところの[MATH]，つまり，判定に用いた訓練データ数である．
図[REF_fig:gk]から，[MATH]が極端に小さくない場合，網羅検索の精度が最も良いことがわかる．
また，HBCを用いたクラスタ検索も，網羅検索の精度曲線を良く近似している．
このことから，検索に要する速度などを考えると，HBCを用いたクラスタ検索は速度/精度の点でバランスの取れた手法であると言える．
逆に，Ward法を用いたクラスタ検索が与える精度曲線は，網羅検索の精度曲線とは極端に異なり，特に[MATH]が[MATH]以下での精度が非常に悪くなっている．
興味深いのは，網羅検索，二つのクラスタ検索共に，[MATH]が大きくなるにつれトピック検索法が与える精度に収束していく点である．
ただし，HBCを用いたクラスタ検索，網羅検索が，[MATH]を適当に設定するとトピック検索法を上回るのに対し，Ward法を用いたクラスタ検索は，常にトピック検索法を下回る．
以上の実験結果から，HBCを用いたクラスタ検索法は，従来のクラスタ検索よりも有効であることが確認できた．
次節では，ノイズを含むより実データに近いWSJを用いて，HBCを用いたクラスタ検索と網羅検索との違いを詳しく調べる．
クラスタ検索は，網羅検索と比べると汎化能力という点で優れている．
クラスタ検索は訓練データを一般化したクラスタ集合を扱うためである．
網羅検索は訓練データそれ自体を扱うため，訓練データ中に存在するノイズの影響を受けやすい．
前節のGKによる実験では，この点が確かめられなかったが，これはGKがノイズの少ない均一なデータセットであることによる．
本節では，WSJを使って，データセット中に存在するノイズがトピック割り付け(すなわち連想検索)に及ぼす影響を調べる．
WSJの各文書には複数のトピックが割り付けられているため，前述の再現率/適合率で評価を行った．
トピック割り付け戦略としては以下の3種類を用い比較した．
各テストデータに，均一に[MATH]個づつトピックを割り当てる．
ここでは[MATH]の値を変化させて再現率/適合率曲線を描く．
各テストデータに割り付けられるトピックには，確率から重みが計算できる．
よって，あるしきい値以上の重みを持つトピックを各テストデータに割り付ける．
ここでは割り付けのしきい値を変化させて再現率/適合率曲線を描く．
各トピック毎にテストデータを重みの順にソートしておき，訓練データ中でそのトピックが占める割合に比例した数のテストデータにそのトピックを割り付ける．
例えば，訓練データ中で[MATH]の文書に割り付けられているトピックは，比例配分の定数を[MATH]とすると，テストデータ中の[MATH]の文書に割り付けられる．
比例配分の定数を[MATH]とすると，テストデータ中の[MATH]の文書に割り付けられる．
ここでは，比例配分の定数を変化させて再現率/適合率曲線を描く．
従来行なわれた実験[CITE]では，比例配分割り付けの優位性が確認されている．
しかし，比例配分割り付けを行うには，あらかじめ十分な数のテストデータがそろっている必要がある．
よって，比例配分割り付けは，バッチ的な割り付け処理の局面では有効であるが，オンライン(リアルタイム)で割り付けを行なうような状況に適用することはできない．
図[REF_fig:wsj-kdoc] [MATH] [REF_fig:wsj-prop]にそれぞれの割り付け戦略による実験結果を示す．
ここでは，HBCによるクラスタ検索と網羅検索を比較している．
また，ベースラインとして，トピック検索法による結果も示した．
Y軸のbreakevenとは，再現率/適合率トレードオフ曲線において，再現率と適合率が等しくなる点の値である．
X軸は，前節と同じく[MATH]-NN法における[MATH]の値である．
図[REF_fig:wsj-kdoc] [MATH] [REF_fig:wsj-prop]から，まず，他の二つの割り付け戦略に比べ，比例配分割り付けが優れていることがわかる．
また，比例配分割り付けでは，網羅検索，クラスタ検索共に，トピック検索と同程度の精度である．
更に，両者共に[MATH]-NN法の[MATH]による影響をあまり強く受けていない．
よって，比例配分割り付けは，検索の手法に対して安定した割り付け戦略であると言える．
ところが，前述したように，比例配分割り付けはバッチ処理に限られるという制限がある．
定数割り付け，確率的割り付けでは，網羅検索，クラスタ検索共に，ベースラインのトピック検索を大きく上回っている．
これは，[MATH]-NN法の優位性を示している．
ここで注目して欲しいのは，[MATH]-NN法でも，網羅検索の精度曲線が[MATH]の値に大きく影響を受けている点である．
特に，最大breakevenを与える[MATH]の範囲が非常に狭く，それより[MATH]の値が大きくなると，breakevenが急激に低下している．
これは，訓練データ中に存在するノイズの影響を強く受けていることを意味している．
一方，クラスタ検索の精度曲線は[MATH]に依存せず安定している．
つまり，最大breakevenを与える[MATH]の範囲が広いため，微妙なパラメータ([MATH])設定を行う必要がない．
これは，クラスタリングという汎化操作により，訓練データ中のノイズの影響があらわれにくくなっていることを意味している．
以上から，HBCを用いたクラスタ検索は，網羅検索に比べノイズ頑健性に優れていると言える．
