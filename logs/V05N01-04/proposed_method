文章の論説モデル

\subsection{文末表現と論説文の構造}

\subsubsection{文のタイプ}

日本語の文は，客体的な出来事や事柄を表す部分と，それに対する筆者／話し手
の立場からの把握の仕方（言表事態めあてのモダリティ），発話・伝達的態度の
有り方を示す部分（発話・伝達のモダリティ）から成り立っている
\cite{Nitta:91}．我々は，モダリティが文末の述語を表層的に分類することに
よりある程度解析できることに着目し，\cite{Fukumoto:91}に基づいて分類する．
文のタイプの分類としては，福本らの分類を小分類として用いるが，さらにこれ
らを「意見」，「断定」，「叙述」の３つに大分類する．本研究ではこれを利用
することにより論説文の構造の解析を行なう．

以下に文のタイプを示す．
\begin{description}
 \item[意見] 筆者の願望や疑問などの意見が含まれる文\\
	これらは仁田\cite{Nitta:91}における発話・伝達のモダリティ
	のうち，表出，働き掛け，問い掛けにあたる．
\begin{center}
\begin{tabular}{lll}
 意見 & 問掛 & 要望 \\
 \end{tabular}
\end{center}
 \item[断定] 筆者の判断が含まれる文\\
	これらは仁田\cite{Nitta:91}における発話・伝達のモダリティのうち
	述べ立てにあたり，
	また言表事態めあてのモダリティのうち判断・推量をとる．
 \begin{center}
  \begin{tabular}{llll}
  断定 & 推量 & 理由 & 判断\\
\end{tabular}
\end{center}

 \item[叙述] 事実を述べている文\\
	これらは仁田\cite{Nitta:91}における発話・伝達のモダリティのうち，
	述べ立て（現象描写文）である．
\begin{center}
 \begin{tabular}{lllll}
  叙述 & 可能 & 伝聞 & 様態 & 存在 \\
  継続 & 状態 & 使役 & 例示 \\
  \end{tabular}
\end{center}
\end{description}

小分類個々を実際にどう分類するかについては，\cite{Fukumoto:91}を参照さ
れたい．

\subsubsection{文のタイプと論説文構造の特性}

上記の分類に基づき，文のタイプと文章中の出現位置の関係を調べた．図
\ref{bunpu}は文の位置と各文のタイプの出現頻度の関係を，304個の社説
\footnote{日本経済新聞94年1月から6月までの社説}について調べた結果である．
各文章はそれぞれ文数が異なるので，文の位置は0〜1に規格化してある．

\begin{figure}[htbp]
\begin{center}
\includegraphics{bunpu.ps}
\caption{各タイプの文の出現頻度}\label{bunpu}
\end{center}
\end{figure}

「意見」は，文章の$3/4$以降で出現頻度が増加し始めているが，それ以前では
ほとんど一定である．「叙述」は，文章の開始部で際だって頻出し，中間部では
ほぼ一定，終了部で頻度が低下している．「断定」は，文章全体に現れるが，終
了部でわずかに減少する．

これによると，論説文(新聞の社説)では，論旨の展開の構造があり，少なくとも
３つの部分に分割される．さらに，このうちの中間の部分も構造化されることが
予想される．


\subsection{論説文の修辞レベル}

本研究では，論説文の構成を図\ref{model}のように考える．この階層的な文章
構造の構築を目標に，文章の解析手法を考える．文章の修辞レベルとは，以下の
通りである．
\begin{itemize}

 \item 論証レベル：論説文章の最上位のレベルである．ここのレベルの構造は，
       固定的に「導入」，「展開」，「結論」をノードとして，これ以下の構
       造を統括する．

 \item 話題レベル：このレベルでは，名詞の分布，連鎖に着目した話題の構造，
       および議論の展開構造における一まとまりの話題を扱う．

\item 思考レベル：\hspace{2mm}\cite{Ono:89}\hspace{2mm}を参考に，思考レベル，言明レベルを導入す
      る．これらの構造は，修辞構造理論\cite{Mann:87:a}に基づいており，言
      明間の関係，およびそうして関係付けられたものの間の関係を表す．表
      \ref{rheto}に分類を表す．表中で，n，n1，n2は核(nucleus)を，sは衛星
      (satellite)を表わす．「n ← s」，「s → n」等はそれぞれ前文が核，
      後文が衛星，あるいは前文が衛星，後文が核であることを表す．

 \item 言明レベル：一つの話題，筆者の一つの言明を表現した構造で，ノード
       は，一文あるいは言明レベルの修辞関係(表\ref{rheto}参照)に対応する．
       各文は，命題とモダリティに相当する文末情報からなるとするが，本研
       究では，命題部分からは名詞の出現を，文末部分からは文のタイプのみ
       を扱う．

\end{itemize}
\begin{figure}[htbp]
\begin{center}
\includegraphics[scale=1.0,clip]{ronsi_model.eps}
\caption{論説文の修辞レベル}\label{model}
\end{center}
\end{figure}

\begin{table}[htb]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}\hline
\multicolumn{5}{|c|}{思考レベル} &  言明レベル \\ \hline
\multicolumn{3}{|c|}{直列型} & 並列型 & 転換型 & \\ \hline
n1 → n2 & n ← s & s → n & n1 → n2 & n1 → n2 & n ← s \\ \hline
順接 & 添加 & 条件 & 並列 & 転換 & 説明 \\
逆接 &      & 結論 & 選択 &      & 強調 \\
換言 &      & 一般化 & 対比 &    & 例示 \\
     &      & 相反 &      &      & \\
     &      & 提起 &      &      & \\
     &      & 根拠 &      &      & \\
     &      & 因果 &      &      & \\  \hline
\end{tabular}
\end{center}
\caption{修辞関係の分類}\label{rheto}
\end{table}

文章解析のトップダウン的アプローチ \label{top1}

\subsection{文章のセグメンテーションの手法とトップダウン的構造化} \label{top2}

望月ら\cite{Mochiduki:96}のテキスト・セグメンテーションの手法は，
文章中のすべての文と文の境界について
種々の観点から設定したパラメタを観測し，
\begin{equation}
\hat{y} = a_o + a_1x_1 +a_2x_2 + \cdots + a_px_p \label{siki}
\end{equation}
\[ (x_i:パラメタiの点数，a_i:パラメタiの重み) \]
なる式で，閾値を越えた\hspace{-0.2mm}$\hat{y}$\hspace{-0.2mm}によりテキスト分割の可
不可を判定するもの
である．パラメタとしては，段落をはさんでの出現する傾向が強いもの／性質，
あるいは段落をまたいでは出現しそうにないもの／性質などを選ぶ（次節参照）．

まず，我々は次のように仮定する．
\begin{description}
\item{\bf 仮定}
\begin{quote}
(\ref{siki})式の評価値は，テキストの「非連続性の強さ」と相関性があ
る．
\end{quote}
\end{description}

この値の大きさをもとに次のアルゴリズムで文章のトップダウン的
構造化を行う．
\begin{description}
\item{\bf 構造化のトップダウン・アルゴリズム}
\begin{enumerate}
\item 文章中のすべての文と文の境界について(\ref{siki})式により評価値を求
      める．
\item 評価値の高い順にセグメントの分割を行い，二分木を作る．
\end{enumerate}
\end{description}

\subsection{セグメンテーションのパラメタ}

望月ら\cite{Mochiduki:96}をもとに，パラメタを以下のような観点から選択
する．パラメタの選択には，有効と思われるものをなるべく多く用意し，訓練
データに対する重回帰分析によりパラメタの重みを決める．なお，形式段落で
あるかどうかは，有力なパラメタの候補であるが，本研究では，訓練の際の正解
として用いている．

\begin{itemize}
 \item 助詞は「は」と「が」の出現 \\着目している境界の前後の文について調
       べる．これにより主題，主語の存在の影響が判定に反映される．
 \item 接続語句の有無 \\接続語句は文間の接続関係を表層的に明示している．
       これにより文間の接続関係の影響が判定に反映される．
 \item 指示語(こそあど)の有無 \\指示語の参照先は同一段落内であることが多
       い．これにより上記性質が判定に反映される．
 \item 時制の情報 \\着目している境界の前後の文の時制の変化について調べる．
       以前の調査\cite{Isoyama:94}によると，過去形となるのは叙述文のみで，
       過去形の叙述文は「導入」に用いられる，など段落に影響する場合があ
       る．
 \item 文のタイプの情報 \\例えば，段落の末尾で著者は意見や断定を行なう傾
       向があるかもしれない．このような性質が判定に反映される．
 \item 名詞の連鎖の情報 \\文章中で，ある名詞は話題に関連してある段落にか
       たよって出現するかもしれない．これにより，同義語
       \footnote{\cite{Hayashi:66}による．}も含めた名詞の連鎖やその切れ
       目の情報を判定に反映させられる．
\end{itemize}

パラメタの一覧を表\ref{juu-param}に示す．なお，「重み」欄は，次節で述
べる訓練の結果得られたパラメタの重みである．重みから接続語句の展開型，
時制，文のタイプの情報（境界の候補の前文が「意見文」であるかどうか）がセ
グメンテーションに大きく影響していることが分かる．
\begin{table}[htb]
  \begin{center}
    \begin{tabular}{|c|l|l||r|} \hline
 パラメタ & 分類	& 抽出方法 & 重み($a_i$)\\
 \hline \hline
      $x_1$ & 助詞	& 前文に「は」が出現なら，1点 & -0.078 \\
      $x_2$ & 	& 「は」が出現なら，1点 & 1.867 \\
      $x_3$ & 	& 前文に「が」が出現なら，1点 & 1.151 \\
      $x_4$ & 	& 「が」が出現なら，1点 & 0.334 \\ \hline
      $x_5$ & 接続	& 文頭に「補足」型が出現なら，1点 & -0.437 \\
      $x_6$ & 語句	& 文頭に「展開」型が出現なら，1点 & -2.039 \\
      $x_7$ & （注１）	& 文頭に「転換」型が出現なら，1点 & (注２) \\ \hline
      $x_8$ & 指示語	& 後文の文頭に「こそあど」型が出現なら，1点 & -0.091 \\ \hline
     $x_9$ & 時制	& 現在$\rightarrow$現在なら，1点 & 3.449 \\
     $x_{10}$ & 	& 現在$\rightarrow$過去なら，1点 & 4.604 \\
     $x_{11}$ & 	& 過去$\rightarrow$現在なら，1点 & 1.407 \\
     $x_{12}$ & 	& 過去$\rightarrow$過去なら，1点 & 2.862 \\ \hline
     $x_{13}$ & 文の	& 叙述$\rightarrow$叙述なら，1点 & 0.481 \\
     $x_{14}$ & タイプ	& 叙述$\rightarrow$断定なら，1点 & 0.224 \\
     $x_{15}$ & 	& 叙述$\rightarrow$意見なら，1点 & 1.643 \\
     $x_{16}$ & 	& 断定$\rightarrow$叙述なら，1点 & -0.519 \\ 
     $x_{17}$ & 	& 断定$\rightarrow$断定なら，1点 & 0.267 \\ 
     $x_{18}$ & 	& 断定$\rightarrow$意見なら，1点 & -0.987 \\ 
     $x_{19}$ & 	& 意見$\rightarrow$叙述なら，1点 & 2.220 \\ 
     $x_{20}$ & 	& 意見$\rightarrow$断定なら，1点 & 2.963 \\ 
     $x_{21}$ & 	& 意見$\rightarrow$意見なら，1点 & 2.250 \\ \hline
     $x_{22}$ & 名詞の	& 連鎖の開始なら，1点加点 & 0.236 \\
     $x_{23}$ & 連鎖	& 前文で連鎖の終了なら，1点加点 & 0.400 \\
     $x_{24}$ & 	& 前文でギャップの開始なら，1点加点 & -0.156 \\
     $x_{25}$ & 	& ギャップの終了なら，1点加点 & -0.048 \\ \hline \hline
	$a_0$ & 定数項  & & -2.522 \\ \hline
    \end{tabular}
  \end{center}
\begin{quote}
\hspace*{1mm}（注１）接続語句の分類については付録Iに示す．\\
\hspace*{1mm}（注２）実際は出現個数が少なく未使用\\
\end{quote}
  \caption {重回帰分析に使用するパラメタ}
  \label{juu-param}
\end{table}


\subsection{パラメタの訓練}

まず，パラメタの重みを決定するが，訓練の十分性をみるために，訓練とセグ
メンテーションの精度の関係を調べる．

訓練では，テキスト中のすべての文と文の境界についてパラメタを評価し，正
解としてその境界が形式段落と一致するときに$y=10$，しないとき$y=-1$を与え
る．

図\ref{kunren}に訓練データの数と，訓練データとは別な２０編の社説に対する
段落検出の精度の関係を示す．別の調査\footnote{1993年，1994年の日本経済新
聞の社説1227編から，一段落あたりの平均の文の数は$2.69$であることがわかっ
た．}から求めた段落内の文の数の平均をもとに，一定の段落の数だけ，評価値
の大きい境界から順に段落として採用する．

実験は，訓練データの数を変えていき，訓練データとは
別の２０編の評価データにより再現率，適合率
\footnote{
\[
\mbox{適合率} = \frac{\mbox{形式段落と一致した境界の数}}{\mbox{プログラムで検出された境界の数}}
\]
\[
\mbox{再現率} = \frac{\mbox{形式段落と一致した境界の数}}{\mbox{形式段落の境界の数}}
\]}
を求めたものである．

以上により訓練は，80編程で十分であることがわかった．

\begin{figure}
\begin{center}
\includegraphics[scale=0.95,clip]{nikkei_2.eps}
\caption{訓練データ数と精度}\label{kunren}
\end{center}
\end{figure}

文章解析のボトムアップ的アプローチ

\subsection{セグメント統合のアルゴリズム（ボトムアップ的構造化）}

まず，セグメントの統合について述べる．次節以降で述べる「結束性の強さ」に
基づいて，セグメントは次のように統合される．
\begin{description}
 \item {\bf セグメント統合のアルゴリズム}\\
連続する４個のセグメント\hspace{-0.2mm}$S_1$，$S_2$，$S_3$，$S_4$において，
$S_1$と$S_2$，$S_2$と$S_3$，$S_3$と$S_4$\hspace{-0.2mm}の結束性の強さを
それぞれ\hspace{-0.2mm}$R_1$，$R_2$，$R_3$\hspace{-0.2mm}とすると，
       \[
	R_1 < R_2 > R_3
       \]
の場合のみ，セグメント$S_2$と$S_3$を
統合して新しいセグメント$S_{23}$を作る(図\ref{bottomup}参照)．
\end{description}

これにより，文章のボトムアップ的構造化のアルゴリズムは次のように
表される．
\begin{description}
\item{\bf 構造化のボトムアップ・アルゴリズム}\\
文の並びから始めて，「セグメント統合のアルゴリズム」を繰り返し適用し，
セグメントを統合していく．
\end{description}

\begin{figure}[htbp]
\begin{center}
\includegraphics[scale=0.8,clip]{bottomup.ps}
\caption{セグメント統合のアルゴリズム}\label{bottomup}
\end{center}
\end{figure}

\subsection{結束性の良さの指標} \label{tuyosa}

結束関係とは，文章を構成する要素間の意味的な関係をいう\cite{Halliday:76}が，
本研究の範囲からいえば，二つのセグメント間の意味的な関係ということになる．
オリジナルの結束関係では，指示，代用，省略，接続，語彙的結束性があるが，
ここでは，修辞関係の観点から見た「接続」のみ扱う．

また，以下の規則を1から順に適用することにより，「結束性の強さ」という
尺度を導入する．
\begin{enumerate}
 \item 形式段落をまたぐ結び付きより形式段落内の結び付きの方が結束性が強い．
 \item 接続表現のあるものの間の結び付きの方がないものの間より結束性が強い．
 \item 思考レベルの修辞関係より言明レベルの修辞関係の方が結束性が強い．
 \item 思考レベルにおいては並列型，直列型，転換型の順で結束性が強い．
 \item 思考レベル，言明レベルにおいて同型同士ならば先の結合の方が結束性
       が強い．
\end{enumerate}

\subsection{セグメントの隣接関係}

構造化された隣接する二つのセグメント間の修辞関係の同定は，次のような手順
で行なう．

\begin{enumerate}
 \item 右セグメントの左端が形式段落の切れ目で接続表現があれば，それによ
       り同定する．接続表現からの修辞関係同定は，付録Iによる．
 \item セグメントが部分木に統合されている場合，評価は「核優先の仮定」を
       用いて代表する核同士を比較し，付録IIIの表により同定する（後述）．
 \item 接続表現があればそれにより同定する（付録I参照）．
 \item 左右のセグメントが両方とも一文であるならば，
       言明レベルの修辞関係を優先する．
 \item 文のタイプの比較によって同定する（後述）．
 \item デフォルトは``順接''とする．
\end{enumerate}
     
ここで，「核優先の仮定」とは以下である．
\begin{description}
\item{\bf 核優先の仮定}
\begin{quote}
セグメント間の修辞関係を評価するとき，基本的に核だけでそのセグメントの評
価ができる（表\ref{rheto}参照）．ただし，前文と後文が両方とも核になる修
辞関係では，
      \begin{itemize}
       \item 前文が主$\cdots$換言・並列・選択・対比
       \item 後文が主$\cdots$順接・逆接・転換
      \end{itemize}
とする．
\end{quote}
\end{description}

「文のタイプの比較」とは，二文（セグメントの場合は代表する文）のタイプを
比較することにより修辞関係を同定するもので，詳細を付録IIIに示す．この際，
二つのセグメントの境界が形式段落と一致している場合は「形式段落間」，２文
とも形式段落内に存在する場合は「形式段落内」の各項目を参照する．

トップダウン的アプローチとボトムアップ的アプローチの融合

\subsection{トップダウン（分割） vs. ボトムアップ（統合）}

ここで，トップダウン的なアプローチとボトムアップ的なアプローチについて
比較する．

\begin{description}
\item{\bf トップダウン的アプローチ（セグメント列の分割）}
\begin{itemize}
 \item パラメタにより，(表層的に)明確に指標が現れている箇所ほど早い段
       階で分割が行われている．
 \item 構造木の葉にあたる下部に近付くにつれ，適当でない分割が行なわれる．
       これは評価関数による判定では小さいセグメント列をさらに分割すると
       いう細かい判定まで正しく評価できないことによる．
\end{itemize}
\item{\bf ボトムアップ的アプローチ（セグメントの統合）}
\begin{itemize}
 \item 対象とする構造が小さいほど，結束性の強さや修辞関係は正しく判定さ
       れる．
 \item 反面，大きい構造（セグメント）同士の修辞関係ほど意味的な影響が強
       くなり，判定は困難である．
\end{itemize}
\end{description}

\subsection{両者を融合したアルゴリズム}

本研究で提案する解析アルゴリズムは，前節で述べたトップダウン解析とボトム
アップ解析の良いところのみを採り入れたアルゴリズムで，次の二つの手順から
なる．
\begin{description}
\item{\bf topdown}
\begin{enumerate}
\item 処理範囲が１セグメントなら終了．
\item (\ref{siki})式により，セグメント列において最大の分割箇所を求め，二
      分割する．
\item それぞれのセグメント列を{\bf bottomup} により構造化する．
\end{enumerate}
\item{\bf bottomup}
\begin{enumerate}
\item 処理範囲が１セグメントなら終了．
\item 「セグメント統合のアルゴリズム」に基づき，セグメント列上で統合でき
      るセグメントを検出し，次にそれらを統合する．統合できるセグメントが
      なければ次のステップへ．
\item 得られたセグメント列を{\bf topdown} により構造化する．
\end{enumerate}
\end{description}

解析処理の例を，図\ref{tb_model}に摸式的に示す．
\begin{figure}
\begin{center}
\includegraphics[scale=0.9,clip]{tb_model.eps}
\caption{分割と統合による構造解析}\label{tb_model}
\end{center}
\end{figure}


