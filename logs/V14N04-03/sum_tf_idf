================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:7, score:0.24214] まず，原文から連体修飾部を欠落させた課題文を生成し，次に，被験者にその箇所に情報不足を感じるかどうかを判定させ正解判定データを作成した．
[i:9, score:0.20462] 機械判定に用いる主な素性として，修飾部の欠落箇所におけるつながりの滑らかさに関係した語の連鎖に関する統計量を取り上げた．
[i:10, score:0.22266] 約1,000箇所の判定課題に対し，SVMによる機械学習アルゴリズムを用いた自動判定により正解率を測定した結果，機械判定の正解率として，ベースライン50％，上限（人間の評価のバラツキから上限を定義）76％に対し，10-fold cross validationで67％の正解率を得た．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:24, score:0.12634] しかしながら，それに対応した格解析や照応解析といった意味解析技術の精度が現状では不十分なため，解析困難の理由が，解析技術の精度不足に起因するのか，原文側の問題に起因するのか区別がつかず，指摘の要否判定ができない．
[i:43, score:0.12825] 量の格率の2条件を満足しないために生じる情報不足と情報過多の問題の中で，本研究では情報不足の問題のみを扱い，情報過多の問題は扱わない．
[i:46, score:0.14310] そのため，情報不足の場合には，文が難解になることに加え，論理の飛躍によって誤解を生じさせると言う深刻な事態を招くのに対し，情報過多の場合には，冗長な情報を無視するのに読解の負担がかかるものの，誤解を生じる可能性は低いため，深刻さの程度は低い．

================================================================
[section type  : proposed_method]
[section title : 全体概要]
================================================================
[i:53, score:0.15569] この文を被験者に提示して，欠落箇所に情報不足を感じるかどうか判定してもらう．
[i:60, score:0.14056] すなわち，評価データから，各被験者毎に，OK判定とNG判定の比率が同じになるように文を抜き取り，データセットを作成する．
[i:61, score:0.13559] そのように作成された被験者毎のデータセットは，判定の正解値に関するベースラインが50％である．

================================================================
[section type  : proposed_method]
[section title : 課題文と正解データの作成]
================================================================
[i:69, score:0.00000] 
-----------------------------------------------------
  [subsection title : 課題文の作成手順]
-----------------------------------------------------
  [i:lead, score:0.06919] 本研究では毎日新聞の記事に形態素・構文情報などの各種言語情報を人手で付与したテキストコーパスである京大コーパスを用いて課題文の作成を行った．
.....
  [i:85, score:0.14409] 連体修飾と連用修飾では機械判定に使う素性が少し異なる．
  [i:86, score:0.11539] そのため，判定の正解率を高めるには，素性のセットを入れ換えて個々に処理することになる．
  [i:104, score:0.10569] 被験者への文の提示と評価も1文単位で行い，機械判定も1文内の情報を基に行う．
-----------------------------------------------------
  [subsection title : 主観評価]
-----------------------------------------------------
  [i:lead, score:0.14888] 機械学習アルゴリズムに基づく自動判定に用いる正解値を与えるために，被験者による主観評価を行う．
.....
  [i:106, score:0.14888] 機械学習アルゴリズムに基づく自動判定に用いる正解値を与えるために，被験者による主観評価を行う．
  [i:116, score:0.08459] 被験者に，初めの10問は練習用と断って評価してもらい，以降のデータ処理で使用していない．
  [i:118, score:0.08486] 総計1,792文を評価するのにおおよそ10数時間を要するため，被験者の判断で，数日に分けて評価した．
-----------------------------------------------------
  [subsection title : 被験者間での主観評価の一致率]
-----------------------------------------------------
  [i:lead, score:0.08932] 被験者間での主観評価の一致率を計算する．
.....
  [i:119, score:0.08932] 被験者間での主観評価の一致率を計算する．
  [i:122, score:0.10348] 4名の被験者から2名を選んだ6通りの組に対しての一致率は，表[REF_table:一致率]に示す通りである．
  [i:126, score:0.12134] 2名の被験者がカテゴリ判定したデータのクロス集計結果を表[REF_table:行列定義]とするとき，[MATH]係数は，[MATH]で定義される．

================================================================
[section type  : proposed_method]
[section title : 機械判定で用いる素性の定義]
================================================================
[i:131, score:0.07992] 文の受容性に関する機械判定を行うための識別器としてSVMを用いる．
[i:136, score:0.08989] 11個のうちの3個は語彙表記と語の意味クラスに関する素性である．
[i:137, score:0.09425] その他の8個は，大規模な生コーパスから計算した言語統計量を用いて計算した素性である．
-----------------------------------------------------
  [subsection title : 語彙素性]
-----------------------------------------------------
  [i:lead, score:0.09037] はじめに，語彙に関する3つの素性について図[REF_fig:素性1]を参照しながら説明する．
.....
  [i:141, score:0.12358] 評価文節に含まれる複数の形態素のうち，先頭に位置する形態素の表記が本素性である．
  [i:142, score:0.14088] 「評価文節先頭形態素の表記」と同じ形態素に対して，日本語語彙大系[CITE]の意味クラスをツリー構造を持たない単なるカテゴリとみなして素性に割り当てたものである．
  [i:144, score:0.12698] 本論文では図[REF_fig:素性1]の中で示すように，文を構成する複数の文節のうち，評価位置の直前に来る文節を「直前文節」と呼ぶ．
-----------------------------------------------------
  [subsection title : 語彙素性以外の素性]
-----------------------------------------------------
  [i:lead, score:0.09198] 以下に示す8個の素性は，大規模な生コーパスから計算した統計量を用いて計算した素性である．
.....
  [i:183, score:0.12567] ここで扱うエントロピーでも，他の素性同様，欠落評価位置を挟んだ前後の連結性を扱う．
  [i:184, score:0.15696] 具体的には，連続した2形態素についての条件付き確率に基づくエントロピーとして，文頭から文末に向かう順方向エントロピーと文末から文頭に向かう逆方向エントロピーの2つを扱う（図[REF_fig:素性4]参照）．
  [i:197, score:0.15406] 本節で導入するエントロピー指標は，文脈による次の語（順方向エントロピーの場合には次の語で，逆方向エントロピーの場合には前の語）の予測が容易か困難かの指標であり，連体修飾部の欠落の受容性と次の関係を持つ．

================================================================
[section type  : proposed_method]
[section title : 機械判定の正解率測定結果]
================================================================
[i:215, score:0.14692] 学習量に対する正解率のグラフを調べたところ，素性を語彙素性のみにすると，学習サンプル数の増加に伴って正解率が増加しており，ここで調べたサンプル数の範囲では，まだ飽和していない．
[i:216, score:0.17507] 素性を統計量に関する素性のみにすると学習サンプル数に依存せず，同じ値となり，語彙素性と統計量の双方を用いた場合の正解率は，語彙素性のみの正解率および統計量のみの正解率を上回った（図[REF_fig:学習曲線]）．
[i:218, score:0.15195] 図中に，ベースラインおよび各主観被験者に対し，他の3名との一致率の相乗平均値を上限値の目安として横線で示す．

================================================================
[section type  : proposed_method]
[section title : 機械判定のパラメータ検討]
================================================================
[i:223, score:0.17947] そこで，機械学習アルゴリズムの中で基本的な手法であるKNN法(k-nearest neighbor method)を使用した場合の正解率を求めてSVMの正解率と比較し，同じ素性でも，機械学習の違いによる性能向上分の程度を調べる．
[i:232, score:0.15980] なお，正解率が最も低下したのは，順方向エントロピーを削除したときで，正解率0.65であった（表[REF_table:素性削減]）．
[i:235, score:0.16923] 今回新規な素性としてNoisy Channel Modelに基づく素性を導入しているが，単体での正解率は0.52であり，全体中，中間的な性能であった（表[REF_table:単一素性]）．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[i:245, score:0.21715] まず，語彙素性における機械判定による正解率について図[REF_fig:学習曲線]の学習曲線を参照すると，学習サンプル数が少ないときにベースライン手法とほぼ同一であり，十分多いサンプル数を機械学習に与えた場合に全素性とほぼ同等の正解率で判定できることが確認できた．
[i:253, score:0.18542] 本研究では，被験者評価用の文を作成する際に，[REF_課題文の作成手順]で述べたように，１文毎の評価に限定したり，1文内の連体修飾部を1箇所に限定するなど，様々な条件設定を工夫して，被験者間の一致度が高くなるよう配慮した．
[i:261, score:0.17552] なお，この研究では，231記事，4,013文からなる文書データに対し，6名の被験者で，重要文の人手判定を行い，大規模な機械学習用の正解値データセットを作成している．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:279, score:0.10144] 酒井らはテキスト自動要約における文内要約の要素技術として動詞連体修飾節の省略可能性に関する知識をコーパスから獲得する手法を提案している[CITE][CITE]．
[i:282, score:0.12181] そのため，[MATH]-gram素性やエントロピー素性など，語の統計量に基づく素性を構築する上で，酒井らの手法を参考にした．
[i:283, score:0.12290] 一方，最も異なる点は，省略可能性評価の場合に，省略のない完全な文と省略のある文を生成できるのに対し，本研究の場合には，与えられた文は，全て連体修飾部を欠落させた文であり，原文は与えられず，復元出来ない点である．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[i:288, score:0.23870] 本研究では，原文から連体修飾部を欠落させた文を生成し，被験者がその箇所に何か言葉を補った方が良いか，その必要はないかを評価してもらい，そのようにして作成した正解判定データを使って機械判定する．
[i:291, score:0.16605] 機械判定の主な素性として，語彙素性に関する素性3種，コーパスからの統計量に関する素性8種を用い，機械学習アルゴリズムに基づく自動判定の手法として，SVMを用いた．
[i:292, score:0.15651] その際，ベースラインを50％にすべく，正例数と負例数が等しくなるようにサンプルの抽出を行い，928サンプル（4名の被験者の平均値）からなるデータセットを作成した．

