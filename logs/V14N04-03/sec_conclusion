機械判定の正解率として，ベースライン50％，人間の評価のバラツキから定義した上限 76％に対し，67％の正解率を得た．
上限に近い70％前半が正解率の最終目標になるであろうから，今回の正解率67％は，それと比べ，ある程度近い値に達していると思われる．
なお，素性の削減実験で全素性から「逆方向バイグラム」の素性を削減したときに，正解率の最高値69％を記録したが，今回のデータに限って偶然高い値になった可能性もあり，また，素性選択の組合せは膨大で正解率の最大値を網羅的に調べるのは困難なため，パラーメータ検討前の正解率を本手法の正解率として代表させた．
以下では，実験に用いた素性について，語彙素性とそれ以外の素性の2種類に分けて考察する．
まず，語彙素性における機械判定による正解率について図[REF_fig:学習曲線]の学習曲線を参照すると，学習サンプル数が少ないときにベースライン手法とほぼ同一であり，十分多いサンプル数を機械学習に与えた場合に全素性とほぼ同等の正解率で判定できることが確認できた．
これは語彙素性として使用したものが主に形態素の表記であったため，素性の異なり数が非常に多く，少ない学習サンプル数では十分学習できなかったためと考える．
次に，語彙素性以外の素性について考察する．
語彙素性以外の素性は8種類ある．
これらは主に，[MATH]-gramに基づく素性など，語のつながりの滑らかさを反映した統計量であり，新聞記事１年分の生コーパスから求めたものである．
図[REF_fig:学習曲線]の学習サンプル数は，被験者判定による学習サンプル数であり，統計量を求める際の生コーパスの量とは異なる．
そのため，学習により，判定に用いられる素性に対する重み係数が調整されるものの，学習サンプル数による効果は小さい．
本研究のように，被験者の主観評価に基づいて正解判定データを整備し，機械学習ベースの判定処理を行うという研究スタイルの場合，主観評価に関わる実験デザインの善し悪しが研究の成否に大きく影響する．
本研究では，被験者評価用の文を作成する際に，[REF_課題文の作成手順]で述べたように，１文毎の評価に限定したり，1文内の連体修飾部を1箇所に限定するなど，様々な条件設定を工夫して，被験者間の一致度が高くなるよう配慮した．
結果的に，被験者間の一致率が約8割で[MATH]係数がmoderateという十分高い一致率となり機械判定処理に成功した．
近年研究の盛んなテキスト自動要約の研究では，主観評価結果のバラツキの問題が大きいため，評価法に関して様々な研究が行われ[CITE]，評価型ワークショップNTCIRのTSCにおいて，評価法をいかにすべきかの議論がなされている[CITE]．
本研究での被験者間の一致率を，従来研究における別のタスクの場合と比較してみる．
Maniらの要約の研究[CITE]では，4名の被験者で，要約文（もしくは原文）がトピックスに適合する検索結果かどうかを判定してもらう適合性判定（二者択一）を行い，被験者間の一致率を調べている．
その結果，2名1組での一致率は69％で，[MATH]であった．
また，要約文もしくは原文が，5カテゴリまたはその他のどれに該当するかを答える被験者実験の結果，2名1組での一致率は56％で[MATH]であった．
平尾らの重要文抽出の研究[CITE]では，要約率を30％に設定したときの被験者間の重要文の一致に関し，2名1組の[MATH]程度となっている．
なお，この研究では，231記事，4,013文からなる文書データに対し，6名の被験者で，重要文の人手判定を行い，大規模な機械学習用の正解値データセットを作成している．
また，小林らの音声要約における重要文抽出の研究[CITE]では，学会講演の音声に対する，人間による重要文抽出（要約率33％）の一致率を調べている．
2名の評価者間の[MATH]係数について，10組の平均値は[MATH]である．
重要文抽出に関しては，[MATH]程度(Fair)である．
以上の要約に関連した様々なタスクでの被験者間の一致率と比較して，本研究のタスクにおける被験者間の一致率は，[MATH]が0.46〜0.56（全てmoderate）であり，一致率が高いと言える．
要約文の品質評価法に関して，外的評価という方法がある．
例えば，適合性判定のタスクを設定して，様々な品質の要約文で，タスクの達成時間を計測し，達成時間を短縮できた要約文の品質が高いと判定する方法である．
この評価方法は競技型ワークショップSUMMACで用いられたが，評価の実施が高価だったことに加えて，時間の制限から原文書を比較的短いものに限定しており，評価の妥当性の疑問が問題点として挙げられている[CITE]．
本研究では，被験者間のばらつきの少ない実験条件を整備することに留意し，被験者間の一致率約8割で[MATH]係数がmoderateになる高い一致率を得た．
その結果，機械判定の処理が成功した．
次に，今回の課題設定に関する特殊性を吟味する．
本研究で扱った連体修飾部の追加の要否判定（換言すると欠落に対する受容性判定）の課題には，意味レベルと表層レベルとが混在している．
これらのレベルの構成比率についてはデータセット中にある課題文を分析することで算出することが可能である．
同様に，それらの分析を行った上で，各レベルに属する課題文の中で正解率が特に低いものに照準を合わせて，素性の選定を行うという対策も考えることが出来る．
しかし，そのような個別対策に基づくアプローチは，コーパスベースの統計的言語処理と機械学習による枠組に合致せず，オープンテストによる正解率評価の公正性にも反する恐れもある．
以上の観点から個別対策は行っていない．
本研究の意義を一言で言えば，文章推敲支援の分野において，これまであまり研究が進んでいなかった「意味レベル2」（[REF_はじめに]節で定義）の課題を扱い，広く行われている統計的言語処理のアプローチで機械判定を行い，ある程度高い正解率を達成した点である．
成功のポイントは，意味処理の課題を扱うに際して，主観評価の安定性を向上させるよう，実験デザインを工夫することによって，学習量の圧縮や，機械判定の正解値評価の部分を容易にした点である．
文章校正，推敲の支援に関する従来研究では，主に，タイプミス，構文構造の複雑さ，表記の揺れを指摘する手法など，表記レベルと統語レベルの手法に重点がおかれていた．
一方，人間による文章の推敲の作業では，読みやすさを向上させるために，説明が不足していて論理展開が読み取りにくいと感じられる箇所を指摘する場面が多く見られ，コンピュータ支援に対するニーズは高い．
しかし，これまで，このような課題は，意味処理レベルの困難な課題と考えられ，機械判定の対象として十分に研究されていなかった．
本研究では，原文から連体修飾部を欠落させた文を生成し，被験者がその箇所に何か言葉を補った方が良いか，その必要はないかを評価してもらい，そのようにして作成した正解判定データを使って機械判定する．
この課題設定に関して，人間の判定結果の一致率を調べた．
その結果，4名の評定者による各1,792箇所の判定に関し，４名中2名ずつ，6通りの組合せについて，いずれもほぼ８割の高い一致率を示した．
機械判定の主な素性として，語彙素性に関する素性3種，コーパスからの統計量に関する素性8種を用い，機械学習アルゴリズムに基づく自動判定の手法として，SVMを用いた．
その際，ベースラインを50％にすべく，正例数と負例数が等しくなるようにサンプルの抽出を行い，928サンプル（4名の被験者の平均値）からなるデータセットを作成した．
機械判定の正解率として，ベースライン50％，上限（人間の評価のバラツキから上限を定義）76％に対し，67％の正解率を得た．
今回の実験上の制約の中で，1文毎で評価している点が最も大きな制約であろう．
この制約を外し，文脈を含めて検討することが今後の課題である．
その際，照応技術の進展に合わせて研究開発することが鍵となろう．
また同様に，今回用いなかった技術として，格解析の技術がある．
格要素の有無に関する情報は，情報不足の推定に有力な情報を与えることが期待できるため，格解析技術の進展に合わせて利用を検討すべきである．
