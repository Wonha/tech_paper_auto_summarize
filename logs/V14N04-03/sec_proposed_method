詳細説明に入る前に，本章では，実験に用いる文を準備する段階から，機械学習アルゴリズムを用いた自動判定に至る流れの概略を説明する（図[REF_fig:全体概要]）．
原文として，新聞記事を基にして作られた京大コーパスを用いる．
京大コーパスは，文に，形態素情報と係り受け情報が付与されているので，係り受け構造を利用して連体修飾節あるいは連体修飾句の場所を認定する．
その部分を欠落させた文を作成し，被験者判定用の文とする．
この文を被験者に提示して，欠落箇所に情報不足を感じるかどうか判定してもらう．
被験者数は4名である．
判定対象とする文の数は約1,800文である．
全員が各々これら約1,800文を判定する．
通常，被験者毎の判定結果は異なる．
そのため，OK判定（情報不足なし）とNG判定（情報不足あり）の比率は1対1にならない．
本研究は，機械判定の要素技術を確立する段階の研究であるため，手法の性能を評価する際の容易さから，次のように，OKとNG判定が1対1になるようなデータセットを作成する．
すなわち，評価データから，各被験者毎に，OK判定とNG判定の比率が同じになるように文を抜き取り，データセットを作成する．
そのように作成された被験者毎のデータセットは，判定の正解値に関するベースラインが50％である．
次の段階は，機械判定に用いる素性値の算出である．
素性は全部で11素性である．
その中の１つは，例えば，各文の情報不足評価位置での文の滑らかさ等に関する素性情報である．
それらの素性値を使って，10-fold cross validation法に基づく学習と判定を行う．
機械学習アルゴリズムを用いた自動判定の手法としてSVM (Support Vector Machines)を用いる．
なお，4名の被験者による判定を各々の正解値としたため，正解率も4通りが得られる．
一方，被験者の判定の一致率によって手法の精度の上限を推定し，それを基に正解率を評価する．
本研究では毎日新聞の記事に形態素・構文情報などの各種言語情報を人手で付与したテキストコーパスである京大コーパスを用いて課題文の作成を行った．
京大コーパスを利用するのは次の理由による．
自動的に付与した形態素，構文解析に関して人手修正を行っているため，解析誤りが少ない．
京大コーパスの素材となった毎日新聞記事は新聞記事であり，本研究が対象とする仕事文に相当する．
また，文の品質が高く，機械処理向きの優れた素材である．
次に，京大コーパスから機械処理で課題文を作成する方法について説明する．
本研究では原文のある部分を削除する加工を行って情報不足を生じさせた文を生成する．
削除する部分の選定基準を以下のように設定する．
削除する部分は文中で連続した文字列部分である．
削除する部分の数は1文につき最大1箇所に限定する．
この条件を満たさない文は採用しない．
削除する部分の候補が1文につき複数存在する場合，文頭に近い方1箇所を採用する．
理由は，１文中に複数箇所ある場合に，後続の評価が，前の評価結果に影響される可能性を否定できないため，その影響を避けるためである．
削除対象を連体修飾部（本論文では連体修飾句と連体修飾節を合わせて連体修飾部と称する）に限定する．
連用修飾を扱わない理由について述べる．
連体修飾と連用修飾では機械判定に使う素性が少し異なる．
そのため，判定の正解率を高めるには，素性のセットを入れ換えて個々に処理することになる．
しかし，解析の流れが煩雑になるだけで，判定手法の基本的な枠組は同一であるため，今回の研究では連体修飾部に限定して検討する．
機械処理で連体修飾部を求めるには，係り受け解析結果から認定する（図[REF_fig:連体修飾部]参照）．
同図(b)は連体修飾部が再帰的な修飾状態（以下，再帰修飾と呼ぶ）になっている例を示す．
再帰修飾の場合は，最も外側の修飾部を採用する．
連体修飾の係り先である名詞の種類を一般名詞に限定する．
その理由を述べる．
名詞は一般名詞，固有名詞，形式名詞，その他（数詞，時相名詞，副詞的名詞）に分かれる．
情報不足判定のアルゴリズムを構築するにあたって，これらの種類によってアルゴリズムが異なる．
このうち，出現頻度は一般名詞が非常に多く，実用上の観点からも一般名詞を扱うのが有利である．
次に判定処理を考えると，固有名詞では，初めに出現した固有名詞には説明が必要で，次回以降は不要であるといった判定法が有効であると予想される．
また，形式名詞は指示照応の問題が深く関係し，先行文脈に関する文脈処理の判定問題となる．
後述する通り，本研究では文脈の要素を除外して1文内で完結した主観評価と機械判定を行うため，固有名詞と形式名詞を扱うと，この基準を超えることになる．
以上の理由から一般名詞に限定する．
連体修飾部を削除したとき，その位置の前に文節が存在するという条件を課す．
このようにした理由は，本研究で扱う素性が文節間のつながりに関する情報を利用するためである．
以上の処理により，京大コーパスの初めの600記事から，１文に1箇所の評価箇所を含む課題文を作成した結果1,792文が得られた．
評価は１文毎の評価で行う．
被験者への文の提示と評価も1文単位で行い，機械判定も1文内の情報を基に行う．
主観評価において，文脈上の影響を除外するために，文の提示順をランダムにした．
機械学習アルゴリズムに基づく自動判定に用いる正解値を与えるために，被験者による主観評価を行う．
成人男性4名によって評価を行った．
評価にあたって，被験者に与えた教示は次の通りである．
新聞記事（毎日新聞1995年版）の文を素材として，加工を加えた文を読んでもらい主観評価して頂きます．
1文ずつ文が表示され，評価してもらいますが，文毎に独立しており，文脈はありません．
1文につき1箇所の評価箇所があり，「★」印がついています．
この部分に，原文ではなんらかの文字が挿入されていましたが，それを欠落させています．
この文を読み，ここに何か言葉を補った方が良いか，その必要はないかを評価していただきます．
なお，文字を欠落させるにあたり，言語解析を行うことにより，文法的な誤りは生じないようになっています．
従いまして，ここに何か言葉を補わないと文を理解する上で読み辛いかどうかの観点で評価して下さい．
被験者に，初めの10問は練習用と断って評価してもらい，以降のデータ処理で使用していない．
評価の際に，評価時間に制限は設けていない．
総計1,792文を評価するのにおおよそ10数時間を要するため，被験者の判断で，数日に分けて評価した．
被験者間での主観評価の一致率を計算する．
一致率を次のように定義する．
ただし，計算は文単位で行う．
4名の被験者から2名を選んだ6通りの組に対しての一致率は，表[REF_table:一致率]に示す通りである．
全て，ほぼ，80％の一致率が得られた．
また，主観評価の一致の程度を[MATH]係数[CITE][CITE]で検証した．
[MATH]係数について簡単に説明する．
2名の被験者がカテゴリ判定したデータのクロス集計結果を表[REF_table:行列定義]とするとき，[MATH]係数は，[MATH]で定義される．
ここで，[MATH]は実際の一致割合（被験者A，BともにNGあるいは，ともにOK）であり，[MATH]である．
[MATH]は被験者AとBの間に関連がない場合の各セルの期待値を足して全数で割った値であり，[MATH]である．
[MATH]係数の値により，一致の度合は表[REF_table:カッパ係数]のように評価される．
今回の実験において，6通り全ての組に関し，表[REF_table:一致率κ]に示すように，``moderate''な一致の範囲であった．
文の受容性に関する機械判定を行うための識別器としてSVMを用いる．
SVMは最大マージン原理を利用した2クラスの分類問題を解くための識別器であり，SVMは言語処理分野の他にも様々な分野に利用されている[CITE]．
SVMの一般的な教科書としては[CITE][CITE]がある．
また，高い性能を持つSVMの性能に関係する汎化誤差の議論については，例えば「パターン認識と学習の統計学」6.4節[CITE]等を参照されたい．
素性として，以下で定義する11個の素性を用いる．
11個のうちの3個は語彙表記と語の意味クラスに関する素性である．
その他の8個は，大規模な生コーパスから計算した言語統計量を用いて計算した素性である．
以上の枠組を模式図の形式で図[REF_fig:機械判定の枠組]に示す．
はじめに，語彙に関する3つの素性について図[REF_fig:素性1]を参照しながら説明する．
本論文では図[REF_fig:素性1]に示すように，文中に存在する複数の文節のうち，評価位置の直後に来る文節を「評価文節」と呼ぶ．
評価文節に含まれる複数の形態素のうち，先頭に位置する形態素の表記が本素性である．
「評価文節先頭形態素の表記」と同じ形態素に対して，日本語語彙大系[CITE]の意味クラスをツリー構造を持たない単なるカテゴリとみなして素性に割り当てたものである．
複数の意味クラスを持つ場合，第1語義に対する意味クラスを用いる．
本論文では図[REF_fig:素性1]の中で示すように，文を構成する複数の文節のうち，評価位置の直前に来る文節を「直前文節」と呼ぶ．
本素性は，直前文節に含まれる複数の形態素のうち，最後の形態素の表記である．
以下に示す8個の素性は，大規模な生コーパスから計算した統計量を用いて計算した素性である．
大規模な生コーパスとして，2000年の毎日新聞記事を収めた「CD-毎日新聞2000[CITE]」1年分を用いる．
形態素の分割には標準的な形態素解析ソフトであり，また，京大コーパスとの親和性がよいためJUMANを用いる．
[MATH]-gramに基づく素性として次の5つを用いる（図[REF_fig:素性2]参照）．
この中の「評価文節の確率」以外は，欠落箇所におけるつながりの滑らかさに関する特性を表現している．
直前文節の最後の2つの形態素表記と評価文節先頭形態素表記の同時確率の底を10とする対数（以下，同様）である．
直前文節の最後の2つの形態素表記が出現したという条件の下で，評価文節先頭形態素表記の出現する条件付き確率の対数である．
評価文節先頭形態素とそこから2形態素前の形態素の出現する同時確率の対数である．
通常，評価文節先頭形態素の直前形態素に助詞が来る確率が高い．
そのため，評価文節先頭形態素と意味的な共起関係を表現する特徴量になりにくい．
そこで，評価文節先頭形態素の直前の形態素の代わりに，2形態素前の形態素を扱う．
評価文節を構成する形態素列の出現確率（形態素の同時確率の対数）である．
ただし，形態素数の上限を3形態素（トライグラム）までとする．
評価文節先頭形態素表記が出現したという条件の下で直前文節の最後の形態素表記の出現する条件付き確率の対数である．
誤字の修正の問題にNoisy Channel Modelに基づく手法が用いられている[CITE]．
本素性はNoisy Channel Modelの考え方にヒントを得たものである（図[REF_fig:noisy]参照）．
図[REF_fig:素性3](a)に示すように，形態素の並び[MATH]を観測したとする．
ここで，[MATH]はどんな形態素でも良い．
[MATH]が与えられたという条件の下で，2つ前の形態素が[MATH]である条件付き確率を[MATH]で表す．
全ての語[MATH]に対して[MATH]となる確率を[MATH]で表す．
次に，[MATH]が降順になるように[MATH]の並び順を定める．
このときの並び順を[MATH]とする．
すると，[MATH]は[MATH]のいづれかに位置する．
次に，[MATH]から累積分布[MATH]を次式で計算する．
累積分布の説明図を同図(a)中の右図に示す．
この中で[MATH]に対応する累積確率[MATH]が本素性（Noisy Channel Modelに基づく素性）である．
以下，本指標の性質について図と例を用いて説明する．
同図(b)のイラストに示す．
例として，[MATH]が「今日」で[MATH]が「日」と「直径」の2つについて説明する．
各々の文脈は「…日○今日…」と「…直径○今日…」である．
ここで，「○」はこの位置を何か1文節が占めていることを示している．
[MATH]が定まると，それに従って累積分布[MATH]のカーブも固定される．
上記の例の場合，[MATH]に対して，共起しやすい語である[MATH]は[MATH]軸で左端（上位14位）に位置し，共起しにくい語である[MATH]は[MATH]軸の右端（上位362位）に位置する．
累積分布のカーブであるため，[MATH]が[MATH]軸上の上位（左側）に位置すると，指標は小さな値になる．
ここの例で「…日○今日…」という自然な文脈に対応する．
一方，[MATH]が[MATH]軸上の下位（右側）に位置すると，指標は大きな値になる．
ここの例で「…直径○今日…」という不自然な文脈に対応する．
ここで扱うエントロピーでも，他の素性同様，欠落評価位置を挟んだ前後の連結性を扱う．
具体的には，連続した2形態素についての条件付き確率に基づくエントロピーとして，文頭から文末に向かう順方向エントロピーと文末から文頭に向かう逆方向エントロピーの2つを扱う（図[REF_fig:素性4]参照）．
直前文節の最後の形態素[MATH]が与えられたという条件の下で，評価文節先頭形態素[MATH]の出現確率に基づくエントロピー（ただし，対数の底は10）である．
ただし，
[MATH]：形態素[MATH]の直後に出現する形態素の集合
評価文節の先頭の形態素[MATH]が与えられたという条件の下で，直前文節の最後の形態素[MATH]が出現する確率に基づくエントロピー（ただし，対数の底は10）である．
ただし，
[MATH]：形態素[MATH]の直前に出現する形態素の集合
いくつかの語でエントロピーを計算した例を表[REF_table:entropy]に示す．
特定の文脈で使われる語はエントロピーが小さく，いろいろな文脈で使われる語はエントロピーが大きい．
例えば，「記事」は「関連記事」，「この記事」という文脈で使われることが多いためエントロピーが小さいのに対し，「ニュース」ではそのような文脈上のつながりがなく，エントロピーが少し大きくなる．
「電池」は，「太陽電池」，「燃料電池」という文脈が非常に多いため，ここで示した6語の中で最小の値となっている．
一方，「教育」，「文化」はいろいろな文脈で使われるため，エントロピーが大きい．
「首相」は村上首相（人名＋首相）のような特定の文脈で使われる場合と，そうでない場合が半々程度出現し，エントロピーは中程度の大きさになる．
本節で導入するエントロピー指標は，文脈による次の語（順方向エントロピーの場合には次の語で，逆方向エントロピーの場合には前の語）の予測が容易か困難かの指標であり，連体修飾部の欠落の受容性と次の関係を持つ．
説明がなくても分かる（連体修飾部不要）．
エントロピー小．
十分に説明してほしい（連体修飾部が必要）．
エントロピー大．
機械判定を行うにあたり，データセットに含まれる「補う必要なし」（以下，正例と表記する）と「補う必要あり」（以下，負例と表記する）の数が等しくなるようにサンプルの抜き取りを行って調整する．
具体的には，全被験者とも，負例が少なかったので，正例の中からランダムに，負例の数のサンプルを抽出して，正例と負例のサンプル数が等しくなるようにデータセットを調整する．
そのようにして得られた被験者毎のサンプル数を図[REF_fig:サンプル数]および表[REF_table:サンプル数]に示す．
この操作により，サンプル数800弱の被験者2名と，サンプル数1,100弱の被験者2名の2グループに分けた．
以下の機械判定では，調整後のデータセットを基に，学習と判定を行う．
前章で述べた素性を用い，分類器として自然言語処理で広く使われるSVMを使って判定を行った．
SVMのパラメータとして線形カーネルを用い，ソフトマージンでコスト[MATH]を用いた．
機械学習アルゴリズムを用いた自動判定の評価にあたり10-fold cross validationを行った．
学習コーパスの量と正解値の関係，すなわち学習曲線を図[REF_fig:学習曲線]に示す．
課題の正解値は，4名の主観評価中の1名に関するデータを用いる．
前述のようにデータセット中の正例と負例の比率を等しくすることによって，ベースラインを0.5に設定してある．
ベースラインの値は，正例と負例の2値判定をランダムに行った場合の正解率に相当する．
各被験者に対し，他の3名との一致率の相乗平均値を上限値の目安として横線で示す．
学習量に対する正解率のグラフを調べたところ，素性を語彙素性のみにすると，学習サンプル数の増加に伴って正解率が増加しており，ここで調べたサンプル数の範囲では，まだ飽和していない．
素性を統計量に関する素性のみにすると学習サンプル数に依存せず，同じ値となり，語彙素性と統計量の双方を用いた場合の正解率は，語彙素性のみの正解率および統計量のみの正解率を上回った（図[REF_fig:学習曲線]）．
次に，被験者毎の正解率を図[REF_fig:正解率]，表[REF_table:正解率]に示す．
図中に，ベースラインおよび各主観被験者に対し，他の3名との一致率の相乗平均値を上限値の目安として横線で示す．
被験者間での正解率に大きな違いはない．
4名の正解率の平均値はベースライン0.5，上限0.76に対し，0.67であった．
本論文では，機械学習アルゴリズムとして正解率の高さから定評のあるSVMを用いた．
しかし，SVMだけを対象としたのでは，達成される正解率の内訳が，選択された素性に基づく性能によるのか機械学習アルゴリズムの性能によるのか区別がつかない．
そこで，機械学習アルゴリズムの中で基本的な手法であるKNN法(k-nearest neighbor method)を使用した場合の正解率を求めてSVMの正解率と比較し，同じ素性でも，機械学習の違いによる性能向上分の程度を調べる．
その結果，ベースライン0.5に対し，KNN法で0.65，SVMで0.67となった．
したがって，性能のうちの大部分は素性によって実現されたものと考えられる．
なお，KNN法はパラメータKを含むので，網羅的に調べるため，Kを1.5の冪乗(1, 2, 3, 5, 7, 11, .
..
, 437)で変化させて正解率の最大を求めた．
次に，SVMを使う場合の，素性選択による影響を調べるために，素性を1つずつ削除した場合の正解率を調べる．
それによって，素性選択の改良による性能向上の余地がどの程度あるのかを調べる．
その結果，逆方向バイグラム素性を削減したときに最高値を示し，正解率0.69であった．
なお，正解率が最も低下したのは，順方向エントロピーを削除したときで，正解率0.65であった（表[REF_table:素性削減]）．
最後に，本論文で導入した11素性を各々単一に用いた場合の正解率を調べる．
単体性能の最高を示す素性が「語の表記」で0.66であり，全体を使った性能が0.67である．
今回新規な素性としてNoisy Channel Modelに基づく素性を導入しているが，単体での正解率は0.52であり，全体中，中間的な性能であった（表[REF_table:単一素性]）．
先の「素性を1つずつ削除」する実験でこの素性を削除した場合に，正解率の低下は中程度であり，補助的な役割は果たしている．
主要な素性を補助するために導入した素性の場合，主要な素性無しで，補助的な素性のみを使っても，本来，高い性能は得られない．
例えば，順方向エントロピーがこれに該当する．
先の「素性を1つずつ削除した場合の正解率」では，削除による正解率低下が最も大きく，重要であるが，それに対して，単一で用いた場合，性能の低い順に2位である．
以上の結果，素性選択の方法による正解率への影響を調べた結果，本実験で用いる素性に対して，素性選択を調整すると正解率は多少向上するが，その程度は大きくないことが判明した．
詳細説明に入る前に，本章では，実験に用いる文を準備する段階から，機械学習アルゴリズムを用いた自動判定に至る流れの概略を説明する（図[REF_fig:全体概要]）．
原文として，新聞記事を基にして作られた京大コーパスを用いる．
京大コーパスは，文に，形態素情報と係り受け情報が付与されているので，係り受け構造を利用して連体修飾節あるいは連体修飾句の場所を認定する．
その部分を欠落させた文を作成し，被験者判定用の文とする．
この文を被験者に提示して，欠落箇所に情報不足を感じるかどうか判定してもらう．
被験者数は4名である．
判定対象とする文の数は約1,800文である．
全員が各々これら約1,800文を判定する．
通常，被験者毎の判定結果は異なる．
そのため，OK判定（情報不足なし）とNG判定（情報不足あり）の比率は1対1にならない．
本研究は，機械判定の要素技術を確立する段階の研究であるため，手法の性能を評価する際の容易さから，次のように，OKとNG判定が1対1になるようなデータセットを作成する．
すなわち，評価データから，各被験者毎に，OK判定とNG判定の比率が同じになるように文を抜き取り，データセットを作成する．
そのように作成された被験者毎のデータセットは，判定の正解値に関するベースラインが50％である．
次の段階は，機械判定に用いる素性値の算出である．
素性は全部で11素性である．
その中の１つは，例えば，各文の情報不足評価位置での文の滑らかさ等に関する素性情報である．
それらの素性値を使って，10-fold cross validation法に基づく学習と判定を行う．
機械学習アルゴリズムを用いた自動判定の手法としてSVM (Support Vector Machines)を用いる．
なお，4名の被験者による判定を各々の正解値としたため，正解率も4通りが得られる．
一方，被験者の判定の一致率によって手法の精度の上限を推定し，それを基に正解率を評価する．
本研究では毎日新聞の記事に形態素・構文情報などの各種言語情報を人手で付与したテキストコーパスである京大コーパスを用いて課題文の作成を行った．
京大コーパスを利用するのは次の理由による．
自動的に付与した形態素，構文解析に関して人手修正を行っているため，解析誤りが少ない．
京大コーパスの素材となった毎日新聞記事は新聞記事であり，本研究が対象とする仕事文に相当する．
また，文の品質が高く，機械処理向きの優れた素材である．
次に，京大コーパスから機械処理で課題文を作成する方法について説明する．
本研究では原文のある部分を削除する加工を行って情報不足を生じさせた文を生成する．
削除する部分の選定基準を以下のように設定する．
削除する部分は文中で連続した文字列部分である．
削除する部分の数は1文につき最大1箇所に限定する．
この条件を満たさない文は採用しない．
削除する部分の候補が1文につき複数存在する場合，文頭に近い方1箇所を採用する．
理由は，１文中に複数箇所ある場合に，後続の評価が，前の評価結果に影響される可能性を否定できないため，その影響を避けるためである．
削除対象を連体修飾部（本論文では連体修飾句と連体修飾節を合わせて連体修飾部と称する）に限定する．
連用修飾を扱わない理由について述べる．
連体修飾と連用修飾では機械判定に使う素性が少し異なる．
そのため，判定の正解率を高めるには，素性のセットを入れ換えて個々に処理することになる．
しかし，解析の流れが煩雑になるだけで，判定手法の基本的な枠組は同一であるため，今回の研究では連体修飾部に限定して検討する．
機械処理で連体修飾部を求めるには，係り受け解析結果から認定する（図[REF_fig:連体修飾部]参照）．
同図(b)は連体修飾部が再帰的な修飾状態（以下，再帰修飾と呼ぶ）になっている例を示す．
再帰修飾の場合は，最も外側の修飾部を採用する．
連体修飾の係り先である名詞の種類を一般名詞に限定する．
その理由を述べる．
名詞は一般名詞，固有名詞，形式名詞，その他（数詞，時相名詞，副詞的名詞）に分かれる．
情報不足判定のアルゴリズムを構築するにあたって，これらの種類によってアルゴリズムが異なる．
このうち，出現頻度は一般名詞が非常に多く，実用上の観点からも一般名詞を扱うのが有利である．
次に判定処理を考えると，固有名詞では，初めに出現した固有名詞には説明が必要で，次回以降は不要であるといった判定法が有効であると予想される．
また，形式名詞は指示照応の問題が深く関係し，先行文脈に関する文脈処理の判定問題となる．
後述する通り，本研究では文脈の要素を除外して1文内で完結した主観評価と機械判定を行うため，固有名詞と形式名詞を扱うと，この基準を超えることになる．
以上の理由から一般名詞に限定する．
連体修飾部を削除したとき，その位置の前に文節が存在するという条件を課す．
このようにした理由は，本研究で扱う素性が文節間のつながりに関する情報を利用するためである．
以上の処理により，京大コーパスの初めの600記事から，１文に1箇所の評価箇所を含む課題文を作成した結果1,792文が得られた．
評価は１文毎の評価で行う．
被験者への文の提示と評価も1文単位で行い，機械判定も1文内の情報を基に行う．
主観評価において，文脈上の影響を除外するために，文の提示順をランダムにした．
機械学習アルゴリズムに基づく自動判定に用いる正解値を与えるために，被験者による主観評価を行う．
成人男性4名によって評価を行った．
評価にあたって，被験者に与えた教示は次の通りである．
新聞記事（毎日新聞1995年版）の文を素材として，加工を加えた文を読んでもらい主観評価して頂きます．
1文ずつ文が表示され，評価してもらいますが，文毎に独立しており，文脈はありません．
1文につき1箇所の評価箇所があり，「★」印がついています．
この部分に，原文ではなんらかの文字が挿入されていましたが，それを欠落させています．
この文を読み，ここに何か言葉を補った方が良いか，その必要はないかを評価していただきます．
なお，文字を欠落させるにあたり，言語解析を行うことにより，文法的な誤りは生じないようになっています．
従いまして，ここに何か言葉を補わないと文を理解する上で読み辛いかどうかの観点で評価して下さい．
被験者に，初めの10問は練習用と断って評価してもらい，以降のデータ処理で使用していない．
評価の際に，評価時間に制限は設けていない．
総計1,792文を評価するのにおおよそ10数時間を要するため，被験者の判断で，数日に分けて評価した．
被験者間での主観評価の一致率を計算する．
一致率を次のように定義する．
ただし，計算は文単位で行う．
4名の被験者から2名を選んだ6通りの組に対しての一致率は，表[REF_table:一致率]に示す通りである．
全て，ほぼ，80％の一致率が得られた．
また，主観評価の一致の程度を[MATH]係数[CITE][CITE]で検証した．
[MATH]係数について簡単に説明する．
2名の被験者がカテゴリ判定したデータのクロス集計結果を表[REF_table:行列定義]とするとき，[MATH]係数は，[MATH]で定義される．
ここで，[MATH]は実際の一致割合（被験者A，BともにNGあるいは，ともにOK）であり，[MATH]である．
[MATH]は被験者AとBの間に関連がない場合の各セルの期待値を足して全数で割った値であり，[MATH]である．
[MATH]係数の値により，一致の度合は表[REF_table:カッパ係数]のように評価される．
今回の実験において，6通り全ての組に関し，表[REF_table:一致率κ]に示すように，``moderate''な一致の範囲であった．
文の受容性に関する機械判定を行うための識別器としてSVMを用いる．
SVMは最大マージン原理を利用した2クラスの分類問題を解くための識別器であり，SVMは言語処理分野の他にも様々な分野に利用されている[CITE]．
SVMの一般的な教科書としては[CITE][CITE]がある．
また，高い性能を持つSVMの性能に関係する汎化誤差の議論については，例えば「パターン認識と学習の統計学」6.4節[CITE]等を参照されたい．
素性として，以下で定義する11個の素性を用いる．
11個のうちの3個は語彙表記と語の意味クラスに関する素性である．
その他の8個は，大規模な生コーパスから計算した言語統計量を用いて計算した素性である．
以上の枠組を模式図の形式で図[REF_fig:機械判定の枠組]に示す．
はじめに，語彙に関する3つの素性について図[REF_fig:素性1]を参照しながら説明する．
本論文では図[REF_fig:素性1]に示すように，文中に存在する複数の文節のうち，評価位置の直後に来る文節を「評価文節」と呼ぶ．
評価文節に含まれる複数の形態素のうち，先頭に位置する形態素の表記が本素性である．
「評価文節先頭形態素の表記」と同じ形態素に対して，日本語語彙大系[CITE]の意味クラスをツリー構造を持たない単なるカテゴリとみなして素性に割り当てたものである．
複数の意味クラスを持つ場合，第1語義に対する意味クラスを用いる．
本論文では図[REF_fig:素性1]の中で示すように，文を構成する複数の文節のうち，評価位置の直前に来る文節を「直前文節」と呼ぶ．
本素性は，直前文節に含まれる複数の形態素のうち，最後の形態素の表記である．
以下に示す8個の素性は，大規模な生コーパスから計算した統計量を用いて計算した素性である．
大規模な生コーパスとして，2000年の毎日新聞記事を収めた「CD-毎日新聞2000[CITE]」1年分を用いる．
形態素の分割には標準的な形態素解析ソフトであり，また，京大コーパスとの親和性がよいためJUMANを用いる．
[MATH]-gramに基づく素性として次の5つを用いる（図[REF_fig:素性2]参照）．
この中の「評価文節の確率」以外は，欠落箇所におけるつながりの滑らかさに関する特性を表現している．
直前文節の最後の2つの形態素表記と評価文節先頭形態素表記の同時確率の底を10とする対数（以下，同様）である．
直前文節の最後の2つの形態素表記が出現したという条件の下で，評価文節先頭形態素表記の出現する条件付き確率の対数である．
評価文節先頭形態素とそこから2形態素前の形態素の出現する同時確率の対数である．
通常，評価文節先頭形態素の直前形態素に助詞が来る確率が高い．
そのため，評価文節先頭形態素と意味的な共起関係を表現する特徴量になりにくい．
そこで，評価文節先頭形態素の直前の形態素の代わりに，2形態素前の形態素を扱う．
評価文節を構成する形態素列の出現確率（形態素の同時確率の対数）である．
ただし，形態素数の上限を3形態素（トライグラム）までとする．
評価文節先頭形態素表記が出現したという条件の下で直前文節の最後の形態素表記の出現する条件付き確率の対数である．
誤字の修正の問題にNoisy Channel Modelに基づく手法が用いられている[CITE]．
本素性はNoisy Channel Modelの考え方にヒントを得たものである（図[REF_fig:noisy]参照）．
図[REF_fig:素性3](a)に示すように，形態素の並び[MATH]を観測したとする．
ここで，[MATH]はどんな形態素でも良い．
[MATH]が与えられたという条件の下で，2つ前の形態素が[MATH]である条件付き確率を[MATH]で表す．
全ての語[MATH]に対して[MATH]となる確率を[MATH]で表す．
次に，[MATH]が降順になるように[MATH]の並び順を定める．
このときの並び順を[MATH]とする．
すると，[MATH]は[MATH]のいづれかに位置する．
次に，[MATH]から累積分布[MATH]を次式で計算する．
累積分布の説明図を同図(a)中の右図に示す．
この中で[MATH]に対応する累積確率[MATH]が本素性（Noisy Channel Modelに基づく素性）である．
以下，本指標の性質について図と例を用いて説明する．
同図(b)のイラストに示す．
例として，[MATH]が「今日」で[MATH]が「日」と「直径」の2つについて説明する．
各々の文脈は「…日○今日…」と「…直径○今日…」である．
ここで，「○」はこの位置を何か1文節が占めていることを示している．
[MATH]が定まると，それに従って累積分布[MATH]のカーブも固定される．
上記の例の場合，[MATH]に対して，共起しやすい語である[MATH]は[MATH]軸で左端（上位14位）に位置し，共起しにくい語である[MATH]は[MATH]軸の右端（上位362位）に位置する．
累積分布のカーブであるため，[MATH]が[MATH]軸上の上位（左側）に位置すると，指標は小さな値になる．
ここの例で「…日○今日…」という自然な文脈に対応する．
一方，[MATH]が[MATH]軸上の下位（右側）に位置すると，指標は大きな値になる．
ここの例で「…直径○今日…」という不自然な文脈に対応する．
ここで扱うエントロピーでも，他の素性同様，欠落評価位置を挟んだ前後の連結性を扱う．
具体的には，連続した2形態素についての条件付き確率に基づくエントロピーとして，文頭から文末に向かう順方向エントロピーと文末から文頭に向かう逆方向エントロピーの2つを扱う（図[REF_fig:素性4]参照）．
直前文節の最後の形態素[MATH]が与えられたという条件の下で，評価文節先頭形態素[MATH]の出現確率に基づくエントロピー（ただし，対数の底は10）である．
ただし，
[MATH]：形態素[MATH]の直後に出現する形態素の集合
評価文節の先頭の形態素[MATH]が与えられたという条件の下で，直前文節の最後の形態素[MATH]が出現する確率に基づくエントロピー（ただし，対数の底は10）である．
ただし，
[MATH]：形態素[MATH]の直前に出現する形態素の集合
いくつかの語でエントロピーを計算した例を表[REF_table:entropy]に示す．
特定の文脈で使われる語はエントロピーが小さく，いろいろな文脈で使われる語はエントロピーが大きい．
例えば，「記事」は「関連記事」，「この記事」という文脈で使われることが多いためエントロピーが小さいのに対し，「ニュース」ではそのような文脈上のつながりがなく，エントロピーが少し大きくなる．
「電池」は，「太陽電池」，「燃料電池」という文脈が非常に多いため，ここで示した6語の中で最小の値となっている．
一方，「教育」，「文化」はいろいろな文脈で使われるため，エントロピーが大きい．
「首相」は村上首相（人名＋首相）のような特定の文脈で使われる場合と，そうでない場合が半々程度出現し，エントロピーは中程度の大きさになる．
本節で導入するエントロピー指標は，文脈による次の語（順方向エントロピーの場合には次の語で，逆方向エントロピーの場合には前の語）の予測が容易か困難かの指標であり，連体修飾部の欠落の受容性と次の関係を持つ．
説明がなくても分かる（連体修飾部不要）．
エントロピー小．
十分に説明してほしい（連体修飾部が必要）．
エントロピー大．
機械判定を行うにあたり，データセットに含まれる「補う必要なし」（以下，正例と表記する）と「補う必要あり」（以下，負例と表記する）の数が等しくなるようにサンプルの抜き取りを行って調整する．
具体的には，全被験者とも，負例が少なかったので，正例の中からランダムに，負例の数のサンプルを抽出して，正例と負例のサンプル数が等しくなるようにデータセットを調整する．
そのようにして得られた被験者毎のサンプル数を図[REF_fig:サンプル数]および表[REF_table:サンプル数]に示す．
この操作により，サンプル数800弱の被験者2名と，サンプル数1,100弱の被験者2名の2グループに分けた．
以下の機械判定では，調整後のデータセットを基に，学習と判定を行う．
前章で述べた素性を用い，分類器として自然言語処理で広く使われるSVMを使って判定を行った．
SVMのパラメータとして線形カーネルを用い，ソフトマージンでコスト[MATH]を用いた．
機械学習アルゴリズムを用いた自動判定の評価にあたり10-fold cross validationを行った．
学習コーパスの量と正解値の関係，すなわち学習曲線を図[REF_fig:学習曲線]に示す．
課題の正解値は，4名の主観評価中の1名に関するデータを用いる．
前述のようにデータセット中の正例と負例の比率を等しくすることによって，ベースラインを0.5に設定してある．
ベースラインの値は，正例と負例の2値判定をランダムに行った場合の正解率に相当する．
各被験者に対し，他の3名との一致率の相乗平均値を上限値の目安として横線で示す．
学習量に対する正解率のグラフを調べたところ，素性を語彙素性のみにすると，学習サンプル数の増加に伴って正解率が増加しており，ここで調べたサンプル数の範囲では，まだ飽和していない．
素性を統計量に関する素性のみにすると学習サンプル数に依存せず，同じ値となり，語彙素性と統計量の双方を用いた場合の正解率は，語彙素性のみの正解率および統計量のみの正解率を上回った（図[REF_fig:学習曲線]）．
次に，被験者毎の正解率を図[REF_fig:正解率]，表[REF_table:正解率]に示す．
図中に，ベースラインおよび各主観被験者に対し，他の3名との一致率の相乗平均値を上限値の目安として横線で示す．
被験者間での正解率に大きな違いはない．
4名の正解率の平均値はベースライン0.5，上限0.76に対し，0.67であった．
本論文では，機械学習アルゴリズムとして正解率の高さから定評のあるSVMを用いた．
しかし，SVMだけを対象としたのでは，達成される正解率の内訳が，選択された素性に基づく性能によるのか機械学習アルゴリズムの性能によるのか区別がつかない．
そこで，機械学習アルゴリズムの中で基本的な手法であるKNN法(k-nearest neighbor method)を使用した場合の正解率を求めてSVMの正解率と比較し，同じ素性でも，機械学習の違いによる性能向上分の程度を調べる．
その結果，ベースライン0.5に対し，KNN法で0.65，SVMで0.67となった．
したがって，性能のうちの大部分は素性によって実現されたものと考えられる．
なお，KNN法はパラメータKを含むので，網羅的に調べるため，Kを1.5の冪乗(1, 2, 3, 5, 7, 11, .
..
, 437)で変化させて正解率の最大を求めた．
次に，SVMを使う場合の，素性選択による影響を調べるために，素性を1つずつ削除した場合の正解率を調べる．
それによって，素性選択の改良による性能向上の余地がどの程度あるのかを調べる．
その結果，逆方向バイグラム素性を削減したときに最高値を示し，正解率0.69であった．
なお，正解率が最も低下したのは，順方向エントロピーを削除したときで，正解率0.65であった（表[REF_table:素性削減]）．
最後に，本論文で導入した11素性を各々単一に用いた場合の正解率を調べる．
単体性能の最高を示す素性が「語の表記」で0.66であり，全体を使った性能が0.67である．
今回新規な素性としてNoisy Channel Modelに基づく素性を導入しているが，単体での正解率は0.52であり，全体中，中間的な性能であった（表[REF_table:単一素性]）．
先の「素性を1つずつ削除」する実験でこの素性を削除した場合に，正解率の低下は中程度であり，補助的な役割は果たしている．
主要な素性を補助するために導入した素性の場合，主要な素性無しで，補助的な素性のみを使っても，本来，高い性能は得られない．
例えば，順方向エントロピーがこれに該当する．
先の「素性を1つずつ削除した場合の正解率」では，削除による正解率低下が最も大きく，重要であるが，それに対して，単一で用いた場合，性能の低い順に2位である．
以上の結果，素性選択の方法による正解率への影響を調べた結果，本実験で用いる素性に対して，素性選択を調整すると正解率は多少向上するが，その程度は大きくないことが判明した．
