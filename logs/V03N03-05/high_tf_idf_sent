================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.40181] 評価過程の客観性と評価結果の解釈の客観性を維持するために、本手法では単なる評価用例文集ではなく、システムの出力を評価するための設問と、その設問がどのような言語現象を対象としているかについての解説とを各例文に付与したテストセットを用いている。
[i:2, score:0.24685] 各例文は基本的な言語現象と現在の機械翻訳システムにおいて処理が困難である言語現象のそれぞれを出来る限り網羅するように収集された。
[i:3, score:0.26270] 今回、英日機械翻訳システム、日英機械翻訳システムのそれぞれについての評価用テストセットを作成した。

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:8, score:0.36656] これらの検討に基づいて、(社)日本電子工業振興協会によって一連の機械翻訳システム評価基準が開発されてきた(野村・井佐原1992, Nomura and Isahara 1992a, Nomura and Isahara 1992b,日本電子工業振興協会1993)。
[i:14, score:0.36965] わが国においては、(社)日本電子工業振興協会が既に昭和６０年に機械翻訳例文資料として、翻訳における曖昧性に関する問題点に着目して、英文および和文を収集分類し公開している(日本電子工業振興協会1985)。
[i:15, score:0.43734] また同協会は昭和６２年度に、機械翻訳システムの技術レベルを評価するために、文の複雑さの定量化、文の複雑さや文体の定性的特徴の抽出、標準的例文の収集を行なった(日本電子工業振興協会1988,石崎・井佐原1988)。

================================================================
[section type  : experiment_result]
[section title : テストセットを用いた機械翻訳システムの品質評価法]
================================================================
-----------------------------------------------------
  [subsection title : 本評価法の利点]
-----------------------------------------------------
  [i:lead, score:0.19762] これまで、機械翻訳システムの品質評価法として種々の方法が提案されているが、それらの方法に関しては一貫して客観的評価が困難であるという指摘が行なわれてきた。
.....
  [i:31, score:0.33754] ここでは、単にそれに答えるだけで、システム開発者が自己のシステムの性能評価を行なえるように作られたyes/no設問を各例文に付加することにより、翻訳結果を評価する手続きを明確化した。
  [i:44, score:0.30806] この目的のために各例文に設問や訳出例を付与しているということを明確にする意味で、我々の評価法においては「テストセット(Test Set)」という名称を用いている。
  [i:50, score:0.39262] 各テストセットには、評価用例文、その人間による模範訳、システムの出力(翻訳結果)を評価するための設問などが記述されており、評価者はテストセット中の例文を翻訳し、その翻訳結果を参照しながら各例文に付与された設問に回答していく。
-----------------------------------------------------
  [subsection title : 本評価法の基本的立場(どのような情報を開発者に与えるか)]
-----------------------------------------------------
  [i:lead, score:0.27045] この評価用テストセットは、個々の機械翻訳システムに依存しない汎用の品質評価法として作成している。
.....
  [i:58, score:0.30327] このテストセットの目的は機械翻訳システムの開発者が自己のシステムの性能を向上するために、システムの処理できない言語現象を正確に把握することである。
  [i:70, score:0.29241] また、本テストセットは単なる例文集ではなく、各例文にはその対象とする言語現象が解説されており、さらには必要に応じて関連文と、その模範訳が付加されている。
  [i:82, score:0.33132] 常にその時点で機械翻訳において問題となっている言語現象を１０００文程度のテストセットで示すのが理想であろう。
-----------------------------------------------------
  [subsection title : 評価用例文の収集]
-----------------------------------------------------
  [i:lead, score:0.31039] テストセットの例文は機械翻訳システムや自然言語処理システムを実際に開発してきた経験に基づいて、著者らによって収集された。
.....
  [i:85, score:0.31039] テストセットの例文は機械翻訳システムや自然言語処理システムを実際に開発してきた経験に基づいて、著者らによって収集された。
  [i:100, score:0.39276] なお、このテストセットを用いた品質評価法の提案の主旨と、作成の詳しい経緯については、参考文献(井佐原他1992,日本電子工業振興協会1993,日本電子工業振興協会1994, Isahara et al 1994,日本電子工業振興協会1995a, Isahara 1995)を参照されたい。
  [i:101, score:0.25494] また、テストセットの全容は、参考文献(日本電子工業振興協会1995b)に示されている。

================================================================
[section type  : experiment_result]
[section title : 英日機械翻訳システム品質評価用テストセット]
================================================================
[i:103, score:0.43695] このテストセットは、機械翻訳システムが処理すべき様々な言語現象を含んだ英語例文770文とその模範訳、及びシステムの出力(翻訳結果)を評価するための設問などからなる。
-----------------------------------------------------
  [subsection title : 概要]
-----------------------------------------------------
  [i:lead, score:0.34875] 我々は、英日機械翻訳システムの評価基準として、システム開発者が自己のシステムの不備をチェックすることを主要目的とした品質評価用テストセットを作成した。
.....
  [i:109, score:0.36469] 平成５年度末までに第１段階として、英語の単文を中心に評価すべき項目を抽出して評価基準を設定し、309の基本例文を収集・評価して「電子協平成５年度版テストセット」としてまとめた。
  [i:118, score:0.36876] また、本テストセットの実用性の検証と設問の修正のために、ハードウェアタイプの異なる８種の市販の英日機械翻訳システムを対象とした評価を行った。
  [i:119, score:0.45228] このテストセット中の各項目は、文番号、例文、その模範訳、○×で答えることが出来る質問文、主として機械翻訳システムによる訳出例、例文と関連する言語現象を含む文、関連する項目の番号、解説から成り立っている。
-----------------------------------------------------
  [subsection title : テストセットの利用法]
-----------------------------------------------------
  [i:lead, score:0.11512] 本テストセットは、以下の利用法を想定している。
.....
  [i:140, score:0.24793] (2)そのシステムでテストセット中の【例文】を翻訳する。
  [i:148, score:0.16127] 本テストセットを用いて○×の分布を見ることで、システムの対応が不十分な(可能性がある)項目を容易に抽出できる。
  [i:149, score:0.24094] ただし本テストセットでは、各項目(例文)間の重要度、頻度などの差異は考慮していないので、単純に○の数をカウントして正解率をシステム間で比較することは、本評価法の意図するところではない。
-----------------------------------------------------
  [subsection title : テストセットの構成]
-----------------------------------------------------
  [i:lead, score:0.33226] 本テストセットは、機械翻訳システムが処理すべき様々な言語現象を含んだ英語例文770文からなる。
.....
  [i:150, score:0.33226] 本テストセットは、機械翻訳システムが処理すべき様々な言語現象を含んだ英語例文770文からなる。
  [i:153, score:0.27957] 把握部においては、英文法の解説書(江川1964, Hornby 1977,小川他1991,荒木他1992,村田1992)などを参考に英語の文法現象を収集し、そのレベルによって、品詞、文の部分構造、文構造の３段階に分類した。
  [i:228, score:0.26095] 図２テストセットの全体構成、項目別設問数
-----------------------------------------------------
  [subsection title : テストセットの書式]
-----------------------------------------------------
  [i:lead, score:0.18595] 本テストセットの各項目の書式を図３に示す。
.....
  [i:229, score:0.18595] 本テストセットの各項目の書式を図３に示す。
  [i:232, score:0.23603] 【番号】：例文の番号【例文】：例文（１文のみ）【訳文】：模範訳（例文の日本語訳）【質問】："Ａ"が「Ｂ」のようにＣとして訳されていますか？という形式の質問文・Ａ：英語表現。
  [i:241, score:0.20788] 本テストセットは作業者が翻訳結果（訳文）を見るだけで○×を与えることを前提としており、解析の詳細に直接言及することは避ける。

================================================================
[section type  : experiment_result]
[section title : 日英機械翻訳システム品質評価用テストセット]
================================================================
[i:258, score:0.48749] 日英翻訳システム品質評価用テストセットも英日翻訳システム用と同様に、開発者が自己のシステムの不備な点を発見するための評価法であり、テストセット中の各例文に付与された設問に答えることによって、客観的に評価を下せるように作られている。
[i:288, score:0.56029] （１）述部（１−１）述部の訳し分け（１−２）断定文（１−３）体言述語（１−４）複合述部（１−５）訳が一用言となる並列用言（１−６）用言の副詞（句）化（１−７）補助動詞（１−８）基本動詞の訳し分け（２）名詞（２−１）名詞の訳し分け（２−２）複合名詞（２−３）「名詞１の名詞２」という構造を持つ名詞句の処理（２−４）「名詞１の名詞２の〈名詞３〉」という構造を持つ名詞句の処理（２−５）並列構造を持つ名詞句の処理（２−６）疑問表現の名詞節の処理（２−７）用言性名詞（サ変名詞）（２−８）英語における数の扱い（２−９）固有名詞表現（２−１０）形式名詞（２−１１）関係を示す名詞（３）副詞（３−１）副詞のタイプ（３−２）副詞句（３−３）擬音語・擬態語（４）連体修飾語句（４−１）非活用連体修飾（４−２）用言性連体詞（４−３）格助詞相当句（４−４）埋め込み文修飾（５）助詞（５−１）助詞の訳し分け（５−２）深層格の認定（６）接辞（７）テンス、アスペクト、モーダル（７−１）テンスの処理（７−２）アスペクトの処理（７−３）モーダルの処理（７−４）ボイスの処理（８）特殊構造表現（８−１）慣用表現の処理に関して（８−２）四字熟語（８−３）呼応表現（８−４）天候・気象表現（８−５）無生物主語構文（８−６）「はが」構文（８−７）比較表現（８−８）比喩表現（８−９）部分否定、二重否定、倒置文（８−１０）敬語（８−１１）引用・伝聞表現（８−１２）例示・列挙表現
[i:297, score:0.48206] JET??????項目タイトルJEX??????全体的な解説・説明JEQ??????設問（着目すべき主題）JEX??????主題に対する解説（省略されることもある）JEG??????日本文JEE??????英文対訳例JEC??????訳例に対するコメント（チェックすべきポイント,失敗例）

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:318, score:0.31222] この手法は、評価用の各例文に質問と解説を付加したテストセットを用いることにより評価過程を明確化した客観的品質評価法である。
[i:319, score:0.34982] 本稿で提案したテストセットは、評価用の例文に、その人間による訳、システムの出力を評価するための設問、(もしあった場合には)関連する文、文法事項の解説等を付与したものである。
[i:366, score:0.36427] 機械翻訳システム評価基準−−品質評価用テストセット−−95-計-17. \bibitem{}野村浩郷・井佐原均(1992).

