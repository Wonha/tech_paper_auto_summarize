はじめに

機械翻訳システムの開発過程では，システムの評価と改良を幾度も繰り返さね
ばならない．
信頼性の高い評価を行うためには，人間による評価を採用することが理想ではあるが，
時間的な制約を考えるとこれは困難である．
よって，人間と同程度の質を持つ自動評価法
，つまり，人間の評価と高い相関を
持つ自動評価法を利用して人間の評価を代替することが実用上求められる\footnote{
本稿では，100 文規模程度のコーパスを用いて翻訳システムの性能を評価すること，
つまり，システム間の優劣を比較することを目的とした自動評価法について
議論する．}．

こうした背景のもと，
様々な自動評価法が提案されてきた．BLEU \cite{bleu}, NIST \cite{nist},
METEOR \cite{meteor}，Word Error Rate (WER) \cite{WER} などが広く利用されて
いるが，
そのなかでも BLEU \cite{bleu} は，
数多くの論文でシステム評価の指標として採用されているだけでなく，
評価型ワー
クショップにおける公式指標としても用いられており，自動評価のデファクトス
タンダードとなっている．
その理由は，人間による評価との相関が高いと言われていること，計算法
がシステム翻訳と参照翻訳（正解翻訳）との間で一致するNグラム（一般的に
$\mathrm{N}=4$が用いられる）を数えあげるだけで実装も簡単なことにある．

しかし，BLEUのように Nグラムという短い単語列にのみに着目してスコアを決定
すると，システム翻訳が参照翻訳のNグラ
ムを局所的に保持しているだけで，その意味が参照翻訳の意味と大きく
乖離していようとも高いスコアを与えてしまう．
局所的なNグラムは一致しつつも参照翻訳とは
異なるような意味を持つ翻訳をシステムが生成するという
現象は，翻訳時に大きな語順の入れ替えを必要としない
言語間，つまり，構文が似ている言語間の翻訳ではほとんど起こらない．
例えば，構文が似ている言語対である
英語，仏
語の間の翻訳では大きな語順の入れ替えは必要なく，
BLEU と人間の評価結果との間の相関も高い \cite{bleu}．
一方，日本語と英語のように翻訳時に大きな語順の入
れ替えが必要となる言語対を対象とすると，先に示した問題が深刻となる．
例えば，Echizen-ya らは日英翻訳において，BLEU \cite{bleu}，
その変種であるNIST \cite{nist}と人間の評価との間の相関が低いことを
報告している \cite{echizenya-wpt09}．

文全体の大局的な語順を考慮する自動評価法としては，ROUGE-L \cite{ROUGEL}，
IMPACT \cite{impact}がある．これらの手法は
参照翻訳とシステム翻訳との間で一致する最長共通部分単語列(Longest
Common Subsequence: LCS)に基づき評価スコアを決定する．
LCS という文全体での大局的な語順を考慮していることから，英日，日英翻訳シス
テムの評価において，Nグラム一致率に基
づく自動評価法よりもより良い評価ができるだろう．しかし，Nグラム一致率に
基づく自動評価法と同様，訳語の違いに敏感すぎるという問題がある．後に述べ
るが，NTCIR-9 での特許翻訳タスクにおいては，人間が高い評価を与えるルールベー
スの翻訳システムに高スコアを与えることができないという問題がある．


本稿では日英，英日という翻訳時に大きな語順の入れ替えを必要とす
る言語対を対象とした翻訳システムの自動評価法を提案する．
提案手法の特徴は，Nグラムという文中の局所的な単語の並びに着目するのではなく，文
全体における
大局的な語順に着目する点と，参照翻訳とシステム翻訳との間で一致しない単語を
採点から外し，別途，ペナルティとしてそれをどの程度重要視するかを調整でき
るようにすることで訳語の違いに対して寛大な評価を行う点にある．
より具体的には，システム翻訳と参照翻訳との間の語順の近さを測るため，
両者に一致して出現する単語を同定した後，それらの出現順序の
近さを順位相関係数を用いて計算し，これに重み付き単語正解率と
短い翻訳に対するペナルティを乗じたものを最終的なスコアとする．

近年，提案手法と同じく語順の相関に基づいた自動評価法である LRscore が
Birch らによって独立に提案されている \cite{birch-acl}．
LRscore は，参照翻訳とシステム
翻訳との間で一致する単語の語順の近さを Kendall 距離で表し，それをさらに低レンジでの
スコアを下げるために非線形変換した後，短い翻訳に対するペナルティを乗じ
，さらに BLEU スコアとの線形補間で評価スコアを決定する．提
案手法と LRscore は特殊な状況下では同一の定式化となるが，研究対象としてきた言語対が
異なることから，相関係数と語彙の一致に対する考え方が大きく異なる．

提案手法がどの程度人間の評価に近いかを調べるため，NTCIR-7，NTCIR-9の日
英，英日，特
許翻訳タスク \cite{ntcir7,ntcir9}のデータを用いて検証したところ，翻訳シ
ステムの評価という観点から，従来の自動評価法より
も人間の評価に近いことを確認した．

以下，2章ではBLEUを例として，Nグラムという局所的な語順に着目してシステム
を評価することの問題点，3章では LCS を用いてシステムを評価するこ
との問題点を指
摘する．そして，4章でそれら問題点の解決法として，訳語の違いに寛大，かつ，
大局的な語順の相関に基づ
く自動評価法を提案する．5章で実験の設定を詳述し，6章では実験結果を考
察する．最後に7章でまとめ，今後の課題について述べる．


