

機械翻訳システムの開発過程では，システムの評価と改良を幾度も繰り返さねばならない．信頼性の高い評価を行うためには，人間による評価を採用することが理想ではあるが，時間的な制約を考えるとこれは困難である．よって，人間と同程度の質を持つ自動評価法，つまり，人間の評価と高い相関を持つ自動評価法を利用して人間の評価を代替することが実用上求められる．

こうした背景のもと，様々な自動評価法が提案されてきた．BLEU [CITE], NIST [CITE], METEOR [CITE]，Word Error Rate (WER) [CITE]などが広く利用されているが，そのなかでもBLEU [CITE]は，数多くの論文でシステム評価の指標として採用されているだけでなく，評価型ワークショップにおける公式指標としても用いられており，自動評価のデファクトスタンダードとなっている．その理由は，人間による評価との相関が高いと言われていること，計算法がシステム翻訳と参照翻訳（正解翻訳）との間で一致するNグラム（一般的に[MATH]が用いられる）を数えあげるだけで実装も簡単なことにある．

paragraph score: 1.00997972184442
