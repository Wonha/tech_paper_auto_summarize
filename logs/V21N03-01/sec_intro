機械翻訳システムの開発過程では，システムの評価と改良を幾度も繰り返さねばならない．
信頼性の高い評価を行うためには，人間による評価を採用することが理想ではあるが，時間的な制約を考えるとこれは困難である．
よって，人間と同程度の質を持つ自動評価法，つまり，人間の評価と高い相関を持つ自動評価法を利用して人間の評価を代替することが実用上求められる．
こうした背景のもと，様々な自動評価法が提案されてきた．
BLEU [CITE], NIST [CITE], METEOR [CITE]，Word Error Rate (WER) [CITE]などが広く利用されているが，そのなかでもBLEU [CITE]は，数多くの論文でシステム評価の指標として採用されているだけでなく，評価型ワークショップにおける公式指標としても用いられており，自動評価のデファクトスタンダードとなっている．
その理由は，人間による評価との相関が高いと言われていること，計算法がシステム翻訳と参照翻訳（正解翻訳）との間で一致するNグラム（一般的に[MATH]が用いられる）を数えあげるだけで実装も簡単なことにある．
しかし，BLEUのようにNグラムという短い単語列にのみに着目してスコアを決定すると，システム翻訳が参照翻訳のNグラムを局所的に保持しているだけで，その意味が参照翻訳の意味と大きく乖離していようとも高いスコアを与えてしまう．
局所的なNグラムは一致しつつも参照翻訳とは異なるような意味を持つ翻訳をシステムが生成するという現象は，翻訳時に大きな語順の入れ替えを必要としない言語間，つまり，構文が似ている言語間の翻訳ではほとんど起こらない．
例えば，構文が似ている言語対である英語，仏語の間の翻訳では大きな語順の入れ替えは必要なく，BLEUと人間の評価結果との間の相関も高い[CITE]．
一方，日本語と英語のように翻訳時に大きな語順の入れ替えが必要となる言語対を対象とすると，先に示した問題が深刻となる．
例えば，Echizen-yaらは日英翻訳において，BLEU [CITE]，その変種であるNIST [CITE]と人間の評価との間の相関が低いことを報告している[CITE]．
文全体の大局的な語順を考慮する自動評価法としては，ROUGE-L [CITE]，IMPACT [CITE]がある．
これらの手法は参照翻訳とシステム翻訳との間で一致する最長共通部分単語列(Longest Common Subsequence: LCS)に基づき評価スコアを決定する．
LCSという文全体での大局的な語順を考慮していることから，英日，日英翻訳システムの評価において，Nグラム一致率に基づく自動評価法よりもより良い評価ができるだろう．
しかし，Nグラム一致率に基づく自動評価法と同様，訳語の違いに敏感すぎるという問題がある．
後に述べるが，NTCIR-9での特許翻訳タスクにおいては，人間が高い評価を与えるルールベースの翻訳システムに高スコアを与えることができないという問題がある．
本稿では日英，英日という翻訳時に大きな語順の入れ替えを必要とする言語対を対象とした翻訳システムの自動評価法を提案する．
提案手法の特徴は，Nグラムという文中の局所的な単語の並びに着目するのではなく，文全体における大局的な語順に着目する点と，参照翻訳とシステム翻訳との間で一致しない単語を採点から外し，別途，ペナルティとしてそれをどの程度重要視するかを調整できるようにすることで訳語の違いに対して寛大な評価を行う点にある．
より具体的には，システム翻訳と参照翻訳との間の語順の近さを測るため，両者に一致して出現する単語を同定した後，それらの出現順序の近さを順位相関係数を用いて計算し，これに重み付き単語正解率と短い翻訳に対するペナルティを乗じたものを最終的なスコアとする．
近年，提案手法と同じく語順の相関に基づいた自動評価法であるLRscoreがBirchらによって独立に提案されている[CITE]．
LRscoreは，参照翻訳とシステム翻訳との間で一致する単語の語順の近さをKendall距離で表し，それをさらに低レンジでのスコアを下げるために非線形変換した後，短い翻訳に対するペナルティを乗じ，さらにBLEUスコアとの線形補間で評価スコアを決定する．
提案手法とLRscoreは特殊な状況下では同一の定式化となるが，研究対象としてきた言語対が異なることから，相関係数と語彙の一致に対する考え方が大きく異なる．
提案手法がどの程度人間の評価に近いかを調べるため，NTCIR-7，NTCIR-9の日英，英日，特許翻訳タスク[CITE]のデータを用いて検証したところ，翻訳システムの評価という観点から，従来の自動評価法よりも人間の評価に近いことを確認した．
以下，2章ではBLEUを例として，Nグラムという局所的な語順に着目してシステムを評価することの問題点，3章ではLCSを用いてシステムを評価することの問題点を指摘する．
そして，4章でそれら問題点の解決法として，訳語の違いに寛大，かつ，大局的な語順の相関に基づく自動評価法を提案する．
5章で実験の設定を詳述し，6章では実験結果を考察する．
最後に7章でまとめ，今後の課題について述べる．
