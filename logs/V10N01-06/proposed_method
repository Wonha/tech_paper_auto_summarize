本節では，我々の実験で使用した言語資源と解析環境の概略を述べる．
我々は，入手可能な中国語言語資源として，現在最も一般に知られていると考えられるPenn Chinese Treebank (CTB)を使用した．
CTBは，米国ペンシルバニア大学(University of Pennsylvania)のChinese Treebank Projectにより作成された構文木コーパスである．
このコーパスの概要ならびに入手方法を付録[REF_CTB_CORPUS]に示す．
以下に述べる実験では，このプロジェクトの最終版であるLDC2000T48を用いた．
また，CTBで定義されている中国語品詞数は33，句情報の数は17である．
この一覧を巻末の付録[REF_tagset]に示す．
SVMは，[MATH]次元の特徴ベクトル(パターン) [MATH]を定められた二つのクラス(A, B)のいずれかに識別する2値クラスの線形識別器である．
また，SVMでは，カーネルトリックと呼ばれる計算技術によって非線形識別器を実現できる．
従来の手法と比べて多くの面で優位性を示し，文字認識や画像認識など，様々な分野で応用されている．
識別器は，識別関数[MATH]の形によって与えられ，[MATH]が正ならクラスA, [MATH]が負ならクラスBに識別される．
[MATH]を満たす[MATH]の集合を識別面と呼ぶ．
SVMの大きな特徴の一つは，マージン最大化である．
マージンとは，識別面と特徴ベクトル間の最小距離であり，マージンが大きいほうが，汎化能力が高く，テストパターンを精度良く識別できる．
一般に，学習パターンを識別する超平面は複数存在する．
SVMでは，上に述べた理由から超平面と学習パターンとの最小距離を最大にする超平面を求め，これを識別面とする．
決定した超平面からの最小距離に対応する特徴ベクトルをサポートベクトルと呼ぶ．
またサポートベクトル以外の特徴ベクトルは最終的に得られる識別関数に一切影響を及ぼさない．
したがって，出現頻度などの統計量を用いる識別器(たとえば決定木など)とは性質が異なる．
SVMを用いることの短所は，(1) 2値クラス識別器であるため多クラスを考慮に入れた識別関数の最適化ができない(2)計算量が大きい(3)問題に適したカーネルトリック(カーネル関数)の明確な選択方法は知られていない，などである[CITE]．
自然言語処理における同定解析(chunking)とは，与えられた言語的な要素列(文字列，単語列など)をより上位概念の言語的要素(単語，句，文など)にまとめあげるために，各要素に情報を付与する一連の処理を指す．
たとえば，単語の分かち書きや形態素解析，文節まとめあげ，テキストセグメンテーション，文書分類などはすべて同定解析とみなすことができる．
工藤は，SVMに基づく汎用的な同定解析器としてYamCha (Yet Another Multipurpose CHunk Annotator) を公開している．
YamChaは同定解析を各要素に対する情報付与と見なすため，一般的な解析器として用いることが可能である．
SVMは2値識別器であるため，情報付与(tagging)のような多値クラスの識別問題を扱うためには，何らかの拡張を行う必要がある．
これに対してYamChaでは，pairwise classification[CITE]（一対比較分類）と呼ばれる手法を採用している．
これは，[MATH]クラスの識別問題を解くために，各クラス2つの組み合わせを識別する[MATH]種類の識別器を作成し，最終的にそれらの多数決でクラスを決定する手法である．
SVMを用いた自然言語解析の例として英文の基本句同定実験[CITE]や，日本語の係り受け解析実験[CITE]があり，従来手法と比較して高い解析結果を示している．
また，平と春野は，SVMを用いた文書分類について，高い分類精度を得るためには品詞によるフィルタリングをした後，全単語を入力として用いればよいことを示している[CITE]．
SVMを用いた中国語の解析器として，我々はYamChaを用いた．
この節ではYamChaによる中国語の形態素解析について述べる．
形態素解析を文字のならびを形態素へまとめあげる同定解析と見なす．
したがって，各文字がチャンク(chunk)を構成する1要素に相当する．
チャンクとは，同定解析における同定単位を指し，ここでは形態素に相当する．
SVMの学習のためにCTBを正解データとして用いる．
YamChaで扱うデータ形式は，複数のトークンと複数のカラムから構成される．
各行は入力のトークンに対応する．
形態素解析を行う場合は，1トークンが1文字に対応する．
各カラムにはトークンに付与された属性が記述される．
また，各カラムはタブまたはスペースによって区切られている必要がある．
YamChaによって推定(学習)すべき属性は最後のカラムに与える．
ここでは，形態素解析を行うので，第1カラムには，形態素の要素である1文字を記述し，第2カラムには，YamChaで推定する情報を記述する．
この情報には，形態素の区切り位置を示す情報と，形態素に付与する品詞情報の両方が含まれる．
また，文と文の境界は，EOSと記述した行，もしくは空行を付与することで同定する．
トークンがチャンクに含まれるか否かの状態を示すためにIOB2モデルを用いた[CITE]．
これは，あるトークンがチャンクの先頭ならばBタグを付与し，チャンクに含まれる先頭以外のトークンならばIタグを付与し，チャンクに含まれない場合にはOタグを付与するモデルである．
一方，本実験ではすべてのトークンが何らかのチャンクに含まれるためOタグは用いられない．
付与する品詞タグセットはCTBのタグセットと同一である．
また，CTBにおいて品詞が``-NONE-''の形態素は構文構造上形式的に配置され，実体を持たないため対象外とする．
最終的にトークンに付与されるタグはB/Iタグと品詞タグを``--''で結んだものとなる．
CTBからYamChaで中国語形態素解析を行うための書式へ変換する概要を図[REF_YamChaFormat]に示す．
以上の処理で得られた学習データをYamChaに与え，SVMのモデルを作成する．
その際に，素性として使用したデータはYamChaの標準設定に従った．
すなわち，推定するトークンと，その前方，および後方2トークンの計5トークンにおける文字データと前方2トークンの推定タグを素性として学習した．
解析方向は前方からである．
これは，使用する素性を変化させた場合の精度を検討した予備実験の結果において，YamChaの標準設定が最も高い精度であったためである．
これらの関係を図[REF_features]に示す．
また，YamChaで学習を行うために用いたSVMの実装は同じく工藤が公開しているTinySVM 0.08 である．
本報告では，YamChaと同程度の時間的コストで実現できる中国語形態素解析器としてMOZ [CITE]をとりあげ，両者の比較を行う．
本節では，MOZに関する概略を述べる．
MOZで形態素解析を行うためには，形態素辞書と接続表が必要となる．
MOZはコスト最小法に基づく解析器であるので，形態素辞書と接続表にはそれぞれコストを与えなければならない．
ここでは，CTBから得られる情報(品詞2つ組の頻度や形態素の頻度など)から形態素辞書と接続表，ならびにそれらのコストを求める．
すなわち，形態素辞書は形態素とその出現確率から，品詞接続表は品詞bi-gramによって与える．
MOZでは，品詞接続表にtri-gram以上のデータを用いることができるが，データ過疎性(data sparseness)による精度低下を避けるために本実験では品詞bi-gramのみを用いた．
形態素を[MATH]，品詞を[MATH]，[MATH]の頻度を[MATH]と表記すると品詞が[MATH]である形態素[MATH]の出現確率を式([REF_mor_p])で与える．
ここで，[MATH]は形態素[MATH]，かつその品詞が[MATH]である頻度を示している．
また，品詞接続表の確率は式([REF_con_p])で与える．
ここで[MATH]は品詞[MATH]のあとに品詞[MATH]が出現した頻度である．
システムで扱う最高コストを128として，コスト化係数を求める．
コスト化係数は式([REF_cost_co])により与えられる．
ここで最小確率は，すべての[MATH]および[MATH]における最小値である．
形態素辞書ならびに接続表のコストはそれぞれの確率から式([REF_costing])により与えられる．
以上述べた方法により形態素辞書ならびに接続表のコストを計算する．
まず，CTB全体を学習データ(4181文)とし，この中から無作為に抽出した1割の文（418文）を解析する学習文テスト(closed test)を行った．
具体的には，YamChaとMOZをそれぞれ用いて，418文からなるテストデータを解析し，その結果をCTBの正解と比較し，評価した．
その結果から，再現率(recall)と適合率(precision)を算出した．
再現率と適合率はそれぞれ式([REF_recall])および式([REF_precision])とした．
再現率と適合率からF値(F-measure)も求めた．
F値は再現率[MATH]と適合率[MATH]の調和平均であり，式([REF_F-measure])によって与えられる．
ただし，本実験では正解形態素数を求める場合に形態素分割のみ正解の場合と，分割ならびに品詞の両方の2段階の条件を設けて評価した．
この結果を表[REF_MorclosedTest]に示す．
また，品詞誤りの上位10件を表[REF_MorclosedResult2]に示す．
ここで，出現率とは誤りの総数に対する各誤りの割合を示す．
次に，CTB全体を母集団とする10分割交差検定(cross validation)による未知文テスト(open test)を行った．
まず，CTB全体(4181文)を無作為に10等分し，1割をテストデータ，残りの9割を学習データとする．
この方法で10組の学習データとテストデータを作成した．
YamChaとMOZそれぞれに対して，10組の学習データとテストデータを用いて学習ならびにテストを行い，平均値を求めた．
実験結果を表[REF_MOR_Opentest]に示す．
また，品詞誤りの上位10件の内訳を表[REF_MoropenResult2]に示す．
表中のnullは未知語のために付与されたタグを示している．
未知文テストにおいてYamChaが1学習データを学習するために要した処理時間と1テストデータを解析するために要した処理時間などを表[REF_MorTime]に示す．
測定時は，CPU: Pentium III 600 MHz，メモリ: 256 MB，OS: Linuxの計算機を用いた．
ただし，YamChaで解析を行うためには，アーキテクチャ非依存のテキスト形式のモデルファイル(学習結果を格納するファイル)をアーキテクチャ依存のバイナリ形式にコンパイルする必要がある．
その際にテキスト形式のモデルをメモリ上に展開するため大量のメモリを必要とする．
この実験では，約650 MBのメモリを必要としたため，コンパイル作業だけは，CPU: Pentium III 733 MHz，メモリ: 960 MBの計算機を使用した．
このコンパイルに要した時間は約5分であった．
本実験のあと，コンパイルに必要なメモリ量を抑える目的からプログラムを修正した．
その結果，速度を少々犠牲にするが，80MB程度のメモリで，上記のモデルファイルをコンパイル可能となった．
処理時間は，CPU: Pentium III 600MHz，メモリ: 256 MBの計算機で約7分であった．
このYamCha 0.1に対するプログラムの差分はWWWページにて公開している．
一方，MOZが学習データ(約3700文)から形態素辞書と接続表のコストを求めるために必要とした時間は約3秒であり，1テストデータ(約400文)を解析するために必要とした時間は約1秒であった．
次に，テストデータに含まれる形態素のうち，学習データに含まれていないものを未知語と定義し，その性質を調べた．
未知文テストにおける平均未知語率などを求めた．
結果を表[REF_OpenUnknown]に示す.
未知語率とはテストデータの単語数に占める未知語数の割合を指し，平均未知語率とはテストセット全体での未知語率の平均を示している．
未知語に対する解析器の性質をより詳しく調べるため，以下の実験を行った．
まず，CTBから40記事を無作為に選択する．
そのうち30記事を学習データ，残り10記事をテストデータとする．
次にテストデータから順に1記事ずつ学習データに加えていき，計11個の学習データを作成する．
それぞれの学習データに基づく解析器で同一のテストデータ10記事を解析した．
以上の実験概要を図[REF_UnknownWordExp]に示す．
テストデータに含まれる単語数は1111，のべ語数は2954である．
11のテストセットにおける学習データの単語，未知語数ならびに未知語率を表[REF_UkTEST]に示す．
各テストセットにおける未知語率(異なり)と解析精度の関係を図[REF_MorCrbyUk]に示す．
図では，解析精度をF値で示す．
なお，未知語率(のべ)と精度の関係を図示していないが，図[REF_MorCrbyUk]とほぼ同一の図となるため省略する．
次に，未知語がある場合の解析結果を調査した．
テストセット[MATH]における未知語の集合を[MATH]，[MATH]のうち形態素分割に成功した形態素の集合を[MATH]とする．
さらに，[MATH]のうち品詞も正しく解析された形態素の集合を[MATH]とする．
これらの集計結果を表[REF_UK_Analyze_table]に示す．
また，MOZでは入力に未知語が含まれる場合，解析不能で停止することはないが，最終的に未知語と判断された文字列を1文字ずつ，nullという品詞を与えて出力する．
したがって，MOZでの解析で[MATH]を示していないのは，MOZでは未知語がnullと解析されるため，[MATH]は空集合となるためである．
一方，MOZでの解析において[MATH]が得られるのは，正解が1文字の形態素である場合に形態素分割が成功したと見なすからである．
これまで，CTBをコーパスとして，中国語の形態素解析について2つの解析器，YamChaとMOZを比較してきた．
しかしその未知文テストの結果は，表[REF_MOR_Opentest]に示す通り，これまでに報告されている日本語の形態素解析器の精度より低い．
ここでは，その原因が，中国語の言語としての解析の難しさにあるのか，コーパスの量にあるのかを検討する．
CTBで用いられているのは，新華社通信の新聞記事である．
そこで，SVMに基づく形態素解析器の日本語に対する精度を検証するために我々は，京都大学テキストコーパス第3.0版（以下，京大コーパスと呼ぶ）を用いて実験を行った．
このコーパスの詳細については付録[REF_KYODAI_CORPUS]を参照されたい．
CTBの大きさが約10万語であるところから，我々は，京大コーパスのうち1月1, 3, 4, 5日の記事，4117文，102310単語を用いることにした．
CTB全体では，4181文，99720単語である．
我々が選択した京大コーパスの一部についてCTBに対する実験と同様に，10分割交差検定を実施した．
この検定における平均未知語率などを表[REF_OpenUnknown]に示す．
京大コーパスを用いた実験における品詞は，JUMANが定義する品詞のうち品詞細分類までを含めたものとした．
この結果，タグセットの大きさは，41となり，CTBの33より大きい．
YamChaの学習に用いたデータの例を以下に示す．
今B-名詞-時相名詞話B-名詞-普通名詞年I-名詞-時相名詞題I-名詞-普通名詞のB-助詞-接続助詞のB-助詞-接続助詞大B-名詞-普通名詞力B-名詞-普通名詞相I-名詞-普通名詞士I-名詞-普通名詞撲I-名詞-普通名詞たB-接尾辞-名詞性名詞接尾辞をB-助詞-格助詞ちI-接尾辞-名詞性名詞接尾辞支B-動詞えI-動詞るI-動詞
実験結果を表[REF_MOR_Opentest]に示す．
参考までに我々が選択した京大コーパスの一部をJUMANで形態素解析した結果もあわせて示す．
日本語を対象とした実験でも，同程度の大きさのコーパスでは，同程度の精度となった．
CTBは既に述べた通り4181文，99720単語からなるコーパスだが，大きいとは言えない．
そのため，10分割交差検定を行っても，テストセットにおける未知語率が非常に大きくなり，精度が低くなる．
品詞タグ付けされたコーパスがあれば，それを形態素解析器のために利用することが可能である．
CTBのように構文木を備えている必要はない．
品詞タグ付けされた中国語のコーパスはいくつかあるが，我々は，CTBよりも大きく，そして同じ新聞記事という点から人民日報タグ付きコーパスを使用した．
人民日報タグ付きコーパスに関しては，付録[REF_PKU_CORPUS]にその概要等を示す．
ただし，我々は人民日報半年分であるコーパス全てではなく，無償公開している1ヶ月分のデータを用いた．
人民日報タグ付きコーパス1ヶ月分(以下，PKUと呼ぶ)は，44011文，1121447単語からなるコーパスである．
定義されているタグセットの大きさは39である．
しかしながら，実際のPKUにはここに定義されていないタグが7種類(Bg: 8, Mg: 7, Rg: 10, Yg: 1, na: 1, nx: 459, vvn: 1，コロンの後の数値は頻度を示す)出現する．
ここで，nxは，定義されているタグxに該当することがわかったので，nx以外の6種類のタグを含む文を除いた．
その結果，PKUは，43913文，1118794単語からなるコーパスとなった．
PKUはCTBの約11倍の大きさを持つ．
まず，同程度のコーパスの大きさでの精度を検証した．
PKUをランダムに文単位で11等分し，そのうちの1つ(約10万語)を用いて10分割交差検定を行った．
結果を表[REF_MOR_Opentest]に示す．
以下，このPKUの10万語のコーパスをPKU10万語と表記する．
PKU10万語を用いての未知文テストとCTBでの未知文テストでの精度の違いは，両者のコーパスの違いに起因する．
両者はともに約10万語のコーパスであるが，表[REF_OpenUnknown]から，PKUの方が未知語が多く，なおかつ1文あたりの平均形態素数がCTBより約1単語多いことがわかる（CTBでの1文平均形態素数[MATH]，PKU10万語での1文平均形態素数[MATH]）．
さらに，PKUは，CTBと比較してタグセットが大きく，タグ一種類あたりの学習データが少なくなることからタグの推定がより難しくなっている．
したがって，PKU10万語での結果は，同じ10万語のCTBと比較して精度が大きく低下したと考える．
MOZが再現率の面でYamChaを上回るのは，辞書を用いる利点が活かされていると考える．
YamChaは1文字単位でタグの推定を行う．
タグの推定に用いるのは推定対象文字とその前後2文字，さらに直前に推定した2つのタグの計7つの素性である．
したがって，学習量が不十分な状態では，ある形態素が学習，テストコーパスの両方に含まれている場合でも，テストデータにおける当該形態素とその周辺文字列の組合せを素性として学習している可能性は低いためSVMが誤る可能性が大きくなる．
一方，MOZでは，一度辞書に登録された形態素は，形態素分割および品詞の曖昧性が生じない限り正しく再現される．
さらに学習コーパスが大きくない場合では，これらの曖昧性が発生する頻度は低いと予想する．
したがってMOZが再現率の面で，YamChaを上回ったと考える．
次に，PKU全てを学習コーパスとし，学習文テストを行った．
テストデータとしてPKUから無作為に抽出した3993文，101218単語を解析した．
なお，学習に用いるコーパスが大きくなることから，より大きな分解能が必要になると考え，MOZのコスト化係数を128から1024へと変更した．
実験結果を表[REF_MorclosedTest]に示す．
この結果から，学習コーパスが100万語を越えても，YamChaは変わらず高い性能を示していることがわかる．
学習に用いるコーパスの大きさが非常に大きくなった場合の2つの解析器のふるまいを検討するために，11等分したデータを用いて11分割交差検定を行った．
結果を表[REF_MOR_Opentest]に示す．
以上得られた形態素解析に関する実験結果について考察する．
まず，YamChaとCTBを使用した場合の未知文に対する形態素解析(分割と品詞付与)精度(F値)は87.9%であった．
同条件でMOZが83.3%であることを考えると，言語資源としてCTBしか得られない条件下ではYamChaを使用したほうが高精度な解析器を実現できる．
次に，解析時間についてはYamChaが極端に遅い．
学習時間も同様である．
よって解析時に実時間性を問われる状況においてはMOZを使用すべきである．
YamChaでは，既に述べたように，一対比較分類に基づき品詞付与を行うため，品詞数が大きくなると，その2乗に比例するSVMが必要となる．
そのため，品詞数の増加とともに，学習，解析時間が増大する．
品詞付与誤りの傾向では，1節で述べたように中国語において本質的に解析の難しいと予想される箇所で両解析器共に誤っており，解析器としての誤りのくせはあまり見受けられない．
未知語に対する頑健性については，YamChaのほうが優れる．
実験では，YamChaは未知語の約4割を正しく解析しており，頑健性を確かめられた．
この割合は，未知語率が変化しても，大きく変化することはなく，実験した範囲の未知語率(51.5%から6.4%)で，40%から45%程度であった．
このことから，未知語率が大きくなったからといってそれに影響されて極端に精度が低下することはないと予想する．
一方，MOZは，未知語に対して1文字ずつにnullという品詞を付与して出力するのみであるため，何らかの拡張を行わない限り品詞の推定を行えない．
したがって，再現率に対して適合率が低くなる傾向がある．
また，YamChaにはこのような傾向はなく，適合率が再現率を若干上回る傾向を示す．
これらのことから，入力文中に多くの未知語の存在が予想される場合，あるいは学習データの語彙傾向と異なる入力文を解析する場合はYamChaを用いたほうがよい．
ただし，一般的な状況としてコーパスとは別個に単語集合を入手できる場合がある．
この場合にはMOZを使うべきだろう．
YamChaでは単語集合があってもこの情報を学習に反映させることができず，コーパス中の出現単語のみが学習対象であるためである．
言語資源をより活用しているのはYamChaであるが，辞書を用いないことから語彙的整備ができない．
また人間の内省による知見を反映させにくい．
したがって，既に大量のタグ付きコーパスが存在する状況では，MOZのような，接続コストを統計的言語モデルに基づいて推定する手法が頑健で，整備しやすい解析器となる．
逆に，タグ付きコーパスが充分に整備されていない言語の解析器を必要とする場合，あるいは，新たに定義した品詞に対する解析器が，その品詞で解析されたコーパスが充分に存在しない状況で必要となる場合にはYamChaが有効である．
また，中国語に固有の解析の難しさが考えられるが，日本語を対象とした実験の結果から，同程度のコーパスならびにそのタグセットの大きさの場合では顕著な違いは見られなかった（表[REF_MOR_Opentest]）．
しかしながら，京大コーパスの平均未知語率が，CTBのそれと比較して大きく（表[REF_OpenUnknown]），さらに，京大コーパスのタグセット(41)がCTBのそれ(33)より大きい．
これは，日本語解析の実験条件が中国語解析の条件に比べ，厳しいことを示す．
それにもかかわらず，実験結果は同程度の精度を示した．
これらのことから中国語解析が，日本語解析に比べて難しいと判断する．
さらに，表[REF_MOR_Opentest]は，京大コーパスの解析結果とCTBの解析結果において単語分割のみと分割と品詞付与との間の逆転現象があることを示している．
これは，中国語解析の困難な点は，品詞付与にあるという我々の予見を裏付ける結果と考える．
一方で，より大きなコーパスを用いることにより，高精度な解析器が実現可能であることが，表[REF_MOR_Opentest]からわかる．
また，表[REF_MorclosedTest]に示した学習文テストの結果から，学習コーパスをさらに大きくするとYamChaはさらに精度を向上させる可能性がある．
それに対し，MOZは，PKU（100万語以上の大きさを持つコーパス）を用いての学習文テスト結果において分割と品詞付与のF値が約95%（表[REF_MorclosedTest]）だったことから，現状の枠組のままでは，F値で95%程度がその性能の限界だと考える．
これをさらに向上させるためには，接続表へのtri-gram規則の適用ならびにその補完などが可能である．
しかし，浅原らは，中国語の場合には，tri-gramの規則自体があまり有効ではなく，品詞体系の詳細化が精度の向上に寄与することを実験結果から予測している[CITE]．
本節では，YamChaを用いた基本句同定解析(base phrase chunking)実験について述べる．
基本句同定解析とは，形態素解析結果すなわち品詞付与された単語列を入力として，最も下位の構造を同定し，その構造に対して構文的情報を付与する処理である．
ここで，最も下位の構造を基本句，基本句に対する構文的情報を句情報と本報告では呼ぶことにする．
このように，基本句同定解析は一段階の構文解析と考えることができる．
したがって，構文解析は同定解析を繰り返すことで実現できる[CITE]．
工藤らは，SVMに基づく同定解析の段階適用が，日本語の係り受け解析に有効であることを示している[CITE]．
同定解析の学習データは，形態素解析と同様にCTBを用いた．
CTBが表現する構文木では，葉が形態素に相当する．
基本句同定解析では，葉に最も近い位置に付与されている構造が基本句であり，形態素が基本句を構成する要素に該当する．
すなわち，形態素情報を入力として基本句の区切り位置と句情報を推定する．
CTB全体(3572文)を学習データとして無作為に抽出した1割の文(357文)を解析する学習文テストを行った．
この結果を表[REF_BP_close]に示す．
学習文テストにおけるテストデータは7746の基本句からなる．
そのうちYamChaは7745の基本句を同定した．
このうち7741の基本句の同定に成功し，そのうち句情報も正解だったものは7740であった．
すなわち，学習文テストではYamChaはほとんどすべての解析に成功した．
次に，形態素解析実験と同様に，10分割交差検定による未知文テストを行った．
学習の素性は，形態素の文字列情報，品詞情報，基本句の区切りを示すIOBタグとその基本句の句情報である．
すべての学習条件はYamChaの標準設定に従っている．
形態素解析実験と同様に再現率と適合率を求めた．
未知文テストの結果を表[REF_BphopenResult1]に示す．
なお，正解基本句数の平均は7734.4であり，YamChaが出力した基本句数の平均は7691.9である．
基本句同定，句情報付与共に比較的高い精度を得られることがわかった．
また，句情報付与における誤りのうち出現率の大きい上位5種を表[REF_BphopenResult2]に示す．
1テストセットあたりの学習・解析時間は，表[REF_BphTime]の通りである．
なお，形態素解析実験と同一の計算機を使用した場合，モデルファイルのコンパイルに要した時間は約1分だった．
基本句同定解析は，形態素解析と比べて高い解析精度を得た．
また，学習・解析に要する時間がいずれも短い．
これは付与する情報の種類が少ない，およびトークン数が少ないためである．
