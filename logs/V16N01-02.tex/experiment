実験

2つの提案手法，つまり，
\begin{itemize}
\item 式(\ref{式：n-gram確率の比})の値の推定を手法1で行う判別手法
	   (Hypo1)，
\item 式(\ref{式：n-gram確率の比})の値の推定を手法2で行う判別手法(Hypo2)
\end{itemize}
を用いた母語話者性判別実験を行った．
また，
\begin{itemize}
\item 藤井らの手法で使用する言語モデルを $n$-gram に拡張した手法(Skew)，
\item 青木らの手法(KL)
\end{itemize}
による
母語話者性判別を行い，提案手法との比較を行った．

実験データは以下の2種類を用意した．
\begin{itemize}
 \item {\bf データ1}\\
       電気情報関係の国際会議で発表された英語科学技術論文．内訳は，
       \begin{itemize}
	\item 英語圏（米国，英国，カナダ，オーストラリア）で開催された採択率
	      50\%未満の国際会議の論文で，第一著者が英語圏所属の非日本人名で
	      ある論文 602 件，
	\item 東／東南アジアで開催された採択率50\%以上の国際会議の論文で，
	      第一著者が日本所属の日本人名の論文 679 件
       \end{itemize} 
       である．
       擬似的に，前者を母語話者文書集合，
       後者を非母語話者文書集合とした．なお，母語話者文書集合／非母語話者
       文書集合における品詞列の出現頻度情報の信頼度がほぼ同一となるよう
       に，両文書集合中の延べ単語数（下記の前処理後の単語数）がほぼ同数
       になるように文書数を設定した．
 \item {\bf データ2}\\
       電気情報関係の国際会議で発表された英語科学技術論文で，
       校正専門家（母語話者）が母語話者性を判定したもの60件（母語話者文
       書 25 件，非母語話者文書 35 件）．これは，\cite{青木}で使用されて
       いる評価用論文と同一のものである．
\end{itemize}

なお，論文の収集に際しては，両文書集合に母語話者／非母語話者以外の
特徴の差が現れないように注意を払った．すなわち，複数の研究分野から
論文を収集し，図表や数式，ヘッダやフッタなどの情報を削除するという
前処理を行った．単語列から品詞列への変換には Tree Tagger\footnote{
http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisonTreeTagger.html
}を用いた．変換後の品詞異なり数は 57 であった（文頭，文末の特殊記号
$@_s$，$@_e$ を除く）．

データ1に付与された母語話者性
（$N$/$N\!N$ の別）
はかなり精度は高いものの，勿論誤りを含む．
そこで，参考としてデータ2をテストデータ（判別対象文書）とした実験（評価実験2）
も行った．データ数が少ないため，各手法に対して有意な差は期待できないが，
データ1での結果と同様の傾向が見られるかどうかを調べた．

各手法の評価は，以下の2つの精度
\begin{align*}
 Prec(N)   &= \frac{母語話者文書で母語話者文書と判別された文書数}
                    {母語話者文書と判別された文書数}\\[4mm]
 Prec(\NN) &= \frac{非母語話者文書で非母語話者文書と判別された文書数}
                    {非母語話者文書と判別された文書数}
\end{align*}
のうち値の低い方（これを MinPrec と表記する）を用いて評価する．
これは，本手法の目的が，母語話者文書および
非母語話者文書をともに高精度で収集することにあるからである．


\subsection{評価実験1}

以下のようにして，各手法の精度をデータ1を用いて10交差検定
(10-fold cross validation)\cite{確率的言語モデルテキスト}
で求める．

\begin{itemize}
 \item[(1)] データ1の母語話者文書集合を $B_1^N, B_2^N, \cdots, B_{10}^N$
	    と10ブロックに分割する．同様にデータ1の非母語話者文書集合
	    を $B_1^\NN, B_2^\NN, \cdots, B_{10}^\NN$ と10ブロックに分割
	    する．
 \item[(2)] 各 $t=1,2,\cdots,10$ に対して，以下を行う．
	    \begin{itemize}
	     \item[(a)] 各 $i=1,2,\cdots,10\,(\neq t)$ に対して，\\
		   $B_t^N,\,B_i^N$ を除く8ブロックの母語話者文書を
		   母語話者言語モデルの学習データ，
		   $B_t^\NN,\,B_i^\NN$ を除く8ブロックの非母語話者文書を
		   非母語話者言語モデルの学習データとして，
		   $(B_i^N,B_i^\NN)$ の各文書の母語話者性を判別し，
		   MinPrec が最大となるメタパラメタの値を求める．
	     \item[(b)] 上記で求めたメタパラメタの値（9個）の平均値をメ
		   タパラメタの値として設定し，
		   $B_t^N$ を除く9ブロックの母語話者文書を
		   母語話者言語モデルの学習データ，
		   $B_t^\NN$ を除く9ブロックの非母語話者文書を
		   非母語話者言語モデルの学習データとして，
		   $(B_t^N,B_t^\NN)$ の各文書の母語話者性を判別する．
	    \end{itemize}
 \item[(3)] 上記(b)で求めた母語話者性判別結果より，精度を求める．
\end{itemize}
なお，各手法におけるメタパラメタは，手法 Hypo1 
と Hypo2 では有意水準 $\alpha$，
手法 Skew では式(\ref{Skew:α})の $\beta$，
手法 KL では式(\ref{式：Sibun加算スムージング})の
加算項 $\delta$ である．上記 (2) の (a) での各 $(B_i^N,B_i^\NN)$ に
対する MinPrec が最大となるメタパラメタの値は，
\begin{align*}
 \alpha &\in \{0.01,\; 0.03,\; 0.05,\; 0.07,\; 0.09,\; 0.11\} 
  \quad\mbox{(Hypo 1, 2)}\\
  \beta &\in \{0.01,\; 0.02,\;\cdots,\;0.15\}
  \quad\mbox{(Skew)}\\
  \delta &\in \{1\times10^{-7},\; 3\times10^{-7},\; 5\times10^{-7},\;
                 1\times10^{-6},\; 3\times10^{-6},\; 
                  \cdots,\; 5\times10^{-4}\}
  \quad\mbox{(KL)}
\end{align*}
の範囲で求めた．


\subsection{評価実験2}

以下のようにして，データ1を学習データ，データ2をテストデータとした場合の
各手法の精度を求める．

\begin{itemize}
 \item[(1)] データ1の母語話者文書集合を $B_1^N, B_2^N, \cdots, B_{10}^N$
	    と10ブロックに分割する．同様にデータ1の非母語話者文書集合
	    を $B_1^\NN, B_2^\NN, \cdots, B_{10}^\NN$ と10ブロックに分割
	    する．
 \item[(2)] 各 $i=1,2,\cdots,10$ に対して，\\
	    $B_i^N$ を除く9ブロックの母語話者文書を
	    母語話者言語モデルの学習データ，
	    $B_i^\NN$ を除く9ブロックの非母語話者文書を
	    非母語話者言語モデルの学習データとして，
	    $(B_i^N,B_i^\NN)$ の各文書の母語話者性を判別し，
	    MinPrec が最大となるメタパラメタの値を求める．
 \item[(3)] 上記で求めたメタパラメタの値（10個）の平均値をメタパラメタの
	    値として設定し，データ1の全母語話者文書を母語話者言語モデル
	    の学習データ，データ1の全非母語話者文書を非母語話者言語モデル
	    の学習データとして，データ2の各文書の母語話者性を判別し，
	    精度を求める．
\end{itemize}
上記(2)での MinPrec が最大となるメタパラメタ値は前節と同様の範囲で求めた．


\subsection{結果と考察}

$n=3,4,5,6,7,8$ なる品詞 $n$-gram を言語モデルとした場合の
2つの評価実験の結果を表\ref{実験結果}に示す．
表には，MinPrec だけでなく，参考のため，Prec(N)，Prec(NN) も挙げている．
また，『未定』の判定になった数を挙げている．
手法 Skew のみ未定があるが，これは，条件部の品詞列の学習データにおける
頻度が高い品詞 $n$-gram 分布が存在し，
用いた計算機の精度では式(\ref{Skew:α})の値が1となり，
その結果 $ED(d\;;\;N)$ も $ED(d\;;\;\NN)$ も$\infty$ となってしまっ
たことによる．

評価実験1では，
各手法とも，$n>3$ で MinPrec が最も高い．
手法 Skew は，$\alpha$ の設定式(\ref{Skew:α})が最適とは限らないことを
述べたが，それでも，$n=5$ の場合は $n=3$ の場合より精度が1\%向上しており，
このことからも，条件部の長い品詞 $n$-gram モデルを言語モ
デルとすることの有効性が分かる．

提案手法では，Hypo2 の $n=7$ の場合の MinPrec が最も高く，
$\mbox{MinPrec}=Prec(N)=552/597\simeq 0.925$ である．一方，
従来手法では，Skew の $n=5$ の場合の MinPrec が最も高く，
$\mbox{MinPrec}=Prec(N)=546/606\simeq 0.901$ である．
2つの二項母集団の母比率の差の検定\cite{統計テキスト2}
を行うと，有意水準
約 8 \% で有意差があることが示せ，AICに基づく2つの二項母集団の母比率
の差の検定\cite{統計テキスト3}
でも有意差が示せる．

2つの提案手法 Hypo1 と Hypo2 の比較では，
同一の $n$ に対する MinPrec は Hypo2 の方が概ね高い．特に，$n=6,7,8$ では
その差は大きく，$n$-gram 確率に関して，
母語話者／非母語話者文書間で有意な差がない場合に，$k<n$ なる $k$-gram 確率
を利用して式(\ref{式：n-gram確率の比})を推定する効果が現れていることが分かる．

評価実験2でも，
各手法とも $n>3$ で MinPrec が最も高く，そのうち，Hypo2 の MinPrec が最
も高い．また，Hypo1 と Hypo2 における同一の $n$ に対する MinPrec は
Hypo2 の方が概ね高い．評価実験2では使用したテスト文書数が少ないため，
信頼性のある結果とは言えないが，このように評価実験1とある程度同様の傾向
が現れていることが分かる．

\begin{table}[t]
\caption{評価実験 1，2 の結果}
\label{実験結果}
\input{02table02.txt}
\end{table}


