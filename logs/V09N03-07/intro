序論

近年，テキスト自動要約の研究が活発化するとともに，要約の評価方法が研究
分野内の重要な検討課題の一つとして認識されてきている．これまで提案され
てきた要約の評価方法は，内的な(intrinsic)評価と外的な(extrinsic)評価の
2種類に分けることができる\cite{Sparck-Jones:1996}．内的な評価とは，シ
ステムの出力した要約そのものを，主に内容と読みやすさの2つの側面から評
価する方法である．一方， 外的な評価とは，要約を利用して人間がタスクを
行う場合の，タスクの達成率が間接的に要約の評価となるという考え方に基づ
いて評価を行う方法である．本研究では，近年活発にその評価方法が議論され，
改良が試みられている内的な評価，特に内容に関する評価方法に焦点を当てる．

これまでの要約の内容に関する評価は，人手で作成した抜粋と要約システムの出
力との一致の度合を，F-measure等の尺度を用いて測るのが典型的な方法であっ
た．しかし，Jingら\cite{jing:98:a}は，要約のF-measureによる評価と外的な
評価を分析し，F-measureには「テキスト中に類似の内容を含む文が複数
存在する場合，どちらの文が正解として選択されるかにより，システムの評価は
大きく変化する」という問題があることを指摘している．






この問題点を解決する方法がこれまでにいくつか提案されている．
Radevら\cite{radev:00:a}は，文のutilityという概念を用いた評価方法を示し
ている．文のutilityとは，そのテキストの話題に対する各文の適合度(重要度)
を10段階で表したものであり，正解の文のutility にどのくらい近いutilityの
文を選択できるかで評価を行なう．しかし，このような適合性の評価は被験者へ
の作業負荷が大きいという問題がある．

Donawayら\cite{Donaway:2000}は，人間の作成した正解要約の単語頻度ベクトル
とシステムの要約の単語頻度ベクトルの間のコサイン距離で評価する
content-basedな評価を提案している．content-basedな評価では，指定された要
約率の正解要約を一つだけ用意すれば評価可能であるため，utilityに基づく評
価に比べ，被験者への負荷が少ない．しかし，この評価方法で2つの要約を比較
する場合，どの程度意味があるのかについては，これまで十分な議論がなされて
いない．

そこで，本研究では，まず，utilityに基づく評価の問題点を改良する新しい評
価方法を提案する．一般に低い要約率の抜粋に含まれる文は高い要約率の抜粋中
の文よりも重要であると考えられる．このような考えに基づけば，あるテキスト
に関して複数の要約率のデータが存在する場合，テキスト中の各文に重要度を割
り振ることが可能であるため，utilityに基づく評価を疑似的に実現することが
できる．これまでの要約研究において，1テキストにつき複数の要約率で正解要
約が作成されたデータは数多く存在する(例えば，\cite{jing:98:a})ことから，
提案する評価方法に用いるデータの作成にかかる負荷は決して非現実的なもので
はなく，utilityを直接被験者が付与するより負荷は小さいと考えられる．




本研究では，評価型ワークショップNTCIR 2の要約サブタスクTSC(Text
Summarization Challenge)\cite{Fukushima:2001a,Fukushima:2001b}で作成され
た10\%，30\%，50\% の3種類の要約率の正解データを用いて，提案方法により評
価を行う．この評価結果をF-measureによる結果と比較し，提案方法がF-measure
による評価を改善できることを示す．

次に，本研究では，content-basedな評価を取り上げる．同様にTSCのデータを用
いて，人間の主観評価の結果と比較し，これまで十分議論されていないその有用
性に関する議論を行う．

本論文の構成は以下のとおりである．次節では，まず，これまで提案されてきた
内的な評価方法，特にF-measureの問題点の解消方法について述べる．3節では，
本研究で提案する評価方法について説明する．4節では，F-measureと提案する評
価方法を比較し，結果を報告する．また，content-basedな評価に関する調査に
ついても述べる．最後に結論と今後の課題について述べる．


