================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:5, score:0.42902] 本研究では，あるテキストに関する複数の要約率のデータを用いることで，疑似的にutilityに基づく評価を実現する方法を提案する．
[i:8, score:0.55533] content-basedな評価では，指定された要約率の正解要約を一つだけ用意すれば評価可能であるため，utilityに基づく評価に比べ，被験者への負荷が少ない．
[i:10, score:0.65957] そこで，pseudo-utilityに基づく評価と同様にTSCのデータを用い，content-basedな評価の結果を被験者による主観評価の結果と比較した結果，2つの要約がcontent-basedな評価値で0.2以上の開きがあれば，93%以上の割合で主観評価の結果と一致することが分かった．

================================================================
[section type  : intro]
[section title : 序論]
================================================================
[i:23, score:0.55533] content-basedな評価では，指定された要約率の正解要約を一つだけ用意すれば評価可能であるため，utilityに基づく評価に比べ，被験者への負荷が少ない．
[i:27, score:0.44304] このような考えに基づけば，あるテキストに関して複数の要約率のデータが存在する場合，テキスト中の各文に重要度を割り振ることが可能であるため，utilityに基づく評価を疑似的に実現することができる．
[i:28, score:0.45518] これまでの要約研究において，1テキストにつき複数の要約率で正解要約が作成されたデータは数多く存在する(例えば，[CITE])ことから，提案する評価方法に用いるデータの作成にかかる負荷は決して非現実的なものではなく，utilityを直接被験者が付与するより負荷は小さいと考えられる．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:61, score:0.35036] 人間が選択した重要文を用いたこれまでの評価方法は，正解と一致した場合正解数1，一致しない場合0として再現率，精度を計算していたが，utilityに基づく評価値は，システムが選択した文に対して人間が割り当てたutilityの総和を，正解の文のutilityの総和で割った値として計算する．
[i:67, score:0.38921] Donawayらが提案するもう一つの評価尺度は，人間の作成した正解要約の単語頻度ベクトルとシステムの要約の単語頻度ベクトルの間のコサイン距離で評価する方法(以後，content-basedな評価)である．
[i:71, score:0.36663] その結果，content-basedな評価が人間の要約との比較による評価方法としては，Jingらの指摘する問題点2に対する解決策ともなっており，もっとも優れていると結論づけている．

================================================================
[section type  : experiment_result]
[section title : pseudo-utilityに基づく評価]
================================================================
[i:72, score:0.52289] 本研究では，あるテキストに関する複数の要約率の正解データを用いることで，utilityに基づく評価を疑似的に実現する方法(以後，pseudo-utilityに基づく評価)を提案する．
[i:85, score:0.63866] 表[REF_table:exp2]において，要約率10%におけるF-measure値とpseudo-utility値を比較すると，どちらのシステムも10%要約の正解であるS1ではなくS4を選択しているため，F-measure値は0になる．
[i:87, score:0.58288] この例の場合，要約率10%ではF-measure値は0か1しか取り得ないが，pseudo-utilityに基づく評価では，このような文も評価の対象とすることで，より適切な評価が可能になる．

================================================================
[section type  : experiment_result]
[section title : 評価方法の分析]
================================================================
[i:92, score:0.38768] 本研究では，pseudo-utilityに基づく評価の有効性を調べるために，TSCのデータを用いて評価を行う．
[i:93, score:0.21107] また，TSCではcontent-basedな評価がシステムの評価方法の一つに採用されているが，この評価結果を用い，content-basedな評価の有効性についても検討する．
[i:94, score:0.05722] 本節では，まず，4.1節でTSCの課題および評価方法について説明する．
-----------------------------------------------------
  [subsection title : TSCにおける評価]
-----------------------------------------------------
  [i:lead, score:0.23840] TSCとは，要約研究における資源の共有や日本語テキストの要約に関する共通の評価方法や評価基準の明確化を本格的に推進させるために行われた，第2回NTCIRワークショップのタスクである．
.....
  [i:97, score:0.26853] TSCでは3種類の課題が設定されているが，本節ではそのうち内的(intrinsic)な評価を適用している2つの課題A-1「重要文抽出型要約」とA-2「人間の自由作成要約と比較可能な要約」について述べる．
  [i:128, score:0.32570] そして，人間の作成した正解要約(FREEとPART)の単語頻度ベクトルとシステムの要約の単語頻度ベクトルの間の距離を計算し，どの程度内容が単語ベースで類似しているかという値を求める[CITE]．
  [i:130, score:0.36010] なお，課題A-2において，人間の作成する要約は，(1)人間が自由作成した要約，(2)人間が重要個所抽出により作成した要約の2種類があり，content-basedな評価はこの両方に対して行なった．
-----------------------------------------------------
  [subsection title : 評価方法の分析]
-----------------------------------------------------
  [i:lead, score:0.44958] pseudo-utilityに基づく評価の有効性を示すためには，pseudo-utilityに基づく評価とutilityに基づく評価の比較，および，F-measureとpseudo-utilityに基づく評価の比較を行う必要があると考えられる．
.....
  [i:148, score:0.52574] 一方，システムの出力した3文のうち，正解に含まれていない残りの2文の一方は30%の正解に，もう一方は50%の要約に含まれているため，pseudo-utility値は0.511([MATH])となっている．
  [i:184, score:0.61314] システムIとIIが出力したそれぞれ90個の要約(30テキスト×10%, 30%, 50%)のうち，システムIとIIでF-measure値は同じだがpseudo-utility値の異なる16組の要約について調査した．
  [i:187, score:0.57171] 表[REF_ivsii]は，記事980500136における要約率10%での例で，原文中の文ID，pseudo-utilityに基づく評価に用いた重要度，システムIとIIが選んだ文，および文の内容を示している．

================================================================
[section type  : conclusion]
[section title : 結論と今後の課題]
================================================================
[i:234, score:0.56429] 本研究では，要約の評価方法について，pseudo-utilityに基づく評価方法を提案し，F-measureとの比較を行った．
[i:236, score:0.60243] F-measureとpseudo-utilityに基づく評価の比較では，要約システムの出力をいくつか調べたところ，正解には含まれていないが正解文と類似する内容の文をシステムが抽出した場合，pseudo-utilityに基づく評価では評価値にそれが反映されていることが確認された．
[i:237, score:0.51112] すなわち，pseudo-utilityに基づく評価は，F-measureがかかえる2つの問題点のうち「(2)テキスト中に類似の内容を含む文が複数存在する場合，どちらの文が正解として選択されるかにより，システムの評価が大きく変化する」が解消できていることがわかった．

