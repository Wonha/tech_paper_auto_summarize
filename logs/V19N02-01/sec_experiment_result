本節では，提案する2つの素性（言い換え素性と翻字素性）が片仮名複合名詞の分割処理の精度に与える効果について報告を行う．
発音モデルのパラメータ推定に必要な翻字対のデータは，外国人の名前を日本語で表記するときにはほぼ常に翻字が行われることに着目し，Wikipediaを用いて自動的に構築した．
構築手順としては，まず「存命人物」のカテゴリに所属するWikipeida記事のタイトルを抽出することにより，片仮名表記の人名リストを作成した．
そして次に，Wikipediaの言語間リンクを利用し，各人名に対する原語を抽出した．
これにより17,509の翻字対を収集することができた．
このように自動収集したデータの中には翻字対として不適切なものも含まれている可能性があるが，大量のデータを手軽に用意できるという利点を重視して，この方法を採用している．
実際，このようにパラメータ推定のためのデータを大量に生成するアプローチは，翻字生成において有効であることが報告されている[CITE]．
パラメータ推定時には，EMアルゴリズムの初期値を無作為に10回変化させ，尤度が最大となったモデルを以降の実験で用いた．
平均化パープトロンの学習に必要なラベル付きデータは，日英対訳辞書EDICTを利用して手作業で作成した．
具体的には，まず，EDICTの見出し語から，翻字である片仮名（複合）名詞を無作為に抽出した．
そして，EDICTに記載されている英訳に基づき，単語境界のラベルを付与した．
この結果，5286の片仮名語データを得た．
このデータにおける構成語数の分布を調べたところ，構成語が1語のものが3041，2語のものが2081，3語以上のものが164となっていた([MATH])．
また，複合名詞1つあたりの平均文字数および平均構成語数は6.60および1.46であった．
以下本節において報告する実験結果は，このラベル付きデータを用いて2分割交差検定を行ったものである．
言い換え及び逆翻字を抽出するためのテキストには，ウェブから収集した17億文のブログ記事を用いた．
このテキストを用いることによって14,966,205の言い換え表現と，116,027の単語対応付き翻字対を抽出することができた．
表[REF_fig:extract-para]と[REF_fig:extract-backtrans]に，実際に抽出された言い換え表現（の候補）と単語対応付き翻字対の具体例を示す．
単語対応付き翻字対の抽出を行う際には閾値[MATH]を設定する必要がある．
[MATH]は確率の対数に対する閾値であるため，0より小さな任意の値を設定することが可能であるが，ここでは[MATH]の範囲で値を変化させ，実験において最も高いF値が得られた値([MATH])を採用した．
実験では，3つの教師なし学習手法(Unigram, GMF, GMF2)，2つの教師あり学習手法(AP, AP [MATH] GMF2)，3つの単語分割器(JUMAN, MeCab, KyTea)との比較を行った．
以下ではこれらベースライン手法について簡単に説明を行う．
分割結果[MATH]に対する[MATH]-gram言語モデルの尤度[MATH]が最も大きくなる分割を選択する手法[CITE]:
ここで[MATH]は構成語[MATH]の出現確率であり，[REF_sec:setting]節で述べたウェブテキストから推定をした値を用いた．
構成語[MATH]の頻度の幾何平均GMF[MATH]が最大となる分割[MATH]を選択する手法[CITE]:
ここで[MATH]は構成語[MATH]の出現頻度であり，[MATH]と同様にウェブテキストから推定した値を用いた．
頻度の幾何平均に構成語の長さに基づく補正を導入したスコアを用いる手法[CITE]:
ここで[MATH]，[MATH]，[MATH]は超パラメータ，[MATH]は構成語の平均文字数を表す．
本実験ではNakazawaら[CITE]と同じく[MATH] = 2500，[MATH] = 4，[MATH] = 0.7とした．
基本素性（[REF_sec:approach]節参照）のみを用いた平均化パーセプトロン．
基本素性に加えてGmf2の処理結果を素性として用いた平均化パーセプトロン．
Alfonsecaら[CITE]に従って，(i) GMF2[MATH]の値が全分割候補中で最大であるか否かを表す2値素性，(ii)分割を行わない候補（i.e., [MATH]となる候補）よりもGMF2の値が大きくなるか否かを表す2値素性を追加した．
ルールベースの単語分割器 JUMAN ver. 6.0 [CITE]．
対数線形モデルに基づく単語分割器MeCab ver. 0.98 [CITE]．
解析辞書にはNAIST-jdic ver. 0.6.0を用いた．
点推定モデルに基づく単語分割器KyTea ver. 0.3.1 [CITE]．
表[REF_tab:comparison_result]に提案手法(Proposed)とベースライン手法との比較結果を示す．
この表の結果から以下のようなことが分かる．
まず，ProposedとAPの結果の比較から，言い換え素性と逆翻字素性を導入することにより，分割精度が大きく向上したことが分かる．
マクネマー検定を行ったところ，この精度変化は統計的に有意なものであることが確認された([MATH])．
この結果は，提案する2つの素性の有効性を示すものである．
次に，提案手法の精度は，全ての教師なし学習ベースライン(Unigram, GMF, GMF2)及びAP [MATH] GMF2の精度を上回っていることが確認できる．
これらの結果は，複合名詞の言い換えや逆翻字の情報が，構成語の頻度情報よりも効果的であることを示唆している．
なお，マクネマー検定を行ったところ，これらの精度向上も全て統計的に有意であることが確認できた([MATH])．
単語分割器(JUMAN, MeCab, KyTea)の結果は，これまでに単語分割タスクにおいて報告されている精度[CITE]を大きく下回っている．
このことから，一般的な単語分割と比較して，片仮名複合語の分割処理が困難なタスクであることが分かる．
さらに，提案手法の精度は，単語分割器の精度を大きく上回っており，提案手法が既存の単語分割器の弱点補強に有用であることが示唆されている．
例えば，既存の単語分割器によって「片仮名表記の名詞の連続」と解析された部分を，提案手法を用いて再分割することにより，解析結果の改善を期待することができる．
表[REF_tab:example]に，MeCabでは分割に失敗したが，Proposedでは正しく分割することができた例を示す．
まず最初の例では，片仮名語「ディクショナリー」がNAIST-jdicに登録されていなかったため，MeCabは分割に失敗している．
一方，Proposedにおいては，以下のような単語対応付き翻字対が学習されており，これに基づいて発火した逆翻字素性(1-gram)が有効に働いた結果，正しく分割することに成功している．
オックスフォード[MATH]ディクショナリー[MATH]    oxford[MATH] dictionary[MATH]
次の例では「メイン」と「タイトル」が両方ともNAIST-jdicに登録されているにも関わらず，MeCabは分割に失敗している．
これは，MeCabの未知語処理に起因する誤りであると考えられる．
その一方でProposedが分割に成功しているのは，例えば「メインのタイトル」といった言い換え表現に基づく素性など，分割を示唆する素性がより多く発火しているためだと推測できる．
最後の例では，NAIST-jdicに人名「トミー」が登録されているため，MeCabは過分割を行ってしまっているが，Proposedでは「アナトミー」に対する逆翻字素性が適切に発火しており，過分割を防ぐことに成功している．
本論文の趣旨からは外れるが，3つの単語分割器のなかではKyTeaの精度が他の2つを大きく引き離している点は非常に興味深い．
これは，JUMANやMeCabの解析アルゴリズムが，辞書引きによる候補選択に強く依存しているのに対して，KyTeaはそのような候補選択を行っていないことが要因と考えられる．
実験に使用した5286の片仮名複合名詞のうち，2542は少なくとも1つの未知語を構成語に含んでいた．
ただし，ここで言う未知語とは，訓練データに出現せず，なおかつ外部辞書NAIST-jdicにも登録されていない単語のことを指す．
未知語が分割精度に与える影響について考察するため，提案手法を含む3つの教師あり学習手法(AP, AP [MATH] GMF2, Proposed)と単語分割器MeCabの分類結果を，1つ以上の未知語を含む2542の片仮名複合名詞と残る2744の片仮名複合名詞に分けて集計した（表[REF_tab:oov]）．
以下では，前者のサブセットをw/ OOVデータ，後者をw/o OOVデータと呼ぶ．
この表から，3つの教師あり学習手法については，w/o OOVデータに対しては90%を越える高い精度が達成されているのに対して，w/ OOVデータの精度は大きく低下していることが確認できる．
同様の傾向はMeCabの結果においても見られる．
MeCabは汎用的な単語分割器であるため，複合名詞分割というタスクに特化して学習された提案手法(Proposed)やその他の教師あり学習手法（APやAP [MATH] GMF2）と比べると，精度自体はどちらのデータにおいても大きく低下している．
しかし，w/ OOVデータよりもw/o OOVデータのほうが精度が高くなるという傾向は，依然として確認することができる．
これらの結果は，片仮名複合名詞の分割処理を困難にしている要因は未知語であるという我々の主張を支持するものである．
3つの教師あり学習手法は，w/o OOVデータについてはほぼ同じ精度を達成していることが分かる．
これは，既知語に対しては，基本素性だけを使ってすでに高い分類精度が達成されているため，これ以上の精度向上が困難であるからだと考えられる．
一方，精度向上の余地が残されているw/ OOVデータについては，3つのシステムの間に大きな精度の差を見てとることができる．
そのため，表[REF_tab:comparison_result]の結果よりも，言い換え素性と翻字素性を導入する効果をより直接的に確認することができる．
言い換え素性と翻字素性の有効性について詳細に検証するため，異なる4つの素性集合を用いたときの平均化パーセプトロンの分割結果の比較を行った（表[REF_tab:comparison]）．
表の1行目は使用した素性集合を表す．
Basicは基本素性，ParaとTransはそれぞれ言い換え素性と翻字素性，Allは全ての素性集合を表す．
この表より，言い換え素性と翻字素性の両方ともが分割精度向上に大きく貢献していることを確認することができた．
いずれの場合においても，基本素性だけを使った場合と比較して，精度の向上は統計的に有意であった（[MATH]，マクネマー検定）．
次に，各素性の発火率について調査を行った．
実験で用いたラベル付きデータには7709の構成語が含まれており，そのうち64.0%(4937/7709)は外部辞書に登録されていた．
これに対して，単語対応付き翻字対に出現していた構成語の割合は64.0%(4935/7709)，外部辞書か単語対応付き翻字対のいずれかに出現していたものの割合は77.1%(5941/7709)であった．
これにより，翻字素性を導入することによって，未知語の数が大幅に減少していることが確認された．
一方，ラベル付きデータに含まれる構成語[MATH]-gramの数は2423であったが，それらに対して発火していた言い換え素性と翻字素性の割合は，それぞれ79.5%(1926/2423)と12.8%(331/2423)であった．
これらの結果から，提案素性はいずれも精度向上に寄与しているものの，カバレージにはまだ改善の余地があることが分かった．
続いて，素性の発火率と収集元であるブログデータの大きさの関係を調査した（図[REF_fig:feature-coverage]）．
ここではブログデータの大きさとして，収集したブログ記事（UTF8エンコーディング）をgzipで圧縮したデータのサイズをギガバイト単位で表示している．
この図から，大量のブログデータを使うことによって，高い発火率を実現できていることが確認できる．
しかし，その一方で，データが増えるにつれて，発火率の向上の度合いは鈍りつつある．
このことから，データを単純に増加させるだけでは，ここからの大幅な発火率の改善を期待することは難しく，言い換え規則の拡張などの方法も併せて検討していくことが今後重要になると考えられる．
最後に，パラメータ[MATH]の値を変化させたときの影響について調査を行った（図[REF_fig:size]--[REF_fig:threshold]）．
図[REF_fig:size]と[REF_fig:fire]は，様々な値の[MATH]に対する，単語対応付き翻字対の抽出数および逆翻字素性の発火した割合（[REF_sec:effect]節において議論したもの）を示している．
これらの図から，[MATH]の値をある程度小さく設定すれば，十分な数の翻字対が抽出され，その結果として多くの事例において素性が発火するようになることが分かる．
図[REF_fig:threshold]は[MATH]とF値の関係を示している．
さきほどの2つの図との比較すると，翻字対の抽出数と素性の発火数の増加が，F値の向上に直接結びついていることが分かる．
パラメータの値が極端に大きい場合(e.g., [MATH])においては，F値が低下する傾向が見られたものの，パラメータによらずF値はおおよそ一定であった．
この結果から，提案手法の精度はパラメータ設定に敏感ではなく，パラメータ調整は難しい作業ではないことが示唆される．
また，少なくとも実験において調べた範囲では，提案手法はパラメータ値によらず，基本素性のみを用いた場合よりも高いF値を達成することができた．
そのため，パラメータの微調整が提案手法の性能に与える影響は小さいと言うことができる．
提案手法が分割を誤った事例を調べたところ，「アップロード」を「アップ」と「ロード」，「トランスフォーマー」を「トランス」と「フォーマー」に分割するなど，単語を過分割している事例が見られた．
ここでの「アップ」や「トランス」は接頭辞であると考えられるため，これらの分割結果は形態論的分割(morphological segmentation)としては正しいものであるかもしれないが，単語分割としては不適切であると考えられる．
こうした過分割が発生する要因として，接辞と単語の曖昧性を指摘することができる．
例えば「アップ」は，確かに接頭辞の1つであるが，文脈によっては「給料がアップする」のように独立した名詞として使われる場合もある．
同じく「トランス」に対しても「トランス状態」のような名詞用法を考えることができる．
このような曖昧性によって引き起こされる最も顕著な問題は，辞書素性（表[REF_tab:feature]におけるテンプレートID4）が過剰に発火することである．
前述の過分割の事例においては，NAIST-jdicに「アップ」と「トランス」がともに名詞として登録されていたため，本来不適切な分割結果であるにも関わらず辞書素性が発火していた．
これと同様の問題は，辞書素性だけでなく，逆翻字素性においても発生しうる．
[REF_sec:trans]節で説明した単語対応付き翻字対の抽出手法は，原語が正しく分かち書きされていることを前提としていた．
しかしながら，実際には接頭辞や接尾辞の前後に空白区切りを挿入しているテキストも存在するため，不適切な対応関係が学習されてしまう場合がある．
表[REF_tab:error]は上記の過分割結果に影響を与えたと思われる単語対応付き翻字対の一部である．
この表から，「アップロード」と「トランスフォーマー」については，それぞれ原語との対応関係が適切に学習されていることが確認できる．
しかしながら「アップローダー」と「トランスフォーム」については，原語が接頭辞の直後で分かち書きされていたため，不適切な単語対応が学習されていることが分かる．
こうした対応付け結果から導出された逆翻字素性（この例では特に1-gram）は分割に悪影響を与えている可能性がある．
翻字抽出の手法を改善することにより，こうした誤りを減少させることは，今後の課題の一つであると考えている．
過分割が多くみられた別要因としてデータの偏りを考えることもできる．
今回使用したデータの半数以上は構成語数が1つであったため，そもそも過分割が発生しやすい設定の実験になっていた可能性がある（[REF_sec:setting]節を参照）．
現在のところ，当該タスクに対する別のデータセットを用意することは難しいため，この点をすぐに調査することはできないが，今後の研究の中で議論を深めていくべきであると考えられる．
本節では，提案する2つの素性（言い換え素性と翻字素性）が片仮名複合名詞の分割処理の精度に与える効果について報告を行う．
発音モデルのパラメータ推定に必要な翻字対のデータは，外国人の名前を日本語で表記するときにはほぼ常に翻字が行われることに着目し，Wikipediaを用いて自動的に構築した．
構築手順としては，まず「存命人物」のカテゴリに所属するWikipeida記事のタイトルを抽出することにより，片仮名表記の人名リストを作成した．
そして次に，Wikipediaの言語間リンクを利用し，各人名に対する原語を抽出した．
これにより17,509の翻字対を収集することができた．
このように自動収集したデータの中には翻字対として不適切なものも含まれている可能性があるが，大量のデータを手軽に用意できるという利点を重視して，この方法を採用している．
実際，このようにパラメータ推定のためのデータを大量に生成するアプローチは，翻字生成において有効であることが報告されている[CITE]．
パラメータ推定時には，EMアルゴリズムの初期値を無作為に10回変化させ，尤度が最大となったモデルを以降の実験で用いた．
平均化パープトロンの学習に必要なラベル付きデータは，日英対訳辞書EDICTを利用して手作業で作成した．
具体的には，まず，EDICTの見出し語から，翻字である片仮名（複合）名詞を無作為に抽出した．
そして，EDICTに記載されている英訳に基づき，単語境界のラベルを付与した．
この結果，5286の片仮名語データを得た．
このデータにおける構成語数の分布を調べたところ，構成語が1語のものが3041，2語のものが2081，3語以上のものが164となっていた([MATH])．
また，複合名詞1つあたりの平均文字数および平均構成語数は6.60および1.46であった．
以下本節において報告する実験結果は，このラベル付きデータを用いて2分割交差検定を行ったものである．
言い換え及び逆翻字を抽出するためのテキストには，ウェブから収集した17億文のブログ記事を用いた．
このテキストを用いることによって14,966,205の言い換え表現と，116,027の単語対応付き翻字対を抽出することができた．
表[REF_fig:extract-para]と[REF_fig:extract-backtrans]に，実際に抽出された言い換え表現（の候補）と単語対応付き翻字対の具体例を示す．
単語対応付き翻字対の抽出を行う際には閾値[MATH]を設定する必要がある．
[MATH]は確率の対数に対する閾値であるため，0より小さな任意の値を設定することが可能であるが，ここでは[MATH]の範囲で値を変化させ，実験において最も高いF値が得られた値([MATH])を採用した．
実験では，3つの教師なし学習手法(Unigram, GMF, GMF2)，2つの教師あり学習手法(AP, AP [MATH] GMF2)，3つの単語分割器(JUMAN, MeCab, KyTea)との比較を行った．
以下ではこれらベースライン手法について簡単に説明を行う．
分割結果[MATH]に対する[MATH]-gram言語モデルの尤度[MATH]が最も大きくなる分割を選択する手法[CITE]:
ここで[MATH]は構成語[MATH]の出現確率であり，[REF_sec:setting]節で述べたウェブテキストから推定をした値を用いた．
構成語[MATH]の頻度の幾何平均GMF[MATH]が最大となる分割[MATH]を選択する手法[CITE]:
ここで[MATH]は構成語[MATH]の出現頻度であり，[MATH]と同様にウェブテキストから推定した値を用いた．
頻度の幾何平均に構成語の長さに基づく補正を導入したスコアを用いる手法[CITE]:
ここで[MATH]，[MATH]，[MATH]は超パラメータ，[MATH]は構成語の平均文字数を表す．
本実験ではNakazawaら[CITE]と同じく[MATH] = 2500，[MATH] = 4，[MATH] = 0.7とした．
基本素性（[REF_sec:approach]節参照）のみを用いた平均化パーセプトロン．
基本素性に加えてGmf2の処理結果を素性として用いた平均化パーセプトロン．
Alfonsecaら[CITE]に従って，(i) GMF2[MATH]の値が全分割候補中で最大であるか否かを表す2値素性，(ii)分割を行わない候補（i.e., [MATH]となる候補）よりもGMF2の値が大きくなるか否かを表す2値素性を追加した．
ルールベースの単語分割器 JUMAN ver. 6.0 [CITE]．
対数線形モデルに基づく単語分割器MeCab ver. 0.98 [CITE]．
解析辞書にはNAIST-jdic ver. 0.6.0を用いた．
点推定モデルに基づく単語分割器KyTea ver. 0.3.1 [CITE]．
表[REF_tab:comparison_result]に提案手法(Proposed)とベースライン手法との比較結果を示す．
この表の結果から以下のようなことが分かる．
まず，ProposedとAPの結果の比較から，言い換え素性と逆翻字素性を導入することにより，分割精度が大きく向上したことが分かる．
マクネマー検定を行ったところ，この精度変化は統計的に有意なものであることが確認された([MATH])．
この結果は，提案する2つの素性の有効性を示すものである．
次に，提案手法の精度は，全ての教師なし学習ベースライン(Unigram, GMF, GMF2)及びAP [MATH] GMF2の精度を上回っていることが確認できる．
これらの結果は，複合名詞の言い換えや逆翻字の情報が，構成語の頻度情報よりも効果的であることを示唆している．
なお，マクネマー検定を行ったところ，これらの精度向上も全て統計的に有意であることが確認できた([MATH])．
単語分割器(JUMAN, MeCab, KyTea)の結果は，これまでに単語分割タスクにおいて報告されている精度[CITE]を大きく下回っている．
このことから，一般的な単語分割と比較して，片仮名複合語の分割処理が困難なタスクであることが分かる．
さらに，提案手法の精度は，単語分割器の精度を大きく上回っており，提案手法が既存の単語分割器の弱点補強に有用であることが示唆されている．
例えば，既存の単語分割器によって「片仮名表記の名詞の連続」と解析された部分を，提案手法を用いて再分割することにより，解析結果の改善を期待することができる．
表[REF_tab:example]に，MeCabでは分割に失敗したが，Proposedでは正しく分割することができた例を示す．
まず最初の例では，片仮名語「ディクショナリー」がNAIST-jdicに登録されていなかったため，MeCabは分割に失敗している．
一方，Proposedにおいては，以下のような単語対応付き翻字対が学習されており，これに基づいて発火した逆翻字素性(1-gram)が有効に働いた結果，正しく分割することに成功している．
オックスフォード[MATH]ディクショナリー[MATH]    oxford[MATH] dictionary[MATH]
次の例では「メイン」と「タイトル」が両方ともNAIST-jdicに登録されているにも関わらず，MeCabは分割に失敗している．
これは，MeCabの未知語処理に起因する誤りであると考えられる．
その一方でProposedが分割に成功しているのは，例えば「メインのタイトル」といった言い換え表現に基づく素性など，分割を示唆する素性がより多く発火しているためだと推測できる．
最後の例では，NAIST-jdicに人名「トミー」が登録されているため，MeCabは過分割を行ってしまっているが，Proposedでは「アナトミー」に対する逆翻字素性が適切に発火しており，過分割を防ぐことに成功している．
本論文の趣旨からは外れるが，3つの単語分割器のなかではKyTeaの精度が他の2つを大きく引き離している点は非常に興味深い．
これは，JUMANやMeCabの解析アルゴリズムが，辞書引きによる候補選択に強く依存しているのに対して，KyTeaはそのような候補選択を行っていないことが要因と考えられる．
実験に使用した5286の片仮名複合名詞のうち，2542は少なくとも1つの未知語を構成語に含んでいた．
ただし，ここで言う未知語とは，訓練データに出現せず，なおかつ外部辞書NAIST-jdicにも登録されていない単語のことを指す．
未知語が分割精度に与える影響について考察するため，提案手法を含む3つの教師あり学習手法(AP, AP [MATH] GMF2, Proposed)と単語分割器MeCabの分類結果を，1つ以上の未知語を含む2542の片仮名複合名詞と残る2744の片仮名複合名詞に分けて集計した（表[REF_tab:oov]）．
以下では，前者のサブセットをw/ OOVデータ，後者をw/o OOVデータと呼ぶ．
この表から，3つの教師あり学習手法については，w/o OOVデータに対しては90%を越える高い精度が達成されているのに対して，w/ OOVデータの精度は大きく低下していることが確認できる．
同様の傾向はMeCabの結果においても見られる．
MeCabは汎用的な単語分割器であるため，複合名詞分割というタスクに特化して学習された提案手法(Proposed)やその他の教師あり学習手法（APやAP [MATH] GMF2）と比べると，精度自体はどちらのデータにおいても大きく低下している．
しかし，w/ OOVデータよりもw/o OOVデータのほうが精度が高くなるという傾向は，依然として確認することができる．
これらの結果は，片仮名複合名詞の分割処理を困難にしている要因は未知語であるという我々の主張を支持するものである．
3つの教師あり学習手法は，w/o OOVデータについてはほぼ同じ精度を達成していることが分かる．
これは，既知語に対しては，基本素性だけを使ってすでに高い分類精度が達成されているため，これ以上の精度向上が困難であるからだと考えられる．
一方，精度向上の余地が残されているw/ OOVデータについては，3つのシステムの間に大きな精度の差を見てとることができる．
そのため，表[REF_tab:comparison_result]の結果よりも，言い換え素性と翻字素性を導入する効果をより直接的に確認することができる．
言い換え素性と翻字素性の有効性について詳細に検証するため，異なる4つの素性集合を用いたときの平均化パーセプトロンの分割結果の比較を行った（表[REF_tab:comparison]）．
表の1行目は使用した素性集合を表す．
Basicは基本素性，ParaとTransはそれぞれ言い換え素性と翻字素性，Allは全ての素性集合を表す．
この表より，言い換え素性と翻字素性の両方ともが分割精度向上に大きく貢献していることを確認することができた．
いずれの場合においても，基本素性だけを使った場合と比較して，精度の向上は統計的に有意であった（[MATH]，マクネマー検定）．
次に，各素性の発火率について調査を行った．
実験で用いたラベル付きデータには7709の構成語が含まれており，そのうち64.0%(4937/7709)は外部辞書に登録されていた．
これに対して，単語対応付き翻字対に出現していた構成語の割合は64.0%(4935/7709)，外部辞書か単語対応付き翻字対のいずれかに出現していたものの割合は77.1%(5941/7709)であった．
これにより，翻字素性を導入することによって，未知語の数が大幅に減少していることが確認された．
一方，ラベル付きデータに含まれる構成語[MATH]-gramの数は2423であったが，それらに対して発火していた言い換え素性と翻字素性の割合は，それぞれ79.5%(1926/2423)と12.8%(331/2423)であった．
これらの結果から，提案素性はいずれも精度向上に寄与しているものの，カバレージにはまだ改善の余地があることが分かった．
続いて，素性の発火率と収集元であるブログデータの大きさの関係を調査した（図[REF_fig:feature-coverage]）．
ここではブログデータの大きさとして，収集したブログ記事（UTF8エンコーディング）をgzipで圧縮したデータのサイズをギガバイト単位で表示している．
この図から，大量のブログデータを使うことによって，高い発火率を実現できていることが確認できる．
しかし，その一方で，データが増えるにつれて，発火率の向上の度合いは鈍りつつある．
このことから，データを単純に増加させるだけでは，ここからの大幅な発火率の改善を期待することは難しく，言い換え規則の拡張などの方法も併せて検討していくことが今後重要になると考えられる．
最後に，パラメータ[MATH]の値を変化させたときの影響について調査を行った（図[REF_fig:size]--[REF_fig:threshold]）．
図[REF_fig:size]と[REF_fig:fire]は，様々な値の[MATH]に対する，単語対応付き翻字対の抽出数および逆翻字素性の発火した割合（[REF_sec:effect]節において議論したもの）を示している．
これらの図から，[MATH]の値をある程度小さく設定すれば，十分な数の翻字対が抽出され，その結果として多くの事例において素性が発火するようになることが分かる．
図[REF_fig:threshold]は[MATH]とF値の関係を示している．
さきほどの2つの図との比較すると，翻字対の抽出数と素性の発火数の増加が，F値の向上に直接結びついていることが分かる．
パラメータの値が極端に大きい場合(e.g., [MATH])においては，F値が低下する傾向が見られたものの，パラメータによらずF値はおおよそ一定であった．
この結果から，提案手法の精度はパラメータ設定に敏感ではなく，パラメータ調整は難しい作業ではないことが示唆される．
また，少なくとも実験において調べた範囲では，提案手法はパラメータ値によらず，基本素性のみを用いた場合よりも高いF値を達成することができた．
そのため，パラメータの微調整が提案手法の性能に与える影響は小さいと言うことができる．
提案手法が分割を誤った事例を調べたところ，「アップロード」を「アップ」と「ロード」，「トランスフォーマー」を「トランス」と「フォーマー」に分割するなど，単語を過分割している事例が見られた．
ここでの「アップ」や「トランス」は接頭辞であると考えられるため，これらの分割結果は形態論的分割(morphological segmentation)としては正しいものであるかもしれないが，単語分割としては不適切であると考えられる．
こうした過分割が発生する要因として，接辞と単語の曖昧性を指摘することができる．
例えば「アップ」は，確かに接頭辞の1つであるが，文脈によっては「給料がアップする」のように独立した名詞として使われる場合もある．
同じく「トランス」に対しても「トランス状態」のような名詞用法を考えることができる．
このような曖昧性によって引き起こされる最も顕著な問題は，辞書素性（表[REF_tab:feature]におけるテンプレートID4）が過剰に発火することである．
前述の過分割の事例においては，NAIST-jdicに「アップ」と「トランス」がともに名詞として登録されていたため，本来不適切な分割結果であるにも関わらず辞書素性が発火していた．
これと同様の問題は，辞書素性だけでなく，逆翻字素性においても発生しうる．
[REF_sec:trans]節で説明した単語対応付き翻字対の抽出手法は，原語が正しく分かち書きされていることを前提としていた．
しかしながら，実際には接頭辞や接尾辞の前後に空白区切りを挿入しているテキストも存在するため，不適切な対応関係が学習されてしまう場合がある．
表[REF_tab:error]は上記の過分割結果に影響を与えたと思われる単語対応付き翻字対の一部である．
この表から，「アップロード」と「トランスフォーマー」については，それぞれ原語との対応関係が適切に学習されていることが確認できる．
しかしながら「アップローダー」と「トランスフォーム」については，原語が接頭辞の直後で分かち書きされていたため，不適切な単語対応が学習されていることが分かる．
こうした対応付け結果から導出された逆翻字素性（この例では特に1-gram）は分割に悪影響を与えている可能性がある．
翻字抽出の手法を改善することにより，こうした誤りを減少させることは，今後の課題の一つであると考えている．
過分割が多くみられた別要因としてデータの偏りを考えることもできる．
今回使用したデータの半数以上は構成語数が1つであったため，そもそも過分割が発生しやすい設定の実験になっていた可能性がある（[REF_sec:setting]節を参照）．
現在のところ，当該タスクに対する別のデータセットを用意することは難しいため，この点をすぐに調査することはできないが，今後の研究の中で議論を深めていくべきであると考えられる．
