================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[1973] 講演音声のような話し言葉の書き起こしや音声認識結果には、話し言葉特有の表現が数多く含まれており講演録などのアーカイブとして二次利用しにくいため、文章として適した形態に整形する必要がある。

================================================================
[section type  : proposed_method]
[section title : 緒論]
================================================================
[2321] これに対して本研究では、規則に基づいて1対1の変換を行うのではなく、話し言葉と書き言葉を別の言語とみなした上で統計的な機械翻訳の手法を適用し、確率モデルによりもっともらしい表現に変換し実際に文章を整形することをめざす。

================================================================
[section type  : proposed_method]
[section title : 整形作業における処理]
================================================================
[1980] 実際に講演録編集者が、「日本語話し言葉コーパス」（CSJ）[CITE]のいくつかの講演について整形・要約したものを参考にして、(a)から(i)で第一段階、(j)と(k)で第二段階の作業についてそれぞれ例を挙げながら説明する。

================================================================
[section type  : proposed_method]
[section title : 統計的手法による文体の整形]
================================================================
[1973] 講演音声のような話し言葉の書き起こしや音声認識結果には、話し言葉特有の表現が数多く含まれており講演録などのアーカイブとして二次利用しにくいため、文章として適した形態に整形する必要がある。
-----------------------------------------------------
  [subsection title : 統計的機械翻訳のアプローチ]
-----------------------------------------------------
  [2172] 2章で述べたように、書き起こしの文体と整形した文章の文体はかなり異なっており、書き起こしの単語列と整形された文章の単語列を異なる言語とみなすことができる。
-----------------------------------------------------
  [subsection title : フィラーの削除]
-----------------------------------------------------
  [1769] これは[MATH]の値にかかわらず書き起こしの単語列[MATH]から全てのフィラーが削除されることを意味している。
-----------------------------------------------------
  [subsection title : 書き言葉表現への変換]
-----------------------------------------------------
  [2320] ただし本研究では、正解の講演録の数が完全な学習には不十分であったため、あらかじめ人手により書き言葉から話し言葉への変換規則を作成しておき、それらに対してのみ確率を推定することとした。
-----------------------------------------------------
  [subsection title : 助詞の挿入]
-----------------------------------------------------
  [1967] ここでは、[MATH]は整形された文章のある単語列パターン[MATH]に含まれる助詞が話し言葉[MATH]において脱落する確率と解釈される。
-----------------------------------------------------
  [subsection title : 句読点の挿入]
-----------------------------------------------------
  [2069] 「です」「ます」などの典型的な文末表現に付随する句点はあらゆる時間長のポーズになりうるが、書き言葉では通常文の区切り表現とならない「〜と」「で〜」、あるいは文中にも頻繁に使われる「〜た」の部分にある句点は平均ポーズ長以上の長さのポーズになると仮定する。
-----------------------------------------------------
  [subsection title : 文体の統一]
-----------------------------------------------------
  [1910] ここでは、変換モデル確率において、表[REF_desumasu]の各グループ(同一行)間で相互に変換可能としたが、変換確率は等しいものとし、その選択は[MATH]に基づいて行うものとした。
-----------------------------------------------------
  [subsection title : デコーディングアルゴリズム]
-----------------------------------------------------
  [1984] 変換で複数の候補が生成されうることも考慮すると、可能な仮説の数は組み合わせ的に爆発するので、探索アルゴリズムを導入する必要がある。

================================================================
[section type  : experiment_result]
[section title : 実験と評価]
================================================================
[1973] 講演音声のような話し言葉の書き起こしや音声認識結果には、話し言葉特有の表現が数多く含まれており講演録などのアーカイブとして二次利用しにくいため、文章として適した形態に整形する必要がある。
-----------------------------------------------------
  [subsection title : データと実験条件]
-----------------------------------------------------
  [2334] また、[MATH]の計算に用いる言語モデルは、毎日新聞記事データで学習されたもの[CITE]と、Web講演録で学習されたもの[CITE]の2種類であるが、4.5節以外ではWeb講演録の方を使用している。
-----------------------------------------------------
  [subsection title : デコーディングパラメータについて]
-----------------------------------------------------
  [1169] 様々な言語重み・挿入ペナルティの値について行った実験結果を図[REF_parameter]に示す。
-----------------------------------------------------
  [subsection title : 句点の挿入]
-----------------------------------------------------
  [2281] したがって、「です」「ます」などの典型的な文末表現部分にある句点はあらゆる時間長のポーズになりうるが、「〜と」「で〜」「〜た」の部分にある句点は平均ポーズ長以上の長さのポーズになるとするモデルを導入した。
-----------------------------------------------------
  [subsection title : 助詞の挿入]
-----------------------------------------------------
  [1889] 参考までに、誤り箇所からこれらの複合名詞の箇所を除いて集計すると、適合率は許容範囲のものまでを正解とした場合で79.4%(81/102)となった。
-----------------------------------------------------
  [subsection title : 言語モデルの使いわけ]
-----------------------------------------------------
  [1919] しかし、全体の半分程度しか「である」調にならないのは、3.6節でも述べたように、今回の変換モデルでは動詞の語幹が変化する表現に対応していないためである。
-----------------------------------------------------
  [subsection title : 規則ベースの手法との比較]
-----------------------------------------------------
  [2211] 例えば学習テキスト中において、「名詞助詞動詞」の並びで出現頻度が最大となる助詞は「が」であったため、「名詞動詞」となっている箇所には、その前後のコンテキストは考えずに、出現回数が最大の「が」を挿入するという規則を抽出した。
-----------------------------------------------------
  [subsection title : 整形結果の具体例]
-----------------------------------------------------
  [2064] また、この場合、「調音地図」というパターンが３回以上出現しているため、これを専門用語であるとみなして助詞の挿入箇所の候補にはしていない。

================================================================
[section type  : conclusion]
[section title : 結論]
================================================================
[2278] 今後の課題としては、書き言葉表現への変換に関して人手により変換規則を作成するのではなく、大規模なコーパスから規則を抽出して変換確率[MATH]を推定することや、文体の統一に関して不十分であった箇所に対応することが挙げられる。

