講演録編集者は、書き起こしから講演録や要約を作成する際に、通常次の4段階の作業を行う。
第一段階の一次整形では、フィラーの削除や書き言葉表現への変換、助詞の挿入などを行う。
第二段階の文法的チェックでは、言語的に正しくない助詞や接続詞を適切なものに修正する。
ポリティカルチェックでは、差別用語などの不適切な表現の修正を行う。
第三段階の意味的チェックでは、専門用語が正しく用いられているかの確認を行う。
実際に講演録編集者が、「日本語話し言葉コーパス」（CSJ）[CITE]のいくつかの講演について整形・要約したものを参考にして、(a)から(i)で第一段階、(j)と(k)で第二段階の作業についてそれぞれ例を挙げながら説明する。
「あのー」や「えっと」といった間投語はすべて削除する。
次に挙げるような話し言葉表現の書き言葉表現への変換を行う。
(例)「行ってるんですが」→「行っているのですが」
「規則合成っていう方式」→「規則合成という方式」
上記の例では話し言葉と書き言葉が1対1に対応しているが、そうでない場合を以下に示す。
(例)「このようにいたしております」→「このようにしています」「このようにしている」「このようにしております」
このような場合は、全体として「ですます調」か「である調」に統一されるように留意する。
話し言葉では、しばしば助詞が脱落して発話されるので、適切な助詞を挿入する。
(例)「観測されたらそれ適当な分布で」→「観測されたらそれを適当な分布で」
「先程も話しありましたが」→「先程も話しがありましたが」
書き起こしに句読点がない場合は、適当な箇所に句読点を挿入する必要がある。
話し言葉では、倒置を用いて発話されることがあるので、通常の語順に修正する。
(例)「日本語は前寄りでも後寄りでも一応‘あ’なんですね音韻的には。
」→「日本語は前寄りでも後寄りでも音韻的には一応‘あ’なんですね。
」
話者が言い淀みをした部分は全て削除する。
(例)「このようなスペクトルのドッ、ギャップがですね」
言葉の説明を付け加えている部分を削除する。
(例)「モデル化を行い、そのモデル自体HMMですが、そのモデルから」
このような表現は必ずしも削除されるわけではなく、別の表現に書き換えられることもある。
(例)「こういうHMM、我々はMSD-HMMと呼んでいる」→「こういうHMM(MSD-HMM)」
本論と関係ないことを発話している部分を削除する。
(例)「えー、そろそろ時間なんですが、」
言い直しをしている部分は削除する。
(例)「これは、テキストテキストからの音声合成を」
「上唇の、ごめんなさいこれ間違いです」
一文が非常に長い場合は、適切な接続詞を用いることでいくつかの単文に分割する。
(例)「〜日本人としてある意味で嬉しいところあるんですけどもどうしてこういう技術が考えられたかというと、〜」→「〜日本人としてある意味で嬉しいところがあります。
どうしてこういう技術が考えられたかというと、〜」
より適切な助詞や接続詞がある場合は、それに訂正する。
(例)「どのようにして音声の合成をするかということが」→「どのようにして音声の合成をするかが」
本研究では、これらの過程のうち、(a)から(d)の一次整形の処理について取り扱う。
これらの処理だけでもかなり読みやすいものに整形される反面、これ以上の処理については、内容の理解を含めた高度な処理が必要であると考えられるからである。
参考のために図[REF_kakiokosi]に書き起こし、図[REF_kouenroku]に整形された文章の例を示す。
現在、音声認識や機械翻訳の研究において統計的な手法が広く用いられている。
入力系列を[MATH]、出力系列を[MATH]とすると、これらは[MATH]を観測した際の[MATH]の事後確率[MATH]を最大にする[MATH]を求めるという枠組みで捉えられ、ベイズ規則により次の式(1)のように定式化される。
ここで、[MATH]は系列[MATH]が生起する事前確率、[MATH]は系列[MATH]から系列[MATH]が生起する条件付き確率である。
右辺の分母[MATH]は、[MATH]の決定に影響しないので無視できる。
音声認識[CITE]の場合は、[MATH]は入力音声、[MATH]は出力単語列となる。
この場合は、音響モデルにより[MATH]を、言語モデルにより[MATH]を求めている。
機械翻訳[CITE]の場合は、[MATH]を入力言語、[MATH]を出力言語として[MATH]を最大にする[MATH]を求めることで、入力言語[MATH]を出力言語[MATH]に変換する。
この場合、[MATH]は出力[MATH]の言語的な自然性を評価するもので、音声認識と同様に言語モデルにより求める。
[MATH]の計算には変換モデルを仮定し、その確率を求める。
変換モデルとは、入力単語はある出力単語系列(nullを含む)に対応づけられるという仮定の下で、どの単語に対応するかを文全体における相対的な位置も考慮して確率で表したものである。
2章で述べたように、書き起こしの文体と整形した文章の文体はかなり異なっており、書き起こしの単語列と整形された文章の単語列を異なる言語とみなすことができる。
そこで、本研究では書き起こしの文体を整形する際に、書き起こしを整形した文章に翻訳すると考えて、機械翻訳と同様に統計的手法を適用することを検討する。
ただし、一般の機械翻訳と異なり、本研究で扱う処理では単語の順序の入れ替わりは考慮しない。
本研究では上記の変換確率と言語モデル確率を1対1で組み合わせるのではなく、言語的妥当性を重視するために言語モデル確率に重みを乗じることにする。
また、言語モデル確率の値として対数尤度を用いるが、対数尤度は単語の数が多くなるほど値が小さくなるので、単語数に応じた補正を行う。
これらは対数スケールで行われ、以下の式(2)で示される仮説スコアを定義する。
([MATH],[MATH])のパラメータは音声認識のデコーディングにおいて通常用いられ、[MATH]は言語重み、[MATH]は挿入ペナルティと呼ばれている。
本研究では、[MATH]の言語モデルとして単語3-gramを用いる。
この場合、[MATH]=([MATH])について、[MATH]として求められる。
変換モデル確率[MATH]の計算においても、同様に[MATH]=([MATH])と[MATH]=([MATH])の部分列に対する確率を規定して(デフォルトは[MATH] for [MATH])その積を求めるが、この単位は可変長(1から数単語)である。
以下では、フィラーの削除、書き言葉表現への変換、助詞の挿入、句点の挿入、文体の統一のそれぞれの処理において、この枠組みをどのように実現するかについて説明する。
なお本研究では、書き起こしを形態素解析した結果を入力データとして用いている。
形態素解析には、ChaSen ver2.02を用いている。
また、話者がポーズをおいた箇所にはその情報がポーズ長とともに記録されている。
ここでは、[MATH]は整形文[MATH]に対応する話し言葉[MATH]においてフィラーが挿入される確率とする。
フィラーは、発話のどの部分にも出現する可能性があるが、特に句読点の後によく出現する傾向がある。
ただし、整形された文章にフィラーは一切出現しない。
つまり、[MATH]をフィラーを含む単語列であると仮定すると、[MATH]の値は0となり、[MATH]の値も0となる。
これは[MATH]の値にかかわらず書き起こしの単語列[MATH]から全てのフィラーが削除されることを意味している。
ここでは、[MATH]([MATH],[MATH]は１つ以上の単語からなる句)は書き言葉表現の話し言葉表現への変換確率と解釈される。
講演録編集者が一次整形を行う際、文章の順序を入れ替える操作は行わないので、元の書き起こしと講演録編集者により一次整形された文章を照合し、句単位で対応づけを行うことで、[MATH]の値を学習・推定することができる。
ただし本研究では、正解の講演録の数が完全な学習には不十分であったため、あらかじめ人手により書き言葉から話し言葉への変換規則を作成しておき、それらに対してのみ確率を推定することとした。
作成した変換規則数は64個あり、その一部を表[REF_kakikae]に示す。
ここでは、[MATH]は整形された文章のある単語列パターン[MATH]に含まれる助詞が話し言葉[MATH]において脱落する確率と解釈される。
書き起こしと講演録編集者により整形された文章を比較したところ、次のような「品詞」「助詞」「品詞」のパターン[MATH]において助詞が脱落していた。
「名詞」(助詞)「名詞」
(例)「このお話しを幹事の方から」
「名詞」(助詞)「動詞」
(例)「我々は作ってきたわけです」
「名詞」(助詞)「形容詞」
(例)「非常に能力が高くなって」
「名詞」(助詞)「接続詞」
(例)「これはつまりサンプルごとの」
そこで、これらのパターンの助詞が脱落する規則をあらかじめ作成しておき、それが生起する確率[MATH]を書き起こしと一次整形の対応づけにより推定する。
用意した変換パターン数は13個あり、その一部を表[REF_joshi]に示す。
そして、それらの助詞を挿入する場合としない場合との尤度を比較することによって助詞を挿入するかしないか、どの助詞を挿入するのか判定を行う。
「日本語話し言葉コーパス」（CSJ）の書き起こしには句読点がなく、その代わりに話者のポーズ情報が記録されている。
ここでは、整形された文章の単語列[MATH]に含まれる句読点が、音声(書き起こしの単語列[MATH])においてポーズに変換される確率[MATH]を考える。
なお、本研究では句点のみを扱う。
なぜなら、句点を挿入する位置は人によらずほぼ一定であるが、読点を挿入する位置は様々であり定量的な評価を行うのが難しいためである。
音声認識における句点の挿入に関する研究は、これまでにも行われているが[CITE]、これらが扱っているのは旅行会話などの短い話し言葉であり、講演のように長い話し言葉は扱っておらず、また、主に言語モデル([MATH]に相当)による情報しか用いられていない。
文末には、「です」「ます」などのような典型的な表現が多い反面、話し言葉においては独特の表現が文の区切りになることがある。
文末での「〜と」と文頭での「で〜」である。
その例を以下に挙げる。
（例）「単位が使われていたと。
あるいは」
「大きく違う。
でそのままでは」
そこで、本研究では[MATH]の確率において、以下の3通りのモデル化を考える。
[MATH]においてはポーズの長さの情報も考慮する。
整形した文章[MATH]における句点があらゆる長さのポーズに変換されうるとする。
この場合は、書き起こし[MATH]におけるポーズがすべて句点に変換されうることになり、その判定を言語モデル確率[MATH]を用いて行う。
著者らが以前報告した講演音声の自動インデキシングの研究[CITE]では、この考え方が用いられている。
句点の挿入箇所には、ある程度長いポーズがおかれると考えられるので、変換確率[MATH]において、句点がある閾値[MATH]以上の長さのポーズに変換されるとする。
ここで、講演では発話速度が話者によってまちまちであり、それに応じてポーズのおかれる長さも大きく異なるため、すべての講演者に対して同一の値を閾値として用いるのは適切でない。
そこで、閾値として各話者ごとの平均ポーズ長を用いることにする。
予備実験においても、一定の値を閾値として用いる場合には、平均ポーズ長が最良であった。
この場合、平均ポーズ長以上のポーズに対してのみ[MATH]を考慮して句点に変換するか否かの判定を行う。
「です」「ます」などの典型的な文末表現に付随する句点はあらゆる時間長のポーズになりうるが、書き言葉では通常文の区切り表現とならない「〜と」「で〜」、あるいは文中にも頻繁に使われる「〜た」の部分にある句点は平均ポーズ長以上の長さのポーズになると仮定する。
この場合、「ます」「です」などの後のポーズは長さに関係なく句点に変換されうるが、「〜と」「で〜」「〜た」の部分のポーズは平均長以上のポーズに限り、句点に変換されうることになる。
この場合も、最終的には[MATH]を考慮して判定を行う。
上記3通りについて、4章で比較・評価する。
話し言葉を書き言葉に変換する際に、その変換候補が複数ある場合には、どれを採用するかの判定を言語モデル確率[MATH]に基づいて行う。
ここで、使用する言語モデルを異なるものにすると、変換結果も異なったものになる。
本研究では2種類の言語モデルを用いることによって、それぞれ文体が「ですます」調あるいは「である」調に統一することができるか検討する。
使用する言語モデルは、講演録のコーパスから作成されたものと、新聞記事のコーパスから作成されたものを用いる。
前者の言語モデルを用いると「ですます」調の文体に、後者の言語モデルを用いると「である」調の文体に統一されると期待される。
ただし、例えば「ですます」調の文でも「〜であると思われます」といった表現があるため、単純に「である」という表現をすべて「です」や「であります」という表現に変えればよいわけではない。
ここでは、変換モデル確率において、表[REF_desumasu]の各グループ(同一行)間で相互に変換可能としたが、変換確率は等しいものとし、その選択は[MATH]に基づいて行うものとした。
なお、変換の際に動詞の語幹が変化する表現、例えば「思います」→「思う」などの表現については変換規則を用意していない。
これまでに、講演の書き起こしから整形された文章を生成する処理とモデルについて述べてきた。
本研究では、確率[MATH]の計算に単語3-gramモデルを用いるので、これらの処理を逐次的に行うのではなく、統合的に行うように実装する必要がある。
なぜなら、これらの処理を個別に行うと、すぐ前後に別の処理をする必要のある表現が存在する場合、式(2)の尤度の計算に影響を与えるからである。
したがって、前後2単語に着目する必要のある表現が存在しなくなる範囲において、そのすべての変換パターンの尤度を比較して出力単語列を決定する。
その様子を図[REF_renzoku]に示す。
変換で複数の候補が生成されうることも考慮すると、可能な仮説の数は組み合わせ的に爆発するので、探索アルゴリズムを導入する必要がある。
本研究ではビームサーチを行う。
具体的には、生成したパターンの数が100を越えた場合は、そこまでの範囲で尤度を計算し、上位100個のパターンのみを選択することにした。
