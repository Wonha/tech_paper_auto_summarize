まずはじめに，辞書から単語の上位語情報を取り出すことを考える．
ここで言う上位語情報とは，上位語と相関のある数値情報のことであり，上位語を一意に決定するものではない．
一般に定義文中に同じ単語が複数回現れることは稀なので，そのままでは単語間で差を付けることはできない．
そこで，定義文を再帰的に展開し，拡張した定義文の中での出現頻度の差を利用することにする．
この再帰的展開は適当な回数の展開を設定しても良いが，本稿は上位語抽出方法として鈴木による再帰的語義展開手法[CITE]を利用することにする．
この手法によれば，定義文を無限に再帰的に展開することにより巨大な仮想定義文を生成し，そこから頻度情報を取り出すことができる．
辞書の定義文が見出語に意味を与えるためのものであるとすれば，上位語は単語に意味付けするために非常に重要な要素である．
従って，この仮想定義文中には上位語が高い頻度で出現することを期待できる．
再帰的語義展開の基本的な考えは，定義文中の単語頻度を再帰的に展開し，より多くの単語からなる定義文を作成するということである．
辞書（国語辞典）は見出語と定義文の組合せから成り立っている．
定義文は単語の集合であり，これを見出語の集合とみなせば，一つの定義文を複数の定義文の集合として再定義することができる．
ところが，このような展開は無限に続いてしまう．
従って，展開された定義文中の単語数も無限になり，頻度計算は一般に不可能になる．
しかしながら，定義文の展開を行なう毎に一定の割合でその影響が小さくなるとすれば，無限に展開された定義文の影響は元の定義文に比べて微小になる．
このとき，定義文の影響力は語義展開の回数に従う等比数列として表すことができる．
同時に，様々な深さまで展開した定義文の集合体を考え，その総和を無限級数として計算すると必ず有限な値となる．
これにより，定義文の集合体中の単語頻度も有限になり，計算可能となる．
これらを確率モデルに置き換えることで，無限の展開を含めた定義文の集合体から単語の出現確率を取り出すことが可能になり，拡張された定義文として再定義することができる．
計算の概要を以下にまとめる．
以下，[MATH]回展開された定義文を[MATH]次の定義文と呼ぶ．
また，辞書中の定義文を0次定義文とする．
まず，見出語[MATH]と0次定義文中の単語[MATH]の関係は[MATH]と表すものとする．
ここで，[MATH]は[MATH]次の定義文中の単語[MATH]を表す．
従って，確率[MATH]は，見出語[MATH]の0次定義文中に現れる[MATH]の出現確率である．
この表記を用いると，各見出語に関する0次定義文中の単語の出現確率は
の列ベクトルとして表される．
ここで，[MATH]は辞書中の見出語の数である．
行列[MATH]の各要素[MATH]は見出語[MATH]の定義文中の単語頻度[MATH]を用いて
と書ける．
このとき，全ての列ベクトルは，要素の合計が[MATH]であり，確率表現となっている．
さらに，この表記に従うと，[MATH]次定義文は[MATH]により表される．
目的とする定義文の集合体[MATH]は，語義展開の度に定義文の影響が一定の割合[MATH]で減少すると仮定すると，
と書ける．
ここで，係数[MATH]は正規化のための定数である．
式([REF_eq:Ca])は無限級数の計算から
と書け，線型計算により解を求めることができる．
計算により得られる行列[MATH]は，列ベクトルの各要素の合計が必ず1となり，確率として扱うことが出来る．
[MATH]の[MATH]要素を[MATH]と書くと，[MATH]は定義文の集合体の中の単語を意味することになる．
以下，この定義文の集合体を拡張定義文と呼ぶことにする．
すなわち，[MATH]は拡張定義文中の単語の確率頻度である．
上記の手法を実際に国語辞典[CITE]に適用した結果を以下に示す．
前処理として，扱う単語を一般名詞とサ変名詞に限定（形態素解析は茶筌[CITE]を利用）し，語義の区別はせず，語義文と例文をまとめて見出語の定義文とした．
その結果，43,915語の見出語と，平均約7語の0次定義文を得た．
以下，[MATH]で行った実験結果を例に詳細を記す．
まず，式([REF_eq:matrix])([REF_eq:frequency])から確率行列[MATH]を計算した．
これはスパースな43,915次元の正方行列である．
次に式([REF_eq:target])から線形ライブラリ[MATH][CITE]を利用して[MATH]を求めた．
このときの計算精度は32 bit長の浮動小数点演算で，有効桁は[MATH]までとした．
この結果得られた列ベクトルの非ゼロの値を持つ次元数は平均約33,000であった．
すなわち，平均約33,000語の仮想定義文ができたことになる．
表[REF_tab:expand]に0次定義文と拡張定義文との比較を示す．
まず，見出語「通信」に関しては，0次定義文では「通信」が頻度4，他の13語が等しく頻度1で，「通信」のみが突出して頻度が高い．
一方，拡張定義文では全ての単語の確率頻度が異なっており，順位づけすることができる．
また，頻度1位の「通信」と2位の「人」との差は相対的に小さくなっている．
さらに，0次定義文に現れていなかった「物事」「一つ」が拡張定義文では上位の頻度で現れている．
定義文中の語数は，0次定義文では14語だったものが，拡張定義文では32,182語に大幅に増えている．
同様に，見出語「傍受」に関しては，0次定義文では5単語が等しく頻度1で現れているのに対し，拡張定義文では順位が付けられ，中でも「通信」が相対的に大きな頻度を示している．
また，見出語「通信」の場合と同様に「人」「物事」「自分」「行動」といった一般的な単語が現れているほか，「電線」「有線」「発信」といった見出語と関連の深い特徴的な単語が現れている．
本手法を用いると，辞書全体でよく使われる単語，即ち一般的な単語が上位に現れやすくなる．
この性質により，等しい頻度の単語でも，より一般的な語が拡張定義文中の上位に現れる傾向があり，場合によっては0次定義文に現れない単語が確率頻度最大となることもある．
見出語[MATH]の拡張定義文中に上位語[MATH]があるとすれば，上位語[MATH]は見出語[MATH]を説明するために非常に重要な単語であるため，その確率頻度[MATH]は高いことが予想される．
従って，見出語[MATH]の上位語は，その拡張定義文の中から確率頻度[MATH]が高い順に尤もらしいと考えることができる．
この仮説を検証するために，日本語語彙大系[CITE]を正解データとした検証実験を行った．
対象としたのは，前節で用いた43,915語のうち，日本語語彙大系と表記が一致する39,982語である．
[REF_sec:intro]節で記したように，日本語語彙大系は意味的上下関係を表した約3,000のカテゴリーからなるオントロジーと各カテゴリーに割当てられた合計約40万語からなる大規模語彙データである．
ただし，単語の割当てに関しては翻訳への適用を主な目的として作成されているため，オントロジーとしては必ずしも正しいとは限らない．
そこで，本論文では，まずはじめに日本語語彙大系をオントロジー検証のための正解データとして適切に利用する方法を検討し，その後，提案手法に対する評価を行うことにする．
まず，日本語語彙大系のオントロジーとしての性質を調べるため，既存手法による上位語抽出結果と，その結果を人手により修正した正解データを利用した．
この既存手法は，Nicholsらにより提案された，辞書定義文の構文解析により得られた主辞を上位語とみなす手法である[CITE]．
ただし，ここで用いた辞書(Lexeed [CITE])は前節の実験で用いた辞書（学研国語辞典[CITE]）とは異なる．
これらのデータを利用して，日本語語彙大系の意味カテゴリー間の関係を上位語の評価指標としての妥当性という観点から評価した．
評価方法は，次に示す3種類をそれぞれ上位語の正解データとして精度を計算するものである．
見出語の含まれる意味カテゴリーの直接上位カテゴリー中の全単語
直接上位カテゴリーを除く全ての上位カテゴリー（間接上位カテゴリー）中の全単語
見出語と同一カテゴリーに属する全単語
評価結果を表[REF_tab:head]に示す．
人手修正データの評価結果を見ると，直接上位カテゴリーよりもむしろ同一カテゴリーの単語に上位語が多く含まれていることがわかる．
人手修正による精度の向上も同一カテゴリーの方が大きく，上位語の多くはここに集まっていると考えられる．
逆に，間接上位カテゴリーでは，人手修正による精度向上率は[MATH]であり，精度を大きく下げている．
この結果は，間接上位カテゴリーは上位語以外の単語を多く含んでおり，間違った結果を正解と判断している率が非常に高いことを示している．
{言い替えると，間接上位カテゴリーは再現率が非常に低く，一方，直接上位カテゴリーと同一カテゴリーには従来手法のような構文解析手法では取り出しにくい上位語が集まる傾向があるといえる．
ここで，人手修正データに強いバイアスが掛っている（脚注参照）点を考慮すると，実際に修正を加えられた人手修正データの方がより信頼性の高いデータであることに気附く．
従って，精度の絶対値ではなく，向上率を重視したほうが信頼性が高いと考えられる．
よって，本論文においては，日本語語彙大系を上位語の評価として使う場合には，同一カテゴリーあるいは直接上位カテゴリーを正解とみなして評価を行うことにする．
特に同一カテゴリーによる評価を重視する方向で検討をすすめることとする．
}
この結果を考慮して，提案手法による上位語情報の抽出結果を日本語語彙大系の直接上位カテゴリーおよび同一カテゴリーを正解データとして評価した．
その結果を図[REF_fig:hyper-above], [REF_fig:hyper-same]に示す．
図[REF_fig:hyper-above]は直接上位カテゴリーを正解とした場合，図[REF_fig:hyper-same]は同一カテゴリーを正解とした場合である．
それぞれの図には，横軸に拡張定義文中の確率頻度を降順に並べた順位を，縦軸に正解データに対する精度をとり，全ての見出語に関する統計量でプロットしている．
黒丸は前述の人手修正による正解データを，白丸は同じく前述の既存手法による結果である．
太い実線は再帰的展開を行わない場合，即ち[MATH]の結果である．
ここでは同一頻度のものは任意に順位を割当てた．
破線，細い実線，鎖線はそれぞれ[MATH]の場合の結果を示している．
図[REF_fig:hyper-above]の順位1位を比較すると，既存手法の精度[MATH]に対して[MATH]では[MATH]であり，提案手法の精度が上回っている．
また，[MATH]でもそれぞれ[MATH]であり，ほぼ同等の結果を得ている．
ただし，人手修正による正解データの精度[MATH]には及んでいない．
一方，図[REF_fig:hyper-same]の順位1位での比較では，既存手法の精度[MATH]に対して[MATH]のそれぞれで[MATH]と大きく上回る結果を出している．
さらに，[MATH]は人手修正による正解データの精度[MATH]をも僅かに上回っている．
また，再帰的展開前の結果([MATH])と展開後の結果([MATH])とを比較してみると，展開後の結果は，展開前に比べて順位1位の精度が上り，順位2,3位以下では精度が下っている．
これは，再帰的展開により，低い順位にあった上位語が高い順位に移動したことを示しており，再帰的展開の効果を明確に表す結果である．
以上の結果から，提案手法は既存手法と同等以上の精度を持ち，評価方法によっては手作業にも劣らない精度を出せることが示された．
さらに，上位語候補として1語あるいは数語しか提示できない既存手法に比べて，提案手法では順位2位以下の情報を多量に持っているため，アプリケーションへの応用の際にこれらの情報が有効に働くことを期待できる．
[REF_sec:hyperinfo]節で得られた上位語情報を利用して，単語オントロジーの自動生成を試みた．
以下は，今回検証したモデルである．
まず，目的とするオントロジーは上位語が下位語を意味的に包含するものである．
従って，下位語は上位語の意味を要素として含まなければならない．
逆に，下位語は上位語以外の単語の意味を要素として含んではいけないことになる．
いま，あるオントロジーが存在し，その中の単語[MATH]の上位語が[MATH]である場合を考える（図[REF_fig:ont-model](a)参照）．
このとき，[MATH]の持つ意味は[MATH]及び[MATH]自身により特徴づけられると考える．
ところが，[MATH]は拡張定義文において様々な単語から成り立っている．
そこで，単語の意味空間の集合としての見出語の意味空間を考える（図[REF_fig:ont-model](b)参照）．
拡張定義文中の各単語は見出語を構成する要素（部分空間）であると考え，見出語自身とその上位語のみが，その見出語を特徴づける意味要素として有効であると仮定する．
即ち，
オントロジー上に単語[MATH]の上位語として単語[MATH]のみが存在する場合，このオントロジーにおける[MATH]の意味は拡張定義文中の[MATH]で構成される部分空間に限定され，拡張定義文中の他の単語は無視される．
そして，これらの単語の確率頻度の合計が大きいほど，見出語の本来の意味が再現される
と考える．
この再現率がオントロジー全体で高いほど，良いオントロジーとなる．
これにオントロジー上の距離の要素を加味し，単語の確率頻度（[REF_sec:method]節参照）を用いて，上位語を[MATH]としたときの再現率を
と書くことにする．
ただし，[MATH]は単語[MATH]の木構造の頂点からのトポロジカルな距離に従う定数([MATH])である．
以下，この[MATH]を意味再現率と呼ぶ．
この仮定の下で，あるオントロジー[MATH]が存在している場合，[MATH]が存在する確からしさは全単語の意味再現率の積，即ち，
で表すことができる．
つまり，全ての単語がより良く元の意味を再現できている状態がオントロジーの存在が最も安定している状態であると考える．
計算を簡単にするため，式([REF_eq:prob_t])の対数をとれば，
となる．
この[MATH]を最大化することにより，前述の仮定の下での最適な単語オントロジーが取り出せる．
本論文では，計算コストを抑えるため，最適化アルゴリズムを各単語の意味再現率最大化と，その組合せとしての全体の最適化の2段階に分離して行った．
即ち，
[MATH]の最大化
[MATH]の最大化
を交互に行うことで，近似的に最適化を行った．
オントロジー上の距離に関するパラメータ[MATH]は，上位語の木構造の最上位からの階層の深さを[MATH]としたとき，[MATH]の4種類とした．
学習の前提として，オントロジー上での各単語の直接上位語は1語に限定し，自身を上位語とすることを許可している．
自身が上位語となる場合は，当該単語は木構造の最上位に位置するものと考える．
これらの前提の下，学習の初期状態は全ての単語が自身を上位語とする状態にあるものとし，学習を行った．
具体的な学習手順は，次の通りである．
見出語を1つ選ぶ．
上位語候補を[MATH]個選ぶ．
各上位語候補に対して[MATH]を計算し，最大となる上位語を決定する．
上記に対し[MATH]を計算し，値が増加すれば上位語を置換，それ以外なら元に戻す．
を全見出語に関し変化がなくなるまで繰り返す．
ただし，[MATH]は事前に与えられる定数であり，今回の実験では[MATH]とした．
以下，[MATH]の場合を例に，結果の詳細を記す．
学習の結果得られたオントロジーの一部を図[REF_fig:tree-word]に示す．
「通信」の全上位語および全下位語の構造を表示している．
(a)はオントロジー上の距離に関するパラメータ[MATH]を用いて学習した結果である．
同様に(b), (c), (d)はそれぞれ[MATH]のときの結果である．
この値が大きくなる程，上位語の影響は階層の離れた下位語まで届くため，深い木構造が期待できる．
逆にこの値が小さいと，浅い木構造ができることが期待される．
今回の実験では，独立した木構造の数は，(a) 1687，(b) 1472，(c) 788，(d) 142であった．
(a), (b), (c)では「通信」は木構造の最上位に位置しているが，(d)では「人」を頂点とする巨大な木構造の一部であり，多くの上位語の下に位置している．
これらの結果から，パラメータ[MATH]の値が増加するに従い木構造の階層がより深く大きくなるのが確認できる．
また，図[REF_fig:tree-word]を詳細にみると，上下関係が特定の意味関係で統一されているとは言い難いものの，関連のある言葉が集まり木構造を構築していることは確認できる．
次に，生成されたオントロジーの精度を，[REF_subsec:eval-hyper]節同様，日本語語彙大系のカテゴリー間の上下関係との一致度を測ることにより調べた．
評価方法は[REF_subsec:eval-hyper]節の結果を考慮して，2種類の正解データを設定した．
一つは，見出語の含まれる意味カテゴリーの直接上位カテゴリーを正解とするもの，もう一つは，見出語の含まれる意味カテゴリーと同一カテゴリーを正解とするものである．
これら正解カテゴリー内の単語のいずれかに，生成したオントロジーから得られる上位語が一致すれば正解とみなした．
この手法による評価を，オントロジー上での上位語の距離に対する精度としてプロットしたのが図[REF_fig:eval-direct]および図[REF_fig:eval-all]である．
横軸は上位語のトポロジカルな距離で，直接上位語であれば``1''，さらにその上位語であれば``2''というように，オントロジー上の距離を表している．
縦軸は精度である．
図の各線は，学習時のパラメータ[MATH]のそれぞれの結果をプロットしたものである．
また，白丸はオントロジー生成学習前（拡張定義文中の出現頻度最大の単語を正解とみなした場合）の精度を，黒丸は人手で修正したデータの精度（表[REF_tab:head]参照）を表している．
全体的に，学習時のパラメータ[MATH]が小さいほど距離1での精度が高く，また，距離が大きくなるに従い急激に精度を落している．
[MATH]が小さいと，生成された木構造の階層が浅いため大きな距離の上位語は非常に少くなり，逆に，[MATH]が大きいと，木構造の階層が深くなり，多くの上位語を同時に学習するため直接上位語の精度が犠牲になると考えられる．
ただし，この差は僅かであり，距離2以上では逆転するものもあるので，[MATH]を如何に設定すべきかは更なる検討が必要である．
さらに，これらの結果を学習の前後で比較してみる．
図[REF_fig:eval-direct]の距離が1（直接上位語）の場合を見ると，オントロジー生成学習前（図では白丸）よりも後の方が大きく精度を下げている．
人手修正データの場合（図では黒丸）と比べると，半分程度の精度である．
ここで人手修正データの性質を考える．
このデータはオントロジーを意識して作成されたものではないので，上位語にさらにその上位語を積上げる手法をとっても木構造にはならず，ループ状につながってしまう．
従って，木構造にするには，いくつかの上位語を変える必要があり，多少の精度低下が起る．
この点を考慮すると，学習前後で精度が低下することは妥当であると思われる．
一方，図[REF_fig:eval-all]では距離が1の各値はオントロジー生成学習前（図の白丸）および人手修正データ（図の黒丸）と比べて大きく精度を上げている．
[REF_subsec:eval-hyper]節の結果を考慮すれば同一カテゴリーによる評価がより重要であるとも考えられるが，同義語など他の要素が影響している可能性も考えられる．
この点に関しても更なる検討が必要である．
以上の結果は，[MATH]の場合でも同様の傾向がみられる．
上述のように，オントロジーとしての十分な評価を下すためには更に検証を加える必要があるが，上記の実験結果は計算により得られた上位語情報を学習によって木構造に組み上げる方法論の妥当性を示唆している．
また，再帰的展開の影響が小さい[MATH]での結果が学習前から大きく改善したことは，辞書から得たカバー率の高い上位語情報が有効に活用されていることを表すものである．
まずはじめに，辞書から単語の上位語情報を取り出すことを考える．
ここで言う上位語情報とは，上位語と相関のある数値情報のことであり，上位語を一意に決定するものではない．
一般に定義文中に同じ単語が複数回現れることは稀なので，そのままでは単語間で差を付けることはできない．
そこで，定義文を再帰的に展開し，拡張した定義文の中での出現頻度の差を利用することにする．
この再帰的展開は適当な回数の展開を設定しても良いが，本稿は上位語抽出方法として鈴木による再帰的語義展開手法[CITE]を利用することにする．
この手法によれば，定義文を無限に再帰的に展開することにより巨大な仮想定義文を生成し，そこから頻度情報を取り出すことができる．
辞書の定義文が見出語に意味を与えるためのものであるとすれば，上位語は単語に意味付けするために非常に重要な要素である．
従って，この仮想定義文中には上位語が高い頻度で出現することを期待できる．
再帰的語義展開の基本的な考えは，定義文中の単語頻度を再帰的に展開し，より多くの単語からなる定義文を作成するということである．
辞書（国語辞典）は見出語と定義文の組合せから成り立っている．
定義文は単語の集合であり，これを見出語の集合とみなせば，一つの定義文を複数の定義文の集合として再定義することができる．
ところが，このような展開は無限に続いてしまう．
従って，展開された定義文中の単語数も無限になり，頻度計算は一般に不可能になる．
しかしながら，定義文の展開を行なう毎に一定の割合でその影響が小さくなるとすれば，無限に展開された定義文の影響は元の定義文に比べて微小になる．
このとき，定義文の影響力は語義展開の回数に従う等比数列として表すことができる．
同時に，様々な深さまで展開した定義文の集合体を考え，その総和を無限級数として計算すると必ず有限な値となる．
これにより，定義文の集合体中の単語頻度も有限になり，計算可能となる．
これらを確率モデルに置き換えることで，無限の展開を含めた定義文の集合体から単語の出現確率を取り出すことが可能になり，拡張された定義文として再定義することができる．
計算の概要を以下にまとめる．
以下，[MATH]回展開された定義文を[MATH]次の定義文と呼ぶ．
また，辞書中の定義文を0次定義文とする．
まず，見出語[MATH]と0次定義文中の単語[MATH]の関係は[MATH]と表すものとする．
ここで，[MATH]は[MATH]次の定義文中の単語[MATH]を表す．
従って，確率[MATH]は，見出語[MATH]の0次定義文中に現れる[MATH]の出現確率である．
この表記を用いると，各見出語に関する0次定義文中の単語の出現確率は
の列ベクトルとして表される．
ここで，[MATH]は辞書中の見出語の数である．
行列[MATH]の各要素[MATH]は見出語[MATH]の定義文中の単語頻度[MATH]を用いて
と書ける．
このとき，全ての列ベクトルは，要素の合計が[MATH]であり，確率表現となっている．
さらに，この表記に従うと，[MATH]次定義文は[MATH]により表される．
目的とする定義文の集合体[MATH]は，語義展開の度に定義文の影響が一定の割合[MATH]で減少すると仮定すると，
と書ける．
ここで，係数[MATH]は正規化のための定数である．
式([REF_eq:Ca])は無限級数の計算から
と書け，線型計算により解を求めることができる．
計算により得られる行列[MATH]は，列ベクトルの各要素の合計が必ず1となり，確率として扱うことが出来る．
[MATH]の[MATH]要素を[MATH]と書くと，[MATH]は定義文の集合体の中の単語を意味することになる．
以下，この定義文の集合体を拡張定義文と呼ぶことにする．
すなわち，[MATH]は拡張定義文中の単語の確率頻度である．
上記の手法を実際に国語辞典[CITE]に適用した結果を以下に示す．
前処理として，扱う単語を一般名詞とサ変名詞に限定（形態素解析は茶筌[CITE]を利用）し，語義の区別はせず，語義文と例文をまとめて見出語の定義文とした．
その結果，43,915語の見出語と，平均約7語の0次定義文を得た．
以下，[MATH]で行った実験結果を例に詳細を記す．
まず，式([REF_eq:matrix])([REF_eq:frequency])から確率行列[MATH]を計算した．
これはスパースな43,915次元の正方行列である．
次に式([REF_eq:target])から線形ライブラリ[MATH][CITE]を利用して[MATH]を求めた．
このときの計算精度は32 bit長の浮動小数点演算で，有効桁は[MATH]までとした．
この結果得られた列ベクトルの非ゼロの値を持つ次元数は平均約33,000であった．
すなわち，平均約33,000語の仮想定義文ができたことになる．
表[REF_tab:expand]に0次定義文と拡張定義文との比較を示す．
まず，見出語「通信」に関しては，0次定義文では「通信」が頻度4，他の13語が等しく頻度1で，「通信」のみが突出して頻度が高い．
一方，拡張定義文では全ての単語の確率頻度が異なっており，順位づけすることができる．
また，頻度1位の「通信」と2位の「人」との差は相対的に小さくなっている．
さらに，0次定義文に現れていなかった「物事」「一つ」が拡張定義文では上位の頻度で現れている．
定義文中の語数は，0次定義文では14語だったものが，拡張定義文では32,182語に大幅に増えている．
同様に，見出語「傍受」に関しては，0次定義文では5単語が等しく頻度1で現れているのに対し，拡張定義文では順位が付けられ，中でも「通信」が相対的に大きな頻度を示している．
また，見出語「通信」の場合と同様に「人」「物事」「自分」「行動」といった一般的な単語が現れているほか，「電線」「有線」「発信」といった見出語と関連の深い特徴的な単語が現れている．
本手法を用いると，辞書全体でよく使われる単語，即ち一般的な単語が上位に現れやすくなる．
この性質により，等しい頻度の単語でも，より一般的な語が拡張定義文中の上位に現れる傾向があり，場合によっては0次定義文に現れない単語が確率頻度最大となることもある．
見出語[MATH]の拡張定義文中に上位語[MATH]があるとすれば，上位語[MATH]は見出語[MATH]を説明するために非常に重要な単語であるため，その確率頻度[MATH]は高いことが予想される．
従って，見出語[MATH]の上位語は，その拡張定義文の中から確率頻度[MATH]が高い順に尤もらしいと考えることができる．
この仮説を検証するために，日本語語彙大系[CITE]を正解データとした検証実験を行った．
対象としたのは，前節で用いた43,915語のうち，日本語語彙大系と表記が一致する39,982語である．
[REF_sec:intro]節で記したように，日本語語彙大系は意味的上下関係を表した約3,000のカテゴリーからなるオントロジーと各カテゴリーに割当てられた合計約40万語からなる大規模語彙データである．
ただし，単語の割当てに関しては翻訳への適用を主な目的として作成されているため，オントロジーとしては必ずしも正しいとは限らない．
そこで，本論文では，まずはじめに日本語語彙大系をオントロジー検証のための正解データとして適切に利用する方法を検討し，その後，提案手法に対する評価を行うことにする．
まず，日本語語彙大系のオントロジーとしての性質を調べるため，既存手法による上位語抽出結果と，その結果を人手により修正した正解データを利用した．
この既存手法は，Nicholsらにより提案された，辞書定義文の構文解析により得られた主辞を上位語とみなす手法である[CITE]．
ただし，ここで用いた辞書(Lexeed [CITE])は前節の実験で用いた辞書（学研国語辞典[CITE]）とは異なる．
これらのデータを利用して，日本語語彙大系の意味カテゴリー間の関係を上位語の評価指標としての妥当性という観点から評価した．
評価方法は，次に示す3種類をそれぞれ上位語の正解データとして精度を計算するものである．
見出語の含まれる意味カテゴリーの直接上位カテゴリー中の全単語
直接上位カテゴリーを除く全ての上位カテゴリー（間接上位カテゴリー）中の全単語
見出語と同一カテゴリーに属する全単語
評価結果を表[REF_tab:head]に示す．
人手修正データの評価結果を見ると，直接上位カテゴリーよりもむしろ同一カテゴリーの単語に上位語が多く含まれていることがわかる．
人手修正による精度の向上も同一カテゴリーの方が大きく，上位語の多くはここに集まっていると考えられる．
逆に，間接上位カテゴリーでは，人手修正による精度向上率は[MATH]であり，精度を大きく下げている．
この結果は，間接上位カテゴリーは上位語以外の単語を多く含んでおり，間違った結果を正解と判断している率が非常に高いことを示している．
{言い替えると，間接上位カテゴリーは再現率が非常に低く，一方，直接上位カテゴリーと同一カテゴリーには従来手法のような構文解析手法では取り出しにくい上位語が集まる傾向があるといえる．
ここで，人手修正データに強いバイアスが掛っている（脚注参照）点を考慮すると，実際に修正を加えられた人手修正データの方がより信頼性の高いデータであることに気附く．
従って，精度の絶対値ではなく，向上率を重視したほうが信頼性が高いと考えられる．
よって，本論文においては，日本語語彙大系を上位語の評価として使う場合には，同一カテゴリーあるいは直接上位カテゴリーを正解とみなして評価を行うことにする．
特に同一カテゴリーによる評価を重視する方向で検討をすすめることとする．
}
この結果を考慮して，提案手法による上位語情報の抽出結果を日本語語彙大系の直接上位カテゴリーおよび同一カテゴリーを正解データとして評価した．
その結果を図[REF_fig:hyper-above], [REF_fig:hyper-same]に示す．
図[REF_fig:hyper-above]は直接上位カテゴリーを正解とした場合，図[REF_fig:hyper-same]は同一カテゴリーを正解とした場合である．
それぞれの図には，横軸に拡張定義文中の確率頻度を降順に並べた順位を，縦軸に正解データに対する精度をとり，全ての見出語に関する統計量でプロットしている．
黒丸は前述の人手修正による正解データを，白丸は同じく前述の既存手法による結果である．
太い実線は再帰的展開を行わない場合，即ち[MATH]の結果である．
ここでは同一頻度のものは任意に順位を割当てた．
破線，細い実線，鎖線はそれぞれ[MATH]の場合の結果を示している．
図[REF_fig:hyper-above]の順位1位を比較すると，既存手法の精度[MATH]に対して[MATH]では[MATH]であり，提案手法の精度が上回っている．
また，[MATH]でもそれぞれ[MATH]であり，ほぼ同等の結果を得ている．
ただし，人手修正による正解データの精度[MATH]には及んでいない．
一方，図[REF_fig:hyper-same]の順位1位での比較では，既存手法の精度[MATH]に対して[MATH]のそれぞれで[MATH]と大きく上回る結果を出している．
さらに，[MATH]は人手修正による正解データの精度[MATH]をも僅かに上回っている．
また，再帰的展開前の結果([MATH])と展開後の結果([MATH])とを比較してみると，展開後の結果は，展開前に比べて順位1位の精度が上り，順位2,3位以下では精度が下っている．
これは，再帰的展開により，低い順位にあった上位語が高い順位に移動したことを示しており，再帰的展開の効果を明確に表す結果である．
以上の結果から，提案手法は既存手法と同等以上の精度を持ち，評価方法によっては手作業にも劣らない精度を出せることが示された．
さらに，上位語候補として1語あるいは数語しか提示できない既存手法に比べて，提案手法では順位2位以下の情報を多量に持っているため，アプリケーションへの応用の際にこれらの情報が有効に働くことを期待できる．
[REF_sec:hyperinfo]節で得られた上位語情報を利用して，単語オントロジーの自動生成を試みた．
以下は，今回検証したモデルである．
まず，目的とするオントロジーは上位語が下位語を意味的に包含するものである．
従って，下位語は上位語の意味を要素として含まなければならない．
逆に，下位語は上位語以外の単語の意味を要素として含んではいけないことになる．
いま，あるオントロジーが存在し，その中の単語[MATH]の上位語が[MATH]である場合を考える（図[REF_fig:ont-model](a)参照）．
このとき，[MATH]の持つ意味は[MATH]及び[MATH]自身により特徴づけられると考える．
ところが，[MATH]は拡張定義文において様々な単語から成り立っている．
そこで，単語の意味空間の集合としての見出語の意味空間を考える（図[REF_fig:ont-model](b)参照）．
拡張定義文中の各単語は見出語を構成する要素（部分空間）であると考え，見出語自身とその上位語のみが，その見出語を特徴づける意味要素として有効であると仮定する．
即ち，
オントロジー上に単語[MATH]の上位語として単語[MATH]のみが存在する場合，このオントロジーにおける[MATH]の意味は拡張定義文中の[MATH]で構成される部分空間に限定され，拡張定義文中の他の単語は無視される．
そして，これらの単語の確率頻度の合計が大きいほど，見出語の本来の意味が再現される
と考える．
この再現率がオントロジー全体で高いほど，良いオントロジーとなる．
これにオントロジー上の距離の要素を加味し，単語の確率頻度（[REF_sec:method]節参照）を用いて，上位語を[MATH]としたときの再現率を
と書くことにする．
ただし，[MATH]は単語[MATH]の木構造の頂点からのトポロジカルな距離に従う定数([MATH])である．
以下，この[MATH]を意味再現率と呼ぶ．
この仮定の下で，あるオントロジー[MATH]が存在している場合，[MATH]が存在する確からしさは全単語の意味再現率の積，即ち，
で表すことができる．
つまり，全ての単語がより良く元の意味を再現できている状態がオントロジーの存在が最も安定している状態であると考える．
計算を簡単にするため，式([REF_eq:prob_t])の対数をとれば，
となる．
この[MATH]を最大化することにより，前述の仮定の下での最適な単語オントロジーが取り出せる．
本論文では，計算コストを抑えるため，最適化アルゴリズムを各単語の意味再現率最大化と，その組合せとしての全体の最適化の2段階に分離して行った．
即ち，
[MATH]の最大化
[MATH]の最大化
を交互に行うことで，近似的に最適化を行った．
オントロジー上の距離に関するパラメータ[MATH]は，上位語の木構造の最上位からの階層の深さを[MATH]としたとき，[MATH]の4種類とした．
学習の前提として，オントロジー上での各単語の直接上位語は1語に限定し，自身を上位語とすることを許可している．
自身が上位語となる場合は，当該単語は木構造の最上位に位置するものと考える．
これらの前提の下，学習の初期状態は全ての単語が自身を上位語とする状態にあるものとし，学習を行った．
具体的な学習手順は，次の通りである．
見出語を1つ選ぶ．
上位語候補を[MATH]個選ぶ．
各上位語候補に対して[MATH]を計算し，最大となる上位語を決定する．
上記に対し[MATH]を計算し，値が増加すれば上位語を置換，それ以外なら元に戻す．
を全見出語に関し変化がなくなるまで繰り返す．
ただし，[MATH]は事前に与えられる定数であり，今回の実験では[MATH]とした．
以下，[MATH]の場合を例に，結果の詳細を記す．
学習の結果得られたオントロジーの一部を図[REF_fig:tree-word]に示す．
「通信」の全上位語および全下位語の構造を表示している．
(a)はオントロジー上の距離に関するパラメータ[MATH]を用いて学習した結果である．
同様に(b), (c), (d)はそれぞれ[MATH]のときの結果である．
この値が大きくなる程，上位語の影響は階層の離れた下位語まで届くため，深い木構造が期待できる．
逆にこの値が小さいと，浅い木構造ができることが期待される．
今回の実験では，独立した木構造の数は，(a) 1687，(b) 1472，(c) 788，(d) 142であった．
(a), (b), (c)では「通信」は木構造の最上位に位置しているが，(d)では「人」を頂点とする巨大な木構造の一部であり，多くの上位語の下に位置している．
これらの結果から，パラメータ[MATH]の値が増加するに従い木構造の階層がより深く大きくなるのが確認できる．
また，図[REF_fig:tree-word]を詳細にみると，上下関係が特定の意味関係で統一されているとは言い難いものの，関連のある言葉が集まり木構造を構築していることは確認できる．
次に，生成されたオントロジーの精度を，[REF_subsec:eval-hyper]節同様，日本語語彙大系のカテゴリー間の上下関係との一致度を測ることにより調べた．
評価方法は[REF_subsec:eval-hyper]節の結果を考慮して，2種類の正解データを設定した．
一つは，見出語の含まれる意味カテゴリーの直接上位カテゴリーを正解とするもの，もう一つは，見出語の含まれる意味カテゴリーと同一カテゴリーを正解とするものである．
これら正解カテゴリー内の単語のいずれかに，生成したオントロジーから得られる上位語が一致すれば正解とみなした．
この手法による評価を，オントロジー上での上位語の距離に対する精度としてプロットしたのが図[REF_fig:eval-direct]および図[REF_fig:eval-all]である．
横軸は上位語のトポロジカルな距離で，直接上位語であれば``1''，さらにその上位語であれば``2''というように，オントロジー上の距離を表している．
縦軸は精度である．
図の各線は，学習時のパラメータ[MATH]のそれぞれの結果をプロットしたものである．
また，白丸はオントロジー生成学習前（拡張定義文中の出現頻度最大の単語を正解とみなした場合）の精度を，黒丸は人手で修正したデータの精度（表[REF_tab:head]参照）を表している．
全体的に，学習時のパラメータ[MATH]が小さいほど距離1での精度が高く，また，距離が大きくなるに従い急激に精度を落している．
[MATH]が小さいと，生成された木構造の階層が浅いため大きな距離の上位語は非常に少くなり，逆に，[MATH]が大きいと，木構造の階層が深くなり，多くの上位語を同時に学習するため直接上位語の精度が犠牲になると考えられる．
ただし，この差は僅かであり，距離2以上では逆転するものもあるので，[MATH]を如何に設定すべきかは更なる検討が必要である．
さらに，これらの結果を学習の前後で比較してみる．
図[REF_fig:eval-direct]の距離が1（直接上位語）の場合を見ると，オントロジー生成学習前（図では白丸）よりも後の方が大きく精度を下げている．
人手修正データの場合（図では黒丸）と比べると，半分程度の精度である．
ここで人手修正データの性質を考える．
このデータはオントロジーを意識して作成されたものではないので，上位語にさらにその上位語を積上げる手法をとっても木構造にはならず，ループ状につながってしまう．
従って，木構造にするには，いくつかの上位語を変える必要があり，多少の精度低下が起る．
この点を考慮すると，学習前後で精度が低下することは妥当であると思われる．
一方，図[REF_fig:eval-all]では距離が1の各値はオントロジー生成学習前（図の白丸）および人手修正データ（図の黒丸）と比べて大きく精度を上げている．
[REF_subsec:eval-hyper]節の結果を考慮すれば同一カテゴリーによる評価がより重要であるとも考えられるが，同義語など他の要素が影響している可能性も考えられる．
この点に関しても更なる検討が必要である．
以上の結果は，[MATH]の場合でも同様の傾向がみられる．
上述のように，オントロジーとしての十分な評価を下すためには更に検証を加える必要があるが，上記の実験結果は計算により得られた上位語情報を学習によって木構造に組み上げる方法論の妥当性を示唆している．
また，再帰的展開の影響が小さい[MATH]での結果が学習前から大きく改善したことは，辞書から得たカバー率の高い上位語情報が有効に活用されていることを表すものである．
