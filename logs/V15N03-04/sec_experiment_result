HTML文書から評価文を収集する手続きは次のようになる．
手がかり句のリストを作成する．
HTML文書をタグとテキストに分割する．
一部の箇条書きと見出しはHTMLタグを使わないで記述されているので，ルールでタグを補完する．
手がかり句のリストを利用して「定型文」「箇条書き」「表」から評価文を抽出する．
以下では，まず実験で用いた手がかり句について説明する．
そして「定型文」「箇条書き」「表」から評価文を抽出する方法を順に説明する．
実験で用いた手がかり句の一覧を表[REF_tab:cue]に示す．
これらは予備実験を通して人手で選定した．
表中の動詞，形容詞，形容動詞（「良い」など）は「所」「点」「面」という3つの名詞と組み合わせて使う．
例えば「良い」は「良い所」「良い点」「良い面」の3つを手がかり句として使うことを意味する．
「長所」や「メリット」のような名詞は，単語そのものを手がかり句として使う．
なお，詳細は省略しているが「駄目な所」と「ダメな所」または「良い所」と「良いところ」のような表記揺れも網羅的に人手で記述している．
定型文から評価文を抽出するために，3種類の語彙統語パターンを人手で作成した．
各パターンとそれにマッチする定型文の具体例を表[REF_tab:pattern]に示す．
最初のパターン（表[REF_tab:pattern]上）は，主部が手がかり句（良いところ）で述部が評価文であるような定型文にマッチする．
パターン中の矢印は文節間の依存関係，手がかり句は手がかり句をそれぞれ表している．
また\ovalbox{評価文}は，この部分にマッチしたテキストが評価文として抽出されることを意味する．
表の右側に評価文が抽出される様子を示す．
残り2つのパターンも同様である．
それぞれ，主部が評価文で述部が手がかり句である定型文にマッチするパターン（表[REF_tab:pattern]中）と，評価文と手がかり句が同格になっている定型文にマッチするパターン（表[REF_tab:pattern]下）である．
箇条書きからの評価文抽出は，手がかり句リストとHTMLタグを利用すれば容易に実現できる．
すなわち，手がかり句が見出しになっている箇条書きを見つけて，その箇条書きの項目を順に取り出していけばよい．
例えば，前節の図[REF_fig:itemize]からは「変に加工しない素直な音を出す」「曲の検索が簡単にでる」が好評文として，「リモコンに液晶表示がない」「ボディに傷や指紋がつきやすい」が不評文として取り出される．
ここで問題となるのは，1つの項目に複数文が記述されている場合の処理である（図[REF_fig:itemize2]の3番目の項目）．
このような場合は1項目に好評文と不評文が混在している可能性がある．
各文の評価極性を自動判定することは難しいので，1つの項目に複数文が存在した場合，その項目は抽出に使わないことにした．
例えば図[REF_fig:itemize2]からは「発色がものすごくよい．
」と「撮っていくうちに楽しくなる．
」「カメラ背面の液晶画面が大きく，見やすい．
」が好評文として抽出される．
最後に，表から評価文を抽出する方法を述べる．
基本的には手がかり表現と[MATH]table[MATH]タグを利用すればよいのだが，HTML文書には多種多様な表が出現するので，あらゆる表に対応した抽出規則を作成することは難しい．
そこで2種類の表だけを考えることにした（図[REF_fig:table_pattern]）．
図中の[MATH]と[MATH]は好評手がかり句と不評手がかり句を表し，＋と−は好評文と不評文を表す．
タイプAは，1列目に手がかり句があって，その横に評価文があるタイプである．
前節で紹介した図[REF_fig:table]はこのタイプに相当する．
タイプBは，1行目に手がかり句があって，その下に評価文があるタイプである．
与えられた表のタイプは，1列目（1行目）を調べて，好評手がかり句と不評手がかり句の両方が出現していればタイプA（タイプB）であると判定する．
表のタイプが決まれば，あとは図の＋と−に対応するマスから評価文を抽出すればよい．
ただし，1つのマスに複数文が記述されている場合は抽出対象としない．
これは箇条書きの1項目に複数文が記述されている場合と同様の理由からである．
約10億件のHTML文書集合を用いて評価文の収集実験を行った結果，約65万の評価文を獲得することができた．
ただし，使用したHTML文書にはミラーサイトなどの重複文書も含まれているため，同一の評価文が複数回抽出された場合は集計に入れていないようにした．
表[REF_tab:result]に収集された評価文数の詳細を示す．
定型文は，3種類の語彙統語パターン（表[REF_tab:pattern]）から抽出された評価文数を分けて示している．
定型文1，2，3というのは，それぞれ表[REF_tab:pattern]の上，中，下に記述されたパターンに相当する．
表[REF_tab:example]に自動収集された評価文の一例を示す．
収集された評価文コーパスから250文（各抽出法ごとに50文ずつ）を無作為に取り出し，妥当な評価文が集められているかどうかを2人の評価者が人手で調査した．
評価者には収集された文のみを提示して，それを好評，不評，曖昧の3つに分類するように指示した．
曖昧というカテゴリは，好評文か不評文かを決めるのが困難な場合に使用するものとした．
評価の結果を表[REF_tab:acc1]に示す．
抽出に利用した記述形式によって精度にややばらつきが見られるものの，おおよそ80%から90%の収集精度で評価文が収集できたことが分かる．
ただし，評価者が曖昧と判断した文は不正解としている．
さらに表[REF_tab:acc2]に，評価者が曖昧と判断した文を除いた場合の精度を示す．
表[REF_tab:acc1]の結果と比べて，精度は大きく向上している．
この結果から，表[REF_tab:acc1]で不正解に数えられている事例は，ほとんどが人間でも判断に迷う（=評価者が「曖昧」に分類していた）ケースであったことが分かる．
曖昧に分類された文の典型例は文脈情報が欠如している文であった．
これについては次節で詳しく議論する．
なお，調査で用いた250文のうち，2人の評価者の分類結果が一致したものは208文であった（Kappa値は0.748）．
次に，自動構築した評価文コーパスをトレーニングデータに使って評価文分類器を構築し，その分類精度を調べた（表[REF_tab:classify]）．
テストデータは，レストラン，コンピュータ，自動車の3ドメインのレビューサイトから収集したものを用いた．
分類器はナイーブベイズ，素性は形容詞の原形を用いた．
「良くない」などの言い回しに対応するため，形容詞と同一文節内に「ない」「ぬ」がある場合には，形容詞の原形に否定を示すタグを付与したものを素性に使った．
また，自動収集した好評文と不評文の数に偏りがあったため，クラスの事前分布は好評，不評ともに0.5に設定した．
比較のため，上記3種類のレビューデータを，それぞれトレーニング／テストデータとして使ったときの分類精度も調査した（表[REF_tab:classify2]）．
ただし，トレーニングとテストで同一データを用いた場合には，10分割の交差検定を行った．
この表から，トレーニングとテストに同一データを使った場合は，本コーパスを用いた場合と同等の精度であることが分かる．
その一方で，異なるデータを用いた場合には精度が大きく低下していることが確認できる．
この実験結果から，レビューデータよりも本コーパスの方がドメインの変化に頑健であると言うことができる．
これは，大量のHTML文書から評価文を収集しているため，幅広いドメインの表現を網羅しているからであると考えられる．
