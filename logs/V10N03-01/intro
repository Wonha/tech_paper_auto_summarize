はじめに
\label{sec:intro}

語義曖昧性解消(Word Sense Disambiguation，以下WSD)は
機械翻訳，情報検索など，
自然言語処理の多くの場面で必要となる基礎技術である\cite{ide:98:a}．
SENSEVALはWSDのコンテストであり，
WSDの共通の評価データを作成し，
その上で様々なシステム・手法を比較することによって
WSDの研究・技術を向上させることを目的としている．
SENSEVALは過去2回行われている．
第1回のSENSEVAL~\cite{kilgarriff:00:a}は1998年夏に，
第2回のSENSEVAL-2~\cite{senseval2:00:a}は2001年春に行われた．
SENSEVAL-2では，9言語を対象に37研究グループが参加した．
日本語を対象としたタスクとしては，
辞書タスクと翻訳タスクの2つが行われた．
辞書タスクでは語の意味の区別(曖昧性)を国語辞典によって定義し，
翻訳タスクではこれを訳語選択によって定義した．
本論文は，SENSEVAL-2の日本語辞書タスクについて，
タスクの概要，データ，コンテストの結果について報告する．

まず，日本語辞書タスクの概要について述べる．
SENSEVAL-2 では，
タスクをlexical sample taskとall words taskに
大別している．
lexical sample taskは特定(数十〜数百)の単語だけをWSDの対象とし，
all words taskでは評価テキスト中のすべての単語を対象とする．
日本語辞書タスクはlexical sample taskである．
以下，本論文では，評価の対象として選ばれた単語を評価単語と呼び，
評価単語の評価データ中での実際の出現を評価インスタンス，
または単にインスタンスと呼ぶ．
辞書タスクでは，
単語の語義を岩波国語辞典~\cite{nisio:94:a} の
語義立てによって定義した．
参加者は，テキスト中の評価インスタンスに対して，
該当する語義を岩波国語辞典の語釈の中から選択し，
その語釈に対応したID(以下，語義ID)を提出する．
評価テキストは毎日新聞の1994年の新聞記事を用いた．
語義を決定する評価単語の数は100と設定した．
また，評価単語のそれぞれについて100インスタンスずつ
語義を決めるとした．
すなわち，評価インスタンスの総数は10,000である．
本タスクには3団体，7システムが参加した．

本論文の構成は以下の通りである．
\ref{sec:data} 節では，辞書タスクで用いたデータの概要を述べる．
\ref{sec:gold standard} 節では，正解データの作成手順について述べる．
また，正解データを作成する際，
1つの評価インスタンスに対して二人の作業者が
独立に正しい語義を選択したが，
そのときの語義の一致率などについても報告する．
\ref{sec:contest} 節では，
参加者のシステムの概要やスコアなどについて述べ，
コンテストの結果に関する簡単な考察を行う．
最後に\ref{sec:conclusion} 節では，本論文のまとめを行う．


