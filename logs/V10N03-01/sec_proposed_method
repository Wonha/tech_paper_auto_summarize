本節では，辞書タスクで用いられた3つのデータ，岩波国語辞典，訓練データ，評価データについて述べる．
[REF_sec:intro]節で述べたように，辞書タスクでは，岩波国語辞典によって語義を定義する．
岩波国語辞典の見出しの数は60,321，語義の総数は85,870であり，一見出し当たりの平均語義数は1.42である．
岩波国語辞典の語釈文の例を図[REF_fig:dic-MURI]に示す．
また，岩波国語辞典では，語義は階層構造を持つ．
例えば，図[REF_fig:dic-MURI]では，「理を欠くこと」という語義が\MARU{ア},\MARU{イ}の語義の上位にある．
階層構造の最大の深さは3である．
辞書タスクでは，語義の定義として，形態素解析された岩波国語辞典の語釈文と，それに対応する語義IDが参加者に配布された．
なお，語釈文の形態素解析結果は人手修正されている．
[btp]
\Ovalbox{
}
訓練データは，毎日新聞の1994年の3,000記事を解析したコーパスである．
このコーパスに付与されている情報を以下にまとめる．
形態素情報(分かち書き，品詞，読み，基本形)
コーパスに含まれる形態素数は880,000である．
これらは人手修正されている．
UDCコード
各記事には，テキストの分類カテゴリを表わす指標として，国際十進分類法(Universal Decimal Classification, UDC)によるコード番号[CITE]が人手によって付与されている．
語義情報
各単語には，その単語の意味に該当する語義IDが付与されている．
但し，語義IDはコーパスの全ての単語ではなく，以下の条件を満たす単語のみに付与されている．
名詞，動詞，形容詞のいずれかである
岩波国語辞典に見出しがある
多義である
語義が付与されている形態素の総数は148,558である．
語義IDは全て人手によって付与された．
また，1つの単語に語義IDを付与した人は1人である．
複数の人が同じ単語に語義IDを付与し，それらを照合するといった作業は行われていない．
評価データは，評価インスタンスとその正解となる語義IDを含むテキストである．
評価テキストとして毎日新聞の1994年の記事を用いた．
これらは訓練データの記事とは異なる．
評価データに付与されている情報は以下の通りである．
形態素情報(分かち書き，品詞)
これらは自動解析されたものである．
訓練データとは異なり，人手による修正はされていない．
したがって，訓練データで学習したWSDシステムを評価データに適用した際，訓練データと評価データにおける分かち書きや品詞付けの違いによって誤りが生じる可能性がある．
本来は評価データの形態素情報も人手修正するべきであったが，今回は準備期間が短かったために断念した．
UDCコード
訓練データにおけるUDCコードと同じ．
語義情報(正解データ)
評価インスタンスには正解となる語義IDが付与されている．
また，訓練データとは異なり，1つのインスタンスに対して最低2人の人が語義IDを付与している(詳細は[REF_sec:gold standard]節を参照)．
もちろん，この情報はコンテストの際には参加者に配布されない．
本節で述べた岩波国語辞典，訓練データ，評価データの付加情報のほとんどは，RWCPによって作成され，1997年から既に公開されているデータである．
訓練データの語義情報については[CITE]，それ以外の情報については[CITE]を参照していただきたい．
これに対し，評価データの語義情報，すなわち正解となる語義IDのデータは，今回のコンテストのために新たに作成した．
[REF_sec:gold standard]節では，正解データの作成過程ならびにその概要について述べる．
正解データの作成は以下のように行った．
まず評価単語を100語選定した．
次に，各評価単語毎に100，合計10,000の評価インスタンスを選定した．
さらに，各評価インスタンスに対し，のべ二人の作業者が語義IDを付与した．
本節では，正解データ作成の過程，ならびに二者の語義IDの一致度などについて報告する．
評価単語を選定する際には，以下の点を考慮した．
評価単語の品詞は名詞または動詞とした．
訓練データにおける出現頻度が50以上の単語を評価単語とした．
訓練データにおける語義の頻度分布のエントロピー[MATH]を考慮した．
[MATH]の定義を式([REF_eq:dic-entropy])に示す．
式([REF_eq:dic-entropy])において，[MATH]は単語[MATH]の語義が[MATH]となる確率を表わす．
[MATH]の値が大きい単語は，語義の頻度分布が一様であり，語義を決定することが比較的難しい単語であると考えられる．
一方，[MATH]の値が小さい単語は，1つの語義が集中して現われる傾向が強く，語義の決定も比較的易しいと考えられる．
評価単語の選定の際には，[MATH]をWSDの難易度の目安とした．
具体的には，以下の3つの難易度クラスを設定し，それぞれのクラスから評価単語をまんべんなく選ぶようにした．
高難易度の単語クラス\clA([MATH])
中難易度の単語クラス\clB([MATH])
低難易度の単語クラス\clC([MATH])
品詞別，難易度クラス別の評価単語数の内訳を表[REF_tab:target words]に示す．
また，評価単語の一覧を付録[REF_sec:target word list]に示す．
表[REF_tab:target words]において，「語義数」は評価単語の岩波国語辞典における語義の数の平均を，「[MATH]」は評価単語毎に求めた訓練データにおけるエントロピーの平均を表わす．
[tbp] {
}
次に，評価テキストである1994年の毎日新聞の記事中から評価インスタンスを選択した．
これらの記事には，RWCPによって，形態素情報とUDCコードが付加情報として与えられている．
各評価単語毎に，日付の古い記事から順に100語を選択し，それらを評価インタンスとした．
ただし，訓練データの記事やUDCコードが付与されていない記事は対象外とした．
評価単語は100語であるので，評価インタンスの総数は10,000である．
また，評価インスタンスが選ばれた記事の総数は2,130となった．
10,000語の評価インスタンスに対して，その単語の意味に該当する語義IDを人手で付与した．
語義IDを付与した作業者は6名で，言語学や辞書編纂の知識をある程度持っている人達である．
また，本タスクの訓練データはRWCPが作成したコーパスを利用しているが，今回の作業者の中には訓練データへ語義IDを付与した人も含まれる．
その手順を以下にまとめる．
二人の作業者が独立に語義IDを付与する．
その際の大まかな指針は以下の通りである．
1つの語義IDを選択する．
複数の語義IDは選択しない．
どの階層の語義IDを選んでもよい．
岩波国語辞典の語釈の中に該当するものがなければ，UNASSIGNABLE(該当無し)とする．
ただし，なるべくUNASSIGNABLEとすることは避け，岩波国語辞典の語釈の中から語義IDを選択する．
二者が選んだ語義IDが一致していれば，それを正解の語義IDとする．
二者が選んだ語義IDが一致していなければ，第三者がその中から正しいと思われるものを選択する．
ただし，第三者が，二者が選んだ語義ID以外の語義IDが正しいと判断した場合には，三者が選んだ3つの語義IDの全てを正解とする．
語義IDを選択する際，どの階層の語義IDを選んでもよいとしたが，階層構造の末端以外の語義IDが選択されたインスタンスの数は94であり，階層の上の語義IDはあまり選ばれなかった．
また，二者の語義IDが一致せず，第三者も違う語義IDを選んだインスタンスの数は28であり，その全体に対する割合は0.3 %と非常に少なかった．
表[REF_tab:dic-agreeement]は，作業者二人が最初に選んだ語義IDの一致率を示したものである．
評価インスタンス全体における一致率は86.3 %であった．
名詞と動詞とで一致率を比較すると，それほど差が見られないことがわかる．
また，名詞，動詞ともに，難易度の高いクラスの単語ほど一致率が低くなるが，その傾向は名詞よりも動詞の方が強いことがわかる．
一方，表[REF_tab:kappa]は評価単語毎に計算したCohenの[MATH] [CITE]の平均を示したものである．
[MATH]とは二系列のデータがどの程度一致しているかを測るためによく用いられる統計的尺度であり，式([REF_eq:kappa])で与えられる．
式([REF_eq:p_o])と([REF_eq:p_e])において，[MATH]はインスタンスの総数を，[MATH]は作業者Aが語義[MATH]，作業者Bが語義[MATH]を与えたインスタンスの数を，[MATH]はそれぞれ作業者A,Bが語義[MATH]を与えたインスタンスの数を表わす．
[MATH]は二人の作業者が同じ語義を付与した実際の確率であり，[MATH]は二人の作業者の語義付与が独立であるときに同じ語義を付与する期待値である．
[MATH]は両者の比から計算され，その値が大きいほど，二者の語義付与が一致していることを示す．
その最大値は1である．
評価単語100語の[MATH]の平均は0.657であり，決して大きいとは言えない．
このことは，岩波国語辞典の語釈の中から正しい語義を選択する作業は人間でも難しく，付与される語義が人によって揺れやすいことを示唆している．
また，表[REF_tab:kappa]を見ると，表[REF_tab:dic-agreeement]の一致率とは異なり，名詞で難易度クラスが\clBのときの[MATH]の値が不自然に低いことがわかる．
これは，一致率と[MATH]が作業者間の語義の一致度に関して必ずしも同じ傾向を示すわけではないためと考えられる．
例えば，100個の評価インスタンスに対して，作業者Aが語義[MATH]を100回付与し，作業者Bが語義[MATH]を99，語義[MATH]を1回付与したとする．
このとき，一致率は0.99と高いのに対し，[MATH]は0となる．
直観的には，[MATH]の値はもっと大きいと考えられるが，これは統計的に信頼できる[MATH]を求めるのに十分な量のサンプルがなかったためかもしれない．
今回の作業では，1つの評価単語のインスタンスの数は100なので，[MATH]を求める際のサンプル数[MATH]も100である．
[tbp] {
}
辞書タスクには3団体7システムが参加した．
参加団体とそのシステムの特徴は以下の通りである．
いずれのシステムも訓練データを利用した教師あり学習を行っている．
通信総研(CRL)
以下の4つのシステムによって回答を提出した．
システム名とその概要は以下の通りである[CITE]．
CRL1
分類器としてサポートベクトルマシンを使用したシステム．
学習に用いる素性としては，対象語及びその周辺にある単語の表記，品詞，構文情報，意味クラスやUDCコードなどを用いている．
CRL2
分類器としてシンプルベイズを使用したシステム．
学習に用いる素性はCRL1と同じ．
CRL3
シンプルベイズとサポートベクトルマシンの混合モデル．
個々の対象単語毎に，それぞれの分類器の精度を学習データを用いたクロスバリデーションによって評価し，精度の高い分類器を選択している．
CRL4
CRL3と同じような混合モデル．
CRL1と同じ素性を用いたシンプルベイズとサポートベクトルマシン，CRL1の素性のうち構文素性を使わないシンプルベイズとサポートベクトルマシンの4つの分類器を使用している．
奈良先端科学技術大学院大学(NAIST)
以下の1つのシステムによって回答を提出した．
その概要は以下の通りである[CITE]．
NAIST
分類器としてサポートベクトルマシンを用いている．
学習に用いる素性は，対象語及びその周辺にある単語の表記や品詞の情報などである．
さらに，独立成分分析(Independent Component Analysis, ICA)や主成分分析(Principle Component Analysis, PCA)といった手法を用いて，素性空間の再構築を行っている．
また，複数の素性空間によって学習された分類器を混合している．
東京工業大学(TITECH)
以下の2つのシステムによって回答を提出した．
システム名とその概要は以下の通りである[CITE]．
TITECH1
分類器として決定リストを用いている．
学習に用いる素性は，対象語及びその周辺にある単語の表記，品詞やUDCコードである．
また，訓練データの他に，岩波国語辞典の語釈文中の例文からも決定リストの規則を学習している．
TITECH2
TITECH1とほぼ同じであるが，評価データに付与された形態素情報の誤りを自動修正することを試みている．
SENSEVAL-2では，全ての言語のタスクにおける共通の評価基準として，以下に述べる3つの評価基準がある．
辞書タスクでも，この評価基準に従ってシステムの評価を行った．
fine-grained scoring
正解の語義IDとシステムの語義IDが完全に一致していれば正解とする．
coarse-grained scoring
正解の語義IDとシステムの語義IDが，語義の階層構造の一番上の層で一致していれば正解とする．
mixed-grained scoring
正解の語義IDとシステムの語義IDが完全に一致していなくても，語義の階層構造に従って部分的にスコアを与える方式で，fine-grainedとcoarse-grainedの中間にあたる．
語義の階層構造において，正解の語義IDがシステムが出力する語義IDの親であるなら正解とみなす(図[REF_fig:mixed-grained] (a))．
逆に，システムの語義IDが正解の語義IDの親であるなら，
といった部分的なスコアを与える(図[REF_fig:mixed-grained] (b))．
参加者は，1つの評価インスタンスに対して複数の語義IDを返してもよい．
また，インスタンスの意味がその語義IDである確率をつけて返してもよい．
確率をつけずに複数の語義IDを回答した場合には，全ての語義IDの確率が等しいとして取り扱われる．
複数の語義IDが提出されたときには，各語義IDの確率に従ってスコアの重み付き平均をとる．
また，正解の語義IDが複数ある場合は，正解の語義ID毎にスコアを計算し，その和を全体のスコアとする．
本項では，コンテストの結果とそれに関する考察について述べる．
まず，システムの評価結果を図[REF_fig:res]に示す．
図[REF_fig:res]において，``Baseline''は訓練データにおける最頻出語義を選択したときのスコアを，``Agree''は2人の作業者の語義IDが一致した割合を示している．
参加システムの中で一番スコアが良かったのはCRL4である．
しかし，どのシステムもベースラインを上回り，お互いのスコアの差も3 %程度で，それほど大きな差は見られなかった．
3つの評価基準によるスコアのうち，coarse-grained scoreはBaselineも含めてほとんど差はない．
また，mixed-grainedとfine-grainedでは，システム間の差に見られる傾向はほとんど同じである．
そのため，以後の考察はfine-grained scoreについてのみ行う．
[tbp]
図[REF_fig:res-pos]は，品詞別に見た各システムのスコア(fine-grained)を示したグラフである．
ベースラインを比べると，動詞の方が名詞よりも平均エントロピーが大きい(表[REF_tab:target words])にも関わらず，約3 %ほどスコアが高い．
これは，特にエントロピーの高い評価単語が動詞にいくつかあり，それらが動詞の平均エントロピーを大きくしているためと考えられる．
参加者のシステムを比べると，名詞のスコアは比較的差が小さいが，動詞のスコアは差が大きい．
特に通信総研のシステムは動詞に対するスコアが高く，このことが全体の評価においても他のシステムよりもスコアが高い要因となっている．
この原因を明らかにするために，CRL1が正解しNAISTとTITECH2が不正解であった動詞のインスタンス(139事例)を抜き出し，どのような動詞に対してCRLのシステムが正しく語義を決めることができるのかについて調査した．
通信総研の4つのシステムの中からCRL1を選択したのは，CRL1が学習アルゴリズムとしてサポートベクトルマシンを採用したシステムであり，同じくサポートベクトルマシンを用いたNAISTと比較するためである．
また，東工大の2つのシステムの中からTITECH1を選択したのは，TITECH1の方がTITECH2に比べて若干スコアが高いためである．
[tbp]
(a) \raisebox{2mm}{
}
(b) \raisebox{2mm}{
[t]{|p{7mm}@{[MATH]}p| c@{}c@{}c|c|}\hline\multicolumn{2}{|l|}{「とう」の語義(抜粋)} & C & N & T & \multicolumn{1}{@{}c@{}|}{正解}
\hline\sensesymbol{0pt}{[一]} & \tume{【問う】((五他))} & & & &
\sensesymbol{0.75zw}{1} & \tume{わからない事、はっきりしない事を、知らせ（教え）てくれるように求める。
問題として出す。
「年齢を—わず（＝問題とせず。
それで差別しないで）出願できる」} & 14 & & &○
\sensesymbol{0.75zw}{2} & \tume{物事の原因、責任の所在、罪を犯した事実などを取り立てて、明らかにするためにただす。
「事故の原因を—」「責任を—」} & & 14 & 14 &
\sensesymbol{0pt}{[二]} & \tume{【訪う】((五他))他人の家や特定の場所を訪問する。
おとずれる。
たずねる。
「恩師を—」「名所旧跡を—」} & & & &
\hline\hline\multicolumn{6}{|p{128mm}|}{交換できる本は汚れのひどくないもので、引き取り価格は一律定価の一〇％。
分野は\head{問わ}ず漫画も可。
}
\hline
}
調査の結果，「描く」「問う」などの動詞について，CRL1は他のシステムよりも正解率が高いことがわかった．
これらの動詞の岩波国語辞典の語釈文と，各システムが出力した語義の頻度を図[REF_fig:verb c+ n- t-]に示す．
しかし，これらの例を見ただけでは，CRL1がNAISTやTITECH1に比べて動詞のスコアが高い原因はわからない．
原因のひとつとして考えられるのは，CRL1がNAISTやTITECH1と比べて，より多くの素性を用いていることである([REF_sec:participants]項参照)．
但し，この推察を裏付けるためには，各システムが個々のインスタンスに対して語義を決める際に手がかりとした素性を明らかにする必要がある．
例えば，図[REF_fig:verb c+ n- t-]に示したインスタンスに対して，CRL1がNAISTやTITECH2が考慮していない構文素性などの素性を特に手がかりとしていることが明らかになれば，それらの素性が動詞の語義曖昧性解消に有効であると結論できる．
但し，著者は，各システムが語義を決定する際に一番有力な手がかりとした素性に関する情報を持っていないため，上記の考察を具体的に検証することはできなかった．
しかし，このように複数のWSDシステムの出力を詳細に比較することは，WSDに有効な素性を明らかにし，今後のWSDシステムの精度向上につながる可能性がある．
[tbp]
図[REF_fig:res-dif]は，難易度別に見た各システムのスコア(fine-grained)を示したグラフである．
クラス\clCの単語については，ベースラインや作業者の一致率も含めて，各システムのスコアにほとんど差がない．
これは，クラス\clCの単語の語義を決定するタスクが比較的容易であったためと考えられる．
これに対し，難易度の高い\clAや\clBの単語では，システム間の相違は全体での評価(図[REF_fig:res])とほぼ同じである．
[tbp] {
}
表[REF_tab:comparing systems]は，10,000語の対象インスタンスを(a)3つの参加者の全てのシステムが正解，(b)1システムだけが正解，(c)1システムだけが不正解，(d)全てのシステムが不正解，の4つに分類し，その内訳を調べたものである．
通信総研と東工大のシステムとしては一番スコアの良いCRL4とTITECH1を選択し，比較の対象とした．
また，NAISTは複数の語義を確率付きで回答するシステムであったが，出力された複数の語義の中に正解が含まれていればそのインスタンスに対して正解したとみなすと，NAISTのシステムのパフォーマンスが過大に評価され，システムの公平な比較ができない．
そこで，確率の一番大きい語義のみを出力したとみなして他のシステムと比較することにした．
ちなみに，確率の一番大きい語義のみを出力したときのNAISTのfine-grainedスコアは0.753である．
表[REF_tab:comparing systems] (b),(c)から，参加者のシステムの回答が完全に一致していない事例の数は2,100であることがわかる．
これらの事例から，それぞれのWSDシステムの特徴を考察することができる．
例えば，表[REF_tab:comparing systems] (c)の事例は，他のシステムは正しい語義を出力したのに対し，あるシステムだけが正しい語義を出力できなかったことを表わす．
付録[REF_sec:example:only one system failure]に具体的な事例をいくつか紹介する．
これらの事例を調べれば，現在のWSDシステムがうまく語義を決定することができない要因を探ることができる．
但し，[REF_sec:results-pos]の考察で述べたように，各システムが個々のインスタンスに対して語義を決定する際に一番有力な手がかりとした素性に関する情報が必要である．
また，自然言語処理における様々なタスクにおいて，votingと呼ばれる技術に関する研究が近年盛んに行われている．
votingとは，複数のシステムの結果を混合することによりパフォーマンスを向上させる技術で，WSDに応用した研究もいくつか報告されている[CITE]．
表[REF_tab:comparing systems]から，3つのシステムのいずれかに正解が含まれるインスタンスの割合は0.865であることがわかる．
これは，3つのシステムの出力を組み合わせたときに得られるスコアの上限であり，単独のシステムよりも8 %程度精度が向上することを意味する．
したがって，日本語のWSDにおいても，votingは精度を向上させる技術として有望であろう．
[tbp] {
}
未知の語義とは，ここでは訓練データに1回も現われない語義を指す．
今回のコンテストでは，未知の語義を正解とするインスタンスの数は108であった．
未知の語義に対する各システムのスコアを表[REF_tab:unknown-word-sense]に示す．
各システムは訓練データを用いた機械学習を行っているため，未知の語義に対するスコアは全体のスコアに比べて著しく劣る．
また，参加者のシステムを比較すると，東工大のシステムのスコアが特に高いことがわかる．
東工大システムのみが正解した例を図[REF_fig:unk-ws-system]に示す．
[tbp]
[t]{|p{9mm}@{[MATH]}p| c@{}c@{}c|c|}\hline\multicolumn{2}{|l|}{「め」の語義(抜粋)} & C & N & T & \multicolumn{1}{@{}c@{}|}{正解}
\hline\sensesymbol{0pt}{[一]} & \tume{((名))} & & & &
\sensesymbol{0.75zw}{1} & \tume{生物の、物を見る働きをする器官。
また、その様子・働き。
} & & & &
\sensesymbol{1.5zw}{ア} & \tume{眼球・視神経から成る器官。
} & 32 & 49 & &
\sensesymbol{1.5zw}{イ} & \tume{目\MARU{1}\MARU{ア}の様子。
目つき。
} & & & &
\sensesymbol{1.5zw}{ウ} & \tume{見ること。
見えること。
また、視力。
更に、注意（力）。
} & 37 & 20 & &
\sensesymbol{0.75zw}{2} & \tume{目\MARU{1}\MARU{ア}に見える姿・様子。
} & & & &
\sensesymbol{0.75zw}{3} & \tume{ある物事に出会うこと。
経験。
体験。
また、局面。
} & & & &
\sensesymbol{0.75zw}{4} & \tume{形が目\MARU{1}\MARU{ア}に似ているもの。
「台風の—」} & & & &
\multicolumn{2}{|c|}{[MATH]} & & & &
\sensesymbol{0pt}{[二]} & \tume{((接尾))} & & & &
\sensesymbol{1zw}{1} & \tume{順序を表す時に添える語。
「三番—の問題」} & & & 69 &☆
\multicolumn{2}{|c|}{[MATH]} & & & &
\hline\hline\multicolumn{6}{|p{128mm}|}{２年連続１３回\head{目}の優勝を狙う早大を中心に、山梨学院大、中大が追う展開になりそうだ。
}
\hline
C=CRL4,   N=NAIST,   T=TITECH1
図[REF_fig:unk-ws-system]に示したように，[二]\MARU{1}が正解となるインスタンスに対して，TITECH1は正解と同じ語義を出力するのに対し，CRL4,NAISTは訓練データの頻出語義である[一]\MARU{1}\MARU{ア}や[一]\MARU{1}\MARU{ウ}を出力することがわかった．
東工大のシステムが訓練データにない語義を正確に返すのは，語釈文中の例文からも決定リストの規則を学習しているためである．
東工大システムの開発者に，「目」の語義を[二]\MARU{1}に決めた決定リストの規則を問い合わせたところ，式([REF_eq:decision rule for ME])の規則であることがわかった．
式([REF_eq:decision rule for ME])の規則は，訓練データの例文ではなく，語義[二]\MARU{1}の語釈文中の例文「三番—の問題」から学習されたものである．
このように，WSDシステムを構築する際に複数の知識源を利用すること---東工大システムの場合は訓練データ(語義タグ付きコーパス)と辞書の語釈文---は，WSDの精度向上に有効な手段であると考えられる．
なお，訓練データ中に[二]\MARU{1}の語義が現われなかった理由は以下の通りである．
訓練データにおいては，図[REF_fig:unk-ws-system]のような「目」の品詞は``名詞接尾''になっている．
訓練データに語義を付与する際に，接尾語は対象外としたため，これらの単語には語義が付与されていない．
ところが，評価データにおいては，RWCの品詞体系の大分類が``名詞''または``動詞''の単語を対象インスタンスとしたため，品詞が``名詞接尾''の単語も語義を決める対象となっている．
このため，学習データに含まれない，接尾語としての意味[二]\MARU{1}を正解とするインスタンスが評価データに頻出した．
このような状況は明らかにタスクの設定として不適切である．
これは主催者側の過失であり，反省点としたい．
図[REF_fig:annotator-system]は，作業者が付与した語義の一致率を横軸，参加者の7システムの平均スコアを縦軸とし，100個の評価単語の結果をプロットしたグラフである．
この図から，作業者の一致率とシステムの平均スコアには正の相関関係があることが読みとれる．
しかし，評価単語の中には，作業者の一致率が高いのにも関わらず，システムの平均スコアが低い単語がある．
具体的には「開発」「核」「精神」「乗る」「生まれる」「かかる」などである．
これらの一部の単語の語義と，参加システムが出力した語義の頻度を付録[REF_sec:example:agr+sys-]に示す．
このような単語は，人間にとっては正しい語義を選択するのは易しいが，現状のWSDシステムではうまく語義を決めることができない単語である．
したがって，特にこれらの単語について，システムが語義の選択を誤る原因を考察すれば，システムの性能を向上させることができると期待される．
[tbp]
