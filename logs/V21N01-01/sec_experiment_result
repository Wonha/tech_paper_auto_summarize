評価実験にはNAISTテキストコーパス1.4[MATH] [CITE]を用いた．
これは京都大学テキストコーパス3.0を基にしており，述語項構造，事態性名詞の項構造，共参照に関する情報が約40,000文の新聞記事にわたって付与されている．
なお，アノテーションの誤りのため6記事を除外した．
このコーパスの記事を\tblref{tbl:corpus-statics}で示すように学習・開発（パラメータチューニング）・評価のために3分割した．
これは，[CITE]や[CITE]と同じ分割方法である．
\tblref{tbl:corpus-arg-dist}に項の分布の統計情報を示す．
実験では，MeCab0.996・IPADIC-2.7.0-20070801で解析して得られた形態素情報，京都大学テキストコーパス3.0で付与されている文節情報，CaboCha0.66で解析して得られた係り受け関係を用いた．
項の候補は文節単位で抽出した．
解析は文頭から文末の順で行い，述語を含む文以降からは項候補を抽出しない．
なお，ある述語の格についての解析結果は同じ述語の他の格についての解析に影響を及ぼさない．
本稿では項同定に焦点を絞るため，述語同定タスクには取り組まない．
言い換えると，どれが述語であるかはあらかじめシステムに与えておく．
述語には軽動詞「する」や複合動詞も含む．
最尤候補同定には，トーナメントモデル[CITE]を用いた．
その際，最尤候補の探索範囲ごとに異なるモデルを作成し，モデルの学習方法も[CITE]に従った．
例えば，提案手法は探索フェーズではINTRA_D, INTRA_Z, INTERの最尤候補を同定するが，それぞれ異なる合計3つの解析モデルを最尤候補同定に用いる．
探索フェーズ・トーナメントフェーズで用いる分類器には，Support Vector Machine [CITE]を線形カーネルで用いた．
具体的にはLIBLINEAR1.93の実装を用い，開発データを用いたパラメータチューニングを行った．
素性には[CITE]で用いられたものとほぼ同一の素性を用いた．
述語・項候補の主辞・機能語・その他の語の出現形・形態素情報
述語が受け身の助動詞を含むときはその原形
係り受け木上の述語と項候補の関係
係り受け木上の項候補ノード[MATH]と述語ノード[MATH]からそれぞれROOT方向に辿っていくときに初めて交叉するノードを[MATH]とし，[MATH]から[MATH]までの道のりに含むノード列を[MATH]，[MATH]から[MATH]までの道のりに含むノード列を[MATH]とする．
また，[MATH]から木のROOTまでの道のりに含むノード列を[MATH]とする．
本実験では，ノード列の文字列表現として，
主辞の原形
主辞の品詞
機能語の原形
機能語の品詞
機能語の原形[MATH]機能語の品詞
の5通りを用いた．
[MATH]の文字列表現を[MATH]，[MATH]の文字列表現を[MATH]とし，それらの連結を[MATH]とする．
素性には，[MATH]，[MATH]，[MATH]，[MATH] [MATH]の[MATH]個の文字列を用いた．
つまり．
述語と項候補の関係を[MATH]個の文字列で表現した．
係り受け木上の2つの項候補の関係
上と同様の素性表現を行った．
述語と項候補・2つの項候補間の距離（文節単位・文単位ともに）
「述語・項候補の主辞・助詞」のコーパス中の共起スコア
動詞と項の共起のモデル化は[CITE]に従った．
名詞[MATH]が格助詞[MATH]を介して動詞[MATH]に係っているときの共起確率[MATH]を推定するため，[MATH]を[MATH]と[MATH]の共起とみなす．
共起尺度には自己相互情報量[CITE]を用いた．
なお，スムージングは行わなかった．
自己相互情報量の算出には次の2つのコーパスを用い，2つの値をそれぞれ二値素性として用いた．
[0.5\Cvs] NEWS: 1995年を除く1991年から2003年までの毎日新聞約1,800万文．
MeCab0.98で形態素解析を行いCaboCha0.60pre4で係り受け解析を行った．
辞書はNAIST Japanese Dictionary 0.6.3を用いた．
約2,700万対の[MATH]動詞,格助詞,名詞[MATH]の組を抽出した．
[0.5\Cvs] WEB: [CITE]がウェブから収集した日本語約5億文．
JUMANで形態素解析を行い，KNPで係り受け解析を行なっている．
KNPの項構造解析結果から約53億対の[MATH]述語,格助詞,項[MATH]の組を抽出した．
項候補が以前の項構造解析で項となったか否かを示す2値情報
項候補の主辞のSalient Reference List [CITE]における順位
先行研究では，我々のものと異なる素性や機械学習の手法を使っており実験設定が異なる．
そのため，ベースラインモデルとしてIIDA2005，比較対象モデルとしてIIDA2007・IIDA2007[MATH]・PPR[MATH]を実装し，位置関係ごとに最尤候補を求めてから最終的な出力を決める提案モデルPPR (Preferences based on Positional Relations)と比較する．
位置関係に関わらずに，全ての候補の中から最尤の候補を探索フェーズで1つ選出した後，トーナメントフェーズでそれが項としてふさわしいか否かを判断するモデル．
[CITE]の探索先行分類型モデルである．
全ての候補の中から1つを選ぶという点で[CITE]とほぼ同等のモデルである．
彼らのモデルと異なる主な点は，最尤候補同定と照応性判定を異なるモデルで行う点と，最尤候補同定時に2候補間の関係性も素性として用いる点である．
このベースラインモデルとその他のモデルと比較することで，項の位置関係によって探索の優先順序をつけることの効果や，位置関係ごとに最尤候補同定モデルを作り最尤候補同士の比較を陽に行う効果を調べる．
文内最尤候補を選出した後，分類器が項としてふさわしいと判断すればそれを項として出力し，そうでなければ同様に文間候補の探索を行うモデル．
\secref{iida-bact}で述べた[CITE]の文内候補を優先的に探索するモデルである．
彼らのモデルと異なる主な点は，最尤候補同定や候補の適格性判定を行う分類器にBACTではなくSVMを用いる点である．
IIDA2005と比較することで，文内候補を優先的に探索することの効果を調べる．
INTRA_Dの探索後，最尤候補が項としてふさわしいかどうかの判断（適格性判定）を行う．
適格であればそれを出力し終了する．
非適格であればINTRA_Zの探索を行い，同様に適格性判定を行う．
それも非適格であればINTERの探索を行い，適格であればそれを出力し，非適格であれば項は無いと判断する．
IIDA2005とIIDA2007の自然な拡張で，述語から統語的な距離の近いものを優先的に探索する．
IIDA2007と比較することで，文内候補を細かくINTRA_DとINTRA_Zに分けて優先順序をつけることの効果を調べる．
このモデルは，提案モデルとほぼ同じモデルであるが，INTRA_DとINTRA_Zを区別せずに，位置関係がINTRAとINTERの2グループであると仮定する．
\figref{fig:anap-tournament-model}の(b)と(c)で示すようにトーナメントフェーズは2つの2値分類モデルからなる．
分類器(c)はINTRAとINTERの候補のどちらが最尤候補であるかを判断する．
PPRと比較することで，文内の項の位置関係を細かくINTRA_DとINTRA_Zに分けて最尤候補同定モデルを作り，最尤候補同士の比較を行うことの効果を調べる．
NAISTテキストコーパスを使い，全ての項の位置関係で実験を行なっている[CITE]と[CITE]との比較も行う．
ただし，本実験とは微妙に実験設定が異なるため，厳密な比較はできないことに注意してほしい．
[CITE]の実験では19,501個の述語をテストに，49,527個を学習に，11,023個を開発に使っている．
また学習では京都大学テキストコーパス4.0で付与されている係り受け情報と形態素情報を用いていているが，テストでは独自の係り受け解析器を用いている．
[CITE]の実験では，25,500個の述語をテストに，67,145個を学習に，13,594個を開発に使っている．
我々は京都大学テキストコーパス3.0を用いたが，[CITE]は京都大学テキストコーパス4.0で付与されている係り受け情報と形態素情報を学習とテストに用いている．
[CITE]は，提案システムは表層格の解析を行うことから，受け身・使役形である述語は評価から除外しており，本稿では比較対象としない．
[CITE]は，文間項は解析対象としていないため，本稿では比較対象としない．
[CITE]は述語語義と項の意味役割の依存関係を考慮しながら，双方を同時に学習，解析を行う構造予測モデルを提案している．
しかし，本稿とは異なるデータセットを用いていることから，比較対象とはしない．
Precision, Recall, F値で位置関係ごとに評価を行う．
システムが出力した位置関係が[MATH]であるもののうち，正しく同定できているものの数を[MATH]，できていないものの数を[MATH]，システムに同定されなかった項のうち位置関係が[MATH]であるものの数を[MATH]とすると，
と定義できる．
また，システム全体(ALL)の[MATH]とPrecision, Recall, F値も，同様に定義できる．
評価実験にはNAISTテキストコーパス1.4[MATH] [CITE]を用いた．
これは京都大学テキストコーパス3.0を基にしており，述語項構造，事態性名詞の項構造，共参照に関する情報が約40,000文の新聞記事にわたって付与されている．
なお，アノテーションの誤りのため6記事を除外した．
このコーパスの記事を\tblref{tbl:corpus-statics}で示すように学習・開発（パラメータチューニング）・評価のために3分割した．
これは，[CITE]や[CITE]と同じ分割方法である．
\tblref{tbl:corpus-arg-dist}に項の分布の統計情報を示す．
実験では，MeCab0.996・IPADIC-2.7.0-20070801で解析して得られた形態素情報，京都大学テキストコーパス3.0で付与されている文節情報，CaboCha0.66で解析して得られた係り受け関係を用いた．
項の候補は文節単位で抽出した．
解析は文頭から文末の順で行い，述語を含む文以降からは項候補を抽出しない．
なお，ある述語の格についての解析結果は同じ述語の他の格についての解析に影響を及ぼさない．
本稿では項同定に焦点を絞るため，述語同定タスクには取り組まない．
言い換えると，どれが述語であるかはあらかじめシステムに与えておく．
述語には軽動詞「する」や複合動詞も含む．
最尤候補同定には，トーナメントモデル[CITE]を用いた．
その際，最尤候補の探索範囲ごとに異なるモデルを作成し，モデルの学習方法も[CITE]に従った．
例えば，提案手法は探索フェーズではINTRA_D, INTRA_Z, INTERの最尤候補を同定するが，それぞれ異なる合計3つの解析モデルを最尤候補同定に用いる．
探索フェーズ・トーナメントフェーズで用いる分類器には，Support Vector Machine [CITE]を線形カーネルで用いた．
具体的にはLIBLINEAR1.93の実装を用い，開発データを用いたパラメータチューニングを行った．
素性には[CITE]で用いられたものとほぼ同一の素性を用いた．
述語・項候補の主辞・機能語・その他の語の出現形・形態素情報
述語が受け身の助動詞を含むときはその原形
係り受け木上の述語と項候補の関係
係り受け木上の項候補ノード[MATH]と述語ノード[MATH]からそれぞれROOT方向に辿っていくときに初めて交叉するノードを[MATH]とし，[MATH]から[MATH]までの道のりに含むノード列を[MATH]，[MATH]から[MATH]までの道のりに含むノード列を[MATH]とする．
また，[MATH]から木のROOTまでの道のりに含むノード列を[MATH]とする．
本実験では，ノード列の文字列表現として，
主辞の原形
主辞の品詞
機能語の原形
機能語の品詞
機能語の原形[MATH]機能語の品詞
の5通りを用いた．
[MATH]の文字列表現を[MATH]，[MATH]の文字列表現を[MATH]とし，それらの連結を[MATH]とする．
素性には，[MATH]，[MATH]，[MATH]，[MATH] [MATH]の[MATH]個の文字列を用いた．
つまり．
述語と項候補の関係を[MATH]個の文字列で表現した．
係り受け木上の2つの項候補の関係
上と同様の素性表現を行った．
述語と項候補・2つの項候補間の距離（文節単位・文単位ともに）
「述語・項候補の主辞・助詞」のコーパス中の共起スコア
動詞と項の共起のモデル化は[CITE]に従った．
名詞[MATH]が格助詞[MATH]を介して動詞[MATH]に係っているときの共起確率[MATH]を推定するため，[MATH]を[MATH]と[MATH]の共起とみなす．
共起尺度には自己相互情報量[CITE]を用いた．
なお，スムージングは行わなかった．
自己相互情報量の算出には次の2つのコーパスを用い，2つの値をそれぞれ二値素性として用いた．
[0.5\Cvs] NEWS: 1995年を除く1991年から2003年までの毎日新聞約1,800万文．
MeCab0.98で形態素解析を行いCaboCha0.60pre4で係り受け解析を行った．
辞書はNAIST Japanese Dictionary 0.6.3を用いた．
約2,700万対の[MATH]動詞,格助詞,名詞[MATH]の組を抽出した．
[0.5\Cvs] WEB: [CITE]がウェブから収集した日本語約5億文．
JUMANで形態素解析を行い，KNPで係り受け解析を行なっている．
KNPの項構造解析結果から約53億対の[MATH]述語,格助詞,項[MATH]の組を抽出した．
項候補が以前の項構造解析で項となったか否かを示す2値情報
項候補の主辞のSalient Reference List [CITE]における順位
先行研究では，我々のものと異なる素性や機械学習の手法を使っており実験設定が異なる．
そのため，ベースラインモデルとしてIIDA2005，比較対象モデルとしてIIDA2007・IIDA2007[MATH]・PPR[MATH]を実装し，位置関係ごとに最尤候補を求めてから最終的な出力を決める提案モデルPPR (Preferences based on Positional Relations)と比較する．
位置関係に関わらずに，全ての候補の中から最尤の候補を探索フェーズで1つ選出した後，トーナメントフェーズでそれが項としてふさわしいか否かを判断するモデル．
[CITE]の探索先行分類型モデルである．
全ての候補の中から1つを選ぶという点で[CITE]とほぼ同等のモデルである．
彼らのモデルと異なる主な点は，最尤候補同定と照応性判定を異なるモデルで行う点と，最尤候補同定時に2候補間の関係性も素性として用いる点である．
このベースラインモデルとその他のモデルと比較することで，項の位置関係によって探索の優先順序をつけることの効果や，位置関係ごとに最尤候補同定モデルを作り最尤候補同士の比較を陽に行う効果を調べる．
文内最尤候補を選出した後，分類器が項としてふさわしいと判断すればそれを項として出力し，そうでなければ同様に文間候補の探索を行うモデル．
\secref{iida-bact}で述べた[CITE]の文内候補を優先的に探索するモデルである．
彼らのモデルと異なる主な点は，最尤候補同定や候補の適格性判定を行う分類器にBACTではなくSVMを用いる点である．
IIDA2005と比較することで，文内候補を優先的に探索することの効果を調べる．
INTRA_Dの探索後，最尤候補が項としてふさわしいかどうかの判断（適格性判定）を行う．
適格であればそれを出力し終了する．
非適格であればINTRA_Zの探索を行い，同様に適格性判定を行う．
それも非適格であればINTERの探索を行い，適格であればそれを出力し，非適格であれば項は無いと判断する．
IIDA2005とIIDA2007の自然な拡張で，述語から統語的な距離の近いものを優先的に探索する．
IIDA2007と比較することで，文内候補を細かくINTRA_DとINTRA_Zに分けて優先順序をつけることの効果を調べる．
このモデルは，提案モデルとほぼ同じモデルであるが，INTRA_DとINTRA_Zを区別せずに，位置関係がINTRAとINTERの2グループであると仮定する．
\figref{fig:anap-tournament-model}の(b)と(c)で示すようにトーナメントフェーズは2つの2値分類モデルからなる．
分類器(c)はINTRAとINTERの候補のどちらが最尤候補であるかを判断する．
PPRと比較することで，文内の項の位置関係を細かくINTRA_DとINTRA_Zに分けて最尤候補同定モデルを作り，最尤候補同士の比較を行うことの効果を調べる．
NAISTテキストコーパスを使い，全ての項の位置関係で実験を行なっている[CITE]と[CITE]との比較も行う．
ただし，本実験とは微妙に実験設定が異なるため，厳密な比較はできないことに注意してほしい．
[CITE]の実験では19,501個の述語をテストに，49,527個を学習に，11,023個を開発に使っている．
また学習では京都大学テキストコーパス4.0で付与されている係り受け情報と形態素情報を用いていているが，テストでは独自の係り受け解析器を用いている．
[CITE]の実験では，25,500個の述語をテストに，67,145個を学習に，13,594個を開発に使っている．
我々は京都大学テキストコーパス3.0を用いたが，[CITE]は京都大学テキストコーパス4.0で付与されている係り受け情報と形態素情報を学習とテストに用いている．
[CITE]は，提案システムは表層格の解析を行うことから，受け身・使役形である述語は評価から除外しており，本稿では比較対象としない．
[CITE]は，文間項は解析対象としていないため，本稿では比較対象としない．
[CITE]は述語語義と項の意味役割の依存関係を考慮しながら，双方を同時に学習，解析を行う構造予測モデルを提案している．
しかし，本稿とは異なるデータセットを用いていることから，比較対象とはしない．
Precision, Recall, F値で位置関係ごとに評価を行う．
システムが出力した位置関係が[MATH]であるもののうち，正しく同定できているものの数を[MATH]，できていないものの数を[MATH]，システムに同定されなかった項のうち位置関係が[MATH]であるものの数を[MATH]とすると，
と定義できる．
また，システム全体(ALL)の[MATH]とPrecision, Recall, F値も，同様に定義できる．
