================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.18849] 一般に，項は述語に近いところにあるという特性がある．
[i:1, score:0.34666] そのため，従来の述語項構造解析の研究では，候補を述語との位置関係でグループ分けし，あらかじめ求めておいたグループ間の優先順序に従って正解項を探索してきた．
[i:3, score:0.20989] そこで我々は，異なるグループごとに最尤候補を選出し，それらの中から最終的な出力を決めるモデルを提案する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:16, score:0.40529] 本稿では，それぞれINTRA_D, INTRA_Z, INTER, EXOと呼ぶ．
[i:19, score:0.61404] 例えば，\exref{exs-atype}において，「受け取った」と「食べた」のヲ格項「コロッケ」はそれぞれINTRA_D・INTRA_Z，「飲んだ」のガ格項「彼女」はINTERで，ニ格項はARG[MATH]である．
[i:33, score:0.32924] また，陽に項の位置関係ごとの比較を行わないモデルや，優先順序に則った決定的な解析モデルと提案モデルを比較して，ガ格・ヲ格ではより高い性能を達成できたことも示す．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:39, score:0.09058] 先行研究と提案手法の概要を\tblref{tbl:rwork}にまとめた．
-----------------------------------------------------
  [subsection title : 決定的な解析を行う方法]
-----------------------------------------------------
  [i:lead, score:0.16291] [CITE]は，解析をゼロ代名詞検出と先行詞同定の2段階に分け，統計的に求めた優先順序を先行詞同定の際に用いた．
.....
  [i:42, score:0.38266] そして，項が存在すると判断された場合は，あらかじめ求めておいた優先順序に従って候補を探索し，候補と格フレーム用例の類似度が閾値以上かつ分類器でも正例と分類される候補を先行詞として同定する．
  [i:76, score:0.34838] Connection into Other Case role Types (ga_c, wo_c, ni_c):項を含む文節が述語を含む文節に，他の格の項を介して係っている
  [i:95, score:0.29668] 上記の処理で生成された対応付け候補に対し，対応付けられなかったガ格・ヲ格・ニ格と，解析対象述語と係り受け関係にない談話要素の対応付けを行う．
-----------------------------------------------------
  [subsection title : 優先順序を素性として表現する方法]
-----------------------------------------------------
  [i:lead, score:0.21068] 位置関係と項へのなりやすさの関係を優先順序として利用し決定的な解析を行うのではなく，素性として利用した研究もある．
.....
  [i:103, score:0.30976] そして候補集合に，項を持たないことを示す特別な名詞句NULLを加え，その中から最尤候補を同定するというモデル化を行った．
  [i:104, score:0.27331] なお，候補数削減のため，文間項候補は述語を含む文の直前の文に出現したものと，これまでの解析ですでに項として同定されたものに限定している．
  [i:109, score:0.27522] 彼らは項同定・項候補削減・格ラベル付与を同時に行うモデルを提案した．

================================================================
[section type  : proposed_method]
[section title : 述語と項の位置関係ごとの候補比較による日本語述語項構造解析]
================================================================
[i:113, score:0.24394] この方法は，優先順位の高い位置関係にある項の同定の性能は上げることができるが，優先順位の低い位置関係にある候補の再現率は下げてしまうという問題点がある．
[i:115, score:0.30843] そこで我々は，探索とトーナメントの2つのフェーズからなる，位置関係ごとに最尤候補を求めてから最終的な出力を決めるモデルを提案する．
[i:116, score:0.17340] これは，「探索」・「分類」という2つのフェーズを持つ探索先行分類型モデル[CITE]に着想を得て，後半の分類フェーズをトーナメント式に置き換えたものである．
-----------------------------------------------------
  [subsection title : 項構造解析における探索先行トーナメントモデル]
-----------------------------------------------------
  [i:lead, score:0.64277] はじめのフェーズでは任意の項同定モデルを用いてINTRA_D, INTRA_Z, INTERの最尤候補を選出する．
.....
  [i:118, score:0.64277] はじめのフェーズでは任意の項同定モデルを用いてINTRA_D, INTRA_Z, INTERの最尤候補を選出する．
  [i:125, score:0.49617] INTRA_DとINTRA_Zを比較して，よりその述語の項らしい方を選ぶ
  [i:126, score:0.34197] INTERと(a)で選出された候補を比較して，よりその述語の項らしい方を選ぶ
-----------------------------------------------------
  [subsection title : 提案手法の関連研究]
-----------------------------------------------------
  [i:lead, score:0.03496] 提案手法は2つのモデルを参考にしている．
.....
  [i:144, score:0.70103] \State\Comment{位置関係ごとに最尤候補を取得する} \State most_likely_candidate_INTRA_D [MATH] getMostLikelyCandidate(predicate, candidates, INTRA_D) \State most_likely_candidate_INTRA_Z [MATH] getMostLikelyCandidate(predicate, candidates, INTRA_Z) \State most_likely_candidate_INTER [MATH] getMostLikelyCandidate(predicate, candidates, INTER)
  [i:145, score:0.71679] \If{gold_argument_type = NO_ARG} \State MakeExample(classifier_c, NO_ARG, predicate, most_likely_candidate_INTRA_D) \State MakeExample(classifier_c, NO_ARG, predicate, most_likely_candidate_INTRA_Z) \State MakeExample(classifier_c, NO_ARG, predicate, most_likely_candidate_INTER) \Statereturn \EndIf
  [i:148, score:0.68865] most_likely_candidate_INTRA_D) \State MakeExample(classifier_b, INTRA, predicate, gold_argument, most_likely_candidate_INTER) \ElsIf{gold_argument_type = INTER} \State MakeExample(classifier_b, INTER, predicate, gold_argument, most_likely_candidate_INTRA_D) \State MakeExample(classifier_b, INTER, predicate, gold_argument, most_likely_candidate_INTRA_Z) \EndIf\Statereturn \EndProcedure

================================================================
[section type  : experiment_result]
[section title : 評価実験]
================================================================
-----------------------------------------------------
  [subsection title : 実験データセット]
-----------------------------------------------------
  [i:lead, score:0.02714] 評価実験にはNAISTテキストコーパス1.4[MATH] [CITE]を用いた．
.....
  [i:155, score:0.23570] これは京都大学テキストコーパス3.0を基にしており，述語項構造，事態性名詞の項構造，共参照に関する情報が約40,000文の新聞記事にわたって付与されている．
  [i:157, score:0.08200] このコーパスの記事を\tblref{tbl:corpus-statics}で示すように学習・開発（パラメータチューニング）・評価のために3分割した．
  [i:159, score:0.16538] \tblref{tbl:corpus-arg-dist}に項の分布の統計情報を示す．
-----------------------------------------------------
  [subsection title : 実験設定]
-----------------------------------------------------
  [i:lead, score:0.09761] 実験では，MeCab0.996・IPADIC-2.7.0-20070801で解析して得られた形態素情報，京都大学テキストコーパス3.0で付与されている文節情報，CaboCha0.66で解析して得られた係り受け関係を用いた．
.....
  [i:162, score:0.24046] 解析は文頭から文末の順で行い，述語を含む文以降からは項候補を抽出しない．
  [i:167, score:0.22653] 最尤候補同定には，トーナメントモデル[CITE]を用いた．
  [i:169, score:0.60639] 例えば，提案手法は探索フェーズではINTRA_D, INTRA_Z, INTERの最尤候補を同定するが，それぞれ異なる合計3つの解析モデルを最尤候補同定に用いる．
-----------------------------------------------------
  [subsection title : 分類器と素性]
-----------------------------------------------------
  [i:lead, score:0.12808] 探索フェーズ・トーナメントフェーズで用いる分類器には，Support Vector Machine [CITE]を線形カーネルで用いた．
.....
  [i:175, score:0.25611] 係り受け木上の述語と項候補の関係
  [i:176, score:0.29855] 係り受け木上の項候補ノード[MATH]と述語ノード[MATH]からそれぞれROOT方向に辿っていくときに初めて交叉するノードを[MATH]とし，[MATH]から[MATH]までの道のりに含むノード列を[MATH]，[MATH]から[MATH]までの道のりに含むノード列を[MATH]とする．
  [i:204, score:0.26289] KNPの項構造解析結果から約53億対の[MATH]述語,格助詞,項[MATH]の組を抽出した．
-----------------------------------------------------
  [subsection title : 比較対象]
-----------------------------------------------------
  [i:lead, score:0.06595] 先行研究では，我々のものと異なる素性や機械学習の手法を使っており実験設定が異なる．
.....
  [i:218, score:0.53129] INTRA_Dの探索後，最尤候補が項としてふさわしいかどうかの判断（適格性判定）を行う．
  [i:223, score:0.53137] IIDA2007と比較することで，文内候補を細かくINTRA_DとINTRA_Zに分けて優先順序をつけることの効果を調べる．
  [i:227, score:0.64791] PPRと比較することで，文内の項の位置関係を細かくINTRA_DとINTRA_Zに分けて最尤候補同定モデルを作り，最尤候補同士の比較を行うことの効果を調べる．
-----------------------------------------------------
  [subsection title : 評価尺度]
-----------------------------------------------------
  [i:lead, score:0.08764] Precision, Recall, F値で位置関係ごとに評価を行う．
.....
  [i:238, score:0.08764] Precision, Recall, F値で位置関係ごとに評価を行う．
  [i:239, score:0.16693] システムが出力した位置関係が[MATH]であるもののうち，正しく同定できているものの数を[MATH]，できていないものの数を[MATH]，システムに同定されなかった項のうち位置関係が[MATH]であるものの数を[MATH]とすると，
  [i:241, score:0.07638] また，システム全体(ALL)の[MATH]とPrecision, Recall, F値も，同様に定義できる．

================================================================
[section type  : proposed_method]
[section title : 議論]
================================================================
[i:242, score:0.23736] \tblref{tbl:result-ga}, [REF_tbl:result-wo], [REF_tbl:result-ni]にガ格・ヲ格・ニ格の実験結果を示す．
[i:243, score:0.44999] [MATH], [MATH], [MATH], [MATH]はそれぞれPrecision, Recall, F値, F値のマクロ平均（INTRA_D, INTRA_Z, INTERのF値の算術平均）を示す．
[i:244, score:0.29872] ALLのF値に関して，PPR[MATH]とPPRがIIDA2007と比較して有意差があるかどうかの検定をTakamuraによるスクリプトを用いてApproximate Randomization Test [CITE]を行った．
-----------------------------------------------------
  [subsection title : 決定的に項を同定していくモデルの比較]
-----------------------------------------------------
  [i:lead, score:0.21654] IIDA2005, IIDA2007, IIDA2007+のALLのF値を比較することで，システム全体の性能について論じる．
.....
  [i:251, score:0.52319] IIDA2005とIIDA2007+の性能を比較すると，INTRA_Dを優先的に探索することで，INTRA_DのPrecisionが上昇し，F値も上昇することが分かる．
  [i:253, score:0.44110] ガ格と同様であるが，INTRA_Zの数は比較的少ないためINTRA_Dを優先的に探索しても，精度はガ格ほど悪化しない．
  [i:256, score:0.48971] ニ格は\tblref{tbl:corpus-arg-dist}によると全ての項のうち，全体の90%以上がINTRA_Dである．
-----------------------------------------------------
  [subsection title : 提案手法の効果]
-----------------------------------------------------
  [i:lead, score:0.16168] 決定的な解析では優先度の低い位置関係にある候補の再現率とF値が低下するため，優先順序をつけるほどマクロ平均は下がっていく．
.....
  [i:261, score:0.37459] そのため，トーナメントフェーズで最尤候補を陽に比較する提案モデルは，決定的に項を同定していくモデルよりも効果があるといえる．
  [i:262, score:0.49875] また，PPRはPPR[MATH]と比較して，ガ格・ニ格では性能はほとんど変わないが，ヲ格ではINTRA_DのPrecisionが向上したため，全体の性能も向上していることが分かる．
  [i:263, score:0.58538] そのため，文内項もINTRA_DとINTRA_Zで，最尤候補の同定モデルを分けて陽に比較することで，さらに性能を向上することがあると分かる．
-----------------------------------------------------
  [subsection title : 先行研究との比較]
-----------------------------------------------------
  [i:lead, score:0.09836] ガ格において，提案手法は[CITE]と[CITE]の性能を上回っている．
.....
  [i:269, score:0.35947] この理由として，ニ格はINTRA_Dが最も多く，他の格の解析結果に依存することが挙げられる．
  [i:272, score:0.36918] 一方，[CITE]は「項を含む文節が述語を含む文節に,他の格の項を介して係っている」という関係をモデル化(ga_c, wo_c, ni_c)し，他の格の解析結果を利用して同時に解析を行なっている．
  [i:273, score:0.29739] そのため，INTRA_Dの解析性能が高いと考えられる．

================================================================
[section type  : proposed_method]
[section title : 事例分析]
================================================================
-----------------------------------------------------
  [subsection title : 成功事例]
-----------------------------------------------------
  [i:lead, score:0.49554] 位置関係の優先順序を用いる決定的な解析モデルの中で，全体的な性能が最も高いIIDA2007と，優先順位を持たない提案モデル(PPR[MATH]・PPR)を比較すると，INTERのPrecisionが少し低下しているが，Recallは上昇し，F値も上昇している．
.....
  [i:277, score:0.57190] IIDA2007は文間の候補を参照せずに，文内最尤候補が項らしいか否かを判定しなければならないが，PPR[MATH]やPPRは文内最尤候補と文間最尤候補を比較した上で，項として何が適切かを判断できるため，INTERのRecallを上昇させることができたと考える．
  [i:279, score:0.51847] PPR[MATH]とPPRを比較すると，ガ格はINTRA_DとINTRA_ZのPrecisionとF値が上昇しており，ヲ格はINTRA_DのPrecisionとF値が，上昇している．
  [i:280, score:0.64210] PPRはINTRA_Dの最尤候補同定モデルとINTRA_Zの最尤候補同定モデルの2つの異なるモデルでINTRA_DとINTRA_Zの最尤候補を選んでから，陽にINTRA_DのINTRA_Zのどちらが項らしいかを比較することで，正解項を同定しやすくなっていると考えられる．
-----------------------------------------------------
  [subsection title : 誤り分析]
-----------------------------------------------------
  [i:lead, score:0.12950] 項構造解析に失敗した事例を分析したところ，誤り理由の上位3つは次のものであった．
.....
  [i:299, score:0.27896] その知識を本文中から取得するには，「鳥」や2回出てくる「ユリカモメ」が照応関係にあるという知識も必要となることから，固有表現解析や共参照解析などと推論を用いた述語項構造解析を同時に行うことで互いに精度を高めあうことができると考える．
  [i:314, score:0.26573] しかしながら，名詞述語の振る舞いは他の述語とは明らかに異なり，同一の素性・モデルで項を同定するのは難しい．
  [i:316, score:0.40996] 実際に，PPRを，名詞述語とそれ以外の述語で単純に解析モデルを分けて学習・テストしたところ，\tblref{tbl:result-copula-ga}に示したようにガ格のALLのF値が77.59から77.75と0.16ポイント上昇した．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:330, score:0.25216] 本稿では，位置関係ごとに最尤候補同定モデルを作成し，実際の解析時には，各位置関係の最尤候補の中から最終的な出力を選ぶモデルを提案した．
[i:333, score:0.10046] これまでに，同時解析を行うモデルは[CITE]や[CITE]によって提案されてきたが，いずれも，特定の位置関係を優先的に決定する手法である．
[i:335, score:0.13479] また，名詞述語などの特殊な述語については，一般の述語とは解析モデルを分けることで，精度向上を目指すことも考えている．

