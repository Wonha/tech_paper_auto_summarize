考察


ここでは本手法を名詞のみに適用した．
同じ処理によって，動詞に対しても適用することができるが，ここではその実験を行わなかった．
教師なし学習を利用するには，本質的に，識別のための冗長性のある情報が必要である．
名詞の場合，その名詞を修飾する語句（左文脈）は，その名詞の語義を特定できる可能性が高いし，
その名詞を格にもつ動詞（右文脈）もその名詞の語義を特定できる可能性が高いので，
一方の文脈から名詞の語義が識別できれば，もう一方の文脈は識別のための冗長性のある情報となる．
このため，設定した属性は教師なし学習に適していると考えられる．
一方，動詞の語義を識別するのは，格要素になる名詞，つまり左文脈が重要であり，
右文脈は語義の識別の助けになることは少ない．連体修飾の用法にしても，左右が逆になるだけである．
つまり，どちらかの文脈を利用して語義を識別した場合に，もう一方の文脈は識別に寄与する情報に
ならない．このため，動詞に対しては，本手法を利用する効果は低いと考えた\cite{shinnou-lrec02}．
ただし「効果がない」ということでもないことを注意しておく．
本手法はラベル付き訓練データのみから得られた分類器の精度を必ずしも向上するとは言えず，
逆に精度を落す危険性もある．そのために，本手法を利用する効果があまり期待できない
場合には，危険性を犯してまで本手法を試みる必要はないと判断した．
動詞に対して実際にどの程度の精度向上，あるいは精度低下があるのか，
あるいは動詞に対してはどのような属性を設定するのが良いのかを調べることは
今後の課題である．

先ほども述べたが，本手法により必ずしも精度が向上するとは限らない．
実際に，実験では\mbox{表 \ref{badword2}}の5単語に関して，
わずかではあるが精度が低下している．

\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{精度が下がる単語}\label{badword2}
    \begin{tabular}{|c|c|c|} \hline
見出し    &    NB       & NB+EM \\ \hline
ippan     &    0.467    &  0.400      \\ 
kaku\_n   &    0.767    &  0.700     \\ 
shimin    &    0.567    &  0.500     \\ 
jidai     &    0.867    &  0.833     \\ 
sugata    &    0.367    &  0.333     \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\noindent
精度低下の原因を一般的に論じるのは難しい．
この実験の場合，偶然的な要素が強かった．
NB による分類器では正解したが，NB+EM による分類器では誤るようなテスト文を調査すると，
NB による分類器で正解したのは，たまたま default の規則が適用できて，
正解になったというように，偶然的な要素が強い．
EM による学習が進むと，default から少しずれてくるために，誤ってしまう．
精度低下の原因に関しては，ラベル付き訓練データ，ラベルなし訓練データおよびテストデータの
関係を詳しく調査する必要がある．

本手法による更なる精度向上をはかるための最も有効な手段は，最初のラベル付き訓練データを
見直すことである．今回利用したラベル付き訓練データは，
コンテストの正解が提示される以前に作成されたものであり，出題者が想定した語義と
微妙に違う部分がある．概して，出題者が想定した語義は荒く，Ibaraki で用意された
語義は細かい．語義が細かいと，結果として訓練データが小さいものになり，
学習から得られる規則の精度が悪く，無用な部分で識別が誤る．
ima や mune でもラベル付きの訓練データを見直すことで精度が改善された．

またラベルなし訓練データの量の問題が指摘されるかも知れない．
ラベルなし訓練データは多ければ多いほど精度が向上すると言われている．
今回，精度低下のあった ippan，shimin, jidai の3単語に関して，
ラベルなし訓練データの量を約4倍に増やして実験を行った．
このデータは別年度の毎日新聞記事から取り出した\footnote{ただしテスト文が94年度版から取られることが
分っているので，94年度版は利用していない．}．
結果を\mbox{表 \ref{muchunlabel}}に示す．

\begin{table}[htbp]
  \begin{center}
    \leavevmode
    \caption{ラベルなし訓練データを増やした実験}\label{muchunlabel}
    \begin{tabular}{|c|c|c|c|c|c|c|} \hline
見出し    &  L    &  U    &  new U    & NB      & NB+EM (using L+U)  & NB+EM (using L+ new U)  \\ \hline
ippan     &   87  & 2170  &  8048     & 0.467    &  0.400  &  0.400           \\ 
shimin    &   64  & 2069  &  7912     & 0.567    &  0.500  &  0.533           \\ 
jidai     &   89  & 4397  & 15858     & 0.867    &  0.833  &  0.833           \\  \hline
    \end{tabular}
  \end{center}
\end{table}

精度は悪くなることはなかったが，ほとんど変化は生じなかった．
おそらく今回実験で利用した程度のラベルなし訓練データの量でも，
このタスクでは十分であったと考えられる．

またもう一つの代表的な教師なし学習の手法である Co-training\cite{blum98}との
比較について述べておく．Co-training は独立な2つの属性させ設定できれば，
ベースとなる学習手法を問わないために，応用範囲が広い．
また完全に独立な2つの属性が設定できた場合，
Co-training は EM アルゴリズムを利用した手法よりも優れていることが
報告されている\cite{nigam00-2}．しかし Co-training には独立な2つの属性という条件の他に，
属性の一貫性という条件も必要になる．
この条件のために，実際は Co-training を多値の分類問題に適用することは難しい\cite{shinnou-sen2}．
一方，本手法は Naive Bayes の学習を基本とするという制限はあるが，
分類問題が多値であっても，原理的に問題はない．
そのために，より頑健性の高い現実的な手法と言える．

また多義語の曖昧性解消問題に教師なし学習を利用した Yarowsky の研究\cite{Yarowsky2}との
比較についても述べておく．
Yarowsky の教師なし学習も，実は Co-training の特殊ケースと見なせる\cite{blum98}．
2つの独立した属性として，1つは前後の文脈，もう1つは
「同じ文書内で使われている曖昧な単語の語義は1つに固定される」
というヒューリスティクスである．
このヒューリスティクスが翻訳タスクで設定している語義の細かさに対して，
どれほど成立しているかは未知である．
またこの手法では，必要とされるラベルなし訓練データは文書，
しかも対象単語が複数含まれているような文書となる．
これはいかにラベルなしと言えども収集は容易ではない．
このため比較対象の実験も困難である．
一方，本手法はその対象単語を含む文が訓練データとなるので，収集は容易であり，
より現実的な手法と言える．

今後の課題としては2つある．1つは名詞以外の単語への適用である．
教師なし学習が機能するような属性をどのように設定するかが課題である．
2つ目は教師なし学習による精度低下の原因の調査，およびその回避策の検討である．
これによってより頑健な教師なし学習が可能となる．


おわりに


本論文では，Nigam らによって提案された EM アルゴリズムを利用した
教師なし学習の手法を，SENSEVAL2 の日本語翻訳タスクで出題された名詞に適用した．
識別のための属性としては，対象単語の前後数単語の原型や表記という簡易なものを利用した．
ラベル付き訓練データだけから学習できた決定リストの正解率は
58.9\,\% (コンテストでの Ibaraki の成績)であり，Naive Bayes による分類器の正解率は 58.2\,\% であった．
そして本手法を用いて Naive Bayes による分類器の正解率を 61.8\,\% まで改善できた．
また一部，訓練データの不具合を修正することで，Naive Bayes による分類器の正解率 62.3\,\% 
（決定リストでの正解率は 63.2\,\%）を，本手法により 68.2\,\% まで高めることができた．
問題点としては名詞のみの適用である点と，精度が低下するケースも存在する点である．
これら問題の解決が今後の課題であり，より頑健性の高い教師なし学習手法の構築を目指す．



\bibliographystyle{jnlpbbl}
\bibliography{4}

\begin{biography}
\biotitle{略歴}
\bioauthor{新納 浩幸}{
1985年東京工業大学理学部情報科学科卒業.
1987年同大学大学院理工学研究科情報科学専攻修士課程修了．
同年富士ゼロックス，翌年松下電器を経て，
1993年茨城大学工学部システム工学科助手．
1997年同学科講師，2001年同学科助教授．
情報処理学会，人工知能学会，言語処理学会，ACL 各会員．博士(工学)．}

\bioreceived{受付}
\biorevised{再受付}
\biorerevised{再々受付}
\bioaccepted{採録}
\end{biography}
