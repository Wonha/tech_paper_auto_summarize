

本論文では，Nigamらによって提案されたEMアルゴリズムを利用した教師なし学習の手法[CITE]を，SENSEVAL2の日本語翻訳タスク[CITE]で出題された名詞の語義の曖昧性解消問題に適用する．その結果，通常の教師付き学習で得られる分類規則の精度を向上させ得ることを示す．

自然言語処理では個々の問題を分類問題として定式化し，帰納学習の手法を利用して，その問題を解決するというアプローチが大きな成功をおさめている．しかしこのアプローチには帰納学習で必要とされる訓練データを用意しなければならないという大きな問題がある．この問題に対して，近年，少量のラベル付き訓練データから得られる分類器の精度を，大量のラベルなし訓練データによって高めてゆく教師なし学習が散見される．代表的な手法として，Co-training[CITE]と，EMアルゴリズムを利用した手法[CITE]がある．Co-trainingは2つの独立した属性AとBを設定し，一方の属性Aから構築される分類器を利用して，ラベルなしデータにラベル（クラス）を付与する．その中から信頼性のあるラベルが付与されたデータをラベル付き訓練データに加える．このようにして追加されたラベル付き訓練データは，もう一方の属性Bから見るとランダムなサンプルにラベル付けされたデータとして振る舞うので，属性Bから構築される分類器の精度が高まる．これをお互いに作用し合うことで，分類器の精度が高められる．一方，EMアルゴリズムは，部分的に欠損値のある不完全な観測データ[MATH]から，そのデータを発生する確率モデル[MATH]を推定する手法である．[MATH]は未知パラメータ[MATH]を含み，[MATH]の推定は，[MATH]の推定に帰着される．分類問題の教師なし学習では，ラベル付き訓練データが完全な観測データ，ラベルなし訓練データがラベルを欠損値とした不完全な観測データとなる．EMアルゴリズムは，現時点での[MATH]を使って，モデル[MATH]のもとでの[MATH]の期待値を取る（E-step）．次に，この期待値を最大にするような[MATH]を求める（M-Step）．[MATH]を新たな[MATH]として先のE-stepとM-stepを繰り返す．ここで[MATH]は欠損値となるラベルである．EMアルゴリズムはパラメータ[MATH]とモデル[MATH]を適切に設定することで，隠れマルコフモデルや文脈自由文法のパラメータ推定，あるいは名詞と動詞間の関係クラスの教師なし学習[CITE][CITE]などに利用できる．そして，Nigamらは文書分類を題材にモデル[MATH]をNaive Bayesのモデル，[MATH]をラベル[MATH]のもとで素性[MATH]が起る条件付き確率[MATH]に設定することで，教師なし学習を試みている[CITE]．

paragraph score: 1.00997972184442
