================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:149] 本論文では，Nigamらによって提案されたEMアルゴリズムを利用した教師なし学習の手法を，SENSEVAL2の日本語翻訳タスクで出題された名詞の語義の曖昧性解消問題に適用する．
[i:1, score:187] この手法は，ラベルなしデータをラベルを欠損値とする観測データ，その観測データを発生させるモデルをNaive Bayesモデル，このモデルの未知パラメータをラベル[MATH]のもとで素性[MATH]が起る条件付き確率[MATH]に設定して，EMアルゴリズムを用いる．
[i:4, score:226] 実験では，ラベル付き訓練データのみから学習したNaive Bayesの正解率が58.2 %，同データから学習した決定リストの正解率が58.9 %（Ibarakiの公式成績）であったのに対し，ラベル付き訓練データの他にラベルなし訓練データを用いた本手法では，61.8 %の正解率を得た．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:7, score:150] 本論文では，Nigamらによって提案されたEMアルゴリズムを利用した教師なし学習の手法[CITE]を，SENSEVAL2の日本語翻訳タスク[CITE]で出題された名詞の語義の曖昧性解消問題に適用する．
[i:25, score:174] そして，Nigamらは文書分類を題材にモデル[MATH]をNaive Bayesのモデル，[MATH]をラベル[MATH]のもとで素性[MATH]が起る条件付き確率[MATH]に設定することで，教師なし学習を試みている[CITE]．
[i:42, score:205] ラベル付き訓練データだけから学習できた決定リストの正解率は58.9 %(コンテストでのIbarakiの成績)であり，Naive Bayesによる分類器の正解率は58.2 %であった．

================================================================
[section type  : proposed_method]
[section title : Naive Bayes による多義語の曖昧性解消]
================================================================
[i:59, score:88] Naive Bayesを使った分類がうまくゆくかどうかは，式[REF_siki1]の仮定をできるだけ満たすような素性を選択することである．
[i:61, score:89] 多義語の曖昧性解消でも式[REF_siki1]の仮定をできるだけ満たすような素性を選択すればNaive Bayesが利用できる．
[i:65, score:80] そして，「その無力感は今も原告たちの胸に染み付いている」という文中の「胸」の語義は『心の中』なので，この事例のクラスは『心の中』となる．

================================================================
[section type  : proposed_method]
[section title : EM アルゴリズムによる教師なし学習]
================================================================
[i:73, score:111] 分類問題の解決にNaive Bayesが使えれば，Nigamらが提案した教師なし学習が利用できる．
[i:74, score:151] そこではEMアルゴリズムを用いることで，ラベルなし訓練データを用いて，ラベル付き訓練データから学習された分類器の精度を向上させる．
[i:87, score:91] ラベル付けされていない訓練データに対しては，最初は0であるが，EMアルゴリズムの繰り返しによって，徐々に適切な値に更新されてゆく．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[i:106, score:280] 表[REF_result2]に，名詞20単語の各単語に対するラベル付き訓練データLの数，ラベルなし訓練データUの数，ラベル付き訓練データから学習できた決定リスト（DLと略す）による正解率（Ibarakiの結果），ラベル付き訓練データのみから学習できたNaive Bayes（NBと略す）による正解率，NBをEMアルゴリズムにより改善させた分類器（NB＋EMと略す）の正解率を示す．
[i:107, score:135] 表[REF_result2]から分るようにラベル付き訓練データLのみから学習できたDLもNBもほぼ同等の正解率（58.9 %と58.2 %）である．
[i:114, score:134] Ibarakiで用意されたラベル付き訓練データは，一部の単語で必要以上に語義を細かく分けている．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[i:144, score:112] 精度低下の原因に関しては，ラベル付き訓練データ，ラベルなし訓練データおよびテストデータの関係を詳しく調査する必要がある．
[i:146, score:132] 今回利用したラベル付き訓練データは，コンテストの正解が提示される以前に作成されたものであり，出題者が想定した語義と微妙に違う部分がある．
[i:152, score:115] 今回，精度低下のあったippan，shimin, jidaiの3単語に関して，ラベルなし訓練データの量を約4倍に増やして実験を行った．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:177, score:125] 本論文では，Nigamらによって提案されたEMアルゴリズムを利用した教師なし学習の手法を，SENSEVAL2の日本語翻訳タスクで出題された名詞に適用した．
[i:179, score:205] ラベル付き訓練データだけから学習できた決定リストの正解率は58.9 %(コンテストでのIbarakiの成績)であり，Naive Bayesによる分類器の正解率は58.2 %であった．
[i:181, score:145] また一部，訓練データの不具合を修正することで，Naive Bayesによる分類器の正解率62.3 %（決定リストでの正解率は63.2 %）を，本手法により68.2 %まで高めることができた．

