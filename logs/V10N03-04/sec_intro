本論文では，Nigamらによって提案されたEMアルゴリズムを利用した教師なし学習の手法[CITE]を，SENSEVAL2の日本語翻訳タスク[CITE]で出題された名詞の語義の曖昧性解消問題に適用する．
その結果，通常の教師付き学習で得られる分類規則の精度を向上させ得ることを示す．
自然言語処理では個々の問題を分類問題として定式化し，帰納学習の手法を利用して，その問題を解決するというアプローチが大きな成功をおさめている．
しかしこのアプローチには帰納学習で必要とされる訓練データを用意しなければならないという大きな問題がある．
この問題に対して，近年，少量のラベル付き訓練データから得られる分類器の精度を，大量のラベルなし訓練データによって高めてゆく教師なし学習が散見される．
代表的な手法として，Co-training[CITE]と，EMアルゴリズムを利用した手法[CITE]がある．
Co-trainingは2つの独立した属性AとBを設定し，一方の属性Aから構築される分類器を利用して，ラベルなしデータにラベル（クラス）を付与する．
その中から信頼性のあるラベルが付与されたデータをラベル付き訓練データに加える．
このようにして追加されたラベル付き訓練データは，もう一方の属性Bから見るとランダムなサンプルにラベル付けされたデータとして振る舞うので，属性Bから構築される分類器の精度が高まる．
これをお互いに作用し合うことで，分類器の精度が高められる．
一方，EMアルゴリズムは，部分的に欠損値のある不完全な観測データ[MATH]から，そのデータを発生する確率モデル[MATH]を推定する手法である．
[MATH]は未知パラメータ[MATH]を含み，[MATH]の推定は，[MATH]の推定に帰着される．
分類問題の教師なし学習では，ラベル付き訓練データが完全な観測データ，ラベルなし訓練データがラベルを欠損値とした不完全な観測データとなる．
EMアルゴリズムは，現時点での[MATH]を使って，モデル[MATH]のもとでの[MATH]の期待値を取る（E-step）．
次に，この期待値を最大にするような[MATH]を求める（M-Step）．
[MATH]を新たな[MATH]として先のE-stepとM-stepを繰り返す．
ここで[MATH]は欠損値となるラベルである．
EMアルゴリズムはパラメータ[MATH]とモデル[MATH]を適切に設定することで，隠れマルコフモデルや文脈自由文法のパラメータ推定，あるいは名詞と動詞間の関係クラスの教師なし学習[CITE][CITE]などに利用できる．
そして，Nigamらは文書分類を題材にモデル[MATH]をNaive Bayesのモデル，[MATH]をラベル[MATH]のもとで素性[MATH]が起る条件付き確率[MATH]に設定することで，教師なし学習を試みている[CITE]．
NigamらのEMアルゴリズムを利用した手法やCo-trainingは，どちらも本来は文書分類に対して考案されており，多義語の曖昧性解消に利用できるかどうかは明らかではない．
多義語の曖昧性解消は自然言語処理の中心的な課題であり，これらの手法が適用できることが望ましい．
ここではSENSEVAL2の日本語翻訳タスクで出題された名詞を題材に，EMアルゴリズムを利用した教師なし学習の手法が名詞の語義の曖昧性解消に適用可能であることを示す．
翻訳タスクの出題形式はある単語[MATH]がマークされた（日本語）文書である．
翻訳タスクでは予め，単語[MATH]に関するTranslation Memory（以下TMと略す）と呼ばれる日英の対訳例文の集合が解答者に配られている．
そして翻訳タスクの解答形式は，出題された文書内において注目する単語[MATH]を英訳する際に利用できるTMの例文番号である．
つまり，翻訳タスクは単語[MATH]の訳を語義と考えた多義語の曖昧性解消問題となっている．
また同時に，翻訳タスクはTMの例文番号をクラスと考えた場合の分類問題として扱える．
ここで注意すべきは，翻訳タスクは訓練データを作るのが困難な点である．
TMは1つの単語に対して平均して21.6例文がある．
今仮にある単語[MATH]の例文として[MATH]から[MATH]までの20例文がTMに記載されていたとする．
新たに訓練データを作成する場合，単語[MATH]を含む新たな文を持ってきて，[MATH]から[MATH]のどれか1つのラベルを与える必要がある．
〇か×かの二者択一は比較的容易であるが，20個のラベルの中から最も適切な1つを選ぶのは非常に負荷のかかる作業である．
このように，翻訳タスクは訓練データを新たに作るのが困難であるために，教師なし学習を適用する格好のタスクになっている．
実験ではSENSEVAL2の日本語翻訳タスクで出題された全名詞20単語を用いて，本手法の評価を行う．
各単語に対して，平均70事例（TMの例文も含む）からなるラベル付き訓練データと，新聞記事1年分から取り出した平均3,354事例からなるラベルなし訓練データを作成し，本手法を適用した．
ラベル付き訓練データだけから学習できた決定リストの正解率は58.9 %(コンテストでのIbarakiの成績)であり，Naive Bayesによる分類器の正解率は58.2 %であった．
そして本手法を用いてNaive Bayesによる分類器の精度を高めた結果61.8 %まで改善された．
また一部，訓練データの不具合を修正することで，Naive Bayesによる分類器の正解率を62.3 %，決定リストでの正解率を63.2 %に向上できた．
更に，本手法を用いてNaive Bayesによる分類器の正解率（62.3 %）を68.2 %まで高めることができた．
