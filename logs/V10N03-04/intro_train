1  本 論文 で は  Nigam ら によって 提案 さ れ た EM アルゴリズム を 利用 し た 教師 なし 学習 の 手法  CITE  を  SENSEVAL 2 の 日本語 翻訳 タスク  CITE  で 出題 さ れ た 名詞 の 語義 の 曖昧 性 解消 問題 に 適用 する  
0  その 結果  通常 の 教師 付き 学習 で 得 られる 分類 規則 の 精度 を 向上 さ せ 得る こと を 示す  
0  自然 言語 処理 で は 個々 の 問題 を 分類 問題 として 定式 化 し  帰納 学習 の 手法 を 利用 し て  その 問題 を 解決 する という アプローチ が 大きな 成功 を おさめ て いる  
0  しかし この アプローチ に は 帰納 学習 で 必要 と さ れる 訓練 データ を 用意 し なけれ ば なら ない という 大きな 問題 が ある  
0  この 問題 に対して  近年  少量 の ラベル 付き 訓練 データ から 得 られる 分類 器 の 精度 を  大量 の ラベル なし 訓練 データ によって 高め て ゆく 教師 なし 学習 が 散見 さ れる  
0  代表 的 な 手法 として  Co  training  CITE  と  EM アルゴリズム を 利用 し た 手法  CITE  が ある  
0  Co  training は 2 つ の 独立 し た 属性 A と B を 設定 し  一方 の 属性 A から 構築 さ れる 分類 器 を 利用 し て  ラベル なし データ に ラベル  クラス  を 付与 する  
0  その 中 から 信頼 性 の ある ラベル が 付与 さ れ た データ を ラベル 付き 訓練 データ に 加える  
0  この よう に し て 追加 さ れ た ラベル 付き 訓練 データ は  もう 一方 の 属性 B から 見る と ランダム な サンプル に ラベル付け さ れ た データ として 振る舞う ので  属性 B から 構築 さ れる 分類 器 の 精度 が 高まる  
0  これ を お互い に 作用 し 合う こと で  分類 器 の 精度 が 高め られる  
1  一方  EM アルゴリズム は  部分 的 に 欠損 値 の ある 不完全 な 観測 データ  MATH  から  その データ を 発生 する 確率 モデル  MATH  を 推定 する 手法 で ある  
1   MATH  は 未知 パラメータ  MATH  を 含み   MATH  の 推定 は   MATH  の 推定 に 帰着 さ れる  
1  分類 問題 の 教師 なし 学習 で は  ラベル 付き 訓練 データ が 完全 な 観測 データ  ラベル なし 訓練 データ が ラベル を 欠損 値 と し た 不完全 な 観測 データ と なる  
1  EM アルゴリズム は  現時点 で の  MATH  を 使っ て  モデル  MATH  の もと で の  MATH  の 期待 値 を 取る  E  step   
0  次に  この 期待 値 を 最大 に する よう な  MATH  を 求める  M  Step   
0   MATH  を 新た な  MATH  として 先 の E  step と M  step を 繰り返す  
0  ここ で  MATH  は 欠損 値 と なる ラベル で ある  
1  EM アルゴリズム は パラメータ  MATH  と モデル  MATH  を 適切 に 設定 する こと で  隠れ マルコフ モデル や 文脈 自由 文法 の パラメータ 推定  あるいは 名詞 と 動詞 間 の 関係 クラス の 教師 なし 学習  CITE  CITE  など に 利用 できる  
1  そして  Nigam ら は 文書 分類 を 題材 に モデル  MATH  を Naive Bayes の モデル  MATH  を ラベル  MATH  の もと で 素性  MATH  が 起る 条件 付き 確率  MATH  に 設定 する こと で  教師 なし 学習 を 試み て いる  CITE  
1  Nigam ら の EM アルゴリズム を 利用 し た 手法 や Co  training は  どちら も 本来 は 文書 分類 に対して 考案 さ れ て おり  多義 語 の 曖昧 性 解消 に 利用 できる か どう か は 明らか で は ない  
0  多義 語 の 曖昧 性 解消 は 自然 言語 処理 の 中心 的 な 課題 で あり  これら の 手法 が 適用 できる こと が 望ましい  
1  ここ で は SENSEVAL 2 の 日本語 翻訳 タスク で 出題 さ れ た 名詞 を 題材 に  EM アルゴリズム を 利用 し た 教師 なし 学習 の 手法 が 名詞 の 語義 の 曖昧 性 解消 に 適用 可能 で ある こと を 示す  
0  翻訳 タスク の 出題 形式 は ある 単語  MATH  が マーク さ れ た  日本語  文書 で ある  
0  翻訳 タスク で は 予め  単語  MATH  に関する Translation Memory  以下 TM と 略す  と 呼ば れる 日 英 の 対訳 例文 の 集合 が 解答 者 に 配ら れ て いる  
0  そして 翻訳 タスク の 解答 形式 は  出題 さ れ た 文書 内 において 注目 する 単語  MATH  を 英訳 する 際 に 利用 できる TM の 例文 番号 で ある  
0  つまり  翻訳 タスク は 単語  MATH  の 訳 を 語義 と 考え た 多義 語 の 曖昧 性 解消 問題 と なっ て いる  
0  また 同時に  翻訳 タスク は TM の 例文 番号 を クラス と 考え た 場合 の 分類 問題 として 扱える  
0  ここ で 注意 す べき は  翻訳 タスク は 訓練 データ を 作る の が 困難 な 点 で ある  
0  TM は 1 つ の 単語 に対して 平均 し て 21  6 例文 が ある  
1  今 仮に ある 単語  MATH  の 例文 として  MATH  から  MATH  まで の 20 例文 が TM に 記載 さ れ て い た と する  
1  新た に 訓練 データ を 作成 する 場合  単語  MATH  を 含む 新た な 文 を 持っ て き て   MATH  から  MATH  の どれ か 1 つ の ラベル を 与える 必要 が ある  
0  〇 か  かの 二者択一 は 比較的 容易 で ある が  20 個 の ラベル の 中 から 最も 適切 な 1 つ を 選ぶ の は 非常 に 負荷 の かかる 作業 で ある  
0  この よう に  翻訳 タスク は 訓練 データ を 新た に 作る の が 困難 で ある ため に  教師 なし 学習 を 適用 する 格好 の タスク に なっ て いる  
1  実験 で は SENSEVAL 2 の 日本語 翻訳 タスク で 出題 さ れ た 全 名詞 20 単語 を 用い て  本手 法 の 評価 を 行う  
1  各 単語 に対して  平均 70 事例  TM の 例文 も 含む  から なる ラベル 付き 訓練 データ と  新聞 記事 1 年 分 から 取り出し た 平均 3  354 事例 から なる ラベル なし 訓練 データ を 作成 し  本 手法 を 適用 し た  
1  ラベル 付き 訓練 データ だけ から 学習 でき た 決定 リスト の 正解 率 は 58  9  コンテスト で の Ibaraki の 成績  で あり  Naive Bayes による 分類 器 の 正解 率 は 58  2  で あっ た  
0  そして 本 手法 を 用い て Naive Bayes による 分類 器 の 精度 を 高め た 結果 61  8  まで 改善 さ れ た  
1  また 一部  訓練 データ の 不具合 を 修正 する こと で  Naive Bayes による 分類 器 の 正解 率 を 62  3  決定 リスト で の 正解 率 を 63  2  に 向上 でき た  
1  更に  本 手法 を 用い て Naive Bayes による 分類 器 の 正解 率  62  3  を 68  2  まで 高める こと が でき た  
