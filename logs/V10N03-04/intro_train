1 本 論文 で は Nigamら によって 提案 さ れ た EMアルゴリズム を 利用 し た 教師 なし 学習 の 手法CITE を SENSEVAL2 の 日本語翻訳タスクCITE で 出題 さ れ た 名詞 の 語義 の 曖昧性解消問題 に 適用 する 
0 その 結果通常 の 教師付き学習 で 得 られる 分類規則 の 精度 を 向上 さ せ 得る こと を 示す 
0 自然言語処理 で は 個々 の 問題 を 分類問題 として 定式化 し 帰納学習 の 手法 を 利用 し て その 問題 を 解決 する という アプローチ が 大きな 成功 を おさめ て いる 
0 しかし この アプローチ に は 帰納学習 で 必要 と さ れる 訓練データ を 用意 し なけれ ば なら ない という 大きな 問題 が ある 
0 この 問題 に対して 近年少量 の ラベル付き訓練データ から 得 られる 分類器 の 精度 を 大量 の ラベル なし 訓練データ によって 高め て ゆく 教師 なし 学習 が 散見 さ れる 
0 代表的 な 手法 として CotrainingCITE と EMアルゴリズム を 利用 し た 手法CITE が ある 
0 Cotraining は 2 つ の 独立 し た 属性A と B を 設定 し 一方 の 属性A から 構築 さ れる 分類器 を 利用 し て ラベル なし データ に ラベルクラス を 付与 する 
0 その 中 から 信頼性 の ある ラベル が 付与 さ れ た データ を ラベル付き訓練データ に 加える 
0 この よう に し て 追加 さ れ た ラベル付き訓練データ は もう 一方 の 属性B から 見る と ランダム な サンプル に ラベル付け さ れ た データ として 振る舞う ので 属性B から 構築 さ れる 分類器 の 精度 が 高まる 
0 これ を お互い に 作用 し 合う こと で 分類器 の 精度 が 高め られる 
0 一方 EMアルゴリズム は 部分的 に 欠損値 の ある 不完全 な 観測データMATH から その データ を 発生 する 確率モデルMATH を 推定 する 手法 で ある 
0 MATH は 未知パラメータMATH を 含み MATH の 推定 は MATH の 推定 に 帰着 さ れる 
0 分類問題 の 教師 なし 学習 で は ラベル付き訓練データ が 完全 な 観測データラベル なし 訓練データ が ラベル を 欠損値 と し た 不完全 な 観測データ と なる 
0 EMアルゴリズム は 現時点 で の MATH を 使っ て モデルMATH の もと で の MATH の 期待値 を 取る 
0 次に この 期待値 を 最大 に する よう な MATH を 求める 
0 MATH を 新た な MATH として 先 の Estep と Mstep を 繰り返す 
0 ここ で MATH は 欠損値 と なる ラベル で ある 
0 EMアルゴリズム は パラメータMATH と モデルMATH を 適切 に 設定 する こと で 隠れマルコフモデル や 文脈自由文法 の パラメータ推定 あるいは 名詞 と 動詞間 の 関係クラス の 教師 なし 学習CITECITE など に 利用 できる 
1 そして Nigamら は 文書分類 を 題材 に モデルMATH を NaiveBayes の モデルMATH を ラベルMATH の もと で 素性MATH が 起る 条件付き確率MATH に 設定 する こと で 教師 なし 学習 を 試み て いる 
0 Nigamら の EMアルゴリズム を 利用 し た 手法 や Cotraining は どちら も 本来 は 文書分類 に対して 考案 さ れ て おり 多義語 の 曖昧性解消 に 利用 できる か どう か は 明らか で は ない 
0 多義語 の 曖昧性解消 は 自然言語処理 の 中心的 な 課題 で あり これら の 手法 が 適用 できる こと が 望ましい 
1 ここ で は SENSEVAL2 の 日本語翻訳タスク で 出題 さ れ た 名詞 を 題材 に EMアルゴリズム を 利用 し た 教師 なし 学習 の 手法 が 名詞 の 語義 の 曖昧性解消 に 適用可能 で ある こと を 示す 
0 翻訳タスク の 出題形式 は ある 単語MATH が マーク さ れ た 日本語文書 で ある 
0 翻訳タスク で は 予め 単語MATH に関する TranslationMemory以下TM と 略す と 呼ば れる 日英 の 対訳例文 の 集合 が 解答者 に 配ら れ て いる 
0 そして 翻訳タスク の 解答形式 は 出題 さ れ た 文書内 において 注目 する 単語MATH を 英訳 する 際 に 利用 できる TM の 例文番号 で ある 
0 つまり 翻訳タスク は 単語MATH の 訳 を 語義 と 考え た 多義語 の 曖昧性解消問題 と なっ て いる 
0 また 同時に 翻訳タスク は TM の 例文番号 を クラス と 考え た 場合 の 分類問題 として 扱える 
0 ここ で 注意 す べき は 翻訳タスク は 訓練データ を 作る の が 困難 な 点 で ある 
0 TM は 1 つ の 単語 に対して 平均 し て 216例文 が ある 
0 今 仮に ある 単語MATH の 例文 として MATH から MATH まで の 20例文 が TM に 記載 さ れ て い た と する 
0 新た に 訓練データ を 作成 する 場合単語MATH を 含む 新た な 文 を 持っ て き て MATH から MATH の どれ か 1 つ の ラベル を 与える 必要 が ある 
0 〇 か かの 二者択一 は 比較的 容易 で ある が 20個 の ラベル の 中 から 最も 適切 な 1 つ を 選ぶ の は 非常 に 負荷 の かかる 作業 で ある 
0 この よう に 翻訳タスク は 訓練データ を 新た に 作る の が 困難 で ある ため に 教師 なし 学習 を 適用 する 格好 の タスク に なっ て いる 
1 実験 で は SENSEVAL2 の 日本語翻訳タスク で 出題 さ れ た 全 名詞20単語 を 用い て 本手法 の 評価 を 行う 
0 各 単語 に対して 平均70事例TM の 例文 も 含む から なる ラベル付き訓練データ と 新聞記事1年分 から 取り出し た 平均3354事例 から なる ラベル なし 訓練データ を 作成 し 本 手法 を 適用 し た 
1 ラベル付き訓練データ だけ から 学習 でき た 決定リスト の 正解率 は 589コンテスト で の Ibaraki の 成績 で あり NaiveBayes による 分類器 の 正解率 は 582 で あっ た 
0 そして 本 手法 を 用い て NaiveBayes による 分類器 の 精度 を 高め た 結果618 まで 改善 さ れ た 
1 また 一部訓練データ の 不具合 を 修正 する こと で NaiveBayes による 分類器 の 正解率 を 623決定リスト で の 正解率 を 632 に 向上 でき た 
0 更に 本 手法 を 用い て NaiveBayes による 分類器 の 正解率623 を 682 まで 高める こと が でき た 
