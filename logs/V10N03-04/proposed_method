Naive Bayes による多義語の曖昧性解消


まず，用語の混乱を避けるため，本論文で用いる「属性」と「素性」の区別をしておく．
本論文では，例えば，「対象単語の直前の単語」といった識別のための観点を「属性」と呼び，
属性に具体的な値が与えられたものを「素性」と呼んでいる．
例えば「対象単語の直前の単語」といった属性を\verb| e1 |などで表し，
対象単語の直前の単語が，例えば，「日本」であった場合に，\verb| 'e1=日本' |と表された
ものを素性と呼ぶ．

ある事例\( x \)が素性のベクトルとして，以下のように表現されたとする．
\[
x = (f_1,f_2,\cdots,f_n )
\]
\( x \)の分類先のクラスの集合を\( C = \{ c_1,c_2, \cdots, c_m \} \)と置く．
分類問題は\( P(c|x) \)の分布を推定することで解決できる．
実際に，\( x \)のクラス\( c_x \)は以下の式で求まる．
\[
c_x = arg \max_{c \in C} P(c|x)
\]

ベイズの定理を用いると，
\[
P(c|x) = \frac{P(c)P(x|c)}{P(x)}
\]
\noindent
なので，結局，以下が成立する．
\[
c_x = arg \max_{c \in C} P(c)P(x|c)
\]
ここで，\( P(c) \)は比較的簡単に推定できる．問題は，\( P(x|c) \) の推定だが，
これは現実的には難しい．Naive Bayes のモデルは，この推定に以下の仮定を導入する．
\begin{equation}
  \label{siki1}
P(x|c) = \prod_{i = 1}^{n} P(f_i|c)  
\end{equation}
\( P(f_i|c) \)の推定は比較的容易であるために，結果として\( P(x|c) \)が推定できる\cite{ml-text}．
Naive Bayes を使った分類がうまくゆくかどうかは，\mbox{式\ref{siki1}} の仮定をできるだけ満たすような
素性を選択することである．文書分類であれば，各素性を各単語の生起に設定することで，
Naive Bayes が有効であることが知られている．

多義語の曖昧性解消でも\mbox{式\ref{siki1}}の仮定をできるだけ満たすような素性を選択すれば
Naive Bayes が利用できる．本論文では以下の4つの属性を利用することにした．

\bigskip
\begin{verbatim}
      e1 :  直前の単語，
      e2 :  直後の単語，
      e3 :  前方の内容語（2つまで）
      e4 :  後方の内容語（2つまで）
\end{verbatim}
\bigskip

例えば，「胸」の語義は『体の一部としての胸』という語義と『心の中』という語義がある．
そして，「その無力感は今も原告たちの胸に染み付いている」という文中の「胸」の語義は
『心の中』なので，この事例のクラスは『心の中』となる．また，この文は以下のように
形態素解析される．
各行が分割された単語であり，第1列が表記，第2列が原型，第3列が品詞を表す．

\bigskip
\begin{verbatim}
                  その      その         連体詞           
                  無力      無力         名詞-形容動詞語幹                
                  感        感           名詞-接尾-一般           
                  は        は           助詞-係助詞              
                  今        今           名詞-副詞可能            
                  も        も           助詞-係助詞              
                  原告      原告         名詞-一般                
                  たち      たち         名詞-接尾-一般           
                  の        の           助詞-連体化              
                  胸        胸           名詞-一般                
                  に        に           助詞-格助詞-一般         
                  染み付い   染み付く     動詞-自立
                  て        て           助詞-接続助詞            
                  いる      いる         動詞-非自立
\end{verbatim}
\bigskip

この結果から以下の4つの素性が抽出できる．

\bigskip
\begin{verbatim}
                  e1=の， e2=に， e3 ={原告, たち}， e4={染み付く，いる}
\end{verbatim}
\bigskip

属性\verb|e3| と \verb|e4| の値は集合になるが，学習の際に以下のように分割して，素性として表す．

\begin{verbatim}
                  e3=原告,  e3=たち,  e4=染み付く,  e4=いる
\end{verbatim}



EM アルゴリズムによる教師なし学習


分類問題の解決に Naive Bayes が使えれば，Nigam らが提案した教師なし学習が利用できる．
そこでは EM アルゴリズムを用いることで，ラベルなし訓練データを用いて，
ラベル付き訓練データから学習された分類器の精度を向上させる．

ここではポイントとなる式とアルゴリズムだけを示す\cite{nigam00}．

基本となるのは，あるクラス\( c_j \)のもとで，素性\( f_i \)が発生する確率\( P(f_i|c_j) \)を求める
ことである．これは以下の式で求まる．この式は頻度 0 の部分を考慮したスムージングを行っている．

\begin{equation}
  \label{siki6}
P(f_i|c_j) = \frac{1 + \sum_{k = 1}^{|D|}N(f_i,d_k)P(c_j|d_k)}{|F| + \sum_{m = 1}^{|F|}\sum_{k = 1}^{|D|}N(f_m,d_k)P(c_j|d_k)}
\end{equation}

式\ref{siki6} の\( D \) はラベル付けされた訓練データとラベル付けされていない訓練データを
合わせた訓練データ全体を示す．\( D \) の各要素を\( d_k \) で表す．
\( F \) は素性全体の集合である．\( F \) の各要素を\( f_m \) で表す．
また，\( N(f_i,d_k) \) は，訓練事例\( d_k \)に含まれる素性\( f_i \)の個数を
表す．ここでの設定では，\( N(f_i,d_k) \)は 0 か 1 の値であり，ほとんどの場合 0 である．
\( P(c_j|d_k) \) は訓練データがクラス\( c_j \)を持つ確率である．
ラベル付けされた訓練データに対しては，0 か 1 の値をとる．
ラベル付けされていない訓練データに対しては，最初は 0 であるが，EM アルゴリズムの
繰り返しによって，徐々に適切な値に更新されてゆく．

式\ref{siki6} を利用して，以下の分類器が作成できる．

\begin{equation}
    \label{siki8}
P(c_j|d_i) = \frac{P(c_j) \prod_{f_n \in K_{d_i}}P(f_n|c_j)}{\sum_{r = 1}^{|C|} P(c_r)\prod_{f_n \in K_{d_i}}P(f_n|c_r)}
\end{equation}
\noindent
ここで，\( C \) はクラスの集合である．
\( K_{d_i} \) は訓練事例\( d_i \)に含まれる素性の集合を示す．
\( P(c_j) \)はクラス\( c_j \)の発生確率であり，以下の式で
計算する．

\[
P(c_j) = \frac{1 + \sum_{k = 1}^{|D|} P(c_j|d_k)}{|C| + |D|}
\]

EM アルゴリズムは\mbox{式\ref{siki8}}を利用して，
ラベル付けされていない事例\( d_i \)に対して，\( P(c_j|d_i) \) を求める(E-step)．
次に\mbox{式\ref{siki6}}を利用して，\( P(f_i|c_j) \) を求める(M-step)．
この E-step と M-step を交互に繰り返して，\( P(f_i|c_j) \) と\( P(c_j|d_i) \) を
収束するまで更新してゆく．

最終的には収束した\( P(f_i|c_j) \)を使って，\mbox{式\ref{siki8}}から分類が行える．


