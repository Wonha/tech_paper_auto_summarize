ウェブから獲得した大規模格フレーム
\label{Section::格フレーム辞書の自動構築}

格フレームは，ウェブから収集した大規模コーパスを用いて，
\cite{Kawahara2006}の手法により自動構築を行う．本節では，格フレーム構築手
法の概要を述べる．

人間のもつ常識的知識の重要な部分である格フレームは，様々な言語現象をカバー
することが望ましい．そのような格フレームを構築するために，大規模コーパス
から漸進的に確からしい情報を抽出する．

\begin{table}[b]
\input{table1.txt}
\end{table}

まず最初に，大規模コーパスを構文解析し，その解析結果から第1段階の格フレー
ムを構築する．格フレームを構築する際の最大の問題は，用言の用法の曖昧性で
ある．つまり，同じ表記の用言でも複数の意味，用法をもち，とりうる格や用例
が異なる．例えば，以下の2つの例は，用言は「積む」で同じであるが用法が異
なっている．

\begin{lingexample}
 \head{トラックに荷物を積む}
 \sent{経験を積む}
\end{lingexample}

\noindent
用法が異なる格フレームを別々につくるために，我々は，格フレーム収集の単位
を用言とその直前の格要素の組とした．「積む」の例では，「荷物を積む」「経
験を積む」を単位として格フレームを収集する．さらに，「荷物を積む」「物資
を積む」などかなり類似している格フレームをマージするためにクラスタリン
グを行う．

上記の第1段階の構築手法では構文解析を用いているために，基本的に格助詞の
付属している格要素を収集している．このため，得られる格フレームは，二重主
語構文，外の関係，格変化のような複雑な言語現象には対処できないという問題
がある．この問題に対処するために，上記で得られた格フレームを用いて再度テ
キストを解析し，新たな情報を格フレームに与える．新たに得られる情報は，1
回目の格フレーム構築では扱うことができなかった係助詞句（「〜は」や「〜も」）
や被連体修飾詞に関する関係である．

\begin{lingexample}
 \single{この車はエンジンが良い}{ガ２1}
\end{lingexample}

例えば，上例において，構文解析の段階では「車は」は解釈できなかったが，格
解析では「｛エンジン｝が　よい」という格フレームを用いることによって，格
フレームにガ格以外の格がないことから「車は」は2つ目のガ格であり，「｛エ
ンジン｝が　よい」は二重主語構文をとることがわかる．

\begin{lingexample}
 \single{その問題は彼が図書館で調べている}{ガ２2}
\end{lingexample}

この例文の「問題は」は，すでに得られている格フレーム「｛問題，課題｝を 
｛図書館｝で　調べる」のヲ格の用例群に合致するため，格解析ではヲ格と解析
されるだけで，新しい情報は得られない．同様に，被連体修飾詞は構文解析では
扱われないが，格解析では，格フレームのガ格，ヲ格などの用例と類似している
かどうか調べることによって解釈される．例えば，「業務を営む免許」の「免許」
は，格フレーム「｛銀行，会社｝が｛業務，ビジネス｝を　営む」のどの格の
用例とも類似せず，外の関係と呼ばれる関係をもっていると判定され，この情報
が格フレームに加えられる．

上記の手法を用いて，ウェブから収集した約5億日本語文から格フレームを構築し
た．約350CPUの計算機グリッドを用いてこの処理を行い，約1週間で格フレームを
構築することができた．この格フレームは約90,000用言からなる．その一部を表
\ref{例::格フレーム}に示す．


構文・格解析の統合的確率モデル

本論文で提案する構文・格解析統合モデルは，入力文がとりうるすべての構文構造
に対して確率的格解析を行い，もっとも確率値の高い格解析結果をもつ構文構造
を出力する．すなわち，入力文$S$が与えられたときの構文構造$T$と述語項構造$L$ 
の同時確率$P(T,L|S)$を最大にするような構文構造$T_{best}$と述語項構造
$L_{best}$を出力する．次のように，$P(S)$は一定であるので，本モデルは
$P(T,L,S)$を最大にすることを考える．
\begin{align}
 (T_{best}, L_{best}) & = \argmax{(T, L)}{P(T,L|S)} \nonumber \\
                      & = \argmax{(T, L)}{\frac{P(T,L,S)}{P(S)}} \nonumber \\
                      & = \argmax{(T, L)}{P(T,L,S)}
\end{align}


\subsection{構文・格解析の統合的確率モデルの概略}

本論文では，依存構造に基づく確率的生成モデルを提案する．本モデルは「節」
を基本単位とし，主節（文末の節）から順次生成していく．「節」とは，用言1つと，
それと関係をもつ格要素群を意味する．$P(T,L,S)$は，文に含まれる節$c_i$を生
成する確率の積として次のように定義する．
\begin{equation} \label{Formula::Division}
 P(T,L,S)  = \prod_{c_i \in S} P(c_i|b_{h})
\end{equation}
$n$は文$S$中に存在する節の数（＝用言数）であり，ここで$b_{h}$は節$c_i$の係り先
文節である．主節は係り先をもたないが，仮想的な係り先を$\mbox{EOS}$とする．

従来研究のほとんどは，文生成の確率を，2文節間の係り受け確率の積としていた
が，本研究では式(\ref{Formula::Division})のように，節，つまり用言と格要素
群を単位として生成するモデルとしている．そのため，複数の格要素を考慮して
係り受けを決定することができ，例(3)のような文も正しく解析できるようなモデ
ルとなっている．

例えば「弁当は食べて目的地に出発した．」という文を考える．「弁当は」が
「食べて」に係る場合には，2つの節「弁当は食べて」「目的地に出発した．」
があり，次の確率を考える．
\[
 P（\mbox{目的地に出発した．}|\mbox{EOS}） \times
	P（\mbox{弁当は食べて}|\mbox{出発した．}）
\]
「弁当は」が「出発した．」に係る場合には，2つの節「食べて」「弁当は目的
地に出発した．」があり，次の確率を考える．
\[
 P（\mbox{弁当は目的地に出発した．}|\mbox{EOS}） \times
	P（\mbox{食べて}|\mbox{出発した．}）
\]
本モデルは，これらのうちもっとも確率の高い構造を採用する．

節$c_i$は，述語項構造$\mathit{CS}_i$と用言タイプ$f_i$に分解して考える．用
言タイプとは，用言の活用や付属語列を意味する．そのため，述語項構造
$\mathit{CS}_i$に含まれる用言は原型である．係り先の文節$b_{h}$も同様に，
語$w_{h}$とタイプ$f_{h}$ に分けて考える．
\begin{align}
 P(c_i|b_{h}) & = P(\mathit{CS}_i, f_i|w_{h}, f_{h})  \nonumber\\
              & = P(\mathit{CS}_i|f_i,w_{h},f_{h}) \times P(f_i|w_{h},f_{h})  \nonumber\\
              & \approx P(\mathit{CS}_i|f_i,w_{h}) \times P(f_i|f_{h}) 
	\label{Formula::FirstDecomposition}
\end{align}
この近似は，用言は係り先文節のタイプには依存しない，また用言タイプは係り
先の語には依存しないと考えられるからである．

例えば，$P（\mbox{弁当は食べて}|\mbox{出発した．}）$は次のようになる．
\[
 P（\mathit{CS}（\mbox{弁当は食べる}）|\mbox{テ形},\mbox{出発する}）
	\times P（\mbox{テ形}|\mbox{タ形．}）
\]

ただし，本モデルにおいて，副詞，連体詞，および連体修飾句は述語項構造に入
れず，考慮しない．これらは用言に対して格関係を持たないので，用言格フレー
ムにおいて扱うことができず，生成することができないためである．これらの係
り先は，読点がなければ直近の係りうる文節とするなどといったルールに基づい
て決定する\cite{Kurohashi1994}．

式(\ref{Formula::FirstDecomposition})の$P(\mathit{CS}_i|f_i,w_{h})$を述語
項構造生成確率，$P(f_i|f_{h})$を用言タイプ生成確率と呼び，これらについて
次の2つの節で説明する．


\subsection{述語項構造生成確率}
\label{Section::述語項構造生成確率}

述語項構造の生成モデルは，その述語項構造にマッチする格フレームの選択と，
入力側の各格要素の格フレームへの対応付けを同時に行うモデルである．

述語項構造$\mathit{CS}_i$は，述語$v_i$，格フレーム$\mathit{CF}_l$，格の対
応関係$\mathit{CA}_k$の3つからなると考える．格の対応関係$\mathit{CA}_k$と
は，図\ref{Figure::Correspondence} に示すように，入力側の格要素と格フレー
ムの格との対応付け全体を表す．対応関係は図示のもの以外にも，「弁当は」を
ガ格に対応付ける可能性がある．述語項構造生成確率
$P(\mathit{CS}_i|f_i,w_{h})$は次のようになる．
\begin{align}
  P(\mathit{CS}_i|f_i,w_{h}) & = P(v_i,\mathit{CF}_l,\mathit{CA}_k|f_i,w_{h}) \nonumber \\
  & = P(v_i|f_i,w_{h}) \nonumber \\
  & \times P(\mathit{CF}_l|f_i,w_{h},v_i) \nonumber \\
  & \times P(\mathit{CA}_k|f_i,w_{h},v_i,\mathit{CF}_l) \nonumber \\
  & \hbox to105pt{$\approx P(v_i|w_{h})$\hfill}\mbox{（用言生成確率）}  \label{Formula::PA}\\
  & \hbox to105pt{$\quad {} \times P(\mathit{CF}_l|v_i)$\hfill}\mbox{（格フレーム生成確率）} 
	\nonumber \\
  & \hbox to105pt{$\quad {} \times P(\mathit{CA}_k|\mathit{CF}_l,f_i)$\hfill}\mbox{（格の対応関係生成確率）} \nonumber
\end{align}
この近似は，述語$v_i$はその係り先の語$w_{h}$のみに，格フレーム$\mathit{CF}_l$は
述語$v_i$のみに，格の対応関係$\mathit{CA}_k$は格フレーム$\mathit{CF}_l$と付属語列$f_i$に依
存すると考えられることによる．

\begin{figure}[b]
 \begin{center}
      \includegraphics{14-4ia4f1.eps}
  \caption{格の対応関係$\mathit{CA}_k$の例}
  \label{Figure::Correspondence}
 \end{center}
\end{figure}

用言生成確率と格フレーム生成確率は大規模コーパスの格解析結果から推定する．\unskip$P(\mathit{CA}_k|\mathit{CF}_l,f_i)$は，格の対応関係生成確率と呼び，以下で詳説する．


\subsubsection{格の対応関係生成確率}

格の対応関係$\mathit{CA}_k$を，格フレームの格スロット$s_j$ごとに考える．格スロッ
ト$s_j$に入力側の格要素（体言$n_j$, 格要素タイプ$f_j$）が対応付けられてい
るかどうかで場合分けすると，次のように書き換えることができる．
\begin{equation}
\begin{aligned}[b]
 P(\mathit{CA}_k|\mathit{CF}_l,f_i) 
  & = \prod_{s_j: A(s_j)=1} P(A(s_j) =1,n_j,f_j|\mathit{CF}_l,f_i,s_j) \\
  & \times \prod_{s_j: A(s_j)=0} P(A(s_j)=0|\mathit{CF}_l,f_i,s_j) 
\end{aligned}
\label{Formula::CCExample}
\end{equation}
ただし，$A(s_j)$ は，格スロット$s_j$に入力側格要素が対応付けられていれば
$1$，そうでなければ$0$をとる関数である．

式(\ref{Formula::CCExample})右辺第1項の各確率は次のように分解できる．
\begin{equation}
\begin{aligned}[b]
 P(A(s_j) & =1,n_j,f_j|\mathit{CF}_l,f_i,s_j) \\
  & = P(A(s_j)=1|\mathit{CF}_l,f_i,s_j) \times P(n_j,f_j|\mathit{CF}_l,f_i,A(s_j)=1,s_j) 
\end{aligned}
\label{Formula::CaseAndExample}
\end{equation}

この式の第1項と式(\ref{Formula::CCExample})第2項の各確率は，$f_i$には依存しな
いと考えられるので，それぞれ$P(A(s_j)=1|\mathit{CF}_l,s_j)$，
$P(A(s_j)=0|\mathit{CF}_l,s_j)$となる．これらは格スロット生成確率と呼び，大規模コー
パスの格解析結果から推定する．$P(n_j,f_j|\mathit{CF}_l,f_i,A(s_j)=1,s_j)$は格要素
生成確率と呼ぶ．

例えば，$P（CS（\mbox{弁当は食べる}）|\mbox{テ形},\mbox{出発する}）$について
考える．「食べる」のある格フレーム$CF_{\mathrm{食べる1}}$がガ格とヲ格を
もっているならば，この格フレームを用いたときの述語項構造生成確率としては，
「弁当は」をガ格またはヲ格に対応付けるときの2つを考えることになる．以下
に「弁当は」をヲ格に対応付けるときの確率を示す．
\begin{align*}
 P（CS（\mbox{弁当は食べる}）|\mbox{テ形},\mbox{出発する}）
 & = P（\mathrm{食べる|出発する}）\\
 & \times P（CF_{\mathrm{食べる1}}|\mathrm{食べる}）\\
 & \times P（A（\mathrm{を}）=1|CF_{\mathrm{食べる1}},\mbox{を}）\\
 & \times P（A（\mathrm{が}）=0|CF_{\mathrm{食べる1}},\mbox{が}）\\
 & \times P（\mathrm{弁当}, \mathrm{は}|CF_{\mathrm{食べる1}},\mbox{テ形},A（\mathrm{を}） =1,\mbox{を}）
\end{align*}


\subsubsection{格要素生成確率}
\label{Section::用例生成確率}

格要素の体言$n_j$と格要素タイプ$f_j$を生成する確率は独立であり，表層格の
解釈は格フレームに依存しないと考え，格要素生成確率は以下のように近似する．
\begin{equation}
  P(n_j,f_j|\mathit{CF}_l,f_i,A(s_j)=1,s_j) \approx P(n_j|\mathit{CF}_l, A(s_j)=1,s_j) 
	\times P(f_j|s_j,f_i) 
	\label{Prob::CaseComponent}
\end{equation}
$P(n_j|\mathit{CF}_l,A(s_j)=1,s_j)$は用例生成確率と呼び，格フレーム自体から推定す
る．

格要素タイプ$f_j$としては，表層格$c_j$，読点の有無$p_j$，提題助詞「は」
の有無$t_j$の3つを考慮する．
\begin{align}
 P(f_j|s_j, f_i) & = P(c_j,t_j,p_j|s_j,f_i) \nonumber \\
  & =  P(c_j|s_j,f_i) \nonumber \\
  & \times P(p_j|s_j,f_i,c_j) \nonumber \\
  & \times P(t_j|s_j,f_i,c_j,p_j) \nonumber \\
  & \hbox to84pt{$\approx P(c_j|s_j)$\hfill}\mbox{（表層格生成確率）} \\
  & \hbox to84pt{$\quad {} \times P(p_j|f_i)$\hfill}\mbox{（読点生成確率）} \nonumber \\
  & \hbox to84pt{$\quad {} \times P(t_j|f_i,p_j)$\hfill}\mbox{（提題助詞生成確率）} \nonumber
\end{align}
この近似は，$c_j$は$s_j$のみに，$p_j$は$f_i$のみに，$t_j$は$f_i$と$p_j$
に依存すると考えられるためである．表層格生成確率は，表層格を解釈した格を
タグ付けした京都テキストコーパス\cite{Kawahara2002j}を用いて推定する．

日本語では，読点や提題助詞はそれらの属する文節が遠くに係る場合に用いられ
やすいという傾向がある．このような傾向を考慮して，読点生成確率
$P(p_j|f_i)$と提題助詞生成確率$P(t_j|f_i,p_j)$を以下のように定義する．
\begin{align}
 P(p_j|f_i)     & = P(p_j|o_i,u_i) \\
 P(t_j|f_i,p_j) & = P(t_j|o_i,u_i,p_j)
\end{align}
$o_{i}$は，対象格要素がほかの係り先候補を越えて$v_i$に係る場合に$1$をと
り，それ以外では$0$となる．$u_i$は，節の区切れとしての強さであり，強い節
ほど読点や提題助詞をもつ句を受けやすい．節の強さとしては，南による節の分
類\cite{Minami1993}を参考にして設定した5段階を考える．


\subsection{用言タイプ生成確率}
\label{Section::付属語列生成確率}

用言タイプ生成確率$P(f_i|f_{h})$は，文節$b_{h}$のタイプを条件にした
ときに，それに係っている節$c_i$の用言タイプを生成する確率である．この確
率は，節$c_i$が連用節であるか連体節であるかで次のように異なる．

節$c_i$が連用節の場合は，節間の係り受けに大きな影響を及ぼすと考えられる
読点の有無と連用節のタイプ（強さ）を考慮する．これに加えて，$c_i$がほかの
係り先候補を越えて$b_{h}$に係るかどうかを考慮する．
\begin{equation}
 P_{\mathit{VBmod}}(f_i|f_{h}) = P_{\mathit{VBmod}}(p_i,u_i|p_{h},u_{h},o_{h})
\end{equation}

節$c_i$が連体節である場合は，受側すなわち体言のタイプには依存しないと考
え，次のように定義する．
\begin{equation}
 P_{\mathit{NBmod}}(f_i|f_{h}) = P_{\mathit{NBmod}}(p_i|o_{h})
\end{equation}



