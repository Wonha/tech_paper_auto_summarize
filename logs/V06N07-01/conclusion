考察と今後の課題
\label{sec:discussion}

\subsubsection*{確率推定法と尺度$L$}

本稿の実験では，(\ref{eq:n})式の確率を推定するために，
\ref{sec:overview}節に述べたような$n$の値と確率推定法を用いたが，確率
推定の方法には，最尤推定やバックオフスムージングの他にも様々な方法があ
り，さらに，バックオフスムージングについても様々な discounting の方法
があるので，これらを適用した場合の尺度$L$の過分割検出精度について網羅
的に調べることを今後の課題としたい．

本稿でこのことを網羅的に調べなかった理由は，本稿での主要な目的は，
\ref{sec:introduction}章で述べたように，従来の研究で人手で発見されるこ
とが前提となっていた過分割を，尺度$L$を用いることにより半自動的に抽出
できることを示すことにあったので，そのことを示すためには，なんらかの
(代表的な)確率推定法を利用した場合について示すだけで十分であったからで
ある．すなわち，確率推定法の優劣(尺度$L$と併用したときの過分割検出精度
の良否)を調べることは副次的な事柄であったからである．

なお，予備実験として，京大コーパスを利用し，
\begin{itemize}
\item n=2，または，n=3
\item Witten-Bell discounting によるバックオフスムージング，または，最尤推定
\end{itemize}
から作られる四つの組合せのそれぞれについて(\ref{eq:n})式の確率を推定し，
尺度$L$による分割点調査率を調べた結果は，教師あり学習と教師なし学習の
双方について，$n=2$に最尤推定を組み合わせたものと$n=3$にバックオフスムー
ジングを組み合わせたものとがほぼ等しく良く(教師なし学習では前者が若干
良く，教師あり学習では後者が若干良い)，その他の組み合わせ($n=3$と最尤
推定および$n=2$とバックオフスムージング)は，この二つよりも劣っていた．
このような結果の原因としては，$n$や確率推定法の違いの他に，訓練データ
のサイズが約1万文と比較的少ないことが影響していると考えられる．

\subsubsection*{確率に基づく形態素解析システムへの適用}

確率に基づいた形態素解析システム(あるいは単語分割システム)には，文字の
連鎖確率に基づいたシステム\cite{yamamoto97,oda98}と単語や品詞の連鎖確
率に基づいたシステム\cite[など]{nagata94,itoh97,mori98}がある．

\cite{yamamoto97,oda98}では，本稿とは実現手法は異なるが，形態素境界の
情報を文字に取り込むことにより，文字列により形態素列を表現している．そ
して，入力文に対して，(形態素境界情報を含む)文字の連鎖確率が最大になる
ような解を求めることにより，最適な形態素列を得ている．一方，\cite[など]
{nagata94,itoh97,mori98}では，単語や品詞n-gramに基づいて形態素解析をし
ており，文字情報を直接用いているのは未知語モデルに限定されている．

これらの形態素解析システムの解析結果からも尺度$L$が過分割を検出できる
かを調べることは今後の課題であるが，\cite{yamamoto97,oda98}と\cite[な
ど] {nagata94,itoh97,mori98}を比べた場合，前者は，文字の連鎖確率を直接
用いて形態素列への分割を行なっている点が，尺度$L$と極めて類似している
ため，前者に尺度$L$を適用した場合の過分割検出精度は，(文字レベルでの分
割の最適化を行なっていない)後者に適用した場合と比較して劣ることが予想
される．しかし，\cite[など] {nagata94,itoh97,mori98}の品詞や単語の
n-gramに基づくシステムに尺度$L$を適用した場合についても，規則に基づく
形態素解析システムに比較すれば，最適な形態素列を求めるときに，可能な分
割を相互に比較し最高確率のものを出すという形で，尺度$L$に用いた情報が
既に用いられているとも言えるため，尺度$L$の有効性は低いと予想される．

\subsubsection*{分割不足の検出}

筆者は，予備実験として，実験1,2と同様の確率推定法で，JUMANにより解析さ
れた京大コーパスB全体を訓練およびテストコーパスとして，教師なし学習で
の確率推定値を用い，尺度$L$により分割不足の検出を試みた．つまり，尺度
$L$の値が小さい位置が形態素として結合されている場合について，それが実
際に分割不足かを確かめた．

その結果は，分割不足の再現率が10％の時点で，既に適合率が4％であり，実
験2における，再現率が10％のときの適合率が47％と比べて非常に劣っていた．

その理由の一つは，形態素解析システム中の形態素に比較的長い単位が多く，
かつ，分割不足として抽出されたものの多くが，その長い単位の形態素を短い
単位に分割しようとしているためである．たとえば，分割不足として抽出され
たものの上位には，'/'が候補位置とすると，「穴を/あけた」「目を/見張る」
「あっという/間」などがある．

このような場合と，明確に間違いである分割不足とを区別することは尺度$L$
には不可能なので，尺度$L$により分割不足を検出するのは，過分割の場合ほ
どには上手くいかない．

おわりに
\label{sec:conclusion}

本稿では，形態素解析結果から過分割を検出する統計的尺度を提案した．その
尺度は，文字列に関する尺度であり，文字列が分割される確率と分割されない
確率との比に基づいていて，分割されにくい文字列ほど大きな値となる．した
がって，この値が大きい文字列は過分割されている可能性が高い．

提案尺度を使うことにより，規則に基づいた形態素解析システムの解析結果か
ら高精度で過分割を検出できたし，人手で修正されたコーパスに残る過分割も
検出できた．また，提案尺度の過分割検出精度は，その他の統計的尺度と比べ
て高かった．これらのことは，提案尺度が，形態素解析システムの高精度化に
役立つこと，及び，コーパス作成・整備の補助ツールとして役立つことを示し
ている．

今後は，提案尺度を実際に使い，形態素解析システムの精度向上やコーパスの
整備に役立てたい．


\acknowledgment

本稿に対して有益なコメントを下さった筑波大学山本幹雄助教授，および，日
頃議論して下さる信州大学音声信号処理研究室の各位に感謝する．本稿では，
一般に公開されている，JUMAN，茶筌，すもも，京都大学テキストコーパス，
CMU-Cambridge Toolkitを利用させていただいた．このことに対して関係者の
方々に感謝する．

