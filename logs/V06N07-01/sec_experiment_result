三つの実験を行った．
実験1では，定性的な評価として，種々の形態素解析システムの解析結果，および，人手修正されたコーパスについて尺度[MATH]を適用し，目視により適用結果を評価した．
実験2では，訓練コーパスのサイズを変えたときの，尺度[MATH]の過分割検出精度を定量的に評価した．
実験3では，五つの尺度(尺度[MATH]/相互情報量/尤度比/改良Dice係数[CITE]/Yates補正された[MATH])について過分割の検出精度を定量的に比較した．
尺度[MATH]を求めるためには，([REF_eq:n])式の確率を求める必要があるので，形態素に分割された訓練コーパスが必要である．
そのようなコーパスとしては，形態素解析システムにより分割されたコーパスをそのまま用いる場合(教師なし学習)と，形態素解析結果の誤りを人手で修正したコーパスを用いる場合(教師あり学習)の二通りが考えられる．
そのため，実験1,2,3では，この二つの場合について，尺度[MATH]の過分割検出精度などを調べた．
([REF_eq:n])式の確率を求めるには，[MATH]を設定し，かつ，確率推定法も適当に決める必要がある．
そのために，本稿では，実験1と実験2においては，n-gram確率推定のためのツールとして広く使われているCMU-Cambridge Toolkit[CITE]を用いて，[MATH]の場合について，バックオフスムージングにより推定した．
このときのディスカウント法はWitten-Bell discounting[CITE]を用い，カットオフは，文字バイグラムと文字トライグラムの双方で1とした．
一方，実験3においては，最尤推定により求めた確率により尺度[MATH]を計算した．
その理由は，尺度[MATH]以外の尺度においては，通常，最尤推定を用いて，確率を計算しているので，それに合せるためである．
また，比較を簡単にするために，[MATH]の場合について各種の尺度を比較した．
実験1,2,3で共通に用いるコーパスは京都大学テキストコーパスversion2.0[CITE]である．
京都大学テキストコーパスは，CD-毎日新聞95年度版から約2万文を抽出したものであり，形態素・構文解析されている．
このコーパスを均等に2分割し，実験に用いた．
以下では，その一方を京大コーパスAと呼び，他方を京大コーパスBと呼ぶ．
京大コーパスAは主に確率推定のための訓練コーパスとして用い，京大コーパスBは主に過分割の検出精度を評価するためのテストコーパスとして用いた．
実験1では，定性的な評価として，種々の形態素解析システムの解析結果，および，人手修正されたコーパスについて尺度[MATH]を適用し，目視により適用結果を評価した．
教師なし学習では，確率推定用の訓練コーパスと過分割検出用のテストコーパスとが同一である．
つまり，確率を推定したコーパス中における過分割を検出する．
このときのコーパスとしては，京大コーパスBとEDR日本語コーパスversion 1.5[CITE]の全文を用いた．
なお，EDR日本語コーパスは，新聞・雑誌・辞典などの流通文書から1文単位でとられた約21万文からなるコーパスであり，各文は，形態素・構文・意味解析されている．
これらのコーパスにおける生の文を分割する形態素解析システムとしては，公開されている形態素解析システムのうちから，JUMAN version 3.5[CITE]，茶筅version 1.51[CITE],すももversion 1.3[CITE]を用いた．
これらの形態素解析システムは，全て，規則に基づいて形態素解析をするものである．
なお，これらの形態素解析システムを用いるときには，ただ一つの(ベストの)解析結果を出力させた．
これらのコーパスと形態素解析システムとの組み合わせは，EDRコーパスに対しては，三つの形態素解析システム全てを適用したが，京大コーパスBについては，JUMANのみを適用した．
また，二つのコーパスの元々の分割(人手修正済みの分割)についても試した．
すなわち，全部で6種の形態素分割に対して尺度[MATH]を適用した．
教師あり学習では，確率推定用の訓練コーパスと過分割検出用のテストコーパスとが異なる．
実験1では，京大コーパスAの元々の分割(JUMANの解析結果を人手修正したもの)を訓練データとして([REF_eq:n])式の確率を推定した．
そして，その推定値を利用して，JUMANにより形態素解析された京大コーパスBに対して尺度[MATH]を適用した．
7種(=教師なし6種+教師あり1種)の形態素分割のそれぞれに対して，その全ての分割点について，前後の形態素から尺度[MATH]を計算した．
たとえば，「休/憩室/は/広い/。
」のように分割されている文については，四つの分割点において，それぞれ，[MATH]，[MATH]，[MATH]，[MATH]を計算した．
このとき，([REF_eq:n])式の確率は，[REF_sec:overview]節で述べたように，[MATH]としてバックオフスムージングにより計算した．
7種の形態素分割のそれぞれに対して，全ての分割点を尺度[MATH]により降順に(同一尺度値の場合はランダムにtieを解消して)ソートし，その上位から異なり150個を選んだ．
そして，それぞれの異なりについて，一個の分割点を無作為に抽出し，それが過分割であるかを判定した．
なお，判定は筆者による．
判定した150個の分割点について，それが実際に過分割であった数を表[REF_tab:errs]に示す．
表から分かるように，これら150個の中に過分割が占める割合は非常に高い．
たとえば，表[REF_tab:errs]では，茶筅には128個の過分割がある．
一方，平均的には，茶筌の分割が過分割であるのは，1.5％以下であると言ってよい．
つまり，茶筅の150個の分割点のうちで，過分割は，平均的には，[MATH]個以下である．
よって，茶筅の解析結果から128個の過分割を検出するためには，平均的には，[MATH]個以上の分割点を調べなければならないことになる．
同様なことが，他の形態素解析システムによる分割結果，あるいは，人手で修正された分割結果についても言える．
これより，尺度[MATH]を用いることにより，形態素解析結果から過分割を効率的に抽出できるといえる．
なお，表[REF_tab:errs]において，JUMANで解析された京大コーパスBからの過分割検出結果について，教師なし学習の場合と教師あり学習の場合とを比べると，教師あり学習の方が検出個数が多い．
これは，教師あり学習の方が，([REF_eq:n])式の値を正確に推定できるからであると解釈できる．
さらに，教師なし学習の場合の6種の形態素分割のそれぞれについて，上位異なり150個中の過分割から上位12個の過分割を付録の表[REF_tab:edr]と表[REF_tab:kyoto2.0]に示す．
表で「数」とある欄には，そのような過分割を含む文の数がある．
また，「形態素/品詞」とある二つの欄は，尺度[MATH]を計算した分割点の前後の形態素と品詞を示す．
なお，品詞は，それぞれの形態素解析システムの品詞である．
また，表の解析結果は，各解析システムが一つだけ解析結果を出力した場合のものである．
もし，複数の解析結果も出力するようにすれば，表中の文について，当該の形態素解析システムが正解を含む解を出すことはある．
これらの表に示されている過分割の中には，何らかの規則性があるとすぐに分るものもある．
たとえば，EDRコーパスの元々の分割に含まれる過分割(表[REF_tab:edr])においては，「引き下げ/よう」が「引き下/げ/よう」と分割されていたり，「掲げ/、」が「掲/げ/、」のように分割されるなど，動詞の語幹が分割される例が大半である．
一方，EDRコーパスに対する茶筌の過分割では，「結果」が「結(普通名詞) /果(普通名詞)」と分割されていたり，「考えて」が「考(普通名詞)/えて(普通名詞)」と分割されているが，このような例に含まれる規則性は，もしあったとしても，容易には分らない．
いずれにしろ，尺度[MATH]を使うことにより，ある程度の量の，形態素解析結果の過分割が，教師なし学習により容易に抽出できることが分かる．
このような例を集めるのは人手では手間が掛る．
また，尺度[MATH]は人手修正後のコーパスに残る過分割も検出できるため，コーパス作成・整備の際の補助ツールとしても役立つと考える．
また，付録の表[REF_tab:cv]には，教師あり学習の場合について，尺度[MATH]の値が上位12個の過分割を示す．
ここで，教師あり学習の結果である表[REF_tab:cv]におけるJUMANの過分割と，教師なし学習の結果である表[REF_tab:kyoto2.0]におけるJUMANの過分割とを比べると，表[REF_tab:cv]においては「護/煕」など固有名詞が占める割合が多いが，表[REF_tab:kyoto2.0]では固有名詞は一つ(「若/乃/花」)しか存在しないことがわかる．
表[REF_tab:kyoto2.0]に固有名詞が少ないのは，固有名詞は未知語である場合が他の品詞と比べて多いため，常に過分割される場合も多くなり，その結果として尺度[MATH]の値が小さくなる場合が多いためである．
このように，形態素解析システムが常に過分割してしまうような場合を検出するためには，人手修正済みコーパスが必要であると言える．
教師なし学習により何か統計的に興味のある言語現象を発見するような応用[CITE]においては，新聞記事などの大規模なコーパスが比較的用意に入手できるので，訓練コーパスのサイズは深刻な問題ではない．
これは本稿における過分割検出の場合でも同様である．
しかし，教師あり学習の場合には，訓練コーパスを構築するのはコストが掛るため，なるべく小さな訓練コーパスであることが望ましい．
そこで，実験2では，主に教師あり学習の場合を対象として，訓練コーパスのサイズと過分割検出精度との関係を調べた．
ただし，教師なし学習の場合についても，教師あり学習と比較するために，訓練コーパスのサイズと過分割検出精度との関係を同様に調べた．
確率推定用の訓練コーパスとしては京大コーパスAを用い，過分割検出の精度を調べるテストコーパスとしてはJUMANにより分割された京大コーパスBを用いた．
このことは，教師あり学習と教師なし学習とで共通である．
ただし，教師あり学習では京大コーパスAの元々の分割から([REF_eq:n])式の確率を推定し，教師なし学習では，京大コーパスAをJUMANにより形態素解析した結果から([REF_eq:n])式の確率を推定した．
テストコーパスである京大コーパスBについて，その元々の分割を正解と看倣して，分割の正誤を判定したときの統計を表[REF_tab:stat]に示す．
表[REF_tab:stat]より，分割の間違いに占める過分割は62.0％である．
加えて，過分割の周辺には分割不足も起りやすいと言えるので，過分割が検出できれば，その周囲も調べることにより，分割誤りの多くが検出できると言える．
しかし，分割点の再現率(=100[MATH](一致した分割点の数/正解における分割点の数))と適合率(=100[MATH](一致した分割点の数/JUMANによる分割点の数))は，それぞれ，99.7％，99.5％と非常に高い．
また，JUMANの分割点全体の中で過分割である分割点は0.5％(=100％[MATH]適合率)であるので，過分割を見付けるのは人手では困難であると考える．
約1万文からなる訓練コーパスから，約1000，2000, .
..
, 10000文を選び，それぞれの場合について，[MATH]としてバックオフスムージングにより([REF_eq:n])式の確率を推定し，それを利用して約1万文からなるテストコーパスにおける全分割点の尺度[MATH]の値を計算した．
そして，全ての分割点を尺度[MATH]により降順にソートし，上位の分割点から，過分割かどうかを，テストコーパスの元々の分割を正解として調べた．
まず，全訓練データを使用した場合についての実験結果を述べ，次に訓練データを1000文ずつ増加した場合についての実験結果を述べる．
図[REF_fig:10000]には，約1万文の訓練データ全てを使って確率推定した場合について，教師あり学習と教師なし学習のそれぞれについて，過分割検出の再現率(percent recall)に対する適合率(percent precision)および分割点調査率(percent examination)を示す．
ここで，
図[REF_fig:10000]の教師あり学習の場合の適合率(supervised-precision)および教師なし学習の場合の適合率(unsupervised-precision)のプロットから分かるように，上位における過分割検出の適合率は非常に高い．
たとえば，再現率が10.0％のとき，適合率は，教師あり学習の場合に90.5％であり，教師なし学習の場合に46.8％であるが，これらは，JUMANの分割点全体の中で過分割が占めるパーセンテージである0.5％の，180倍以上，および，90倍以上である．
この適合率の高さは，実験1での結果を裏付けるものである．
また，図[REF_fig:10000]の教師あり学習の場合の分割点調査率(supervised-examination)および教師なし学習の場合の分割点調査率(unsupervised-examination)から分かるように，一部の分割点を調べるだけで多くの過分割を検出できると言える．
たとえば，全体の過分割のなかから再現率50％で過分割を見付けるためには，教師あり学習の場合には，全分割点の0.5％を調べればよく，教師なし学習の場合には，全分割点の2.0％を調べればよい．
さらに，90％の過分割を見付けるためには，教師あり学習の場合には，全分割点の7.8％を調べればよく，教師なし学習の場合には，全分割点の12.2％を調べればよい．
一方，もし，無作為に分割点を調べるという方法により，過分割を検出しようとしたならば，50％の過分割を見付けるためには，平均的には，全分割点の50％を調べる必要があり，90％の過分割を見付けるためには，90％の分割点を調べる必要がある．
以上より，尺度[MATH]を使うことにより，過分割の検出が効率良くできると言える．
なお，再現率，適合率，分割点調査率の間には
という関係が成立する．
ただし，[MATH]はテストコーパスに固有の定数であり，
([REF_eq:rel])式から，分割点調査率と再現率が決まれば適合率が決まることが分かる(e.g.,分割点調査率が小さければ適合率は高い)．
そのため，以下では，再現率に対する分割点調査率のみに基づいて過分割の検出精度を評価する．
そして，同一の再現率に対して分割点調査率が小さいとき過分割の検出精度が高いと言い，その逆のときに過分割の検出精度が低いと言うことにする．
図[REF_fig:incr-exam]には，過分割検出の再現率が25,50,75％の場合(recall25,recall50,recall75)について，教師あり学習の場合と教師なし学習の場合における，訓練文数(Num. of training sentences)と分割点調査率の関係を示す．
図[REF_fig:incr-exam]から，教師あり学習の場合(supervised-recall25,50,75)については，訓練文数が増加すると，再現率が50％と75％においては，分割点調査率が明確に減少していると言える．
また，再現率が25％についても緩やかに分割点調査率は減少している．
一方，教師なし学習の場合(unsupervised-recall25,50,75)については，訓練文数が増えていっても，2000文以上については，分割点調査率は(若干の変動はあるが)ほぼ横ばいである．
このことは，教師あり学習については，訓練データが多くなれば多くなるだけ，([REF_eq:n])式の確率を精密に推定できるが，教師なし学習については，訓練データが多くなったとしても，その確率推定に対する効果は，教師あり学習の場合に比べれば，小さいことを示している．
実験3では，尺度[MATH]，相互情報量，尤度比，改良Dice係数[CITE]，Yates補正された[MATH]，の五つの尺度について，過分割の検出精度を比較した．
ここで，尤度比，改良Dice係数，Yates補正された[MATH]は，[CITE]において，有用な括弧表現を抽出するために有効であるとされた尺度である．
また，尤度比は，[CITE]でも，2文字間の連関の尺度として，漢字列の分割に有効であることが示されている．
以下では，まず，本実験のテストコーパスとした京大コーパスBについて，そこでの分割点の出現頻度の統計について述べる．
この出現統計は，あとで，各尺度間の過分割検出精度の違いを説明するときの資料に用いる．
次に，各尺度を定義し比較する．
形態素[MATH]の最後の文字を[MATH],形態素[MATH]の最初の文字を[MATH]とし，[MATH]と[MATH]に挟まれるような分割点を，前後1文字で区別される分割点と呼ぶ．
実験3では，分割点といえば，前後1文字で区別される分割点のこととする．
つまり，「ab/cd」と「xb/cy」のような分割点は，分割点の前後1文字が同じであるので，区別しないで同一タイプの分割点として扱う．
表[REF_tab:freq]は，テストコーパスとした京大コーパスBにおける分割点について，過分割である分割点とそうでない分割点のそれぞれに対して，出現頻度ごとの，分割点の異なり数などを調べたものである．
ここで，分割点の総数を[MATH],頻度[MATH]における分割点の異なり数を[MATH]とすると，頻度[MATH]における延べ数は[MATH]であり，[MATH]である．
表[REF_tab:freq]では，頻度[MATH]における「延べ％」は[MATH]であり，「累積％」は[MATH]である．
[htbp]
表[REF_tab:freq]から，過分割である分割点の出現頻度は，そうでない場合に比べて，低頻度であると言える．
これは，過分割である分割点の数自体が少ないことが主な原因である．
また，過分割である場合とそうでない場合の分布の様子を比べると，過分割である分割点の場合には，頻度が1か2であるような場合が全体の50％以上を占めていることから分かるように，低頻度の方に分布が偏っている．
まず，[MATH]として，([REF_eq:n])式を用いて，([REF_eq:L])式を変形すると，
となる．
一方，([REF_eq:mi])式を同様に変形すると
という無意味な値になるので，区切り文字とそれに隣接する文字は特に強く結合すると仮定し，
のような変形をすると，
となる．
なお，以下では，[MATH],[MATH]とする．
([REF_eq:MIn2])式から，[MATH]においては，相互情報量[MATH]は，[MATH]と[MATH]をそれぞれ一つの項と看做せば，この2項に関する通常の相互情報量の式と一致することがわかる．
そこで，尤度比，改良Dice係数，Yates補正された[MATH]についても，これら2項に基づいて，その値を計算する．
以下では，[CITE]に基づいて，尤度比，改良Dice係数，Yates補正された[MATH]を定義する．
また，尺度[MATH]と相互情報量についても，確率を最尤推定した形で定義する．
各尺度を定義する準備として，まず，[MATH]は，分割表で示すと
である．
より厳密には，[MATH]を文字列の頻度とし，[MATH]を，[MATH]と[MATH]を含む任意の文字としたとき，
である．
また，
である．
ここでの「尤度比」は，[MATH]と[MATH]の2項が従属とした場合と独立とした場合との最尤推定量による尤度比であり，
である．
なお，上式では，分割点のソートに無関係な項は除いてある．
[MATH]は，2項が従属して生起する度合が強いとき，正で大きな値をとる．
しかし，これだけでは必ずしも共起強度が強いとは言えない．
たとえば，
と
は同じ[MATH]となる．
これらのうち前者は共起強度が強いが，後者は弱い(反発している)．
このことを考慮して，[MATH]のときには，[CITE]と同様に，Yuleの[MATH]の符合を付けることにより，分割点をソートした．
[MATH]と同様に独立性の判定に用いられる尺度である．
なお，[MATH]に関しても，[MATH]と同様な理由から，Yuleの[MATH]の符合を付けて分割点をソートした．
[CITE]で，対訳単語間の類似度として，提案されている尺度である．
([REF_eq:MIn2])式より，分割点のソートに無関係な項は除くと，
([REF_eq:Ln2])式より，分割点のソートに無関係な項は除くと，
ここで，上記の各尺度について，もし，[MATH]，あるいは，[MATH]となる場合には，それぞれを0.1として計算した．
各尺度について，JUMANにより形態素解析された京大コーパスBを訓練およびテストコーパスとして，過分割の再現率に対する分割点調査率を評価した結果を図[REF_fig:unsup-cmp]に示す．
図[REF_fig:unsup-cmp]から分るように，改良Dice係数(Dice)，[MATH](lambda)，[MATH](chi＾2)の分割点調査率は，[MATH]や[MATH]と比べて大きい．
すなわち，過分割検出精度は低い．
この原因は，これらの尺度が，統計的に有意と言えないような低頻度の共起関係をノイズとして排除するような尺度であるからである．
すなわち，頻度が1とか2とかの共起関係の尺度値は，これらの尺度では大きくならないため，(表[REF_tab:freq]に示されるように)低頻度である過分割が排除されるためである．
このような性質は，[CITE]や[CITE]や[CITE]のような，一般的に共起強度が高い共起関係を必要とするような応用に対しては適していたが，低頻度事象である過分割を検出するには適さない．
一方，[MATH]の過分割検出精度は，再現率50％程度のところまでは，[MATH]とほぼ同じである(実際には若干低い)．
これは，[MATH]が低頻度の共起関係を過大評価する[CITE]からであろう．
つまり，再現率が低いところでは，低頻度で，かつ，共起強度の強い表現を選択的に拾ってくるが，そのようなものは過分割であることが多いため，検出精度が高いと解釈できる．
しかし，再現率が上ってくると，比較的頻度が高い過分割も増えてくるため，共起強度だけでは，過分割なのか，そうでない分割かが区別できなくなり，検出精度が下がると言える．
これらの尺度に対して，[MATH]は，分割されるか分割されないかを直接モデル化した尺度であるため，再現率が高くなっても検出精度が高いものと考える．
なお，筆者は，予備実験として，相互情報量とYate補正した[MATH]を，隣接する形態素間について，(文字ではなく)形態素を単位とする2項関係に基づいて計算してみたが，その性質は尺度[MATH]とは非常に異なっていた．
相互情報量の性質とYate補正した[MATH]の性質とは，互いに若干は異なるが，おおまかには，二つの尺度とも，固有名詞(「福沢/諭吉」など)や四字熟語(「不眠/不休」など)を取ってくる傾向が強かった．
これらの隣接形態素は，それ自体は有用な表現ではあるが，これらの隣接形態素間の分割が間違っているわけではないので，本稿での目的である過分割の検出には適さない．
その他，共起や定型表現を抽出する研究として，特に文字列レベルに関係するものでは，[CITE]がある．
これらの研究では，大量の生テキストコーパスから，統計量を用いることにより，「に関して」や「に対しては」などの定型的な表現を抽出する．
これらの表現は有用な表現ではあるが，「に対して」を「に/対/し/て」と分割しても，過分割ではないことからも分るように，これらの手法は，本稿での目的である過分割の検出には適さない．
各尺度に対して，京大コーパスAの元々の分割を訓練コーパス，京大コーパスBをテストコーパスとして，過分割の再現率に対する分割点率調査を評価した結果を図[REF_fig:sup-cmp]に示す．
図[REF_fig:sup-cmp]では，図[REF_fig:unsup-cmp]と同様に尺度[MATH]の分割点調査率が一番小さい．
そして，図[REF_fig:sup-cmp]と図[REF_fig:unsup-cmp]を比べると，尺度[MATH]については，図[REF_fig:sup-cmp]の教師あり学習の方が図[REF_fig:unsup-cmp]の教師なし学習の場合よりも分割点調査率が小さい．
一方，尺度[MATH]以外の尺度については，教師あり学習の方が分割点調査率は大きくなっている．
これは，教師あり学習の場合の方が，教師なし学習の場合よりも，テストコーパスにおいて，過分割の前後の文字の共起強度が小さいことを示している．
この理由は，教師あり学習においては，訓練コーパスで過分割であるような分割点が人手により除かれているため，テストコーパスで過分割であるような分割点は訓練コーパスで出現することが稀となり，その結果，共起強度が小さくなるからである．
このことから，尺度[MATH]以外の尺度については，教師あり学習をしても過分割検出精度が高くならないことが分かる．
三つの実験を行った．
実験1では，定性的な評価として，種々の形態素解析システムの解析結果，および，人手修正されたコーパスについて尺度[MATH]を適用し，目視により適用結果を評価した．
実験2では，訓練コーパスのサイズを変えたときの，尺度[MATH]の過分割検出精度を定量的に評価した．
実験3では，五つの尺度(尺度[MATH]/相互情報量/尤度比/改良Dice係数[CITE]/Yates補正された[MATH])について過分割の検出精度を定量的に比較した．
尺度[MATH]を求めるためには，([REF_eq:n])式の確率を求める必要があるので，形態素に分割された訓練コーパスが必要である．
そのようなコーパスとしては，形態素解析システムにより分割されたコーパスをそのまま用いる場合(教師なし学習)と，形態素解析結果の誤りを人手で修正したコーパスを用いる場合(教師あり学習)の二通りが考えられる．
そのため，実験1,2,3では，この二つの場合について，尺度[MATH]の過分割検出精度などを調べた．
([REF_eq:n])式の確率を求めるには，[MATH]を設定し，かつ，確率推定法も適当に決める必要がある．
そのために，本稿では，実験1と実験2においては，n-gram確率推定のためのツールとして広く使われているCMU-Cambridge Toolkit[CITE]を用いて，[MATH]の場合について，バックオフスムージングにより推定した．
このときのディスカウント法はWitten-Bell discounting[CITE]を用い，カットオフは，文字バイグラムと文字トライグラムの双方で1とした．
一方，実験3においては，最尤推定により求めた確率により尺度[MATH]を計算した．
その理由は，尺度[MATH]以外の尺度においては，通常，最尤推定を用いて，確率を計算しているので，それに合せるためである．
また，比較を簡単にするために，[MATH]の場合について各種の尺度を比較した．
実験1,2,3で共通に用いるコーパスは京都大学テキストコーパスversion2.0[CITE]である．
京都大学テキストコーパスは，CD-毎日新聞95年度版から約2万文を抽出したものであり，形態素・構文解析されている．
このコーパスを均等に2分割し，実験に用いた．
以下では，その一方を京大コーパスAと呼び，他方を京大コーパスBと呼ぶ．
京大コーパスAは主に確率推定のための訓練コーパスとして用い，京大コーパスBは主に過分割の検出精度を評価するためのテストコーパスとして用いた．
実験1では，定性的な評価として，種々の形態素解析システムの解析結果，および，人手修正されたコーパスについて尺度[MATH]を適用し，目視により適用結果を評価した．
教師なし学習では，確率推定用の訓練コーパスと過分割検出用のテストコーパスとが同一である．
つまり，確率を推定したコーパス中における過分割を検出する．
このときのコーパスとしては，京大コーパスBとEDR日本語コーパスversion 1.5[CITE]の全文を用いた．
なお，EDR日本語コーパスは，新聞・雑誌・辞典などの流通文書から1文単位でとられた約21万文からなるコーパスであり，各文は，形態素・構文・意味解析されている．
これらのコーパスにおける生の文を分割する形態素解析システムとしては，公開されている形態素解析システムのうちから，JUMAN version 3.5[CITE]，茶筅version 1.51[CITE],すももversion 1.3[CITE]を用いた．
これらの形態素解析システムは，全て，規則に基づいて形態素解析をするものである．
なお，これらの形態素解析システムを用いるときには，ただ一つの(ベストの)解析結果を出力させた．
これらのコーパスと形態素解析システムとの組み合わせは，EDRコーパスに対しては，三つの形態素解析システム全てを適用したが，京大コーパスBについては，JUMANのみを適用した．
また，二つのコーパスの元々の分割(人手修正済みの分割)についても試した．
すなわち，全部で6種の形態素分割に対して尺度[MATH]を適用した．
教師あり学習では，確率推定用の訓練コーパスと過分割検出用のテストコーパスとが異なる．
実験1では，京大コーパスAの元々の分割(JUMANの解析結果を人手修正したもの)を訓練データとして([REF_eq:n])式の確率を推定した．
そして，その推定値を利用して，JUMANにより形態素解析された京大コーパスBに対して尺度[MATH]を適用した．
7種(=教師なし6種+教師あり1種)の形態素分割のそれぞれに対して，その全ての分割点について，前後の形態素から尺度[MATH]を計算した．
たとえば，「休/憩室/は/広い/。
」のように分割されている文については，四つの分割点において，それぞれ，[MATH]，[MATH]，[MATH]，[MATH]を計算した．
このとき，([REF_eq:n])式の確率は，[REF_sec:overview]節で述べたように，[MATH]としてバックオフスムージングにより計算した．
7種の形態素分割のそれぞれに対して，全ての分割点を尺度[MATH]により降順に(同一尺度値の場合はランダムにtieを解消して)ソートし，その上位から異なり150個を選んだ．
そして，それぞれの異なりについて，一個の分割点を無作為に抽出し，それが過分割であるかを判定した．
なお，判定は筆者による．
判定した150個の分割点について，それが実際に過分割であった数を表[REF_tab:errs]に示す．
表から分かるように，これら150個の中に過分割が占める割合は非常に高い．
たとえば，表[REF_tab:errs]では，茶筅には128個の過分割がある．
一方，平均的には，茶筌の分割が過分割であるのは，1.5％以下であると言ってよい．
つまり，茶筅の150個の分割点のうちで，過分割は，平均的には，[MATH]個以下である．
よって，茶筅の解析結果から128個の過分割を検出するためには，平均的には，[MATH]個以上の分割点を調べなければならないことになる．
同様なことが，他の形態素解析システムによる分割結果，あるいは，人手で修正された分割結果についても言える．
これより，尺度[MATH]を用いることにより，形態素解析結果から過分割を効率的に抽出できるといえる．
なお，表[REF_tab:errs]において，JUMANで解析された京大コーパスBからの過分割検出結果について，教師なし学習の場合と教師あり学習の場合とを比べると，教師あり学習の方が検出個数が多い．
これは，教師あり学習の方が，([REF_eq:n])式の値を正確に推定できるからであると解釈できる．
さらに，教師なし学習の場合の6種の形態素分割のそれぞれについて，上位異なり150個中の過分割から上位12個の過分割を付録の表[REF_tab:edr]と表[REF_tab:kyoto2.0]に示す．
表で「数」とある欄には，そのような過分割を含む文の数がある．
また，「形態素/品詞」とある二つの欄は，尺度[MATH]を計算した分割点の前後の形態素と品詞を示す．
なお，品詞は，それぞれの形態素解析システムの品詞である．
また，表の解析結果は，各解析システムが一つだけ解析結果を出力した場合のものである．
もし，複数の解析結果も出力するようにすれば，表中の文について，当該の形態素解析システムが正解を含む解を出すことはある．
これらの表に示されている過分割の中には，何らかの規則性があるとすぐに分るものもある．
たとえば，EDRコーパスの元々の分割に含まれる過分割(表[REF_tab:edr])においては，「引き下げ/よう」が「引き下/げ/よう」と分割されていたり，「掲げ/、」が「掲/げ/、」のように分割されるなど，動詞の語幹が分割される例が大半である．
一方，EDRコーパスに対する茶筌の過分割では，「結果」が「結(普通名詞) /果(普通名詞)」と分割されていたり，「考えて」が「考(普通名詞)/えて(普通名詞)」と分割されているが，このような例に含まれる規則性は，もしあったとしても，容易には分らない．
いずれにしろ，尺度[MATH]を使うことにより，ある程度の量の，形態素解析結果の過分割が，教師なし学習により容易に抽出できることが分かる．
このような例を集めるのは人手では手間が掛る．
また，尺度[MATH]は人手修正後のコーパスに残る過分割も検出できるため，コーパス作成・整備の際の補助ツールとしても役立つと考える．
また，付録の表[REF_tab:cv]には，教師あり学習の場合について，尺度[MATH]の値が上位12個の過分割を示す．
ここで，教師あり学習の結果である表[REF_tab:cv]におけるJUMANの過分割と，教師なし学習の結果である表[REF_tab:kyoto2.0]におけるJUMANの過分割とを比べると，表[REF_tab:cv]においては「護/煕」など固有名詞が占める割合が多いが，表[REF_tab:kyoto2.0]では固有名詞は一つ(「若/乃/花」)しか存在しないことがわかる．
表[REF_tab:kyoto2.0]に固有名詞が少ないのは，固有名詞は未知語である場合が他の品詞と比べて多いため，常に過分割される場合も多くなり，その結果として尺度[MATH]の値が小さくなる場合が多いためである．
このように，形態素解析システムが常に過分割してしまうような場合を検出するためには，人手修正済みコーパスが必要であると言える．
教師なし学習により何か統計的に興味のある言語現象を発見するような応用[CITE]においては，新聞記事などの大規模なコーパスが比較的用意に入手できるので，訓練コーパスのサイズは深刻な問題ではない．
これは本稿における過分割検出の場合でも同様である．
しかし，教師あり学習の場合には，訓練コーパスを構築するのはコストが掛るため，なるべく小さな訓練コーパスであることが望ましい．
そこで，実験2では，主に教師あり学習の場合を対象として，訓練コーパスのサイズと過分割検出精度との関係を調べた．
ただし，教師なし学習の場合についても，教師あり学習と比較するために，訓練コーパスのサイズと過分割検出精度との関係を同様に調べた．
確率推定用の訓練コーパスとしては京大コーパスAを用い，過分割検出の精度を調べるテストコーパスとしてはJUMANにより分割された京大コーパスBを用いた．
このことは，教師あり学習と教師なし学習とで共通である．
ただし，教師あり学習では京大コーパスAの元々の分割から([REF_eq:n])式の確率を推定し，教師なし学習では，京大コーパスAをJUMANにより形態素解析した結果から([REF_eq:n])式の確率を推定した．
テストコーパスである京大コーパスBについて，その元々の分割を正解と看倣して，分割の正誤を判定したときの統計を表[REF_tab:stat]に示す．
表[REF_tab:stat]より，分割の間違いに占める過分割は62.0％である．
加えて，過分割の周辺には分割不足も起りやすいと言えるので，過分割が検出できれば，その周囲も調べることにより，分割誤りの多くが検出できると言える．
しかし，分割点の再現率(=100[MATH](一致した分割点の数/正解における分割点の数))と適合率(=100[MATH](一致した分割点の数/JUMANによる分割点の数))は，それぞれ，99.7％，99.5％と非常に高い．
また，JUMANの分割点全体の中で過分割である分割点は0.5％(=100％[MATH]適合率)であるので，過分割を見付けるのは人手では困難であると考える．
約1万文からなる訓練コーパスから，約1000，2000, .
..
, 10000文を選び，それぞれの場合について，[MATH]としてバックオフスムージングにより([REF_eq:n])式の確率を推定し，それを利用して約1万文からなるテストコーパスにおける全分割点の尺度[MATH]の値を計算した．
そして，全ての分割点を尺度[MATH]により降順にソートし，上位の分割点から，過分割かどうかを，テストコーパスの元々の分割を正解として調べた．
まず，全訓練データを使用した場合についての実験結果を述べ，次に訓練データを1000文ずつ増加した場合についての実験結果を述べる．
図[REF_fig:10000]には，約1万文の訓練データ全てを使って確率推定した場合について，教師あり学習と教師なし学習のそれぞれについて，過分割検出の再現率(percent recall)に対する適合率(percent precision)および分割点調査率(percent examination)を示す．
ここで，
図[REF_fig:10000]の教師あり学習の場合の適合率(supervised-precision)および教師なし学習の場合の適合率(unsupervised-precision)のプロットから分かるように，上位における過分割検出の適合率は非常に高い．
たとえば，再現率が10.0％のとき，適合率は，教師あり学習の場合に90.5％であり，教師なし学習の場合に46.8％であるが，これらは，JUMANの分割点全体の中で過分割が占めるパーセンテージである0.5％の，180倍以上，および，90倍以上である．
この適合率の高さは，実験1での結果を裏付けるものである．
また，図[REF_fig:10000]の教師あり学習の場合の分割点調査率(supervised-examination)および教師なし学習の場合の分割点調査率(unsupervised-examination)から分かるように，一部の分割点を調べるだけで多くの過分割を検出できると言える．
たとえば，全体の過分割のなかから再現率50％で過分割を見付けるためには，教師あり学習の場合には，全分割点の0.5％を調べればよく，教師なし学習の場合には，全分割点の2.0％を調べればよい．
さらに，90％の過分割を見付けるためには，教師あり学習の場合には，全分割点の7.8％を調べればよく，教師なし学習の場合には，全分割点の12.2％を調べればよい．
一方，もし，無作為に分割点を調べるという方法により，過分割を検出しようとしたならば，50％の過分割を見付けるためには，平均的には，全分割点の50％を調べる必要があり，90％の過分割を見付けるためには，90％の分割点を調べる必要がある．
以上より，尺度[MATH]を使うことにより，過分割の検出が効率良くできると言える．
なお，再現率，適合率，分割点調査率の間には
という関係が成立する．
ただし，[MATH]はテストコーパスに固有の定数であり，
([REF_eq:rel])式から，分割点調査率と再現率が決まれば適合率が決まることが分かる(e.g.,分割点調査率が小さければ適合率は高い)．
そのため，以下では，再現率に対する分割点調査率のみに基づいて過分割の検出精度を評価する．
そして，同一の再現率に対して分割点調査率が小さいとき過分割の検出精度が高いと言い，その逆のときに過分割の検出精度が低いと言うことにする．
図[REF_fig:incr-exam]には，過分割検出の再現率が25,50,75％の場合(recall25,recall50,recall75)について，教師あり学習の場合と教師なし学習の場合における，訓練文数(Num. of training sentences)と分割点調査率の関係を示す．
図[REF_fig:incr-exam]から，教師あり学習の場合(supervised-recall25,50,75)については，訓練文数が増加すると，再現率が50％と75％においては，分割点調査率が明確に減少していると言える．
また，再現率が25％についても緩やかに分割点調査率は減少している．
一方，教師なし学習の場合(unsupervised-recall25,50,75)については，訓練文数が増えていっても，2000文以上については，分割点調査率は(若干の変動はあるが)ほぼ横ばいである．
このことは，教師あり学習については，訓練データが多くなれば多くなるだけ，([REF_eq:n])式の確率を精密に推定できるが，教師なし学習については，訓練データが多くなったとしても，その確率推定に対する効果は，教師あり学習の場合に比べれば，小さいことを示している．
実験3では，尺度[MATH]，相互情報量，尤度比，改良Dice係数[CITE]，Yates補正された[MATH]，の五つの尺度について，過分割の検出精度を比較した．
ここで，尤度比，改良Dice係数，Yates補正された[MATH]は，[CITE]において，有用な括弧表現を抽出するために有効であるとされた尺度である．
また，尤度比は，[CITE]でも，2文字間の連関の尺度として，漢字列の分割に有効であることが示されている．
以下では，まず，本実験のテストコーパスとした京大コーパスBについて，そこでの分割点の出現頻度の統計について述べる．
この出現統計は，あとで，各尺度間の過分割検出精度の違いを説明するときの資料に用いる．
次に，各尺度を定義し比較する．
形態素[MATH]の最後の文字を[MATH],形態素[MATH]の最初の文字を[MATH]とし，[MATH]と[MATH]に挟まれるような分割点を，前後1文字で区別される分割点と呼ぶ．
実験3では，分割点といえば，前後1文字で区別される分割点のこととする．
つまり，「ab/cd」と「xb/cy」のような分割点は，分割点の前後1文字が同じであるので，区別しないで同一タイプの分割点として扱う．
表[REF_tab:freq]は，テストコーパスとした京大コーパスBにおける分割点について，過分割である分割点とそうでない分割点のそれぞれに対して，出現頻度ごとの，分割点の異なり数などを調べたものである．
ここで，分割点の総数を[MATH],頻度[MATH]における分割点の異なり数を[MATH]とすると，頻度[MATH]における延べ数は[MATH]であり，[MATH]である．
表[REF_tab:freq]では，頻度[MATH]における「延べ％」は[MATH]であり，「累積％」は[MATH]である．
[htbp]
表[REF_tab:freq]から，過分割である分割点の出現頻度は，そうでない場合に比べて，低頻度であると言える．
これは，過分割である分割点の数自体が少ないことが主な原因である．
また，過分割である場合とそうでない場合の分布の様子を比べると，過分割である分割点の場合には，頻度が1か2であるような場合が全体の50％以上を占めていることから分かるように，低頻度の方に分布が偏っている．
まず，[MATH]として，([REF_eq:n])式を用いて，([REF_eq:L])式を変形すると，
となる．
一方，([REF_eq:mi])式を同様に変形すると
という無意味な値になるので，区切り文字とそれに隣接する文字は特に強く結合すると仮定し，
のような変形をすると，
となる．
なお，以下では，[MATH],[MATH]とする．
([REF_eq:MIn2])式から，[MATH]においては，相互情報量[MATH]は，[MATH]と[MATH]をそれぞれ一つの項と看做せば，この2項に関する通常の相互情報量の式と一致することがわかる．
そこで，尤度比，改良Dice係数，Yates補正された[MATH]についても，これら2項に基づいて，その値を計算する．
以下では，[CITE]に基づいて，尤度比，改良Dice係数，Yates補正された[MATH]を定義する．
また，尺度[MATH]と相互情報量についても，確率を最尤推定した形で定義する．
各尺度を定義する準備として，まず，[MATH]は，分割表で示すと
である．
より厳密には，[MATH]を文字列の頻度とし，[MATH]を，[MATH]と[MATH]を含む任意の文字としたとき，
である．
また，
である．
ここでの「尤度比」は，[MATH]と[MATH]の2項が従属とした場合と独立とした場合との最尤推定量による尤度比であり，
である．
なお，上式では，分割点のソートに無関係な項は除いてある．
[MATH]は，2項が従属して生起する度合が強いとき，正で大きな値をとる．
しかし，これだけでは必ずしも共起強度が強いとは言えない．
たとえば，
と
は同じ[MATH]となる．
これらのうち前者は共起強度が強いが，後者は弱い(反発している)．
このことを考慮して，[MATH]のときには，[CITE]と同様に，Yuleの[MATH]の符合を付けることにより，分割点をソートした．
[MATH]と同様に独立性の判定に用いられる尺度である．
なお，[MATH]に関しても，[MATH]と同様な理由から，Yuleの[MATH]の符合を付けて分割点をソートした．
[CITE]で，対訳単語間の類似度として，提案されている尺度である．
([REF_eq:MIn2])式より，分割点のソートに無関係な項は除くと，
([REF_eq:Ln2])式より，分割点のソートに無関係な項は除くと，
ここで，上記の各尺度について，もし，[MATH]，あるいは，[MATH]となる場合には，それぞれを0.1として計算した．
各尺度について，JUMANにより形態素解析された京大コーパスBを訓練およびテストコーパスとして，過分割の再現率に対する分割点調査率を評価した結果を図[REF_fig:unsup-cmp]に示す．
図[REF_fig:unsup-cmp]から分るように，改良Dice係数(Dice)，[MATH](lambda)，[MATH](chi＾2)の分割点調査率は，[MATH]や[MATH]と比べて大きい．
すなわち，過分割検出精度は低い．
この原因は，これらの尺度が，統計的に有意と言えないような低頻度の共起関係をノイズとして排除するような尺度であるからである．
すなわち，頻度が1とか2とかの共起関係の尺度値は，これらの尺度では大きくならないため，(表[REF_tab:freq]に示されるように)低頻度である過分割が排除されるためである．
このような性質は，[CITE]や[CITE]や[CITE]のような，一般的に共起強度が高い共起関係を必要とするような応用に対しては適していたが，低頻度事象である過分割を検出するには適さない．
一方，[MATH]の過分割検出精度は，再現率50％程度のところまでは，[MATH]とほぼ同じである(実際には若干低い)．
これは，[MATH]が低頻度の共起関係を過大評価する[CITE]からであろう．
つまり，再現率が低いところでは，低頻度で，かつ，共起強度の強い表現を選択的に拾ってくるが，そのようなものは過分割であることが多いため，検出精度が高いと解釈できる．
しかし，再現率が上ってくると，比較的頻度が高い過分割も増えてくるため，共起強度だけでは，過分割なのか，そうでない分割かが区別できなくなり，検出精度が下がると言える．
これらの尺度に対して，[MATH]は，分割されるか分割されないかを直接モデル化した尺度であるため，再現率が高くなっても検出精度が高いものと考える．
なお，筆者は，予備実験として，相互情報量とYate補正した[MATH]を，隣接する形態素間について，(文字ではなく)形態素を単位とする2項関係に基づいて計算してみたが，その性質は尺度[MATH]とは非常に異なっていた．
相互情報量の性質とYate補正した[MATH]の性質とは，互いに若干は異なるが，おおまかには，二つの尺度とも，固有名詞(「福沢/諭吉」など)や四字熟語(「不眠/不休」など)を取ってくる傾向が強かった．
これらの隣接形態素は，それ自体は有用な表現ではあるが，これらの隣接形態素間の分割が間違っているわけではないので，本稿での目的である過分割の検出には適さない．
その他，共起や定型表現を抽出する研究として，特に文字列レベルに関係するものでは，[CITE]がある．
これらの研究では，大量の生テキストコーパスから，統計量を用いることにより，「に関して」や「に対しては」などの定型的な表現を抽出する．
これらの表現は有用な表現ではあるが，「に対して」を「に/対/し/て」と分割しても，過分割ではないことからも分るように，これらの手法は，本稿での目的である過分割の検出には適さない．
各尺度に対して，京大コーパスAの元々の分割を訓練コーパス，京大コーパスBをテストコーパスとして，過分割の再現率に対する分割点率調査を評価した結果を図[REF_fig:sup-cmp]に示す．
図[REF_fig:sup-cmp]では，図[REF_fig:unsup-cmp]と同様に尺度[MATH]の分割点調査率が一番小さい．
そして，図[REF_fig:sup-cmp]と図[REF_fig:unsup-cmp]を比べると，尺度[MATH]については，図[REF_fig:sup-cmp]の教師あり学習の方が図[REF_fig:unsup-cmp]の教師なし学習の場合よりも分割点調査率が小さい．
一方，尺度[MATH]以外の尺度については，教師あり学習の方が分割点調査率は大きくなっている．
これは，教師あり学習の場合の方が，教師なし学習の場合よりも，テストコーパスにおいて，過分割の前後の文字の共起強度が小さいことを示している．
この理由は，教師あり学習においては，訓練コーパスで過分割であるような分割点が人手により除かれているため，テストコーパスで過分割であるような分割点は訓練コーパスで出現することが稀となり，その結果，共起強度が小さくなるからである．
このことから，尺度[MATH]以外の尺度については，教師あり学習をしても過分割検出精度が高くならないことが分かる．
