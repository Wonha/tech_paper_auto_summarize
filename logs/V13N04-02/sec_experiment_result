適応分野の生コーパスの利用方法について比較検討するために，生コーパスに対する人手による単語境界情報の付与の程度や方法を複数用意し，その結果得られるコーパスから推定される確率的言語モデルの予測力やそれに基づく仮名漢字変換の精度を計算した．
実験には，一般的な分野のコーパスとして会話辞典の例文と，適応対象として新聞記事を用いた(\tabref{table:corpus}参照)．
両分野のコーパスの各文は人手で単語に分割されているが，適応分野のコーパスは，主として生コーパスとして利用される．
単語分割済みコーパスとしての利用は，比較対象としての理想的な状況を実現するためである．
適応分野の単語リストは，適応分野のコーパスにのみ出現する21,855単語からなる．
基本となる確率的言語モデルは以下の通りである．
単語分割済みの一般分野のコーパスから単語2-gramモデルを構築した．
既知語の数は5,112語である．
適応分野の単語リストは，未知語モデルにおいて出現確率を嵩上げされ，未知語に対して出現しやすくなる外部辞書語[CITE]として利用する．
適応分野のコーパスは利用しない．
この確率的言語モデルの同一分野のテストコーパスに対するクロスエントロピーは4.509であり，テストセットパープレキシティーは64.28であった．
実験に利用した自動単語分割システムは，この言語モデルに基づいており，入力文に対して最大確率となる単語列を返す(\subref{subsection:word-segmenter}参照)．
同一分野のテストコーパスに対する単語境界の推定精度は98.26%であった．
後述する実験において，確率的単語分割コーパスの単語境界確率の推定方法としては，自動分割の結果を利用する方法を採用した．
単語境界の推定結果の信頼度には，自動単語分割システムの精度[MATH]を利用した．
すなわち，自動単語分割システムにより単語境界であると判定された点では[MATH]とし，単語境界でないと判定された点では[MATH]とした．
確率的言語モデルの予測力の評価に用いた基準は，文字単位のクロスエントロピーと単語あたりのテストセットパープレキシティーである．
まず，テストコーパス[MATH]に対して未知語の予測も含む文字単位のエントロピー[MATH]を以下の式で計算する[CITE]．
ここで，[MATH]はテストコーパス[MATH]の文字数を表す．
次に，単語単位のテストセットパープレキシティを以下の式で計算する．
ここで[MATH]は平均単語長(文字数)である．
さらに確率的言語モデルの応用として仮名漢字変換[CITE]を採用し，文単位で一括変換した場合の第一候補の変換精度を計算した．
これは，音声認識において，音響モデルの誤りの影響を排した場合と考えることもできる．
適応分野の生コーパスの利用方法について比較検討するために，生コーパスの自動分割結果に対する単語境界情報の人手による修正の程度や方法として，以下の6つを準備した．
適応分野の生コーパスを自動的に単語分割し，その結果をそのまま用いる．
これは，自動分割システムにより単語境界と判定された点では[MATH]とし，単語境界でないと判定された点では[MATH]とする確率的単語分割コーパスと等価である．
適応分野の生コーパスを確率的単語分割コーパスとして用いる．
すなわち，自動単語分割システムにより単語境界であると判定された点では[MATH]とし，単語境界でないと判定された点では[MATH]とした．
適応分野の生コーパスの全文を人手により正しく単語に分割し，これをAutoと同様に決定的に単語に分割されたコーパスとして利用する．
適応分野の生コーパスの最初から281,398単語目まで(45.00%)を人手により正しく単語に分割し，その残りを自動的に単語分割した．
これをAutoと同様に決定的に単語に分割されたコーパスとして利用する．
まずRawと同様に単語境界確率を設定する．
さらに，単語リストに含まれる文字列が生コーパス中に単語として出現している全ての箇所において，その文字列内の単語境界確率を0とし，その文字列の直前と直後の単語境界確率を1とする．
これは，生コーパスに対する単語リストに含まれる文字列のKWICを見て，その文字列が単語として出現している場合にマークをつける作業をした結果に相当する．
マーク箇所は単語数でのべ138,483箇所(22.13%)である．
まずRawと同様に単語境界確率を設定する．
さらに，単語リストに含まれる文字列が生コーパス中に単語として出現している最初の2箇所において，その文字列内の単語境界確率を0とし，その前後の単語境界確率を1とする．
これは，生コーパスに対する単語リストに含まれる文字列のKWICを見て，その文字列が単語として出現している場合にマークをつける作業を各文字列に対して2つのマークがつくまで行なった結果に相当する．
マーク箇所は単語数でのべ32,643箇所(5.22%)である．
以上のようにして得られる適応分野のコーパスから，Baseモデルの既知語と単語リストに含まれる単語を語彙として単語1-gram確率と単語2-gram確率を計算し，Baseモデルと補間して適応分野のための確率的言語モデルを構築した．
各モデルの予測力と仮名漢字変換の精度を\tabref{table:result}に示す．
Baseとコーパス修正のコストがないAutoとRawの結果から，適応分野のコーパスは可能な限り収集し，言語モデルの推定に利用するのがよいといえる．
利用方法においては，AutoとRawの結果の比較から，誤りを含む自動分割結果を100%信頼してそのまま用いるのではなく，単語境界か否かの判定結果を割り引いて，確率的単語分割コーパスとして用いるほうがよいといえる．
コーパス修正のコストがないRawの予測力や変換精度は，自動分割の結果を人手で完全に修正した場合のWell-doneの予測力と変換精度に対してかなり低く，修正のコストを払うことで改善する余地があることが分かる．
自動分割結果の修正は文単位で行なうのが一般的であるが，単語リストに含まれる単語が出現する箇所に限定して，文の一部分のみをチェックする場合の結果がRareとMediumである．
単語リストの各単語に対して2箇所の出現のみを人手でマークするRareでは，単語数の割合にして5.22%のみがマークの対象になるが，仮名漢字変換の精度はコーパスの最初から順に45.00%の単語をチェックする45%-doneの精度にほぼ等しい．
単語リストの各単語に対して全ての出現箇所を人手でチェックするMediumと自動分割の結果を人手で完全に修正するWell-doneの予測力と変換精度は同程度である．
この結果から，適応分野に特有の語彙の出現箇所に修正のコストを集中すれば，コーパス全体の約22.13%の単語のみのチェックで，予測力においても，仮名漢字変換の精度においても，コーパス全体の分割結果を人手で修正したコーパスを利用する場合にかなり近い性能を達成することが可能であるといえる．
文単位で分割結果を修正する方法と，特定の文字列のKWICを見てそれが各文脈で単語として用いられているかをマークするするのは，1単語あたりのチェックに要するコストが等しいとは限らない．
しかしながら，Rareと45%-doneのチェック対象の単語数には9倍の差がある．
特定の単語のKWICにおける1箇所のマークが，注目単語の前後4単語の修正を含めた分割修正(合計9単語)に相当する時間を要するとは思えず，Rareと45%-doneの総修正コストの順序関係は変わらないであろう．
加えて，文全体に対して分割結果の修正を行なう場合には，主に活用語尾や助詞や助動詞からなる，文法の専門家でさえも正確な単語分割が容易でない箇所が含まれることになる．
このような正確な単語分割が困難な機能語などの列の分割方針を作業者に徹底することは非常に困難である．
単語リストに含まれる単語のみをチェック対象にすれば，このような困難を回避することが可能となり，さらに，適応分野に特有の単語の統計的な振る舞いを捕捉するという，適応分野のコーパスを利用する本来の目的のみにコーパス修正のコストを集中することが可能となる．
以上のことから，適応分野に特有の語彙の出現箇所に修正のコストを集中し，この結果得られる部分的に修正されたコーパスを確率的単語分割コーパスとみなして確率的言語モデルを構築することにより，音声認識や仮名漢字変換などの適応対象の分野における精度をより低いコストでより短時間で向上させることが可能となる．
