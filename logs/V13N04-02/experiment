評価
\label{section:evaluation}

適応分野の生コーパスの利用方法について比較検討するために，生コーパスに対する人手によ
る単語境界情報の付与の程度や方法を複数用意し，その結果得られるコーパスから推定される
確率的言語モデルの予測力やそれに基づく仮名漢字変換の精度を計算した．



\subsection{実験条件}

実験には，一般的な分野のコーパスとして会話辞典の例文と，適応対象として新聞記事を用い
た(\tabref{table:corpus}参照)．両分野のコーパスの各文は人手で単語に分割されているが，
適応分野のコーパスは，主として生コーパスとして利用される．単語分割済みコーパスとして
の利用は，比較対象としての理想的な状況を実現するためである．適応分野の単語リストは，
適応分野のコーパスにのみ出現する21,855単語からなる．

基本となる確率的言語モデルは以下の通りである．
\begin{list}{}{}
\item[$\bullet$ Base] 単語分割済みの一般分野のコーパスから単語2-gramモデルを構築した．
  既知語の数は5,112語である．適応分野の単語リストは，未知語モデルにおいて出現確率を嵩
  上げされ，未知語に対して出現しやすくなる外部辞書語\cite{日本語の情報量の上限の推定} 
  として利用する．適応分野のコーパスは利用しない．
\end{list}
この確率的言語モデルの同一分野のテストコーパスに対するクロスエントロピーは4.509であ
り，テストセットパープレキシティーは64.28であった\footnotemark．\footnotetext{テスト
セットパープレキシティーは平均単語長に影響されるので，異なるテストコーパスに対する結
果との比較には適さない．}

実験に利用した自動単語分割システムは，この言語モデルに基づいており，入力文に対して最
大確率となる単語列を返す(\subref{subsection:word-segmenter}参照)．同一分野のテストコ
ーパスに対する単語境界の推定精度は98.26\%であった\footnotemark．\footnotetext{対象分
野のテストコーパス(\tabref{table:corpus}参照)に対する単語境界の推定精度は89.25\%であ
った．}

後述する実験において，確率的単語分割コーパスの単語境界確率の推定方法としては，自動分
割の結果を利用する方法を採用した．単語境界の推定結果の信頼度には，自動単語分割システ
ムの精度$\alpha=98.26\%$を利用した．すなわち，自動単語分割システムにより単語境界であ
ると判定された点では$P_{i} = \alpha$とし，単語境界でないと判定された点では$P_{i} =
1-\alpha$とした．

\begin{table}[t]
  \caption{コーパス}
  \begin{center}
    \begin{tabular}{c|c|r|r|r}
      \hline
      \hline
      用途   & 分野 & \multicolumn{1}{c|}{文数} & \multicolumn{1}{c|}{単語数} &
        \multicolumn{1}{c}{文字数} \\
      \hline
      学  習 & 会話 & 14,754 & 187,658 & 254,436 \\
      学  習 & 新聞 & 20,700 & 625,761 & 917,830 \\
      テスト & 会話 &  1,639 &  21,105 &  28,655 \\
      テスト & 新聞 &  2,300 &  68,566 & 100,091 \\
      \hline
    \end{tabular}
  \end{center}
  \label{table:corpus}
\end{table}



\subsection{評価基準}

確率的言語モデルの予測力の評価に用いた基準は，文字単位のクロスエントロピーと単語あた
りのテストセットパープレキシティーである．まず，テストコーパス$C_{t}$に対して未知語
の予測も含む文字単位のエントロピー$H$を以下の式で計算する
\cite{An.Estimate.of.an.Upper.Bound.for.the.Entropy.of.English}．
\begin{displaymath}
  H = -\frac{1}{|C_{t}|}\log_{2} \prod_{\Bdma{w} \in C_{t}}M_{w,n}(\Bdma{w})
\end{displaymath}
ここで，$|C_{t}|$はテストコーパス$C_{t}$の文字数を表す．次に，単語単位のテストセット
パープレキシティを以下の式で計算する．
\begin{displaymath}
  PP = 2^{H\times\overline{|\Bdma{w}|}}
\end{displaymath}
ここで$\overline{|\Bdma{w}|}$は平均単語長(文字数)である．

さらに確率的言語モデルの応用として仮名漢字変換\cite{確率的モデルによる仮名漢字変換} 
を採用し，文単位で一括変換した場合の第一候補の変換精度を計算した\footnotemark．
\footnotetext{評価基準は文献\cite{確率的モデルによる仮名漢字変換}と同一である．}これ
は，音声認識において，音響モデルの誤りの影響を排した場合と考えることもできる．



\subsection{適応分野の生コーパスの利用方法}

適応分野の生コーパスの利用方法について比較検討するために，生コーパスの自動分割結果に
対する単語境界情報の人手による修正の程度や方法として，以下の6つを準備した．

\begin{list}{}{}

\item[$\bullet$ Auto] 適応分野の生コーパスを自動的に単語分割し，その結果をそのまま用
  いる．これは，自動分割システムにより単語境界と判定された点では$P_{i} = 1$とし，単語
  境界でないと判定された点では$P_{i} = 0$とする確率的単語分割コーパスと等価である．

\item[$\bullet$ Raw] 適応分野の生コーパスを確率的単語分割コーパスとして用いる．すなわ
  ち，自動単語分割システムにより単語境界であると判定された点では$P_{i} = \alpha$とし，
  単語境界でないと判定された点では$P_{i} = 1- \alpha$とした．

\item[$\bullet$ Well-done] 適応分野の生コーパスの全文を人手により正しく単語に分割し，
  これをAutoと同様に決定的に単語に分割されたコーパスとして利用する．

\item[$\bullet$ 45\%-done] 適応分野の生コーパスの最初から281,398単語目まで(45.00\%)を
  人手により正しく単語に分割し，その残りを自動的に単語分割した．これをAutoと同
  様に決定的に単語に分割されたコーパスとして利用する．

\item[$\bullet$ Medium] まずRawと同様に単語境界確率を設定する．さらに，単語リス
  トに含まれる文字列が生コーパス中に単語として出現している全ての箇所において，その文
  字列内の単語境界確率を0とし，その文字列の直前と直後の単語境界確率を1とする．これは，
  生コーパスに対する単語リストに含まれる文字列のKWICを見て，その文字列が単語として出
  現している場合にマークをつける作業をした結果に相当する．マーク箇所は単語数でのべ
  138,483箇所(22.13\%)である．

\item[$\bullet$ Rare] まずRawと同様に単語境界確率を設定する．さらに，単語リスト
  に含まれる文字列が生コーパス中に単語として出現している最初の2箇所において，その文字
  列内の単語境界確率を0とし，その前後の単語境界確率を1とする．これは，生コーパスに対
  する単語リストに含まれる文字列のKWICを見て，その文字列が単語として出現している場合
  にマークをつける作業を各文字列に対して2つのマークがつくまで行なった結果に相当する．
  マーク箇所は単語数でのべ32,643箇所(5.22\%)である．

\end{list}

以上のようにして得られる適応分野のコーパスから，Baseモデルの既知語と単語リスト
に含まれる単語を語彙として単語1-gram確率と単語2-gram確率を計算し，Baseモデルと
補間して適応分野のための確率的言語モデルを構築した．



\subsection{評価}


\begin{table}[t]
  \caption{各モデルの予測精度と仮名漢字変換の精度}
  \begin{center}
    \begin{tabular}{@{ \ }c@{ \ }|@{ \ }c@{ \ }|@{ \ }c@{ \ }|@{ \ }c@{ \ }|
        @{ \ }c@{ \ }|@{ \ }c@{ \ }}
      \hline
      \hline
      モデル & \lineB{生コーパス}{の利用方法}
                            &   $H$ &  $PP$ &  再現率 &  適合率 \\
      \hline
      Base       &       -- & 7.558 &  1938 & 62.74\% & 72.34\% \\
      \hline
      Auto       & 自動分割 & 6.618 & 755.7 & 80.52\% & 85.24\% \\
      Raw        & 確率分割 & 6.276 & 536.5 & 84.70\% & 87.85\% \\
      \hline
      Rare       & 部分修正 & 6.133 & 465.2 & 86.57\% & 89.24\% \\
      Medium     & 部分修正 & 5.889 & 364.2 & 88.34\% & 90.50\% \\
      45\%-done  & 部分修正 & 6.049 & 427.4 & 86.56\% & 89.32\% \\
      Well-done  & 完全修正 & 5.858 & 353.1 & 88.90\% & 90.90\% \\
      \hline
    \end{tabular}
  \end{center}
  \label{table:result}
\end{table}

各モデルの予測力と仮名漢字変換の精度を\tabref{table:result}に示す．Baseとコーパ
ス修正のコストがないAutoとRawの結果から，適応分野のコーパスは可能な限り収
集し，言語モデルの推定に利用するのがよいといえる．利用方法においては，AutoとRawの
結果の比較から，誤りを含む自動分割結果を100\%信頼してそのまま用いるのでは
なく，単語境界か否かの判定結果を割り引いて，確率的単語分割コーパスとして用いるほうが
よいといえる．

コーパス修正のコストがないRawの予測力や変換精度は，自動分割の結果を人手で完全に
修正した場合のWell-doneの予測力と変換精度に対してかなり低く，修正のコストを払う
ことで改善する余地があることが分かる．自動分割結果の修正は文単位で行なうのが一般的で
あるが，単語リストに含まれる単語が出現する箇所に限定して，文の一部分のみをチェックす
る場合の結果がRareとMediumである．単語リストの各単語に対して2箇所の出現の
みを人手でマークするRareでは，単語数の割合にして5.22\%のみがマークの対象になる
が，仮名漢字変換の精度はコーパスの最初から順に45.00\%の単語をチェックする45\%-doneの
精度にほぼ等しい．単語リストの各単語に対して全ての出現箇所を人手でチェッ
クするMediumと自動分割の結果を人手で完全に修正するWell-doneの予測力と変換
精度は同程度である．この結果から，適応分野に特有の語彙の出現箇所に修正のコストを集中
すれば，コーパス全体の約22.13\%の単語のみのチェックで，予測力においても，仮名漢字変換
の精度においても，コーパス全体の分割結果を人手で修正したコーパスを利用する場合にかな
り近い性能を達成することが可能であるといえる．

文単位で分割結果を修正する方法と，特定の文字列のKWICを見てそれが各文脈で単語として用
いられているかをマークするするのは，1単語あたりのチェックに要するコストが等しいとは限
らない．しかしながら，Rareと45\%-doneのチェック対象の単語数には9倍の差が
ある．特定の単語のKWICにおける1箇所のマークが，注目単語の前後4単語の修正を含めた分割
修正(合計9単語)に相当する時間を要するとは思えず，Rareと45\%-doneの総修正
コストの順序関係は変わらないであろう．加えて，文全体に対して分割結果の修正を行なう場
合には，主に活用語尾や助詞や助動詞からなる，文法の専門家でさえも正確な単語分割が容易
でない箇所が含まれることになる．このような正確な単語分割が困難な機能語などの列の分割
方針を作業者に徹底することは非常に困難である．単語リストに含まれる単語のみをチェック
対象にすれば，このような困難を回避することが可能となり，さらに，適応分野に特有の単語
の統計的な振る舞いを捕捉するという，適応分野のコーパスを利用する本来の目的のみにコー
パス修正のコストを集中することが可能となる．以上のことから，適応分野に特有の語彙の出
現箇所に修正のコストを集中し，この結果得られる部分的に修正されたコーパスを確率的単語
分割コーパスとみなして確率的言語モデルを構築することにより，音声認識や仮名漢字変換な
どの適応対象の分野における精度をより低いコストでより短時間で向上させることが可能とな
る．

