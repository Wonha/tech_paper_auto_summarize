[REF_sec:Intro]章で述べた凝集型クラスタリングに基づいた人名の曖昧性解消は，クラスタリングを適切に導いていく基準がないため，正確なクラスタリングを行うことは難しい．
一方，これまでに提案されている半教師有りクラスタリングは，クラスタ数[MATH]をあらかじめ設定する必要がある[MATH]-meansアルゴリズム[CITE]を改良することを目的としている．
しかし，本研究においては，Web検索結果における同姓同名人物の数は，事前にわかっているわけではない．
したがって，我々の手法においては，事前にクラスタ数を設定するのではなく，新たに生成されたクラスタと，すでに生成されているクラスタ間の類似度を計算し，これらの値がすべて，あらかじめ設定した閾値よりも小さくなった場合に，クラスタリングの処理を終え，その時点で生成されているクラスタ数を最終的な同姓同名人物の数とする．
また，従来の半教師有りクラスタリングアルゴリズムは，制約を導入したり[CITE]，[CITE]，[CITE]，距離を学習したり[CITE]，[CITE]，[CITE]することにのみ着目していた．
しかし，半教師有りクラスタリングにおいて，より正確なクラスタリング結果を得るためには，seedページ間への制約の導入とともに，seedページを含むクラスタの重心の変動の抑制も重要である．
これは，(1) seedページを導入して半教師有りクラスタリングを行なう場合，通常の重心の計算法では重心の変動が大きくなる傾向にあり，クラスタリングの基準となるseedページを導入する効果が得られない，(2)重心を完全に固定して半教師有りクラスタリングを行なう場合，その重心と類似度が高いWebページしかマージされなくなり，多数の独立したクラスタが生成されやすくなる，という二つの考えに基づく．
したがって，seedページを含むクラスタの重心の変動を抑えることができれば，より適切なクラスタリングが実現できると期待される．
本章では，我々の提案する半教師有りクラスタリングの手法について説明する．
以下，検索結果集合[MATH]中のWebページ[MATH]の特徴ベクトル[MATH] [MATH]を式([REF_Eq:feature vector_org])のように表す．
ここで，[MATH]は検索結果集合[MATH]における単語の異なり数であり，[MATH] [MATH]は，各単語を表す．
予備実験として，(a) Term Frequency (TF)，(b) Inverse Document Frequency (IDF)，(c) residual IDF (RIDF)，(d) TF-IDF，(e) [MATH]-measure，(f) gainの6つの単語重み付け法を比較した．
これらの単語重み付け法は，それぞれ，次のように定義される．
(a) Term Frequency (TF)
TFは，与えられた文書において，ある単語がどれだけ顕著に出現するかを示し，この値が大きければ大きいほど，その単語が文書の内容をよく表現していることを示す．
[MATH]をWebページ[MATH]における単語[MATH]の頻度とする．
このとき，[MATH]の各要素[MATH]は，式([REF_eq: tf])によって定義される．
(b) Inverse Document Frequency (IDF)
[CITE]によって導入されたIDFは，その単語が出現する文書数が少なければ少ないほど，その単語が出現する文書にとっては，有用であることを示すスコアである．
このとき，[MATH]の各要素[MATH]は，式([REF_eq: idf])によって定義される．
ここで，[MATH]はWebページの総数，[MATH]は単語[MATH]が現れるWebページ数である．
(c) Residual Inverse Document Frequency (RIDF)
Church and Gale [CITE]は，ほとんどすべての単語は，ポアッソンモデルのような独立性に基づいたモデルに応じて，非常に大きなIDFスコアを持つことを示した．
また，単語の有用性は，推定されるスコアからは大きな偏差を持つ傾向があるという考えに基づいて導入したスコアがresidual IDFである．
このスコアは，実際のIDFとポアッソン分布によって推定されるIDFとの差として定義される．
[MATH]を文書集合中における単語[MATH]の総出現数，[MATH]をWebページの総数としたとき，1つのWebページあたりの単語[MATH]の平均出現数は，[MATH]と表される．
このとき，[MATH]の各要素[MATH]は，式([REF_eq: ridf])によって定義される．
w_{t_{k}}^{p_{i}} &= IDF - \log\frac{1}{1-p(0;\lambda_{i})} \nonumber
&= \log\frac{N}{df(t_{k})}+\log(1-p(0;\lambda_{k}))
ここで，[MATH]は，パラメータ[MATH]を伴うポアッソン分布である．
この手法は，少数の文書のみに出現する単語は，より大きなRIDFスコアを持つ傾向がある．
(d) TF-IDF
TF-IDF法[CITE]は，文書中の単語を重み付けするために，情報検索の研究において広く使われている．
TF-IDFは，上述した(a) TFと(b) IDFに基づいて，式([REF_eq: tfidf])のように定義される．
ここで，[MATH]と[MATH]は，それぞれ，Webページ[MATH]における単語[MATH]の頻度と，単語[MATH]が出現するWebページ数を表す．
また，[MATH]はWebページの総数である．
(e) [MATH]-measure
Bookstein and Swanson [CITE]は，単語[MATH]に対する[MATH]-measureというスコアを導入した．
[MATH]をWebページ[MATH]における単語[MATH]の頻度，[MATH]を単語[MATH]が現れるWebページ数とすると，[MATH]の各要素[MATH]は，式([REF_eq: xI])によって定義される．
この手法は，同程度の出現頻度である2つの単語のうち，少数の文書に集中して出現する単語ほど，高いスコアを示す．
(f) gain
一般に，IDFは単語の重要性を表すと考えられているが，Papineni [CITE]は，IDFは単語の特徴を表す最適な重みに過ぎず，単語の重要性とは異なるものであるため，利得を単語の重要性と考え，gainを提案した．
本手法では，[MATH]の各要素[MATH]は，式([REF_eq: gain])によって定義される．
ここで，[MATH]は，単語[MATH]が現れるWebページ数を，[MATH]はWebページの総数を示す．
本手法では，ほとんど出現しない単語と，非常に頻出する単語は，両方とも低いスコアとなり，中頻度の単語は高いスコアとなる．
上述した(a)〜(f)の単語重み付け手法の中で，本研究においては，``(f) gain''が最も効果的な単語の重み付け法であることがわかったため，これを本研究における単語の重み付け法として用いる．
さらに，クラスタ[MATH]の重心ベクトル[MATH]を式([REF_Eq:centroid vector])のように定義する．
ここで，[MATH]は[MATH]における各単語の重みであり，[MATH] [MATH]は各単語を表す．
なお，以下で述べるクラスタリング手法では，2つのクラスタ[MATH]，[MATH]間の類似度[MATH]を，式([REF_eq:sim])によって計算する．
ただし，[MATH]，[MATH]は，それぞれ，クラスタ[MATH]，[MATH]の重心ベクトルを表す．
凝集型クラスタリングにおいては，はじめに各Webページを，個々のクラスタとして設定する．
次に，二つのクラスタ間の類似度が，あらかじめ設定された閾値より小さくなるまで，類似度が最大となる二つのクラスタをマージして新たなクラスタを生成する．
図[REF_Fig:AggClsAlgorithm]に凝集型クラスタリングのアルゴリズムを示す．
このアルゴリズムでは，あるクラスタ[MATH] (要素数[MATH])を最も類似したクラスタ[MATH] (要素数[MATH])にマージした後の，新たなクラスタ[MATH]の重心ベクトル[MATH]は，式([REF_eq:new agg-centroid])のように定義される．
一般に，seedページを含むクラスタ[MATH]と，seedページを含まないクラスタ[MATH]の類似度が大きい場合には，両者を新たなクラスタとしてマージすべきであるが，両者の距離が大きい場合には，通常の重心の計算法では，重心の変動が大きくなる傾向にある．
そこで，はじめに，あるクラスタ[MATH](重心ベクトル[MATH])を，seedページを含むクラスタ[MATH](重心ベクトル[MATH])にマージする際，これらのクラスタの重心間の距離[MATH]に基づいて，Webページ[MATH]の特徴ベクトル[MATH]を重み付けする．
次に，この重み付けした特徴ベクトルを用いて重心の計算を行なうことで上述した傾向を防ぎ，重心の変動を抑える．
まず，これまでに[MATH]個のクラスタがマージされたseedページを含むクラスタ[MATH] (要素数[MATH])に対して，クラスタ[MATH] (要素数[MATH])が[MATH]回目にマージされるクラスタであるとする．
なお，クラスタ[MATH]の要素は，初期のseedページとなる．
(1)この[MATH]にマージされるクラスタ[MATH]に含まれる各要素について，[MATH]の重心[MATH]と，クラスタ[MATH]の重心[MATH]間の距離尺度[MATH]を用いて，クラスタ[MATH]に含まれるWebページの特徴ベクトル[MATH] [MATH]を重み付けし，その後に生成されるクラスタを[MATH] (要素数[MATH])とする．
このとき，[MATH]の要素となる重み付けした後のWebページの特徴ベクトル[MATH]は，式([REF_eq:TransferedCor])で表される．
本研究では，[MATH]として，(i)ユークリッド距離，(ii)マハラノビス距離，(iii)適応的マハラノビス距離，の三つの距離尺度を比較する．
また，[MATH]は[MATH]が0に非常に近い値となったとき，[MATH]の各要素が極端に大きな値となることを防ぐために導入した定数である．
この[MATH]の値の影響については，3.3.1節で述べる．
(2)次に，seedページを含むクラスタ[MATH] (要素数[MATH])に[MATH](要素数[MATH])の要素を追加し，クラスタ[MATH] (要素数[MATH])を作成する．
(3)このとき，[MATH]回目のクラスタをマージしたクラスタ[MATH]の重心[MATH]は，式([REF_eq:NewG])のように計算される．
ここで，式([REF_eq:TransferedCor])において，マージされるクラスタの特徴ベクトル[MATH]に重み付けをしているため，重み付き平均の計算となるように，[MATH]にも同様の重みを乗じている．
このように本研究では，seedページを含むクラスタを重視してクラスタリングの基準を明確にし，正確なクラスタリングを行うことを目的とする．
もし，2つのクラスタが種用例を含まないのであれば，新たなクラスタの重心ベクトル[MATH]は，式([REF_eq:new centroid(agg)])のように計算される．
本研究では，seedページを含むクラスタに，それと最も類似したクラスタをマージする際，seedページを含むクラスタの重心の変動を抑える半教師有りクラスタリングを適用して，Web検索結果における人名の曖昧性を解消する．
従来の半教師有りクラスタリングの手法のうち，制約を導入する手法では，クラスタの基準となる重心についての検討は見逃されており，また，距離を学習する手法では，特徴空間が大域的に変換される．
一方，我々の手法は，seedページを含むクラスタの重心の変動を抑え，その重心を局所的に調整できる効果が期待される．
なお，seedページを導入することで，検索結果を改善することは，適合性フィードバック[CITE]に類似した手法であると考えられる．
しかし，適合性フィードバックでは，検索結果中の文書に対して，ユーザが判断した適合文書・非適合文書に基づいた検索語の修正を目的としているのに対し，本手法は，あらかじめ設定したseedページに基づいて，検索結果の改善，特に本研究においては，検索結果のクラスタリング精度の改善を目的としている点が異なる．
また，検索結果をクラスタリングする検索エンジンとして，``Clusty''が挙げられる．
しかし，そのクラスタリングされた検索結果には，適合しないWebページが含まれることも多く，クラスタリングを行う上で，何らかの基準が必要である．
すなわち，本研究のように，seedページをクラスタリングの基準として導入し，かつ，そのseedページを含むクラスタの重心を抑えることで，その基準を保つような手法が必要であると考えられる．
図[REF_Fig:SSClsAlgorithm]に，我々の提案する半教師有りクラスタリングアルゴリズムの詳細を示す．
なお，提案する半教師有りクラスタリングでは，対象とするすべてのWebページが，いずれかのseedページを含むクラスタにマージされるのではなく，seedページを含まないクラスタにもマージされることに，注意されたい（図[REF_Fig:SSClsAlgorithm]下から7行目，``else if''以降参照）．
ここで，本研究において比較する式([REF_eq:TransferedCor])直後に述べた(i)，(ii)，(iii)の3つの距離尺度は，それぞれ，以下のように定義される．
(i)ユークリッド距離
式([REF_eq:TransferedCor])において，ユークリッド距離を導入した場合，seedページを含むクラスタの重心ベクトル[MATH]と，あるクラスタ[MATH]の重心ベクトル[MATH]間の距離[MATH]は，式([REF_Eq:centroid vector])に基づいて，式([REF_Eq:Euclidean disrance])のように定義される．
(ii)マハラノビス距離
マハラノビス距離は，データ集合の相関を考慮した尺度であるという点において，ユークリッド距離とは異なる．
したがって，ユークリッド距離を用いるよりもマハラノビス距離を用いた方が，クラスタの重心の変動を，より効果的に抑えられることが期待される．
式([REF_eq:TransferedCor])において，マハラノビス距離を導入した場合，seedページを含むクラスタ[MATH]の重心ベクトル[MATH]と，あるクラスタ[MATH]の重心ベクトル[MATH]間の距離[MATH]は，式([REF_Eq:Mahalanobis distance])のように定義される．
ここで，[MATH]は，seedページを含むクラスタ[MATH]の要素によって定義される共分散行列である．
すなわち，クラスタ[MATH]内の要素を，
と表せば，重心ベクトル[MATH]，
を用いて，共分散[MATH]を式([REF_eq:CovMHD])のように定義することができる．
以上から，共分散行列[MATH]は，
と表すことができる．
(iii)適応的マハラノビス距離
(ii)のマハラノビス距離は，クラスタ内の要素数が少ないときに，共分散が大きくなる傾向がある．
そこで，seedページを含むあるクラスタ[MATH]について，このクラスタに含まれるWebページの特徴ベクトル間の非類似度を局所最小化することを考える．
この局所最小化で得られる分散共分散行列を用いて計算した[MATH]の重心ベクトル[MATH]と，このクラスタにマージされるクラスタ[MATH]の重心ベクトル[MATH]間の距離が，適応的マハラノビス距離[CITE]である．
この分散共分散行列は，次のように導出される．
(1)まず，クラスタ[MATH]において，このクラスタに含まれるWebページの特徴ベクトル[MATH]と，それ以外の特徴ベクトル[MATH] [MATH]との非類似度[MATH]を，式([REF_eq:intra-cls])により定義する．
ただし，[MATH]は[MATH]の分散共分散行列を表す．
すなわち，クラスタ[MATH]内の要素を，
と表せば，重心ベクトル[MATH]，
を用いて，共分散[MATH]を式([REF_eq:CovAMHD])のように定義することができる．
以上から，共分散行列[MATH]は，
と表すことができる．
(2)次に，目的関数
\Delta_{s_{j}}(\boldsymbol{v},\boldsymbol{M}_{s_{j}}) &= \sum_{w}^{p_{i}}\in C_{s_{j}}d_{s_{j}} (\boldsymbol{w}^{p_{i}},\boldsymbol{v})
& = \sum_{w}^{p_{i}}\in C_{s_{j}} (\boldsymbol{w}^{p_{i}}-\boldsymbol{v})^{T}\boldsymbol{M}_{s_{j}}^{-1} (\boldsymbol{w}^{p_{i}}-\boldsymbol{v})
を定義し，これを局所最小化するような[MATH]の代表点の特徴ベクトル[MATH]と分散共分散行列[MATH]を求める．
(i)まず，クラスタ[MATH]の要素により定義される共分散行列[MATH]を固定し，[MATH]を最小化する[MATH]を求める．
式([REF_eq:Lj])において，クラスタ[MATH]の重心[MATH]に最も近い点[MATH]の特徴ベクトルを[MATH]と表せば，[MATH]と求めることができる．
(ii)次に，(i)で求めた代表点の特徴ベクトル[MATH]を固定する．
ここで，[MATH]のもとで，[MATH]を局所最小化する[MATH]を求める．
この[MATH]は，クラスタ[MATH]の共分散行列[MATH]を用いて，式([REF_eq:AdpCov])によって与えられることが，文献[CITE]により示されている．
ただし，[MATH]であり，[MATH]は検索結果集合における単語の異なり数を表す．
以上から，seedページを含むあるクラスタ[MATH]において，Webページ間の非類似度を局所最小化することを考慮した分散共分散行列[MATH]を求めることができる．
この[MATH]を用いて，[MATH]の重心ベクトル[MATH]と，このクラスタにマージされるべきクラスタ[MATH]の重心ベクトル[MATH]間の適応的マハラノビス距離は，式([REF_Eq:Adapt. Mahalanobis distance])のように定義される．
なお，式([REF_Eq:Adapt. Mahalanobis distance])は，上述した(1)〜(2)によるクラスタ[MATH]におけるWebページ間の非類似度を考慮して得られた式([REF_eq:AdpCov])の分散共分散行列[MATH]を適用している点で，式([REF_Eq:Mahalanobis distance])とは異なる．
[REF_sec:Intro]章で述べた凝集型クラスタリングに基づいた人名の曖昧性解消は，クラスタリングを適切に導いていく基準がないため，正確なクラスタリングを行うことは難しい．
一方，これまでに提案されている半教師有りクラスタリングは，クラスタ数[MATH]をあらかじめ設定する必要がある[MATH]-meansアルゴリズム[CITE]を改良することを目的としている．
しかし，本研究においては，Web検索結果における同姓同名人物の数は，事前にわかっているわけではない．
したがって，我々の手法においては，事前にクラスタ数を設定するのではなく，新たに生成されたクラスタと，すでに生成されているクラスタ間の類似度を計算し，これらの値がすべて，あらかじめ設定した閾値よりも小さくなった場合に，クラスタリングの処理を終え，その時点で生成されているクラスタ数を最終的な同姓同名人物の数とする．
また，従来の半教師有りクラスタリングアルゴリズムは，制約を導入したり[CITE]，[CITE]，[CITE]，距離を学習したり[CITE]，[CITE]，[CITE]することにのみ着目していた．
しかし，半教師有りクラスタリングにおいて，より正確なクラスタリング結果を得るためには，seedページ間への制約の導入とともに，seedページを含むクラスタの重心の変動の抑制も重要である．
これは，(1) seedページを導入して半教師有りクラスタリングを行なう場合，通常の重心の計算法では重心の変動が大きくなる傾向にあり，クラスタリングの基準となるseedページを導入する効果が得られない，(2)重心を完全に固定して半教師有りクラスタリングを行なう場合，その重心と類似度が高いWebページしかマージされなくなり，多数の独立したクラスタが生成されやすくなる，という二つの考えに基づく．
したがって，seedページを含むクラスタの重心の変動を抑えることができれば，より適切なクラスタリングが実現できると期待される．
本章では，我々の提案する半教師有りクラスタリングの手法について説明する．
以下，検索結果集合[MATH]中のWebページ[MATH]の特徴ベクトル[MATH] [MATH]を式([REF_Eq:feature vector_org])のように表す．
ここで，[MATH]は検索結果集合[MATH]における単語の異なり数であり，[MATH] [MATH]は，各単語を表す．
予備実験として，(a) Term Frequency (TF)，(b) Inverse Document Frequency (IDF)，(c) residual IDF (RIDF)，(d) TF-IDF，(e) [MATH]-measure，(f) gainの6つの単語重み付け法を比較した．
これらの単語重み付け法は，それぞれ，次のように定義される．
(a) Term Frequency (TF)
TFは，与えられた文書において，ある単語がどれだけ顕著に出現するかを示し，この値が大きければ大きいほど，その単語が文書の内容をよく表現していることを示す．
[MATH]をWebページ[MATH]における単語[MATH]の頻度とする．
このとき，[MATH]の各要素[MATH]は，式([REF_eq: tf])によって定義される．
(b) Inverse Document Frequency (IDF)
[CITE]によって導入されたIDFは，その単語が出現する文書数が少なければ少ないほど，その単語が出現する文書にとっては，有用であることを示すスコアである．
このとき，[MATH]の各要素[MATH]は，式([REF_eq: idf])によって定義される．
ここで，[MATH]はWebページの総数，[MATH]は単語[MATH]が現れるWebページ数である．
(c) Residual Inverse Document Frequency (RIDF)
Church and Gale [CITE]は，ほとんどすべての単語は，ポアッソンモデルのような独立性に基づいたモデルに応じて，非常に大きなIDFスコアを持つことを示した．
また，単語の有用性は，推定されるスコアからは大きな偏差を持つ傾向があるという考えに基づいて導入したスコアがresidual IDFである．
このスコアは，実際のIDFとポアッソン分布によって推定されるIDFとの差として定義される．
[MATH]を文書集合中における単語[MATH]の総出現数，[MATH]をWebページの総数としたとき，1つのWebページあたりの単語[MATH]の平均出現数は，[MATH]と表される．
このとき，[MATH]の各要素[MATH]は，式([REF_eq: ridf])によって定義される．
w_{t_{k}}^{p_{i}} &= IDF - \log\frac{1}{1-p(0;\lambda_{i})} \nonumber
&= \log\frac{N}{df(t_{k})}+\log(1-p(0;\lambda_{k}))
ここで，[MATH]は，パラメータ[MATH]を伴うポアッソン分布である．
この手法は，少数の文書のみに出現する単語は，より大きなRIDFスコアを持つ傾向がある．
(d) TF-IDF
TF-IDF法[CITE]は，文書中の単語を重み付けするために，情報検索の研究において広く使われている．
TF-IDFは，上述した(a) TFと(b) IDFに基づいて，式([REF_eq: tfidf])のように定義される．
ここで，[MATH]と[MATH]は，それぞれ，Webページ[MATH]における単語[MATH]の頻度と，単語[MATH]が出現するWebページ数を表す．
また，[MATH]はWebページの総数である．
(e) [MATH]-measure
Bookstein and Swanson [CITE]は，単語[MATH]に対する[MATH]-measureというスコアを導入した．
[MATH]をWebページ[MATH]における単語[MATH]の頻度，[MATH]を単語[MATH]が現れるWebページ数とすると，[MATH]の各要素[MATH]は，式([REF_eq: xI])によって定義される．
この手法は，同程度の出現頻度である2つの単語のうち，少数の文書に集中して出現する単語ほど，高いスコアを示す．
(f) gain
一般に，IDFは単語の重要性を表すと考えられているが，Papineni [CITE]は，IDFは単語の特徴を表す最適な重みに過ぎず，単語の重要性とは異なるものであるため，利得を単語の重要性と考え，gainを提案した．
本手法では，[MATH]の各要素[MATH]は，式([REF_eq: gain])によって定義される．
ここで，[MATH]は，単語[MATH]が現れるWebページ数を，[MATH]はWebページの総数を示す．
本手法では，ほとんど出現しない単語と，非常に頻出する単語は，両方とも低いスコアとなり，中頻度の単語は高いスコアとなる．
上述した(a)〜(f)の単語重み付け手法の中で，本研究においては，``(f) gain''が最も効果的な単語の重み付け法であることがわかったため，これを本研究における単語の重み付け法として用いる．
さらに，クラスタ[MATH]の重心ベクトル[MATH]を式([REF_Eq:centroid vector])のように定義する．
ここで，[MATH]は[MATH]における各単語の重みであり，[MATH] [MATH]は各単語を表す．
なお，以下で述べるクラスタリング手法では，2つのクラスタ[MATH]，[MATH]間の類似度[MATH]を，式([REF_eq:sim])によって計算する．
ただし，[MATH]，[MATH]は，それぞれ，クラスタ[MATH]，[MATH]の重心ベクトルを表す．
凝集型クラスタリングにおいては，はじめに各Webページを，個々のクラスタとして設定する．
次に，二つのクラスタ間の類似度が，あらかじめ設定された閾値より小さくなるまで，類似度が最大となる二つのクラスタをマージして新たなクラスタを生成する．
図[REF_Fig:AggClsAlgorithm]に凝集型クラスタリングのアルゴリズムを示す．
このアルゴリズムでは，あるクラスタ[MATH] (要素数[MATH])を最も類似したクラスタ[MATH] (要素数[MATH])にマージした後の，新たなクラスタ[MATH]の重心ベクトル[MATH]は，式([REF_eq:new agg-centroid])のように定義される．
一般に，seedページを含むクラスタ[MATH]と，seedページを含まないクラスタ[MATH]の類似度が大きい場合には，両者を新たなクラスタとしてマージすべきであるが，両者の距離が大きい場合には，通常の重心の計算法では，重心の変動が大きくなる傾向にある．
そこで，はじめに，あるクラスタ[MATH](重心ベクトル[MATH])を，seedページを含むクラスタ[MATH](重心ベクトル[MATH])にマージする際，これらのクラスタの重心間の距離[MATH]に基づいて，Webページ[MATH]の特徴ベクトル[MATH]を重み付けする．
次に，この重み付けした特徴ベクトルを用いて重心の計算を行なうことで上述した傾向を防ぎ，重心の変動を抑える．
まず，これまでに[MATH]個のクラスタがマージされたseedページを含むクラスタ[MATH] (要素数[MATH])に対して，クラスタ[MATH] (要素数[MATH])が[MATH]回目にマージされるクラスタであるとする．
なお，クラスタ[MATH]の要素は，初期のseedページとなる．
(1)この[MATH]にマージされるクラスタ[MATH]に含まれる各要素について，[MATH]の重心[MATH]と，クラスタ[MATH]の重心[MATH]間の距離尺度[MATH]を用いて，クラスタ[MATH]に含まれるWebページの特徴ベクトル[MATH] [MATH]を重み付けし，その後に生成されるクラスタを[MATH] (要素数[MATH])とする．
このとき，[MATH]の要素となる重み付けした後のWebページの特徴ベクトル[MATH]は，式([REF_eq:TransferedCor])で表される．
本研究では，[MATH]として，(i)ユークリッド距離，(ii)マハラノビス距離，(iii)適応的マハラノビス距離，の三つの距離尺度を比較する．
また，[MATH]は[MATH]が0に非常に近い値となったとき，[MATH]の各要素が極端に大きな値となることを防ぐために導入した定数である．
この[MATH]の値の影響については，3.3.1節で述べる．
(2)次に，seedページを含むクラスタ[MATH] (要素数[MATH])に[MATH](要素数[MATH])の要素を追加し，クラスタ[MATH] (要素数[MATH])を作成する．
(3)このとき，[MATH]回目のクラスタをマージしたクラスタ[MATH]の重心[MATH]は，式([REF_eq:NewG])のように計算される．
ここで，式([REF_eq:TransferedCor])において，マージされるクラスタの特徴ベクトル[MATH]に重み付けをしているため，重み付き平均の計算となるように，[MATH]にも同様の重みを乗じている．
このように本研究では，seedページを含むクラスタを重視してクラスタリングの基準を明確にし，正確なクラスタリングを行うことを目的とする．
もし，2つのクラスタが種用例を含まないのであれば，新たなクラスタの重心ベクトル[MATH]は，式([REF_eq:new centroid(agg)])のように計算される．
本研究では，seedページを含むクラスタに，それと最も類似したクラスタをマージする際，seedページを含むクラスタの重心の変動を抑える半教師有りクラスタリングを適用して，Web検索結果における人名の曖昧性を解消する．
従来の半教師有りクラスタリングの手法のうち，制約を導入する手法では，クラスタの基準となる重心についての検討は見逃されており，また，距離を学習する手法では，特徴空間が大域的に変換される．
一方，我々の手法は，seedページを含むクラスタの重心の変動を抑え，その重心を局所的に調整できる効果が期待される．
なお，seedページを導入することで，検索結果を改善することは，適合性フィードバック[CITE]に類似した手法であると考えられる．
しかし，適合性フィードバックでは，検索結果中の文書に対して，ユーザが判断した適合文書・非適合文書に基づいた検索語の修正を目的としているのに対し，本手法は，あらかじめ設定したseedページに基づいて，検索結果の改善，特に本研究においては，検索結果のクラスタリング精度の改善を目的としている点が異なる．
また，検索結果をクラスタリングする検索エンジンとして，``Clusty''が挙げられる．
しかし，そのクラスタリングされた検索結果には，適合しないWebページが含まれることも多く，クラスタリングを行う上で，何らかの基準が必要である．
すなわち，本研究のように，seedページをクラスタリングの基準として導入し，かつ，そのseedページを含むクラスタの重心を抑えることで，その基準を保つような手法が必要であると考えられる．
図[REF_Fig:SSClsAlgorithm]に，我々の提案する半教師有りクラスタリングアルゴリズムの詳細を示す．
なお，提案する半教師有りクラスタリングでは，対象とするすべてのWebページが，いずれかのseedページを含むクラスタにマージされるのではなく，seedページを含まないクラスタにもマージされることに，注意されたい（図[REF_Fig:SSClsAlgorithm]下から7行目，``else if''以降参照）．
ここで，本研究において比較する式([REF_eq:TransferedCor])直後に述べた(i)，(ii)，(iii)の3つの距離尺度は，それぞれ，以下のように定義される．
(i)ユークリッド距離
式([REF_eq:TransferedCor])において，ユークリッド距離を導入した場合，seedページを含むクラスタの重心ベクトル[MATH]と，あるクラスタ[MATH]の重心ベクトル[MATH]間の距離[MATH]は，式([REF_Eq:centroid vector])に基づいて，式([REF_Eq:Euclidean disrance])のように定義される．
(ii)マハラノビス距離
マハラノビス距離は，データ集合の相関を考慮した尺度であるという点において，ユークリッド距離とは異なる．
したがって，ユークリッド距離を用いるよりもマハラノビス距離を用いた方が，クラスタの重心の変動を，より効果的に抑えられることが期待される．
式([REF_eq:TransferedCor])において，マハラノビス距離を導入した場合，seedページを含むクラスタ[MATH]の重心ベクトル[MATH]と，あるクラスタ[MATH]の重心ベクトル[MATH]間の距離[MATH]は，式([REF_Eq:Mahalanobis distance])のように定義される．
ここで，[MATH]は，seedページを含むクラスタ[MATH]の要素によって定義される共分散行列である．
すなわち，クラスタ[MATH]内の要素を，
と表せば，重心ベクトル[MATH]，
を用いて，共分散[MATH]を式([REF_eq:CovMHD])のように定義することができる．
以上から，共分散行列[MATH]は，
と表すことができる．
(iii)適応的マハラノビス距離
(ii)のマハラノビス距離は，クラスタ内の要素数が少ないときに，共分散が大きくなる傾向がある．
そこで，seedページを含むあるクラスタ[MATH]について，このクラスタに含まれるWebページの特徴ベクトル間の非類似度を局所最小化することを考える．
この局所最小化で得られる分散共分散行列を用いて計算した[MATH]の重心ベクトル[MATH]と，このクラスタにマージされるクラスタ[MATH]の重心ベクトル[MATH]間の距離が，適応的マハラノビス距離[CITE]である．
この分散共分散行列は，次のように導出される．
(1)まず，クラスタ[MATH]において，このクラスタに含まれるWebページの特徴ベクトル[MATH]と，それ以外の特徴ベクトル[MATH] [MATH]との非類似度[MATH]を，式([REF_eq:intra-cls])により定義する．
ただし，[MATH]は[MATH]の分散共分散行列を表す．
すなわち，クラスタ[MATH]内の要素を，
と表せば，重心ベクトル[MATH]，
を用いて，共分散[MATH]を式([REF_eq:CovAMHD])のように定義することができる．
以上から，共分散行列[MATH]は，
と表すことができる．
(2)次に，目的関数
\Delta_{s_{j}}(\boldsymbol{v},\boldsymbol{M}_{s_{j}}) &= \sum_{w}^{p_{i}}\in C_{s_{j}}d_{s_{j}} (\boldsymbol{w}^{p_{i}},\boldsymbol{v})
& = \sum_{w}^{p_{i}}\in C_{s_{j}} (\boldsymbol{w}^{p_{i}}-\boldsymbol{v})^{T}\boldsymbol{M}_{s_{j}}^{-1} (\boldsymbol{w}^{p_{i}}-\boldsymbol{v})
を定義し，これを局所最小化するような[MATH]の代表点の特徴ベクトル[MATH]と分散共分散行列[MATH]を求める．
(i)まず，クラスタ[MATH]の要素により定義される共分散行列[MATH]を固定し，[MATH]を最小化する[MATH]を求める．
式([REF_eq:Lj])において，クラスタ[MATH]の重心[MATH]に最も近い点[MATH]の特徴ベクトルを[MATH]と表せば，[MATH]と求めることができる．
(ii)次に，(i)で求めた代表点の特徴ベクトル[MATH]を固定する．
ここで，[MATH]のもとで，[MATH]を局所最小化する[MATH]を求める．
この[MATH]は，クラスタ[MATH]の共分散行列[MATH]を用いて，式([REF_eq:AdpCov])によって与えられることが，文献[CITE]により示されている．
ただし，[MATH]であり，[MATH]は検索結果集合における単語の異なり数を表す．
以上から，seedページを含むあるクラスタ[MATH]において，Webページ間の非類似度を局所最小化することを考慮した分散共分散行列[MATH]を求めることができる．
この[MATH]を用いて，[MATH]の重心ベクトル[MATH]と，このクラスタにマージされるべきクラスタ[MATH]の重心ベクトル[MATH]間の適応的マハラノビス距離は，式([REF_Eq:Adapt. Mahalanobis distance])のように定義される．
なお，式([REF_Eq:Adapt. Mahalanobis distance])は，上述した(1)〜(2)によるクラスタ[MATH]におけるWebページ間の非類似度を考慮して得られた式([REF_eq:AdpCov])の分散共分散行列[MATH]を適用している点で，式([REF_Eq:Mahalanobis distance])とは異なる．
