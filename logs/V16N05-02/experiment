実験
\label{sec:Experiments}

\subsection{実験データ}
\label{subsec:ExperimentalData}

本研究では，``Web People Search Task'' \cite{Artiles07} において
作成された 「WePS コーパス」を，実験に用いた．
この WePS コーパスは，訓練集合とテスト集合から構成され，それぞれ49，30，
合計で79の人名が含まれる．これらは，人名を検索語として，
Yahoo!\footnote{http://www.yahoo.com/} の検索APIを
通じて得られた上位100件の検索結果から取得されたものである．
すなわち，このコーパスは約7,900のWebページから構成される．
具体的な統計量を表\ref{tab:WePS-stat}に示す．

まず前処理として，このコーパスにおけるすべての
Webページに対して，
不要語リスト\footnote{ftp://ftp.cs.cornell.edu/pub/smart/english.stop} に
基づいて，不要語を取り除き，
Porter Stemmer \cite{Porter80}\footnote{http://www.tartarus.org/\~{}martin/PorterStemmer/} を用いて語幹処理を行なった．
次に，WePS コーパスの訓練集合を用いて類似したクラスタをマージする
ための最適なパラメータを決定し，これをWePS コーパスのテスト集合に
適用した．


\begin{table}[t]
 \caption{WePSコーパスにおける統計量} 
\label{tab:WePS-stat}
\input{06table01.txt}
\end{table}



\subsection{評価尺度}
\label{subsec:EvaluationMeasure}

本研究では，``purity''，``inverse purity''と，これらの調和平均である
$F$値 \cite{Hotho05} に基づいて，クラスタリングの精度を評価する．これらは，
``Web People Search Task'' において
採用されている標準的な評価尺度である．
以下，生成されたクラスタに割り当てられるべき，人手で定めた正解を「カテゴリ」と
呼ぶことにする．``purity''は，各クラスタにおいて最もよく現れるカテゴリの
頻度に注目し，ノイズの少ないクラスタを高く評価する．$C$を評価対象となるクラスタの
集合，$L$を人手で作成したカテゴリの集合，$n$をクラスタリング対象の
文書数とすると，purityは，式(\ref{eq:Purity})に基づいて，
最大となる適合率の重み付き平均をとることで計算される．
\begin{eqnarray}
Purity=\sum_{i}\frac{|C_{i}|}{n}\max Precision(C_{i}, L_{j}) \label{eq:Purity}  
\end{eqnarray}
ここで，あるカテゴリ$L_{j}$に対するクラスタ$C_{i}$の
適合率$Precision(C_{i},L_{j})$は，式(\ref{eq:Precision})によって
定義される．
\begin{eqnarray}
Precision(C_{i},L_{j})=\frac{|C_{i}\bigcap L_{j}|}{|C_{i}|} \label{eq:Precision}
\end{eqnarray}

``inverse purity''は，各カテゴリに対して最大の再現率となるクラスタに
着目する．ある一つのクラスタにおいて，各カテゴリで
定められた要素を多く含むクラスタを高く評価する．
inverse purityは，式(\ref{eq:InvPur})によって定義される．
\begin{eqnarray}
Inverse Purity=\sum_{j}\frac{|L_{j}|}{n}\max Recall(C_{i}, L_{j}) \label{eq:InvPur} 
\end{eqnarray}
ここで，あるカテゴリ$L_{j}$に対するクラスタ$C_{i}$の
再現率$Recall(C_{i},L_{j})$は，式(\ref{eq:Recall})によって
定義される．
\begin{eqnarray}
Recall(C_{i},L_{j})=\frac{|C_{i}\bigcap L_{j}|}{|L_{j}|} \label{eq:Recall}
\end{eqnarray}

また，purity と inverse purityの調和平均$F$は，式(\ref{eq:F})に
よって定義される．
\begin{eqnarray}
F=\frac{1}{\alpha\frac{1}{Purity}+(1-\alpha)\frac{1}{InversePurity}} \label{eq:F}
\end{eqnarray}
なお，本研究では，$\alpha=0.5$，$0.2$として，評価を行なった．
以下，$\alpha=0.5$，$0.2$のときの$F$値を，それぞれ，
$F_{0.5}$，$F_{0.2}$と示すことにする．


\subsection{実験結果}
\label{subsec:ExpResults}

我々の提案する半教師有りクラスタリングの手法では，次の
2種類の seed ページを用いた実験を行なった．
\begin{itemize}
 \item[(a)] Wikipedia \cite{Remy02} における各人物の記事，
 \item[(b)] Web検索結果において上位に順位付けされたWebページ．
\end{itemize} 


    \subsubsection{パラメータ$c$の設定}

我々の提案する手法では，
seedページを含むクラスタ$C_{s_{j}}$と，それに最も類似した
クラスタ$C_{i}$をマージした後の新しいクラスタの
重心ベクトルは，\ref{sec:ProposedMethod}章で述べたように，
式(\ref{eq:TransferedCor})に基づいて
クラスタ$C_{i}$に含まれるWebページの特徴ベクトル
$\boldsymbol{w}^{p_{l}}_{C_{i}}$ $(l=1,\cdots ,n_{i})$を
重み付けし，この重み付けした特徴ベクトルを用いて，式(\ref{eq:NewG})に
よって計算される．

式(\ref{eq:TransferedCor})における
$c$は，$D(\boldsymbol{G}^{C_{i}}, \boldsymbol{G}^{C_{s_{j}}})$が
0に非常に近い値となったとき，
$\boldsymbol{w}^{p}$の各要素が極端に大きな値となることを防ぐ
ために導入した定数であるが，この値によっては，
クラスタリングの精度にも影響が及ぶものと考えられる．
そこで，WePSコーパスの訓練集合を用いて，上述した2種類の
seedページ(a)，(b)ともに7個までのseedページを
用いた場合について，$0.1\le c\le 50$として
得られるクラスタリング精度について検証した．
ここで，seedページの数を7個までと定めたのは，
少数のseedページでの効果を確認するためである．
この結果，表\ref{Table:CbyEuclidDistance}
〜\ref{Table:CbyAdpMahalanobisDistance}に示す$c$の値のときに，
$F_{0.5}$，$F_{0.2}$ともに，最良なクラスタリング精度が得られた．

\begin{table}[b]
 \caption{ユークリッド距離を用いたときの最良なクラスタリング精度を与える$c$の値}
 \label{Table:CbyEuclidDistance}
\input{06table02.txt}
\end{table}


なお，以下の3.3.3節では，
距離尺度，seedページの種類とその数，
に応じて，表\ref{Table:CbyEuclidDistance}
〜\ref{Table:CbyAdpMahalanobisDistance}に示した$c$の値を，
WePSコーパスのテスト集合に適用して得られた
実験結果を示している．


\begin{table}[t]
 \caption{マハラノビス距離を用いたときの最良なクラスタリング精度を与える$c$の値}
 \label{Table:CbyMahalanobisDistance}
\input{06table03.txt}
\end{table}
\begin{table}[t]
 \caption{適応的マハラノビス距離を用いたときの最良なクラスタリング精度を与える$c$の値}
 \label{Table:CbyAdpMahalanobisDistance}
\input{06table04.txt}
\end{table}


\subsubsection{文書全体を用いた実験結果}

\noindent
\textbf{(1) 凝集型クラスタリングを用いた実験結果}

凝集型クラスタリングによって得られた精度を表\ref{Table:AggCls}に
示す．


\begin{table}[t]
 \caption{凝集型クラスタリングを用いて得られたクラスタリング精度}
 \label{Table:AggCls}
\input{06table05.txt}
\end{table}

\noindent
\textbf{(2) 半教師有りクラスタリングを用いた実験結果}

seedページを導入することによる効果を確かめるため，
はじめに一つの seedページを用いて実験を行なった．
この際，\ref{subsec:ExpResults}節はじめに述べた2種類の
seedページに関して，(a)は検索結果の上位にある
Wikipediaの記事を，(b)は第1位に順位付けされたWebページを
用いた．しかしながら，
\ref{subsec:ExperimentalData}節で述べたWePSコーパスの
テスト集合におけるすべての人名が，必ずしも Wikipedia に対応する
記事を有するわけではない．
したがって，ある人名が Wikipedia に
記事を有するのであれば，これをseed ページとして用いた．そうでなければ，
Web検索結果において第1位に順位付けされたWebページを用いた．この方針に
基づき，WePSコーパスのテスト集合における30の人名のうち，16の人名に
対してはWikipediaの記事を，
14の人名に対しては第1位に順位付けされたWebページをseedページとして
用いた．なお，人名の曖昧性解消にWikipediaを利用した最近の研究
として，Bunescu \cite{Bunescu06} らは，Wikipediaの構造を用いる
ことによって固有名を同定するとともに，その固有名の曖昧性を解消している．
表\ref{Table:OneSeedSSCls}に，
一つの seed ページでの半教師有りクラスタリングを用いて得られた
クラスタリング精度を示す．

\begin{table}[b]
 \hangcaption{1つのseedページを使い，提案する半教師有りクラスタリングを用いて得られたクラスタリング精度} 
\label{Table:OneSeedSSCls}
\input{06table06.txt}
\end{table}

さらに，一つの seed ページを用いた実験において，最も良い
$F$値($F_{0.5}=0.68$，$F_{0.2}=0.66$)が得られた
適応的マハラノビス距離に関して，seed ページの数を変えることによって，
さらなる実験を行なった．3.3.1節でも述べたように，
少数のseedページでの効果を確認するために，導入するseedページの数は
7個までとした．
また，図\ref{Fig:SSClsAlgorithm}に示したように，これらのseedページの
間には，``cannot-link''の制約を導入している．
これは，上位に順位付けされる検索エンジンの出力結果を信頼し，
それぞれのWebページが異なる人物について記述していると
想定していることに基づく．
図\ref{fig:multiple seeds (Wiki)}，\ref{fig:multiple seeds (Web)}は，
それぞれ, 複数のWikipedia記事，
上位7位までに順位付けされたWebページを用いて得られた
クラスタリング精度($F$値)を示す．

また，この実験では，
\ref{sec:ProposedMethod}章で述べたように，
seedページを含むクラスタの重心と，それにマージされるクラスタの重心間の
距離を考慮する．この提案手法の有効性を確認するために，
\ref{sec:Intro}章で述べた
距離を学習する半教師有りクラスタリング手法であるKleinら \cite{Klein02}，
Xingら\cite{Xing03}，Bar-Hillelら\cite{Bar-Hillel03} の手法を用いて
得られた結果との比較を示す．また，seedページを含むクラスタの
重心の変動を抑えることによる効果を確認するために，
重心を固定する手法との比較も示す．


\begin{figure}[t]
\begin{center}
\includegraphics{16-4ia3f3.eps}
\end{center}
\caption{複数のseedページを用いて得られたクラスタリング精度 (7つまでの Wikipedia記事)}
\label{fig:multiple seeds (Wiki)}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics{16-4ia3f4.eps}
\end{center}
\hangcaption{複数のseedページを用いて得られたクラスタリング精度 (上位7位までに順位付けされたWebページ)}
\label{fig:multiple seeds (Web)}
\end{figure}



    \subsubsection{文書を部分的に用いた実験結果}
\label{subsec:ExpResults(Fragments)}

3.3.2節で述べた実験では，
検索結果のWebページと seedページの全文を用いた．しかし，
人物について記述されたWebページにおいて，その人物を特徴付ける単語は，
人名の周囲にしばしば現れること，また，検索結果のスニペットにおいても，
同様の傾向が観察される．

そこで，seedページを用いて最も良い結果が
得られている場合，すなわち，図\ref{fig:multiple seeds (Wiki)}において，
5つのWikipedia記事を用いた場合($F_{0.5}=0.76, F_{0.2}=0.74$)
に，さらに精度が改善されるかを確認するために，
\begin{itemize}
 \item[(i)] seedページと検索結果のWebページにおいて，人名前後の単語，および文の数を変化させる， 
 \item[(ii)] 検索結果のスニペットを用いる， 
\end{itemize}
実験を行なった．

(i)については，まず，WePSコーパスの訓練集合を用いて，
最も良い$F$値を与えるseedページと検索結果のWebページの
それぞれにおいて用いる人名前後の単語数，または
文数を求める．この結果を図\ref{fig:multiple seeds (Partial)}に示す．
次に，これらのパラメータをテスト集合に適用し，評価する．
(ii)についても同様に，WePSコーパスの訓練集合を用いて，
最も良い$F$値を与えるseedページでの人名前後の単語数，または文数を求める．
この結果を図\ref{fig:RsltSnippet}に
示す．次に，これらのパラメータをテスト集合に適用し，評価する．
最終的に(i)，(ii)の実験によって得られたクラスタリング精度を，
表\ref{Table:ResultsByOthers}に示す．

\begin{figure}[t]
\begin{center}
\includegraphics{16-4ia3f5.eps}
\end{center}
\hangcaption{図\ref{fig:multiple seeds (Wiki)}における5つの seed ページ
(Wikipedia記事)の場合に, seedページと検索結果のWebページで用いる
人名前後の単語数と文数を変化させて得られるクラスタリング精度(``w'' と
 ``s'' は, それぞれ「単語」と「文」を表す)}
\label{fig:multiple seeds (Partial)}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics{16-4ia3f6.eps}
\end{center}
\hangcaption{図\ref{fig:multiple seeds (Wiki)}における5つの seed ページ
 (Wikipedia記事)の場合に，検索結果のスニペットを用い，seedページ中の人名前後
 の単語数と文数を変化させて得られるクラスタリング精度 
(``w'' と ``s'' は, それぞれ「単語」と「文」を表す)}
\label{fig:RsltSnippet}
\end{figure}



    \subsubsection{他手法との比較}
\label{subsec:ComparisonWithOthers}

``Web People Search Task''における上位3チームのクラスタリング
精度($F値$)を，表\ref{Table:ResultsByOthers}に示す．
なお，これらのチームで採用している手法の詳細については，
表\ref{Table:ResultsByOthers}に示した文献を参照されたい．
基本的には，凝集型クラスタリングの手法が採用されている．
また，提案手法によって得られた結果も，比較のために示す．

\begin{table}[t]
 \caption{Web People Search Task における上位3チームと提案手法とのクラスタリング精度の比較}
 \label{Table:ResultsByOthers}
\input{06table07.txt}
\end{table}


\subsection{処理時間に関する検討} 
\label{subsec:ProcessingTime}

3.3.2節で述べたように，
式(\ref{eq:TransferedCor})において，適応的マハラノビス距離を
用いて，seedページを含むクラスタにマージされるクラスタに含まれる
Webページの特徴ベクトルを重み付けし，この変換された特徴ベクトルを
用いて重心の計算を行なった場合に，
最良なクラスタリング精度が得られることがわかった．
この場合について，7つまでのWikipedia記事，
上位7位までに順位付けされたWebページを
seedページとして用い，最も処理時間を要すると考えられる
3.3.2節の文書全体を
用いた場合についての処理時間を測定した．なお，提案手法は，
PC (CPU: Intel Pentium M・2.0~GHz，Memory: 2~GByte，
OS: Windows XP) 上にPerlを用いて実装されている．
図\ref{fig:time}に，その結果を示す．


\begin{figure}[t]
\begin{center}
\includegraphics{16-4ia3f7.eps}
\end{center}
\caption{seedページ数を変化させたときのクラスタリングに要する処理時間}
\label{fig:time}
\end{figure}


\subsection{考察}
\label{subsec:Discussion}

式(\ref{eq:TransferedCor})における$c$の値について，特徴ベクトルを重み付けする際には，
表\ref{Table:CbyEuclidDistance}〜
\ref{Table:CbyAdpMahalanobisDistance}から
$c=0.95$前後の値を用いたときに，
最良なクラスタリング精度が得られることがわかった．
なお，$5\le c\le 50$の大きな値のときには，
それほど高いクラスタリング精度が得られないことも観察された．
これは，式(\ref{eq:TransferedCor})において，
距離尺度よりも$c$が支配的になることにより，クラスタにマージすべき
Webページの特徴ベクトルの各要素の値が小さくなりすぎることによる
影響であると考えられる．

凝集型クラスタリングの手法においては，
表\ref{Table:AggCls}から，purity (0.67) は，inverse purity (0.48) よりも
高いことがわかる．このように，purity が高いことは，
凝集型クラスタリングが，一つの要素しか含まないクラスタを生成する
傾向にあることを示す．また，$F$値が$F_{0.5}$=0.52，$F_{0.2}$=0.49
であり，それほど高い精度が得られていないことは，凝集型クラスタリングでは，
クラスタリングを適切に行なうことが難しいことを改めて確認できたといえる．

\ref{sec:ProposedMethod}章で述べた
半教師有りクラスタリングの手法において，
表\ref{Table:OneSeedSSCls}からpurity の値(0.47〜0.57)は，
表\ref{Table:AggCls}の凝集型クラスタリングを用いて
得られた purity の値(0.67)を上回ることができなかったが，
inverse purityの値(0.75〜0.88)は，すべての手法が
凝集型クラスタリングの値(0.48)を上回っていることがわかる．
また，良好なinverse purityの値によって，
$F$値においても，良い結果が得られている．
これは，seedページを導入したこと，ならびに，そのseedページを含むクラスタの
重心の変動を抑えられたことによる効果であると考えられる．
さらに，表\ref{Table:OneSeedSSCls}からは，seed ページとしてWikipediaの記事を
用い，適応的マハラノビス距離を適用した場合において，最も良い
$F$値($F_{0.5}=0.68$，$F_{0.2}=0.66$)が得られたことがわかる．

複数のseed ページを用いた半教師有りクラスタリング手法に
おいては，図\ref{fig:multiple seeds (Wiki)}，
\ref{fig:multiple seeds (Web)}から，次の内容が観察される．
まず，いずれのseedページを用いても，また，いずれの手法においても，
導入する種文書数の増加とともに，クラスタリング精度($F$値)が改善されて
いる．seedページの数について，7個まで導入したが，いずれのseedページ
とも5個の時点でのクラスタリング精度が最も良いことが観察される．
さらに，重心を固定する方法は，他の手法に比べて非常に
精度が劣る結果となった．これは，重心を完全に固定してしまうと，
その重心と類似度が高いWebページしかマージされなくなるため，
本来クラスタにマージされるべきWebページが独立したクラスタと
なってしまうことが原因であると考えられる．この実験においては，
高いpurityの値が得られていたことからも，上述した原因が
裏付けられるといえる．

一方，距離を学習するクラスタリング手法では，
Bar-Hillelら \cite{Bar-Hillel03}，Xingら \cite{Xing03}，
Kleinら \cite{Klein02} の手法の順に良いクラスタリング
精度が得られている．
\ref{sec:Intro}章で述べたように，
Kleinらの手法では，類似した2点($x_{i},x_{j}$)間を0，
類似していない2点間を($\max_{i,j} D_{ij}$)+1と設定した単純な隣接行列を
作成した上で，クラスタリングを行なうのに対し，
Xingら，Bar-Hillelらの方法では，特徴空間を適切に変換する
手法が用いられている．後者の二つの手法では，この変換手法が有効に作用している
ものと考えられる．しかし，これらの距離を学習する手法と比較しても，
重心の変動を抑えたクラスタリングを行なう我々の提案手法が，最も良いクラスタ
リング精度を示した．これは，
あるクラスタをseedページを含むクラスタにマージするたびに，
そのseedページを含むクラスタの重心を局所的に調整できることに
よる効果であると考えられる．

さらに，seedページについては，Wikipediaにおける各人物の記事を
用いたほうが，Web検索結果の上位に順位付けされたWebページを
用いるよりも良い精度が得られた．これは，
クラスタリングのためのseedページとして，Wikipediaの記述内容を
用いることが有効であることを示す事例であると考えられる．

また，文書を部分的に用いた場合には，以下に述べるような傾向が
観察される．まず，WePSコーパスの訓練集合において，
3.3.3節(i)で述べたように，
seedページ，および検索結果のWebページ中の人名前後の単語数または
文数を変化させた場合，
図\ref{fig:multiple seeds (Partial)}から，
検索結果のWebページに関して，単語よりも文を用いることで，
より良いクラスタリング精度が得られることが観察される．
これは，人名前後の数語のみでは，人物の実体を
識別することは難しいが，人名前後の数文を用いることで，
その人物を特徴付ける情報を獲得でき，人物の実体を識別しやすく
なったことによる効果であると考えられる．また，
図\ref{fig:multiple seeds (Partial)}からは，
seedページ，検索結果のWebページについて，
それぞれ，人名前後の2文，3文を用いた場合に最も良い
$F$値($F_{0.5}=0.79$，$F_{0.2}=0.80$)が得られることが
わかった．これらの文数をWePSコーパスのテスト集合に適用した場合，
[purity:0.80，inverse purity:0.83, $F_{0.5}=0.81$，$F_{0.2}=0.82$]の
結果が得られた．特に$F$値は，$\alpha=0.5$のとき，
表\ref{Table:ResultsByOthers}に示した
``Web People Search Task'' \cite{Artiles07} の
第1位のチーム (CU\_COMSEM) の結果を0.03上回り，提案手法が
有効であることが確認される．なお，3.3.2節(2)で述べたように，
Wikipediaに記事のある16人名のうち，Wikipediaから取得した
人名数は10 (表\ref{tab:WePS-stat}参照，以下(A)とする)，
ACL'06参加者リスト，アメリカ合衆国・国勢調査の人名のうち，
Wikipediaにも記事のある人名数は6（表\ref{tab:WePS-stat}参照，
以下(B)とする）である．
これらの人名について，Wikipediaをseedページとして
クラスタリングした場合に，その精度に差があるか否かを検証した．
その結果を表\ref{Table:WikiDetail}に
示す．(A)の方が(B)よりも，0.02〜0.04上回る結果が得られているが，
それほど大きな差ではない．このことから，seedページとして
Wikipediaの記述内容を用いることは，(B)のよう
に他分野から取得した人物のWebページに対しても有効であり，
Wikipediaの記述内容の汎用性が特徴付けられる結果であると考えられる．
また，クラスタ数については，seedページを導入したことで，このseedページを中心に，
Webページのグループが形成され，実際の正解クラスタ数よりも
少ない数のクラスタが生成される傾向が観察された．これは，表
\ref{Table:ResultsByOthers}において，inverse purityの値が高いことからも裏付けられる．


\begin{table}[b]
 \hangcaption{Wikipediaをseedページとした場合，(A) Wikipediaから取得した10人名と，(B) Wikipediaに記事はあるが，ACL'06参加者リスト，アメリカ合衆国・国勢調査から取得した6人名のクラスタリング精度の比較}
 \label{Table:WikiDetail}
\input{06table08.txt}
\end{table}
\begin{table}[b]
 \hangcaption{``Web People Search Task''の上位3チームが使用した素性を，提案する半教師有りクラスタリングに適用して得られたクラスタリング精度}
 \label{Table:ClsRsltsbyWePSFeat}
\input{06table09.txt}
\end{table}

なお，``Web People Search Task''の上位3チームは，
凝集型クラスタリングの手法を採用しているが，これらの手法は素性を
工夫することで，比較的高い精度を得ている．一方，我々の提案する
半教師有りクラスタリングでは，
seedページを含むクラスタの重心の変動を抑えることで，
表\ref{Table:AggCls}に示した凝集型クラスタリングよりも
精度が改善されている．我々が導入した素性は，
\ref{sec:ProposedMethod}章で述べたように，
gainによって単語を重み付けする簡単なものであるが，
``Web People Search Task''の上位3チームが使用した素性を
我々の手法に適用すれば，さらなる精度の向上が期待される．
そこで，これらの3チームの素性を，我々の手法で用いた結果を
表\ref{Table:ClsRsltsbyWePSFeat}に示す．
なお，表\ref{Table:ResultsByOthers}に示した我々の提案手法で
得られた最良の結果と比較するため，
seedページとしてWikipediaにおける各人物の記事を5つ導入した
場合についての比較を行った．
まず，CU\_COMSEMについて，表\ref{Table:ResultsByOthers}に示した
凝集型クラスタリングの$F$値($F_{0.5}=0.78$，$F_{0.2}=0.83$)と
比較して，半教師有りクラスタリングの$F$値も
高め($F_{0.5}=0.81$，$F_{0.2}=0.84$)となっている．
しかし，$F_{0.5}$で0.03，$F_{0.2}$で0.01程度の改善に
過ぎない．これは，文中の単語，URLのトークン，名詞句など，
すでに多くの素性を導入しているため，半教師有りクラスタリングを適用しても，
それほど効果は得られないことによると考えられる．
IRST-BPについては，表\ref{Table:ResultsByOthers}に示した
凝集型クラスタリングの$F$値($F_{0.5}=0.75$，$F_{0.2}=0.77$)と
比較しても，半教師有りクラスタリングの精度は
($F_{0.5}=0.76$，$F_{0.2}=0.81$)であり，改善の程度は
$F_{0.5}$で0.01，$F_{0.2}$で0.04であった．
このチームが使用している固有名詞，時制表現，人名のある
段落で最も良く出現する単語といった素性は，あまり有効な素性ではないと
考えられる．
PSNUSについては，NE素性をTF-IDFで重み付けしたのみの単純な
素性であるが，表\ref{Table:ResultsByOthers}に示した凝集型クラスタリングの
$F$値($F_{0.5}=0.75$，$F_{0.2}=0.78$)と比較して，
半教師有りクラスタリングで得られた$F$値は
$F_{0.5}=0.78$，$F_{0.2}=0.82$であり，$F_{0.5}$で0.03，$F_{0.2}$で0.04
の改善が観察される．一方，我々の手法では素性としてgainを用い，
表\ref{Table:ResultsByOthers}に示したとおり，
$F_{0.5}=0.81$，$F_{0.2}=0.82$の$F$値を得ている．
これは，CU\_COMSEMで使用されている多数の
素性で得られた$F$値とほぼ同じ値が得られていることから，gainによって単純に
Webページ中の単語を重み付けした素性だけでも，
我々の提案する半教師有りクラスタリングを適用することで，
高い精度が得られることが確認された．また，表\ref{Table:AggCls}に
示した凝集型クラスタリングによる
$F$値($F_{0.5}=0.52$，$F_{0.2}=0.49$)と比較しても，
$F_{0.5}$で0.29，$F_{0.2}$で0.33の改善が観察されたことから，
我々の提案する半教師有りクラスタリングの有効性が確認される．


次に，WePSコーパスの訓練集合において，
3.3.3節(ii)で述べたように，
検索結果のスニペットを用い，seedページ中の人名前後の単語数または
文数を変化させた場合，図\ref{fig:RsltSnippet}から，
seedページ中の人名前後の単語ではなく，同様に文を用いたときに，
より良いクラスタリング精度が得られることが観察される．
この場合も同様に，人名前後の数語の情報よりも，
人名前後の数文を用いることで，その人物を特徴付ける情報が
獲得でき，人物の実体が識別しやすくなった効果によるものと
考えられる．また，図\ref{fig:RsltSnippet}からは，
seedページについて，人名前後の3文を用いた場合に
最も良い$F$値($F_{0.5}=0.64$，$F_{0.2}=0.67$)が
得られることがわかった．この文数をWePSコーパスの
テスト集合に適用した場合，[purity:0.70，inverse purity:0.62，
$F_{0.5}=0.66$，$F_{0.2}=0.68$]の
結果が得られた．この結果は，Web People Search Taskの上位3チームの結果，
および本研究における他の実験結果と比較して，かなり劣っている．
これは，スニペットのような数語程度の情報だけでは，
seedページで人名前後の3文という情報を用いたとしても，
該当する人物について述べた適切なWebページが，
そのseedページには集まらず，結果として，クラスタリング精度が
悪くなったことによるためであると考えられる．

以上から，提案手法ではWikipediaの記事をseedページとして
利用し，人名前後の2文を，また，検索結果のWebページについては
人名前後の3文を用いた場合に，良好な検索結果が得られることが
わかった．

さらに，処理時間に関して，最良なクラスタリング精度が得られた
適応的マハラノビス距離の式(\ref{Eq:Adapt. Mahalanobis distance})に
おける分散共分散行列の計算には，単語数の2乗の計算量が必要となるが，
1人名について100件のWebページのクラスタリングを行なうのに，
最も多い5つのseedページを用い，seedページと検索結果のWebページの
双方ともに文書全体を用いた場合でも，0.8秒余りで
処理できることが図\ref{fig:time}から観察され，妥当な応答性を
実現できていると考えられる．


