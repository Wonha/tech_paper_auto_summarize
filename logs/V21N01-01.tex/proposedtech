    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvipdfm]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline



\usepackage{slashbox}
\makeatletter
\newcommand{\figref}[1]{}
\newcommand{\tblref}[1]{}
\newcommand{\secref}[1]{}
\newcommand{\chapref}[1]{}
\newcommand{\exref}[1]{}

\newcommand{\tblrefB}[1]{}
\newcommand{\secrefB}[1]{}

\newcommand{\newcite}[1]{}
\usepackage{url}
\urlstyle{rm}

\usepackage{multirow}

\usepackage{footnote}


\newcounter{enumsentencecounter} 
\setcounter{enumsentencecounter}{0} 
\newcommand{\enumsentence}[2]{}

\usepackage{algorithm}
\usepackage{algpseudocode}





\Volume{21}
\Number{1}
\Month{March}
\Year{2014}

\received{2013}{7}{5}
\revised{2013}{9}{16}
\rerevised{2013}{10}{13}
\accepted{2013}{10}{27}

\setcounter{page}{3}

\jtitle{述語と項の位置関係ごとの候補比較による日本語述語項構造解析}
\jauthor{林部　祐太\affiref{Author_1} \and 小町　　守\affiref{Author_2} \and 松本　裕治\affiref{Author_1}\vspace*{0.5\Cvs}}
\jabstract{
一般に，項は述語に近いところにあるという特性がある．
そのため，
従来の述語項構造解析の研究では，
候補を述語との位置関係でグループ分けし，
あらかじめ求めておいたグループ間の
優先順序に従って正解項を探索してきた．
しかしながら，その方法には
異なるグループに属する候補同士の比較ができないという問題がある．
そこで我々は，異なるグループごとに最尤候補を選出し，
それらの中から最終的な出力を決めるモデルを提案する．
このモデルは
優先度の高いグループに属する候補以外も参照することによって最終的な決定を行うことができ，
全体的な最適化が可能である．
実験では，提案手法は優先順序に従う解析よりも精度が向上することを確認した．
}
\jkeywords{述語項構造解析，項と述語の位置関係，探索先行分類型モデル\vspace*{1\Cvs}}


\etitle{Japanese Predicate Argument Structure Analysis by Comparing Candidates in Different Positional Relations between Predicate and Arguments}
\eauthor{Yuta Hayashibe\affiref{Author_1} \and Mamoru Komachi\affiref{Author_2} \and Yuji Matsumoto\affiref{Author_1}\vspace*{0.5\Cvs}} 
\eabstract{
In general, arguments are located near the predicate.
A previous study has exploited this characteristic to group candidates by positional relations
between a predicate and its candidate arguments and then searched for the final candidate using a predetermined priority list of the groups.
However, in such an analysis, candidates in different groups cannot be compared.
Therefore, we propose a Japanese predicate 
\linebreak
argument structure analysis model that gathers the most likely candidates from all the groups and then selects the final candidate amongst them.
We can account for candidates with less priority before making a final decision to perform global optimization.
Experimental results show that our model outperforms deterministic models. 
}
\ekeywords{predicate argument structure analysis, positional relations between predicates and arguments, selection-then-classification model}


\headauthor{林部・小町・松本}
\headtitle{述語と項の位置関係ごとの候補比較による日本語述語項構造解析}

\affilabel{Author_1}{奈良先端科学技術大学院大学}{Nara Institute of Science and Technology}
\affilabel{Author_2}{首都大学東京}{Tokyo Metropolitan University}


\begin{document}
\maketitle


\section{述語と項の位置関係ごとの候補比較による日本語述語項構造解析}
\label{sec:sca}

先行研究では，
優先順位の低い位置関係にある候補は参照されずに，解析が行われていた．
この方法は，
優先順位の高い位置関係にある項の同定の性能は上げることができるが，
優先順位の低い位置関係にある候補の再現率は下げてしまうという問題点がある．
また，
優先順位の低い位置関係にある候補も参照してから最終的な決定を行った方が，
全体的な解析性能が向上すると考える．




そこで我々は，
\emph{探索}と\emph{トーナメント}の
2つのフェーズからなる，
位置関係ごとに最尤候補を求めてから最終的な出力を決めるモデルを提案する．
                これは，「探索」・「分類」という2つのフェーズを持つ
                探索先行分類型モデル\cite{Iida:2005:TALIP}
                に着想を得て，
                後半の分類フェーズをトーナメント式に置き換えたものである．
なお，このモデルは格ごとに解析器を学習・使用する．


\subsection{項構造解析における探索先行トーナメントモデル}

\subsubsection{探索}

はじめのフェーズでは
任意の項同定モデルを用いて
INTRA\_D, INTRA\_Z, INTERの最尤候補を選出する．
それぞれ異なる素性やモデルを用いてもよい．
モデルには，
述語と探索対象の候補を入力として与え，
探索対象の候補の中の1つを出力させる．


\subsubsection{トーナメント}

次のフェーズでは
探索フェーズで得られた
3つの最尤候補を入力とし，
そのうちの1つか
``NO-ARG''を出力する．
これにより，
最尤候補のうちどれが正解項であるか，
もしくは項を持たないかを判断する．

このフェーズは
\figref{fig:anap-tournament-model}に示したように
(a)から(c)の3つの2値分類モデルで構成される．
なお，予備実験にて異なる順序を試したが，
文内最尤候補同士を(a)にて直接比較できる
この順序の性能が最も高かった．

\begin{itemize}
	  \setlength{\parskip}{0cm} 
	    \setlength{\itemsep}{0cm} 
\item[(a) ] INTRA\_DとINTRA\_Zを比較して，よりその述語の項らしい方を選ぶ

\item[(b) ] INTERと(a)で選出された候補を比較して，よりその述語の項らしい方を選ぶ

\item[(c) ] (b)で選出された候補と``NO-ARG''を比較して，よりその述語の項らしい方を選ぶ

\end{itemize}


(a)から(c)の分類器の学習事例には，
Algorithm \ref{alg:train}で示すように
探索フェーズで得られた
最尤候補を用いる．

\begin{figure}[t]
\begin{center}
\includegraphics{21-1ia1f1.eps}
\end{center}
\caption{トーナメントフェーズでの，位置関係が異なる候補からの項の同定}
\label{fig:anap-tournament-model}
\end{figure}



\subsection{提案手法の関連研究}
提案手法は2つのモデルを参考にしている．

1つ目は
名詞句の照応解析における
\emph{探索先行分類型モデル(selection-then-classification model)} \cite{Iida:2005:TALIP}である．
このモデルは最初に，
最尤先行詞を求める
（彼らはこれを``探索''と呼んだ）．
次に，その最尤先行詞を用いて，名詞句が実際に照応詞であるかどうかを判定する
（彼らはこれを``分類''と呼んだ）．
このモデルの利点は，
照応性を持たない名詞句も学習事例の生成に使えることである．
彼らは実験で，
最尤先行詞を用いて照応性判定を行ったほうが，
最尤先行詞を用いない場合よりも
高い性能が出ること確かめた．
提案手法も，
位置関係ごとに最尤候補を求めた後，
どの候補が実際に項であるのかを判定する．
最尤候補の探索を先に行なうことで，
位置関係ごとの最尤候補を学習事例の生成に用いることができる．


2つ目はゼロ照応解析における
\emph{トーナメントモデル} \cite{Iida:2004:IPSJ}である．
そのモデルは，
全ての先行詞候補（実際には先行する全ての名詞句）のペアに対して，
どちらがより先行詞らしいかの
2値分類を繰り返す．
トーナメントモデルの利点は候補間の関係性の素性を使うことができる点である．
提案手法のトーナメントフェーズでも同様に，
トーナメントモデルを用いて，
位置関係ごとに選出された最尤候補のペアから
どちらが正解項らしいかの2値分類を繰り返し，
候補間の比較を行うことができる．



\begin{algorithm}[p]
\caption{分類器(a) classifier\_a, (b) classifier\_b, (c) classifier\_c の学習事例の作成アルゴリズム}\label{alg:train}
\begin{algorithmic}
\Procedure{train}{predicate, gold\_argument, candidates}
\State gold\_argument\_type $\leftarrow$ getArgumentType(predicate, gold\_argument)\\
\Comment{正解項の位置関係を取得する}
\\
\State \Comment{位置関係ごとに最尤候補を取得する}
\State most\_likely\_candidate\_INTRA\_D $\leftarrow$ getMostLikelyCandidate(predicate, candidates, INTRA\_D)
\State most\_likely\_candidate\_INTRA\_Z $\leftarrow$ getMostLikelyCandidate(predicate, candidates, INTRA\_Z)
\State most\_likely\_candidate\_INTER $\leftarrow$ getMostLikelyCandidate(predicate, candidates, INTER)
\\
\If{gold\_argument\_type = NO\_ARG}
	\State MakeExample(classifier\_c, NO\_ARG, predicate, most\_likely\_candidate\_INTRA\_D)
	\State MakeExample(classifier\_c, NO\_ARG, predicate, most\_likely\_candidate\_INTRA\_Z)
	\State MakeExample(classifier\_c, NO\_ARG, predicate, most\_likely\_candidate\_INTER)
	\State \textbf{return}
\EndIf
\\
\State MakeExample(classifier\_c, HAVE\_ARG, predicate, gold\_argument)
\If{gold\_argument\_type = INTRA\_D}
	\State MakeExample(classifier\_a, INTRA\_D, predicate, gold\_argument, \\
		\hspace*{88pt}most\_likely\_candidate\_INTRA\_Z)
	\State MakeExample(classifier\_b, INTRA, predicate, gold\_argument, most\_likely\_candidate\_INTER)
\ElsIf{gold\_argument\_type = INTRA\_Z}
	\State MakeExample(classifier\_a, INTRA\_Z, predicate, gold\_argument, \\
		\hspace*{88pt}most\_likely\_candidate\_INTRA\_D)
	\State MakeExample(classifier\_b, INTRA, predicate, gold\_argument, most\_likely\_candidate\_INTER)
\ElsIf{gold\_argument\_type = INTER}
	\State MakeExample(classifier\_b, INTER, predicate, gold\_argument, most\_likely\_candidate\_INTRA\_D)
	\State MakeExample(classifier\_b, INTER, predicate, gold\_argument, most\_likely\_candidate\_INTRA\_Z)
\EndIf
\State \textbf{return}
\EndProcedure
\\
\Procedure{MakeExample}{classifier, label, predicate, candidate1, candidate2} \\
\Comment{candidate2は省略できる}
\State 項候補candidate1, candidate2が照応関係にあれば事例は作成しない．
\State 述語predicateと項候補candidate1, candidate2に対して，
	素性集合$F$を取得する．
\State 学習器classifierに対して，$F$を用いて，labelをラベルとする学習事例を1つ作成する．
\EndProcedure
\end{algorithmic}
\end{algorithm}


\section{議論}

\tblref{tbl:result-ga}, \ref{tbl:result-wo}, \ref{tbl:result-ni}にガ格・ヲ格・ニ格の実験結果を示す．
$P$, $R$, $F$, $A_M$はそれぞれPrecision, Recall, F値,
F値のマクロ平均（INTRA\_D, INTRA\_Z, INTERのF値の算術平均）を示す．


\begin{table}[tb]
\caption{ガ格の述語項構造解析の比較}
\label{tbl:result-ga}
\input{01table04.tex}
\end{table}
\begin{table}[tb]
\caption{ヲ格の述語項構造解析の比較}
\label{tbl:result-wo}
\input{01table05.tex}
\end{table}
\begin{table}[tb]
\caption{ニ格の述語項構造解析の比較}
\label{tbl:result-ni}
\input{01table06.tex}
\end{table}

ALLのF値に関して，
PPR$-$とPPRがIIDA2007と比較して有意差があるかどうかの検定を
Takamuraによるスクリプト\footnote{\url{http://www.lr.pi.titech.ac.jp/~takamura/pubs/randtest_fm.pl}}を用いて
Approximate Randomization Test \cite{Chinchor:1993:CL}を
行った
\footnote{このTestを行うためには
システムの出力によらずに事例の正解ラベルを定める必要があるため，
「項あり」のときにシステムが誤った出力した場合は，$fp$ではなく，$fn$として扱った．}．
0.05水準で有意であったものに，記号$^{*}$を付記した．


\subsection{決定的に項を同定していくモデルの比較}
\label{sec:discussion-determin}
IIDA2005, IIDA2007, IIDA2007+のALLのF値を比較することで，システム全体の性能について論じる．

\subsubsection{ガ格の性能}

ALLの性能を比較すると，
ガ格の性能は
IIDA2007$>$IIDA2005$>$IIDA2007+
である．

IIDA2007とIIDA2005の性能を比較すると，
PrecisionはIIDA2007の方が高く，RecallはIIDA2005の方が高い．
探索範囲を文内に限定することで，Precisionが上がることが分かる．
IIDA2007のINTERのRecallは減少しているが，
文間項よりも文内項の方が3倍以上多いため，
システム全体の性能としては
向上することが分かる．

IIDA2005とIIDA2007+の性能を比較すると，
INTRA\_Dを優先的に探索することで，INTRA\_DのPrecisionが上昇し，F値も上昇することが分かる．
INTRA\_ZのPrecisionも上昇するが，Recallは悪化し，
INTRA\_Zの分量が相当数あるため，全体としては性能が悪化することが分かる．


\subsubsection{ヲ格の性能}

ガ格と同様であるが，INTRA\_Zの数は比較的少ないため
INTRA\_Dを優先的に探索しても，精度はガ格ほど悪化しない．



\subsubsection{ニ格の性能}

ニ格の性能は
ガ格・ヲ格とは異なり，
IIDA2007+$\simeq$IIDA2007$>$IIDA2005
である．

この傾向は項の分布が影響している．
ニ格は\tblref{tbl:corpus-arg-dist}によると
全ての項のうち，
全体の90\%以上がINTRA\_Dである．
このため，INTRA\_Dの探索を優先し，INTRA\_DのRecallを上昇させることで，
全体としての性能を上昇させることができる．



\subsection{提案手法の効果}

決定的な解析では優先度の低い位置関係にある候補の再現率とF値が低下するため，
優先順序をつけるほどマクロ平均は下がっていく．
しかし，提案手法は全ての位置関係について最尤候補を比較するので，
マクロ平均を大きく下げずにマイクロ平均（ALLのF値）も向上させることができている．


PPRとPPR$-$のいずれも，IIDA2005・IIDA2007・IIDA2007$+$より性能が向上している．
そのため，
トーナメントフェーズで最尤候補を陽に比較する
提案モデルは，
決定的に項を同定していくモデルよりも効果があるといえる．

また，
PPRはPPR$-$と比較して，
ガ格・ニ格では性能はほとんど変わないが，
ヲ格では
INTRA\_DのPrecisionが向上したため，
全体の性能も向上していることが分かる．
そのため，文内項もINTRA\_DとINTRA\_Zで，
最尤候補の同定モデルを分けて陽に比較することで，
さらに性能を向上することがあると分かる．


\subsection{先行研究との比較}
\label{result:prevwork}

ガ格において，
提案手法は
\citeA{Taira:2008:EMNLP}と\citeA{Imamura:2009:ACL}の性能を上回っている．
\citeA{Imamura:2009:ACL}は候補同士の比較をせず，
\citeA{Taira:2008:EMNLP}は優先順序を用いた決定的な解析を行なっており，
それらが，提案手法と比べて性能が低い原因であると考える．
ヲ格では，
提案手法は
\citeA{Taira:2008:EMNLP}の性能を上回っており，
\citeA{Imamura:2009:ACL}とも同程度の性能を達成している．




しかしながら，ニ格では，
\citeA{Taira:2008:EMNLP}
が最も性能が高い．
\citeA{Imamura:2009:ACL}も，
ガ格・ヲ格では\citeA{Taira:2008:EMNLP}を上回る性能を発揮しているのにも関わらず， 
ニ格では\citeA{Taira:2008:EMNLP}よりも性能が低い．
この理由として，ニ格は
INTRA\_Dが最も多く，
他の格の解析結果に依存することが挙げられる．
一般に，1つの述語に対して異なる格で項を共有することはない．
しかし，提案手法も
\citeA{Imamura:2009:ACL}も各格で独立に解析を行なっており，
他の格の解析結果の利用ができない．
一方，
\citeA{Taira:2008:EMNLP}は
「項を含む文節が述語を含む文節に,他の格の項を介して係っている」という関係をモデル化(ga\_c, wo\_c, ni\_c)し，
他の格の解析結果を利用して
同時に解析を行なっている．
そのため，INTRA\_Dの解析性能が高いと考えられる．


\section{事例分析}

\subsection{成功事例}

\subsubsection{特定の位置関係を優先する決定的な解析モデル(IIDA)では解析できず，提案モデル(PPR)で解析できた事例}


\begin{table}[b]
\caption{IIDA2007（各セル左側）・PPR$-$（同中央）・PPR（同右側）のガ格の誤り事例のConfusion Matrix}
\label{tbl:confusion-matrix-ga}
\input{01table07.tex}
\end{table}

位置関係の優先順序を用いる
決定的な解析モデルの中で，全体的な性能が最も高い
IIDA2007と，
優先順位を持たない提案モデル(PPR$-$・PPR)を比較すると，
INTERのPrecisionが少し低下しているが，
Recallは上昇し，F値も上昇している．
ガ格の解析にて，
IIDA2007・PPR$-$・PPRが解析に誤った事例の内訳を
\tblref{tbl:confusion-matrix-ga}に
Confusion Matrixで示した．
PPR$-$やPPRでは，誤ってINTERを出力した事例が増えており
（3列目を参照），
一方で，
誤って「項なし」と判断した事例が減って
いることが分かる（4列目を参照）．
IIDA2007は文間の候補を参照せずに，文内最尤候補が項らしいか否かを判定しなければならないが，
PPR$-$やPPRは
文内最尤候補と文間最尤候補を比較した上で，項として何が適切かを判断できるため，
INTERのRecallを上昇させることができたと考える．
そして，これが全体の性能に影響している．


\subsubsection{2種類の最尤候補を用いるモデル(PPR$-$)では解析できず，3種類の最尤候補を用いる提案モデル(PPR)で解析できた事例}

PPR$-$とPPRを比較すると，
ガ格は
INTRA\_DとINTRA\_Zの
PrecisionとF値が上昇しており，
ヲ格は
INTRA\_DのPrecisionとF値が，
上昇している．



PPRは
INTRA\_Dの最尤候補同定モデルと
INTRA\_Zの最尤候補同定モデルの
2つの異なるモデルで
INTRA\_DとINTRA\_Zの最尤候補を選んでから，
陽にINTRA\_DのINTRA\_Zのどちらが項らしいかを比較することで，
正解項を同定しやすくなっていると考えられる．
これは，特に（候補数が増加する）長い文の中にある文内項の同定に効果があった．


\enumsentence{
一九五二年以来の不平等が続いている「日米航空協定」の平等化を実現するため、
\underline{「政府}$_{ガ}$が米側に、米航空会社の新規路線開設を今後\underline{認め}ない強硬\underline{方針}を通告していたことが、十三日明らかになった。
}{ex-ok2}

「認める」のガ格に対して，
PPR$-$では誤って「方針」を項として出力したが，
PPRは正しく「政府」を出力した．


\subsection{誤り分析}

項構造解析に失敗した事例を分析したところ，
誤り理由の上位3つは次のものであった．

1つ目は，談話の理解が必要な場合である．

以下の文で，「絡みつく」のニ格は「ユリカモメ」である．
しかし，
システムは
ニ格は項なしと判断してしまった．

\enumsentence{
       東京・上野の不忍池で、無残な姿の鳥が目立つ。
       片足が切れたユリカモメ。
       釣り糸を引っ掛けて取れなくなって、そのうちに足を切断してしまうケースが多い。

       竹ぐしが右の首に突き刺さった\underline{ユリカモメ}$_{ニ}$も。
       くしが十センチほど体の外にのぞく。
       水面に浮かんだ\underline{ゴム}$_{ガ}$が\underline{絡み付き}、もがくうちに首まで入ってしまったらしい。
}{error-1}

「ユリカモメ」が話題の中心であることが捉えられなかったことが
解析に失敗した理由として考えられる．
今回の実験で，談話を捉えるために，
Salient Reference Listを用いたが，
「絡み付く」の解析時に「ユリカモメ」はListには無いため，うまくいかない．
これを解析するためには，
「ユリカモメは負傷している」
「絡み付くは負傷に関する述語である」
という知識のもとで，
「ユリカモメが絡み付くのニ格である」という
推論が必要となる．
その知識を本文中から取得するには，
「鳥」や2回出てくる「ユリカモメ」が照応関係にあるという知識も必要となることから，
固有表現解析や共参照解析などと
推論を用いた述語項構造解析を同時に行うことで
互いに精度を高めあうことができると考える．



2つ目は，格フレームなどの情報を使った格の同時解析が必要な場合である．
次の文の「書く」のニ格は「日記」・ヲ格は「矛盾」とアノテートされているが，
システムはニ格は「項なし」・ヲ格は「日記」と判断した．

\enumsentence{
\underline{日記}$_{ニ}$には、小説の読後感や将来への夢、希望などをつづるようになり、
高校生になると、大学受験のこと、沖縄における政治の\underline{矛盾}$_{ヲ}$なども\underline{書く}ようになった。
}{error-2}

一般に，「書く」のニ格に「日記」が来ることは少ない．
しかし，
京都大学格フレーム\cite{Kawahara:2005:NLP}\footnote{\url{http://www.gsk.or.jp/catalog/GSK2008-B/catalog.html}}
のような
格フレーム辞書を用いれば，
「書く」は「日記」をニ格にとりうることがわかる．
\tblref{tbl:kaku-case}に
京都大学格フレームにおける「書く」の第1格フレームと第3格フレームを示した．
この表は，それぞれの格フレームを構成する格が
どのような項をどのくらい取るのかを，
WEBコーパス内の頻度付きで表している．
\tblref{tbl:kaku-case}より，
ヲ格に``補文''（ここでは「沖縄における政治の矛盾」）をとれば，
「問い」をニ格にとりうる，とわかる．


\begin{table}[b]
\caption{京都大学格フレームにおける「書く」の第1・第3格フレーム}
\label{tbl:kaku-case}
\input{01table08.tex}
\end{table}


3つ目は，一般の述語とは異なる扱いをすべき述語の場合である．
NAISTテキストコーパスでは
名詞述語
『名詞句$+$コピュラ「だ」』
も述語としてアノテーションされている．

\enumsentence{
\underline{欧州連合}$_{ガ}$
が十五カ国に拡大して初の交渉となる。
昨年は欧州市場での乗用車の売れ行き回復を受け、規制枠を若干上方修正したが、
今年については「昨年の新車登録台数集
計を踏まえて対応したい」と\underline{慎重姿勢だ}。
}{ex-c}

しかしながら，
名詞述語の振る舞いは他の述語とは明らかに異なり，
同一の素性・モデルで項を同定するのは難しい．
そのため，他の述語の解析モデルと分けるべきであると考える．

実際に，PPRを，名詞述語とそれ以外の述語で
単純に解析モデルを分けて学習・テストしたところ，
\tblref{tbl:result-copula-ga}に示したように\footnote{「全ての述語」は「名詞述語」と「その他の述語」からなる．}
ガ格のALLのF値が77.59から77.75と0.16ポイント上昇した．


大きな上昇がみられなかったのは，
項と名詞述語の意味的関係を既存の素性ではうまく捉えられないためだと考える．
名詞述語文の働きは様々で，
「ラッセルは哲学者だ」のように
ある事物がどのような範疇に属するのかを述べたり，
「この部屋の温度は19度だ」のように
記述を満たす値がどれなのかを述べたり
する\cite{Imada:2010:DThesis}．
このような関係は\secref{sec:feature}での素性では捉えられない．
そのため，
京都大学名詞格フレーム\cite{Sasano:2005:JNLP}
や
日本語語彙大系\cite{goitaikei}などの
名詞間の関係を捉える知識を用いる必要があると考える．

\begin{table}[t]
\caption{名詞述語とそれ以外の述語とでモデルを分けた場合のガ格の性能の比較}
\label{tbl:result-copula-ga}
\input{01table09.tex}
\end{table}





また，動詞にも一般動詞とは異なる振る舞いをする
動詞「なる」の解析誤りも多かった．


\enumsentence{
山花氏らにとっては、社会党が離脱を認めるか\underline{どうか}$_{ガ}$が、最初の\underline{関門}$_{ニ}$と\underline{なる}。
}{error-naru1}

\enumsentence{
\underline{長さ}$_{ガ}$ \underline{\mbox{40 メートル}}$_{ニ}$にも\underline{なる}3 両編成の大型トラック、ロードトレインに便乗して大乾燥地帯を行く蛭子。
}{error-naru2}

\enumsentence{
福井市の中心から足羽川を上流へ十キロたどると、\underline{そこ}$_{ガ}$はもうひなびた農村の\underline{たたずまい}$_{ニ}$と\underline{なる}。
}{error-naru3}

これらの事例の「なる」自体には意味はあまり持たず，
ニ格が名詞述語相当の意味を持っているとも言える．
そのため，名詞述語同様，解析モデルを分けるべきであると考える．


\end{document}

