\resp{三品らによって提案された類似度計算を用いた用例に基づく感情推定アルゴリズムは次の式で定式化される．
}
\resp{ここで{[MATH]}を入力文，{[MATH]}を推定結果となる感情，{[MATH]}を感情{[MATH]}のコーパス，{[MATH]}を{[MATH]}に含まれる文，{[MATH]}を{[MATH]}と{[MATH]}の類似度を返す関数とする．
三品らは{[MATH]}にBLEU{[CITE]}を用いている．
}この手法は，発話文を発話者の感情別に分類して構築した感情コーパスを用いることで感情推定を行う用例ベースの手法である．
発話文の分類先は，発話文の収集者が発話者の感情を判定することで決定する．
図[REF_fig:estimation]に発話文からの感情推定の流れを示す．
まず発話者の感情によって分類された感情コーパスを用意しておく．
次に発話者の感情を推定する対象となる発話文を入力とする．
そして，各感情コーパスに含まれる発話文と入力文との類似度を求める．
最後に各感情コーパス別に，得られた類似度の最大値を求める．
この類似度が入力文が表現している感情のスコアとなる．
スコアは0から1までの値をとり，値が大きいほどその感情を表しているという意味になる．
得られた類似度の中で最も値が大きい類似度の感情を，感情推定結果として出力する．
この方法では図[REF_fig:estimation]における類似度の計算にBLEUを用いている．
用例ベースではない手法では，単語や文末表現への感情属性の付与や，単語や文末表現の組み合わせから感情を導出するルールを作成する必要が出てくるため，作業コストが非常に高いと考えられる．
しかし従来手法のような用例ベースのシステムを構築する際には，発話文を集め，発話者の感情ごとに発話文を分類してコーパスを構築すればよく，用例ベースではない手法と比べて作業コストが低いと考えられる．
BLEUは機械翻訳システムが出力した複数の翻訳候補文から，システムの翻訳精度を評価するための尺度である．
BLEUは次のとおりに定義されている[CITE]．
なお，[CITE]では[MATH]を用いている．
\resp{{[MATH]}}は機械翻訳文\resp{{[MATH]}}と人による翻訳文\resp{{[MATH]}}における共通\NGRAM数の適合率（\NGRAM適合率）\resp{を返す関数}であり，[MATH]は機械翻訳文が人による翻訳文に比べて簡潔すぎることによる適合率のペナルティである．
三品らの方法では，BLEUにおける機械翻訳文をコーパス中の1文，人による翻訳文を入力文と変更して，類似度計算に用いている\resp{（以下，式({[REF_eq:bleu]})を{[MATH]}と表記する）}．
\NGRAM適合率\resp{{[MATH]}}は，入力文\respeqn{[MATH]}と感情コーパス中の1文\respeqn{[MATH]}の間で共通な\NGRAMが多く存在するかを表す値である．
共通な\NGRAMが多いほど\resp{{[MATH]}}は大きくなる．
\respeqn{[MATH]}と\respeqn{[MATH]}を用いて，\resp{{[MATH]}}は次のとおりに定義されている．
p_{n}(x,s) = \frac\sum_\in G_{n}(s)Count^{*}_{n}(x, s, \ngram)\sum_\in G_{n}(s)Count_{n}(s, \ngram)
Count^{*}_{n}(x, s, \ngram) = \min\left{Count_{n}(x, \ngram), Count_{n}(s, \ngram)\right}
\resp{ここで{[MATH]}を{[MATH]}に含まれる``連続する{[MATH]}個の形態素から作られる形態素N-gram''の集合を返す関数とする．
{[MATH]}は，{[MATH]}中の{[MATH]}の出現数を返す}．
\respeqn{[MATH]}が\respeqn{[MATH]}と共通な\NGRAMを持っていなければ\resp{{[MATH]}}は\resp{すべての{[MATH]}で}0になるため，\resp{{[MATH]}}は入力文と感情コーパス中の1文がどれほど共通な\NGRAMを持っているかの指標となる．
\resp{{[MATH]}}を求める例として，形態素unigramの適合率\resp{{[MATH]}}と形態素bigramの適合率\resp{{[MATH]}}を計算する．
\respeqn{[MATH]}を``明日からの旅行が楽しみです''，\respeqn{[MATH]}を``明日がすごく楽しみです''とする．
このときの形態素unigramの\resp{{[MATH]}}と\resp{{[MATH]}}の値を表[REF_table:count1]に示す．
表[REF_table:count1]と式([REF_eq:pn])より，\resp{{[MATH]}}は[MATH]であることがわかる．
また形態素bigramの\resp{{[MATH]}}と\resp{{[MATH]}}の値を表[REF_table:count2]に示す．
表[REF_table:count2]と式([REF_eq:pn])より，\resp{{[MATH]}}は[MATH]であることがわかる．
なお，形態素bigramには文頭や文末を表す記号は[CITE]と同様に用いていない．
ここでは感情コーパス中の1文\respeqn{[MATH]}が入力文\respeqn{[MATH]}に比べて簡潔すぎることによる適合率のペナルティBPについて説明する．
\respeqn{[MATH]}が\respeqn{[MATH]}に比べて簡潔すぎる場合，\respeqn{[MATH]}に含まれるほとんどの形態素を\respeqn{[MATH]}が含んでいる可能性がある．
この場合は[MATH]が大きくなり，BLEUスコアが高くなってしまう．
つまり，簡潔な文を数多く含んでいる感情コーパスのほうが，入力文との類似度が高くなりやすくなってしまうので，これを防ぐためにBPが用いられる．
\resp{{[MATH]}}を\resp{{[MATH]}}の形態素数を返す関数として，[MATH]は次のとおりに定義される．
\respeqn{[MATH]}を``明日からの旅行が楽しみです''，\respeqn{[MATH]}を``明日がすごく楽しみです''としたとき，[MATH]，[MATH]となるため，[MATH]となる．
これは\respeqn{[MATH]}が短かすぎるため，適合率へペナルティが課せられることを意味する．
三品らの方法には次のような文の影響を受け，感情推定に失敗する問題点がある．
感情が異なっていても，たまたま表現や文型が類似している文
コーパスを構築する際に誤って分類された文
これらの文が影響を及ぼしてしまう原因として，1文対1文の類似度のみを用いて感情推定を行っている点があげられる．
これが原因で，例えば``喜び''の文を入力したとしても，この入力文と表現や文型が類似している文が``希望''のコーパスに存在していれば，感情推定結果として``希望''が出力される可能性が非常に高くなる．
また，``喜び''の文を``希望''のコーパスに分類されてしまっていた場合，``喜び''の文を入力した時に``希望''が出力される可能性もある．
\resp{この問題を解決するために，形態素N-gram適合率に対して新たなペナルティFPを導入する．
FPは入力文の形態素列が各感情コーパスにどの程度偏って存在するかを表す指標であり，各感情コーパス中の出現頻度から計算される．
この指標を用いる理由は，入力文に含まれる形態素列が，他の感情コーパスに比べて相対的に数多く出現している感情コーパスの感情を，入力文は表現している可能性が高いのではないか，と考えたためである．
入力文{[MATH]}において，感情{[MATH]}に対するFPを次のとおりに定義する．
}
\resp{ここで{[MATH]}をすべての感情コーパス，{[MATH]}を感情コーパス{[MATH]}における{[MATH]}の出現回数を返す関数とする．
FPは，たまたま1文対1文の類似度が高かったとしても，類似度計算に用いている文を含むコーパスにおいて入力文の形態素列の出現回数が少なければ，求められる類似度を低く押さえる効果を持つ．
これにより，(1)と(2)の文による影響を改善する．
}
\resp{一般に，一部の文書に偏って存在している単語を表す指標として，TF-IDFがよく用いられている．
その意味では，FPのかわりにTF-IDFを用いる方法が考えられる．
しかしTF-IDFは，ある感情コーパス中の絶対的な出現頻度（tf値）を，他の感情コーパスにも出現しているかどうか，という形態素N-gramの一般性を示す値（idf値）を用いて修正したものであり，ある感情コーパス中での出現頻度が低い形態素N-gramであれば，たとえその感情コーパスに偏って存在していたとしても，その値は低いものとなる．
そのため，TF-IDFを類似度計算に導入したとしても，FPよりその効果は薄いものとなることが予想される．
}
従来手法で用いられていた\resp{{[MATH]}に{[MATH]}を導入し，更に式を適切に変更することで，``類似しているが感情が異なる文''や，``コーパス構築時に誤って分類されてしまった文''を含むコーパスに対して頑健な感情推定を行うための新たな類似度計算式RECARE}\resp{を定義する．
RECAREは二つの文に類似した表現が含まれており，かつ二つの文が同じ感情を表しているかどうかを表すスコアとなる．
}
\resp{まず，式（{[REF_eq:bleu]}）で定義される{[MATH]}に対し，前節で定義したFPを導入する（これを{[MATH]}と表記する）．
}
\respeqn{sim_BLEUFP^{+}(x,s)} & \respeqn{=} \respeqn{BP \cdot\exp\left^N_{n=1}\frac{1}N\log\left(FP_{n} \cdot p_{n}(x,s) \right)\right} \nonumber
& \respeqn{=} \respeqn{BP \cdot\exp\left{1}N\log\prod^N_{n=1} \left(FP_{n} \cdot p_{n}(x,s) \right)\right} \nonumber
& \respeqn{=} \respeqn{BP \cdot\exp\left\left^N_{n=1} \left(FP_{n} \cdot p_{n}(x,s) \right)\right^{1}N\right} \nonumber
& \respeqn{=} \respeqn{BP \cdot\left(\prod^N_{n=1} \left(FP_{n} \cdot p_{n}(x,s)\right) \right)^{1}N}
式([REF_eq:bleu_with_fp_pi])では\resp{{[MATH]}}の相乗平均を求めていることになるが，\resp{{[MATH]}}となる[MATH]が存在したとき，[MATH]となる．
これは[MATH]が高次になるほど起こりやすくなると考えられる（[MATH]が高次になるほど入力文とコーパス中の1文との共通な形態素N-gramが現れにくくなると考えられるためである）．
このままでは，低次の\resp{{[MATH]}}の情報も失われてしまう．
しかし，単語や文末表現の組み合わせによって発話文の感情が決まるとするならば，``隣接する形態素同士の組み合わせからなる低次の形態素N-gram''の適合率は積極的に利用すべきである．
高次の形態素N-gramの適合率が0になったとしても，低次の形態素N-gramの適合率を破棄する理由はない．
以上のことから，形態素N-gramの適合率の相乗平均を求めることは，用例ベースの感情推定には不向きであると考え，提案する新たな類似度計算式では形態素N-gramの適合率の相加平均を求めることとした．
以上のことから，\respeqn{RECARE}を次のとおりに定義する．
\resp{三品らによって提案された類似度計算を用いた用例に基づく感情推定アルゴリズムは次の式で定式化される．
}
\resp{ここで{[MATH]}を入力文，{[MATH]}を推定結果となる感情，{[MATH]}を感情{[MATH]}のコーパス，{[MATH]}を{[MATH]}に含まれる文，{[MATH]}を{[MATH]}と{[MATH]}の類似度を返す関数とする．
三品らは{[MATH]}にBLEU{[CITE]}を用いている．
}この手法は，発話文を発話者の感情別に分類して構築した感情コーパスを用いることで感情推定を行う用例ベースの手法である．
発話文の分類先は，発話文の収集者が発話者の感情を判定することで決定する．
図[REF_fig:estimation]に発話文からの感情推定の流れを示す．
まず発話者の感情によって分類された感情コーパスを用意しておく．
次に発話者の感情を推定する対象となる発話文を入力とする．
そして，各感情コーパスに含まれる発話文と入力文との類似度を求める．
最後に各感情コーパス別に，得られた類似度の最大値を求める．
この類似度が入力文が表現している感情のスコアとなる．
スコアは0から1までの値をとり，値が大きいほどその感情を表しているという意味になる．
得られた類似度の中で最も値が大きい類似度の感情を，感情推定結果として出力する．
この方法では図[REF_fig:estimation]における類似度の計算にBLEUを用いている．
用例ベースではない手法では，単語や文末表現への感情属性の付与や，単語や文末表現の組み合わせから感情を導出するルールを作成する必要が出てくるため，作業コストが非常に高いと考えられる．
しかし従来手法のような用例ベースのシステムを構築する際には，発話文を集め，発話者の感情ごとに発話文を分類してコーパスを構築すればよく，用例ベースではない手法と比べて作業コストが低いと考えられる．
BLEUは機械翻訳システムが出力した複数の翻訳候補文から，システムの翻訳精度を評価するための尺度である．
BLEUは次のとおりに定義されている[CITE]．
なお，[CITE]では[MATH]を用いている．
\resp{{[MATH]}}は機械翻訳文\resp{{[MATH]}}と人による翻訳文\resp{{[MATH]}}における共通\NGRAM数の適合率（\NGRAM適合率）\resp{を返す関数}であり，[MATH]は機械翻訳文が人による翻訳文に比べて簡潔すぎることによる適合率のペナルティである．
三品らの方法では，BLEUにおける機械翻訳文をコーパス中の1文，人による翻訳文を入力文と変更して，類似度計算に用いている\resp{（以下，式({[REF_eq:bleu]})を{[MATH]}と表記する）}．
\NGRAM適合率\resp{{[MATH]}}は，入力文\respeqn{[MATH]}と感情コーパス中の1文\respeqn{[MATH]}の間で共通な\NGRAMが多く存在するかを表す値である．
共通な\NGRAMが多いほど\resp{{[MATH]}}は大きくなる．
\respeqn{[MATH]}と\respeqn{[MATH]}を用いて，\resp{{[MATH]}}は次のとおりに定義されている．
p_{n}(x,s) = \frac\sum_\in G_{n}(s)Count^{*}_{n}(x, s, \ngram)\sum_\in G_{n}(s)Count_{n}(s, \ngram)
Count^{*}_{n}(x, s, \ngram) = \min\left{Count_{n}(x, \ngram), Count_{n}(s, \ngram)\right}
\resp{ここで{[MATH]}を{[MATH]}に含まれる``連続する{[MATH]}個の形態素から作られる形態素N-gram''の集合を返す関数とする．
{[MATH]}は，{[MATH]}中の{[MATH]}の出現数を返す}．
\respeqn{[MATH]}が\respeqn{[MATH]}と共通な\NGRAMを持っていなければ\resp{{[MATH]}}は\resp{すべての{[MATH]}で}0になるため，\resp{{[MATH]}}は入力文と感情コーパス中の1文がどれほど共通な\NGRAMを持っているかの指標となる．
\resp{{[MATH]}}を求める例として，形態素unigramの適合率\resp{{[MATH]}}と形態素bigramの適合率\resp{{[MATH]}}を計算する．
\respeqn{[MATH]}を``明日からの旅行が楽しみです''，\respeqn{[MATH]}を``明日がすごく楽しみです''とする．
このときの形態素unigramの\resp{{[MATH]}}と\resp{{[MATH]}}の値を表[REF_table:count1]に示す．
表[REF_table:count1]と式([REF_eq:pn])より，\resp{{[MATH]}}は[MATH]であることがわかる．
また形態素bigramの\resp{{[MATH]}}と\resp{{[MATH]}}の値を表[REF_table:count2]に示す．
表[REF_table:count2]と式([REF_eq:pn])より，\resp{{[MATH]}}は[MATH]であることがわかる．
なお，形態素bigramには文頭や文末を表す記号は[CITE]と同様に用いていない．
ここでは感情コーパス中の1文\respeqn{[MATH]}が入力文\respeqn{[MATH]}に比べて簡潔すぎることによる適合率のペナルティBPについて説明する．
\respeqn{[MATH]}が\respeqn{[MATH]}に比べて簡潔すぎる場合，\respeqn{[MATH]}に含まれるほとんどの形態素を\respeqn{[MATH]}が含んでいる可能性がある．
この場合は[MATH]が大きくなり，BLEUスコアが高くなってしまう．
つまり，簡潔な文を数多く含んでいる感情コーパスのほうが，入力文との類似度が高くなりやすくなってしまうので，これを防ぐためにBPが用いられる．
\resp{{[MATH]}}を\resp{{[MATH]}}の形態素数を返す関数として，[MATH]は次のとおりに定義される．
\respeqn{[MATH]}を``明日からの旅行が楽しみです''，\respeqn{[MATH]}を``明日がすごく楽しみです''としたとき，[MATH]，[MATH]となるため，[MATH]となる．
これは\respeqn{[MATH]}が短かすぎるため，適合率へペナルティが課せられることを意味する．
三品らの方法には次のような文の影響を受け，感情推定に失敗する問題点がある．
感情が異なっていても，たまたま表現や文型が類似している文
コーパスを構築する際に誤って分類された文
これらの文が影響を及ぼしてしまう原因として，1文対1文の類似度のみを用いて感情推定を行っている点があげられる．
これが原因で，例えば``喜び''の文を入力したとしても，この入力文と表現や文型が類似している文が``希望''のコーパスに存在していれば，感情推定結果として``希望''が出力される可能性が非常に高くなる．
また，``喜び''の文を``希望''のコーパスに分類されてしまっていた場合，``喜び''の文を入力した時に``希望''が出力される可能性もある．
\resp{この問題を解決するために，形態素N-gram適合率に対して新たなペナルティFPを導入する．
FPは入力文の形態素列が各感情コーパスにどの程度偏って存在するかを表す指標であり，各感情コーパス中の出現頻度から計算される．
この指標を用いる理由は，入力文に含まれる形態素列が，他の感情コーパスに比べて相対的に数多く出現している感情コーパスの感情を，入力文は表現している可能性が高いのではないか，と考えたためである．
入力文{[MATH]}において，感情{[MATH]}に対するFPを次のとおりに定義する．
}
\resp{ここで{[MATH]}をすべての感情コーパス，{[MATH]}を感情コーパス{[MATH]}における{[MATH]}の出現回数を返す関数とする．
FPは，たまたま1文対1文の類似度が高かったとしても，類似度計算に用いている文を含むコーパスにおいて入力文の形態素列の出現回数が少なければ，求められる類似度を低く押さえる効果を持つ．
これにより，(1)と(2)の文による影響を改善する．
}
\resp{一般に，一部の文書に偏って存在している単語を表す指標として，TF-IDFがよく用いられている．
その意味では，FPのかわりにTF-IDFを用いる方法が考えられる．
しかしTF-IDFは，ある感情コーパス中の絶対的な出現頻度（tf値）を，他の感情コーパスにも出現しているかどうか，という形態素N-gramの一般性を示す値（idf値）を用いて修正したものであり，ある感情コーパス中での出現頻度が低い形態素N-gramであれば，たとえその感情コーパスに偏って存在していたとしても，その値は低いものとなる．
そのため，TF-IDFを類似度計算に導入したとしても，FPよりその効果は薄いものとなることが予想される．
}
従来手法で用いられていた\resp{{[MATH]}に{[MATH]}を導入し，更に式を適切に変更することで，``類似しているが感情が異なる文''や，``コーパス構築時に誤って分類されてしまった文''を含むコーパスに対して頑健な感情推定を行うための新たな類似度計算式RECARE}\resp{を定義する．
RECAREは二つの文に類似した表現が含まれており，かつ二つの文が同じ感情を表しているかどうかを表すスコアとなる．
}
\resp{まず，式（{[REF_eq:bleu]}）で定義される{[MATH]}に対し，前節で定義したFPを導入する（これを{[MATH]}と表記する）．
}
\respeqn{sim_BLEUFP^{+}(x,s)} & \respeqn{=} \respeqn{BP \cdot\exp\left^N_{n=1}\frac{1}N\log\left(FP_{n} \cdot p_{n}(x,s) \right)\right} \nonumber
& \respeqn{=} \respeqn{BP \cdot\exp\left{1}N\log\prod^N_{n=1} \left(FP_{n} \cdot p_{n}(x,s) \right)\right} \nonumber
& \respeqn{=} \respeqn{BP \cdot\exp\left\left^N_{n=1} \left(FP_{n} \cdot p_{n}(x,s) \right)\right^{1}N\right} \nonumber
& \respeqn{=} \respeqn{BP \cdot\left(\prod^N_{n=1} \left(FP_{n} \cdot p_{n}(x,s)\right) \right)^{1}N}
式([REF_eq:bleu_with_fp_pi])では\resp{{[MATH]}}の相乗平均を求めていることになるが，\resp{{[MATH]}}となる[MATH]が存在したとき，[MATH]となる．
これは[MATH]が高次になるほど起こりやすくなると考えられる（[MATH]が高次になるほど入力文とコーパス中の1文との共通な形態素N-gramが現れにくくなると考えられるためである）．
このままでは，低次の\resp{{[MATH]}}の情報も失われてしまう．
しかし，単語や文末表現の組み合わせによって発話文の感情が決まるとするならば，``隣接する形態素同士の組み合わせからなる低次の形態素N-gram''の適合率は積極的に利用すべきである．
高次の形態素N-gramの適合率が0になったとしても，低次の形態素N-gramの適合率を破棄する理由はない．
以上のことから，形態素N-gramの適合率の相乗平均を求めることは，用例ベースの感情推定には不向きであると考え，提案する新たな類似度計算式では形態素N-gramの適合率の相加平均を求めることとした．
以上のことから，\respeqn{RECARE}を次のとおりに定義する．
