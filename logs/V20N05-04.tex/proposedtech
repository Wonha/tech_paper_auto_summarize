    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline



\Volume{20}
\Number{5}
\Month{December}
\Year{2013}

\received{2013}{5}{25}
\revised{2013}{7}{30}
\rerevised{2013}{9}{5}
\accepted{2013}{10}{4}

\setcounter{page}{707}

\jtitle{k 近傍法とトピックモデルを利用した語義曖昧性解消の領域適応}
\jauthor{新納　浩幸\affiref{Author_1} \and 佐々木　稔\affiref{Author_1}}
\jabstract{
本論文では語義曖昧性解消(Word Sense Disambiguation, WSD)の領域適応に対する手法を提案する．
WSD の領域適応の問題は，2つの問題に要約できる．1つは領域間で語義の分布が
異なる問題，もう1つは領域の変化によりデータスパースネスが生じる問題であ
る．本論文では上記の点を論じ，前者の問題の対策として学習手法に k~近傍法
を補助的に用いること，後者の問題の対策としてトピックモデルを用いるこ
とを提案する．具体的にはターゲット領域から構築できるトピックモデル
によって，ソース領域の訓練データとターゲット領域のテストデータ
にトピック素性を追加する．拡張された素性ベクトルから SVM を用いて語義識
別を行うが，識別の信頼性が低いものには k~近傍法の識別結果を用い
る．BCCWJ コーパスの2つの領域 PB（書籍）と OC（Yahoo!知恵袋）から共に頻度が 50 以上の
多義語 17 単語を対象にして，WSD の領域適応の実験を行い，
提案手法の有効性を示す．
別種の領域間における本手法の有効性の確認，
領域の一般性を考慮したトピックモデルを WSD に利用する方法，
および WSD の領域適応に有効なアンサンブル手法を考案することを今後の課題とする．
}
\jkeywords{語義曖昧性解消，領域適応，トピックモデル，k~近傍法，教師なし学習}

\etitle{Domain Adaptation for Word Sense Disambiguation using k-Nearest Neighbor Algorithm and Topic Model}
\eauthor{Hiroyuki Shinnou\affiref{Author_1} \and Minoru Sasaki\affiref{Author_1}} 
\eabstract{
In this paper, we propose the method of domain adaptation for word sense disambiguation (WSD).
This method faces the following problems for WSD. 
(1) The difference between sense distributions on domains.
(2) The sparseness of data caused by changing the domain.
In this paper, we discuss and recommend  the countermeasure for each problem.
We use the k-nearest neighbor algorithm (k-NN) and the topic model 
for the first and second problems, respectively.
In particular, we append 
topic features developed by the topic model for target domain corpus to 
to training data in source domain and test data in target domain.
Using the extended features of support vector machine (SVM) classifier, we solve WSD.
However, when the reliability of decision of the SVM classifier for a test instance is low,
we use the decision of the k-NN.
In the experiment, we select 17 ambiguous words 
in both domains, PB (books) and OC (Yahoo! Chie Bukuro) 
in the balanced corpus of contemporary written Japanese (BCCWJ corpus),
which appear 50 times or more in these domains,
and  conduct the experiment of domain adaptation for WSD using these words
to show the effectiveness of our method.
In the future, we will apply the proposed method to other domains and
examine a way to use the topic model considering 
the universality of a corpus,
and an effective ensemble learning for domain adaptation for WSD.
}
\ekeywords{Word Sense Disambiguation, Domain Adaptation, Topic Model, k-Nearest Neighbor Algorithm, Unsupervised Learning}

\headauthor{新納，佐々木}
\headtitle{k 近傍法とトピックモデルを利用した語義曖昧性解消の領域適応}

\affilabel{Author_1}{茨城大学工学部情報工学科}{Department of Computer and Information Sciences, Ibaraki University}



\begin{document}
\maketitle



\section{WSD の領域適応の問題}


WSD の対象単語\( w\)の語義の集合を\( C = \{c_1,c_2,\cdots,c_k \}\)，
\( w\)を含む文（入力データ）を\( x \)とする．
WSD の問題は最大事後確率推定を利用すると，以下の式の値を求める問題として表現できる．
\[
\arg \max_{c \in C } P(c) P(x|c)
\]
つまり訓練データを利用して語義の分布\( P(c) \) と各語義上での入力データの分布
\( P(x|c) \)を推定することで WSD の問題は解決できる．
今，ソース領域を\( S\)，ターゲット領域を\( T\)とした場合，
WSD の領域適応の問題は\( P_S (c) \ne P_T (c)\) と
\( P_S (x|c) \ne P_T (x|c)\) から生じている．

\( P_S (c) \ne P_T (c)\)が成立していることは明らかだが，
\( P_S (x|c) \ne P_T (x|c)\) に対しては一考を要する．
一般の領域適応の問題では\( P_S (x|c) \ne P_T (x|c)\)であるが，
WSD に限れば\( P_S (x|c) = P_T (x|c)\)と考えることもできる．
実際 Chan らは\( P_S (x|c) \) と \( P_T (x|c)\)の違いの影響は
非常に小さいと考え，\( P_S (x|c) = P_T (x|c)\)を仮定し，
\( P_T (c)\)を EM アルゴリズムで推定することで WSD の領域適応を
行っている\cite{chan2005word,chan2006estimating}．
古宮らは2つのソース領域の訓練データを用意し，そこからランダムに訓練データを取り出して
WSD の分類器を学習している\cite{komiya-nenji2013}．論文中では指摘していないが，これも
\( P_S (c)\)を\( P_T (c)\)に近づける工夫である．ソース領域が1つだとランダムに
訓練データを取り出しても\( P_S (c)\)は変化しないが，
ソース領域を複数用意することで\( P_S (c)\)が変化する．

ただし\( P_S (x|c) = P_T (x|c)\)が成立していたとしても，
WSD の領域適応の問題が\( P_T (c)\)の推定に帰着できるわけでない．
仮に\( P_S (x|c) = P_T (x|c)\)であったとしても，領域\( S \)の訓練データだけから
\( P_T (x|c)\)を推定することは困難だからである．
これは共変量シフトの問題\cite{shimodaira2000improving,sugiyama-2006-09-05}と関連が深い．
共変量シフトの問題とは入力\( x \)と出力\( y \)に対して，推定する分布\( P(y|x)\) が
領域\( S \)と\( T \)で共通しているが，\( S \)における入力の分布\( P_S(x) \)と
\( T \)における入力の分布\( P_T(x) \)が異なる問題である．
\( P_S (x|c) = P_T (x|c)\)の仮定の下では，入力\( x \)と出力\( c \)が逆になっているので，
共変量シフトの問題とは異なる．
ただし WSD の場合，全く同じ文\( x \)が別領域に出現したとしても，\( x \)内の多義語\( w \)
の語義が異なるケースは非常に稀であるため\( P_S (c|x) = P_T (c|x)\)が仮定できる．
\( P_T (c|x)\)は語義識別そのものなので，WSD の領域適応の問題は
共変量シフトの問題として扱えることができる．
共変量シフト下では訓練事例\( x_i \)に対して密度比\( P_T(x_i)/P_S(x_i) \)を推定し，
密度比を重みとして尤度を最大にするようにモデルのパラメータを学習する．
Jiang らは密度比を手動で調整し，
モデルにはロジステック回帰を用いている\cite{jiang2007instance}．
齋木らは\( P(x) \)を unigram でモデル化することで密度比を推定し，
モデルには最大エントロピーモデルを用いている\cite{saiki-2008-03-27}．
ただしどちらの研究もタスクは WSD ではない．
WSD では\( P(x) \)が単純な言語モデルではなく，「\( x \)は対象単語\( w \)を含む」
という条件が付いているので，密度比\( P_T(x)/P_S(x) \)の推定が困難となっている．
また教師なしの枠組みで共変量シフトの問題が扱えるのかは不明である．

本論文では\( P_S (c|x) = P_T (c|x)\)を仮定したアプローチは取らず，
\( P_S (x|c) = P_T (x|c)\)を仮定する．この仮定があったとしても，
領域\( S \)の訓練データだけから\( P_T (x|c)\)を推定するのは困難である．
ここではこれをスパース性の問題と考える．
つまり領域\( S \)の訓練データ\( D \)は領域\( T \)においてスパースになっていると考える．
スパース性の問題だと考えれば，半教師あり学習や能動学習を領域適応に応用するのは自然である
\footnote{ただし\( D \)は領域\( T \)内のサンプルではなく不均衡な訓練データという点には注意すべきであり，この点を考慮した半教師あり学習や能動学習が必要である．}
    (Rai, Saha, Daum{\'e}, and Venkatasubramanian 2010)\nocite{rai2010domain}．
また半教師あり学習や能動学習のアプローチを取った場合，
\( T \)の訓練データが増えるので語義の分布の違い自体も同時に解消されていく\cite{chan2007domain}．

ここで指摘したいのは\( P_S (x|c) = P_T (x|c)\)が成立しており\( P_T (x|c)\)の推定を
困難にしているのがスパース性の問題だとすれば，領域\( S \)の訓練データ\( D \)は
多いほどよい推定が行えるはずで，\( D \)が大きくなったとしても推定が悪化するはずがない点である．
しかし現実には\( D \)を大きくすると WSD 自体の精度が悪くなる場合もあることが報告されている
（例えば\cite{komiya-nenji2013}）．
これは一般に負の転移現象\cite{rosenstein2005transfer}と呼ばれている．
WSD の場合\( P_T (x|c)\)を推定しようとして，逆に語義の分布\( P_T (c)\)の推定が悪化することから
生じる．
つまり領域\( T \)における WSD の解決には\( T \)におけるデータスパースネスの問題に対処しながら，
同時に\( P_T (c)\)の推定が悪化することを避けることが必要となる．

また領域適応ではアンサンブル学習も有効な手法である．
アンサンブル学習自体はかなり広い概念であり，
実際，バギング，ブースティングまた混合分布もアンサンブル学習の一種である．
    Daum{\'e}らは領域適応のための混合モデルを提案している(Daum{\'e} and Marcu 2006)\nocite{daume2006domain}．
そこでは，ソース領域のモデル，ターゲット領域のモデル，そして
ソース領域とターゲット領域を共有したモデルの3つを混合モデルの構成要素としている．
Dai らは代表的なブースティングアルゴリズムの AdaBoost を領域適応の
問題に拡張した TrAdaBoost を提案している\cite{Dai2007}．
また Kamishima らはバギングを領域適応の学習用に拡張した TrBagg を提案している\cite{kamishima2009trbagg}．
WSD の領域適応については古宮の一連の研究\cite{komiya2,komiya3,komiya-nlp2012}があるが，
そこではターゲット領域のラベルデータの使い方に応じて学習させた複数の分類器を用意しておき，
単語や事例毎に最適な分類器を使い分けることで，WSD の領域適応を行っている．
これらの研究もアンサンブル学習の一種と見なせる．



\section{提案手法}

\subsection{k~近傍法の利用}

領域\( T \)におけるデータスパースネスの問題に対処する際に，\( P_T (c)\)の推定が
悪化することを避けるために，
本論文では識別の際に\( P_T (c)\)の情報をできるだけ利用しないという方針をとる．
そのために k~近傍法を利用する．
どのような学習手法を取ったとしても，何らかの汎化を行う以上，\( P_T (c)\)の影響を受けるが，
k~近傍法はその影響が少ない．
k~近傍法はデータ\( x \)のクラスを識別するのに，訓練データの中から\( x \)と近いデータ
\( k \)個を取ってきて，それら\( k \)個のデータのクラスの多数決により\( x \)のクラスを識別する．
\mbox{k~近傍法}が\( P_T (c)\)の影響が少ないのは\( k = 1\)の場合（最近傍法）を考えればわかりやすい．
例えば，クラスが\( \{ c_1, c_2 \} \) であり，\( P(c_1) = 0.99 \)，\( P(c_2) = 0.01 \)であった場合，
通常の学習手法であれば，ほぼ全てのデータを\( c_1 \)と識別するが，
最近傍法では，入力データ\( x \)と最も近いデータ 1 つだけがクラス\( c_2 \)であれば，
\( x \)のクラスを\( c_2 \)と判断する（\mbox{図\ref{zu1}}参照）．
つまりk~近傍法ではデータ全体の分布を考慮せずに\( k \)個の局所的な近傍データのみで
クラスを識別するために，その識別には\( P_T (c)\)の影響が少ない．

\begin{figure}[t]
\begin{center}
\includegraphics{20-5ia4f1.eps}
\end{center}
\caption{分布の影響が少ない k-NN}
\label{zu1}
\vspace{-1\Cvs}
\end{figure} 

ただし k~近傍法は近年の学習器と比べるとその精度が低い．
そのためここでは k~近傍法を補助的に利用する．
具体的には通常の識別は SVM で行い，SVM での識別の信頼度が
閾値\( \theta \)以下の場合のみ，k~近傍法の識別結果を利用することにする．

ここで\( \theta \)の値が問題だが，語義の数が\( K \)個である場合，
識別の信頼度（その語義である確率）は少なくとも\( 1/K \)以上の値となる．
そのためここではこの値の1割をプラスし\( \theta = 1.1/K \) とした．
なおこの値は予備実験等から得た最適な値ではないことを注記しておく．



\subsection{トピックモデルの利用}

領域\( T \)におけるデータスパースネスの問題に対処するために，ここでは
トピックモデルを利用する．

WSD の素性としてシソーラスの情報を利用するのもデータスパースネスへの 1 つの
対策である．シソーラスとしては，分類語彙表などの手作業で構築されたものと
コーパスから自動構築されたものがある．前者は質が高いが分野依存の問題がある．
後者は質はそれほど高くないが，分野毎に構築できるという利点がある．
ここでは領域適応の問題を扱うので，後者を利用する．
つまり領域\( T \)からシソーラスを自動構築し，そのシソーラス情報を
領域\( S \)の訓練事例と領域\( T \)のテスト事例に含めることで，
WSD の識別精度の向上を目指す．
注意として，WSD では単語間の類似度を求めるためにシソーラスを利用する．
そのため実際にはシソーラスを構築するのではなく，単語間の類似度が測れる仕組みを
作っておけば良い．この仕組みが単語のクラスタリング結果に対応する．
つまり WSD での利用という観点では，シソーラスと単語クラスタリングの結果は
同等である．そのため本論文においてシソーラスと述べている部分は，
単語のクラスタリング結果を指している．

この単語のクラスタリング結果を得るためにトピックモデルを利用する．
トピックモデルとは文書\( d \)の生起に\( K \)個の潜在的なトピック\( z_i \)を
導入した確率モデルである．
\[
p(d) = \sum_{i = 1}^{K} p(z_i) p(d |z_i)
\]
トピックモデルの 1つである Latent Dirichlet Allocation (LDA) \cite{blei}を用いた場合，
単語\( w \)に対して\( p(w|z_i) \)が得られる．
つまりトピック\( z_i \)をひとつのクラスタと見なすことで，
LDA を利用して単語のソフトクラスタリングが可能となる．

領域\( T \)のコーパスと LDA を利用して，\( T \)に適した\( p(w|z_i) \)が得られる．
\( p(w|z_i) \)の情報を WSD に利用するいくつかの研究\cite{li,boyd1,boyd2}があるが，
ここではハードタグ\cite{cai}を利用する．
ハードタグとは\( w \)に対して最も関連度の高いトピック\( z_{\hat{i}} \)を付与する方法である．
\[
\hat{i} = \arg \max_{i} p(w|z_i) 
\]
まずトピック数を\( K \)としたとき，\( K \)次元のベクトル\( t \)を用意し，
入力事例\( x \)中に\( n \)種類の単語\( w_1, w_2, \cdots, w_n \)が存在したとき，
各\( w_j \)(\(j = 1 \sim n\))に対して最も
関連度の高いトピック\( z_{\hat{i}} \)を求め，\( t \)の\( \hat{i} \)次元の
値を 1 にする．これを\( w_1 \)から\( w_n \)まで行い\( t \)を完成させる．
作成できた\( t \)をここでは{\bf トピック素性}と呼ぶ．
トピック素性を通常の素性ベクトル（ここでは{\bf 基本素性}と呼ぶ）に結合することで，
新たな素性ベクトルを作成し，その素性ベクトルを対象に学習と識別を行う．

なお，本論文で利用した基本素性は，対象単語の前後の単語と品詞及び
対象単語の前後3単語までの自立語である．


\section{考察}

\subsection{語義分布の違い}

本論文では，WSD の領域適応は語義分布の違いの問題を解決するだけは
不十分であることを述べた．Naive Bayes を利用して，この点を調べた．
Naive Bayes の場合，以下の式で語義を識別する．
\[
\arg \max P_S(c) P_S(x|c)
\]
ここで事前分布\( P_S (c) \)の代わりに領域\( T \)の訓練データから推定した
\( P_T (c) \)を用いる．これは語義分布を正確に推定できたという仮定での仮想的な実験である．
結果を\mbox{表\ref{gogibunpu}}に示す．

\begin{table}[b]
\caption{理想的語義分布の推定による識別}
\label{gogibunpu}
\input{04table08.txt}
\end{table}

全体として理想的な語義分布を利用すれば，正解率は改善されるが，効果はわずかしかない．
また PB から OC の「前」や OC から PB の「見る」「持つ」は逆に精度が悪化している．
更に理想的な語義分布を利用できたとしても，通常の SVM よりも正解率が劣っている．
これらのことから，語義分布の正確な推定のみでは WSD の領域適応の解決は困難で
あることがわかる．


\subsection{トピックモデルの領域依存性の度合い}

WSD においてデータスパースネスの問題の対処として，
シソーラスを利用することは一般に行われてきている．
LDA から得られるトピック\( z_i \)のもとで単語\( w \)が
生起する確率\( p(w|z_i) \)は，単語のソフトクラスタリング結果に対応しており，
これは LDA の処理対象となったコーパスに合ったシソーラスと見なせる．
このためトピックモデルが WSD に利用できることは明らかである．
ただしその具体的な利用方法は確立されていない．

問題は2つある．1つはトピック素性の表現方法である．
ここではハードタグを利用したが，ソフトタグの方が優れているという報告もある\cite{cai}．
國井はハードタグとソフトタグの中間にあたるミドルソフトタグを提案している\cite{kunii}．
いずれにしても，トピック素性の有効な表現方法はトピック数やコーパスの規模にも依存した問題であり，
どういった表現方法で利用すれば良いかは未解決である．

もう1つの問題はトピックモデルから得られるシソーラスの領域依存性の度合いである．
本論文でも LDA から領域依存のトピックモデルが作成できることに
着目してトピックモデルを領域適応の問題に利用した．
ただし領域\( A \)のコーパスと領域\( B \)のコーパスがあった場合，
各々のコーパスから各々の知識を獲得するよりも，両者のコーパスを合わせて
両領域の知識を獲得した方が，一方のコーパスから得られる知識よりも優れている
ことがある．
例えば森は単語分割のタスクにおいて，各々の領域のタグ付きデータを使うことで精度を上げることが
できたが，全ての領域のタグ付きデータを使えば
更に精度を上げることができたことを報告している\cite{mori}．
領域の知識を合わせることは，その知識をより一般的にしていることであり，
領域依存の知識はあまり領域に依存しすぎるよりも，ある程度，
一般性があった方がよいという問題と捉えられる．
本実験で言えば PB のコーパスと OC のコーパスと両者を合わせて学習した
トピックモデルは，各々のコーパスから学習したトピックモデルよりも優れている可能性がある．
以下その実験の結果を\mbox{表\ref{bunruigoi}}に示す．

\begin{table}[t]
\caption{両領域コーパスを利用した識別}
\label{bunruigoi}
\input{04table09.txt}
\end{table}

ターゲット領域が PB の場合，ソース領域の OC のコーパスを追加することで正解率は低下するが，
ターゲット領域が OC の場合，ソース領域の PB のコーパスを追加することで正解率が向上する．
これは OC（Yahoo!知恵袋）のコーパスの領域依存が強いが，
その一方で，PB（書籍）のコーパスの領域依存が弱く，より一般的であることから
生じていると考える．
一般性の高い領域に領域依存の強い知識を入れると性能が下がるが，
より特殊な領域には，その領域固有の知識に一般的知識を組み入れることで
性能が更に向上すると考えられる．これらの詳細な分析と対策は今後の課題である．



\subsection{k~近傍法の効果とアンサンブル手法}

本論文では SVM での識別の信頼度の低い部分を k~近傍法の識別結果に置き換えるという
処理を行った．置き換えが起こったものだけを対象にして，
k~近傍法と SVM での正解数を比較した．
結果を\mbox{表\ref{tab:change1}}と\mbox{表\ref{tab:change2}}に示す．

PB から OC への領域適応では「子供」，OC から PB への領域適応では「入れる」については
SVM の方が k~近傍法の方よりもよい正解率だが，それ以外は
k~近傍法の正解率は SVM の正解率と等しいかそれ以上であった．
つまり SVM で識別精度が低い部分に関しては，k~近傍法で識別する効果が確認できる．

また k~近傍法の\( k \)をここでは\( k = 1 \)とした．この\( k \)の値を
3 や 5 に変更した実験結果を\mbox{図\ref{kekka3}}と\mbox{図\ref{kekka4}}に示す．

\begin{table}[p]
\begin{minipage}[t]{.45\textwidth}
\caption{識別結果の変更(PB → OC)}
\label{tab:change1}
\input{04table10.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\caption{識別結果の変更(OC → PB)}
\label{tab:change2}
\input{04table11.txt}
\end{minipage}
\end{table}
\begin{figure}[p]
\begin{center}
\includegraphics{20-5ia4f4.eps}
\end{center}
\caption{k による変化(PB → OC)}
\label{kekka3}
\end{figure} 

複数の分類器を組み合わせて利用する学習手法をアンサンブル学習というが，
本論文の手法もアンサンブル学習の一種と見なせる．
k~近傍法自体は\( k = 1 \)よりも\( k = 3 \)や\( k = 5 \)の方が正解率が高いが，
本手法のように SVM の識別の信頼度の低い部分のみに限定すれば，
\( k = 1 \)の\mbox{k~近傍法}を利用した方がよい．これはアンサンブル学習では
高い識別能力の学習器を組み合わせるのではなく，
互いの弱い部分を補強し合うような形式が望ましいことを示している．

\begin{figure}[t]
\begin{center}
\includegraphics{20-5ia4f5.eps}
\end{center}
\caption{k による変化(OC → PB)}
\label{kekka4}
\end{figure} 




\end{document}
