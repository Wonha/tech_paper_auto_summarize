本節では，フィルタリング処理について述べる．
フィルタリングとは，製品メーカのサイトからHTMLダウンローダで獲得したWeb文書群から，性能表を含む文書を抽出することを指す．
フィルタリング処理では，SVMおよびTSVMを用いる．
SVMはVapnikらが考案したOptimal Separating Hyperplaneを起源とする，超平面による特徴空間の分割法であり，現在，二値分類問題を解決するための最も優秀な学習モデルの一つとして知られている[CITE]．
SVMは訓練サンプル集合からマージン最大化と呼ばれる戦略を用いて，線形識別関数
のパラメータを学習する．
ここで，\boldmath[MATH]は入力ベクトルである．
\boldmath[MATH]と[MATH]がマージン最大化戦略の際に学習されるパラメータであり，[MATH]x[MATH]となる．
図[REF_svm]にSVMの学習モデルを示す．
＋は正のサンプル，−は負のサンプルである．
図中の実線は[MATH]x[MATH]となる点の集合であり，分離超平面(hyperplane)と呼ばれる．
サンプルは，この超平面を境界として2つのクラスに分類される．
すなわち，識別関数は分離超平面によって入力素性空間を二分する．
また，超平面に対して最近傍のサンプル間の距離をマージンと呼び，[MATH]w \cdot x[MATH]w[MATH]で表す．
図中の2つの破線上にある，分類を決定づける事例をサポートベクタと呼ぶ．
訓練データが線形分離可能な場合，[MATH]w[MATH]および[MATH]は複数存在することから，以下のような制約を与える．
この制約により，距離は[MATH]w[MATH]となり，結論として識別関数は
となる．
本研究では，線形カーネルを利用した．
一般に，高精度の分類器生成には多量の訓練サンプルを必要とする．
しかし，十分な量の訓練データを人手によってラベリングするのは非常に高コストな作業といえる．
そこで，少量の訓練データで高精度の分類器を生成する手法が期待される．
Vapnik [CITE]が提案した理論を基にJoachims [CITE]によって具体化されたTransductive SVM (TSVM)は，Transductive法と呼ばれる，与えられたラベル無しデータの分布に注目し，ラベル無しデータの誤分類の最小化を目的とする学習方法をSVMに適用し，拡張したもので，学習時にラベル無しデータの分布を考慮する事で分類精度を上げる手法である．
以下にTSVMのアルゴリズムを示す．
訓練データを基にSVMで分類器を生成する．
得られた分類器を用いてラベル無しデータを分類する．
得られた分類結果をそれぞれのラベル無しデータの仮クラスとする．
仮クラスの付与されたラベル無しデータを訓練データに含め，SVMによって分類器を再生成する．
マージン内のラベル無しデータのうち，各々の仮クラスを入れ替えることでマージンを最大化できるペアを見つけ，入れ換える．
入れ換えられたデータセットを用いて，SVMによる再学習を行う．
この処理の際に，ラベル無しデータ中の正例および負例の分布を考慮する．
入れ換えるペアがなくなるまでStep 4を繰り返す．
図[REF_tsvm]は，TSVMの学習過程の例である．
図中の＋と−は，通常のSVMが分離超平面を生成する際に使用した正のサンプルと負のサンプルを表す(すなわち図[REF_svm]における＋および−と同じ意味を持つ)．
ここで，[MATH]および[MATH]はそれぞれ最初のSVMによる分離超平面によって正例および負例と判断されたラベル無しデータを表す．
例では，マージン内にある\boldmath[MATH]と\boldmath[MATH]がアルゴリズム中のStep 4の部分で入れ換えられ，再学習の結果，マージンが最大化された新しい分離超平面が得られる過程を示している．
TSVMにおいても，通常のSVMと同様に線形カーネルを使用した．
線形分離可能な場合，TSVMの識別関数および制約条件は下式に拡張される．
ここで，[MATH]x[MATH]および[MATH]は，それぞれ仮クラスが与えられたラベル無データにおける入力ベクトルおよび仮クラスである．
続いて，SVMおよびTSVMのための素性選択について述べる．
本研究では，以下の条件を全て満たすものを素性候補とした．
表の属性欄中に出現する単語
一定長以内の文章中に出現する単語
性能表が存在する文書および性能表が存在しない文書内で顕著または限定的に出現する単語
これらの条件に基づき，素性となる候補をWeb文書から抽出する．
条件(1)では表中の要素を属性および属性値に切り分ける必要がある．
ここでは，一般に殆どの性能表は第1列目(最左列)に属性が現れ，それより右側の列に属性値が存在するという経験則から，最左列の要素を属性だと解釈する．
表の属性部分を素性に使い，属性値を素性として用いない理由は，製品の属性(例えば，パソコンならCPUやメモリなど)は，新しい機種が発売されても変更されにくいのに対し，属性値(例えば，CPUでいえば，800MHz，2GHzなど)は，その値や表現に揺れが生じやすいためである．
素性候補の抽出は，以下の手順で行われる．
HTML文書から<TABLE>タグで記述された領域を抽出する．
<TABLE>タグ中の各<TR>タグ中の初めの<TD>タグの内容を抽出する(図[REF_tdandtr])．
得られた文字列が25文字以内であれば，形態素解析を行い，素性候補を抽出する．
25文字という制約は経験的に定められた．
続いて，素性候補について重み付けを行い，素性を選択する．
本稿では，(1)正規化[MATH], (2)ベイズの定理の2種類を用いて，その精度を比較，考察する．
ここで，性能表を含んでいる文書中の<TABLE>タグ内で顕著に生起する語と，性能表を含んでいない文書中の<TABLE>タグ内で顕著に生起する語を素性とする．
以下に各手法での素性選択の流れを示す．
[MATH]は，文書群[MATH]について，文書[MATH]におけるキーワード候補[MATH]の生起数[MATH]，および候補が生起する文書数[MATH]を基に重み付けを行う最も有名な手法の一つである．
ここで，本研究では，素性候補の抽出条件を考慮する．
すなわち，素性の候補となる単語[MATH]としては，文書[MATH]中の<TABLE>タグにおける最左列の単語のみを利用する．
さらに，これを学習用に拡張し，[MATH]とする．
ここで，[MATH]は性能表を含む文書群，[MATH]は求めている製品の性能表を含まないもしくは性能表以外のテーブルを含む文書群である．
各々の文書群に生起する単語[MATH]について，Wangら[CITE]が表抽出で用いた式を基に重み付けを行う．
ここで，[MATH]は[MATH]および[MATH]における単語[MATH]の[MATH]値である．
また，[MATH]および[MATH]は，[MATH]および[MATH]に属する文書の総数を表す．
最終的な重みは以下の式で求める．
ただし，
ここで閾値以上の値を持つ[MATH]および[MATH]をSVMおよびTSVMのための素性として扱う．
素性選択のためのもう一つの手段として，パターン認識・分類の分野で広く知られているベイズの定理を用いる．
事象[MATH]{[MATH]}において，[MATH] [MATH]{[MATH]}[MATH]は事前確率と呼ばれる．
ここで，正規化[MATH]と同様に素性候補の抽出条件を考える．
すなわち，単語[MATH]としては，文書[MATH]中の<TABLE>タグにおける最左列に生じるもののみを利用する．
事前確率と条件付き確率密度分布[MATH]が事前に得られる場合，単語[MATH]が[MATH]に属する事後確率[MATH]は次の式で求められる．
ここで，[MATH]である．
全単語に対して各クラスでの事後確率を求め，それらを単語の重みと考える．
すなわち，[MATH]，および[MATH]である．
ここで，[MATH]を満たす語，[MATH]でかつ5回以上生起した語を素性とする．
本節では，表領域抽出処理について述べる．
表領域抽出処理とは，フィルタリング処理によって得られた性能表を含んでいる文書から性能表の領域を特定する処理を指す．
一般に，1つのHTML文書中には複数の<TABLE>タグが存在するため，それらの中から特定の表のみを抽出する処理が必要となる．
まず，文書内の全ての<TABLE>タグについて，それぞれにユニークなIDとその<TABLE>タグの深さに関する情報を付加する．
深さは1から始まり，<TABLE>タグが入れ子構造になれば，その値は大きくなる．
例を図[REF_numbering]に示す．
次に，各<TABLE>[MATH]についてスコアリングを行う．
スコアリングには，前節で素性として選ばれた語[MATH]とその値[MATH]を用いる．
各<TABLE>[MATH]の最左列の要素について，以下の式でスコアを計算する．
ここで，[MATH]は各<TABLE>[MATH]の最左列のセル中に存在する単語のリストを表し，[MATH]は，<TABLE>[MATH]の最左列の要素に生起したキーワード[MATH]の総数を表す．
この[MATH]が最大になる<TABLE>[MATH]を性能表であると見なし，抽出する．
また，1つの文書に複数の性能表が含まれていることもある．
そこで，[MATH]が最大になる<TABLE>にマッチしたキーワードの[MATH]がマッチする<TABLE>も性能表だとして抽出する．
性能表が必ずしも1つの<TABLE>タグで構成されているとは限らない．
実際に複数の表が入れ子構造になった性能表や複数の<TABLE>タグで分割されている性能表が多く存在する．
前者の例は，図[REF_numbering]で[MATH]および[MATH]がまとまって1つの性能表である場合であり，後者の例は[MATH]と[MATH]が1つの性能表である場合である．
入れ子構造になった<TABLE>タグの場合，ある<TABLE>[MATH]が性能表と見なされたとすると，その<TABLE>より深さの深い<TABLE>は，性能表の一部だとして抽出する．
さらに特殊な入れ子構造の例として，ブラウジングの際の視覚効果を狙い，<TABLE>タグ中の各<TD>.
..
</TD>内の要素が単一の<TABLE>タグで構成されている場合がある．
このような場合は入れ子構造になっている<TABLE>タグ部分を通常の単一セルと見なして処理する．
図[REF_nest]に例を示す．
続いて，1つの性能表が複数の<TABLE>タグによって構成されている場合の処理について述べる．
まず，次の条件を満たす<TABLE>[MATH]を抽出する．
<TABLE>タグの深さが等しい．
同じ親を持つ<TABLE>タグである．
図[REF_numbering]でいえば，[MATH]と[MATH]のペア，[MATH]と[MATH]のペアがこれにあたる．
次に抽出された<TABLE>タグ群について，次の項目をチェックする．
各行のセルの数が一致するか
<TABLE>タグに幅(width)が指定されている場合，その値が一致するか
<TABLE>タグの<TD>タグについて，背景色(bgcolor)が指定されている場合，その使用パターンが一致するか
これらの項目のうち，2つ以上の項目に，抽出された<TABLE>群がマッチする場合は，それらを1つの<TABLE>として捉え，スコアリングの際に，それぞれのスコアの和をその<TABLE>のスコアとする．
本節では，フィルタリング処理について述べる．
フィルタリングとは，製品メーカのサイトからHTMLダウンローダで獲得したWeb文書群から，性能表を含む文書を抽出することを指す．
フィルタリング処理では，SVMおよびTSVMを用いる．
SVMはVapnikらが考案したOptimal Separating Hyperplaneを起源とする，超平面による特徴空間の分割法であり，現在，二値分類問題を解決するための最も優秀な学習モデルの一つとして知られている[CITE]．
SVMは訓練サンプル集合からマージン最大化と呼ばれる戦略を用いて，線形識別関数
のパラメータを学習する．
ここで，\boldmath[MATH]は入力ベクトルである．
\boldmath[MATH]と[MATH]がマージン最大化戦略の際に学習されるパラメータであり，[MATH]x[MATH]となる．
図[REF_svm]にSVMの学習モデルを示す．
＋は正のサンプル，−は負のサンプルである．
図中の実線は[MATH]x[MATH]となる点の集合であり，分離超平面(hyperplane)と呼ばれる．
サンプルは，この超平面を境界として2つのクラスに分類される．
すなわち，識別関数は分離超平面によって入力素性空間を二分する．
また，超平面に対して最近傍のサンプル間の距離をマージンと呼び，[MATH]w \cdot x[MATH]w[MATH]で表す．
図中の2つの破線上にある，分類を決定づける事例をサポートベクタと呼ぶ．
訓練データが線形分離可能な場合，[MATH]w[MATH]および[MATH]は複数存在することから，以下のような制約を与える．
この制約により，距離は[MATH]w[MATH]となり，結論として識別関数は
となる．
本研究では，線形カーネルを利用した．
一般に，高精度の分類器生成には多量の訓練サンプルを必要とする．
しかし，十分な量の訓練データを人手によってラベリングするのは非常に高コストな作業といえる．
そこで，少量の訓練データで高精度の分類器を生成する手法が期待される．
Vapnik [CITE]が提案した理論を基にJoachims [CITE]によって具体化されたTransductive SVM (TSVM)は，Transductive法と呼ばれる，与えられたラベル無しデータの分布に注目し，ラベル無しデータの誤分類の最小化を目的とする学習方法をSVMに適用し，拡張したもので，学習時にラベル無しデータの分布を考慮する事で分類精度を上げる手法である．
以下にTSVMのアルゴリズムを示す．
訓練データを基にSVMで分類器を生成する．
得られた分類器を用いてラベル無しデータを分類する．
得られた分類結果をそれぞれのラベル無しデータの仮クラスとする．
仮クラスの付与されたラベル無しデータを訓練データに含め，SVMによって分類器を再生成する．
マージン内のラベル無しデータのうち，各々の仮クラスを入れ替えることでマージンを最大化できるペアを見つけ，入れ換える．
入れ換えられたデータセットを用いて，SVMによる再学習を行う．
この処理の際に，ラベル無しデータ中の正例および負例の分布を考慮する．
入れ換えるペアがなくなるまでStep 4を繰り返す．
図[REF_tsvm]は，TSVMの学習過程の例である．
図中の＋と−は，通常のSVMが分離超平面を生成する際に使用した正のサンプルと負のサンプルを表す(すなわち図[REF_svm]における＋および−と同じ意味を持つ)．
ここで，[MATH]および[MATH]はそれぞれ最初のSVMによる分離超平面によって正例および負例と判断されたラベル無しデータを表す．
例では，マージン内にある\boldmath[MATH]と\boldmath[MATH]がアルゴリズム中のStep 4の部分で入れ換えられ，再学習の結果，マージンが最大化された新しい分離超平面が得られる過程を示している．
TSVMにおいても，通常のSVMと同様に線形カーネルを使用した．
線形分離可能な場合，TSVMの識別関数および制約条件は下式に拡張される．
ここで，[MATH]x[MATH]および[MATH]は，それぞれ仮クラスが与えられたラベル無データにおける入力ベクトルおよび仮クラスである．
続いて，SVMおよびTSVMのための素性選択について述べる．
本研究では，以下の条件を全て満たすものを素性候補とした．
表の属性欄中に出現する単語
一定長以内の文章中に出現する単語
性能表が存在する文書および性能表が存在しない文書内で顕著または限定的に出現する単語
これらの条件に基づき，素性となる候補をWeb文書から抽出する．
条件(1)では表中の要素を属性および属性値に切り分ける必要がある．
ここでは，一般に殆どの性能表は第1列目(最左列)に属性が現れ，それより右側の列に属性値が存在するという経験則から，最左列の要素を属性だと解釈する．
表の属性部分を素性に使い，属性値を素性として用いない理由は，製品の属性(例えば，パソコンならCPUやメモリなど)は，新しい機種が発売されても変更されにくいのに対し，属性値(例えば，CPUでいえば，800MHz，2GHzなど)は，その値や表現に揺れが生じやすいためである．
素性候補の抽出は，以下の手順で行われる．
HTML文書から<TABLE>タグで記述された領域を抽出する．
<TABLE>タグ中の各<TR>タグ中の初めの<TD>タグの内容を抽出する(図[REF_tdandtr])．
得られた文字列が25文字以内であれば，形態素解析を行い，素性候補を抽出する．
25文字という制約は経験的に定められた．
続いて，素性候補について重み付けを行い，素性を選択する．
本稿では，(1)正規化[MATH], (2)ベイズの定理の2種類を用いて，その精度を比較，考察する．
ここで，性能表を含んでいる文書中の<TABLE>タグ内で顕著に生起する語と，性能表を含んでいない文書中の<TABLE>タグ内で顕著に生起する語を素性とする．
以下に各手法での素性選択の流れを示す．
[MATH]は，文書群[MATH]について，文書[MATH]におけるキーワード候補[MATH]の生起数[MATH]，および候補が生起する文書数[MATH]を基に重み付けを行う最も有名な手法の一つである．
ここで，本研究では，素性候補の抽出条件を考慮する．
すなわち，素性の候補となる単語[MATH]としては，文書[MATH]中の<TABLE>タグにおける最左列の単語のみを利用する．
さらに，これを学習用に拡張し，[MATH]とする．
ここで，[MATH]は性能表を含む文書群，[MATH]は求めている製品の性能表を含まないもしくは性能表以外のテーブルを含む文書群である．
各々の文書群に生起する単語[MATH]について，Wangら[CITE]が表抽出で用いた式を基に重み付けを行う．
ここで，[MATH]は[MATH]および[MATH]における単語[MATH]の[MATH]値である．
また，[MATH]および[MATH]は，[MATH]および[MATH]に属する文書の総数を表す．
最終的な重みは以下の式で求める．
ただし，
ここで閾値以上の値を持つ[MATH]および[MATH]をSVMおよびTSVMのための素性として扱う．
素性選択のためのもう一つの手段として，パターン認識・分類の分野で広く知られているベイズの定理を用いる．
事象[MATH]{[MATH]}において，[MATH] [MATH]{[MATH]}[MATH]は事前確率と呼ばれる．
ここで，正規化[MATH]と同様に素性候補の抽出条件を考える．
すなわち，単語[MATH]としては，文書[MATH]中の<TABLE>タグにおける最左列に生じるもののみを利用する．
事前確率と条件付き確率密度分布[MATH]が事前に得られる場合，単語[MATH]が[MATH]に属する事後確率[MATH]は次の式で求められる．
ここで，[MATH]である．
全単語に対して各クラスでの事後確率を求め，それらを単語の重みと考える．
すなわち，[MATH]，および[MATH]である．
ここで，[MATH]を満たす語，[MATH]でかつ5回以上生起した語を素性とする．
本節では，表領域抽出処理について述べる．
表領域抽出処理とは，フィルタリング処理によって得られた性能表を含んでいる文書から性能表の領域を特定する処理を指す．
一般に，1つのHTML文書中には複数の<TABLE>タグが存在するため，それらの中から特定の表のみを抽出する処理が必要となる．
まず，文書内の全ての<TABLE>タグについて，それぞれにユニークなIDとその<TABLE>タグの深さに関する情報を付加する．
深さは1から始まり，<TABLE>タグが入れ子構造になれば，その値は大きくなる．
例を図[REF_numbering]に示す．
次に，各<TABLE>[MATH]についてスコアリングを行う．
スコアリングには，前節で素性として選ばれた語[MATH]とその値[MATH]を用いる．
各<TABLE>[MATH]の最左列の要素について，以下の式でスコアを計算する．
ここで，[MATH]は各<TABLE>[MATH]の最左列のセル中に存在する単語のリストを表し，[MATH]は，<TABLE>[MATH]の最左列の要素に生起したキーワード[MATH]の総数を表す．
この[MATH]が最大になる<TABLE>[MATH]を性能表であると見なし，抽出する．
また，1つの文書に複数の性能表が含まれていることもある．
そこで，[MATH]が最大になる<TABLE>にマッチしたキーワードの[MATH]がマッチする<TABLE>も性能表だとして抽出する．
性能表が必ずしも1つの<TABLE>タグで構成されているとは限らない．
実際に複数の表が入れ子構造になった性能表や複数の<TABLE>タグで分割されている性能表が多く存在する．
前者の例は，図[REF_numbering]で[MATH]および[MATH]がまとまって1つの性能表である場合であり，後者の例は[MATH]と[MATH]が1つの性能表である場合である．
入れ子構造になった<TABLE>タグの場合，ある<TABLE>[MATH]が性能表と見なされたとすると，その<TABLE>より深さの深い<TABLE>は，性能表の一部だとして抽出する．
さらに特殊な入れ子構造の例として，ブラウジングの際の視覚効果を狙い，<TABLE>タグ中の各<TD>.
..
</TD>内の要素が単一の<TABLE>タグで構成されている場合がある．
このような場合は入れ子構造になっている<TABLE>タグ部分を通常の単一セルと見なして処理する．
図[REF_nest]に例を示す．
続いて，1つの性能表が複数の<TABLE>タグによって構成されている場合の処理について述べる．
まず，次の条件を満たす<TABLE>[MATH]を抽出する．
<TABLE>タグの深さが等しい．
同じ親を持つ<TABLE>タグである．
図[REF_numbering]でいえば，[MATH]と[MATH]のペア，[MATH]と[MATH]のペアがこれにあたる．
次に抽出された<TABLE>タグ群について，次の項目をチェックする．
各行のセルの数が一致するか
<TABLE>タグに幅(width)が指定されている場合，その値が一致するか
<TABLE>タグの<TD>タグについて，背景色(bgcolor)が指定されている場合，その使用パターンが一致するか
これらの項目のうち，2つ以上の項目に，抽出された<TABLE>群がマッチする場合は，それらを1つの<TABLE>として捉え，スコアリングの際に，それぞれのスコアの和をその<TABLE>のスコアとする．
