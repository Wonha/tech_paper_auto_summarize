\section{評価実験}

以上で提案した手法を評価するために，
ATR 対話データベースを用いた評価実験を行った．
それぞれのデータの文数，単語数，文字数を表\ref{Tab:datasize}に示す．
\begin{table}[hbt]
\begin{center}
\caption{学習データと評価データのサイズ}
\label{Tab:datasize}
\begin{tabular}{l|r|r}
\hline
\hline
 & 学習データ & 評価データ\\
\hline
文数 & 11,430 & 1,267\\
\hline
単語数 & 155,553 & 17,829\\
\hline
文字数 & 278,771 & 31,450\\
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{文字クラスモデルのクロス・エントロピー評価}

前節の単語分割モデルで用いる文字クラスモデルを作成する．
したがって，文字 trigram クラスモデルや
可変長 $n$-gram クラスモデルの予測力を改善するような
文字クラスを求める必要がある．
しかし，文字クラスタリング・アルゴリズムの評価基準である
平均クロス・エントロピーの計算を考えると，
高次のモデルでは，必要な記憶容量と計算時間が大きな問題となる．

そこで，本実験では，クロス・エントロピーの計算は，
低次の bigram 確率によって計算した．
bigram モデルであれば，高速なクラスタリング処理が可能である．
もし日本語における文字分類の最適解に近い解を得ることができれば，
得られたクラス関数 $f$ はどのような次数のモデルに対しても
ある程度有効であると考えられる．

また，本論文では，日本語文字が明らかに字種によって分類できることから，
クラスタリング処理において，字種により規制を設けることを考えた．
たとえば，漢字は漢字同士でグループ化するというように考えることで，
文字とクラスの対応関係の変更を考える場合に
必要な計算量を少なくすることができる．これにより，
漢字の場合は $move$ 関数の移動先クラスとして漢字のクラスのみを
考えることとなり，
ひらがなの場合はひらがなのクラスのみとなる．

以上の条件により，
文字クラスタリングを行うために，学習データを 9 個のデータ
$L_1, L_2, \cdots, L_9$ に分割した．ここで，1 個のデータにしか出現しない
文字は未知文字とし，字種ごとに未知文字クラスを用意した．
これは，クロス・バリデーション法による
平均クロス・エントロピーの計算 (9 回の評価) において
未知文字であった文字をそのまま学習データ全体における未知文字の
実例の収集に用いることを意味する．
したがって，クラスタリングの対象となる文字は，2 個以上のデータに
出現する文字となる．
また，単語分割に用いる言語モデルを獲得することを念頭におくため，
単語間に単語境界記号を挿入した分かち書きデータを用いた．
単語境界記号自体はクラスタリングの対象ではないが，
その存在により，
クロス・エントロピー評価では単語境界(単語間のスペース)まで考慮するようになる．

本実験において，評価データ中の未知文字(クラスタリング対象文字以外)は
字種ごとに異なる特別な記号に置き換えてクロス・エントロピーの計算を行った．
未知文字の扱いは文字モデルと文字クラスモデルで共通であるので，
未知文字の確率はモデルの比較においては問題とならない．
重要なことは，クラスタリング対象文字のグループ化によって，
モデルの予測力がどのように変化するかである．
以上の点から，モデルの状態は，既知文字すべて(もしくは文字クラスすべて)，
未知文字クラス(字種ごと)，単語境界，文区切りの各々に対応することとなる．
実験により得られた，文字 bigram モデルと文字 bigram クラスモデルの
クロス・エントロピーを表\ref{Tab:CrossEntropy}に示す．
\begin{table}[hbt]
\begin{center}
\caption{言語モデルのクロス・エントロピー}
\label{Tab:CrossEntropy}
\begin{tabular}{l|r}
\hline
\hline
言語モデル & \multicolumn{1}{c}{$H$}\\
\hline
文字bigramモデル & 3.5980\\
文字bigramクラスモデル & 3.5591\\
\hline
\end{tabular}
\end{center}
\end{table}

本実験において，文字クラスモデルのクロス・エントロピーは
文字モデルのものよりも小さく，より予測力の高い言語モデルの
獲得に成功している
\footnote{
単語間のスペースを考慮しない「ベタ書き」の日本語データを用いた
実験では，
クロス・エントロピーは，文字 bigram モデルでは 4.3563 ビット，
文字 bigram クラスモデルでは 4.3060 ビット
であり，同様に，文字クラスモデルのほうが一文字当たりのクロス・エントロピーが
小さいという結果が得られている．
}．
また，表\ref{Tab:CharClassParameters}に，クラスタリング対象文字数
とそれらをクラスタリングした後の文字クラス数を示す．
学習データ中には，1357 種類の文字が含まれていたが，
約 200 種類の低頻度文字が未知文字として取り扱われた．
実験の結果，クラス当たりの平均要素(文字)数は 1.36 文字であり，
最大のクラスの所属文字数は 12 文字であった．
\begin{table}[hbt]
\begin{center}
\caption{文字数と文字クラス数の比較}
\label{Tab:CharClassParameters}
\begin{tabular}{l||r|r}
\hline
\hline
 & \multicolumn{1}{|c|}{既知文字数} & \multicolumn{1}{c}{文字クラス数}\\
\hline
漢字 & 935 & 675\\
ひらがな & 70 & 67\\
カタカナ & 78 & 71\\
数字 & 10 & 8\\
英字 & 42 & 13\\
記号 & 23 & 15\\
\hline
合計 & 1,158 & 849\\
\hline
\end{tabular}
\end{center}
\end{table}

文字クラスタリング実験により得られたクラス関数 $f$ が返す
文字集合 (文字クラス) を，図\ref{Fig:ExampleCharClass}にいくつか示す．
必ずしもすべての文字クラスが言語直観から納得がいくものではないが，
いくつかのノイズと思われる文字を除けば，(特に出現位置の類似という点で)
ある程度良い解が得られていることが分かる．
不自然な印象を受ける文字のグループが存在するのは，
あくまで bigram クラスモデルの改善における準最適解を求めている
からであると考えられる．
\begin{figure}[hbt]
\{ 送, 乗, 居, 貼 \}
\{ 私, 誠, 娘, 又 \}
\{ 思, 誓 \}
\{ 今, 昨 \}
\{ 部, 型 \}
\{ 中, 低 \}
\{ 他, 皆, 僕 \}\\
\{ 原, 松, 草 \}
\{ 山, 竹, 塚, 吉 \}
\{ 別, 誰 \}
\{ 特, 既 \}
\{ 忙, 楽 \}
\{ 近, 多, 暗\}
\{ 渡, 貸, 探, 押 \}\\
\{ 朝, 昼 \}
\{ 市, 職, 命, 履 \}
\{ 安, 幸 \}
\{ 図, 計, 義 \}
\{ 島, 木, 川, 根 \}
\{ 食, 刻, 飯 \}
\{ 帰, 困 \}\\
\{ 女, 性 \}
\{ 校, 化, 枠, 郊 \}
\{ 映, 厳, 撮 \}
\{ 含, 休, 混 \}
\{ 購, 納 \}
\{ 離, 訪 \}
\{ 項, 故 \}\\
\{ 戸, 宮 \}
\{ 欄, 横, 机, 縦, 層, 逆 \}
\{ 界, 株, 財 \}
\caption{実験により得られた文字クラスの例}
\label{Fig:ExampleCharClass}
\end{figure}

本実験では，各文字クラスに属する文字数は少なく，
文字クラスタリングによって，
それほど極端にパラメータ数が減少するということにはならなかった．
この原因は，今回用いたコーパスの規模が小さく，学習データに
含まれる文字の種類が少なかったためであると考えられる．
より多くの文字種をクラスタリングの対象とすれば，
モデルのパラメータ数の減少度はさらに大きくなるであろう．

\subsection{単語分割精度の比較評価}
\vspace{-1.5mm}
文字クラスタリング実験により得られたクラス関数 $f$ を用いる
ことで，文字 trigram クラスモデルや可変長 $n$-gram クラスモデルを
構築することができる．
ここで，文字クラスタリングでは字種別にグループ化を行ったので，
単語分割に用いる文字クラスモデルを作成するときに，
クラス関数 $f$ を用いる字種を限定してみることについても
試みることとした．
もしあまり有効でない文字のグループ化が行われている字種が
あれば，それらの文字はクラス関数 $f$ を用いず，文字を予測単位
として処理すれば，より性能の良いモデルが得られる可能性がある．

また，本論文で提案した文字クラスモデルに基づく単語分割モデルは非常に
簡単な構造となっており，いかにクラス連鎖により単語境界の
生起を把握するかが単語分割精度の鍵となる．
ここで，字種変化によるヒューリスティクスを考慮した場合，
カタカナ，数字，英字はその字種同士の文字間では分かち書きされる
可能性がほとんどないと考えられる．
単語分割を行う場合，これらの文字は単にカタカナか数字か英字である
という情報のみでモデル化したほうが良い結果が得られる可能性がある．
そこで，それらの字種に関しては字種全体を一つのクラスとみなして
同一視することについても検討することとした．

以上の点から，文字クラスモデルと文字モデルの比較において，
表\ref{Tab:ClusteringCondition}の 5 つのモデルを考え，単語分割実験を
行った．表中には，字種ごとに何を予測単位としてモデル化を行うかを示している．
モデル 1 は文字モデルであり，モデル 2 は文字クラスタリングの結果に
何も手を加えず
に，すべての文字でクラス関数 $f$ を用いた文字クラスモデルである．
モデル 3, 4, 5 は字種クラス
(字種全体を一つのクラスとする) を予測単位と
することを試みたモデルであり，それらの中のモデル 4 とモデル 5 では
文字クラスタリングの結果得られるクラス関数 $f$ を用いる文字を限定している．
\begin{table}[hbt]
\begin{center}
\caption{字種ごとに予測単位を使い分けることを仮定したモデル}
\label{Tab:ClusteringCondition}
{\tabcolsep 1.5mm
\begin{tabular}{c||llllll}
\hline
\hline
モデル & 漢字 & ひらがな & カタカナ & 数字 & 英字 & 記号\\
\hline
1 & 文字 & 文字 & 文字 & 文字 & 文字 & 文字\\
\hline
2 & クラス & クラス & クラス & クラス & クラス & クラス\\
\hline
3 & 文字 & 文字 & 字種 & 字種 & 字種 & 文字\\
\hline
4 & クラス & クラス & 字種 & 字種 & 字種 & クラス\\
\hline
5 & クラス & 文字 & 字種 & 字種 & 字種 & 文字\\
\hline
\end{tabular}
}
\end{center}
\end{table}
\vspace{-2mm}


表\ref{Tab:PerformanceTrigram}に，
文字 trigram モデルと文字 trigram クラスモデル
に基づく単語分割モデルによる単語分割精度を示す．
単語分割の性能は，再現率({\it recall})と適合率({\it precision})
により評価する\cite{Nagata94}．
ここで，Std をコーパス中の単語数，Sys を本手法で分割された単語数，
M を照合した単語数とすると，再現率は ${\rm M}/{\rm Std}$ ，
適合率は ${\rm M}/{\rm Sys}$ で表される．
\begin{table}[hbt]
\begin{center}
\caption{trigram モデルと trigram クラスモデルによる単語分割精度}
\label{Tab:PerformanceTrigram}
{\tabcolsep 1.5mm
\begin{tabular}{c||c|c|c|c}
\hline
\hline
 & \multicolumn{2}{|c|}{クローズドテスト} & \multicolumn{2}{c}{オープンテスト}\\
\cline{2-5}
モデル & 再現率 & 適合率 & 再現率 & 適合率\\
\hline
1 & 98.10\% & 98.56\% & 95.48\% & 94.11\%\\
2 & 98.09\% & 98.56\% & 95.83\% & 94.34\%\\
3 & 97.82\% & 98.44\% & 95.91\% & 94.73\%\\
4 & 97.80\% & 98.43\% & 95.86\% & 94.70\%\\
5 & 97.83\% & 98.44\% & 96.01\% & 94.74\%\\
\hline
\end{tabular}
}
\end{center}
\end{table}

本実験では，バックオフ・スムージング\cite{Katz87}
付きの trigram 確率値を計算した．
表\ref{Tab:PerformanceTrigram}のモデル 1 とモデル 2 は
文字 trigram モデルと文字 trigram クラスモデルの精度であるが，
オープンテストにおいて文字クラスモデルの精度が上回る結果となっている．
また，モデル 1 とモデル 3 およびモデル 2 とモデル 4 の
オープンテストの結果を比較することで，
カタカナ，数字，英字を各々一つのクラスとしたほうが
未知語を含むデータに対して，精度が向上していることが分かる．
したがって，字種単位でのグループ化の有効な字種の存在が確認できた．
全体として，オープンテストでは，漢字に関して文字クラスを用いたモデル 5 の
場合が最も高精度であった．
本実験結果より，文字クラスタリングの動機であった漢字のクラスタリング
には特に良い解が得られていることが分かる．

また，可変長 $n$-gram モデル\cite{Oda99a,Oda99b}と
可変長 $n$-gram クラスモデルの比較に関する単語分割実験も行ったが，
trigram 同様，クラスモデルの方が高精度であった．
本実験において，可変長 $n$-gram クラスモデルによる探索空間は
trigram による場合と同じものとした．
文献\cite{Oda99b}において，trigram モデルによる探索空間と同じ
場合に最も高い精度を達成している可変長 $n$-gram モデルを用いた
場合の結果を表\ref{Tab:PerformancePPMBackOff}に示す．
実験結果から，可変長 $n$-gram クラスモデルは trigram クラスモデル
よりもさらに高い単語分割精度を達成できることが分かる．
学習データと評価データの組を変更して，
可変長 $n$-gram クラスモデルによる単語分割の再評価を行ったところ，
オープンテストで 96\% 〜 98\% 以上のかなりの高精度を達成することを確認した．
パラメータ数の少ない文字クラスモデルでは，
本論文で用いたような比較的小規模の学習データからでも信頼のおける確率値を
得ることが容易となり，有効な未知語モデルとして機能できることが結論できる．
\begin{table}[hbt]
\begin{center}
\caption{可変長 $n$-gram モデルと可変長 $n$-gram クラスモデルによる単語分割精度}
\label{Tab:PerformancePPMBackOff}
{\tabcolsep 1.5mm
\begin{tabular}{c||c|c|c|c}
\hline
\hline
 & \multicolumn{2}{|c|}{クローズドテスト} & \multicolumn{2}{c}{オープンテスト}\\
\cline{2-5}
モデル & 再現率 & 適合率 & 再現率 & 適合率\\
\hline
1 & 99.51\% & 99.71\% & 95.89\% & 95.91\%\\
2 & 99.50\% & 99.71\% & 96.30\% & 96.04\%\\
3 & 99.42\% & 99.68\% & 96.20\% & 96.15\%\\
4 & 99.38\% & 99.67\% & 96.27\% & 96.17\%\\
5 & 99.42\% & 99.69\% & 96.38\% & 96.23\%\\
\hline
\end{tabular}
}
\end{center}
\end{table}

