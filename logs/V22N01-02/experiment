評価実験

\subsection{実験条件}

実験には「楽天データ公開\footnote{楽天データ公開：http://rit.rakuten.co.jp/rdr/ データは2010年時点の公開データを用いた．}」に収録されている楽天トラベル\footnote{楽天トラベル：http://travel.rakuten.co.jp/} のレビューを用いた．楽天トラベルのレビューでは，宿泊施設に対するユーザのレビュー文書に対して宿泊施設提供者が返答することによって文書対が構成されている．典型的な文書対と文対応を示した例を図 \ref{fig:dependency-example} に示す．

\begin{figure}[b]
\begin{center}
\includegraphics{22-1ia2f10.eps}
\end{center}
\caption{宿泊予約ウェブサイトのレビュー・応答文書における文対応の例}
\label{fig:dependency-example}
\end{figure}

実際には楽天トラベルのレビュー 348,564 件のうち，レビュー文書・応答文書の双方が存在する 276,562 件からランダムサンプリングした 1,000 文書対を用いた．この各文書を簡易的なヒューリスティックによって文単位に分割し，レビュー文 4,813文・応答文 6,160文を得た．この 1,000 文書対に対して5分割交差検定を適用して評価を行う．

宿泊予約サイトの文種類の定義は，レビュー文書・応答文書ごとに文種類の分類に詳しい大沢らの先行研究を参考にした \cite{大沢:2010}．大沢らは本実験と同じウェブサイトである楽天トラベルの「クチコミ・お客さまの声」を分析し，レビュー文を8種類，応答文を14種類に分類している．本研究では文種類が特定できれば文対応の特定が容易になるよう，レビュー文を12種類，返答文を20種類に再分類した\footnote{レビュー文書の中には，末尾に「【ご利用の宿泊プラン】」に続いて宿泊プランの名称が書かれている文が存在した．この記述は，おそらく楽天トラベルのレビューを投稿する際に自動で挿入される文であると考えている．}．この分類を表 \ref{tb:review-discourse} 及び 表 \ref{tb:reply-discourse} に示す．また，大沢らの分析からの主な変更点とその理由を以下に示す．

\begin{enumerate}
  \renewcommand{\labelenumi}{}
  \item \textbf{レビュー文種類— ＜ポジ／ネガ感想＞ の追加}：一文にポジティブ・ネガティブな感想を双方含むレビュー文は，複数の応答文と対応することがあるため．
  \item \textbf{応答文種類 — ＜対応明示＞ ＜検討明示＞ の具体性による細分化}：具体性のある対応・検討明示文はそれぞれレビュー文で書かれた一つの事情と対応するが，抽象的なものはレビュー文で書かれた複数の事情と対応することがあるため．
\end{enumerate}

\begin{table}[t]
\caption{レビュー文書を構成する文の種類（大沢らによる分類を参考に再構成）}
\label{tb:review-discourse}
\input{02table01.txt}
\end{table}

以上の文種類の定義に基づき，人手で文種類及び文対応の有無をタグ付けした．その結果，1,000 文書対全体では 4,492 通りの文対応が得られた．また，文種類について，各文種類の出現数と各文種類ごとに文対応がどの程度存在するかを調査したデータを表 \ref{tb:review-dep-exists}, \ref{tb:reply-dep-exists} に示す\footnote{なお，「その他」は例えば文書が英語で書かれているため分類が不可能であった文などである．}．表中の「対応（平均数）」は一文から見たときの平均対応文数を示しており，「対応（存在率）」は一つでも対応が存在する割合を示している．表 \ref{tb:review-dep-exists}, \ref{tb:reply-dep-exists} より，例えばレビュー文種類では ＜ネガティブ感想＞ や ＜要求・要望＞ が，応答文種類では ＜お詫び＞ や ＜具体的対応明示＞ などの文種類で対応存在率が高いなど，文種類によって対応の平均数や対応存在率が大きく異なることが分かる．

\begin{table}[p]
\caption{応答文書を構成する文の種類（大沢らによる分類を参考に再構成）}
\label{tb:reply-discourse}
\input{02table02.txt}
\end{table}

次に，文対応が交差する割合を示す．交差割合の計算は，各文書対において「文書対内において交差を持つ文対応の数／文書対内における全ての文対応の数」により求めた．結果，交差割合の平均は 0.249 であることから，本データにおいても文の出現順序と文対応の出現位置は必ずしも一致しないことが分かる．

\begin{table}[t]
\begin{minipage}[t]{.49\hsize}
\caption{レビュー文の各文ごとの対応数・対応存在率}
\label{tb:review-dep-exists}
\input{02table03.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{.49\hsize}
\caption{応答文の各文ごとの対応数・対応存在率}
\label{tb:reply-dep-exists}
\input{02table04.txt}
\end{center}
\end{minipage}
\end{table}

最後に，文対応の有無別にコサイン類似度の分布を表したヒストグラムを図 \ref{fig:cossim-dist-f}, \ref{fig:cossim-dist-t} に示す（なお，コサイン類似度が 0.3--1.0 である文対応の割合は少なかったため省略している）．なお，コサイン類似度は，各文における stop-word を除く単語の出現頻度を値に持つベクトルを用いて計算した値である．文対応を持つ文間の方が比較的高いコサイン類似度が高い傾向がある一方，文対応が存在する文対のうち 53.56\% はコサイン類似度が 0 であった．そのため，本データにおいても対応する文同士は必ずしも類似しないことが分かる．

実験で比較する手法は次の5つである．まず，\ref{sec:proposal-simple} 節で説明した L-CRF$_{\rm org}$, L-CRF$_{\rm rep}$, 2D CRF の3種類を用いる．また，\ref{sec:proposal-combine} 節 で説明した統合モデル combine を用いる．加えて，系列ラベリング問題ではなく二値分類問題と考えるモデルとしてロジスティック回帰 (Logistic) でも性能を調査する．ロジスティック回帰は，L-CRF や 2D CRF において隣接する出力変数間の依存関係を考慮しないモデルに相当する．

\begin{figure}[t]
\begin{minipage}[b]{0.49\hsize}
\begin{center}
\includegraphics{22-1ia2f11.eps}
\end{center}
\caption{コサイン類似度の分布（文対応なし）}
\label{fig:cossim-dist-f}
\end{minipage}
\begin{minipage}[b]{0.49\hsize}
\begin{center}
\includegraphics{22-1ia2f12.eps}
\end{center}
\caption{コサイン類似度の分布（文対応あり）}
\label{fig:cossim-dist-t}
\end{minipage}
\end{figure}

CRF の各モデルのパラメータ学習・利用には MALLET 2.0.7 \cite{McCallumMALLET2002} 中の GRMM \cite{GRMM2006} を用いた．GRMM に用いたパラメータはデフォルト（TRP の最大 iteration 回数1,000回，TRP の収束判定用の値 0.01）とし，周辺確率の計算には TRP \cite{Wainwright2001b} を利用した．なお，GRMM は CRF 学習パラメータの正則化に L2 正則化 \cite{Chen99agaussian} を利用している．また，ロジスティック回帰のパラメータ学習・利用には scikit-learn 0.15.1 \cite{scikit-learn} を用い，正則化には L2 正則化を利用した．

文種類の推定には，文を構成する unigram（単語の表層形）を素性として用いる．また，文対応の推定，及び combine モデルにおいて新たに追加した因子には以下の素性を用いる．なお，単語分割には MeCab 0.994 \cite{kudo-yamamoto-matsumoto:2004:EMNLP} を利用した．
\begin{itemize}
  \item レビュー文を構成する unigram
  \item 応答文を構成する unigram
  \item レビュー文・応答文のコサイン類似度（0〜1 の値）
  \item 予め文種類モデルで推定したレビュー文・応答文の種類（combine モデル以外\footnote{combine モデルの場合は，レビュー文種類・応答文種類は文対応と同時に推定されるため，これらを陽に素性として追加する必要はない．combine モデルにおいては文種類と文対応を同時に考慮する因子が存在するため，文種類を考慮した文対応推定が実現できる．}）
\end{itemize}
また，unigram 素性及びコサイン類似度の計算に利用する単語からは予め stop-word を除去しており\footnote{本実験では，品詞が「助詞」「助動詞」「記号」の単語を stop-word とした．}，1,000文書対全体では9,300種類の単語が存在した．

文対応推定性能の評価は，適合率 (Precision)・再現率 (Recall)，及びそれらの調和平均であるF値から行う．すなわち，考えうる全ての文対応の可能性から正しい文対応を探す課題とみなし，次の式で計算する．
\pagebreak
\begin{align*}
\text{Recall} & = \frac{正しく推定できた対応数}{評価データ中に存在する文対応数} \\[0.5zw]
\text{Precision} & =  \frac{正しく推定できた文対応数}{システムが文対応有りと出力した文対応数}
\end{align*}

本実験では，以下に説明する手法により適合率・再現率を調整し，これらの性能がどのように変化するかを調査する．具体的には，文同士が対応する確率 $P(y_{i,j}=1)$ と対応しない確率 $P(y_{i,j}=0)$ の比率を取り，閾値を与えて閾値以上か否かで文対応の有無の出力を変更する．すなわち，文対応 $y_{i,j}$ の最終的な出力 $\hat{y}_{i,j}$ は閾値 $\alpha$ を用いて次の式 (\ref{eq:alpha}) のようにする．
\begin{equation} \label{eq:alpha}
  \hat{y_{ij}} = \left\{
  \begin{array}{cl}
     1 & ~~ \rm{if} ~~ \log \frac{P(y_{i,j}=1 | \mathbf{x})}{P(y_{i,j}=0 | \mathbf{x})} > \alpha \\
     0 & ~~ \rm{otherwise} \\
  \end{array}
  \right.
\end{equation}


\subsection{実験結果と考察}

実験結果を表 \ref{tb:result} に示す．各数値は適合率・再現率を調整した際に学習データにおいてF値が最大となる点を用い，5分割交差検定でのマイクロ平均値を計算した数値である．なお，表 \ref{tb:result} に示す結果のF値に対してブートストラップ検定で得られたp値を Holm 法 \cite{Holm1979} によって調整した有意水準と比較することで多重比較を行い，統合モデル combine は他手法全てに対して統計的有意差があることを確認している（有意水準5\%）{\kern-0.5zw}\footnote{ブートストラップ検定におけるブートストラップ回数は1,000回とした．}．併せて，閾値を変化させた際のPrecision-Recall 曲線を図 \ref{fig:pr} に示す．

\begin{table}[b]
  \caption{実験結果（分割交差検定でのF値最大点におけるマイクロ平均値）}
  \label{tb:result}
\input{02table05.txt}
\vspace{-1\Cvs}
\end{table}

表 \ref{tb:result} から，統合モデル combine は文種類・文対応を別々に推定する各手法よりも高い性能となった．また，図 \ref{fig:pr} より中程度の再現率 (Recall: 0.25〜0.75) でも combine は概ね他手法よりも高い適合率であり，多くの場合において高い性能であったといえる．

\begin{figure}[b]
\begin{center}
\includegraphics{22-1ia2f13.eps}
\end{center}
\caption{実験結果の Precision-Recall 曲線}
\label{fig:pr}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{22-1ia2f14.eps}
\end{center}
\hangcaption{平均コサイン類似度値-Recall 曲線．各 Recall 値において推定された全ての文対応に対しコサイン類似度を計算し，平均を取った値の変化を示す．}
\label{fig:recall-vs-avgcossim}
\vspace{-0.5\Cvs}
\end{figure}


一方で，低再現率 (Recall: 0.0〜0.25) では，中再現率で高い適合率であった combine よりもロジスティック回帰や L-CRF$_{\rm rep}$ の方が高い性能であった．この原因を調べるため，低再現率と中再現率においてどのような文対応が推定できているかをコサイン類似度の観点から調査した．ここで，各 Recall 値の性能時において推定できた全ての文対応に対しコサイン類似度を計算し，平均を取った値の変化をグラフにした図を図 \ref{fig:recall-vs-avgcossim} に示す．図 \ref{fig:recall-vs-avgcossim} より，いずれの手法においても低い再現率値においてはコサイン類似度の平均が高く，徐々にコサイン類似度の平均は下がって行くことが分かる．中でも combine は低再現率においてコサイン類似度の平均が他手法に比較すると特に低いことから，コサイン類似度の重要性を低く見ているために高類似度の文間に見られる文対応を見落としていると考えている\footnote{なお，例えば再現率 10\% において推定された文対応のコサイン類似度について，ロジスティック回帰の分散は 0.052，combine の分散は 0.035 であった．特に，コサイン類似度が 0 であった文対の割合は，ロジスティック回帰の場合は 12.3\% であったのに対し，combine の場合は 48.8\% と大きな差があった．}．これに対しては，combine では他の手法よりも単純な単語マッチなどでは推定が困難な文対応もある程度発見できるという特徴を持つことでもあるため，コサイン類似度の値によって推定手法を切り替えるなどで様々な文対にも対応可能になると考えている．すなわち，コサイン類似度が高い文対ではロジスティック回帰やL-CRF$_{\rm rep}$など，低い文対では combine を用いることで，より推定性能が向上すると考えている．

\begin{table}[b]
\begin{minipage}[t]{205pt}
\setlength{\captionwidth}{190pt}
\hangcaption{提案モデル combine におけるレビュー文種類ごとの文対応推定性能（F値最大点）}
\label{tb:rvl-pr}
\input{02table06.txt}
\end{minipage}
\begin{minipage}[t]{205pt}
\setlength{\captionwidth}{190pt}
\hangcaption{提案モデル combine における応答文種類ごとの文対応推定性能（F値最大点）}
\label{tb:rpl-pr}
\input{02table07.txt}
\end{minipage}
\end{table}

次に，combine モデルにおける文種類ごとの推定性能を表 \ref{tb:rvl-pr}, \ref{tb:rpl-pr} に示す\footnote{表 \ref{tb:rpl-pr} で全ての項目が「---」となっている文種類（＜結びでの感謝＞ ＜署名・フッター＞）は今回のデータには該当する文種類に文対応がなかったもの，F値が「---」となっている文種類（＜定型的挨拶＞）は推定結果が全て false-positive であったものである．}．いずれの文書を基準にしても文種類によって性能に大きな差があるが，この主な理由は学習データ量の差によるものと考えている．すなわち，一部の文種類はほとんど文対応を持たないことや，そもそも当該文種類を持つ文の出現回数が少ないことに起因して学習が難しくなっている．特に前者については，例えばレビュー文種類 ＜感謝・応援＞＜プラン名＞ や応答文種類 ＜投稿御礼＞ について表 \ref{tb:review-dep-exists}, \ref{tb:reply-dep-exists} を見ると，登場する回数は多いものの文対応を持つものは極めて少ないことが分かる．これらの文種類については再現率が高いものの適合率が極めて低いことから，過剰に対応有りと推定してしまっていることが分かる．このように対応する可能性が低い文種類については，推定後に予め人手で作成したルールによりフィルタリングするなどにより解決できると考えている．

次に，実際の combine モデルの出力例を図 \ref{fig:result-ex} に示す（表 \ref{tb:result} に示すF値最大点における出力結果）．図中の実線が推定によって得られた正しい文対応を示し，実線に $\times$ 記号があるものは対応有りと推定されたが実際には対応していないもの，破線は対応無しと推定されたが実際には対応しているものを示す．

\begin{figure}[b]
\begin{center}
\includegraphics{22-1ia2f15.eps}
\end{center}
\hangcaption{combine モデルによる推定例．実線は対応有りと推定された正しい文対応を示す．実線に $\times$ 記号があるものは対応有りと推定されたが実際には対応していないもの，破線は対応無しと推定されたが実際には対応しているものを示す．}
\label{fig:result-ex}
\end{figure}

図 \ref{fig:result-ex} 左側は誤りなく文対応を推定できた例である．例えばレビュー文「フロントの係の方や…」「駅から歩いて5分程…」はいずれも対応先の応答文「また、温かな嬉しいお言葉…」と共通する内容語が存在しないが，正しく文対応が推定できている．これは，それぞれの文種類を ＜ポジティブ感想＞ ＜ほめへの感謝＞ と正しく推定できており，加えて「気持ちよく」「おいしい」「便利」といった語が現れる文と「御礼」といった言葉が現れる文の間には対応する可能性が高いといった傾向をうまく学習できたことによると考えている．

また，図 \ref{fig:result-ex} 右側は誤った推定が含まれている例である．例えばレビュー文「夜遅かったので…」は応答文「また、フロントスタッフに対しても…」と対応していると推定して誤っている．これは逆に，文種類がそれぞれ ＜ポジティブ感想＞ ＜ほめへの感謝＞ であることや，レビュー文中に「チェックアウト」が，応答文中に「フロント」「スタッフ」などの語が出現すると対応しやすいという傾向に影響されているためであると考えている．この場合，それぞれの文で触れられている対象が，チェックアウト時刻そのものなのか，チェックアウト時のスタッフの対応なのかを区別できればより正確な推定が可能になる．同様に，「夜遅かったので…」に対して応答文「当ホテルでは…」「クリスマスシーズン…」の間の文対応を発見することができなかった問題についても，それぞれの文でチェックアウト時刻に触れられていることを特定できれば対応を発見できる可能性が向上すると考えている．

\begin{figure}[b]
\begin{center}
\includegraphics{22-1ia2f16.eps}
\end{center}
\caption{combine モデルと 2D CRF モデルの推定例．左が combine，右が 2D CRF．}
\label{fig:result-ex-comparison}
\end{figure}

最後に，combine モデルと 2D CRF モデルによる出力の比較例を図 \ref{fig:result-ex-comparison} に示す（表 \ref{tb:result} に示すF値最大点における出力結果）．この例では，2D CRF モデルでは誤って対応ありと出力したペアに対しても，combine モデルでは正しく対応がないと出力できている．2D CRF モデルが誤った理由の一つとして，文対応推定の前提処理である文種類推定の誤りによる影響があると考えている．この例では，応答文「今回はサラダのある…」及び「次回宿泊時には…」に対して文種類 ＜情報追加＞ が誤って推定されているが（正しくは ＜お詫び＞ 及び ＜対話＞），\mbox{＜情}報追加＞ は関連した語が登場するレビュー文と対応を持ちやすいという傾向があるため，過剰に対応有りと出力されていると考えている．これに対し，combine モデルでは文種類と文対応を同時に推定するため，事前の文種類推定における誤りに影響されるといったことはないため正しく推定できている．


