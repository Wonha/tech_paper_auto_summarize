実験には「楽天データ公開」に収録されている楽天トラベルのレビューを用いた．
楽天トラベルのレビューでは，宿泊施設に対するユーザのレビュー文書に対して宿泊施設提供者が返答することによって文書対が構成されている．
典型的な文書対と文対応を示した例を図[REF_fig:dependency-example]に示す．
実際には楽天トラベルのレビュー348,564件のうち，レビュー文書・応答文書の双方が存在する276,562件からランダムサンプリングした1,000文書対を用いた．
この各文書を簡易的なヒューリスティックによって文単位に分割し，レビュー文4,813文・応答文6,160文を得た．
この1,000文書対に対して5分割交差検定を適用して評価を行う．
宿泊予約サイトの文種類の定義は，レビュー文書・応答文書ごとに文種類の分類に詳しい大沢らの先行研究を参考にした[CITE]．
大沢らは本実験と同じウェブサイトである楽天トラベルの「クチコミ・お客さまの声」を分析し，レビュー文を8種類，応答文を14種類に分類している．
本研究では文種類が特定できれば文対応の特定が容易になるよう，レビュー文を12種類，返答文を20種類に再分類した．
この分類を表[REF_tb:review-discourse]及び表[REF_tb:reply-discourse]に示す．
また，大沢らの分析からの主な変更点とその理由を以下に示す．
レビュー文種類—＜ポジ／ネガ感想＞の追加：一文にポジティブ・ネガティブな感想を双方含むレビュー文は，複数の応答文と対応することがあるため．
応答文種類—＜対応明示＞＜検討明示＞の具体性による細分化：具体性のある対応・検討明示文はそれぞれレビュー文で書かれた一つの事情と対応するが，抽象的なものはレビュー文で書かれた複数の事情と対応することがあるため．
以上の文種類の定義に基づき，人手で文種類及び文対応の有無をタグ付けした．
その結果，1,000文書対全体では4,492通りの文対応が得られた．
また，文種類について，各文種類の出現数と各文種類ごとに文対応がどの程度存在するかを調査したデータを表[REF_tb:review-dep-exists], [REF_tb:reply-dep-exists]に示す．
表中の「対応（平均数）」は一文から見たときの平均対応文数を示しており，「対応（存在率）」は一つでも対応が存在する割合を示している．
表[REF_tb:review-dep-exists], [REF_tb:reply-dep-exists]より，例えばレビュー文種類では＜ネガティブ感想＞や＜要求・要望＞が，応答文種類では＜お詫び＞や＜具体的対応明示＞などの文種類で対応存在率が高いなど，文種類によって対応の平均数や対応存在率が大きく異なることが分かる．
次に，文対応が交差する割合を示す．
交差割合の計算は，各文書対において「文書対内において交差を持つ文対応の数／文書対内における全ての文対応の数」により求めた．
結果，交差割合の平均は0.249であることから，本データにおいても文の出現順序と文対応の出現位置は必ずしも一致しないことが分かる．
最後に，文対応の有無別にコサイン類似度の分布を表したヒストグラムを図[REF_fig:cossim-dist-f], [REF_fig:cossim-dist-t]に示す（なお，コサイン類似度が0.3--1.0である文対応の割合は少なかったため省略している）．
なお，コサイン類似度は，各文におけるstop-wordを除く単語の出現頻度を値に持つベクトルを用いて計算した値である．
文対応を持つ文間の方が比較的高いコサイン類似度が高い傾向がある一方，文対応が存在する文対のうち53.56%はコサイン類似度が0であった．
そのため，本データにおいても対応する文同士は必ずしも類似しないことが分かる．
実験で比較する手法は次の5つである．
まず，[REF_sec:proposal-simple]節で説明したL-CRF[MATH], L-CRF[MATH], 2D CRFの3種類を用いる．
また，[REF_sec:proposal-combine]節で説明した統合モデルcombineを用いる．
加えて，系列ラベリング問題ではなく二値分類問題と考えるモデルとしてロジスティック回帰(Logistic)でも性能を調査する．
ロジスティック回帰は，L-CRFや2D CRFにおいて隣接する出力変数間の依存関係を考慮しないモデルに相当する．
CRFの各モデルのパラメータ学習・利用にはMALLET 2.0.7 [CITE]中のGRMM [CITE]を用いた．
GRMMに用いたパラメータはデフォルト（TRPの最大iteration回数1,000回，TRPの収束判定用の値0.01）とし，周辺確率の計算にはTRP [CITE]を利用した．
なお，GRMMはCRF学習パラメータの正則化にL2正則化[CITE]を利用している．
また，ロジスティック回帰のパラメータ学習・利用にはscikit-learn 0.15.1 [CITE]を用い，正則化にはL2正則化を利用した．
文種類の推定には，文を構成するunigram（単語の表層形）を素性として用いる．
また，文対応の推定，及びcombineモデルにおいて新たに追加した因子には以下の素性を用いる．
なお，単語分割にはMeCab 0.994 [CITE]を利用した．
レビュー文を構成するunigram
応答文を構成するunigram
レビュー文・応答文のコサイン類似度（0〜1の値）
予め文種類モデルで推定したレビュー文・応答文の種類（combineモデル以外）
また，unigram素性及びコサイン類似度の計算に利用する単語からは予めstop-wordを除去しており，1,000文書対全体では9,300種類の単語が存在した．
文対応推定性能の評価は，適合率(Precision)・再現率(Recall)，及びそれらの調和平均であるF値から行う．
すなわち，考えうる全ての文対応の可能性から正しい文対応を探す課題とみなし，次の式で計算する．
\text{Recall} & = \frac{正しく推定できた対応数}{評価データ中に存在する文対応数}
[0.5zw] \text{Precision} & = \frac{正しく推定できた文対応数}{システムが文対応有りと出力した文対応数}
本実験では，以下に説明する手法により適合率・再現率を調整し，これらの性能がどのように変化するかを調査する．
具体的には，文同士が対応する確率[MATH]と対応しない確率[MATH]の比率を取り，閾値を与えて閾値以上か否かで文対応の有無の出力を変更する．
すなわち，文対応[MATH]の最終的な出力[MATH]は閾値[MATH]を用いて次の式([REF_eq:alpha])のようにする．
実験結果を表[REF_tb:result]に示す．
各数値は適合率・再現率を調整した際に学習データにおいてF値が最大となる点を用い，5分割交差検定でのマイクロ平均値を計算した数値である．
なお，表[REF_tb:result]に示す結果のF値に対してブートストラップ検定で得られたp値をHolm法[CITE]によって調整した有意水準と比較することで多重比較を行い，統合モデルcombineは他手法全てに対して統計的有意差があることを確認している（有意水準5%）-0.5zw．
併せて，閾値を変化させた際のPrecision-Recall曲線を図[REF_fig:pr]に示す．
表[REF_tb:result]から，統合モデルcombineは文種類・文対応を別々に推定する各手法よりも高い性能となった．
また，図[REF_fig:pr]より中程度の再現率(Recall: 0.25〜0.75)でもcombineは概ね他手法よりも高い適合率であり，多くの場合において高い性能であったといえる．
一方で，低再現率(Recall: 0.0〜0.25)では，中再現率で高い適合率であったcombineよりもロジスティック回帰やL-CRF[MATH]の方が高い性能であった．
この原因を調べるため，低再現率と中再現率においてどのような文対応が推定できているかをコサイン類似度の観点から調査した．
ここで，各Recall値の性能時において推定できた全ての文対応に対しコサイン類似度を計算し，平均を取った値の変化をグラフにした図を図[REF_fig:recall-vs-avgcossim]に示す．
図[REF_fig:recall-vs-avgcossim]より，いずれの手法においても低い再現率値においてはコサイン類似度の平均が高く，徐々にコサイン類似度の平均は下がって行くことが分かる．
中でもcombineは低再現率においてコサイン類似度の平均が他手法に比較すると特に低いことから，コサイン類似度の重要性を低く見ているために高類似度の文間に見られる文対応を見落としていると考えている．
これに対しては，combineでは他の手法よりも単純な単語マッチなどでは推定が困難な文対応もある程度発見できるという特徴を持つことでもあるため，コサイン類似度の値によって推定手法を切り替えるなどで様々な文対にも対応可能になると考えている．
すなわち，コサイン類似度が高い文対ではロジスティック回帰やL-CRF[MATH]など，低い文対ではcombineを用いることで，より推定性能が向上すると考えている．
次に，combineモデルにおける文種類ごとの推定性能を表[REF_tb:rvl-pr], [REF_tb:rpl-pr]に示す．
いずれの文書を基準にしても文種類によって性能に大きな差があるが，この主な理由は学習データ量の差によるものと考えている．
すなわち，一部の文種類はほとんど文対応を持たないことや，そもそも当該文種類を持つ文の出現回数が少ないことに起因して学習が難しくなっている．
特に前者については，例えばレビュー文種類＜感謝・応援＞＜プラン名＞や応答文種類＜投稿御礼＞について表[REF_tb:review-dep-exists], [REF_tb:reply-dep-exists]を見ると，登場する回数は多いものの文対応を持つものは極めて少ないことが分かる．
これらの文種類については再現率が高いものの適合率が極めて低いことから，過剰に対応有りと推定してしまっていることが分かる．
このように対応する可能性が低い文種類については，推定後に予め人手で作成したルールによりフィルタリングするなどにより解決できると考えている．
次に，実際のcombineモデルの出力例を図[REF_fig:result-ex]に示す（表[REF_tb:result]に示すF値最大点における出力結果）．
図中の実線が推定によって得られた正しい文対応を示し，実線に[MATH]記号があるものは対応有りと推定されたが実際には対応していないもの，破線は対応無しと推定されたが実際には対応しているものを示す．
図[REF_fig:result-ex]左側は誤りなく文対応を推定できた例である．
例えばレビュー文「フロントの係の方や…」「駅から歩いて5分程…」はいずれも対応先の応答文「また、温かな嬉しいお言葉…」と共通する内容語が存在しないが，正しく文対応が推定できている．
これは，それぞれの文種類を＜ポジティブ感想＞＜ほめへの感謝＞と正しく推定できており，加えて「気持ちよく」「おいしい」「便利」といった語が現れる文と「御礼」といった言葉が現れる文の間には対応する可能性が高いといった傾向をうまく学習できたことによると考えている．
また，図[REF_fig:result-ex]右側は誤った推定が含まれている例である．
例えばレビュー文「夜遅かったので…」は応答文「また、フロントスタッフに対しても…」と対応していると推定して誤っている．
これは逆に，文種類がそれぞれ＜ポジティブ感想＞＜ほめへの感謝＞であることや，レビュー文中に「チェックアウト」が，応答文中に「フロント」「スタッフ」などの語が出現すると対応しやすいという傾向に影響されているためであると考えている．
この場合，それぞれの文で触れられている対象が，チェックアウト時刻そのものなのか，チェックアウト時のスタッフの対応なのかを区別できればより正確な推定が可能になる．
同様に，「夜遅かったので…」に対して応答文「当ホテルでは…」「クリスマスシーズン…」の間の文対応を発見することができなかった問題についても，それぞれの文でチェックアウト時刻に触れられていることを特定できれば対応を発見できる可能性が向上すると考えている．
最後に，combineモデルと2D CRFモデルによる出力の比較例を図[REF_fig:result-ex-comparison]に示す（表[REF_tb:result]に示すF値最大点における出力結果）．
この例では，2D CRFモデルでは誤って対応ありと出力したペアに対しても，combineモデルでは正しく対応がないと出力できている．
2D CRFモデルが誤った理由の一つとして，文対応推定の前提処理である文種類推定の誤りによる影響があると考えている．
この例では，応答文「今回はサラダのある…」及び「次回宿泊時には…」に対して文種類＜情報追加＞が誤って推定されているが（正しくは＜お詫び＞及び＜対話＞），＜情報追加＞は関連した語が登場するレビュー文と対応を持ちやすいという傾向があるため，過剰に対応有りと出力されていると考えている．
これに対し，combineモデルでは文種類と文対応を同時に推定するため，事前の文種類推定における誤りに影響されるといったことはないため正しく推定できている．
実験には「楽天データ公開」に収録されている楽天トラベルのレビューを用いた．
楽天トラベルのレビューでは，宿泊施設に対するユーザのレビュー文書に対して宿泊施設提供者が返答することによって文書対が構成されている．
典型的な文書対と文対応を示した例を図[REF_fig:dependency-example]に示す．
実際には楽天トラベルのレビュー348,564件のうち，レビュー文書・応答文書の双方が存在する276,562件からランダムサンプリングした1,000文書対を用いた．
この各文書を簡易的なヒューリスティックによって文単位に分割し，レビュー文4,813文・応答文6,160文を得た．
この1,000文書対に対して5分割交差検定を適用して評価を行う．
宿泊予約サイトの文種類の定義は，レビュー文書・応答文書ごとに文種類の分類に詳しい大沢らの先行研究を参考にした[CITE]．
大沢らは本実験と同じウェブサイトである楽天トラベルの「クチコミ・お客さまの声」を分析し，レビュー文を8種類，応答文を14種類に分類している．
本研究では文種類が特定できれば文対応の特定が容易になるよう，レビュー文を12種類，返答文を20種類に再分類した．
この分類を表[REF_tb:review-discourse]及び表[REF_tb:reply-discourse]に示す．
また，大沢らの分析からの主な変更点とその理由を以下に示す．
レビュー文種類—＜ポジ／ネガ感想＞の追加：一文にポジティブ・ネガティブな感想を双方含むレビュー文は，複数の応答文と対応することがあるため．
応答文種類—＜対応明示＞＜検討明示＞の具体性による細分化：具体性のある対応・検討明示文はそれぞれレビュー文で書かれた一つの事情と対応するが，抽象的なものはレビュー文で書かれた複数の事情と対応することがあるため．
以上の文種類の定義に基づき，人手で文種類及び文対応の有無をタグ付けした．
その結果，1,000文書対全体では4,492通りの文対応が得られた．
また，文種類について，各文種類の出現数と各文種類ごとに文対応がどの程度存在するかを調査したデータを表[REF_tb:review-dep-exists], [REF_tb:reply-dep-exists]に示す．
表中の「対応（平均数）」は一文から見たときの平均対応文数を示しており，「対応（存在率）」は一つでも対応が存在する割合を示している．
表[REF_tb:review-dep-exists], [REF_tb:reply-dep-exists]より，例えばレビュー文種類では＜ネガティブ感想＞や＜要求・要望＞が，応答文種類では＜お詫び＞や＜具体的対応明示＞などの文種類で対応存在率が高いなど，文種類によって対応の平均数や対応存在率が大きく異なることが分かる．
次に，文対応が交差する割合を示す．
交差割合の計算は，各文書対において「文書対内において交差を持つ文対応の数／文書対内における全ての文対応の数」により求めた．
結果，交差割合の平均は0.249であることから，本データにおいても文の出現順序と文対応の出現位置は必ずしも一致しないことが分かる．
最後に，文対応の有無別にコサイン類似度の分布を表したヒストグラムを図[REF_fig:cossim-dist-f], [REF_fig:cossim-dist-t]に示す（なお，コサイン類似度が0.3--1.0である文対応の割合は少なかったため省略している）．
なお，コサイン類似度は，各文におけるstop-wordを除く単語の出現頻度を値に持つベクトルを用いて計算した値である．
文対応を持つ文間の方が比較的高いコサイン類似度が高い傾向がある一方，文対応が存在する文対のうち53.56%はコサイン類似度が0であった．
そのため，本データにおいても対応する文同士は必ずしも類似しないことが分かる．
実験で比較する手法は次の5つである．
まず，[REF_sec:proposal-simple]節で説明したL-CRF[MATH], L-CRF[MATH], 2D CRFの3種類を用いる．
また，[REF_sec:proposal-combine]節で説明した統合モデルcombineを用いる．
加えて，系列ラベリング問題ではなく二値分類問題と考えるモデルとしてロジスティック回帰(Logistic)でも性能を調査する．
ロジスティック回帰は，L-CRFや2D CRFにおいて隣接する出力変数間の依存関係を考慮しないモデルに相当する．
CRFの各モデルのパラメータ学習・利用にはMALLET 2.0.7 [CITE]中のGRMM [CITE]を用いた．
GRMMに用いたパラメータはデフォルト（TRPの最大iteration回数1,000回，TRPの収束判定用の値0.01）とし，周辺確率の計算にはTRP [CITE]を利用した．
なお，GRMMはCRF学習パラメータの正則化にL2正則化[CITE]を利用している．
また，ロジスティック回帰のパラメータ学習・利用にはscikit-learn 0.15.1 [CITE]を用い，正則化にはL2正則化を利用した．
文種類の推定には，文を構成するunigram（単語の表層形）を素性として用いる．
また，文対応の推定，及びcombineモデルにおいて新たに追加した因子には以下の素性を用いる．
なお，単語分割にはMeCab 0.994 [CITE]を利用した．
レビュー文を構成するunigram
応答文を構成するunigram
レビュー文・応答文のコサイン類似度（0〜1の値）
予め文種類モデルで推定したレビュー文・応答文の種類（combineモデル以外）
また，unigram素性及びコサイン類似度の計算に利用する単語からは予めstop-wordを除去しており，1,000文書対全体では9,300種類の単語が存在した．
文対応推定性能の評価は，適合率(Precision)・再現率(Recall)，及びそれらの調和平均であるF値から行う．
すなわち，考えうる全ての文対応の可能性から正しい文対応を探す課題とみなし，次の式で計算する．
\text{Recall} & = \frac{正しく推定できた対応数}{評価データ中に存在する文対応数}
[0.5zw] \text{Precision} & = \frac{正しく推定できた文対応数}{システムが文対応有りと出力した文対応数}
本実験では，以下に説明する手法により適合率・再現率を調整し，これらの性能がどのように変化するかを調査する．
具体的には，文同士が対応する確率[MATH]と対応しない確率[MATH]の比率を取り，閾値を与えて閾値以上か否かで文対応の有無の出力を変更する．
すなわち，文対応[MATH]の最終的な出力[MATH]は閾値[MATH]を用いて次の式([REF_eq:alpha])のようにする．
実験結果を表[REF_tb:result]に示す．
各数値は適合率・再現率を調整した際に学習データにおいてF値が最大となる点を用い，5分割交差検定でのマイクロ平均値を計算した数値である．
なお，表[REF_tb:result]に示す結果のF値に対してブートストラップ検定で得られたp値をHolm法[CITE]によって調整した有意水準と比較することで多重比較を行い，統合モデルcombineは他手法全てに対して統計的有意差があることを確認している（有意水準5%）-0.5zw．
併せて，閾値を変化させた際のPrecision-Recall曲線を図[REF_fig:pr]に示す．
表[REF_tb:result]から，統合モデルcombineは文種類・文対応を別々に推定する各手法よりも高い性能となった．
また，図[REF_fig:pr]より中程度の再現率(Recall: 0.25〜0.75)でもcombineは概ね他手法よりも高い適合率であり，多くの場合において高い性能であったといえる．
一方で，低再現率(Recall: 0.0〜0.25)では，中再現率で高い適合率であったcombineよりもロジスティック回帰やL-CRF[MATH]の方が高い性能であった．
この原因を調べるため，低再現率と中再現率においてどのような文対応が推定できているかをコサイン類似度の観点から調査した．
ここで，各Recall値の性能時において推定できた全ての文対応に対しコサイン類似度を計算し，平均を取った値の変化をグラフにした図を図[REF_fig:recall-vs-avgcossim]に示す．
図[REF_fig:recall-vs-avgcossim]より，いずれの手法においても低い再現率値においてはコサイン類似度の平均が高く，徐々にコサイン類似度の平均は下がって行くことが分かる．
中でもcombineは低再現率においてコサイン類似度の平均が他手法に比較すると特に低いことから，コサイン類似度の重要性を低く見ているために高類似度の文間に見られる文対応を見落としていると考えている．
これに対しては，combineでは他の手法よりも単純な単語マッチなどでは推定が困難な文対応もある程度発見できるという特徴を持つことでもあるため，コサイン類似度の値によって推定手法を切り替えるなどで様々な文対にも対応可能になると考えている．
すなわち，コサイン類似度が高い文対ではロジスティック回帰やL-CRF[MATH]など，低い文対ではcombineを用いることで，より推定性能が向上すると考えている．
次に，combineモデルにおける文種類ごとの推定性能を表[REF_tb:rvl-pr], [REF_tb:rpl-pr]に示す．
いずれの文書を基準にしても文種類によって性能に大きな差があるが，この主な理由は学習データ量の差によるものと考えている．
すなわち，一部の文種類はほとんど文対応を持たないことや，そもそも当該文種類を持つ文の出現回数が少ないことに起因して学習が難しくなっている．
特に前者については，例えばレビュー文種類＜感謝・応援＞＜プラン名＞や応答文種類＜投稿御礼＞について表[REF_tb:review-dep-exists], [REF_tb:reply-dep-exists]を見ると，登場する回数は多いものの文対応を持つものは極めて少ないことが分かる．
これらの文種類については再現率が高いものの適合率が極めて低いことから，過剰に対応有りと推定してしまっていることが分かる．
このように対応する可能性が低い文種類については，推定後に予め人手で作成したルールによりフィルタリングするなどにより解決できると考えている．
次に，実際のcombineモデルの出力例を図[REF_fig:result-ex]に示す（表[REF_tb:result]に示すF値最大点における出力結果）．
図中の実線が推定によって得られた正しい文対応を示し，実線に[MATH]記号があるものは対応有りと推定されたが実際には対応していないもの，破線は対応無しと推定されたが実際には対応しているものを示す．
図[REF_fig:result-ex]左側は誤りなく文対応を推定できた例である．
例えばレビュー文「フロントの係の方や…」「駅から歩いて5分程…」はいずれも対応先の応答文「また、温かな嬉しいお言葉…」と共通する内容語が存在しないが，正しく文対応が推定できている．
これは，それぞれの文種類を＜ポジティブ感想＞＜ほめへの感謝＞と正しく推定できており，加えて「気持ちよく」「おいしい」「便利」といった語が現れる文と「御礼」といった言葉が現れる文の間には対応する可能性が高いといった傾向をうまく学習できたことによると考えている．
また，図[REF_fig:result-ex]右側は誤った推定が含まれている例である．
例えばレビュー文「夜遅かったので…」は応答文「また、フロントスタッフに対しても…」と対応していると推定して誤っている．
これは逆に，文種類がそれぞれ＜ポジティブ感想＞＜ほめへの感謝＞であることや，レビュー文中に「チェックアウト」が，応答文中に「フロント」「スタッフ」などの語が出現すると対応しやすいという傾向に影響されているためであると考えている．
この場合，それぞれの文で触れられている対象が，チェックアウト時刻そのものなのか，チェックアウト時のスタッフの対応なのかを区別できればより正確な推定が可能になる．
同様に，「夜遅かったので…」に対して応答文「当ホテルでは…」「クリスマスシーズン…」の間の文対応を発見することができなかった問題についても，それぞれの文でチェックアウト時刻に触れられていることを特定できれば対応を発見できる可能性が向上すると考えている．
最後に，combineモデルと2D CRFモデルによる出力の比較例を図[REF_fig:result-ex-comparison]に示す（表[REF_tb:result]に示すF値最大点における出力結果）．
この例では，2D CRFモデルでは誤って対応ありと出力したペアに対しても，combineモデルでは正しく対応がないと出力できている．
2D CRFモデルが誤った理由の一つとして，文対応推定の前提処理である文種類推定の誤りによる影響があると考えている．
この例では，応答文「今回はサラダのある…」及び「次回宿泊時には…」に対して文種類＜情報追加＞が誤って推定されているが（正しくは＜お詫び＞及び＜対話＞），＜情報追加＞は関連した語が登場するレビュー文と対応を持ちやすいという傾向があるため，過剰に対応有りと出力されていると考えている．
これに対し，combineモデルでは文種類と文対応を同時に推定するため，事前の文種類推定における誤りに影響されるといったことはないため正しく推定できている．
