Negation Naive Bayesの導出 \label{Sec:Negation Naive Bayesの導出}

NNBはCNBと同様に補集合を利用して文書分類を行うが，CNBと異なってNBと同じ事後確率最大化の式から導出が可能である．
その結果，事前確率を数学的に正しく考慮することで，クラスごとの文書数が異なっているときにもより正確な文書分類を行えるようにした．
本節ではNBの導出と，CNBの概念について触れた後，提案手法であるNNBの導出について述べる．


\subsection{Naive Bayes分類器}\label{Sec:Naive Bayes分類器}

一般に確率モデルによる文書分類では，分類対象となる文書を$d$，ある一つのクラスを$c$としたとき，
事後確率$P(c|d)$を最大化するクラス$\hat{c}$を求める\cite{Zhang}．
NB分類器を用いた文書分類では，事後確率にBayesの定理を適用する．
文書の取り出される確率$P(d)$はすべてのクラスについて一定であることを考慮すると，
事後確率が最大のクラスを推定することは，クラスの出現確率$P(c)$と各クラスでの文書の出現確率$P(d|c)$の積を最大化するクラスを推定することと等しくなる．
\begin{equation}
\begin{aligned}[b]
\hat{c} & = \argmax_{c} P(c|d)  \\
 & = \argmax_{c} \frac{P(c)P(d|c)}{P(d)}  \\
 & = \argmax_{c} P(c) P(d|c) 
\end{aligned}
\label{eq:bayes}
\end{equation}

式(\ref{eq:bayes})において，$P(c)$は全文書中でクラス$c$に属する文書の割合を用いて容易に推定ができるが，$P(d|c)$を直接推定するのは難しい．
そこで，まず文書$d$を単語列$w_1, w_2, \ldots , w_n$で近似する．
\begin{equation}
P(d|c) \approx P(w_1,w_2,\ldots,w_n|c) \label{eq:bayes2}
\end{equation}

次に，各クラスで単語が独立に生起すると仮定すると，式(\ref{eq:bayes2})は
\begin{equation}
P(w_1,w_2,\ldots,w_n|c)\approx\prod_{i=1}^{n} P(w_i|c) \label{eq:bayes3}
\end{equation}
と近似される．

したがって，$d$の属するクラス$\hat{c}$は最終的に以下の式で求められる．
\begin{equation}
\hat{c}=\argmax_{c} P(c) \prod_{i=1}^{n} P(w_i|c) \label{eq:rnb}
\end{equation}


\subsection{Complement Naive Bayes分類器}
\label{Sec:Complement Naive Bayes分類器}

多項モデルを用いたNB分類器では，クラス間の文書数に大きなばらつきがある場合に，
文書数の小さいクラスで$P(w_i|c)$が大きくなる傾向がある．
$P(w_i|c)$は「そのクラス中に出てきたそのトー
クン$w_i$の数／そのクラス中に出てきたそのトークンの総数」であるため，訓練事例の単語トー
クン数に大きな差ができた結果，大きいクラスの$P(w_i|c)$は比較的小さく，小さいクラスの
$P(w_i|c)$はかなり大きくなることが予想できる．その結果，小さいクラスに出現した単語を含む
文書が出現した場合，その文書は，その単語をもつ小さなクラスに割り当てられることになる．

また，文書数の少ないクラスでは，新規文書に出現した単語がそのクラスに含まれていない割合が多くなり，データがスパースになりやすい．

そこで，学習する文書数のばらつきを抑え，スパースネス問題を緩和するようNBを改良したのが\citeA{Rennie}のCNBである．
具体的には，「クラス$c$に属す訓練事例」ではなく「クラス$c$に属さない訓練事例」
すなわち「$\bar{c}$に属する訓練事例（補集合）」を用いて学習を行う\footnote{Rennieらは文献の中でCNBのほかに5種類のヒューリスティックを導入しているが，本研究では純粋に式の変更による違いを見るため，ヒューリスティックは使用しなかった．}．

\begin{figure}[b]
\begin{center}
\includegraphics{20-2ia4f1.eps}
\end{center}
\caption{NBとCNBでの学習に用いる文書数の違い}
\label{Fig:コンプ文書数変化}
\end{figure}

図\ref{Fig:コンプ文書数変化}は，NBとCNBでの学習に用いる文書数の違いを表している．
文書数10，10，20，40の4つのクラスがある場合，NBではこの文書数を自身のクラスの学習に使う．
そのため，文書数が最も少ないクラスと最も多いクラスでは学習に使用する文書数に4倍の差がある．

一方，CNBでは自身のクラスに属する文書以外の文書から学習を行うため，
学習に用いる文書数は最小のもので40，最大のもので70となり，NBに比べてばらつきが小さくなる．

CNBは，文書内にある単語の出現確率の積から尤度を計算し，分類するクラスを決めるという点ではNBと同じである．
つまり，式(\ref{eq:rnb})を用いて文書$d$の属するクラス$\hat{c}$を推定する．
しかし，CNBでは$P(w_i|c)$を最尤推定で求めるのではなく，$c$以外のクラス$\bar{c}$の尤度の積から推定する．
つまり，$d$の属するクラス$\hat{c}$は最終的に以下の式で求められる．
\begin{equation}
\hat{c}=\argmax_{c} P(c) \prod_{i=1}^{n} \frac{1}{P(w_i|\bar{c})} \label{eq:cnb}
\end{equation}


\subsection{Negation Naive Bayes分類器}
\label{Sec:Negation Naive Bayes分類器}

前節で説明したCNBは，NBの持つ「クラス間の文書数のばらつきによって分類結果が偏る」という特徴を緩和する手法である．
しかし，CNBはヒューリスティックによる解決法であって，事後
確率最大化の式から導出することはできない．

そこで本研究では，事後確率最大化の式から導出でき，かつ，CNBの「訓練にクラスの補集合を
利用する」という長所をもつ分類器を作成する．
以下でNBと同様の，事後確率最大化の式（式
(\ref{eq:bayes})）からの式の変形について述べる．

まず，事後確率$P(c|d)$を最大化するクラス$\hat{c}$を求める式を補集合を利用するように変形する．
\begin{equation}
\begin{aligned}[b]
\hat{c}  & = \argmax_{c} P(c|d) \\
  & =  \argmax_{c} (1-P(\bar{c}|d)) \\
  & =  \argmin_{c} P(\bar{c}|d) 
\end{aligned}
\label{eq:eqnnb1}
\end{equation}
次に，Bayesの定理を用いて式(\ref{eq:eqnnb1})を変形する．
\begin{equation}
\begin{aligned}[b]
 \hat{c} & =  \argmin_{c} \frac{P(\bar{c})P(d|\bar{c})} {P(d)} \\
   & =  \argmin_{c} P(\bar{c})P(d|\bar{c}) 
\end{aligned}
\label{eq:eqnnb2}
\end{equation}

そして，式(\ref{eq:eqnnb2})を近似する．$P(d|\bar{c})$は式(\ref{eq:bayes2})，(\ref{eq:bayes3})と同様に
\begin{equation}
P(d|\bar{c})\approx\prod_{i=1}^{n} P(w_i|\bar{c}) \label{eq:eqnnb3}
\end{equation}
と近似される．
したがって，文書$d$の属するクラス$\hat{c}$を以下の式で推定する．
\begin{equation}
\hat{c} =\argmin_{c} P(\bar{c}) \prod_{i=1}^{n} P(w_i|\bar{c}) \label{eq:nnb}
\end{equation}

なお，$P(\bar{c})=1-P(c)$であり，CNBと同じく最大化で表現すると以下の式になる．
\begin{equation}
\hat{c} =\argmax_{c} \frac{1}{1-P(c)} \prod_{i=1}^{n} \frac{1}{P(w_i|\bar{c})} \label{eq:nnb2}
\end{equation}

式 (\ref{eq:cnb}) と比較すると，$\frac{1}{1-P(c)}$の最大化の部分，つまり事前確率$P(c)$の部分が異なっていることが分かる．
式(\ref{eq:nnb2})は事後確率最大化の式から求められたため，事前確率を数学的に正しく考慮し
た式となっている．なお，Rennie らの研究では，式(\ref{eq:cnb})において事前確率の扱いについてあま
り注意を払っていないが，我々はクラスごとに単語数の偏りが大きいデータセットについて分
類を行う場合には，$P(c)$を利用するか$\frac{1}{1-P(c)}$を利用するかの影響は必ずしも無視して良いとは
言えないと考える．また，Rennieらの研究では，$P(c)$は$P(w_i|\bar{c})$に比べて分類結果への影響が
小さいと判断し，事前確率は計算してもしなくても結果は同じと考え，実際の分類には$P(c)$を
無視して$P(w_i|\bar{c})$のみを計算しているため，P(c)なしのCNBについても参考として実験を行う．



結果 \label{Sec:結果}

\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}と\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}に
全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率のマイクロ平
均とマクロ平均をそれぞれ示し，
\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}に
名詞だけを使用したオークションのカテゴリ分類実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示す．
また，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率}と\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}に
ニュースグループの分類実験において，一文書あたりの単語数を減らした実験の分類正解率のマイクロ平均
とマクロ平均をそれぞれ示し，
\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}に
同分類実験において，クラスごとの文書数を不均一にした実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示す．
なお，正解率は，（分類
に成功したもの）／（実験データ数）として求めた．
同じ文書集合の実験で，NB，CNB，NNBのうちで最も良かった正解率を太字で示した．さらに，次に良かった正解率との差がカイ二乗検定で有意だったものに関しては
下線を引いた．また，$P(c)$なしのCNBとSVMに関しては，上記の三手法のうち最も良かった手法と同じか，それよりも良いものは太字で示し，
その優劣にかかわらず，差がカイ二乗検定で有意だったものに関しては下線を引いた．
さらに，参考として最頻出カテゴリ（クラス）を答えた場合の正解率も併記した．

\begin{table}[b]
\caption{全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マイクロ平均）}
\label{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}
\input{04table06.txt}
\end{table}
\begin{table}[b]
\caption{全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ平均）}
\label{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}
\input{04table07.txt}
\end{table}


\begin{table}[p]
\caption{名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マイクロ平均）}
\label{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率}
\input{04table08.txt}
\end{table}
\begin{table}[p]
\caption{名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ平均）}
\label{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}
\input{04table09.txt}
\end{table}
\begin{table}[p]
\hangcaption{ニュースグループの分類実験において一文書あたりの単語数を減らした実験の分類正解率{\break}（マイクロ平均）}
\label{Tab:一文書あたりの単語数を減らした実験の分類正解率}
\begin{center}
\input{04table10.txt}
\end{table}
\begin{table}[p]
\hangcaption{ニュースグループの分類実験において一文書あたりの単語数を減らした実験の分類正解率{\break}（マクロ平均）}
\label{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}
\input{04table11.txt}
\end{table}

\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}と
\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率}から，オークションのカテゴリ分類実験において，
マイクロ平均を比較した際，
NNBが常にNBとCNBを有意に上回っていることが分かる．
また同じ二つの表から，NNBが$P(c)$なしのCNBよりも大抵（名詞だけの実験の
「デスクトップ」が例外である）上回っていることが分かる．このうち，「記念切手」の実験では，全単語使用した場合，名詞だけを使用した場合に拘わらず，カイ二乗検定によりその差が有意であった．
しかし，これらの実験において最も良い結果なのはSVMであり，NNBを有意に上回っている．

\begin{table}[t]
\hangcaption{ニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の分類正解率{\break}（マイクロ平均）}
\label{Tab:クラスごとの文書数を不均一にした実験の分類正解率}
\input{04table12.txt}
\end{table}
\begin{table}[t]
\hangcaption{ニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の分類正解率{\break}（マクロ平均）}
\label{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}
\input{04table13.txt}
\end{table}

また，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}
から，
オークションのカテゴリ分類実験において，マクロ平均においても，
有意ではないながら，NNBが常にNBとCNBを上回っていることが分かる．また同じ二つの
表から，$P(c)$なしのCNBが有意ではないものの，NNBを上回っていることが分かる．さらに，
SVMは「デスクトップ」と「記念切手」においては有意に，「赤ちゃん用の玩具」では有意
ではないものの，NNBを上回った．

また，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}から，ニュースグループの分類実験においても，
マイクロ平均で比較した場合，
常にNBBがNBとCNBを上回ることが分かる．ただし，その差が有意なのは，クラスごとの文書数を不均一にした実験（\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}）
のパラメータが1のときと3のときだけである．
また，これらの実験において，$P(c)$なしのCNBはしばしばNNBを上回っているが，有意に上回っていることは一度もなかった．
さらに\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率}の一文書あたりの単語数を減らした実験では，
パラメータ0，1，2のとき，NNBの分類正解率がSVMを有意に上回っている．しかし，パラメータ3，4のときはSVMが最高であり，NNBと比較してその差は有意であった．
一方，\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率}から，クラスごとの文書数を不均一にした実験では，
全ての実験設定のときにNNBがSVMを上回っている．この差はカイ二乗検定により有意であった．

これに対し，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}と\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}
から，ニュースグループの分類実験において，マクロ平均におい
ても，NNBが常にNBとCNBを上回っていることが分かる．また同じ二つの表から，$P(c)$な
しのCNBがNNBを上回っていることが分かるが，これらの差はいずれも有意ではない．さら
に，\tabref{Tab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）}の一文書あたりの単語数を減らした実験では，
常に有意でないながらもNNBの分類正解率がSVMを上回っている．しかし，パラ
メータ3，4のときは，マイクロ平均と同様にSVMが最高であり，NNBと比較してその差は有
意であった．一方，\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，クラスごとの文書数を不均一にした実験では，全ての実験設定
のときにNNBがSVMを上回っている．この差はパラメータ0と1のとき，カイ二乗検定に
より有意であった．



考察 \label{Sec:考察}

オークションのカテゴリ分類実験の結果とニュースグループの分類実験の結果を総合してNNBの特色について考察する．
まず，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率}〜\tabref{Tab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）}から，
全ての実験を通して，NNBはNBとCNBを上回っていること，また$P(c)$なしのCNBに有意に勝っていることはあっても有意に負けていることはないことが
読みとれる\footnote{ただし，有意ではないものの，\tabref{Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}と\tabref{Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）}では常に$P(c)$なしのCNBがNNBを上回っている．$P(c)$は事前確率であるため，カテゴリ間のデータ数に偏りがあり，なおかつ単語トークン数が少ない場合には，NNBは大きなカテゴリに分類されやすいことが予想できる．そのため，マイクロ平均は$P(c)$なしのCNBを有意に上回ったが，マクロ平均は$P(c)$なしのCNBが高くなる傾向がある可能性がある．}
．
このことから，NNBは他のBayesの定理を利用した文書分類手法に比較しても引けを取らない文書分類手法であると言える．特にNBと比較したときには，マイクロ平均では常に有意に，
マクロ平均ではオークションのカテゴリ実験において「デスク
トップ」と「記念切手」の全品詞を使った分類実験以外の実験で有意に勝っていた．
なお，
マクロ平均ではサンプル数の減少から，NNBと比較した際，SVMとNBだけにしか有意差が
認められなかったため，今後は主にマイクロ平均について考察する．

オークションのカテゴリ分類実験とニュースグループの分類実験の実験設定の違いのうち，NNBの式に大きく関わりそうな点は二点あるだろう．
一つ目は第一項の事前確率に関わる，クラスごとの文書数（またはカテゴリごとの商品数）のばらつき，
二つ目はそれ以外の部分に関わる，一文書ごとの単語トークン数である．
\ref{Sec:ニュースグループの文書分類の実験}節でも述べたように，
CNBとNNBの式，式 (\ref{eq:cnb}) と式 (\ref{eq:nnb2}) を比較してみると，事前確率$P(c)$と$ \frac{1}{1-P(c)}$の部分が異なっており，
残りの$\prod_{i=1}^{n} \frac{1}{P(w_i|\bar{c})}$については等しい．
NNBは事前確率を数学的に正しく考慮しているため，文書分類ではクラスごとの文書数が不均一である際に効果を発揮すると考えられる．
また，単語数が少ない文書を分類する際には，単語数が多い文書を分類する際よりも，相対的に事前確率の影響が大きくなることが予想される．


クラスごとの文書数のばらつきを見るために，
\figref{Fig:標準偏差／平均}に同実験においてクラスごとの文書数を不均一にした実験の，クラスごとの文書数の標準偏差／平均を横軸とした
分類正解率の散布図を示す．

\begin{figure}[b]
\begin{center}
\includegraphics{20-2ia4f5.eps}
\end{center}
\hangcaption{ニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の，
	クラスごとの文書数の標準偏差／平均を横軸とした分類正解率の散布図}
\label{Fig:標準偏差／平均}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{20-2ia4f6.eps}
\end{center}
\hangcaption{ニュースグループの分類実験において一文書あたりの単語数を減らした実験の，一文書あたりの単語トークン数を横軸とした分類正解率の散布図}
\label{Fig:1文書ごとに平均した単語数}
\end{figure}

また，単語トークン数の影響を見るために，\figref{Fig:1文書ごとに平均した単語数}にニュースグループの分類実験において一文書あたりの単語数を減らした実験の，
一文書あたりの単語トークン数を横軸とした分類正解率の散布図を示す．その上でNNBの特徴をNB，CNB（$P(c)$のないものを含む），SVMの順で比較しつつ考察する．

\figref{Fig:標準偏差／平均}から，NBはクラスごとの文書数のばらつきが多い際にその分類正解率が著しく低下することが分かる．
また，商品のカテゴリ分類実験において，NBの分類正解率がとても低いのも
同じ原因によるものであることがうかがえる．商品のカテゴリ分類実験において，標準偏
\linebreak
差／平均は「デスクトップ」，「記念切手」，「赤ちゃん用の玩具」
がそれぞれ1.44，2.84，1.33と高く，
カテゴリごとの商品数のばらつきが大きいからである．
この原因として，クラスごとの$P(w_i|c)$のデータスパースネスの差が考えられる．ここでNBの式を再掲する．
\begin{equation}
\hat{c}=\argmax_{c} P(c) \prod_{i=1}^{n} P(w_i|c) \label{eq:rnb2}
\end{equation}
NBではクラスごとの文書数のばらつきが大きい際には，クラスによって訓練事例の単語トークン数に大きな差ができる．
例えば最も大きなクラスでは，その訓練事例となるトークン数が一万となり，小さなクラスでは10トークンといった具合である．
その結果，小さなクラスではデータがス
パースになり，より頻繁にスムージングが行われる．そのため，NBでは，個々の分類問題と
相性の良いスムージング手法を用いることが求められるが，今回のジェフリー・パークス法は
ラプラス法よりは良いとはいえ，まだ実際よりも大きな値を小さなクラスに与えていたと思わ
れる\footnote{\citeA{佐藤}のスムージング（頻度0の時には0.1/Nを用いる．このNは訓練事例中の全単語トークン数．）を用いるとNBだけ飛躍的に正解率が上昇した．ただし，本論文の主張との矛盾はない結果であった．}．
このように，NBではデータスパースネスによって誤分類が起きて分類正解率が著しく
下がることがあるが，この
問題を補集合を用いることで解決したのがCNBであり，この点についてNNBはCNBと全く同じ特色を持っている．

次に，NNBとCNBの差について考察する．
\figref{Fig:標準偏差／平均}を見てみると，$P(c)$を考慮しないCNBとNNBの差はあまりないが，NNBはCNBより若干
良いことが分かる．
これは，クラスごとの文書数に偏りが出てくると，CNBとNNBの違いである事前確率が異なってくるため，
その分類正解率に差がつくからであると考えられる．

次に\figref{Fig:1文書ごとに平均した単語数}を見てみると，一文書当たりの平均の単語数が減ると，どの手法を用いても全体的に分類正解率が低下することが分かる．
これは，単語数が減ることで，統計の材料となる$w_i$が減っているためであると考えられる．
これに対し，一文書当たりの単語数を変化させても，CNBとNNBの差が大きくなることはなかった．
これは，ニュースグループのオリジナルのコーパスでは，そもそもクラスごとの文書数に偏りがあまり見られないため，事前確率に偏りがなく，CNBとNNBがそう違わない結果になったためであると考えられる．

ここで，オークションのカテゴリ分類実験の実験設定も共に比較してみる．
\figref{Fig:CNBとNNB}に縦軸を標準偏差／平均，横軸をクラスごとの単語数にした，実験設定ごとのCNBとNNBの差の散布図を示す．
左の図が事前確率を考慮したCNBとNNBの差が有意であるかを表しており，右の図が事前確率を考慮しないCNBとNNBの差が有意であるかを表している．
なお，両方の図において，縦軸の値が0.10である五つの点が，ニュースグループの一文書当たりの単語数を減らした一連の実験であり，
横軸の値が128.71である五つの点が，ニュースグループのクラスごとの文書数を不均一にした一連の実験である．
オークションのカテゴリ分類実験の実験設定では，
ニュースグループの実験よりも，ひとつの文書（商品）ごとのトークン数が少なく（一文書当たりの単語数を最も減らした実験と同じくらいである），
なおかつクラス（カテゴリ）ごとの文書数（商品数）の偏りが，クラスごとの文書数を不均一にしたニュースグループの実験と同じくらい，またはそれ以上に偏っていることが分かる．

\begin{figure}[t]
\begin{center}
\includegraphics{20-2ia4f7.eps}
\end{center}
\hangcaption{横軸を標準偏差／平均，縦軸をクラスごとの単語数にした，実験設定ごとのCNBとNNBの差の散布図}
\label{Fig:CNBとNNB}
\end{figure}

\figref{Fig:CNBとNNB}により，標準偏差／平均が小さい時にはCNBとNNBの差はほとんどないこと，また，標準偏差／平均が大きくなるにつれてNNBが有意にCNBを上回るようになる傾向がうかがえる．
また，一文書あたりの単語数が少ない時に，なおかつ標準偏差／平均が大きければ，NNBが有意に事前確率を考慮しないCNBに対しても有意に上回ることが分かる．
オークションのカテゴリ分類実験の「記念切手」（左上の二点）のときには，両方の条件が共に十分当てはまったため，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回ったものと
思われる．

次に，SVMとの比較を行う．
残念ながら，NNBの分類正解率が，CNBにも事前確率を考慮しないCNBにも有意に上回った「記念切手」の実験設定を含む，オークションのカテゴリ分類実験では，SVMの分類正解率がいつも他手法を有意に上回った．
しかし，ニュースグループの文書分類実験では，一文書あたりの文書数を減らした場合のパラメータが3と4の実験を除き，NNBがSVMを有意に上回った．
上述したように，$w_i$の数が減ってしまうと，Bayesianアプローチの正解率は下がることが一文書当たりの単語数が減った際にSVMを有利にしたと考えられる．
しかし，ニュースグループのオリジナルのコーパスの実験では，CNBとの差は有意ではないながらも，NNBが全ての分類器の中で最も高い分類正解率となっている．
このことから，NNBは時にはSVMを有意に上回り，他手法と比較しても最も良い分類正解率を示しうる手法であることが分かる\footnote{\citeA{Gabrilovich}では，ニュースグループの分類実験において素性選択をする前でも76.9\%，素性選択後は85.3\%という正解率を報告している．また，\citeA{Siolas}では，同実験において素性選択を行うと86.44\%となっている．このように，SVMは素性選択などによってもっと性能をあげることが可能であるため，それらの手法を用いればSVMの方が性能が良くなる可能性が高い．また，五分割交差検定の分割法を変えて実験してみると，SVMの正解率が75.79\%となったことから，SVMの性能は，選択されるテストセットの選び方によって変化することが分かった．NNBなどのベイズの手法の正解率も，五分割交差検定の分割法により変化することが予想される．}．

\begin{table}[t]
\caption{ニュースグループの分類実験にかかった時間}
\label{Tab:ニュースグループの分類実験にかかった時間}
\input{04table14.txt}
\end{table}

また，最後に，提案手法の速度についての目安を知るために，最も実行時間がかかるオリジ
ナルのニュースグループの分類実験において，それぞれの手法の実行時間を測った．
\tabref{Tab:ニュースグループの分類実験にかかった時間}に
その結果を示す．SVMはC言語により実装されたツールによるものであり，それ以外の
BayesianアプローチはPerlにより個人的に実装したものであるため，一概に比較は難しいが，
NNBがCNBとほぼ同じ速度で実行されることが分かる．



