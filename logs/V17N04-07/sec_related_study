第[REF_sect_intro]節で述べた通り，人手によって任意の分野における未知語の情報を収集することはコストの面で現実的ではない．
このため，未知語に関する情報を自動獲得する研究が多く行われている．
まず，形態素解析など，自動単語分割を行うシステムにおいて単語辞書に未知語を追加することを目的とした研究について述べる．
文献[CITE]では，ある文の自動単語分割候補における[MATH]-bestの相対確率を，それぞれの候補において出現する未知語の出現頻度の期待値として与える．
その後，出現した未知語の中から一定の閾値より大きい出現頻度の期待値を持つ未知語を獲得している．
また，単語分割の際には，未知語を構成する字種によって9種類の未知語タイプを定義し，それぞれのタイプにおける単語長の分布を考慮した未知語モデルを用いることで，未知語モデルの性能向上を図っている．
形態素解析のため，品詞を考慮して未知語を獲得する研究として，文献[CITE]では，コーパス中に出現する任意の部分文字列[MATH]に注目し，[MATH]の前後の文字から，[MATH]が未知語として出現する可能性の高い品詞に属する確率を推定している．
その後，出現頻度が一定値以上かつ2文字以上の文字列[MATH]を単語として抽出しておき，形態素解析器にかけた結果に辞書未登録語が含まれている文字列[MATH]を未知語として獲得している．
日本語は分かち書きを行わない言語であるため，自動単語分割器や形態素解析器において必須となる未知語の情報は正しい単語単位である．
このため，形態素解析器のための未知語獲得を行う研究では未知語の読みには言及しないことが多い．
しかしながら，本研究では統計的仮名漢字変換の精度向上を目的としているため，未知語の表記ならびにその読みに関する情報を同時に獲得することが望ましい．
文献[CITE]では，仮名漢字変換を用いる際の入力とその変換結果から未知語の獲得と言語モデルの更新を行う手法を提案している．
また，言語モデルの更新を繰り返すことで，仮名漢字変換システムの精度が徐々に向上すると報告している．
ただし，ここで行われている実験はユーザによるシステムの利用を想定したシミュレーションであり，本論文で扱う自動獲得とは性質が異なる．
音声認識の分野においては，未知語を原因とする認識誤りの影響を抑制するため，単語より小さい単位の語彙であるサブワードを擬似的な単語とし，未知語をサブワードの連続として認識する手法が提案されている[CITE] [CITE] [CITE]．
しかしながら，日本語の音声認識においてサブワードは基本的に仮名文字列から構成されるため，サブワードをそのまま未知語獲得に用いても仮名漢字変換への寄与は低いと考えられる．
文献[CITE]では，規則を用いてテキストから未知語の候補を抽出，音声認識を用いて読みを自動的に獲得し，発音辞書に追加する手法が提案されている．
この手法は，テキストと音声から未知語と読みの情報を獲得する点で本研究と共通しているが，未知語候補の抽出方法と獲得する情報の粒度が本研究と異なる．
本研究では，疑似確率的単語分割コーパスを用いることにより，一貫した単語単位で言語モデルと発音辞書を作成する．
また，音声認識結果から未知語の読みだけではなく文脈情報を獲得し，統計的仮名漢字変換で利用する確率的言語モデル全体の性能向上を図っている．
第[REF_sect_intro]節で述べた通り，人手によって任意の分野における未知語の情報を収集することはコストの面で現実的ではない．
このため，未知語に関する情報を自動獲得する研究が多く行われている．
まず，形態素解析など，自動単語分割を行うシステムにおいて単語辞書に未知語を追加することを目的とした研究について述べる．
文献[CITE]では，ある文の自動単語分割候補における[MATH]-bestの相対確率を，それぞれの候補において出現する未知語の出現頻度の期待値として与える．
その後，出現した未知語の中から一定の閾値より大きい出現頻度の期待値を持つ未知語を獲得している．
また，単語分割の際には，未知語を構成する字種によって9種類の未知語タイプを定義し，それぞれのタイプにおける単語長の分布を考慮した未知語モデルを用いることで，未知語モデルの性能向上を図っている．
形態素解析のため，品詞を考慮して未知語を獲得する研究として，文献[CITE]では，コーパス中に出現する任意の部分文字列[MATH]に注目し，[MATH]の前後の文字から，[MATH]が未知語として出現する可能性の高い品詞に属する確率を推定している．
その後，出現頻度が一定値以上かつ2文字以上の文字列[MATH]を単語として抽出しておき，形態素解析器にかけた結果に辞書未登録語が含まれている文字列[MATH]を未知語として獲得している．
日本語は分かち書きを行わない言語であるため，自動単語分割器や形態素解析器において必須となる未知語の情報は正しい単語単位である．
このため，形態素解析器のための未知語獲得を行う研究では未知語の読みには言及しないことが多い．
しかしながら，本研究では統計的仮名漢字変換の精度向上を目的としているため，未知語の表記ならびにその読みに関する情報を同時に獲得することが望ましい．
文献[CITE]では，仮名漢字変換を用いる際の入力とその変換結果から未知語の獲得と言語モデルの更新を行う手法を提案している．
また，言語モデルの更新を繰り返すことで，仮名漢字変換システムの精度が徐々に向上すると報告している．
ただし，ここで行われている実験はユーザによるシステムの利用を想定したシミュレーションであり，本論文で扱う自動獲得とは性質が異なる．
音声認識の分野においては，未知語を原因とする認識誤りの影響を抑制するため，単語より小さい単位の語彙であるサブワードを擬似的な単語とし，未知語をサブワードの連続として認識する手法が提案されている[CITE] [CITE] [CITE]．
しかしながら，日本語の音声認識においてサブワードは基本的に仮名文字列から構成されるため，サブワードをそのまま未知語獲得に用いても仮名漢字変換への寄与は低いと考えられる．
文献[CITE]では，規則を用いてテキストから未知語の候補を抽出，音声認識を用いて読みを自動的に獲得し，発音辞書に追加する手法が提案されている．
この手法は，テキストと音声から未知語と読みの情報を獲得する点で本研究と共通しているが，未知語候補の抽出方法と獲得する情報の粒度が本研究と異なる．
本研究では，疑似確率的単語分割コーパスを用いることにより，一貫した単語単位で言語モデルと発音辞書を作成する．
また，音声認識結果から未知語の読みだけではなく文脈情報を獲得し，統計的仮名漢字変換で利用する確率的言語モデル全体の性能向上を図っている．
