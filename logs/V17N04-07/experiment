評価
\label{sect:eval}

本節では，\ref{sect3_Ext}節で述べた提案手法の評価実験について述べる．
まず，\ref{subsect:ext_unk}項〜\ref{subsect:ASR}項で
述べた手法に従って，未知語の読み・文脈情報を単語とその読みの組の列として獲得した．
その後，\ref{subsect:mkmodel}項で示した学習コーパスから
統計的仮名漢字変換の言語モデルならびに仮名漢字モデルを構築して精度評価を行い，
提案手法の有効性を検証した．


\subsection{実験で利用するテキストと音声}
\label{subsect:text_pre}

本項では，実験を行う際にあらかじめ準備するデータ，ならびに実験の過程で利用する
データについて述べる．


\subsubsection{テキスト}

本実験において利用するテキストコーパスを以下に示す．

一般分野のコーパス$C_b$には
現代日本語書き言葉均衡コーパス
(Balanced Corpus of Contemporary Written Japanese; BCCWJ)
\cite{『現代日本語書き言葉均衡コーパス』形態論情報規程集}
を用いた
．BCCWJはあらかじめ単語分割がされており，各単語に読みが付与されている\footnote{
本研究では，人手による修正が入ったコアデータのみを使用し，さらに
活用語を語幹と語尾に分割する等の変更を加えている．}．
ここで，BCCWJの内部に出現する全ての単語が既知語となる．

対象分野のテキストとして，2007年11月2日から2008年1月8日のうち68日間の
ウェブニュースを自動収集したものを用いた．
このウェブニューステキストには情報が付与されていないため，
このテキストに対して\ref{subsect:mkmodel}項で示した手法を
適用することで，単語分割と読みの付与を自動的に行い，コーパス$C_n$を作成した．
また，ウェブニュースのテキストは\ref{subsect:ext_unk}項で述べた疑似確率的単語分割コー
パスの作成に用いた．

後述する\ref{subsect:ex_ext}項の実験により，音声認識結果$C_r$として単語
と読みの組の列が獲得される．$C_r$は，$C_n$と同様に仮名漢字変換のためのモデル構築に用い
た．

テストセット$C_t$として，2008年1月9日，
2008年1月10日の2日間のウェブニュースを単語分割し，読みを付与したものを用いた．

\begin{table}[b]
  \caption{コーパスの一覧}
\input{08table01.txt}
  \label{table_corpus_suff}
\end{table}

以上に述べたテキストコーパスの文数，単語数，文字数を表\ref{table_corpus_suff}に示す．
なお，表\ref{table_corpus_suff}において，対象分野のテキストに対する自動読み推定結果，
ならびに音声認識結果の単語数は，各システムの出力結果から単語数を計数したものである．
また，音声認識結果の出力から文境界を同定することは困難であるため，単語数と文字数のみを
示す．

表\ref{table_unkr_test}に，
テストセットにおける未知の1-gram率（未知語率），未知の2-gram率を，単語を単位とする場合
と単語と読みの組を単位とする場合のそれぞれについて示す．

\begin{table}[t]
  \caption{テストセット$C_t$の未知$n$-gram率(\%)}
\input{08table02.txt}
  \label{table_unkr_test}
\end{table}



\subsubsection{音声}

読みを選択するために用いる音声として，収集したウェブニュース記事と同時期に当たる
2007年12月5日から2008年1月8日の間に放送された30分のニュース番組の
合計17時間の音声を用いた．
ここで，対象分野のテキストと音声の類似度として，音声の一部
の書き起こし（2008年1月7日，8日の2日分）に対するパープレキシティを示す．
後述する対象分野の疑似確率的単語分割コーパスから単語3-gramモデルを構築し
，書き起こしに対するパープレキシティを求めたところ，58.5となった．
これは，本実験で用いる疑似確率的単語分割コーパスから構築される音声認識用言語モデルは
認識対象となる音声に対して十分な単語予測性能を持っている（対象分野の音声と対象分野のテ
キストが十分に似ている）ことを示している．


\subsection{未知語とその読み・文脈情報の自動獲得}
\label{subsect:ex_ext}

本項では，
対象分野のテキストと対象分野の音声を用いた
未知語とその読み・文脈情報の自動獲得について述べる．
また，処理の途中段階で獲得した未知語とテストセット中の未知語を比較し，
各処理における未知語の検出精度を示す．


\subsubsection{未知語候補の抽出}

まず，
\ref{subsect:ext_unk}項で述べた手法に従って
対象分野のテキストから疑似確率的単語分割コーパスを作成し，
未知語候補の抽出を行った．
ここで，疑似確率的単語分割コーパスの倍率は$M=10$とした．
また，未知語候補を決定する際の閾値は，$F_{th} = 50$とした．

また，対象分野のテキストの規模と最終的に獲得可能な未知語の数との関係として，
表\ref{table_cov_cond}に，未知語候補のテストセット$C_t$中の未知語に対する再現率を
示す．表\ref{table_cov_cond}では，
利用するウェブニュースの日数と疑似確率的単語分割コーパスの倍率$M$
を変えることでテキストの規模を調節し，それぞれについて再現率を示した．
また，確率的単語分割コーパスを作成せず，決定的に単語分割を行った場合の再現率についても，
併せて表\ref{table_cov_cond}に示した．
$C_t$内の未知語の集合を$UW_t$，疑似確率的単語分割コーパス内の未知語候補の
集合を$UW_c$とし，コーパス$C$における単語$w$の出現頻度を$f(C,w)$とすると，
再現率は
\[
\cfrac{\displaystyle\sum_{w \in UW_t \cap UW_c} f(C_t, w)}{\displaystyle\sum_{w \in UW_t } f(C_t, w)}
\]
で表される．ここで，$\sum_{w \in UW_t } f(C_t, w) = 2,772$である（表
\ref{table_unkr_test}参照）．

\begin{table}[t]
  \caption{対象分野のテキストから抽出した未知語候補の再現率(\%)}
\input{08table03.txt}
  \label{table_cov_cond}
\end{table}

表\ref{table_cov_cond}から，未知語の抽出を行う場合には，決定的な単語分
割を行ったコーパスではなく，疑似確率的単語分割コーパスを利用することが有効であることが
わかる．



\subsubsection{未知語候補を含む言語モデルと発音辞書の作成}

\ref{subsect:ucest}項で述べた手法を用いて音声認識用の言語モデルと発音辞書を作
成した．
本実験で用いる音声認識システムJuliusは言語モデルとして順向き2-gramモデル，逆向き3-gram
モデルを必要とする．
ここでは，一般分野の単語分割コーパス(BCCWJ)と対象分野の疑似確率的単語分割コーパス
（ウェブニュース）から
単語表記を単位とする順向き2-gramモデルならびに逆向き3-gramモデルを構築した．

次に，抽出した未知語候補の読みを，文字と読みの組を単位とする2-gramモデルによって推定し，
生成確率の上位$L$個の単語と読みの組を既知語から作成される発音辞書に追加した．
本実験では$L=5$とした．


作成した発音辞書の詳細を表\ref{table_pron-dict}に示す\footnote{
片仮名のように文字ごとの読み候補が少ない場合，
もしくは単語長が短い場合など，5個まで読みの列挙を行うことができない未知語候補が存
在する．
このため，未知語候補のエントリ数は単語数の5倍未満になることがあり得る．}．
言語モデルにおける語彙の総数は表\ref{table_pron-dict}における既知語と
未知語候補の単語数を合計した数である20,712，
発音辞書のエントリ（単語と読みの組）の総数は26,880となった．

ここで，$L$の値の妥当性を検証するため，
$L$を変えた場合に得られる未知語候補と読みの組の，テスト
セット$C_t$内の未知語と読みの組に対する再現率を表\ref{table_cov_prondict}に示す．
コーパス$C$における単語と読みの組$u$の出現頻度を$f(C,u)$，
未知語候補と推定された読みの組の集合を$UU_e$，
テストセット$C_t$内の未知語と読みの組の集合を$UU_t$とすると，再現率は
\[
 \cfrac{\displaystyle{\sum_{u \in UU_t \cap UU_e} f(C_t, u)}}{\displaystyle{\sum_{u \in UU_t } f(C_t, u)}}
\]
で表される．ここで，$\sum_{u \in UU_t } f(C_t, u) = 2,925$である（表
\ref{table_unkr_test}参照）．
表\ref{table_cov_prondict}より，$L \geq 5$では再現率に大きな変化が見られないことか
ら，$L$の値を単純に大きくしても最終的に獲得可能な未知語と読みの組の量は変わらないことが
予想される．
また，$L$を大きくするに従って，誤った読みを持つエントリがより多く発音辞書に登録され，
認識誤りが増加する．本実験では以上の2点を考慮し，$L=5$とした．

\begin{table}[t]
  \caption{音声認識用の発音辞書}
\input{08table04.txt}
 \label{table_pron-dict}
\end{table}
\begin{table}[t]
  \caption{発音辞書に列挙された未知語候補と読みの組の再現率(\%)}
\input{08table05.txt}
  \label{table_cov_prondict}
\end{table}



\subsubsection{未知語の読み・文脈情報の獲得}

作成した言語モデルと発音辞書を利用し，
音声認識によって読みを選択し，音声認識結果から
未知語を含む単語と読みの組の列を獲得した．
音声認識システムには，Julius 3.5.3を用いた．
なお，Juliusの動作に必要となる音響モデルは，連続音声認識コンソーシアム2003年度版ソフト
ウェア\footnote{http://www.lang.astem.or.jp/CSRC/}
に同梱されている，
新聞記事読み上げ音声コーパス (JNAS) から学
習された3,000状態，64混合のPTM triphoneモデル
\cite{Phonetic.Tied-Mixture.モデルを用いた大語彙連続音声認識}
を用いた．


音声認識結果のうち，単語信頼度が$CM_{th}$を超えている単語のみ
を抽出し，単語と読みの組の列を単語境界と読みの付与されたコーパス($C_r$)の形で獲得した．
この際，単語信頼度の閾値は$CM_{th} = 0.1$とした．
また，獲得頻度の少ない未知語候補には音声認識誤りと考えられるものが多かったため，
上記の閾値による制限に加えて2回以上認識した未知語候補のみを獲得した\footnote{
アナウンサーの発話のように，音声が明瞭である部分の認識精度は80\%程度，記
者発表のように，背景に雑音が多く含まれる部分の認識精度は30\%程度であった．}．

$C_r$の単語数ならびに文字数は表\ref{table_corpus_suff}で示した通りである．
また，表\ref{table_unkr_rec}に音声認識結果$C_r$の未知語率を示す．ここでは，
テストセット$C_t$の未知語率（表\ref{table_unkr_test}参照）と同様に，
単語ならびに単語と読みの組を単位とした場合の未知$n$-gram率を示す．
なお，最終的に獲得された未知語候補と読みの組（異なり数）は872となった．


最後に，対象分野の音声の規模と獲得した未知語と読みの組の数との関係を調べるため，
使用するニュースの日数を変更した場合の$C_t$に対する再現率を表\ref{table_cov_rec}に示す．
$C_r$内の未知語と読みの組の集合を$UU_{r}$とすると，再現率は
\[
\cfrac{\displaystyle{\sum_{u \in UU_t \cap UU_{r}} f(C_t, u)}}
 {\displaystyle{\sum_{u \in UU_t } f(C_t, u)}}
\]
で表される．

\begin{table}[t]
  \caption{音声認識結果$C_r$の未知$n$-gram率(\%)}
\input{08table06.txt}
  \label{table_unkr_rec}
\end{table}
\begin{table}[t]
  \caption{音声認識結果内の未知語候補と読みの組の再現率(\%)}
\input{08table07.txt}
  \label{table_cov_rec}
\end{table}


\subsubsection{獲得した未知語と読み・文脈情報の再現率と適合率}

本実験の目的は，後述する仮名漢字変換の精度評価において，音声認識結果$C_r$から獲得した
未知語とその読み・文脈情報を利用してテストセット$C_t$を対象とした仮名漢字変換の変換精
度を向上させることにある．
$C_r$を用いて仮名漢字変換のモデルを構築する場合，$C_t$と
$C_r$に共通して出現する未知語と読みの組，または単語を単位とする未知の2-gram
が多いほど
仮名漢字変換の精度が向上する\footnote{前者は\ref{subsect:KKC}項で述べた
仮名漢字モデルの性能に影響し，後者は言語モデルの性能に影響する．}．
以下では，それぞれの再現率ならびに適合率を示す．


まず，$C_r$から獲得した未知語と読みの組の再現率，適合率を示す．
再現率
ならびに適合率はそれぞれ
\[
再現率   = \cfrac{\displaystyle{\sum_{u \in UU_t \cap UU_{r}} f(C_t, u)}}
 {\displaystyle{\sum_{u \in UU_t } f(C_t, u)}} \quad , \qquad
適合率 = \cfrac{\displaystyle{\sum_{u \in UU_t \cap UU_{r}} f(C_r, u)}}
 {\displaystyle{\sum_{u \in UU_t } f(C_r, u)}}
\]
で表される．計算の結果，再現率は31.6\%，適合率は38.2\%となった．

次に，未知の2-gramの再現率，適合率を示す．
コーパス$C$における単語2-gram ($w_{i-1}^i$) の出現頻度を$f(C,w_{i-1}^i)$，
テストセット$C_t$内の未知の単語2-gramの集合を$UB_t$，
音声認識結果$C_r$内の未知の単語2-gramの集合を$UB_r$とすると，再現率ならびに適合率は
\[
再現率  = \cfrac{\displaystyle{\sum_{w_{i-1}^i \in UB_t \cap UB_{r}} f(C_t, w_{i-1}^i)}}
 {\displaystyle{\sum_{w_{i-1}^i \in UB_t } f(C_t, w_{i-1}^i)}} \quad , \qquad
適合率 = \cfrac{\displaystyle{\sum_{w_{i-1}^i \in UB_t \cap UB_{r}} f(C_r, w_{i-1}^i)}}
 {\displaystyle{\sum_{w_{i-1}^i \in UB_t } f(C_r, w_{i-1}^i)}}
\]
で表される．計算の結果，再現率は31.9\%，適合率は25.5\%となった．



\subsection{統計的仮名漢字変換による精度評価}
\label{subsect:eval_KKC}

本項では，\ref{subsect:mkmodel}項で挙げた学習コーパスを用いて
統計的仮名漢字変換の精度評価を行い，提案手法の有効性を検証する．


\subsubsection{実験の条件}

本実験では，一般分野のコーパス$C_b$，対象分野のテキストの自動読み推定結果$C_n$，
音声認識結果$C_r$を用いて統計的仮名漢字変換のためのモデルを構築した．
各コーパスの規模は\ref{subsect:text_pre}の表\ref{table_corpus_suff}に示した通りである．

本実験では，3種類のコーパスを以下のように組み合わせて学習コーパスとし，言語モデル
（単語2-gramモデル）ならびに仮名漢字モデルを構築した．
\begin{enumerate}
 \item $C_b$: ベースライン
 \item $C_b + C_n$: テキストのみを用いた手法（既存手法）
 \item $C_b + C_n + C_r$: テキストと音声に共通して現れる
       未知語の読み・単語文脈を反映させる手法（提案手法）
\end{enumerate}
統計的仮名漢字変換システム全体の精度を評価する基
準として，文字単位の再現率と適合率を計算し，(1)--(3)について比較を行った．
\pagebreak
また，提案手法において未知語の読みと単語文脈を共に利用することの有効性を
検証するため
，(2)を基準として，$C_r$から言語モデル(LM)のみを更新した場合\footnote{
$C_b+C_n+C_r$から言語モデルを構築し，$C_b+C_n$から仮名漢字モデルを構築する．}と，
仮名漢字モデル(PM)のみを更新した場合\footnote{
	$C_b+C_n$から言語モデルを構築し，$C_b+C_n+C_r$から仮名漢字モデルを構築する．}についても変換精度の評価を行った．



本実験における評価指標として，文字単位の再現率と適合率を用いる．
それぞれの定義を以下に示す．
\begin{align*}
 \mbox{再現率} &= \cfrac{\mbox{正解文字数}}
                        {\mbox{テストセット中の文字数}}\\
 \mbox{適合率} &= \cfrac{\mbox{正解文字数}}
                        {\mbox{システムの出力した文字数}}\\
\end{align*}



\subsubsection{実験結果と考察}

(1)--(3)で示した学習コーパスから構築されるモデルによる
再現率，適合率を
表\ref{table_result}に示す．

\begin{table}[b]
  \caption{統計的仮名漢字変換による評価(\%)}
\input{08table08.txt}
  \label{table_result}
\end{table}

$C_b$を用いる場合（ベースライン）
の変換精度と$C_b, C_n$を用いる場合（既存手法）の変換精度を比較した結果
，再現率で8.94\%，適合率で11.68\%の精度向上が確認された．
ここで$C_n$と$C_t$は同分野のコーパスであり，
$C_b$は$C_n$に比較すると小規模なコーパスであるため，
この精度向上は単純に学習データの量を増やしたことに起因すると考えられる．

次に，$C_b, C_n$を用いる場合（既存手法）の変換精度と
$C_b, C_n, C_r$を用いる場合（提案手法）の変換精度
を比較した結果，仮名漢字変換の精度は再現率で0.36\%，適合率で0.48\%の改善
が見られた．既存手法において，
コーパス$C_n$は対象分野の未知語を考慮しない手法で読みを付与されているため，
未知語の正しい分割と読みの付与が行われず，$C_b$と$C_n$のみを用いて構築されるモデルでは
未知語の誤変換が発生する．
しかし，提案手法では\ref{subsect:ex_ext}項の実験で得られた$C_rを用いて$
未知語の読み・文脈情報をモデルに反映させることが可能である．
上記の精度増加は，
\ref{subsect:ex_ext}項で示した未知語の読み・文脈情報の獲得の実験で獲得した未知語と読みの
組，未知の2-gramの量に対応しており，より多くの未知語を獲得する
ほど変換精度が向上すると考えられる．

また，$C_r$を追加することによる精度向上の要因を明らかにするため，
$C_b$と$C_n$から構築したモデルによる変換精度
を基準に，$C_r$を利用して言語モデルと仮名漢字モデルを独立
に更新して精度を比較した．
言語モデルのみを更新した場合は，再現率，適合率ともに0.03\%の改善となり，
仮名漢字モデルのみを更新した場合は，再現率で0.17\%，適合率で0.27\%の改善となった．

言語モデルのみを更新する場合，
未知語と読み（仮名漢字変換における入力記号列）との対応付けを行うことが不可能であるため，
未知語周辺の文脈が変換精度の向上にほとんど寄与しない．
この際，
変換精度の向上に寄与する要素は$C_r$に現れる既知語周辺の文脈情報のみであり，かつ
$C_n$に比較して$C_r$の規模は非常に小さいために，精度がほぼ変化していないと考えられる．

仮名漢字モデルのみを更新する場合については，一定の精度向上が観察された．
しかしながら，
ある読みを持つ未知語に対し，同じ読みを持つ既知語，もしくは結合の結果同じ読みとなる既知
語の連続が存在するという状況では，
未知語を含む変換候補の言語モデル確率は既知語を含む変換候補の確率に比較して
小さくなる．
言語モデルと仮名漢字モデルの両方を更新する場合（提案手法）との精度の差は，
上述の言語モデル確率の差に起因する．

最後に，提案手法を用いることで未知語の変換誤りが改善した例を示す．
       \vspace{10pt}
       \begin{center}
	\begin{tabular}{|rl|}\hline
	 $C_b+C_n$: &前 事務 次官 の 森 や タケマサ\\
	 $C_b+C_n+C_r$: &前 事務 次官 の 守屋 武昌\\
	 \hline
	\end{tabular}
       \end{center}
       \vspace{10pt}
\ref{subsect:ext_unk}〜\ref{subsect:ASR}項において例として示した未知語（守屋）は，
本実験において実際に獲得された未知語の例であり，
音声認識結果$C_r$を用いることによって未知語の誤変換が改善されることを確認した．


以上の結果より，
テキストと音声から獲得される
未知語の読み・文脈情報は
統計的仮名漢字変換システムの精度向上に有効であることが確認された．




