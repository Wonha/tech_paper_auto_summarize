解析対象
\label{sec:target}

本章では，まず，解析対象である絵本データベースの紹介を行う（\ref{sec:ehon-db}節）．
次に，新聞などの一般向けテキストと絵本のテキストを比較し，違いを調査する（\ref{sec:mojisyu}節）．
また，評価，実験用に形態素情報を付与した絵本のラベルありデータ（フルアノテーションデータ）を紹介する（\ref{sec:full-ano}節）．


\subsection{絵本データベース}
\label{sec:ehon-db}

本稿では構築中の絵本データベースを解析対象とする
\cite{Taira:Fujita:Kobayashi:2012j}．絵本データベースは，発達心理学におけ
る研究や，子供の興味や発達に応じた絵本リコメンデーションを目的として構築
されている．


含まれる絵本は，2010年度の紀伊国屋書店グルー
プの売上冊数が上位のファーストブック（以下，\first{}）と絵本（以下，\ehon）\footnote{
	絵本とファーストブックの分類は紀伊国屋書店による．絵本には，大人向けと見られる絵本も一部含まれていた．}
計 1,010冊，および，福音館書店の月刊誌（以下，\kodomo）190冊，合計 1,200冊である\footnote{含まれる絵本のリストは http://www.kecl.ntt.co.jp/icl/lirg/members/sanae/ehon-list.html で閲覧可能である．}．
これらの選定理由は，
前者は多くの子供に読まれていると考えられること，
後者は対象年齢が比較的はっきりしていることである．
後者の対象年齢は0・1・2歳向け（以下，\kod{012}），年少（3歳児）向け（以下，\kod{3}），年中（4歳児）向け（以下，\kod{4}），
年長（5歳児）向け（以下，\kod{5}）とわかれている．
本稿では，これらをまとめて絵本と呼ぶこととする．
なお，\kodomo 以外で対象年齢が記載されていた絵本は，463冊 (45.8\%) にとどまり，
その記載方法も「3歳から小学校初級むき」「乳児から」「4才から」のように多様で，
\kodomo のように 1 歳単位で対象年齢が設定されている絵本は少ない．

\begin{table}[b]
 \caption{絵本データベースのサイズ}\label{tb:size}
\input{1008table02.txt}
\end{table}

本稿では，絵本の本文のテキストを解析対象とする．
本文のテキストは人手で入力されている\footnote{当初，既存OCRによる自動的
な文字認識を試したが，絵と文字の判別が難しく，高精度な自動認識は困難
だった．}．
また文や文節の途中での改行など元のページのレイアウトも
忠実に再現されている
（例\refs{ex-org}）．
なお，絵本データベースの 1,200冊のサイズは
表~\ref{tb:size}の通りである．
\begin{exe}
 \ex \label{s:ex-org}
もう　いつ　はるが　きて、なつが　きたのか、いつが\\
あきで、いつが　ふゆなのか、わかりません。\\
\small （バージニア・リー・バートン，石井桃子・訳「ちいさいおうち」p.~24（1954，岩波書店））
\end{exe}


\subsection{絵本と他のコーパスの比較}
\label{sec:mojisyu}

絵本のテキストの特徴を調べるため，絵本と一般的なコーパスにおける
文字種の割合を比較する．
表~\ref{tb:mojisyu}に，
絵本 1,200冊（表 \ref{tb:size}）における
文字種と，
現代日本語書き言葉均衡コーパス\footnote{http://www.ninjal.ac.jp/kotonoha/}（以下，\bccwj），
京都大学テキストコーパス\footnote{http://nlp.ist.i.kyoto-u.ac.jp/index.php}（以下，京大コーパス）
，および，基本語データベース\cite{Lexeed:2004j} （以下，\lxd）
の定義文，例文に出現する文字種の数と割合を示す．

\begin{table}[t]
\caption{文字種毎の数と割合：絵本と他のコーパスの比較}
\label{tb:mojisyu}
\input{1008table03.txt}
\end{table}

表 \ref{tb:mojisyu}から，他のコーパスに比べ，
絵本の場合，ひらがなと空白が占める割合が圧倒的に高いことがわかる．
また逆に，漢字が占める割合は非常に低い．
表~\ref{tb:mojisyu}には，参考として，
一文に含まれる平均文字数，および，平均形態素数も記載した．但し，絵本の場合は，一行に含まれる平均文字
数を記載しており，必ずしも文単位ではない．また，平均形態素数について，絵本は未知であり，
\bccwj は品詞体系が異なるため記載していない．


\subsection{絵本のフルアノテーションデータ}
\label{sec:full-ano}

精度評価
のために，絵本の一部に正解の形態素区切り，IPA品詞，読み，できるだけ漢字表記にした原形を
付与したフルアノテーションデータ（ラベルありデータ）を作成した．
ただし，活用型と活用形は付与していない．
付与自体が難しいことと，
作業量が増えるためにコストと時間がかかること，
これらの情報を今後利用する予定がないことが理由である．

絵本に出現した文\refs{eva-org}に対するフルアノテーションデータを
\refs{ehon-full}に示す．
ただし\refs{ehon-full}では，形態素区切りは\jpn[,]{}で示し，
形態素は\jpn[出現形/品詞/読み/原形]{}の形で示し，
漢字表記にした原形には\ul{下線}を引いた（以降の例でも同様）．

\begin{exe}
 \ex \label{s:eva-org}
めには、いちごの　あかい　みを　いれました。\\
\small （舟崎靖子「もりのおかしやさん」p.~11（1979，偕成社））
\end{exe} 

\begin{exe}
 \ex \label{s:ehon-full}
め/名詞-一般/メ/\ul{目},
に/助詞-格助詞-一般/ニ/に,
は/助詞-係助詞/ハ/は,
、/記号-読点/、/、,
いちご/名詞-一般/イチゴ/\ul{苺},
の/助詞-連体化/ノ/の,
　/記号-空白/　/　,
あかい/形容詞-自立/アカイ/\ul{赤い},
　/記号-空白/　/　,
み/名詞-一般/ミ/\ul{実},
を/助詞-格助詞-一般/ヲ/を,
　/記号-空白/　/　,
いれ/動詞-自立/イレ/\ul{入れる},
まし/助動詞/マシ/ます,
た/助動詞/タ/た,
。/記号-句点/。/。
 \end{exe}

アノテーションは，言語学者や研究者ではない一般の作業者によって行ったが，
特に活用語に対するアノテーションは難しく，既存のラベルありデータを参照しながら作業を行った．
また，作業者による不一致や判断のゆれをなくすため，一定の作業の後には
同じ出現形の形態素に異なる品詞や原形が振られたもの\footnote{例えば，\jpn[ごしごし]{}を\pos{名詞-サ変接続}にするか，\pos{副詞-一般}にするか，といった判断のゆれが多かった．}をリストアップし，
統一的に確認，修正を行う作業を繰り返した．
なお，実際の作業では，アノテーションしたデータを順次学習データに追加することで，
解析精度自体を高めながら作業を進めた（\ref{sec:exp-add-ehon}章参照）．


フルアノテーションを行う
対象データは 2 通りの方法で選んだ．まず，
対象年齢がはっきりしている\kodomo\ 190 冊を対象とした．
また，それ以外の\first, \ehon の中から，絵本をランダムに選び，さらにラン
ダムに 1 ページずつ選んで対象とした（以下，\random）．サイズは表~\ref{tb:test-size}の通りである．
フルアノテーションデータは，\ref{sec:exp-adult}章の
教師なし分野適応実験の評価用データとして利用するほか，
\ref{sec:exp-add-ehon}章の
教師あり分野適応実験の学習，評価用データとして利用する．

\begin{table}[t]
\caption{絵本のフルアノテーションデータのサイズ}
\label{tb:test-size}
\input{1008table04.txt}
\end{table}


形態素解析器
\label{sec:morph-kytea}

本稿では，既存の辞書やラベルありデータを，対象分野である絵本の特徴にあ
わせて自動的に変換する手法を提案する．学習器は学習データと独立に選ぶこ
とができるが，本稿では，京都テキスト解析ツールキッ
ト\kytea\ \cite{Mori:Nakata:Graham:Kawahara:2011j} の学習機能を利用する．

\kytea では，点予測を採用しており，分類器の素性として，周囲の単語境界や品詞等の推定値を利用せ
ずに，周囲の文字列の情報のみを利用する．
そのため，柔軟に言語資源を利用することができ，分野適応が容易だという
特徴がある\cite{Mori:Nakata:Graham:Kawahara:2011j}．


\kytea のモデル学習時には，フルアノテーションデータ，部分アノテーショ
ンデータ，辞書などの言語資源が利用できる．これらの言語資源は，それぞれ
複数利用することができる．また，辞書と部分アノテーションデータはなくて
もよい．

ここで，フルアノテーションデー
タとは，文全体に形態素情報が付与されたデータである（\ref{sec:full-ano}節，
例\refs{ehon-full}）．また，部分アノテーションデータとは，文の一部に
だけ単語境界や形態素情報が付与されたデータである．
例えば，例\refs{ehon-part}のように，文\refs{eva-org}の\jpn[め]{}と
\jpn[み]{}にだけ形態素情報をアノテーションしたデータを，部分アノ
テーションデータとして利用することができる．
誤りやすい語や分野特有の語にだけ集中的にアノテーションを付与して利用
できるため，能動学習や分野適応に有効である．
 \begin{exe}
 \ex \label{s:ehon-part}
め/名詞-一般/メ/\ul{目},に は 、 い ち ご の 　 あ か い 　,み/名詞-一般/ミ/\ul{実},を 　 い れ ま し た 。
 \end{exe}

なお，\kytea の配布版モデルでは，単語分割とUniDicの品詞大分類，読みの付与を行っているが，
他の種類の品詞や情報を推定するモデルの構築も可能である．
本稿では，既存言語資源との整合性を考慮し，品詞はIPA品詞体系に準拠した．
さらに，元の漢字表記の推定も同時に行う．つまり，
単語分割，IPA品詞体系の品詞，読み，漢字表記による原形推定を出力とするモデルを構築する．

本稿では，フルアノテーションデータとして，
コーパス\hinoki\ \cite{Bond:Fujita:Tanaka:2006}を用いる．\hinoki に
は，\lxd の定義文，例文，京大コーパスの全文\footnote{但し，IPA品詞体系で解析
しなおしてある．}が含まれている．さらに教師あり分野適応
の実験（\ref{sec:exp-add-ehon}章）では，絵本のフルアノテーションデータも利用する．

辞書には，
\naistj \footnote{http://sourceforge.jp/projects/naist-jdic/} （以下，
\ntj），\lxd，および，日本語語彙大系\cite{GoiTaikeij}の固有名詞，および，動植物名\footnote{
具体的には，日本語語彙大系の日本語辞書のうち，\izj{543:生物}配
下の意味クラスが付与されている語を追加した．}を利用する．但し，\lxd と日
本語語彙大系は，本来IPA品詞体系ではないため，自動的に品詞を変換した．


絵本を対象とした形態素解析における問題分析
\label{sec:bunseki}

本章では，絵本を形態素解析するときに起こる精度低下の原因を調査する．

\ref{sec:mojisyu}節では，一般的なテキストと比べて，絵本のテキストでは，
空白，ひらがなが圧倒的に多く，漢字が非常に少ないことを示した．これらの
違いのうち，直感的には，ひらがなによる曖昧性の増加が精度低下の主要因で
あり，空白は解析の手がかりとなるように感じられる．しかしこれまで，この
直感が正しいかどうか，また，実際にどの程度精度への影響があるのかを調査
した研究はない．そこで本章では，ひらがなと空白の形態素解析への影響を調
査する．


\subsection{実験用解析対象文の作成}
\label{sec:bunseki-bun}

調査用の評価データとして，絵本の\kodomo の
フルアノテーションデータをいくつかのルールに沿って自動的に変換したデータを作成する．
つまり，
絵本に出現した文\refs{eva-org} （\ref{sec:full-ano}節）
から空白を削除したもの（文\refs{eva-del}），
空白を読点に変換したもの（文\refs{eva-punc}），
ひらがなをできるだけ漢字に変換したもの（文\refs{eva-han}），
漢字に変換し，かつ，空白を削除したもの（文\refs{eva-handel}），
漢字に変換し，かつ，空白を読点に変換したもの（文\refs{eva-hanpunc}）
を作成した．

 \begin{exe}
 \ex \label{s:eva-del}
めには、いちごのあかいみをいれました。
 \ex \label{s:eva-punc}
めには、いちごの、あかい、みを、いれました。
 \ex \label{s:eva-han}
目には、苺の　赤い　実を　入れました。
  \ex \label{s:eva-handel}
目には、苺の赤い実を入れました。
  \ex \label{s:eva-hanpunc}
目には、苺の、赤い、実を、入れました。
\end{exe} 


\subsection{実験と結果}
\label{sec:bunseki-exp}

調査のため，
\hinoki コーパスと\naistj などの辞書（\ref{sec:morph-kytea}章）をそのま
ま学習に利用したモデル（以下，\kytea（\Def））を構築する．これは，一般的
な形態素解析モデルと同じような学習条件に相当する．
また，表~\ref{tb:morph-ex} （\ref{sec:introduction}章）で利用した
既存の形態素解析モデルの中で最も誤りの少なかった \mecab も利用する．

\begin{table}[b]
\caption{評価結果: 形態素区切り，および，品詞が一致した数と割合 (\kodomo)}
\label{tb:res-bunseki}
\input{1008table05.txt}
\par\vspace{4pt}
\small
ただし，\refs{eva-org}から\refs{eva-handel}は，対応する評価用データの例の番号を示している．
\par
\end{table}

表~\ref{tb:res-bunseki}に，評価用データ（文\refs{eva-org}，および，
文\refs{eva-del}から文\refs{eva-hanpunc}）のそれぞれに対し，形態素解析を
実行し，形態素区切りと品詞一致精度を調べた結果を示す．



\subsection{分析}
\label{sec:ana-sphan}


表~\ref{tb:res-bunseki}の\pos{\Org \refs{eva-org}}の列が，
絵本のテキストをそのまま解析した場合の精度であり，
\kytea（\Def）では 63.0\%，\mecab では 83.2\%だった．
\mecab は
ひらがなのままの評価データの場合でも，ひらがなを考慮しない一般的な学習条件で学習し
た\kytea（\Def）よりも精度が高い．しかし，
新聞である京大コーパスを対象とした場合
98\% 以上の精度が報告されているのに比べると\footnote{\mecab\ ver.0.90 の場合．http://mecab.googlecode.com/svn/trunk/mecab/doc/feature.htmlより．}，
はるかに低い精度である．

ここで，空白の影響を分析する．\kytea（\Def）では，空白を削除す
ると精度が向上する．また，空白を読点に変更すると精度はさらに向上する．
これは，学習データに空白が出現しないため，学習できていないためだと考えられる．
空白をただ削除するよりも，読点に変更した方が精度が高くなることから，
空白の働きをうまく学習することができれば，区切りの判別の手がかりとして有効に働く
だろうことが予想できる．

実際，\mecab の場合，空白は区切りの判別のための手がかりと
して有効に利用されているようであり，空白を削除するとむしろ精度は低下す
る．また，空白を読点に変更した場合と空白のままの場合の精度は同程度で
あり，空白が読点の代わりを果たしていることが伺える．


特に，\refs{err-del}のように，擬音語や擬態語が連なる場合，
空白を削除すると，解析が非常に困難になっており，
空白の有無が形態素の判別に有効な手がかりであることがわかる．
 \begin{exe} 
 \ex \label{s:err-del}
  「こちょ　こちょ　こちょ　こちょ \\
 {\small （豊田一彦 「こちょこちょももんちゃん」p.~24（2010，童心社））}\\
  COR:「,\ul{こちょ,　,こちょ,　,こちょ,　,こちょ}\\
  RES:「,\ul{こ,ちょこ,ちょこちょこ,ちょ}\\
 \small （ただし，COR: は正解，RES: は空白を削除した場合の結果）
 \end{exe} 

次に，ひらがなが多いことによる影響を分析する．
評価データ中のひらがなを漢字に変換した場合，
\kytea（\Def）でも\mecab でも，ひらがなのままの評価データより高い精度
が得られる．空白を読点に変換した場合の精度
（表~\ref{tb:res-bunseki}の
\pos{\Sp\ \refs{eva-punc}}と
\pos{\HanSp\ \refs{eva-hanpunc}}）で
比較すると，
\kytea（\Def）では $+11.4$\%，\mecab では $+8.2$\% 精度が向上しており，
漢字は大きな手がかりとなっていることがわかる．
つまり，一般的なテキストとの大きな違いのうち，
ひらがなによる曖昧性の増大が解析精度の低下の主な要因だといえる．


なお，元データのままだと解析に失敗するが，漢字に変換すると正解する例には，
\refs{err-org}などがあった．
 \begin{exe}
 \ex \label{s:err-org}
  みずを　のみにきた　うしさんに \hfill
{\small （たちもとみちこ「おほしさま」p.~10（2006，教育画劇））}\\
COR: みず,を,　,のみ,に,き,た,　,うし,さん,に,\\
RES: みず,を,　,のみ,に,\ul{きた},　,\ul{うしさん},に\\
RES2: 水,を,　,飲み,に,\ul{来,た},　,\ul{牛,さん},に\\
\small （ただし，COR: は正解，RES: は結果，RES2: は漢字に変換した場合の結果）
 \end{exe} 


提案手法
\label{sec:morph}

 本章では，絵本の特徴に合わせたラベルありデータと辞書の変換方法を提案す
 る（\ref{sec:train-data}，\ref{sec:dic}節）．また，ラベルありデータと辞
 書の変換と追加の必要性について議論する（\ref{sec:comp-kudo}節）．


\subsection{ラベルありデータの変換方法}
\label{sec:train-data}


\ref{sec:bunseki}章で示したように，絵本の解析では，空白の働きを学習することと，
ひらがなが多い文でも解析できることが必要である．
そこで，既存のラベルありデータである\hinoki コーパスを 3 通りの方法で自動的に変換する．
例えば，文\refs{lxdex-org}は，\lxd での見出し語\jpn[きしめん]{}に付与さ
れた例文である．
この文に，まず，句読点の直後を除く文節毎に空白を挿入する（文\refs{lxdex-sp}）．
また，すべての漢字をひらがなの読みに変換する（文\refs{lxdex-hira}）．
句読点の直後を除く文節毎に空白を挿入し，かつ，ひらがなに変換する
（文\refs{lxdex-hirasp}）．このように，元の文に対して 3 通りの変換を行い，ラベルありデータデータを作成する．

 \begin{exe} 
 \ex \label{s:lxdex-org}
寄せ鍋,に,きしめん,を,入れる,。
 \ex \label{s:lxdex-sp}
寄せ鍋,に,　,きしめん,を,　,入れる,。
 \ex \label{s:lxdex-hira}
よせなべ,に,きしめん,を,いれる,。
 \ex \label{s:lxdex-hirasp}
よせなべ,に,　,きしめん,を,　,いれる,。
 \end{exe}

 さらに，元の漢字表記の推定も同時に行うため，元の漢字表記による原形を利
 用する．つまり，文\refs{lxdex-hira}や\refs{lxdex-hirasp}のようにひらが
 なに変換した場合でも，原形は漢字表記を利用する．そのため，例え
 ば\refs{lxdex-hira}は，実際には\refs{lxdex-hira-full}のような形で与えられる．

 \begin{exe}
 \ex \label{s:lxdex-hira-full}
よせなべ/名詞-一般/ヨセナベ/\ul{寄せ鍋},に/助詞-格助詞-一般/ニ/に,きしめん/名詞-一般/キシメン/きしめん,を/助詞-格助詞-一般/ヲ/を,いれる/動詞-自立/イレル/\ul{入れる},。/記号-句点/。/。
 \end{exe}

\ref{sec:exp-adult}章では，ラベルありデータの変換方法毎の
 効果を検証するため，これらの組み合わせを変えて利用した場合の精度評価を
 行う．

なお，空白の挿入に利用した文節区切りや，ひらがなへの変換に利用した読みは，
元々コーパスに付与されていたものであり，自動的に変換することができる．
本稿では\hinoki コーパスを利用したが，京大コーパスでも文節
情報や読みは付与されているため，同様の変換ができる．また\bccwj 
にも読みは付与されている．文節情報は付与されていないが，形態素情
報は付与されているため，助詞と自立語が連続する箇所に空白をいれるなどの
簡単なルールによって，同様の自動的変換が可能である．


\subsection{辞書の変換方法}
\label{sec:dic}

\ref{sec:morph-kytea}章で紹介した通り，辞書には
\ntj，\lxd，日本語語彙大系の固有名詞，および，動植物名を利用しており，
これらを絵本の特徴にあわせて変換する．

まず，\ntj と\lxd の漢字やカタカナのエントリ
をひらがなに変換したエントリも作成し，辞書に追加する．
固有名詞や動植物名は，カタカナで表記されることも多いため，
カタカナ，ひらがなの両方に変換したエントリも作成し，辞書に追加する．
このとき，原形には漢字やカタカナの表記を用いる．
例えば，
\jpn[伊予柑]{}の場合，元の見出し語か
ら得られる辞書エントリは\refs{iyokan-org}となるが，ひらがなのエントリ
\refs{iyokan-hira}とカタカナのエントリ\refs{iyokan-kata}も追加した．
しかし，人名の固有名詞だけは，カタカナはカタカナのまま，
ひらがなはひらがなのまま原形とした．
これは，ひらがなで出てくる人名の漢字表記が何かは決められないためである．
最終的に利用した辞書サイズは，表~\ref{tb:dic-size}の通りで
ある．

\begin{exe}
  \ex \label{s:iyokan-org}
  伊予柑/名詞-一般/イヨカン/伊予柑
  \ex \label{s:iyokan-hira}
  いよかん/名詞-一般/イヨカン/伊予柑
  \ex \label{s:iyokan-kata}
  イヨカン/名詞-一般/イヨカン/伊予柑
\end{exe}

\begin{table}[b]
\caption{辞書サイズ：ひらがなやカタカナに展開済み}
\label{tb:dic-size}
\input{1008table06.txt}
\end{table}


\subsection{辞書と学習データの追加の必要性についての議論}
\label{sec:comp-kudo}

\citeA{Kudo:Ichikawa:Talbot:Kazawa:2012j}は，
Web上のひらがな交じり文に対する形態素解析手法の提案にあたり，
次のように述べている．
\begin{quote}
ひらがな交じりの解析も，通常の日本語の文の解析であ
ることには変わりがないため，
以下のような一般的に用いられている既存手法で解析精度を向上させること
が可能である．\\
1. ひらがな単語のユーザ辞書への追加\\
2. ひらがな交じり文を含む学習データを人手で作成し，再学習\\
1. は簡単な手法であるが，ひらがなは日本語の機能語に用いられているた
め，むやみにひらがな語を追加すると副作用により精度が低下する可能性
がある．2. の方法は学習データの作成が必要なためコストが高い．
\end{quote}

これらの理由によって，\citeA{Kudo:Ichikawa:Talbot:Kazawa:2012j}では，
辞書への追加や学習データの追加は行われていない．
\citeA{Kudo:Ichikawa:Talbot:Kazawa:2012j}の手法は，広い分野に対して安定
的に比較的高い精度で解析を行える．しかし，特定の分野における実用を考え
た場合，対象分野においてより高い精度を得ることが重要である．
確かに，1. に関して，ひらがな語を多く追加することによる副作用の可能性は
否定できないが，絵本の場合，いずれの語でもひらがなで記述される可能性が
あるため，すべてのエントリをひらがなにする必要がある．また，2. に関して
は，提案手法では自動的に学習データを作成するので問題ない．

本稿では，提案手法で変換・作成した
辞書と学習データを学習に用いることで，絵本に対しては
既存モデルより高い精度が得られることを示す（\ref{sec:exp-adult}章）．
ただし，本提案手法で得られる精度
は，既存モデルよりは高いが，実用的にはまだ改良の必要がある．
そのため，さらなる精度向上のためには，能動学習や対象分野のラベルありデータの構築が必要となるが，
その際も，ベースとなるモデルの精度がより高い方がより効率的である．


考察
\label{sec:kousatsu}


本章では，前章までに得たモデルをさらに改良するための問題分析と改良案の提示を行う．
まず，\ref{sec:age-acc}節では，対象年齢と形態素解析精度の関係に着目し，精度低下のより詳細な原因調査を行う．
\ref{sec:add-proc}節では，絵本のラベルありデータを追加しても精度が向上しにくかった
固有名詞に焦点をあて，固有名詞の部分アノテーションによる精度向上の効果を検証する．
さらに，\ref{sec:other}節では，提案手法の絵本以外のコーパスへの適用可能性についても考察する．


\subsection{対象年齢と形態素解析精度}
\label{sec:age-acc}

\ref{sec:ehon-db}節で述べたように，\kodomo は対象年齢がはっ
きり設定されている．そこで本節では，\kodomo を用いて，対象年齢と形態素
解析精度の関係を分析する．\kytea\ (\bestHINOKI)と，\mecab を使って
元データを解析した場合の対象年齢と精度の関係を図~\ref{fig:age-acc}に示
す．ただし，図~\ref{fig:age-acc}では，\kod{012}を2歳児にプロットしてい
る．

 図~\ref{fig:age-acc}から，\kytea\ (\bestHINOKI)でも\mecab でも，対
 象年齢が低いほど形態素解析精度も低いことがわかる．
どちらの解析器も，基本的に一般向けのコーパスを学習データとして
モデルが作成されており，対象年齢が上がるとより一般向けの文に
近づいていることが図~\ref{fig:age-acc}からも読み取れる．

 \begin{figure}[b]
   \begin{center}
    \includegraphics{21-3ia1008f11.eps}
   \end{center}
 \caption{対象年齢と形態素解析（形態素区切りと品詞一致）精度の関係(\kodomo)}
  \label{fig:age-acc}
 \end{figure}
\begin{table}[b]
\caption{文字種毎の数と割合：絵本の対象年齢ごと (\kodomo)}
\label{tb:mojisyu-kodomo}
\input{1008table08.txt}
\end{table}


表~\ref{tb:mojisyu}（\ref{sec:mojisyu}節）で示したように，絵本と
京大コーパスなど
に出現する文字種を比較すると，
絵本はひらがなと空白が多く，漢字が少ない点が顕著に異なっていた．また，
\ref{sec:ana-sphan}節では，特にひらがなが形態素解析精度の低下に非常に関わることを
示した．
そこで，対象年齢によってそれらの文字種の出現傾向が変わるかどうか
を，\kodomo のデータを使って調査した（表~\ref{tb:mojisyu-kodomo}）．


 表~\ref{tb:mojisyu-kodomo}によると，文字種の出現傾向に絵本全体の傾向と
 顕著な違いは見られず，対象年齢によって明らかな変化は見られなかった．つ
 まり，ひらがなの多さだけが精度低下の原因ではないことがわかる．ただし，
 表~\ref{tb:mojisyu-kodomo}に参考として示した，行平均の文字数と形態素数
 は，対象年齢が上がるにつれ増加している．京大コーパスと\lxd の文平均の
 文字数や形態素数（表~\ref{tb:mojisyu}）と比較すると，文平均か，行平均か
 の差はあるが，対象年齢が上がるにつれ\lxd の数値に近づいており，辞書の
 例文や定義文に近い長さになってきていることがわかる．つまり，語の羅列で
 はなく，文になってきていると考えられる．


そこで，文字種だけではわからない差分を調査するため，
空白を除く全形態素に占める品詞毎の割合を調査した．
その結果，対象年齢によってもっとも変化が大きかった品詞は，\pos{助詞}\pos{記号}
\pos{副詞}\pos{感動詞}だった．
図~\ref{fig:age-hinshi}に，これらの品詞の占める割合の対象年齢毎の変化と，\lxd での割合を示す．
ここで，\pos{助詞}の割合は対象年齢と共に単調増加しており，
単語の羅列から助詞などを含む文となっていることがわかる．
\pos{記号}は，句読点や括弧などを含むため，句読点を使った文や会話文の量や長さに関係すると考えられる．
\pos{記号}は，\kod{012}と\kod{3}の間で大きく増加しているが，単調増加で
はなく，\kod{5}や\lxd での割合はむしろ\kod{3}や\kod{4}より低い．これは
文が長くなるため記号の占める割合が低くなるのだと考えられ
る．例えば，会話文の場合，記号である\jpn[「]{}と\jpn[」]{}の間
  に発話内容が記述されるが，発話内容が長くなれば，記号の占める割合は低
  くなる．一方，\pos{副詞}の割合は対象年齢に応じて単調減少してい
る．\pos{副詞}には擬音語や擬態語が多く含まれ，対象年齢が低いほど，そう
した語の含まれる割合が高いことがわかる．また，\pos{感動詞}の割合
は\kod{012}と\kod{3}の間で大きく減少している．\pos{感動詞}には挨拶など
が含まれ，より小さな子供向けの絵本では，挨拶などが多く出現するためだと
思われる．

 \begin{figure}[b]
   \begin{center}
    \includegraphics{21-3ia1008f12.eps}
   \end{center}
 \caption{空白を除く全形態素に占める品詞割合：絵本対象年齢毎(\kodomo)と\lxd}
  \label{fig:age-hinshi}
 \end{figure}

なお，絵本毎に精度を調査すると，品詞一致精度で最も精度の高かった絵本と，最も精度の低かった絵本は，
両方とも\kod{012}に含まれた．
これらは，一行一形態素程度の非常に短い文からなっており，
\jpn[ぴょん]{}\jpn[ぼちゃん]{}\jpn[ぶらぶら]{}などの擬音語や擬態語の繰り返しがほとんどだった．
文脈はほぼないため，学習データや辞書に該当する語が
存在するかどうかに依存して精度が大きく変化したとみられる．
そのため，より対象年齢の低い子供向け絵本の解析精度の向上は，
擬音語や擬態語の辞書や学習データの拡充にかかっているといえるだろう．
今後は，擬音語や擬態語の収集による精度向上にも取り組みたい．


\subsection{固有名詞のアノテーション}
\label{sec:add-proc}

\ref{sec:errors}節で述べたように，固有名詞は
他の絵本を追加しても解析精度が向上しにくく，学習データなしでは
解析が難しい語が多い．その上，固有名詞の誤りは数値以上に精度が悪い印象を与えかねない．
しかし一方で，活用語や非自立語などに比べ，固有名詞のアノテーションや辞書への追加は非常に容易である．

ここで，\random に出現した固有名詞でもっとも誤り回数が多かった（各 4 回）
\jpn[ぐり]{}と\jpn[ぐら]{}に着目する．
これらを辞書登録しただけでは解析精度は変わらなかったが，
\kytea では，部分アノテーションしたデータを学習データに加えることがで
きる（\ref{sec:morph-kytea}章）．
そこで，\jpn[ぐり]{}と\mbox{\jpn[ぐら]{}}に対し部分アノテーションを行い，その効果を検証した．


部分アノテーションは以下の流れで行った．
まず，[1] 対象語を含む文を字面一致で抽出し，
次に，[2] 人手で該当箇所に対象語以外の語が含まれないか確認し，
最後に，[3] 自動的に部分アノテーションを実行した．

ここで，
\jpn[ぐり]{}と\jpn[ぐら]{}の場合，[2]の確認作業で，
\jpn[どん\ul{ぐり}]{}，
\jpn[うす\ul{ぐら}い]{}，
\mbox{\jpn[\ul{ぐら}い]{}}が混じっていることがわかった．
[3]では，最長一致によってこれらの語のアノテーションも自動的に行った．
例えば，文\refs{gurigura}の場合，
下線部をそれぞれ，
\jpn[ぐり/名詞-固有名詞-人名-一般/グリ/ぐり]{}，
\jpn[ぐらい/助詞-副助詞/グライ/ぐらい]{}
として部分アノテーションした．

 \begin{exe} 
 \ex \label{s:gurigura}
\ul{ぐり}が　けいとを　まくと、えんどうまめ\ul{ぐらい}になりました。\\
\small （なかがわりえこ　と　やまわきゆりこ「ぐりとぐらのえんそく」p.~15 （1979, 福音館書店））
 \end{exe}

これにより部分アノテーションされたのは，
\jpn[ぐら]{} 135箇所，
\jpn[ぐり]{} 131箇所，
\jpn[どんぐり]{} 1箇所，
\jpn[うすぐらい]{} 2箇所，
\jpn[ぐらい]{} 6箇所だった．
これらの部分アノテーションデータを学習データに追加したところ，
原形一致の精度が $+0.2$\% 改良された．品詞一致までの精度は，
小数点第一位までの比較では同じだったが，
\jpn[ぐり]{}と\jpn[ぐら]{}に関する誤りはなくなった．
固有名詞は学習しにくく，かつ，同じ絵本では何度も出現
するため，固有名詞のみを先にアノテートすることは有効だと考えられる．


固有名詞を含めた固有表現や未知語の抽出方法に関する研究は多
く\cite{Murawaki:Kurohashi:2010j,Katsuki:Sasano:Kawahara:Kurohashi:2011j,Sasano:Kurohashi:2007j}
，特に格フレーム情報を利用する方法\cite{Sasano:Kurohashi:2008j}は，
絵本でも有効だと考えられる．今後は，
絵本やシリーズ毎の固有名詞の抽出や，該当固有名詞を含む他の語の確認・抽
出を自動・半自動化することにより，精度向上を目指したい．
また，\citeA{Neubig:Nakata:Mori:2011}
は，SVM平面からの距離を用いて
確信度の低いデータを選び，部分アノテーションして学習データに追加
する能動学習を提案している．
固有名詞のように，一気にアノテートできる部分を学習に追加した後は，
\citeA{Neubig:Nakata:Mori:2011}
と同様に能動学習を行うことが考えられる．


\subsection{他分野への適用可能性}
\label{sec:other}

本節では，提案手法の絵本以外への適用可能性について考察する．

提案手法は，既存の言語資源と解析対象の言語資源の特徴が大きく異なる場合
に有用である．

例えば，小学生は学年毎に習う配当漢字が決められている．そのため教科書では，習っていな
い漢字をひらがなで記載するため，漢字とひらがなが一般向け文章とは全く異なる交じり方を
する場合があり，形態素解析を難しくしている．例えば，\mbox{\jpn[音楽]{}}の場合，
\jpn[音]{}は 1 年生，\mbox{\jpn[楽]{}}は
2 年生の配当漢字であるため，\mbox{\jpn[音がく]{}}
と記載される場合がある\footnote{畑中良輔ほか「小学生の音楽 2」（2006，教育芸術社）より．}．
そこで，教科書等の学
童用の文章の解析用には，学年配当漢字に基づいて利用できる漢字を制限し，それ以外はひら
がなに変換して学習データを作成することが考えられる．


あるいは，Webなどに出現するくだけた文章の解析用として，文末表現の変換，
利用語彙の制限などにより，学習データを変換することも考えられる．

このように，
学習データを対象分野に合わせて自動的に変換するルールを決定できる場合には，
本提案手法が適用できると考えられる．


