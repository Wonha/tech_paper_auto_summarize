評価実験(1): 教師なし分野適応
\label{sec:exp-adult}

本章では，前章で提案した手法により変換した既存言語資源だけを学習に利用する
評価実験，つまり，教師なし分野適応の実験を行う．

前章で紹介した通り，ラベルありデータは3通りの変換により作
  成した．これらと，変換前のラベルありデータを組み合わせて学習に用いた
  場合の精度評価を行った（表~\ref{tb:res}）．
表~\ref{tb:res}では，形態素区切り，および，品詞の細分類までが一致した精度を示している．
表~\ref{tb:res}は，絵本に出現した
文に対する解析精度であり，表~\ref{tb:res-bunseki}の左端\pos{元データ \refs{eva-org}}の列に当たる．
比較のため，表~\ref{tb:res}にも結果を再掲した．


\begin{table}[b]
\caption{評価結果: 形態素区切り，および，品詞が一致した数と割合 (\kodomo)}
\label{tb:res}
\input{1008table07.txt}
\vspace{4pt}
\small
ただし，\refs{lxdex-org}から\refs{lxdex-hirasp}は，対応する学習データの例の番号を示している．\\
また，[A]--[C]は参照用に付与した記号である．
\par
\end{table}

既存言語資源をそのまま学習に利用した場合，精度は 63.0\%と非常に低いが，
空白を追加したり，ひらがなに変換した学習データを利用することで，
88.5\%まで精度を向上できた．
つまり，新聞データなどの一般向けのテキストを学習データに利用する場合でも，
絵本での出現傾向にあわせて変換することで，相当な精度向上が出来た．

ここで，空白を追加した学習データだけを利用する場合[B]より，空白を追加し
ない学習データも利用する[C]の方が精度が高かった．これは，すべての絵本で
全文節ごとに空白が入るわけではないので，両方を学習に利用した方が良かっ
たのだと考えられる．同様に，ひらがなに変換した学習データだけを利用する
より，漢字のままの学習データも利用する方が若干精度が高かった．これは，
すべての絵本で漢字が全く出現しないわけではないためだと考えられる．

以降，最も高い精度を得られたラベルありデータ（表~\ref{tb:res} [C] の ``両方利用 \refs{lxdex-org}〜\refs{lxdex-hirasp}''）を\bestHINOKI，
得られたモデルを用いた解析器を\kytea\ (\bestHINOKI)と呼び，これ
をベースに，さらに改良を加えることを検
討したい．
また，絵本によって，空白や漢字の含有率は非常に異なるため，
これらの含有率によって
学習に利用するデータを変更することも考えられる．


評価実験(2): 教師あり分野適応
\label{sec:exp-add-ehon}

\ref{sec:exp-adult}章の実験では，ラベルありデータとして既存言語資源から得た
コーパスだけを用いた．
しかし分野適応では，同じ分野のラベルありデータを追加すると精度が向上す
ることはよく知られており，本章では，絵本自体のラベルありデータを学習に
用いた実験を行う．

本章の目的は二つある．一つは，
提案手法によって既存言語資源から自動的に獲得し
たラベルありデータが，どの程度の絵本自体のフルアノテーションデータと
同程度の効果があるかを調べることである．
もう一つは，絵本自体へアノテーションするときの効率的な方法
を示すことである．


\subsection{学習曲線}
\label{sec:exp-add-ehon-full}

本節では，
フルアノテーションデータ\kodomo（\ref{sec:full-ano}節）の
各絵本をそれぞれ10分割し，それらを徐々に学習データに追加した場合
の学習曲線を調べる．ここで，\ref{sec:exp-adult}章で最も良い精度を得
た学習データである\bestHINOKI と絵本を両方学習に利用する場合
と，絵本だけを学習に利用する場合の両方の実験を行った．

また，評価は2通り行う．
つまり，学習データを追加した絵本と，
(1) 同じ絵本のテキストによる評価（\kodomo を利用），
(2) 違う絵本のテキストによる評価（\random を利用），
を行う．

本節での精度評価は，品詞まで一致した精度に加え，原形まで一致した精度評価も行っている．
本稿で構築している形態素解析モデルでは，
出現形がひらがなでも，原形は出来る限り漢字表記を推定している（\ref{sec:train-data}節）．
ひらがなで出現した語に対し，漢字表記を推定することができれば，
その後の解析に有用だからである．
例えば，\jpn[め]{}という語が\jpn[目]{}なのか\jpn[芽]{}なのか，
\jpn[はな]{}という語が\jpn[鼻]{}なのか\jpn[花]{}なのか，などは，幼児の言語発達を調べる
ときにも区別する必要がある\cite{Ogura:Watamaki:2008}．
これは，本来，語義曖昧性解消問題として取り組むべき課題かもしれないが，
形態素解析時に同時に推定が可能なら利便性が高い．
そこで，本節では，形態素解析時の漢字の原形推定をどの程度の精度で行うことができるかも
同時に調査した．

 \begin{figure}[b]
\setlength{\captionwidth}{197pt}
  \begin{minipage}{199pt}
    \includegraphics{21-3ia1008f1.eps}
    \hangcaption{学習曲線：同じ絵本を学習データに追加（\kodomo, 品詞一致）}
    \label{fig:lc-self-POS}
  \end{minipage}
\hfill
  \begin{minipage}{199pt}
    \includegraphics{21-3ia1008f2.eps}
   \hangcaption{学習曲線：異なる絵本を学習データに追加（\random, 品詞一致）}
    \label{fig:lc-rand-POS}
  \end{minipage}
\end{figure}
\begin{figure}[b]
\setlength{\captionwidth}{197pt}
  \begin{minipage}[t]{199pt}
    \includegraphics{21-3ia1008f3.eps}
   \hangcaption{学習曲線：同じ絵本を学習データに追加（\kodomo, 原形一致）}
    \label{fig:lc-self-BS2}
  \end{minipage}
\hfill
  \begin{minipage}[t]{197pt}
   \begin{center}
    \includegraphics{21-3ia1008f4.eps}
   \end{center}
   \hangcaption{学習曲線：異なる絵本を学習データに追加（\random, 原形一致）}
    \label{fig:lc-rand-BS2}
  \end{minipage}
 \end{figure}

ここで，図~\ref{fig:lc-self-POS}, \ref{fig:lc-self-BS2}は，\kodomo の
各絵本の1/10を評価データとし，それ以外を順次追加した場合の学習曲線を示
している．また，図~\ref{fig:lc-rand-POS}, 
\ref{fig:lc-rand-BS2}は，\random を評価データとした場合の精度を示して
おり，\kodomo のすべてを学習データに追加した場合の精度も示している．ま
た，図~\ref{fig:lc-self-POS}, \ref{fig:lc-rand-POS}は，品詞一致の精度，
図~\ref{fig:lc-self-BS2}, \ref{fig:lc-rand-BS2}は，原形まで一致した精度
を示している．
ただし，学習データでは，コーパス\hinoki の漢字等による原形をそのまま原形として利用したため，
学習データの原形に表記ゆれが存在する．
そこで，原形一致精度の評価時には，\jpn[仔牛]{}と\jpn[子牛]{}，
\jpn[雄]{}と\jpn[オス]{}のように，表記ゆれだとみなせるものは正解に含めている
\footnote{表記ゆれの判断は，日本語語彙大系によった．}．
また，\mecab は漢字表記による原形推定はしないため，ひらがなの原形も正解とした．
標準表記の決定，学習データの標準表記への変換は今後の課題としたい．


\subsection{提案手法の効果：評価(2)}
\label{sec:eva2}

提案手法で作成した\bestHINOKI の効果を調べる．
図~\ref{fig:lc-self-POS}〜\ref{fig:lc-rand-BS2}から，
すべての場合で，\bestHINOKI に
絵本データを追加した方が，絵本データだけの
場合や，\bestHINOKI だけの場合より精度が向上しており，
絵本とは全く異なる一般向けのテキストであっても，
\bestHINOKI を学習に利用する方が良いことがわかる．

特に，図~\ref{fig:lc-rand-POS}, \ref{fig:lc-rand-BS2}に示した通り，
別の絵本(\random)に対する精度は，学習データに絵本だけを用いる場合より非常に高い．
\random の場合，品詞一致でも，原形一致でも，絵本の学習データだけで
\kytea\ (\bestHINOKI)と同等の精度を得るには，
\kodomo のフルアノテーションデータ約 11,000行，90,000形態素が必要である．
これは，\kodomo のフルアノテーションデータの 8/10近くにあたる．
これだけのフルアノテーション作業には相当な時間とコストがかかっており，
提案手法による自動的な変換による精度向上の効果は高い．


なお，\random に対する精度は，すべての\kodomo を学習データに追加した場合で，
形態素区切り 98.3\%，品詞完全一致 91.1\%，品詞大分類 94.7\%，原形一致 89.0\%だった．
これが，新しい絵本を解析する場合の精度にあたる．


\subsection{アノテーション方針の提案}
\label{sec:ano-houshin}

本節では，同じ絵本を学習データとして追加した場合の効果を調べる．
図~\ref{fig:lc-self-POS}, \ref{fig:lc-self-BS2}から，
同じ絵本の学習データは非常に有効であることがわかる．
\bestHINOKI を使わない場合でも，同じ絵本の 10 分の 2 を学習データとして用いただけで
\kytea\ (\bestHINOKI)の精度より高い精度を得ることができる．
このように，同じ絵本のデータの追加のほうが効果が圧倒的に高いため，
同じ分量のアノテーションを行うのであれば，少しずつでも，
できるかぎり全ての絵本からアノテーションすることが望ましい．
同じ絵本のアノテーションが特に有効な理由には，同じ固有名詞（\ref{sec:errors}, \ref{sec:add-proc}節参照）
や，同じ表現が出現することがあげられるだろう．
絵本は，例えば，例\refs{ex-repeat}のように
一部の語を変えて同じ表現が繰り返されることが多く，一部をアノテーションする効果が高い．
なお，\refs{ex-repeat}の絵本の場合，\jpn[なんて　なく？]{}は11 回出現している．

 \begin{exe} 
 \ex \label{s:ex-repeat}
 かえるは\\
 \ul{なんて　なく？}\\
 にわとりは\\
 \ul{なんて　なく？} \hspace{5mm}
\small （凹工房 「どうぶつ　なんて　なく？」p.~2--3 （2008，ポプラ社））
 \end{exe}


\subsection{誤り内容の変化}
\label{sec:errors}

\newcommand{\COM}{}

\begin{figure}[b]
 \begin{minipage}{0.48\hsize}
   \begin{center}
    \includegraphics{21-3ia1008f5.eps}
   \end{center}
  \caption{\COM（\kodomo, 動詞）}
   \label{fig:lc-self-err-VERB}
 \end{minipage}
\hfill
 \begin{minipage}{0.48\hsize}
   \begin{center}
    \includegraphics{21-3ia1008f6.eps}
   \end{center}
  \caption{\COM（\random, 動詞）}
   \label{fig:lc-rand-err-VERB}
 \end{minipage}
\end{figure}
\begin{figure}[b]
\setlength{\captionwidth}{197pt}
 \begin{minipage}{199pt}
    \includegraphics{21-3ia1008f7.eps}
  \hangcaption{\COM（\kodomo, 名詞-固有名詞）}
   \label{fig:lc-self-err-PROP}
 \end{minipage}
\hfill
 \begin{minipage}{199pt}
    \includegraphics{21-3ia1008f8.eps}
  \hangcaption{\COM（\random, 名詞-固有名詞）}
   \label{fig:lc-rand-err-PROP}
 \end{minipage}
\end{figure}

\begin{figure}[t]
 \begin{minipage}{0.48\hsize}
   \begin{center}
    \includegraphics{21-3ia1008f9.eps}
   \end{center}
  \caption{\COM（\kodomo, 感動詞）}
   \label{fig:lc-self-err-KANDO}
 \end{minipage}
\hfill
 \begin{minipage}{0.48\hsize}
   \begin{center}
    \includegraphics{21-3ia1008f10.eps}
   \end{center}
  \caption{\COM（\random, 感動詞）}
   \label{fig:lc-rand-err-KANDO}
 \end{minipage}
\end{figure}

本節では，絵本を学習データに追加した場合の，誤り内容の変化を調査する．
解析を誤った語を品詞毎に集計し，\pos{動詞}\pos{名詞-固有名詞}\pos{感動詞}について，それぞれ
図~\ref{fig:lc-self-err-VERB}と\ref{fig:lc-rand-err-VERB}，
\ref{fig:lc-self-err-PROP}と\ref{fig:lc-rand-err-PROP}，
\ref{fig:lc-self-err-KANDO}と\ref{fig:lc-rand-err-KANDO}
に示した．
図~\ref{fig:lc-self-err-VERB}〜\ref{fig:lc-rand-err-KANDO}
では，誤りの絶対数と，全誤り数に占める対象品詞の割合をプロットしている．

誤りの絶対数はどの品詞でも減少しているが，全誤りに占める各品詞の割合を
見ると，比較的学習しにくい品詞がわかる．\pos{動詞}（図~\ref{fig:lc-self-err-VERB}, \ref{fig:lc-rand-err-VERB}）は
\kodomo でも\random でも相対的に上昇している．
\pos{固有名詞}（図~\ref{fig:lc-self-err-PROP}, \ref{fig:lc-rand-err-PROP}）の場合，\kodomo では急激に割合が下がるが，
\random では逆に相対的に上昇している．
\pos{固有名詞}は，絵本間で共通のものが少なく，しかも，
ひらがな（\mbox{\jpn[ぐり]{}}\footnote{\label{prop1}「ぐりとぐら」（なかがわりえこ　と　やまわきゆりこ（1963，福音館書店））などより．}，
\jpn[ぐら]{}$^{\ref{prop1}}$，
\jpn[もものこ]{}\footnote{「もものこさん」（あまんきみこ　さく　かのめかよこ　え（2011，福音館書店））より．}など）や，
ひらがなカタカナ混じり
（\jpn[ウサこ]{}\footnote{\label{prop2}「いけるといいね　トイレ」（原作やなせたかし　作画東京ムービー（2001，フレーベル館））などより．}，
\jpn[ネコみ]{}$^{\ref{prop2}}$など）など，
非常に解析が難しいものが多いからだと思われる．
対照的に，\pos{感動詞}（図~\ref{fig:lc-self-err-KANDO}, \ref{fig:lc-rand-err-KANDO}）は，\random でも誤る割合が下がっている．
これは，異なる絵本でも共通の表現が多いためだと考えられる．
例えば，\random 側で，\bestHINOKI だけでは正解しなかったが，
絵本を追加していくことで正解するようになった感動詞には，
\jpn[あっぷっぷ]{}，\jpn[ごくろうさま]{}，
\mbox{\jpn[ギャオー]{}}などがあった．


