 情報検索ではベクトル空間モデルが主流である．そこでは文書とクエリを索引語ベクトルで表し，
 それらベクトル間の距離をコサイン尺度などで測ることで，クエリと最も近い文書を検索する．
 ベクトル空間モデルの問題点として，同義語（synonymy）と多義語（polysemy）の問題が
 指摘されている．同義語の問題とは，例えば，``car'' というクエリから ``automobile'' を含む文書が
 検索できないこと．多義語の問題とは，例えば，ネットサーフィンについてのクエリ ``surfing''に対して，
 波乗りに関する文書が検索されることである．
 これらの問題は文書のベクトルに索引語を当てることから生じている．
 そこでこれら問題の解決のために文書のベクトルを潜在的（latent）な概念に設定することが
 提案されており，そのような技術を潜在的意味インデキシング
 （Latent Semantic Indexing，以下 LSI と略す）と呼んでいる．
 LSI の中心課題はどのようにして潜在的な概念に対応するベクトルを抽出するかである．
 その抽出手法に LSI では特異値分解を利用する．
 具体的には索引語文書行列\( A \)に対して特異値分解を行い，
 その左特異ベクトル（\( A A^{T} \) の固有ベクトル）を固有値の
 大きい順に適当な数\( k \)だけ取りだし\footnote{ここでは索引語ベクトルを
 列ベクトルとしている．また\( A^{T} \)は\( A \)の転置行列を表す．}，
 それらを潜在的な概念に対応するベクトルとする\cite{kita-ir}．

 LSI は魅力的な手法であるが，実際に試してみるには，特異値分解のプログラムが必要になる．
 低次元の特異値分解のプログラムは比較的簡単に作成できるが，
 現実の問題においては，高次元かつスパースな行列を扱わなくてはならない．
 このような場合，特異値分解のプログラムを作成するのはそれほど容易ではない．
 そこで本論文では，この特異値分解を行うためのツール SVDPACKC を紹介する．
 このツールによって高次元かつスパースな行列に対する特異値分解が行え，
 簡単に LSI を試すことができる．

 また LSI の情報検索以外の応用として，語義判別問題を取り上げ SVDPACKC の
 利用例として紹介する．実験では SENSEVAL2 の日本語辞書タスク\cite{sen2}で
 出題された単語の中の動詞 50 単語を対象とした．
 LSI に交差検定を合わせて用いることで，最近傍法\cite{ishii}の精度を向上させることができた．
 また最近傍法をベースとした手法は，一部の単語に対して
 決定リスト\cite{Yarowsky1}や Naive Bayes \cite{ml-text}以上の正解率が
 得られることも確認できた．
score of this paragraph is 4
