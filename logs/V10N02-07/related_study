情報検索ではベクトル空間モデルが主流である．そこでは文書とクエリを索引語ベクトルで表し，それらベクトル間の距離をコサイン尺度などで測ることで，クエリと最も近い文書を検索する．ベクトル空間モデルの問題点として，同義語（synonymy）と多義語（polysemy）の問題が指摘されている．同義語の問題とは，例えば，``car''というクエリから``automobile''を含む文書が検索できないこと．多義語の問題とは，例えば，ネットサーフィンについてのクエリ``surfing''に対して，波乗りに関する文書が検索されることである．これらの問題は文書のベクトルに索引語を当てることから生じている．そこでこれら問題の解決のために文書のベクトルを潜在的（latent）な概念に設定することが提案されており，そのような技術を潜在的意味インデキシング（Latent Semantic Indexing，以下LSIと略す）と呼んでいる．LSIの中心課題はどのようにして潜在的な概念に対応するベクトルを抽出するかである．その抽出手法にLSIでは特異値分解を利用する．具体的には索引語文書行列[MATH]に対して特異値分解を行い，その左特異ベクトル（[MATH]の固有ベクトル）を固有値の大きい順に適当な数[MATH]だけ取りだし，それらを潜在的な概念に対応するベクトルとする[CITE]．

LSIは魅力的な手法であるが，実際に試してみるには，特異値分解のプログラムが必要になる．低次元の特異値分解のプログラムは比較的簡単に作成できるが，現実の問題においては，高次元かつスパースな行列を扱わなくてはならない．このような場合，特異値分解のプログラムを作成するのはそれほど容易ではない．そこで本論文では，この特異値分解を行うためのツールSVDPACKCを紹介する．このツールによって高次元かつスパースな行列に対する特異値分解が行え，簡単にLSIを試すことができる．

またLSIの情報検索以外の応用として，語義判別問題を取り上げSVDPACKCの利用例として紹介する．実験ではSENSEVAL2の日本語辞書タスク[CITE]で出題された単語の中の動詞50単語を対象とした．LSIに交差検定を合わせて用いることで，最近傍法[CITE]の精度を向上させることができた．また最近傍法をベースとした手法は，一部の単語に対して決定リスト[CITE]やNaive Bayes [CITE]以上の正解率が得られることも確認できた．

paragraph score: 1.00798387289598
