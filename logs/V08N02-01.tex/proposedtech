\documentstyle[epsf,jnlpbbl]{jnlp_j}

\setcounter{page}{3}
\setcounter{巻数}{8}
\setcounter{号数}{2}
\setcounter{年}{2001}
\setcounter{月}{4}
\受付{2000}{8}{28}
\再受付{2000}{10}{6}
\採録{2001}{1}{12}

\setcounter{secnumdepth}{2}


\title{決定リストを弱学習器としたアダブーストによる日本語単語分割}
\author{新納 浩幸\affiref{ibaraki}}

\headauthor{新納 浩幸}
\headtitle{決定リストを弱学習器としたアダブーストによる日本語単語分割}

\affilabel{ibaraki}{茨城大学工学部システム工学科}
{Faculty of Engineering, Ibaraki University Department of Systems Engineering}

\jabstract{
本論文では決定リストを弱学習器としたアダブーストによる日本語単語分割法を提案する．
日本語単語分割は，入力文の各文字の間に単語区切りを置くか置かないかの問題とみなすことで，
分類問題として定式化できる．
この分類問題を決定リストを利用して解くことで単語分割が行える．
ここでは決定リストで利用する属性に辞書情報を含めない．
そのためここでの単語分割は未知語の問題を受けないという長所がある．
更に単語分割を分類問題として解く場合，近年研究の盛んなアダブーストの手法を適用できる．
アダブーストを用いることで，決定リストの精度を高めることができる．
実験では，京大コーパス（約4万文）を利用して決定リストを作成した．
この決定リストによる単語分割の正解率は 97.52\% であった．
この値は、同じ訓練データから構築したtri-gram モデルに基づく
単語分割法での正解率 92.76\% を
大きく上回った．またアダブーストを利用することで精度が 98.49\% にまで向上させる
ことができた．また作成した単語分割システムは未知語の検出能力が高いことも確認できた．
}

\jkeywords{単語分割，分類問題，決定リスト，アダブースト}

\etitle{Japanese word segmentation by Adaboost \\
using the decision list as the weak learner}
\eauthor{Hiroyuki Shinnou\affiref{ibaraki}} 

\eabstract{
In this paper, we propose the new method of Japanese word segmentation
by Adaboost using the decision list as the weak learner.
The word segmentation is regarded as the classification problem of 
judging whether the word boundary exists between two characters or not.
By solving the problem by the decision list method,
we can conduct Japanese word segmentation.
Our method has the advantage not to suffer the unknown word problem
because we do not use dictionary information as an attribute of our decision list.
Moreover, by taking this approach we can use Adaboost which is actively researched in 
the machine learning domain recently.
Adaboost improves the precision of our decision list.
In experiments, we built the decision list through Kyoto University
Corpus (about 40K sentences).
The precision of this decision list was 97.52\%.
This values was much higher than the precision of character based tri-gram model, 92.76\%.
By using Adaboost method, our precision was improved to 98.49\%.
Furthermore, our word segmentation system was excellent in detecting unknown words.
}

\ekeywords{Word segmentation, classification problem, decision list, Adaboost}

\begin{document}
\maketitle





\section{決定リストによる単語分割}


\subsection{単語分割と分類問題}

\( n \)文字からなる入力文を \( s = c_1 c_2 \cdots c_n \) （各\( c_i \)は文字を表す）とすると，
日本語単語分割は文字\( c_{i} \) と \( c_{i+1} \) 
の間（\( b_{i} \) と名付ける）に
単語境界がある(\(+1\)) かない(\(-1\)) かを与えることによって行える。
つまり\( b_{i} \) （ \( i = 1,2, \cdots, n-1 \) ）に\( +1 \)か\( -1 \)を
与える分類問題としてとらえられる.
例えば，「太郎は海でアイスクリームを食べた。」という文に対しては，
\mbox{図\ref{zu1}} のように各文字間にクラス\( +1 \)あるいは\( -1 \)を付与し，
\( +1 \)の部分を単語境界に置き換えることにより単語分割が行える．

\begin{figure*}[htbp]
\begin{center}
\atari(116.3,42.2)
\end{center}
\caption{クラスの付与による単語分割}
\ecaption{Word segmentation by class assignment}\label{zu1}
\end{figure*}

分類問題を解く手法は様々なものがある．どの手法が優れているかは問題に依存するために
一概には言えない．本論文では決定リストを利用して上記の分類問題を解く．

\subsection{決定リストの構築}

決定リストは帰納学習手法の一種であり，正解付きの訓練データから，
分類規則を学習する．決定リストの場合，分類規則は
証拠とクラスの組の順序付きの表となる．
ここで証拠とは属性とその属性の値の組である．
実際の分類はリストの上位のものから順に，その証拠があるかどうかを
調べ，その証拠があれば，それに対応するクラスを出力する．

決定リストの作成は概ね以下の手順による．

\begin{description}
\item[step 1] 属性を設定する．

例えば\( n \)個の属性を\( att_{1} , att_{2} , \cdots , att_{n} \)とする。

\item[step 2] 訓練データから証拠とクラスの組の頻度を調べる．

訓練データ中のあるデータの属性\( att \) の値が \( a \) で
あるとし，そのデータのクラスが\( C \) だとする．
その場合，\( (att,a) \) という証拠とクラス\( C \) の組
\( ((att,a),C) \) の頻度に 1 を足す．
これを訓練データ中の全データに対する全属性について行う．

\item[step 3] 証拠の判別力と分類クラスを導く．

\( ((att,a),C) \) の頻度が\( f_{C} \) であった場合，
\( f_{C} \) の最大値を与える\( \hat{C} \) が
証拠 \( (att,a) \) に対する分類クラスとなる．
またそのときの判別力\( pw(att,a) \)は以下で定義される．
\[
pw((att,a)) = \log \frac{f_{\hat{C}}}{\sum_{C \neq \hat{C}} f_{C}}
\]

\item[step 4] 判別力の順に並べる．

全ての証拠と分類クラスの組を判別力の大きい順に並べる．
これによって作成できた表が決定リストである．

\end{description}

\subsection{属性の設定}

各文字間\( b_i \)がどのクラスに属するかを判断する材料が属性である．
本論文では\( b_i \)の属性として，\mbox{表\ref{attribute}}の 7 種類を用意した．

\begin{table}[h]
  \begin{center}
    \leavevmode \small
    \caption{設定した属性}
    \ecaption{Setting attributes}  \label{attribute}
    \begin{tabular}{|c|cc|} \hline
属性           &     値    &   \\ \hline
\( att_{1} \)  &  文字列 & \( c_{i-1}c_{i}c_{i+1} \)      \\ \hline
\( att_{2} \)  &  文字列 & \( c_{i}c_{i+1}c_{i+2} \)      \\ \hline

\( att_{3} \)  &  文字列 & \( c_{i-1}c_{i} \)          \\ \hline
\( att_{4} \)  &  文字列 & \( c_{i}c_{i+1} \)            \\ \hline
\( att_{5} \)  &  文字列 & \( c_{i+1}c_{i+2} \)           \\ \hline
\( att_{6} \)  &  字種の接続関係1 & \( ((c_{i}の大分類字種), (c_{i+1}の大分類字種)) \)  \\ \hline
\( att_{7} \)  &  字種の接続関係2 & \( ((c_{i}の細分類字種), (c_{i+1}の細分類字種)) \)  \\ \hline
    \end{tabular}
  \end{center}
\end{table}

6，7番目の属性として，字種の情報を利用している形になっている．
ここでは字種を大分類と細分類の二つの観点から分類した．
字種の大分類は6番目の属性，字種の細分類は7番目の属性で利用した．

字種の大分類は\mbox{表\ref{dai-bunrui}}に示した 9種類である．

\newpage

\begin{table}[h]
  \begin{center}
    \leavevmode \small
    \caption{大分類字種}
    \ecaption{Classification of character types}\label{dai-bunrui}
    \begin{tabular}{|c|c|c|} \hline
字種  & 意味    & 例 \\ \hline
平    &  平仮名 & あ，い，う， … \\ \hline
カ    & カタカナ   & ア，イ，ウ， … \\ \hline
数    & 漢数字    & 一，二，…，百，千，… \\ \hline
漢    & 漢字      & 亜，位，卯， … \\ \hline
Ｎ    & 英数字    & ０，１，２，… \\ \hline
ア    & アルファベット & Ａ，Ｂ，Ｃ，… \\ \hline
記    & 記号     & 、，。，「，… \\ \hline
〇    & 小丸かゼロ &  〇 \\ \hline
○    & 大丸かゼロ &  ○ \\ \hline
    \end{tabular}
  \end{center}
\end{table}

字種の細分類は大分類の平仮名の部分をその文字自身にしたものである．

また注意として，本論文の決定リストでは \( default \) の証拠を導入していない．
決定リストでは通常\( default \)という証拠を設けて，それ以下の判別力の
証拠は表には入れない．\( default \)は文脈上の証拠が決定リストに存在しない場合の
処理ととらえられるが，ここでは大分類の字種の情報が必ずヒットするので，
\( default \)の証拠を含める必要がない．
6番目の属性からの証拠の最下位のものが，決定リストの最下位の証拠となる．

\subsection{利用例}

決定リストの利用例を示す．例えば「太郎は海でアイスクリームを食べた。」という入力文の
5番目の文字 ``で'' と 6 番目の文字 ``ア'' の間，つまり \( b_5 \) にクラス
\( +1 \)あるいは\( -1 \)を与えてみる．
\( b_5 \)の持つ証拠は以下の 7 種である．

\bigskip
\begin{center}
\( (att_{1}, "海でア") \)，\( (att_{2}, "でアイ") \)，\( (att_{3}, "海で") \)，\\
\( (att_{4}, "でア") \)，\( (att_{5}, "アイ") \)，\( (att_{6}, "平カ") \)，\( (att_{7}, "でカ") \)  
\end{center}
\bigskip

後述する実験で得られた決定リストを用いると，各証拠の分類クラスと判別力は以下の通りである．

\newpage

\begin{table}[h]
  \begin{center}
    \leavevmode \small
    \caption{クラス判別の例}
    \ecaption{Example of class judgement}\label{class-hanbetu}
    \begin{tabular}{|c|cc|} \hline
証拠           &  分類クラス & 判別力  \\ \hline
\( (att_{1}, "海でア") \)  &   --  &  --    \\ \hline
\( (att_{2}, "でアイ") \)  &   --  &  --    \\ \hline
\( (att_{3}, "海で") \)  &   +1  & 2.74377     \\ \hline
\( (att_{4}, "でア") \)  &   +1  & 5.83188     \\ \hline
\( (att_{5}, "アイ") \)  &   +1  & 1.64565     \\ \hline
\( (att_{6}, "平カ") \)  &   +1  & 6.33293     \\ \hline
\( (att_{7}, "でカ") \)  &   +1  & 8.64488     \\ \hline
    \end{tabular}
  \end{center}
\end{table}

表の中で ``--'' の記号のものは，決定リスト中にその証拠がないことをあらわす．
また本来ならば，決定リスト中の順位を求めなければならないが，
ここでは相対的な順位関係だけが必要であり，
順位の値自体は必要でない．判別力の最も大きなものが最上位の順位になるはずである．
この場合，証拠 \((att_{7},"でカ") \) が最も大きな判別力を持つので，
この証拠の分類クラス +1 が判定結果となる．
つまり\( b_5 \) には単語境界を置くと判定する．


\section{アダブーストの利用}


精度の低い分類規則を組み合わせて精度の高い分類規則を得る方式をブースティングという．
アダブーストはブースティング方式の一つであり，
現在まで多くの理論的検証と実験的実証から有効性が示されている．

アダブーストのアルゴリズムを\mbox{図\ref{algo}} に示す．
分類クラス(\mbox{図\ref{algo}} の \( Y \) )をここでは\( \{ +1, -1 \} \) の 2値とする．
また訓練データを\( (x_1,y_1),(x_2,y_2),\cdots,(x_m,y_m) \) で表す．
ここで各\( x_i \) はデータを表し，\( y_i \) はデータ\( x_i \) のクラスである．
具体的に\( y_i \) は\( +1 \) あるいは\( -1 \)の値である．
この訓練データに対して，分類問題に対する学習アルゴリズム，
例えば，決定木や決定リストなどを適用して，分類規則\( h_1 \)を学習する．
得られた分類規則\( h_1 \)を訓練データに適用すると，\( h_1 \)によって
各\( x_i \)の判定クラスが得られる．今，\( x_i \)の実際のクラス\( y_i \) は
与えられているので，分類規則\( h_1 \)が各\( x_i \)に対して正しい判定を行ったかどうかを
調べられる．これによって不正解のデータを集め，それら不正解のデータに対してある重みを付加して，
訓練データ\( (x_1,y_1),(x_2,y_2),\cdots,(x_m,y_m) \)を再構成する．
そしてこの再構成された訓練データに対して，
再び学習アルゴリズムを適用して，分類規則\( h_2 \)を学習する．
これを\( T \)回繰り返す．
この繰り返しによって，\( T \)組の分類規則\( h_1, h_2, \cdots, h_T \) が得られる．
実際の判定は入力データに対して各分類規則が出力するクラスの重み付き多数決により行われる．

例えば，\( T = 3 \) とし，入力データ\( x \) に対して，分類器\( h_1 \) による
判定クラスが\( +1 \)，\( h_2 \) による判定クラスが\( -1 \)，
\( h_3 \) による判定クラスが\( +1 \) であり，各重みが 1 ， 2.0 ，2.2 であった場合，
重み付き多数決の結果は \( +1.2 \) である．
最終的な判定クラスは総和の符合により求まる．この例の場合，符合は正であるので，
\( +1 \) が判定クラスになる．

アダブーストのポイントは不正解のデータに課す重みの与え方である．
概略，得られた分類規則の誤り確率（ \mbox{図\ref{algo}}における \( \epsilon_{t} \) ) が
小さいほど重みが大きくなるように設定している．

\begin{figure*}[htbp]
\begin{center}
\atari(120.5,128)
\end{center}
\caption{アダブースト}
\ecaption{AdaBoost}\label{algo}
\end{figure*}

本論文では．分類問題に対する学習アルゴリズムを決定リストに設定する．
不正解データに与える重みをどのように反映させるかが問題である．
ここでは，重みを頻度として与えることにした．
例えば，「太郎が東京へ行く。」という文に
以下のように単語境界 ``/'' が置かれたものが訓練データである．

\begin{verbatim}
                         太郎/が/東京/へ/行く/。
\end{verbatim}

今，4番目の文字 ``東'' と 5 番目の文字 ``京'' の間，つまり \( b_4 \) に対する証拠は
以下の通りである．

\bigskip
\begin{center}
\( (att_{1}, "が東京") \)，\( (att_{2}, "東京へ") \)，\( (att_{3}, "が東") \)，\\
\( (att_{4}, "東京") \)，\( (att_{5}, "京へ") \)，\( (att_{6}, "漢漢") \)，\( (att_{7}, "漢漢") \)
\end{center}
\bigskip

``東'' と ``京'' の間には，単語境界がないので，クラスは\( -1 \)である．
そして，決定リスト作成の step 2 で示したように，以下の証拠の頻度に 1 が足される．

\bigskip
\begin{center}
\( ((att_{1},"が東京"),-1) \)，\( ((att_{2},"東京へ"),-1) \)，\( ((att_{3},"が東"),-1) \)，\\
\( ((att_{4},"東京"),-1) \)，\( ((att_{5},"京へ"),-1) \)，\( ((att_{6},"漢漢"),-1) \)，\( ((att_{7},"漢漢"),-1) \)
\end{center}
\bigskip

この頻度に加算される 1 という数値に重みを反映させる．

例えば，決定リスト\( h_k \) により上記例文の4番目の文字 ``東'' と 5 番目の文字 ``京'' の間
の判定クラスが\( +1 \)と判定された場合，この判定は不正解である．
そこで次の決定リスト\( h_{k+1} \)を作成するときに，上記の７つの各証拠の頻度に 1 ではなく，
重み自身を加える．

つまり決定リストを作成する際には各訓練データには重みがついているとして，
その重みが決定リスト作成の step 2 で各証拠と正解の組に付加する数値とする．
\mbox{図\ref{algo}}のアルゴリズムでは正規化するために重みの総和が１になっているが，
ここでは重みの最小値が１となるようにして計算を簡単にした．
このため最初の決定リストを作成する際の各訓練データの重みは１であり，
２回目では正解のデータの重みは１で変化せず，不正解の部分の重みが大きくなる．


\section{考察}


本手法での判別の出力は 2 値であり，判別に使った判別力の値自体は利用されていない．
テストデータに対して判別力の値による正解率を調べるために，以下の調査を行った．
テストデータには 56,411 個所の判定位置があるが，
0 以上 1 未満の間の判別力で判定された位置は 83 個所であり，
その正解率は 57.83\% であった．
同様にして，1 以上 2 未満の間，2 以上 3 未満の間という具合いに順に調べていった
結果を示したものが\mbox{図\ref{kousatu2}}である．
このグラフからもわかるように，
判別に利用した判別力が小さいほど誤る確率が高くなる．
このような判別力の値を利用して，さらに誤りを減らせる工夫も可能であろう．

\begin{figure}[htbp]
\begin{center}
\atari(101.6,71.1)
\end{center}
\caption{判別力と正解率}
\ecaption{Identification strength and precision}\label{kousatu2}
\end{figure}

また本論文では分類問題の解法として決定リストを利用したが，
他の手法，例えば，決定木\cite{quinlan93}や最大エントロピー法\cite{ratnaparkhi98} の利用も可能である．
ただし本論文で利用した属性にあたるものを，それらの手法では単純には利用できない．
決定木を利用する場合，属性の数は 7種類であり問題ないが，bi-gram あるいは tri-gram にあたる
属性の値の種類数が非常に多い．このため決定木の各ノードから出る枝の数が膨大になり，
現実的には決定木を作成できない．
また最大エントロピー法では素性の設定と素性パラメータの算出が必要となる．
素性は本論文で述べた証拠自体となるため，素性の種類は頻度 7 で間引いて
約 14 万弱である．最大エントロピー法で利用できる素性の数は現実的には，
数万が限度であるために，最大エントロピー法の利用も現実的には無理がある．
文字ベースの手法を利用する場合には，bi-gram や tri-gram などの情報を直接
利用できる決定リストは現実的に有効な選択である．

本論文では単語分割を分類問題としてみなして解決した．
分類問題とみなした場合，精度に関わる最も大きな要因は属性の選択である．
アダブーストを利用するという枠組みでは，属性の設定はさらに考慮すべきである．
ブースティングは弱学習アルゴリズムに対して利用できる．具体的には
精度が 50\% を越えるようなアルゴリズムであれば適用できる．
つまり作成できた決定木などの分類器自体の精度はそれほど高い必要はない．
属性をうまく考慮して決定リストの精度を上げるよりも，
作成される決定リストの精度は低いが，ブースティングにより精度が増して
ゆくような属性を設定するアプローチも有望である．
いくつかの実験を行った結果，以下の点が確認できた．
\begin{itemize}
\item 属性を増やす，間引きの頻度を調整する，などの工夫を入れて
決定リストの精度を上げた場合，ブースティングでは精度が上がらなかった．
\item 属性を単純化して決定リストの精度を若干下げた場合，ブースティングによって精度は
上がるが本実験で行った結果以上には精度は上がらなかった．
\end{itemize}
\noindent
結論的には本論文で設定した属性の情報を利用する上では，本論文で示した値程度
が限界に近いと感じられた．

分類誤りの原因を追求すると，訓練データに現れない表現あるいは頻度の低い表現の
部分で分類が誤っている\footnote{先の実験により示した本手法が検出できなかった未知語の
出現数（336）から考えて，全体の誤りの数（851）が多いようにも感じられる．
しかしこれは，本実験では頻度7以下の証拠を間引いているために，
本手法における未知語の実質的な総数は，先の実験で示した数よりも多いことによる．}．
これは未知語の問題そのものであり，
未知語への対処が単語分割の中心の課題と言える．
この解決策は3つ考えられる．1つ目は規則の一般化を精度良く行うことである．
例えば文字クラス\cite{oda99}などの導入などが考えられる．
2つ目は別リソースの利用である．例えば辞書の利用である．
単語分割に本手法の分類手法と辞書による最長一致法を利用することも考えられる．
3つ目は訓練データの拡充である．
事例ベースの手法\cite{yamashita98,ito99}は訓練データつまり事例を大規模化することで精度が上がる．
ただし大規模な正解付きの訓練データが用意できない現状では，
正解のない訓練データをどう使うかが鍵となる\cite{shinno00}．
１つ目のアプローチ以外は，未知語の検出に対して理論的な保証がない．
しかしだからといって，単語分割を文字ベースの手法によって解くことに意味がないわけではない．
辞書に基づいた分割では数値表現や字種区切りが有効になるような未知語しか
解析できず，解析できる未知語が限定されている．このような未知語の多くは，
実験に示したように，本手法でもその多くを検出できる．
さらに文字ベースの手法では，その他のタイプの未知語も検出できる
場合が多々あるが，辞書に基づいた分割では確実に検出できない．この違いは大きい．

最後に本手法のアプローチは解析が決定的になるという長所もあることを付記しておく\cite{shinnou00}．
通常の形態素解析システムも現実的にはほぼ文字数に比例した時間で解析が行えるので，
決定的であるということはそれほど大きな長所ではない．ただし理論的に線形時間での
解析を保証できることには意味がある．


\end{document}



