================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:2, score:0.21916] 従来の文節まとめあげは，人手規則による手法と機械学習による手法の二つに大きく分けられる．
[i:3, score:0.20794] 前者は，長年の努力により非常に高い精度を得られているが，入力データ形式が固定であるために柔軟性に欠け，人手で規則を作成・保守管理するため多大な労力を要し，車載情報機器へ実装するには問題が大きい．
[i:5, score:0.29532] そこで本研究は，決定リストを用いる手法を発展させ，複数の決定リストを順に適用するだけという非常に簡明な文節まとめあげの手法を提案する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:20, score:0.22506] 従来の文節まとめあげは，人手によりまとめあげ規則を書き下す方法と，機械学習によって得た統計情報を利用する方法の二通りに大きく分けられる．
[i:21, score:0.21940] 人手により作成した規則を用いる方法としてはknp [CITE]があり，高い精度を得られているが，人手により規則を保守管理することは容易ではなく，車載情報機器には不向きであるといえる．
[i:24, score:0.38545] 本研究ではこれらの問題を解決し，従来手法と比べて遜色ない精度を持ち，保守管理が容易でかつ車載情報機器の求める厳しい条件に適した，複数決定リストの順次適用による文節まとめあげという新しい手法を考案した．

================================================================
[section type  : proposed_method]
[section title : 従来の研究]
================================================================
[i:27, score:0.00719] これらの手法について以下で説明する．
-----------------------------------------------------
  [subsection title : 人手規則による文節まとめあげ]
-----------------------------------------------------
  [i:lead, score:0.24331] 人手により作成した文節まとめあげの規則を利用する最もよく知られているツールに，knpがある．
.....
  [i:28, score:0.24331] 人手により作成した文節まとめあげの規則を利用する最もよく知られているツールに，knpがある．
  [i:29, score:0.26228] knpは文節に関する規則を人手で網羅することにより，99%以上という非常に高精度な文節まとめあげを実現している．
  [i:31, score:0.25887] knpへの入力は形態素解析ツールjuman [CITE]の出力に限定されており，文節まとめあげの規則もその形式に基づいて作成されている．
-----------------------------------------------------
  [subsection title : 機械学習による文節まとめあげ]
-----------------------------------------------------
  [i:lead, score:0.24312] 人手規則による文節まとめあげの持つ問題に対処でき，最近最も盛んに研究されているのが，大規模コーパスから機械学習により得た統計情報を利用して文節まとめあげを行う手法である[CITE]．
.....
  [i:45, score:0.33622] 村田らは，決定リストを用いた文節まとめあげの手法に排反な規則を組み合わせた手法を提案している．
  [i:53, score:0.40149] 村田らの手法は，文節に区切るあるいは区切らない確率が100%である規則を排反な規則と呼び，決定リストの手法に排反な規則を組み合わせて文節まとめあげを行う．
  [i:58, score:0.31088] 例えば，ある形態素の隙間の文節区切りを決定する時に図[REF_fig:村田リスト]のような規則のパターンが一致して適用可能である場合，決定リストの手法であれば，最初の規則Aが適用されるため「文節に区切らない」と決定される．

================================================================
[section type  : conclusion]
[section title : 本研究の文節まとめあげの手法]
================================================================
[i:68, score:0.00000] 
-----------------------------------------------------
  [subsection title : 複数決定リストの順次適用による文節まとめあげ]
-----------------------------------------------------
  [i:lead, score:0.01535] 本研究では，従来手法の問題点を解決するために次の点に着目した．
.....
  [i:78, score:0.49072] 文節まとめあげの処理は，村田らと同様に形態素解析済みのテキストに対して行い，形態素の隙間ごとにその前後の形態素の情報からn-gramリストを調べて文節を区切るか区切らないかを決定する処理とした．
  [i:82, score:0.37282] n-gramリスト中に規則が見つかり，文節に区切る数が区切らない数よりも多い場合には区切りを入れ，少ない場合には区切らないこととする．
  [i:86, score:0.41983] 本手法の最大の特徴は，このように6種類のn-gramリストを順番に調べるだけで文節まとめあげを行う，という非常に簡明な点である．
-----------------------------------------------------
  [subsection title : n-gramリストの取得方法]
-----------------------------------------------------
  [i:lead, score:0.24682] 各n-gramリストの要素は，大規模コーパスから機械学習によって得る．
.....
  [i:89, score:0.24682] 各n-gramリストの要素は，大規模コーパスから機械学習によって得る．
  [i:91, score:0.24259] 京大コーパスにはあらかじめ詳細な形態素の情報と文節区切りの情報が付与されているので，形態素の隙間ごとに文節に区切る数と区切らない数を数えて，それを確率の高い順に並べて保持する．
  [i:94, score:0.20708] 以上のようにして得られた品詞2-gramの学習結果の決定リストの例を図[REF_tab:学習結果例]に示す．

================================================================
[section type  : experiment_result]
[section title : 実験と考察]
================================================================
[i:95, score:0.00000] 
-----------------------------------------------------
  [subsection title : 実験方法]
-----------------------------------------------------
  [i:lead, score:0.01672] 本手法の性能を評価するため，評価システムを作成して以下の実験を行った．
.....
  [i:97, score:0.23817] 6種類のn-gramリストを適用する数や順序を変化させる実験
  [i:101, score:0.15155] n-gramや条件の追加実験
  [i:102, score:0.09201] 1.,3.,4.,5.の実験の学習コーパスには，京大コーパスの最初の10000文を利用し，2.の実験には，京大コーパスを最初から1000文ずつ10000文まで変化させて利用した．
-----------------------------------------------------
  [subsection title : 評価基準]
-----------------------------------------------------
  [i:lead, score:0.21398] 本研究の文節まとめあげの評価基準には，村田らが用いたF値を採用した．
.....
  [i:105, score:0.21398] 本研究の文節まとめあげの評価基準には，村田らが用いたF値を採用した．
  [i:108, score:0.13117] ここで，[MATH]を評価システムが文節に区切った数，[MATH]をテストコーパスで文節に区切られている数(正解の区切り)，[MATH]を両者の文節区切りが一致している数とする．
  [i:110, score:0.12056] 例えば，次のようなテストコーパスの文節区切りと評価システムの出力がある時のF値の計算例を示す．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, score:0.24681] 6種類のn-gramリストを用いる時に，n-gramリストを用いる数や適用する順序により精度が変化すると考えられる．
.....
  [i:132, score:0.28448] 学習結果を利用する割合を，10000文を学習した各n-gramリストの上位から10%，20%と10%ずつ増やし100%まで変化させて実験を行ったところ，図[REF_fig:一部利用]の結果を得た．
  [i:139, score:0.27784] 決定リストの手法では，確率，頻度，素性という順序でソートして用い，村田らの手法では，この決定リスト中の同じ確率となる規則の各頻度を足しあわせた結果により文節の区切りを判定した．
  [i:149, score:0.30919] 6種類のn-gramリストの排反な規則を考慮して実験を行ったところ，F値が99.26%に上昇した．
-----------------------------------------------------
  [subsection title : 処理速度]
-----------------------------------------------------
  [i:lead, score:0.23588] n-gramリストの学習と評価システムの処理速度の計測を行った．
.....
  [i:152, score:0.35533] [REF_subsec:n-gramリスト取得]節の図[REF_tab:学習結果例]で示した品詞2-gramの学習に関しては，学習プログラムの最適化は全く行わなかったが，計算機にSun Ultra1 133MHzを，プログラム言語にPerlを用いたところ，10000文の学習に要した時間は58秒(1文あたり5.8ms)と非常に高速であった．
  [i:154, score:0.29621] 6種類のn-gramリストを学習した結果は約41万規則で，圧縮を全く行わずに図[REF_tab:学習結果例]のようにテキストベースでデータを保持すると約14.4MB，圧縮を行うと約2MBとなった．
  [i:155, score:0.33147] また評価システムについても同様にアルゴリズムの最適化を全く行わなかったが，[REF_subsubsec:n-gramの数]節の実験に関して，計算機にSun Ultra1 133MHzを，プログラム言語にPerlを用いたところ，4種類のn-gramリストを用いた処理に要した時間は225秒(1文あたり22.6ms)，6種類のn-gramリストの場合には253秒(1文あたり25.4ms)と非常に高速であった．
-----------------------------------------------------
  [subsection title : 実験のまとめ]
-----------------------------------------------------
  [i:lead, score:0.01825] 以上の実験の結果を図[REF_fig:まとめ]のグラフにまとめた．
.....
  [i:158, score:0.29313] knp2.0b6の精度が非常に高いのは，京大コーパスがknp2.0b4の出力を人手で修正して作成されたものであり，その修正結果をさらにknpの文節まとめあげ規則に反映したためである．
  [i:159, score:0.06215] つまり，knp2.0b6の結果はクローズドテストにほぼ等しい．
  [i:161, score:0.16515] また，本手法が非常に簡明であること，車載情報機器への実装を最大の目標としていることを考慮すると，本手法は非常に優れているといえる．
-----------------------------------------------------
  [subsection title : 考察]
-----------------------------------------------------
  [i:lead, score:0.14111] 本手法のように非常に簡明な方法で99.38%という高い精度を得られる理由と，本手法のロバスト性について，[REF_subsec:実験結果]節で行った実験の結果に基づいて考察する．
.....
  [i:166, score:0.38717] これらのn-gramリストをそれぞれ1つだけ用いて文節まとめあげを行った場合の精度は，表[REF_tab:n-gram1つ]に示したとおりである．
  [i:167, score:0.40410] [REF_sec:文節まとめあげ]章で述べたように，本手法では文節に区切るか区切らないか決定できない場合のデフォルト処理を「文節に区切る」としているが，「文節に区切らない」とすると，それぞれの精度は表[REF_tab:n-gram1つ]のようになる．
  [i:176, score:0.40634] 同様にして適合率の高い順にn-gramリストを調べることで，最終的に高い精度での文節まとめあげが可能になる(図[REF_fig:本手法の概念])．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:194, score:0.40794] 本研究で提案した文節まとめあげの手法は，車載情報機器の求める条件を満たすよう考案したものであり，複数の決定リストを順次適用して文節の区切りを行うだけ非常に簡明かつ高速である．
[i:196, score:0.07668] また，本手法は非常に簡明であるため，他の手法の長所のみを導入することが容易である．
[i:197, score:0.16064] そのことを1-gramや排反な規則を組み合わせることにより示した．

