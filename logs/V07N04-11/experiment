実験と考察\label{sec:実験}

\subsection{実験方法}\label{subsec:実験方法}

本手法の性能を評価するため，評価システムを作成して以下の実験を行った．

\begin{enumerate}
\item 6種類のn-gramリストを適用する数や順序を変化させる実験
\item 学習コーパスの量を変化させる実験
\item 学習結果の一部分だけ利用する実験
\item 比較実験
\item n-gramや条件の追加実験
\end{enumerate}

1.,3.,4.,5.の実験の学習コーパスには，京大コーパスの最初の10000文を利用し，2.の実験には，京大コーパスを最初から1000文ずつ10000文まで変化させて利用した．
また，すべての実験のテストコーパスは京大コーパスの10001文目からの残り9956文を利用した．

学習コーパス，テストコーパスの内容は表\ref{tab:京大コーパス}の通りである．

\begin{table}
  \begin{center}
    \caption{京大コーパスの内容}
    
    
    
    \label{tab:京大コーパス}
    \begin{tabular}{l||r|r}
      \hline
      & 学習コーパス   & テストコーパス\\
      \hline
      \hline
      文の数           & 10,000  &   9,956\\
      \hline
      形態素の隙間の数 & 240,682 & 227,053\\
      \hline
      文節区切りの数   &  98,395 &  93,971\\
      \hline
    \end{tabular}
  \end{center}
\end{table}


\subsection{評価基準}\label{subsec:評価基準}

本研究の文節まとめあげの評価基準には，村田らが用いたF値を採用した．
F値はF-measureを意味し，適合率と再現率の調和平均から得られる．

適合率と再現率は，評価システムの出力とテストコーパスの内容を比較して，次のように計算する．
\begin{eqnarray}\label{eq:Eval}
  \begin{array}{rcl}
    適合率 & = & \dfrac{right}{result}\\[4mm]
    再現率 & = & \dfrac{right}{correct}
  \end{array}
\end{eqnarray}
ここで，$result$を評価システムが文節に区切った数，$correct$をテストコーパスで文節に区切られている数(正解の区切り)，$right$を両者の文節区切りが一致している数とする．
これらの調和平均を以下のように計算すると，F値が得られる．
\begin{displaymath}
  F = \left(\dfrac{\dfrac{1}{適合率}+\dfrac{1}{再現率}}{2}\right)^{-1}\times100(\%)
\end{displaymath}

例えば，次のようなテストコーパスの文節区切りと評価システムの出力がある時のF値の計算例を示す．
文中「｜」により文節の区切りを表すものとする．

\begin{quote}
  {\bold テストコーパス}：

  \hspace{10mm}昨日｜政府　は　，｜国会　移転　の｜候補地　を｜発表　した　．

  {\bold 評価システム}　：

  \hspace{10mm}昨日　政府　は　，｜国会｜移転　の｜候補地　を｜発表｜した　．

  \begin{displaymath}
    right=3,~~result=5,~~correct=4
  \end{displaymath}
  \begin{displaymath}
    適合率=\dfrac{3}{5},~~再現率=\dfrac{3}{4}
  \end{displaymath}
  \begin{displaymath}
    F=\dfrac{2}{\dfrac{5}{3}+\dfrac{4}{3}}\times100=66.67(\%)
  \end{displaymath}
\end{quote}


\subsection{実験結果}\label{subsec:実験結果}

\subsubsection{n-gramリストを用いる数や適用する順序を変化させる実験}\label{subsubsec:n-gramの数}

6種類のn-gramリストを用いる時に，n-gramリストを用いる数や適用する順序により精度が変化すると考えられる．
そこで，6種類のn-gramリストを用いる数や順序を変化させて実験したところ，図\ref{fig:n-gramの数}のような結果を得た．
ただし図中，n-gramリストを用いた数が1,2,3,4は4種類の2-gramリストだけを用いた結果で，数が5,6はさらに2種類の3-gramリストを加えた結果である．
n-gramリストを用いた数ごとのF値は，その数における最も精度の高かった順序の結果のみを示した．
また，それぞれn-gramリストを1つだけ用いた結果を表\ref{tab:n-gram1つ}に，最も精度の高かった時のn-gramリストの適用順を表\ref{tab:適用順}に示した．
表\ref{tab:n-gram1つ}中のデフォルト処理とは，n-gramリスト中で規則を見つけられなかった場合に適用する処理のことを表す．
本手法ではデフォルト処理として「区切る」を用いるが，比較のため「区切らない」場合の精度も示した．
また，表\ref{tab:n-gram1つ}中の被覆率は，規則を適用できた割合を示す．

\begin{figure}
  \begin{center}
    \begin{epsf}
    \epsfile{file=graph-1-10000-jis.eps,scale=0.8}
    \end{epsf}
    \begin{draft}
    \atari(216,152,1bp)
    \end{draft}
    \caption{n-gramリストを用いる数や順序による精度の変化}
    
    
    
    \label{fig:n-gramの数}
  \end{center}
\end{figure}

\begin{table}
  \begin{center}
    \caption{各n-gramリストの精度}
    
    
    
    \label{tab:n-gram1つ}
    \begin{tabular}{l|c|c|c|c|c|c|c|}
      ~                    & \multicolumn{3}{c|}{デフォルト処理：区切る}
      &                      \multicolumn{3}{c|}{デフォルト処理：区切らない}\\
      \cline{2-7}
      n-gramリスト         & 適合率  & 再現率  & F値
      &                      適合率  & 再現率  & F値     & 被覆率\\
      \hline
      品詞2-gram           & 92.91\% & 96.52\% & 94.68\%
      &                      92.91\% & 96.51\% & 94.68\% & 99.99\%\\
      単語表記2-gram       & 63.08\% & 99.79\% & 77.30\%
      &                      99.06\% & 55.20\% & 70.89\% & 62.08\%\\
      品詞細分類2-gram     & 96.73\% & 99.48\% & 98.08\%
      &                      98.27\% & 98.08\% & 98.17\% & 98.88\%\\
      単語表記＋品詞2-gram & 62.78\% & 99.95\% & 77.12\%
      &                      99.51\% & 54.90\% & 70.76\% & 61.51\%\\
      品詞3-gram           & 86.38\% & 96.09\% & 90.97\%
      &                      94.66\% & 93.78\% & 94.21\% & 95.49\%\\
      単語表記3-gram       & 44.78\% & 99.96\% & 61.85\%
      &                      99.84\% & 11.70\% & 20.95\% & 21.73\%\\
    \end{tabular}
  \end{center}
\end{table}

\begin{table}
  \begin{center}
    \caption{n-gramリストの最適な適用順}
    
    
    
    \label{tab:適用順}
    \begin{tabular}{c|l}
      \begin{minipage}[b]{5zw}n-gram\\リストの数\end{minipage}  &\\
      \hline
      1 & 品詞細分類 2-gram\\
      2 & 品詞細分類 2-gram → 品詞 2-gram\\
      3 & 単語表記＋品詞 2-gram → 品詞細分類 2-gram → 品詞 2-gram\\
      4 & 単語表記＋品詞 2-gram → 単語表記 2-gram → 品詞細分類 2-gram → 品詞 2-gram\\
      5 &
      \begin{tabular}{c}
        単語表記 3-gram → 単語表記＋品詞 2-gram → 単語表記 2-gram\\
        → 品詞細分類 2-gram → 品詞 2-gram
      \end{tabular}\\
      6 &
      \begin{tabular}{c}
        単語表記 3-gram → 単語表記＋品詞 2-gram → 単語表記 2-gram\\
         → 品詞細分類 2-gram → 品詞 3-gram → 品詞 2-gram\\
      \end{tabular}\\
    \end{tabular}
  \end{center}
\end{table}

この結果から，使用するn-gramリストの数が多いほど精度が上がるが，3つ以上のn-gramリストを用いるとほぼ精度が飽和することがわかった．


\subsubsection{学習コーパスの量を変化させる実験}\label{subsubsec:学習コーパス}

学習コーパスの量を変化させた時に，精度がどのように変化するか調べた．
学習コーパスは京大コーパスの最初から1000文ずつ増やし10000文まで変化させ，テストコーパスは京大コーパスの10001文目からの9956文で固定して実験を行った．
その結果を図\ref{fig:学習量}に示した．
図中，4種類は2-gramリストのみ，6種類はすべてのn-gramリストを利用した時の結果である
\footnote{
  適用順は表\ref{tab:適用順}の結果を利用している．
  }
．

\begin{figure}
  \begin{center}
    \begin{epsf}
    \epsfile{file=graph-2-10000-jis.eps,scale=0.8}
    \end{epsf}
    \begin{draft}
    \atari(232,152,1bp)
    \end{draft}
    \caption{学習コーパスの量による精度の変化}
    
    
    
    \label{fig:学習量}
  \end{center}
\end{figure}

この結果から，学習量が増すにつれて精度が向上することがわかった．
しかし，10000文学習した段階でほぼ飽和していると考えられる．


\subsubsection{学習結果の一部分だけ利用する実験}\label{subsubsec:一部利用}

学習をした結果は確率順に並べられており，リストの上位は確率が高いので確信度が高いといえ，逆にリストの下位は確率が50\%に近いので確信度が低いといえる．
そこで，確率の高いものだけを利用すると精度がどのように変化するか調べた．
この実験で調べる内容は，車載情報機器はメモリ容量の要求が厳しいため，学習結果のデータ量はできるだけ少ないことが求められるが，データ量を減らす時にどれだけの精度が得られるか，ということである．

学習結果を利用する割合を，10000文を学習した各n-gramリストの上位から10\%，20\%と10\%ずつ増やし100\%まで変化させて実験を行ったところ，図\ref{fig:一部利用}の結果を得た．
図中，4種類は2-gramリストのみ，6種類はすべてのn-gramリストを利用した時の結果である

\begin{figure}
  \begin{center}
    \begin{epsf}
    \epsfile{file=graph-3-10000-jis.eps,scale=0.8}
    \end{epsf}
    \begin{draft}
    \atari(232, 168,1bp)
    \end{draft}
    \caption{学習結果の一部利用による精度の変化}
    
    
    
    \label{fig:一部利用}
  \end{center}
\end{figure}

この結果，およそ60\%のデータを利用すれば100\%利用した時とほぼ同等の精度を得られることがわかった．

以上の
実験から，車載情報機器が要求する速度・データ容量などに柔軟に対応できることを示すことができた．


\subsubsection{比較実験}\label{subsubsec:比較実験}

本手法は，複数の決定リストを順次適用するというものであるが，これらの複数の決定リストを大きな一つの決定リストにまとめて考えると，n-gramの種類(素性)によりソートしてから確率でソートしたリストと考えることもできる．
このソートの順序は村田らの提案する手法とは逆で，村田らの手法では確率，頻度，素性という順序でソートしたリストを用いている．
そこで，本手法，村田らの手法，決定リストの手法の3手法を比較するために，本手法の決定リストを大きな1つの決定リストにまとめ，それを用いて比較実験を行った．
決定リストの手法では，確率，頻度，素性という順序でソートして用い，村田らの手法では，この決定リスト中の同じ確率となる規則の各頻度を足しあわせた結果により文節の区切りを判定した．
これらの実験結果を表\ref{tab:比較実験}に示した．

\begin{table}
  \begin{center}
    \caption{比較実験の結果}
    
    
    
    \label{tab:比較実験}
    \begin{tabular}{l|c|c|c|c}
      & n-gramリストの数 & 適合率  & 再現率  & F値\\
      \hline
      本手法         & 4 & 98.92\% & 99.41\% & 99.16\%\\
      本手法         & 6 & 99.07\% & 99.38\% & 99.23\%\\
      決定リスト手法 & 4 & 98.88\% & 99.16\% & 99.02\%\\
      決定リスト手法 & 6 & 99.07\% & 99.16\% & 99.12\%\\
      村田手法       & 4 & 98.90\% & 99.18\% & 99.04\%\\
      村田手法       & 6 & 99.10\% & 99.18\% & 99.14\%\\
    \end{tabular}
  \end{center}
\end{table}

この結果から，同じ評価基準で実験を行った場合には，本手法が最も優れていることが示された．


\subsubsection{n-gramや条件の追加実験}\label{subsubsec:追加実験}

本手法の最大の特徴は，非常に簡明な方法で充分な精度を得られることである．
非常に簡明であるので，従来手法の長所だけを組み合わせることも容易である．
そのことを示すため，京大コーパスの最初の10000文を学習コーパス，残りの9956文をテストコーパスとして以下のような2種類の追加実験を行った．

\begin{itemize}
\item 1-gramを利用する方法

  2-gramや3-gramだけでなく，1-gramが非常に有効となる場合も考えられる．
  例えば，読点や区点は前の単語に必ずつながり，次の単語とは必ず区切れる．
  そこで，6種類のn-gramリストに加えて1-gramリストを用いて実験を行ったところ，F値が99.31\%に上昇した．

\item 排反な規則を用いる方法

  村田らにより，排反な規則を用いる手法が高い精度を得られると報告されている
  \cite{Murata2000}
  ．
  6種類のn-gramリストの排反な規則を考慮して実験を行ったところ，F値が99.26\%に上昇した．

\end{itemize}

上記2種類の手法をすべて組み合わせて実験を行ったところ，村田らの手法よりも簡明であるが，99.38\%という非常に高いF値を得られた．



\subsection{処理速度}\label{subsec:処理速度}

n-gramリストの学習と評価システムの処理速度の計測を行った．

\ref{subsec:n-gramリスト取得}節の図\ref{tab:学習結果例}で示した品詞2-gramの学習に関しては，学習プログラムの最適化は全く行わなかったが，計算機にSun Ultra1 133MHzを，プログラム言語にPerlを用いたところ，10000文の学習に要した時間は58秒(1文あたり5.8ms)と非常に高速であった．
また，6種類のn-gramリストすべての学習に要した時間も，216秒(1文あたり21.5ms)と高速であった．

6種類のn-gramリストを学習した結果は約41万規則で，圧縮を全く行わずに図\ref{tab:学習結果例}のようにテキストベースでデータを保持すると約14.4MB，圧縮を行うと約2MBとなった．

また評価システムについても同様にアルゴリズムの最適化を全く行わなかったが，\ref{subsubsec:n-gramの数}節の実験に関して，計算機にSun Ultra1 133MHzを，プログラム言語にPerlを用いたところ，4種類のn-gramリストを用いた処理に要した時間は225秒(1文あたり22.6ms)，6種類のn-gramリストの場合には253秒(1文あたり25.4ms)と非常に高速であった．



\subsection{実験のまとめ}\label{subsec:まとめ}

以上の実験の結果を図\ref{fig:まとめ}のグラフにまとめた．
比較のため，knp2.0b4の精度とknp2.0b6
\cite{knp2.0b6}
の精度も示した．
knp2.0b6の精度が非常に高いのは，京大コーパスがknp2.0b4の出力を人手で修正して作成されたものであり，その修正結果をさらにknpの文節まとめあげ規則に反映したためである．
つまり，knp2.0b6の結果はクローズドテストにほぼ等しい．

\begin{figure}
  \begin{center}
    \begin{epsf}
    \epsfile{file=all-result-jis.eps,scale=0.66}
    \end{epsf}
    \begin{draft}
    \atari(404, 145,1bp)
    \end{draft}
    \caption{すべての実験の結果}
    
    
    
    \label{fig:まとめ}
  \end{center}
\end{figure}

本手法が従来の手法よりも優れていることは，\ref{subsubsec:比較実験}節の比較実験により示された．
また，本手法が非常に簡明であること，車載情報機器への実装を最大の目標としていることを考慮すると，本手法は非常に優れているといえる．


\subsection{考察}\label{subsec:考察}

本手法のように非常に簡明な方法で99.38\%という高い精度を得られる理由と，本手法のロバスト性について，\ref{subsec:実験結果}節で行った実験の結果に基づいて考察する．

\ref{subsubsec:n-gramの数}節の実験で，6種類のn-gramリストを適用する順序で最も高い精度を得られたのは，表\ref{tab:適用順}に示したように，

\begin{center}
  単語表記 3-gram $\rightarrow$ 単語表記＋品詞 2-gram $\rightarrow$ 単語表記 2-gram

  $\rightarrow$ 品詞細分類 2-gram $\rightarrow$ 品詞 3-gram $\rightarrow$ 品詞 2-gram
\end{center}
であった．
これらのn-gramリストをそれぞれ1つだけ用いて文節まとめあげを行った場合の精度は，表\ref{tab:n-gram1つ}に示したとおりである．
\ref{sec:文節まとめあげ}章で述べたように，本手法では文節に区切るか区切らないか決定できない場合のデフォルト処理を「文節に区切る」としているが，「文節に区切らない」とすると，それぞれの精度は表\ref{tab:n-gram1つ}のようになる．

本手法の評価基準であるF値は，式\ref{eq:Eval}に示すように文節区切りを基準としている．
そのため，デフォルト処理を文節に区切らないことにすると，得られる適合率は，n-gramリストにより「文節に区切る」と確定した個所が正しい区切りかどうか，という正確な値となる．

この適合率が，表\ref{tab:n-gram1つ}の右側の中で最も注目すべき値である．
この表から，先に適用されるn-gramリストほど適合率が高いことがわかる．
つまり本手法の文節まとめあげ処理は次のように考えることができる．
1つの形態素の隙間の文節区切りを確定するために，適合率の最も高いn-gramリストを最初に参照し，その中で見つけられれば最も高い適合率で文節区切りを確定できる．
しかし，適合率が高いと再現率は低くなるため，規則を適用できる個所は少なくなる．
そこで，そのn-gramリスト中で規則を見つけられなかった個所は，次に適合率の高いn-gramリストにより区切りを決定する．
同様にして適合率の高い順にn-gramリストを調べることで，最終的に高い精度での文節まとめあげが可能になる(図\ref{fig:本手法の概念})．

\begin{figure}
  \begin{center}
    \begin{tabular}{ccl}
      \fbox{1番目に高い適合率のn-gramリスト} & → 適用 & → 確定\\
      ↓\\
      非適用\\
      ↓\\
      \fbox{2番目に高い適合率のn-gramリスト} & → 適用 & → 確定\\
      ↓\\
      非適用\\
      ↓\\
      $\cdots$                               & → 適用 & → 確定\\
      ↓\\
      非適用\\
      ↓\\
      \fbox{最も低い適合率のn-gramリスト}    & → 適用 & → 確定\\
      ↓\\
      非適用\\
      ↓\\
      確定\\
      (文節に区切る)\\
    \end{tabular}
    \caption{本手法の処理の概念図}
    
    
    
    \label{fig:本手法の概念}
  \end{center}
\end{figure}

低い適合率のn-gramリストを最初に適用して確定を行えば，その低い適合率が最終的な精度に大きく影響することは容易に想像できる．
そのため，高い適合率のn-gramリストから順に適用するということは理想的な処理であるといえる．
このことは，村田らのが100\%の確率である排反な規則を最優先に考慮するという考えを拡張してより柔軟にした，と考えることもできる．

ただし，先に適用されるn-gramリスト中に51\%の確率の規則が存在する場合には，たとえ後に適用されるn-gramリスト中に100\%の確率の規則が存在しても，先のn-gramリストにより文節区切りが確定される．
本手法はいかに簡明に文節まとめあげを行うか，ということを目標としていたため，この点についての考慮は行わなかった．
しかし，さらに精度を向上させるためには，このような点も考慮して，決定リストの要素を並べる順序をどのようにするのが最適であるか，より詳しく調べる必要があると思われる．

次に，本手法のロバスト性について考察する．
本手法では，入力される形態素解析済みのデータは100\%正しいものとして扱っているが，実際には形態素解析ツールの精度は100\%ではない．
そこで，形態素解析ツールの出力に誤りがある場合に，本手法の文節まとめあげの精度がどのように変化するか調べた．

形態素解析ツールの出力の誤りには主に，付与する品詞の誤りや形態素の区切り誤りがある．
形態素の区切りの誤りには，一つの形態素を複数に区切る誤りや，複数の形態素を一つのまとめる誤りなどがあるため非常に複雑であり，ここでは品詞の誤りがある場合についてだけ考える．
ある形態素に品詞の誤りがある場合，3-gramを用いる時はその前後3個所の文節区切りに影響を及ぼし，2-gramを用いる時はその前後2個所の文節区切りに影響を及ぼす．
そのため，品詞の誤りが1つ生じた場合に必ず文節区切りを誤ると仮定すると，形態素解析から文節まとめあげに至る間に誤りが増加する割合は，表\ref{tab:n-gram1つ}の被覆率と表\ref{tab:適用順}の適用順から，
\begin{eqnarray*}
  誤りの増加率 & = & 3 \times 21.73\% + 2 \times ( 100\% - 21.73\% ) \times 61.51\% + \cdots\\
  & = & 2.49
\end{eqnarray*}
と求められる．
つまり，形態素解析が99.0\%(誤りが1\%)の精度であるとすると，本手法の精度は99.38\%-2.49\%=96.89\%ということになる．

従来の研究では，このような値が示されていないために単純にロバスト性を比較することはできない．
しかし，形態素解析を誤ると必ず文節まとめあげを誤ると仮定していることや，他の手法が3-gram以上の情報も用いているためより多くの誤りを引き起こす可能性があることを考えると，本手法は従来の手法よりロバストであると考えられる．



