本研究では，従来手法の問題点を解決するために次の点に着目した．
学習が容易で用いる情報の数が少ないこと
学習結果を利用して文節をまとめる方法が従来手法より簡明であること
精度が従来手法と同程度かそれ以上となること
これらを実現するために，複数決定リストの順次適用による文節まとめあげという新しい手法を考案した．
機械学習を用いる従来手法では，大規模コーパスから得られた様々なn-gram(主に2-gramから4-gram)が利用されている．
本手法では，1つの形態素の隙間に対して6種類のn-gramのそれぞれの決定リストだけを考慮するという非常に簡明な方法を用いる．
具体的には，品詞，単語表記，品詞細分類，単語表記＋品詞の4種類の形態素2-gramと，品詞，単語表記の2種類の形態素3-gramを要素とする決定リストを利用する (図[REF_fig:本手法])．
以下では，これらのn-gramを要素とする決定リストを，n-gramリストと呼ぶ．
文節まとめあげの処理は，村田らと同様に形態素解析済みのテキストに対して行い，形態素の隙間ごとにその前後の形態素の情報からn-gramリストを調べて文節を区切るか区切らないかを決定する処理とした．
例えば，2-gramの場合には[MATH]，[MATH]という連続する2つの単語の[MATH]と[MATH]の間，3-gramの場合には[MATH]，[MATH]，[MATH]という連続する3つの単語の[MATH]と[MATH]の間に注目し，その間の文節区切りを次のように決定する．
[MATH]，[MATH]，[MATH]の形態素を得る．
図[REF_fig:本手法]の6種類のn-gramリストを順番に調べる．
n-gramリスト中に規則が見つかり，文節に区切る数が区切らない数よりも多い場合には区切りを入れ，少ない場合には区切らないこととする．
この段階で[MATH]と[MATH]の文節区切りを確定し，処理を終了する．
n-gramリスト中に規則が見つからない場合，または文節に区切る数と区切らない数が等しい場合には，次のn-gramリストを調べる．
6種類すべてのn-gramリストを調べた結果，文節に区切るか区切らないか確定しない場合，デフォルト処理として文節に区切るものとする．
本手法の最大の特徴は，このように6種類のn-gramリストを順番に調べるだけで文節まとめあげを行う，という非常に簡明な点である．
村田らの手法では[REF_subsec:機械学習手法]節で示したように，1つの形態素の隙間に対して約3500回もの処理をしなければならない．
しかし，本手法では最大で[MATH]の処理でよいため，村田らの手法と比べて約[MATH]の処理量で文節まとめあげを行うことができる．
各n-gramリストの要素は，大規模コーパスから機械学習によって得る．
本研究では，学習コーパスとして京大コーパス[CITE]を利用した．
京大コーパスにはあらかじめ詳細な形態素の情報と文節区切りの情報が付与されているので，形態素の隙間ごとに文節に区切る数と区切らない数を数えて，それを確率の高い順に並べて保持する．
ただし，確率には文節に区切る確率か文節に区切らない確率の2種類があるが，高い方の確率を基準としてリストに並べた．
つまり，リストの最下位は確率50%となる．
以上のようにして得られた品詞2-gramの学習結果の決定リストの例を図[REF_tab:学習結果例]に示す．
本研究で提案した文節まとめあげの手法は，車載情報機器の求める条件を満たすよう考案したものであり，複数の決定リストを順次適用して文節の区切りを行うだけ非常に簡明かつ高速である．
それにもかかわらず，従来の手法と比較してより高い精度を得られることが示された．
また，本手法は非常に簡明であるため，他の手法の長所のみを導入することが容易である．
そのことを1-gramや排反な規則を組み合わせることにより示した．
今後は，本手法を係り受け解析の技術と融合させ，より高精度な係り受け解析の技術に応用し，音声合成の品質の向上に貢献しようと考えている．
