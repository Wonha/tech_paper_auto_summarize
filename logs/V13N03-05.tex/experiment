\section{評価実験}
\label{sec:fourth}

前節で述べたクラスタリングの効果および
大規模な訓練事例を利用することがどの程度項構造解析の精度向上に寄与するかを調査した．
まず，両実験で使用する実験データと訓練事例作成のための用例クラスタリングの設定，
項構造解析モデルについて説明し，最後に実験結果を示す．

\subsection{評価実験データ}
\label{ssec:data}

4つの動詞（「話す」，「発表する」，「発売する」，「増える」）
を用いて評価した．
これらの動詞は後述のテストデータのコーパス中に頻出する動詞であり，
それぞれの動詞が持つ項構造数は「話す：5」，「発売する：1」，「発表する：3」，「増える：2」である．
例として，
表\ref{tab:arg_dic_2}\,に「話す」の項構造辞書の項目を示す\footnote{その他の動詞の項構造辞書の項目は付録\ref{sec:sonota}\,を参照}．
この項構造辞書は
IPAL動詞辞書\cite{IPAL}を基に
今回収集した用例を参考に，それらの格交替を考慮しながら
作成したものである．
この4つの動詞に対して，毎日新聞社の新聞記事でテストデータ作成に用いた1ヶ月分を除いた，13年分の新聞記事
から
用例異なりを除いた8385用例を抽出した（抽出条件は\ref{ssec:class}\,の用例の収集を参照）．
この用例をクラスタリングし，各クラスタに項構造を対応付けて，項構造解析の訓練事例とした．

項構造解析実験のテストデータとして，
上の13年分の新聞記事から抜き出したある月の新聞記事から
対象動詞の用例を抽出し，用例異なりを除いた220用例にひとつずつ人手で項構造タグを付与したものを用いる．
ただし，
\ref{sec:third}\,節で述べたように(1)「は」，「も」，「無格」が兼務する表層格の曖昧性，
および(2)連体修飾節に関する曖昧性は
表層格パターンを用いてある程度解析可能であると考えられるため，今回のテストデータについては
「は」，「も」，「無格」の曖昧性は人手で解消し，
連体修飾節の被修飾名詞は取り除き
(3)，(4)の曖昧性の解消に焦点を当てて評価する．
また，(5)の接尾辞を伴うことによる格交替の曖昧性については，
文書中の約1割の述語が格交替を生じる接尾辞を伴って出現したが，訓練事例の抽出と同様に今回はそれらを除いて
評価実験を行った．
なお訓練事例，テストデータともに用例に項構造タグを付与する際，可能な項構造が複数あれば複数のタグを付与した．また項構造解析時には，
\ref{ssec:asa}\,の項構造解析モデルで複数のタグを持つ用例が選択された場合，複数の項構造解析結果を出力する．
表\ref{tab:train}\,に訓練事例，表\ref{tab:test}\,にテストデータ中の動詞とその項構造の出現回数を示す．
各動詞の項構造番号は，表\ref{tab:arg_dic_2}\,や付録\ref{sec:sonota}\,に示した動詞項構造辞書の項目番号と対応している．
評価実験では，動詞「増える」の場合，システムが出力すべき項構造の数は142個（5+7+65×2）である（表\ref{tab:test}\,参照）．

\begin{table}[tbp]
\begin{center}
\caption{動詞「話す」の項構造辞書の項目}
\small
\begin{tabular}{||llll|ll||} \hline\hline
\multicolumn{5}{||l}{述語:話す} &  \\
\multicolumn{1}{||l}{} & \multicolumn{4}{l}{語義:口に出して，ある事を人に知らせる．} &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{3}{l}{項構造 1 [agent, theme, beneficiary]} &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} &  & 表層格パタン & 用例 &  \\\cline{4-5}
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & が，を，に & 彼が 用件を 先方に 話す． &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & が，について，に & 彼が 事件について 警察に 話す． &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & が，まで，に & 先生が そんなことまで 生徒に 話す． &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & から，について，に & 私から 結婚について 親に 話す． &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & から，を，に & 彼女から 将来のことを 彼氏に 話す． &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{3}{l}{項構造 2 [agent, beneficiary, content]} &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} &  & 表層格パタン & 用例 &  \\\cline{4-5}
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} &  & が，に，と & 彼が 母に 明日出発すると 話す． &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{3}{l}{項構造 3 [agent, beneficiary, theme,  content]} &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} &  & 表層格パタン & 用例 &  \\\cline{4-5}
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & が，に，を，と & 妻が 私に 映画を すばらしかったと 話す． &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & が，に，について，と & 警察が 市民に 事件について 解決したと 話す． &  \\
\multicolumn{1}{||l}{} & \multicolumn{4}{l}{語義:複数の者で会話，討議する．} &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{3}{l}{項構造 4 [agent, theme]} &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} &  & 表層格パタン & 用例 &  \\\cline{4-5}
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & が，を & 政治家が 貿易摩擦問題を 話す． &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & が，について & 先生らが いじめについて 話す．  &  \\
\multicolumn{1}{||l}{} & \multicolumn{4}{l}{語義:ある言語を用いる．} &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} & \multicolumn{3}{l}{項構造 5 [agent, theme]} &  \\
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} &  & 表層格パタン & 用例 &  \\\cline{4-5}
\multicolumn{1}{||l}{} & \multicolumn{1}{l}{} &  & が，を & 彼が 英語を 話す． &  \\\hline \hline
\end{tabular}
\label{tab:arg_dic_2}
\end{center}
\end{table}


\begin{table}[htbp]
\begin{center}
\caption{訓練事例中の動詞とその項構造の出現回数}
\small
\begin{tabular}{|l||l|l|l|} \hline
動詞 & 出現回数 & 項構造の種類 & 各項構造の出現回数（項構造番号：出現回数） \\\hline\hline
話す & 1867 & 5 & 1：105，2：22，3：133，4：232，5：62，1+2+3：155， \\
 &  &  & 1+3：194，1+3+4：364，2+3：214，1+2+3+4+5：386 \\\hline
発表する & 2822 & 3 & 3：60，1+3：1286，2+3：918，1+2+3：558 \\\hline
発売する & 635 & 1 & 1：635 \\\hline
増える & 3061 & 2 & 1：138，2：232，1+2：2691 \\\hline
\end{tabular}
\label{tab:train}
\end{center}

\begin{center}
\caption{テストデータ中の動詞とその項構造の出現回数}
\small
\begin{tabular}{|l|l|l|l|} \hline
\multicolumn{1}{|l||}{動詞} & \multicolumn{1}{l|}{出現回数} & 項構造の種類 & 各項構造の出現回数（項構造番号：出現回数） \\\hline\hline
話す & 57 & 5 & 1：4，3：5，4：8，5：2，1+2+3：4，1+3：5，\ \ \ \ \ \ \ \  \ \ \ \ \\
 &  &  & 1+3+4：10，2+3：7，1+2+3+4+5：12 \\\hline
発表する & 76 & 3 & 3：4，1+3：33，2+3：24，1+2+3：15 \\\hline
発売する & 10 & 1 & 1：10 \\\hline
増える & 77 & 2 & 1：5，2：7，1+2：65 \\\hline
\end{tabular}
\label{tab:test}
\end{center}
\end{table}


\subsection{用例クラスタリングの設定}
\label{ssec:class}

\subsubsection{用例の収集}

項構造と対応付けるために収集できる用例には「は」，「も」，「無格」
を伴った用例があるが，これらは兼務する表層格の曖昧性があるため訓練事例としては収集しない．
また，格交替が生じる可能性のある接尾辞「れる」，「られる」，「せる」，「させる」，「たい」，「ほしい」，「もらう」，
「いただく」，「くれる」，「くださる」，「やる」，「あげる」，「できる」を伴う述語の用例や連体修飾節の被修飾名詞も
訓練事例としては収集しない．

\subsubsection{格要素ベースクラスタリング}
\label{sssec:cl1}

用例間の類似度の計算式は河原ら\citeyear{kawahara:02:a}の提案した
計算式\footnote{
用例間の対応する格の割合と，対応する格要素の類似度による計算式．詳しくは付録\ref{sec:furoku}\,を参照．
}
を用いた．ただし，異なる項構造の用例を誤ってマージしないように
次の制約を加えた．\\

\begin{description}
\item[・]一方の用例の格パタンが他方の用例の表層格パタンを包含する場合のみマージする．この制約により，
用例「彼\underline{が} 結婚について 両親に 話す」と
「私\underline{から} 結婚について 両親に 話す」を「彼\underline{が} 私\underline{から} 結婚について 両親に 話す」のように
「話す」のagentが2つ存在するといった誤ったマージを避ける．
\item[・]ボトムアップクラスタリングの際に類似度を再計算する用例ペアとして各ステップの初めの類似度計算で設定した閾値を
超えた用例ペアだけを対象にする．この制約により，
直前格を重要視しすぎないないように制御する．
\end{description}

格要素ベースクラスタリングでは，
3ステップのそれぞれで閾値を設定する必要がある．
今回は0.9，0.85，0.8とした．


\subsubsection{動詞ベースクラスタリング}

4つの動詞「話す」，「発表する」，「発売する」，「増える」（図\ref{fig:step3}\,における未知の動詞$T$）の用例クラスタリングに
「語る」，「公表する」，「売り出す」，「減る」（図\ref{fig:step3}\,における既知の動詞$S$）のタグ付き用例4551個を利用する．
このタグ付き用例は格要素ベースクラスタリングの結果に人手で
項構造タグを付与し作成したものである．

動詞ベースクラスタリングのステップ2の用例間の類似度計算には，格要素ベースクラスタリングと同じ類似度計算式を用いた．
ただし，用例の表層格パタンが同一のもののみ対象とし，閾値は0.85に設定した．


\subsection{項構造解析モデル}
\label{ssec:asa}

項構造解析モデルとしては，用例に対応する項構造候補の選択に最近傍法を用い，また
用例間の近さを計算するのにKurohashiら\citeyear{Kurohashi:94}が提案する計算方法を用いた．
この計算方法は分類語彙表\cite{BGH:93}を利用して名詞間の類似度を定め，また用例間の類似度に名詞間の類似度の和を用いている．
項構造解析の処理を説明する．\\

\begin{enumerate}
\item 入力文の格要素とタグ付き用例の対応付けを行う
\item 対応付けられたそれぞれの格要素について，入力文の名詞とタグ付き用例との間の類似度を計算する．
類似度の値は分類語彙表\cite{BGH:93}における2つの名詞の分類コードの一致するレベル
によって決定する．一致するレベルと類似度との関係を表\ref{level2}\,に示す．
\item 式1に従ってタグ付き用例と入力文の対応の評価値を計算し評価値の高い用例の持つ項構造から順に選択する．
\end{enumerate}

\begin{eqnarray}
評価値 = \left\{ \begin{array}{ll}
0 & if　l > n \\
sum \times \sqrt[]{\mathstrut \frac{1}{m}}  & otherwise
\end{array}
\right.
\end{eqnarray}
$n$：対応付けられた格要素数 \\
$l$：$n$ + (入力文側の対応付けられいない格要素数) \\
$m$：$n$ + (タグ付き用例側の対応付けられいない格要素数) \\
$sum$：対応付けられた格要素の類似度の和 \\

\begin{table}[t]
\begin{center}
\caption{黒橋らが提案した名詞間の類似度}
\begin{tabular}{|c|cccccccc|} \hline
レベル & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 一致 \\
\hline
類似度 & 0 & 0 & 5 & 7 & 8 & 9 & 10 & 11
\\
\hline
\end{tabular}
\label{level2}
\end{center}
\end{table}


\subsection{提案手法の有用性の評価実験}
\label{ssec:eva1}
提案手法の有用性を示すために次の3点を経験的に明らかにする．

\paragraph{(a)項構造タグ付与作業のコスト}
訓練事例作成のために，クラスタリングの結果得られるクラスタに項構造タグを人手で付与する必要がある．
今回の実験では，クラスタに項構造を付与する作業はクラスタを代表する用例に対して項構造タグを付与し，それをクラスタの項構造タグと考える．
そのため\textbf{クラスタリング結果のクラスタ数}でタグ付与作業のコストを評価する．
\paragraph{(b)タグ付与の品質}
項構造タグ付与誤りを調査するために，人手で各用例に項構造
タグを付与した．
また提案手法によって得られたクラスタに項構造を付与する作業は
クラスタを代表する用例に対して項構造タグを付与し，それをクラスタの項構造と考える．
これらの結果を比較し，
\textbf{タグ付与誤りの割合}でタグ付与の品質を評価する．
\paragraph{(c)項構造解析精度}
項構造解析は一文ごとに処理を行うため，省略などによって文脈を見なくては項構造を一意に決定することができない．
省略のある入力に対しては可能な項構造解析結果を漏れなく出力することが望まれる．そこで項構造解析の評価尺度として，
類似度の順で解析結果を出力していき，正解を漏れなく答えたときの精度で評価する．
つまり，{\bf 再現率が100％のときの精度}
\footnote{再現率＝出力された正解項構造数/正解項構造数，精度＝出力された正解項構造数/出力された項構造数}
で項構造解析を評価する．
なお評価は事例単位でなく，項構造単位で再現率と精度を計算した．
例えば，入力「父が事件について話す」の項構造は，
表\ref{tab:arg_dic_2}\,に示すように，項構造1[agent，theme，beneficiary]と項構造3[agent，beneficiary，theme，content]の可能性がある．
このような入力に関して，項構造1と項構造3の両方の答えを出力するまでの解析結果の精度で評価する．
ただし，タグ付き用例集合が入力文の正解を網羅していない場合は，その入力に対して可能なすべての項構造をシステムの出力とする．\\

上の(a)項構造タグ付与作業のコスト，(b)タグ付与の品質，(c)項構造解析精度について
以下の3つの手法を用いて訓練事例を作成し比較実験を行なった結果を表\ref{tab:res1}\,に示す．


\begin{enumerate}
\item ベースライン\\各用例に項構造タグを付与し訓練事例を作成．
\item 格要素ベースクラスタリング\\類似性A（ある動詞について同じ項構造を持つ用例は，格の出現パタンとそれぞれの格要素が類似している）に基づいた用例クラスタリングの結果に項構造タグを付与し訓練事例を作成．
\item 動詞ベースクラスタリング\\格要素ベースクラスタリングに加え，類似性B（意味的な類似性がある二つの動詞は，格の出現パタンとそれぞれの格要素が類似している）に基づいた用例クラスタリングの結果に項構造タグを付与し訓練事例を作成．
\end{enumerate}

\begin{table}[t]
\begin{center}
\caption{提案手法の作業コスト，品質と項構造解析精度}
\begin{tabular}{|l||c|c|c|} \hline
 & (a)\ [個] & (b)\ [％] & (c)\ [％] \\\hline\hline
{\footnotesize (1)ベースライン} & 8385 & 0.00 & 99.3 \\\hline
{\footnotesize (2)格要素ベースクラスタリング} & 2745 & 0.31 & 97.7 \\\hline
{\footnotesize (3)動詞ベースクラスタリング} & {\bf 1505} & 0.70 & 97.3 \\\hline
\end{tabular}
\label{tab:res1}
\end{center}
\end{table}


表\ref{tab:res1}\,の(a)項構造タグ付与作業のコストが示すように，格要素ベースクラスタリングによってベースラインの作業コストを約3分の1 (2745/8385)に削減し，
動詞ベースクラスタリングを用いてさらに半減（1505/2745）できた．
この結果より，用例のクラスタリングに一般的な名詞の
類似度を用いた手法に加え，類似する動詞のタグ付き用例を利用して，
未知の動詞の用例をさらにマージすることができたと言える．
また，動詞ベースクラスタリングは格要素ベースクラスタリングと比べ，タグ付与品質では
多少の低下が見られるものの，項構造解析の精度にはほとんど影響しなかった．
この結果から，項構造タグ付与作業済みの動詞が増えると，
ある動詞と意味的に類似する動詞が増加するので，より多くの動詞ベースクラスタリングが可能になり，
項構造解析精度を保ったままタグ付与作業のコストをさらに削減できると考えられる．
また，ベースラインと格要素ベースクラスタリングにおける項構造解析精度の差は，
\ref{ssec:clb}\,節で動詞ベースクラスタリングのねらいとして述べたように，
述語とその項の間の意味的な関係を示す項構造の項となる要素の集合は，
その要素自身が持つ意味だけでは表現することができないことを示す結果になっている．


\begin{figure}[t]
\begin{center}
         \includegraphics[width=\columnwidth,keepaspectratio]{20060219_0.eps}
    \caption{用例規模に対する用例異なり数とクラスタ数，項構造解析精度（テストデータ）}
    \label{fig:res2}
\end{center}
\end{figure}

\subsection{用例規模の異なりによる評価実験}
\label{ssec:eva2}
大規模な訓練事例を利用することがどの程度項構造解析精度の向上に寄与するかを評価する
ため，
用例集合の規模を変化させたときの(a)クラスタ数と(c)項構造解析精度の
変化を調べた．


図\ref{fig:res2}，\ref{fig:res4}\,は動詞ベースクラスタリングまで施したときの結果である．
横軸は用例の規模（年単位）であり，
棒グラフはそれぞれ用例異なり数とそれをクラスタリングすることによって得られるクラスタ数を示している．
また折れ線グラフは項構造解析精度（図\ref{fig:res2}：テストデータの220用例に対する結果，図\ref{fig:res4}：訓練事例の8385用例の10分割交差検定の結果）である．
なお図\ref{fig:res4}\,のクラスタ数，項構造解析精度は交差検定の結果の平均を示している．
図\ref{fig:res2}，\ref{fig:res4}\,を見ると，用例規模が増加すると収集できる用例異なり数は増加し続けているのに対し，
得られるクラスタ数は収束しつつある．
すなわち，用例規模を増やしたときに得られる新規の用例は収集済みの用例と
類似している可能性が高いため，項構造解析の精度向上に寄与する保証は必ず
しもない．しかし，異なるデータセットを用いた実験の結果，図3，4に示すよ
うに，用例規模を増やせば項構造解析精度が向上するということが経験的に明
らかになった．
これは，項構造解析においてはクラスタの重心ではなく，最近傍の用例を参照
しているためである．すなわち，用例規模を変化させたときのクラスタリング
の結果に大きな違いがないとしても，クラスタの外延的定義はより緻密になっ
ており，複数のクラスタ間の用例に対する類似度がより正確に見積もられてい
ると解釈できる．

ちなみに，「は」，「も」，「無格」の曖昧性を人手で解消せずに，Kurohashiら\citeyear{Kurohashi:94}の手法で項構造解析と
表層格の曖昧性解消を行った結果，項構造解析精度は90.8％であり，人手で曖昧性を解消した結果と比べ約7％低下している．この結果より，項構造解析精度を改善するにはこの種の多義性解消の問題に取り組む必要があることが明らかになった．
「は」，「も」，「無格」の曖昧性を解消するためには，
単純に用例を増やすだけでなく，
ゼロ照応解析や連体修飾の解析との統合について検討すべきであると考えられる．

\begin{figure}[t]
\begin{center}
         \includegraphics[width=\columnwidth,keepaspectratio]{20060219_1.eps}
    \caption{用例規模に対する用例異なり数とクラスタ数，項構造解析精度（交差検定）}
    \label{fig:res4}
\end{center}
\end{figure}




