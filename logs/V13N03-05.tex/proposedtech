    \documentstyle[graphicx,jnlpbbl]{jnlp_j_b5_2e}

\setcounter{page}{113}
\setcounter{巻数}{13}
\setcounter{号数}{3}
\setcounter{年}{2006}
\setcounter{月}{7}
\受付{2005}{11}{16}
\再受付{2006}{2}{22}
\採録{2006}{3}{28}

\setcounter{secnumdepth}{2}

\title{動詞項構造辞書への大規模用例付与}
\authorC{平野 徹\affiref{KUEE} \and 飯田 龍\affiref{KUEE} \and 藤田 篤\affiref{KUEE} \and 乾 健太郎\affiref{KUEE} \and 松本 裕治\affiref{KUEE}}
\headauthor{平野，飯田，藤田，乾，松本}
\headtitle{動詞項構造辞書への大規模用例付与}
\affilabel{KUEE}{奈良先端科学技術大学院大学情報科学研究科}
	{Graduate School of Information Science, Nara Institute of Science and Technology}
\jabstract{
本論文では，述語項構造解析の精度向上のために必要となる大規模な
項構造タグ付き事例を
効率的に作成する方法について議論する．
項構造タグ付き事例の効率的な作成方法にはさまざまな方法が考えられるが，本論文では
大規模平文コーパスから抽出した表層格パターンの用例集合を
クラスタリングし，得られたクラスタに項構造タグを付与することで
タグ付与コストを削減する手法を提案する．
提案手法では，(i)表層格パターン同士の類似性と(ii)動詞間の類似性という2種類の類似性を利用してクラスタリングを行う．
評価実験では，
実際に提案手法を用いて8つの動詞の項構造タグ付き事例を作成し，
それを用いた項構造解析の実験を行うことによって，提案手法の
クラスタリングの性能や，人手でタグ付き事例を作成するコストと項構造解析精度の関係
を調査した．
}
\jkeywords{項構造解析，交替，用例クラスタリング}

\etitle{Augmenting a Semantic Verb Lexicon with\\ a Large Scale Collection of Example Sentences}
\eauthor{Toru Hirano\affiref{KUEE} \and Ryu Iida\affiref{KUEE} \and Atsushi Fujita\affiref{KUEE} \and Kentaro Inui\affiref{KUEE} \and Yuji Matsumoto\affiref{KUEE}} 
\eabstract{
In this paper, we propose a method of reducing the cost of annotating examples with argument structure
 in order to increase accuracy of argument structure analysis.
First, a large raw corpus is parsed, and a large scale collection of example sentences is constructed
 from predicate-argument examples in the parsing results. Second, the collection of example sentences
 is clustered by using two similarities about verb. Finally, the acquired clusters are annotated with
 argument structure by human. We report preliminary experiments using our proposed method, and show that
 the method is effective in reducing the cost of annotating.
}
\ekeywords{Argument Structure Analysis, Alternations, Example Clustering}

\begin{document}
\maketitle
\thispagestyle{empty}

\section{用例の類似性に基づく項構造タグ付与の効率化}
\label{sec:third}

入力文の各動詞の項構造を解析するタスクには，
次の5種類の曖昧性の解消が必要である．

\begin{description}
\item[曖昧性(1) 「は」，「も」，「無格\footnotemark」が兼務する表層格の曖昧性]　\\
\footnotetext{無格とは，「明日東京に行く」の「明日」のように助詞のない格．}
「は」，「も」，「無格」が表層「ガ格」，「ヲ格」，もしくはそれ以外となる曖昧性．

\item[曖昧性(2) 連体修飾節に関する曖昧性]　\\
連体修飾節の述語と被修飾名詞との間に格関係がない外の関係（例えば，「魚を焼くにおい」の「焼く」と「におい」）と
格関係がある内の関係（「魚を焼く男」の「焼く」と「男」）の曖昧性．さらに，内の関係における被修飾名詞の表層格の曖昧性．

\item[曖昧性(3) 述語の取る項構造の曖昧性]　\\
動詞「話す」のように，項構造[agent, theme, beneficiary]や[agent, beneficiary, content]などの
複数の項構造を持つ述語が存在するために生じる曖昧性．
例えば，「女性が悲鳴をあげる」と「彼が彼女にプレゼントをあげる」の
動詞「あげる」のように，複数の語義を持つことによる曖昧性も含む．

\item[曖昧性(4) 格の意味役割の曖昧性]　\\
同じ述語の同じ表層格でも項構造中の意味役割が一意に決まらないという曖昧性．
例えば，「彼が扉をひらく」の表層ガ格「彼」は項構造中のagentに対応するのに対し，
「扉がひらく」の表層ガ格「扉」はthemeに対応する．
また表層「ニ格」のように時間，目的地，場所などさまざまな意味役割を担う表層格がある．

\item[曖昧性(5) 接尾辞を伴うことによる格交替の曖昧性]　\\
受身「れる，られる」や使役「せる，させる」によって項構造の意味役割と表層格の対応関係が
変化することによって生じる曖昧性．

\end{description}



この5種類の曖昧性のうち曖昧性(1)，(2)は，表層格レベルの問題であるため，河原ら\citeyear{kawahara:02:a}
の手法のように全自動で収集した用例を使って解消できる可能性がある．すなわち，
必ずしも
項構造情報を教示したデータが必要とならない．
一方，曖昧性(3)，(4)，(5)を解消するには述語の取り得る項構造と入力文とを照らし合わせるために，項構造情報のタグを付与したデータが必要となる．
本論文では曖昧性(3)，(4)の解消に
焦点をあて，
項構造タグ付与作業の
効率化を図る．
具体的には，同じ項構造に対応する用例を自動的にひとまとめにすることで
タグ付与作業のコスト削減を目指す．
曖昧性（5）は，本論文では取り扱わないが，各接尾辞で項構造の意味役割と表層格の対応関係に規則性があり
本論文で扱う項構造解析手法を拡張し解消できると考えられる．

問題設定として，
大量のタグなし用例と項構造辞書が与えられていると仮定する．
ここで，用例とは係り受け解析結果から述語とその係り受けを取り出したものを指す．
タグなし用例は，大規模な生コーパスの文書を係り受け解析することによって収集可能である．
また，図\ref{fig:arg_dic}\,に示すような項構造辞書を仮定する．
このような辞書は，Dorrの交替現象に基づいた大規模項構造辞書作成の研究により基盤ができているため，作成可能であると期待できる．
この項構造辞書では，
各述語に一つ以上の項構造が定義されており，各項構造に取りうる表層格パタンと小規模の用例が記述されているものとする．

以上の仮定のもとで，
大規模用例集合を次の二つの類似性に基づいてクラスタリングする．

\begin{description}
\item[類似性A：]ある動詞について同じ項構造を持つ用例は，格の出現パタンとそれぞれの格要素が類似している．
例えば，2つの用例「女性が悲鳴をあげる」と「こどもが大声をあげる」で
格の出現パタン「が，を」や対応する格の格要素（「女性」と「こども」，「悲鳴」と「大声」）が類似している性質をいう．
\item[類似性B：]意味的な類似性がある二つの動詞は，格の出現パタンとそれぞれの格要素が類似している．
これは，\citeA{levin:93}が提案する交替現象に基づく動詞分類の基本的な考え方であり，
意味的に類似する動詞「公表する」と「発表する」の用例「大統領が98年に計画を公表する」と「首相が10月にプランを発表する」において，
格の出現パタン「が，に，を」とそれぞれの対応する格の格要素「大統領」と「首相」，「98年」と「10月」，「計画」と「プラン」が類似するという性質をいう．

\end{description}



本論文では，類似性Aと
類似性Bに基づいて用例をクラスタリングする．
そしてクラスタに項構造を付与する作業はクラスタを代表する用例に対して項構造タグを付与し，それをクラスタの項構造タグと考える．
つまり用例クラスタリングで
得られたクラスタに対して人手でタグを付与するため，
いかにして異なる項構造を持つ用例を1つのクラスタに含めることなく，できるだけ少数のクラスタに用例をまとめあげるかが課題となる．
\ref{ssec:cla}\,で類似性A，
\ref{ssec:clb}\,で類似性Bに基づく用例クラスタリングについて述べる．



\subsection{格要素ベースクラスタリング}
\label{ssec:cla}

格要素ベースクラスタリングでは，
{\bf 類似性A}を利用することで，格の出現パタンや格要素が
類似する用例（例えば，「女性が悲鳴をあげる」と「こどもが大声をあげる」）
を自動的にまとめる．
\citeA{kawahara:02:a}の大規模平文コーパスから表層格フレーム辞書を自動構築する研究は
「動詞の用法を決定する重要な格要素は動詞の直前にくることが多く，
動詞と直前の格要素をペアにして考
えると動詞の用法はほとんど一意に決定される」という考えに基づいている．
本論文でも，彼らと同様にこの考えに基づき，
次の3つのステップでクラスタリングを行う．

\begin{enumerate}
\item {\bf 直前格とその要素が同じ}用例のクラスタリング
\item {\bf 直前格が同じ}用例のクラスタリング
\item {\bf 直前格が異なる}用例のクラスタリング
\end{enumerate}

各ステップで対象のクラスタ（用例）間の類似度を計算し，
設定する閾値を超えるクラスタ（用例）の組みの中で最も類似度の高い2つのクラスタをマージするボトムアップクラスタリングを行う．
また，クラスタ（用例）間の類似度として用例収集に用いた大規模平文コーパス中での用例の出現回数を考慮した類似度計算式
（詳細は付録\ref{sec:furoku}\,を参照）を用いる．この式は河原らによって提案されたものである．
上の順序で段階的にクラスタリングを行うことで，常に動詞の直前格の出現回数が直前格以外の格の出現回数よりも多くなるように処理を進めることができる．
その結果，類似度計算における動詞の直前格の重みが大きくなり，
動詞の直前格を重視した用例クラスタリングが可能となる．

クラスタリングの各ステップを例を用いて説明する．
最初に，ステップ1では例1に示すように直前格要素が同じ用例だけを対象にクラスタリングする．例1では，
一つ目の用例と二つ目の用例の類似度が高くこれらをマージした結果を示している．\\
\\
例1）\\
$
\left.
\begin{array}{rrr}
月:に & \underline{{\bf 案:を}} & 発表する\\
中旬:に & \underline{{\bf 案:を}} & 発表する\\
久しぶり:に & \underline{{\bf 案:を}} & 発表する
\end{array}
\right\}
\Longrightarrow 
\left\{
\begin{array}{rrr}
\{月,中旬\}:に & \underline{{\bf 案:を}} & 発表する\\
久しぶり:に & \underline{{\bf 案:を}} & 発表する
\end{array}
\right.
$

\ \\

次に，ステップ2ではステップ1の結果を入力とし，例2に示すように直前格が同じ用例だけを対象にクラスタリングする．
クラスタリングの例を例2に示す．\\
\\
例2）\\
$
\left.
\begin{array}{rrrr}
 & \{月,中旬\}:に & 案:\underline{{\bf を}} & 発表する\\
大統領:が & \{年,初め\}:に & 計画:\underline{{\bf を}} & 発表する
\end{array}
\right\}
$
\begin{flushright}
$
\Longrightarrow 
\begin{array}{rrrr}
大統領:が & \{月,中旬,年,初め\}:に & \{案,計画\}:\underline{{\bf を}} & 発表する
\end{array}
$\\
\end{flushright}

最後に，ステップ3ではステップ2の結果を入力とし，例3に示すように直前格が異なる用例だけを対象にクラスタリングする．
このステップ3のクラスタリングによって，例3に示すような
表層格の出現順が「に，を」「を，に」と順序が異なっている用例をマージ例えばできる．\\
\\
例3）\\
$
\left.
\begin{array}{rrrr}
大領領:が & \{月,中旬,年,初め\}:に & \{案,計画\}:\underline{{\bf を}} & 発表する\\
 & \{プラン,計画\}:を & \{年,月\}:\underline{{\bf に}} & 発表する\\
\end{array}
\right\}
$
\begin{flushright}
$
\Longrightarrow 
\begin{array}{rrrr}
大統領:が & \{月,中旬,年,初め\}:\underline{{\bf に}} & \{案,計画,プラン\}:\underline{{\bf を}} & 発表する\\
\end{array}
$\\
\end{flushright}

正確に言えば，このクラスタリングは河原らが提案したクラスタリングとは異なる．
本クラスタリング手法と河原らが提案した手法の主な異なりはステップ(1)の存在であり，河原らの手法にはステップ(2)と(3)しか存在しない．
河原らの手法では動詞，動詞の直前格とその要素を最小単位と考えクラスタリングを開始する．
つまり動詞，動詞の直前格とその要素が同じならば同じクラスタであると判断している．
河原らは大規模平文コーパスからの表層格フレーム辞書自動構築を目的にクラスタリング手法を提案しており，
このように判断することは大きな問題にならない．
しかし，
我々の目的は項構造を考慮したクラスタリングであり，動詞，動詞の直前格とその要素が同じならば同じクラスタであると判断することが大きな問題となる．
そのためにステップ(1)を導入した．これ以外にも異なる項構造を持つ用例やクラスタが誤ってマージされないようにいくつか工夫する必要がある．
詳細は\ref{sssec:cl1}\,節で述べる．


\subsection{動詞ベースクラスタリング}
\label{ssec:clb}

動詞ベースクラスタリングでは，
{\bf 類似性B}に基づき，同じ項構造に対応する意味的に類似する動詞の用例（例えば，「大統領が98年に計画を公表する」と「首相が10月にプランを発表する」）
を自動的にまとめる．
具体的には，動詞$T$の用例をクラスタリングするのに動詞$T$と類似する動詞$S=\{S_{1},S_{2},...,S_{n}\}$の用例を利用する．
動詞集合$S$をどのように選択するか，また各動詞$S_{i}$の用例をどのように利用するかにはさまざまな方法が考えられるが，
今回は動詞を1つだけ用いることにしてクラスタリング手法を検討する．
また，本クラスタリングは類似する動詞の一方の用例に項構造タグを付与した結果を利用する．
つまり，すでに人手で項構造タグが用例に付与された動詞$S_{a}$を用いて，動詞$S_{a}$と類似する動詞$T$の用例集合を
次の3つのステップでクラスタリングする．
なお，本クラスタリングの入力は格要素ベースクラスタリングの結果である．\\

\begin{enumerate}
\item 表層格が最も多い用例
を動詞$T$のクラスタを代表する用
例として選択する．
\item (1)で選択された用例と動詞$S_{a}$の用例の中で表層格パタンが同じでかつ最
も類似する用例を対応付ける． 
\item 動詞$T$の異なるクラスタに属する用例が動詞$S_{a}$の同じ項構造の用例に
対応付けられた場合に，動詞$T$側の2つのクラスタをマージする．\\
\end{enumerate}

\begin{figure}[t]
  \begin{center}
        \includegraphics[width=0.85\columnwidth,keepaspectratio]{clip021.eps}
  \end{center}
  \caption{動詞の類似性に基づくクラスタリング}
  \label{fig:step3}
\end{figure}

まずステップ1では，格要素ベースクラスタリングによってできたクラスタにおいて，
各クラスタを構成する用例で最も多くの表層格を持つ用例をそのクラスタを代表する用例とする．
例えば，「首相が10月にプランを発表する」と「5月に計画を発表する」の用例で構成されるクラスタの例を考える．
これらの用例の表層格はそれぞれ「が，に，を」と「に，を」であり，表層格数は前者が3，後者が2であるため，前者の用例をこのクラスタを
代表する用例として選択する．
図\ref{fig:step3}\,では，
ステップ1で動詞$T$の1番目のクラスタの代表用例を$T_{1}$，2番目のクラスタの代表用例を$T_{2}$として選択したとする．ステッ
プ2で$T_{1}$，$T_{2}$のそれぞれと最も類似度の高い用例を動詞$S_{a}$側の用例集合から選択
し対応付ける．ここではそれぞれ用例$S_{a1}$と用例$S_{a2}$が対応付けられたとする．最
後に，動詞$S_{a}$側で用例$S_{a1}$，$S_{a2}$が同じ項構造であるというタグ付与情報を利用し
て，1番目と2番目のクラスタをマージする．
動詞ベースクラスタリングにおいても，用例間（動詞$T$の用例と動詞$S_{a}$の用例）の類似度計算式として，
格要素ベースクラスタリングと同じ計算式を用いる．但し本クラスタリングにおいては，表層格パタンが
同一の用例のみを類似度計算の対象とした．

動詞ベースクラスタリングでポイントとなるのはステップ3であり，本クラスタリングの狙いは次のとおりである．
格要素クラスタリングでは対応する格の格要素の類似度だけを考慮しているが，
実際には同じ項構造となる用例のなかには類似しない格要素を持つ用例も多い．
つまり，述語とある意味的な関係を持つ要素の集合は，
その要素自身が持つ意味だけでは表現することができないのである．
例えば，図\ref{fig:step3}\,の用例$T_{1}$「首相が10月にプランを発表する」と$T_{2}$「自衛隊が結果を発表する」は格要素の類似度に基づいたクラスタリングでは，
マージされなかった用例である．しかしながら，我々人間には同じ項構造であることがわかる．
このような格要素の類似性だけではマージできない用例を，類似した他の動詞の用例に人間が項構造を付与することで
与えた情報を利用してクラスタリングを行なうのが動詞ベースクラスタリングの狙いである．







\appendix

\section{用例間の類似度計算}
\label{sec:furoku}

\citeA{kawahara:02:a}は以下の類似度計算式を提案した．\\
単語$e_{1},e_{2}$の類似度$sim(e_{1},e_{2})$を，日本語語彙大系\cite{NTT:97}のシソーラスを利用して
以下のように定義する．
\begin{eqnarray}
sim_{e}(e_{1},e_{2}) &=& max_{x\in s_{1},y\in s_{2}} sim(x,y) \nonumber \\
sim(x,y) &=& \frac{2L}{l_{x}+l_{y}} \nonumber
\end{eqnarray}

ここで，$x,y$は意味属性を表し，
$s_{i}$（$i\in$ {1,2}）は単語$e_{i}$の
意味属性の集合を表す
\footnote{日本語語彙大系では，曖昧性を持つ単語を複数の意味属性に登録している．}
．
$sim(x,y)$は意味属性の$x,y$間の類似度であり，
$l_{x},l_{y}$は
それぞれ名詞意味属性の階層の根から$x,y$までの深さを表し，
$L$は根から$x,y$までの共通している
階層の深さを表す．
類似度$sim(x,y)$は0から1の値をとる．

用例$P_{1},P_{2}$の格の一致度$cs$は，$P_{1},P_{2}$に含まれるすべての格パタンに対する，$P_{1},P_{2}$の共通格に
含まれている格パタンの割合とし，
\begin{eqnarray}
cs &=& \frac{\sum^{n}_{i=1}\mid E_{1cc_{i}}\mid + \sum^{n}_{i=1}\mid E_{2cc_{i}}\mid}
{\sum^{l}_{i=1}\mid E_{1c1_{i}}\mid + \sum^{m}_{i=1}\mid E_{2c2_{i}}\mid} \nonumber
\end{eqnarray}
と定義する．ただし用例$P_{1}$中の格を$c1_{1}$,$c1_{2}$,$\cdots$,$c1_{l}$，用例$P_{2}$中の格を
$c2_{1}$,$c2_{2}$,$\cdots$,\\$c2_{m}$，$P_{1}$と$P_{2}$の共通格を$cc_{1}$,$cc_{2}$,$\cdots$,$cc_{n}$とする．また，$E_{1cc_{i}}$は
$P_{1}$内の格$cc_{i}$に含まれる格用例群であり，$E_{2cc_{i}}$,$E_{1c1_{i}}$,$E_{2c2_{i}}$も同様である．$\mid E_{1cc_{i}} \mid$
は$E_{1cc_{i}}$の頻度を表す．

用例$P_{1},P_{2}$の共通格に含まれる格用例群の類似度$sim_{E}(P_{1},P_{2})$は，格用例の類似度の和を正規化したもので，
\begin{eqnarray}
sim_{E}(P_{1},P_{2}) = \frac{\sum^{n}_{i=1} \sum^{}_{e_{1}\in E_{1cc_{i}}} \sum^{}_{e_{2}\in E_{2cc_{i}}} \mid e_{1}\mid \mid e_{2}\mid sim_{e}(e_{1},e_{2})}
{\sum^{n}_{i=1} \sum^{}_{e_{1}\in E_{1cc_{i}}} \sum^{}_{e_{2}\in E_{2cc_{i}}} \mid e_{1}\mid \mid e_{2}\mid} \nonumber
\end{eqnarray}
とする．


用例$P_{1},P_{2}$間の類似度は，格の一致度$cs$と$P_{1},P_{2}$の共通格の格用例群間の類似度の積とし，次のようにして計算する．
\begin{eqnarray}
類似度 &=& cs \cdot sim_{E}(P_{1},P_{2}) \nonumber
\end{eqnarray}

\newpage

\section{その他の動詞の項構造辞書の項目}
\label{sec:sonota}

\begin{table}[htbp]
\begin{center}
\caption{動詞「発表する」項構造辞書の項目}
\small
\begin{tabular}{||llll|p{7cm}l||} \hline\hline
\multicolumn{5}{||l}{述語:発表する} &  \\
 & \multicolumn{4}{l}{語義:新しい事実や考えなどを，広く世間に知らせる．} &  \\
 &  & \multicolumn{3}{l}{項構造 1 [agent, theme]} &  \\
 &  &  & 表層格パタン & 用例 &  \\\cline{4-5}
 &  &  & が，を & 研究者が 論文を 発表する． &  \\
 &  & \multicolumn{3}{l}{項構造 2 [agent, content]} &  \\
 &  &  & 表層格パタン & 用例 &  \\\cline{4-5}
 &  &  & が，と & 政府が 自衛隊を派遣すると 発表する． &  \\
 &  & \multicolumn{3}{l}{項構造 3 [agent, theme, content]} &  \\
 &  &  & 表層格パタン & 用例 &  \\\cline{4-5}
 &  &  & が，を，と & 政治家が 結果を 残念だと 発表する． &  \\\hline\hline
\end{tabular}
\label{tab:pred2}
\end{center}

\begin{center}
\caption{動詞「発売する」項構造辞書の項目}
\small
\begin{tabular}{||llll|p{7cm}l||} \hline\hline
\multicolumn{5}{||l}{述語:発売する} &  \\
 & \multicolumn{4}{l}{語義:売り出すこと．} &  \\
 &  & \multicolumn{3}{l}{項構造 1 [agent, theme]} &  \\
 &  &  & 表層格パタン & 用例 &  \\\cline{4-5}
 &  &  & が，を & SONYが 商品を 発売する． &  \\\hline\hline
\end{tabular}
\label{tab:pred3}
\end{center}

\begin{center}
\caption{動詞「増える」項構造辞書の項目}
\small
\begin{tabular}{||llll|p{7cm}l||} \hline\hline
\multicolumn{5}{||l}{述語:増える} &  \\
 & \multicolumn{4}{l}{語義:数量が多くなる．} &  \\
 &  & \multicolumn{3}{l}{項構造 1 [theme]} &  \\
 &  &  & 表層格パタン & 用例 &  \\\cline{4-5}
 &  &  & が & 映画館が 増える． &  \\
 &  & \multicolumn{3}{l}{項構造 2 [theme, goal]} &  \\
 &  &  & 表層格パタン & 用例 &  \\\cline{4-5}
 &  &  & が，に & 体重が 100\,kgに 増える． &  \\
 &  &  & が，まで & 川の水が 腰の位置まで 増える． &  \\
 &  &  & が，へ & 予算が 一千万円へ 増える． &  \\\hline\hline
\end{tabular}
\label{tab:pred4}
\end{center}
\end{table}


\begin{biography}
\biotitle{略歴}

\bioauthor{平野 徹}{
2003年和歌山大学システム工学部情報通信システム学科卒業．
2005年奈良先端科学技術大学院大学情報科学研究科博士前期課程修了．
同年日本電信電話株式会社入社．
現在に至る．
自然言語処理の研究に従事．}

\bioauthor{飯田 龍}{
2002年九州工業大学情報工学部知能情報工学科卒業．
現在，奈良先端科学技術大学院大学情報科学研究科博士後期課程在学中．
情報処理学会学生会員．
自然言語処理，特に照応解析の研究に従事．}

\bioauthor{藤田 篤（正会員）}{
2005年奈良先端科学技術大学院大学情報科学研究科博士後期課程修了．
京都大学情報学研究科産学官連携研究員を経て，
2006年より名古屋大学大学院工学研究科助手．
現在に至る．
博士（工学）．
自然言語処理，特にテキストの自動言い換えの研究に従事．
情報処理学会，ACL各会員．}

\bioauthor{乾 健太郎（正会員）}{
1995年東京工業大学大学院情報理工学研究科博士課程修了．
同年より同研究科助手．
1998年より九州工業大学情報工学部助教授．
1998年〜2001年科学技術振興事業団さきがけ研究21研究員を兼任．
2001年より奈良先端科学技術大学院大学情報科学研究科助教授．
2004年文部科学省長期在外研究員として英国サセックス大学に滞在．
現在に至る．
博士（工学）．
自然言語処理の研究に従事．
情報処理学会，人工知能学会，ACL各会員．}

\bioauthor{松本 裕治（正会員）}{
1977年京都大学工学部情報工学科卒．
1979年同大学大学院工学研究科修士課程情報工学専攻修了．
同年電子技術総合研究所入所．
1984〜85年英国インペリアルカレッジ客員研究員．
1985〜87年(財)新世代コンピュータ技術開発機構に出向．
京都大学助教授を経て，1993年より奈良先端科学技術大学院大学教授，
現在に至る．工学博士．専門は自然言語処理．
情報処理学会，人工知能学会，日本ソフトウェア科学会，認知科学会，
AAAI, ACL, ACM各会員．}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}
