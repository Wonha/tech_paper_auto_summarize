\section{実験と考察}
 
  \subsection{提案手法の再現率}
\label{SEC::RECALL}

提案手法の有効性を確認するため，まず，再現率，すなわ
  ち対象の未知語のうち正しく解析できる語の割合の調査を行った．すべての未
  知語をタグ付けした大規模なデータを作成するためには大きなコストが必要と
  なることから，本研究では未知語のタイプごとに個別に対象の未知語を含むデー
  タを作成し再現率の調査を行った．未知語のタイプを限定することで，正規表
  現等により対象の未知語を含む可能性のある文を絞り込むことができ，効率的
  にデータを作成できるようになる．具体的には，検索エンジン基盤
  TSUBAKI\cite{Shinzato2008}で使用されているWebページから，各未知語タイプ
  ごとに正規表現を用いて未知語を含む文の候補を収集し，そこから未知語を
  100個含む文集合を作成し，再現率の評価を行った．ただし，ここで使用した文
  集合には\ref{SEC::PRO}節で説明したルール・パターンの作成の際に参考にし
  た文は含まれていない．結果をUniDic\cite{Den2007}によるカバー率とともに
  表\ref{Table::Recall}に示す．ここで，UniDicによるカバー率とは対象の未知
  語100個のうちUniDicに含まれている語の数を表している．実際にUniDicを用い
  たシステムにおいて対象の未知語を正しく解析できるかどうかは考慮していな
  いため，UniDicによるカバー率はUniDicを用いたシステムが達成できる再現率
  の上限とみなせる．
  
  \begin{table}[b]
   \caption{未知語タイプごとの再現率とUniDicによるカバー率}
   \label{Table::Recall}
\input{04table06.txt}
  \end{table}  

  表\ref{Table::Recall}に示した結果から，すべての未知語タイプに対し提案手
  法は高い再現率を達成できることが確認できる．連濁を除く未知語タイプにお
  いてはUniDicによるカバー率よりも高い再現率を達成していることから，考え
  うる多くの未知語を人手で登録するアプローチに比べ，既知語からの派生ルー
  ルと未知オノマトペ認識のためのパターンを用いる提案手法のアプローチは，
  低コストで多くの未知語に対応できると言える．一方，連濁により濁音化した
  語については正しく認識できた語の数はUniDicでカバーされている語の数より
  も少なかった．たとえば以下の文に含まれている「がわら」は正しく認識する
  ことができなかった．

\begin{exe}
  \ex{赤\underline{がわら}の民家です。}
\end{exe}
  
  これは連濁と関係ない表現を連濁により濁音化したものであると認識しないよ
  うに，連濁により濁音化した形態素のノードに大きなコストを与えているため
  である．たとえば以下のような文があった場合，連濁により濁音化した形態素
  のコストを元の形態素のコストと同程度に設定した場合は「でまわり」を「手
  回り」が濁音化したものと解析してしまうため，濁音化した形態素のノードに
  は大きめのコストを与える必要がある．

\begin{exe}
  \ex{笑顔\underline{でまわり}の人たちを幸せにする。
  \label{EX::DEMAWARI}}
\end{exe}

  \begin{table}[t]
   \caption{解析済みブログコーパスにおいて2回以上出現した未知語の分類}
   \label{Table::Coverage}
\input{04table07.txt}
  \end{table}
 
  続いて，実コーパスにおける再現率の評価を行うため，解析済みブログコーパ
  ス\cite{Hashimoto2011}\footnote{Kyoto-University and NTT Blogコーパス 
  http://nlp.ist.i.kyoto-u.ac.jp/kuntt/}を用いた評価を行った．具体的には
  解析済みブログコーパスで1形態素としてタグ付けされている語のうち，2回以
  上出現し，かつ，JUMAN5.1の辞書に含まれていない230語を，村脇らによりコー
  パスから自動生成された辞書\cite{Murawaki2008}でカバーされているもの，そ
  れ以外でWikipediaにエントリを持つもの，それ以外で提案手法によりカバーさ
  れるもの，その他の4つに分類した．結果を表\ref{Table::Coverage}に示す．
  村脇らによる辞書，および，Wikipediaのエントリでもカバーされない未知語の
  うち異なり数でおよそ30\%，出現数でおよそ45\%が提案手法により解析できて
  おり，提案手法による未知語処理が実コーパスに対しても有用であることが確
  認できる．また，提案手法により解析できた未知語には，連濁による濁音化を
  除くすべての未知語タイプが含まれており，様々な未知語タイプが実コーパス
  において出現することが確認できた．


  \subsection{解析精度・速度の評価}   

  本論文で導入したルール・パターンを用いることで新たに認識された未知語の
  精度，および，解析速度の変化を調べるため，これらのルール・パターンを用
  いないベースラインモデルと提案手法を用いたモデルを以下の7つの観点から比
  較することにより提案手法の評価を行った．本節の実験ではJUMAN5.1をデフォ
  ルトのコスト設定のまま使用したものをベースラインモデルとした．
 
  \begin{enumerate}
   \item 解析結果が変化した100箇所中，解析結果が改善した箇所の数：$P_{100D}$
   \item 解析結果が変化した100箇所中，解析結果が悪化した箇所の数：$N_{100D}$
   \item 10万文あたりの解析結果が変化した箇所の数：$D_{100kS}$
   \item 10万文あたりの解析結果が改善した箇所の推定数：$P^{*}_{100kS}$
   \item 10万文あたりの解析結果が悪化した箇所の推定数：$N^{*}_{100kS}$
   \item 形態素ラティスにおけるノードの増加率：$N\!ode_{inc.}$
   \item 解析速度の低下率：$SP_{loss}$
  \end{enumerate}

  実験には検索エンジン基盤TSUBAKI\cite{Shinzato2008}で使用されているWebペー
  ジから収集した10万文を使用した．これらの文は平仮名を1字以上含み，かつ，
  全体で20文字以上で構成される文であり，\ref{SEC::PRO}節で説明したルール・
  パターンの作成の際に参考にした文は含まれていない．

  まず，$P_{100D}$と$N_{100D}$を算出するため，各ルール・パターンを用いた
  場合と用いなかった場合で解析結果が変化した箇所を100箇所抽出し，それらを
  改善，悪化，その他の3クラスに分類した．この際，基本的に分割箇所が変化し
  た場合は分割箇所の優劣を比較し，分割箇所に優劣がない場合で品詞が変化し
  た場合はその品詞の優劣を比較した．ただし，形態素区切りが改善した場合で
  あっても，名詞であるべき品詞が副詞となっている場合など，明らかに正しい
  解析と言えない場合はその他に分類した．たとえば「面白がれる」という表現
  は，JUMANでは子音動詞の可能形は可能動詞として登録されていることか
  ら，JUMANの辞書登録基準では1語となるべきである．しかし，連濁ルールを用
  いなかった場合は下記の例(\ref{EX::OMOSHIRO})aのように，連濁ルールを用
  いた場合は下記の例(\ref{EX::OMOSHIRO})bのように，解析結果は異なるもの
  の，いずれの場合も過分割されてしまうことから，このような場合はその他に
  分類した．

\begin{exe}
\ex \label{EX::OMOSHIRO}
\begin{xlist}
  \ex 面/白/が/れ/る
  \ex 面/白/がれる
\end{xlist}
\end{exe}

  また，$P^{*}_{100kS}$，および，$N^{*}_{100kS}$は，10万文あたりの解析結
  果が変化した箇所の数$D_{100kS}$を用いて，それぞれ以下の式により算出し
  た．
  \begin{align*}
   P^{*}_{100kS} & = D_{100kS} \times P_{100D}/100\notag\\   
   N^{*}_{100kS} & = D_{100kS} \times N_{100D}/100\notag
  \end{align*}
  ここで，各未知語タイプごとに推定誤差は異なっていることに注意が必要であ
  る．特に解析が悪化した箇所の数は少なことから$N^{*}_{100kS}$の推定誤差は
  大きいと考えられる．しかしながら，各未知語タイプごとに大規模な評価を行
  うコストは大きいことから本論文では上記の式から算出された推定数に基づい
  て考察を行う．

  解析精度の評価に加えて，最適解の探索時間に影響を与えると考えられること
  から形態素ラティスにおけるノードの増加率$N\!ode_{inc.}$，および，全体の
  解析速度への影響を調べるため速度の低下率$SP_{loss}$の計測も行った．これ
  らの評価結果を表\ref{Table::ResultAll}に示す．
  
  \begin{table}[t]
    \caption{各ルール・パターンを使用した場合の精度と速度}
 \label{Table::ResultAll}
\input{04table08.txt}
  \end{table}      

  表\ref{Table::ResultAll}に示す結果から提案手法を用いることで，ほとんど
  解析結果を悪化させることなく，また，解析速度を大きく下げることなく，多
  くの未知語を正しく処理できるようになることが確認できる．具体的には，す
  べてのルール・パターンを用いることで10万文あたり4,500個以上の未知語処理
  が改善するのに対し，悪化する解析は80個程度であると推定でき，速度の低下
  率は6.2\%であった．速度の低下率に関してはベースラインとした形態素解析器
  の実装に大きく依存するため，具体的な数値に大きな意味はないと言えるもの
  の，少なくとも提案手法は大幅な速度低下は引き起こさないと考えられる．ま
  た，ノードの増加率に対し解析速度の低下率が大きいことから，速度低下は最
  適パスの探索ではなく，主に形態素ラティスの生成の時間の増加により引き起
  されていると考えられる．以下ではルール・パターンごとの解析の変化につい
  て詳述する．


  \subsubsection{連濁による濁音化}

  表\ref{Table::ResultAll}に示したとおり，連濁パターンを導入した場合，新
  たに正しく解析できるような表現がある一方で，解析結果が悪化する表現が長
  音文字や小書き文字の置換・挿入ルールと比べ多く存在する．これは，長音文
  字や小書き文字を含む形態素はもともと非常に少ないのに対し，濁音を含む形
  態素は多く存在しているため，濁音が含まれているからといって連濁による濁
  音化であるケースが限定的であるためと考えられる．表\ref{Table::Rendaku}
  に連濁ルールを導入することにより解析結果が変化した例を示す．解析結果の
  変化を示した表において`/'は形態素区切りを，太字は解析結果が正解と一致し
  ていることを表す．「はさみ」が濁音化した形態素「ばさみ」や「ためし」が
  濁音化した形態素「だめし」など正しく認識できるようになった表現がある一
  方で，本来，格助詞「が」と形容詞「ない」から構成される「がない」という
  文字列を「かない」が濁音化した表現であると誤って解析されてしまうような
  表現が8例存在した．このような例を改善するためには，連濁化に関する静的な
  情報を活用して連濁処理の対象を制限することが考えられる．たとえばUniDic
  には連濁によって濁音化する語の情報が登録されておりこれを利用することが
  考えられる．
  
  \begin{table}[b]
   \caption{連濁ルールを導入することで解析結果が変化した例}
   \label{Table::Rendaku}
\input{04table09.txt}
  \end{table}

  \subsubsection{長音文字の置換}

  長音文字を置換するルールを導入することで解析結果が変化した例を表
  \ref{Table::MacronR}に示す．もともと正しく解析できていた表現がルールを
  導入することにより解析できなくなった例は存在せず，周辺の解析結果が悪化
  したものが「OKだよ〜ん」の1例のみ存在した．この例ではいずれも形態素区切
  りは誤っているものの，ベースラインモデルでは「だ」を判定詞であると解析
  できていたものが，提案手法を用いた場合は普通名詞であると解析されたた
  め，解析結果が悪化したと判定した．

  \begin{table}[b]
   \caption{長音文字を置換するルールを導入することで解析結果が変化した例}
   \label{Table::MacronR}
\input{04table10.txt}
  \end{table}


  \subsubsection{小書き文字の置換}

  小書き文字を置換するルールを導入することで解析結果が変化した例を表
  \ref{Table::KogakiR}に示す．長音記号の場合と同様にもともと正しく解析で
  きていた表現がルールを導入することにより解析できなくなった例は存在せ
  ず，周辺の解析結果が悪化したものが「ゆみぃの布団」の1例のみ存在した．こ
  の例でベースラインモデルでは格助詞であると正しく解析できていた「の」
  が，「いの」という地名の一部であると解析されたため，解析結果が悪化した
  と判定した．また，小書き文字を置換するルールを導入することで解析結果が
  改善した箇所の推定数は10万文あたり1,374箇所であり，全未知語タイプの中で
  もっとも多く，ほぼ悪影響もないことから，非常に有用なルールであると言え
  る．
  
  \begin{table}[b]
   \caption{小書き文字を置換するルールを導入することで解析結果が変化した例}
   \label{Table::KogakiR}
\input{04table11.txt}
  \end{table}


  \subsubsection{長音文字の挿入}

  挿入されたと考えられる長音文字を削除するルールを導入することで解析結果
  が変化した例を表\ref{Table::MacronI}に示す．長音文字の挿入に対処するこ
  とで解析が悪化した例は存在せず，「苦〜い」や「ぜーんぶ」など多くの表現
  が正しく解析できるようになった．長音文字を削除するルールを導入すること
  で解析結果が改善した箇所の推定数は10万文あたり1,093箇所であり，小書き文
  字の置換ルールに次いで多かった．解析結果が悪化した事例は確認できなかっ
  たことから，非常に有用性の高いルールであると言える．

  \begin{table}[b]
   \caption{長音文字を削除するルールを導入することで解析結果が変化した例}
   \label{Table::MacronI}
\input{04table12.txt}
  \end{table}


  \subsubsection{小書き文字の挿入}

  \begin{table}[b]
   \caption{小書き文字を削除するルールを導入することで解析結果が変化した例}
   \label{Table::KogakiI}
\input{04table13.txt}
  \end{table}

  挿入されたと考えられる小書き文字を削除するルールを導入することで解析結
  果が変化した例を表\ref{Table::KogakiI}に示す．長音文字の挿入の場合と同
  様に小書き文字に対処することで解析が悪化した例は存在せず，「さぁん」や
  「でしたぁぁぁ」など小書き文字の挿入を含む表現が正しく解析できるように
  なった．


  \subsubsection{反復型オノマトペ}

  反復型オノマトペの認識パターンを導入することで解析結果が変化した例を表
  \ref{Table::OnoR}に示す．解析結果に変化があった100箇所中，感動詞の反復
  である「あらあら」と「うんうん」の2例は誤ってオノマトペであると解析され
  たものであったが，この2例以外には解析が悪化した事例はなかった．反復型オ
  ノマトペの認識パターンを導入することで解析結果が改善した箇所の推定数は
  10万文あたり860箇所であり，小書き文字の置換ルール，長音文字の削除ルール
  に次いで多かった．

  \begin{table}[b]
   \caption{反復型オノマトペパターンを導入することで解析結果が変化した例}
\label{Table::OnoR}
\input{04table14.txt}
  \end{table}


  \subsubsection{非反復型オノマトペ}
  非反復型オノマトペの認識パターンを導入することで解析結果が変化した例を
  表\ref{Table::OnoP}に示す．解析結果が悪化した例は存在せず，「のっちょり」
  などのように本来オノマトペではない表現を誤ってオノマトペであると解析し
  た例は存在したが，それらはいずれもベースライン手法でも正しく解析できな
  い表現であった．また，非反復型オノマトペの処理を行うことによる速度の低
  下は確認できなかった．生成される形態素ラティスのノード数の増加率が
  0.008\%にとどまっていることから，正しいオノマトペ以外にはほとんどパター
  ンに該当する文字列が存在しなかったためであると考えられる．

  \begin{table}[b]
   \caption{非反復型オノマトペパターンを導入することで解析結果が変化した例}
 \label{Table::OnoP}
\input{04table15.txt}
  \end{table}



 