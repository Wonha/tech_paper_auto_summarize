ここでは決定リストを利用した単語分割の有効性を示すために，文字n-gramモデルに基づく単語分割法[CITE]との比較を行う．
文字n-gramモデルに基づく単語分割法では，概略，単語境界を付与した訓練データにおいて，単語境界の記号自体も一つの特殊文字として考えて，ある文字列の後に単語境界が生じる確率あるいは生じない確率を文字n-gramモデルに基づいて計算する．
最終的にはViterbiアルゴリズムなどの動的計画法を利用して，文字列の出現確率が最大になるように単語境界のあるなしの列を決定する．
これは文字ベースのHMMにおいて，遷移確率やシンボル出力確率をある確率モデルに基づいて計算したものと同等である．
訓練データとしては京大コーパス(約4万文)を利用した．
京大コーパスは人手でタグをつけたコーパスであり，正解付きの訓練データとして利用できる．
京大コーパスの中から950117.KNPというファイルに納められた1,234文をテストデータとした．
結果，訓練データは京大コーパスからテストデータを除いた35,717文である．
テストデータ1,234文の中には，単語境界を置くか置かないかを判定する位置が56,411個所存在する．
この56,411個所に対して正しいクラスを付与できた割合を正解率とする．
訓練データから文字tri-gram確率を求めるためにCMU-Cambridge Toolkitを利用した．
スムージングの手法としてはWitten-Bell discountingを用い，カットオフは頻度0と設定した[CITE]．
文字tri-gram確率からtri-gramモデルに基づく単語分割法を実装したシステムを作成し，テストデータに対して単語分割を行った．
結果，56,411個所の判定位置について，52,328個所で正しい判定を行い，4,083個所で誤った判定を行った．
つまり正解率は92.76%であった．
次に上記の訓練データを利用して本論文で提案した決定リストを作成した．
頻度7以下の証拠は間引いた．
作成できた決定リストの大きさは136,114であった．
この決定リストによりテストデータに対して単語分割を行った．
結果として，56,411個所の判定位置について，55,015個所で正しい判定を行い，1,396個所で誤った判定を行った．
つまり正解率は97.52%であった．
この値はtri-gramモデルに基づく単語分割法の正解率92.76%を大きく上回っており，本手法の有効性が示せた．
前述したアダブーストにより，決定リストのブースティングを行った．
ブースティングの回数を横軸に，テストデータに対する正解率%を縦軸にしたグラフが図[REF_graph]である．
図[REF_graph]からわかるように，ブースティングにより3組の決定リストを作成し，それらの重み付き多数決によって判別した結果が最も優れていた．
そのとき56,411個所の判定位置について，55,560個所で正しい判定を行い，851個所で誤った判定を行った．
つまり正解率は98.49%まで向上した．
ブースティングにより3組の決定リストを作成し，それらの重み付き多数決によって各文字間に単語境界の有無を判定する手法（以下これを本手法と呼ぶ）が，本実験において，どの程度の未知語を検出できたか調べる．
前述した訓練データ35,717文とテストデータ1,234文の正確な単語分割結果から，それぞれに含まれている単語文字列を取り出した．
ここでいう単語文字列とは，単純に単語分割された分割要素の文字列のことである．
つまり用言の活用語尾が異なるものも，異なる単語文字列として取り出すことに注意する．
結果，訓練データには914,392個（41,890種類）の単語文字列，テストデータには32,764個（6,479種類）の単語文字列が存在した．
そしてテストデータには含まれるが，訓練データには含まれない単語文字列が1,024個（832種類）存在した．
この1,024個（832種類）の単語文字列が本実験における未知語となる．
結論から述べると，本手法によりこの1,024個（832種類）の未知語の中で，正しく検出できたものは688個（562種類），つまり個数で67.2%，種類数で67.5%の検出率であった．
検出できた未知語の中には，字種区切りのような単純なヒューリスティクスから検出できるものも存在するので，本手法の未知語検出が，実質どの程度の有用性があるのかを示すために，対象の未知語を以下のように9タイプに分類した．
例えば，「押しつぶした」という単語文字列は，テストデータには含まれるが，訓練データには含まれないために，本手法では未知語として扱われる．
しかし通常の辞書を利用したシステムでは，「押しつぶした」の原型「押しつぶす」が辞書に登録されていれば，正しく解析できる．
訓練データには，「押しつぶす」の語尾変化形である単語文字列「押しつぶして」が含まれている．
そこで，通常のシステムの辞書には，原型「押しつぶす」が登録されていたと考え，「押しつぶした」は正しく解析できると考える．
ここでは，このようなタイプの未知語は，通常のシステムの用言の語尾変化の規則によって検出できるタイプの未知語として考える．
例えば，「飲みすぎて」という単語文字列は，テストデータには含まれるが，訓練データには含まれない．
しかも(1)の場合とは異なり，「飲みすぎて」の原型「飲みすぎる」を語尾変化させた単語文字列も訓練データに含まれない．
これは通常のシステムにおいても未知語となるものである．
例えば，「一万九千百八十五」や「２７・７」という単語文字列は未知語となっているが，通常のシステムはこれらの表現を数値表現として認識できる規則を持っている．
この種の未知語も通常のシステムで検出できるタイプの未知語とする．
「ＡＣ」「ＯＥＫ」「ＰＡＨ」の単語文字列である．
これらは字種区切りのような単純なヒューリスティクスから通常のシステムでも検出可能である．
例えば，「アロマセラピスト」や「スーザン」のような単語文字列である．
これらも字種区切りのような単純なヒューリスティクスから通常のシステムでも検出可能である．
例えば，「ごあいさつ」や「ぞろぞろ」のような単語文字列である．
これらの検出は通常のシステムでは不可能である．
例えば，「魁」や「鋼」のような単語文字列である．
通常のシステムでも未知語となるが，単語分割の他の候補が生じないために，結果的に正しく単語分割できる場合も多い．
例えば，「重文」や「三井造船」のような単語文字列である．
これらの検出は通常のシステムでは不可能である．
例えば，「寝泊まり」や「亡き後」のような単語文字列である．
これらの検出は通常のシステムでは不可能である．
上記9タイプの未知語の本手法による検出結果を表[REF_unknown]に示す．
同時に通常のシステムで想定できる検出結果も示す．
表[REF_unknown]に示すように通常のシステムの検出率は39.6%であり，本システムの検出率67.2%と大きく差がある．
これは本システムの未知語の検出能力の高さを示している．
また通常のシステムにより検出できるとした未知語のタイプ(1),(3),(4),(5),(7)に対して，本手法の検出率は83.3%であり，通常のシステムにより検出できる未知語の多くは本システムでも検出できると考えられる．
