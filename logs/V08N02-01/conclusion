考察


本手法での判別の出力は 2 値であり，判別に使った判別力の値自体は利用されていない．
テストデータに対して判別力の値による正解率を調べるために，以下の調査を行った．
テストデータには 56,411 個所の判定位置があるが，
0 以上 1 未満の間の判別力で判定された位置は 83 個所であり，
その正解率は 57.83\% であった．
同様にして，1 以上 2 未満の間，2 以上 3 未満の間という具合いに順に調べていった
結果を示したものが\mbox{図\ref{kousatu2}}である．
このグラフからもわかるように，
判別に利用した判別力が小さいほど誤る確率が高くなる．
このような判別力の値を利用して，さらに誤りを減らせる工夫も可能であろう．

\begin{figure}[htbp]
\begin{center}
\atari(101.6,71.1)
\end{center}
\caption{判別力と正解率}
\ecaption{Identification strength and precision}\label{kousatu2}
\end{figure}

また本論文では分類問題の解法として決定リストを利用したが，
他の手法，例えば，決定木\cite{quinlan93}や最大エントロピー法\cite{ratnaparkhi98} の利用も可能である．
ただし本論文で利用した属性にあたるものを，それらの手法では単純には利用できない．
決定木を利用する場合，属性の数は 7種類であり問題ないが，bi-gram あるいは tri-gram にあたる
属性の値の種類数が非常に多い．このため決定木の各ノードから出る枝の数が膨大になり，
現実的には決定木を作成できない．
また最大エントロピー法では素性の設定と素性パラメータの算出が必要となる．
素性は本論文で述べた証拠自体となるため，素性の種類は頻度 7 で間引いて
約 14 万弱である．最大エントロピー法で利用できる素性の数は現実的には，
数万が限度であるために，最大エントロピー法の利用も現実的には無理がある．
文字ベースの手法を利用する場合には，bi-gram や tri-gram などの情報を直接
利用できる決定リストは現実的に有効な選択である．

本論文では単語分割を分類問題としてみなして解決した．
分類問題とみなした場合，精度に関わる最も大きな要因は属性の選択である．
アダブーストを利用するという枠組みでは，属性の設定はさらに考慮すべきである．
ブースティングは弱学習アルゴリズムに対して利用できる．具体的には
精度が 50\% を越えるようなアルゴリズムであれば適用できる．
つまり作成できた決定木などの分類器自体の精度はそれほど高い必要はない．
属性をうまく考慮して決定リストの精度を上げるよりも，
作成される決定リストの精度は低いが，ブースティングにより精度が増して
ゆくような属性を設定するアプローチも有望である．
いくつかの実験を行った結果，以下の点が確認できた．
\begin{itemize}
\item 属性を増やす，間引きの頻度を調整する，などの工夫を入れて
決定リストの精度を上げた場合，ブースティングでは精度が上がらなかった．
\item 属性を単純化して決定リストの精度を若干下げた場合，ブースティングによって精度は
上がるが本実験で行った結果以上には精度は上がらなかった．
\end{itemize}
\noindent
結論的には本論文で設定した属性の情報を利用する上では，本論文で示した値程度
が限界に近いと感じられた．

分類誤りの原因を追求すると，訓練データに現れない表現あるいは頻度の低い表現の
部分で分類が誤っている\footnote{先の実験により示した本手法が検出できなかった未知語の
出現数（336）から考えて，全体の誤りの数（851）が多いようにも感じられる．
しかしこれは，本実験では頻度7以下の証拠を間引いているために，
本手法における未知語の実質的な総数は，先の実験で示した数よりも多いことによる．}．
これは未知語の問題そのものであり，
未知語への対処が単語分割の中心の課題と言える．
この解決策は3つ考えられる．1つ目は規則の一般化を精度良く行うことである．
例えば文字クラス\cite{oda99}などの導入などが考えられる．
2つ目は別リソースの利用である．例えば辞書の利用である．
単語分割に本手法の分類手法と辞書による最長一致法を利用することも考えられる．
3つ目は訓練データの拡充である．
事例ベースの手法\cite{yamashita98,ito99}は訓練データつまり事例を大規模化することで精度が上がる．
ただし大規模な正解付きの訓練データが用意できない現状では，
正解のない訓練データをどう使うかが鍵となる\cite{shinno00}．
１つ目のアプローチ以外は，未知語の検出に対して理論的な保証がない．
しかしだからといって，単語分割を文字ベースの手法によって解くことに意味がないわけではない．
辞書に基づいた分割では数値表現や字種区切りが有効になるような未知語しか
解析できず，解析できる未知語が限定されている．このような未知語の多くは，
実験に示したように，本手法でもその多くを検出できる．
さらに文字ベースの手法では，その他のタイプの未知語も検出できる
場合が多々あるが，辞書に基づいた分割では確実に検出できない．この違いは大きい．

最後に本手法のアプローチは解析が決定的になるという長所もあることを付記しておく\cite{shinnou00}．
通常の形態素解析システムも現実的にはほぼ文字数に比例した時間で解析が行えるので，
決定的であるということはそれほど大きな長所ではない．ただし理論的に線形時間での
解析を保証できることには意味がある．


おわりに


本論文では日本語単語分割を分類問題とみなし，
決定リストを利用してその問題を解いた．
本手法は未知語の問題を受けないという長所がある．
実験では，文字ベースの n-gram モデルに基づく単語分割法との比較を行い，
決定リストによる単語分割の方が優れていることを示した．
また分類問題ととらえることで，ブースティングの手法を適用できることも示した．
アダブーストを利用することによって，単独の決定リストよりも
さらに精度を向上させることができた．未知語の検出能力も高かった．
訓練データにない表現をどのようにカバーしてゆくかが今後の課題である．

\acknowledgment

本研究は（財）栢森情報科学振興財団の研究助成金（K11研IV第71号）によって行われました．
深く感謝します.



\bibliographystyle{jnlpbbl}
\bibliography{jpaper}

\newpage

\begin{biography}
\biotitle{略歴}
\bioauthor{新納 浩幸}{
昭和36年生．
昭和60年東京工業大学理学部情報科学科卒業.
昭和62年同大学大学院理工学研究科情報科学専攻修士課程修了.
同年富士ゼロックス，翌年松下電器を経て,
平成5年4月茨城大学工学部システム工学科助手．
平成9年10月同学科講師，
平成13年4月同学科助教授，現在に至る．博士(工学)．}
\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

