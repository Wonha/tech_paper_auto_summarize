 また本論文では分類問題の解法として決定リストを利用したが，
 他の手法，例えば，決定木\cite{quinlan93}や最大エントロピー法\cite{ratnaparkhi98} の利用も可能である．
 ただし本論文で利用した属性にあたるものを，それらの手法では単純には利用できない．
 決定木を利用する場合，属性の数は 7種類であり問題ないが，bi-gram あるいは tri-gram にあたる
 属性の値の種類数が非常に多い．このため決定木の各ノードから出る枝の数が膨大になり，
 現実的には決定木を作成できない．
 また最大エントロピー法では素性の設定と素性パラメータの算出が必要となる．
 素性は本論文で述べた証拠自体となるため，素性の種類は頻度 7 で間引いて
 約 14 万弱である．最大エントロピー法で利用できる素性の数は現実的には，
 数万が限度であるために，最大エントロピー法の利用も現実的には無理がある．
 文字ベースの手法を利用する場合には，bi-gram や tri-gram などの情報を直接
 利用できる決定リストは現実的に有効な選択である．

 本論文では単語分割を分類問題としてみなして解決した．
 分類問題とみなした場合，精度に関わる最も大きな要因は属性の選択である．
 アダブーストを利用するという枠組みでは，属性の設定はさらに考慮すべきである．
 ブースティングは弱学習アルゴリズムに対して利用できる．具体的には
 精度が 50\% を越えるようなアルゴリズムであれば適用できる．
 つまり作成できた決定木などの分類器自体の精度はそれほど高い必要はない．
 属性をうまく考慮して決定リストの精度を上げるよりも，
 作成される決定リストの精度は低いが，ブースティングにより精度が増して
 ゆくような属性を設定するアプローチも有望である．
 いくつかの実験を行った結果，以下の点が確認できた．
 \begin{itemize}
 \item 属性を増やす，間引きの頻度を調整する，などの工夫を入れて
 決定リストの精度を上げた場合，ブースティングでは精度が上がらなかった．
 \item 属性を単純化して決定リストの精度を若干下げた場合，ブースティングによって精度は
 上がるが本実験で行った結果以上には精度は上がらなかった．
 \end{itemize}
 \noindent
 結論的には本論文で設定した属性の情報を利用する上では，本論文で示した値程度
 が限界に近いと感じられた．

 分類誤りの原因を追求すると，訓練データに現れない表現あるいは頻度の低い表現の
 部分で分類が誤っている\footnote{先の実験により示した本手法が検出できなかった未知語の
 出現数（336）から考えて，全体の誤りの数（851）が多いようにも感じられる．
 しかしこれは，本実験では頻度7以下の証拠を間引いているために，
 本手法における未知語の実質的な総数は，先の実験で示した数よりも多いことによる．}．
 これは未知語の問題そのものであり，
 未知語への対処が単語分割の中心の課題と言える．
 この解決策は3つ考えられる．1つ目は規則の一般化を精度良く行うことである．
 例えば文字クラス\cite{oda99}などの導入などが考えられる．
 2つ目は別リソースの利用である．例えば辞書の利用である．
 単語分割に本手法の分類手法と辞書による最長一致法を利用することも考えられる．
 3つ目は訓練データの拡充である．
 事例ベースの手法\cite{yamashita98,ito99}は訓練データつまり事例を大規模化することで精度が上がる．
 ただし大規模な正解付きの訓練データが用意できない現状では，
 正解のない訓練データをどう使うかが鍵となる\cite{shinno00}．
 １つ目のアプローチ以外は，未知語の検出に対して理論的な保証がない．
 しかしだからといって，単語分割を文字ベースの手法によって解くことに意味がないわけではない．
 辞書に基づいた分割では数値表現や字種区切りが有効になるような未知語しか
 解析できず，解析できる未知語が限定されている．このような未知語の多くは，
 実験に示したように，本手法でもその多くを検出できる．
 さらに文字ベースの手法では，その他のタイプの未知語も検出できる
 場合が多々あるが，辞書に基づいた分割では確実に検出できない．この違いは大きい．
score of this paragraph is 3
