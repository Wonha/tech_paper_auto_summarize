================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.14461] 本論文では決定リストを弱学習器としたアダブーストによる日本語単語分割法を提案する．
[i:2, score:0.11019] この分類問題を決定リストを利用して解くことで単語分割が行える．
[i:9, score:0.14067] この値は、同じ訓練データから構築したtri-gramモデルに基づく単語分割法での正解率92.76%を大きく上回った．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:28, score:0.12545] 通常その確率を計算するためにtri-gramモデルを利用するが，常識的に考えても，前2文字から次の文字を予測することは難しく，文字ベースのHMM単独ではそれほどの精度は期待できない．
[i:32, score:0.14189] 分類問題を解くために設定する属性として，辞書情報を使わないことで，文字ベースの単語分割手法と同様未知語の問題を受けない．
[i:39, score:0.19804] その決定リストを利用した単語分割は，同じデータから学習させた文字tri-gramモデルに基づく単語分割法（文字ベースのHMMの一種）よりも高い精度を示した．

================================================================
[section type  : proposed_method]
[section title : 決定リストによる単語分割]
================================================================
[i:42, score:0.00000] 
-----------------------------------------------------
  [subsection title : 単語分割と分類問題]
-----------------------------------------------------
  [i:lead, score:0.08978] [MATH]文字からなる入力文を[MATH]（各[MATH]は文字を表す）とすると，日本語単語分割は文字[MATH]と[MATH]の間（[MATH]と名付ける）に単語境界がある([MATH])かない([MATH])かを与えることによって行える。
.....
  [i:43, score:0.08978] [MATH]文字からなる入力文を[MATH]（各[MATH]は文字を表す）とすると，日本語単語分割は文字[MATH]と[MATH]の間（[MATH]と名付ける）に単語境界がある([MATH])かない([MATH])かを与えることによって行える。
  [i:46, score:0.11608] 」という文に対しては，図[REF_zu1]のように各文字間にクラス[MATH]あるいは[MATH]を付与し，[MATH]の部分を単語境界に置き換えることにより単語分割が行える．
  [i:49, score:0.08025] 本論文では決定リストを利用して上記の分類問題を解く．
-----------------------------------------------------
  [subsection title : 決定リストの構築]
-----------------------------------------------------
  [i:lead, score:0.13145] 決定リストは帰納学習手法の一種であり，正解付きの訓練データから，分類規則を学習する．
.....
  [i:51, score:0.15403] 決定リストの場合，分類規則は証拠とクラスの組の順序付きの表となる．
  [i:53, score:0.13305] 実際の分類はリストの上位のものから順に，その証拠があるかどうかを調べ，その証拠があれば，それに対応するクラスを出力する．
  [i:65, score:0.13407] 全ての証拠と分類クラスの組を判別力の大きい順に並べる．
-----------------------------------------------------
  [subsection title : 属性の設定]
-----------------------------------------------------
  [i:lead, score:0.07566] 各文字間[MATH]がどのクラスに属するかを判断する材料が属性である．
.....
  [i:75, score:0.16191] 決定リストでは通常[MATH]という証拠を設けて，それ以下の判別力の証拠は表には入れない．
  [i:76, score:0.16134] [MATH]は文脈上の証拠が決定リストに存在しない場合の処理ととらえられるが，ここでは大分類の字種の情報が必ずヒットするので，[MATH]の証拠を含める必要がない．
  [i:77, score:0.13765] 6番目の属性からの証拠の最下位のものが，決定リストの最下位の証拠となる．
-----------------------------------------------------
  [subsection title : 利用例]
-----------------------------------------------------
  [i:lead, score:0.05136] 決定リストの利用例を示す．
.....
  [i:84, score:0.17520] 後述する実験で得られた決定リストを用いると，各証拠の分類クラスと判別力は以下の通りである．
  [i:85, score:0.11254] 表の中で``--''の記号のものは，決定リスト中にその証拠がないことをあらわす．
  [i:88, score:0.14055] この場合，証拠[MATH]が最も大きな判別力を持つので，この証拠の分類クラス+1が判定結果となる．

================================================================
[section type  : proposed_method]
[section title : アダブーストの利用]
================================================================
[i:125, score:0.14955] 例えば，決定リスト[MATH]により上記例文の4番目の文字``東''と5番目の文字``京''の間の判定クラスが[MATH]と判定された場合，この判定は不正解である．
[i:126, score:0.14014] そこで次の決定リスト[MATH]を作成するときに，上記の７つの各証拠の頻度に1ではなく，重み自身を加える．
[i:127, score:0.18663] つまり決定リストを作成する際には各訓練データには重みがついているとして，その重みが決定リスト作成のstep 2で各証拠と正解の組に付加する数値とする．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[i:130, score:0.00000] 
-----------------------------------------------------
  [subsection title : 文字 n-gram モデルに基づく単語分割法との比較]
-----------------------------------------------------
  [i:lead, score:0.14034] ここでは決定リストを利用した単語分割の有効性を示すために，文字n-gramモデルに基づく単語分割法[CITE]との比較を行う．
.....
  [i:131, score:0.14034] ここでは決定リストを利用した単語分割の有効性を示すために，文字n-gramモデルに基づく単語分割法[CITE]との比較を行う．
  [i:132, score:0.16610] 文字n-gramモデルに基づく単語分割法では，概略，単語境界を付与した訓練データにおいて，単語境界の記号自体も一つの特殊文字として考えて，ある文字列の後に単語境界が生じる確率あるいは生じない確率を文字n-gramモデルに基づいて計算する．
  [i:143, score:0.13460] 文字tri-gram確率からtri-gramモデルに基づく単語分割法を実装したシステムを作成し，テストデータに対して単語分割を行った．
-----------------------------------------------------
  [subsection title : ブースティングの効果]
-----------------------------------------------------
  [i:lead, score:0.10375] 前述したアダブーストにより，決定リストのブースティングを行った．
.....
  [i:153, score:0.10375] 前述したアダブーストにより，決定リストのブースティングを行った．
  [i:154, score:0.09616] ブースティングの回数を横軸に，テストデータに対する正解率%を縦軸にしたグラフが図[REF_graph]である．
  [i:155, score:0.16877] 図[REF_graph]からわかるように，ブースティングにより3組の決定リストを作成し，それらの重み付き多数決によって判別した結果が最も優れていた．
-----------------------------------------------------
  [subsection title : 未知語の検出]
-----------------------------------------------------
  [i:lead, score:0.26627] ブースティングにより3組の決定リストを作成し，それらの重み付き多数決によって各文字間に単語境界の有無を判定する手法（以下これを本手法と呼ぶ）が，本実験において，どの程度の未知語を検出できたか調べる．
.....
  [i:158, score:0.26627] ブースティングにより3組の決定リストを作成し，それらの重み付き多数決によって各文字間に単語境界の有無を判定する手法（以下これを本手法と呼ぶ）が，本実験において，どの程度の未知語を検出できたか調べる．
  [i:159, score:0.12891] 前述した訓練データ35,717文とテストデータ1,234文の正確な単語分割結果から，それぞれに含まれている単語文字列を取り出した．
  [i:167, score:0.14715] 例えば，「押しつぶした」という単語文字列は，テストデータには含まれるが，訓練データには含まれないために，本手法では未知語として扱われる．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[i:214, score:0.14652] 属性をうまく考慮して決定リストの精度を上げるよりも，作成される決定リストの精度は低いが，ブースティングにより精度が増してゆくような属性を設定するアプローチも有望である．
[i:216, score:0.14824] 属性を増やす，間引きの頻度を調整する，などの工夫を入れて決定リストの精度を上げた場合，ブースティングでは精度が上がらなかった．
[i:217, score:0.14552] 属性を単純化して決定リストの精度を若干下げた場合，ブースティングによって精度は上がるが本実験で行った結果以上には精度は上がらなかった．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:239, score:0.10197] 本論文では日本語単語分割を分類問題とみなし，決定リストを利用してその問題を解いた．
[i:241, score:0.14895] 実験では，文字ベースのn-gramモデルに基づく単語分割法との比較を行い，決定リストによる単語分割の方が優れていることを示した．
[i:243, score:0.10437] アダブーストを利用することによって，単独の決定リストよりもさらに精度を向上させることができた．

