実験


\subsection{文字 n-gram モデルに基づく単語分割法との比較}

ここでは決定リストを利用した単語分割の有効性を示すために，
文字 n-gram モデルに基づく単語分割法\cite{oda98}との比較を行う．
文字 n-gram モデルに基づく単語分割法では，概略，
単語境界を付与した訓練データにおいて，単語境界の記号自体も一つの特殊文字として考えて，
ある文字列の後に単語境界が生じる確率あるいは生じない確率を文字 n-gram モデルに基づいて計算する．
最終的には Viterbi アルゴリズムなどの動的計画法を利用して，
文字列の出現確率が最大になるように単語境界のあるなしの列を決定する．
これは文字ベースの HMM において，遷移確率やシンボル出力確率をある
確率モデルに基づいて計算したものと同等である．

訓練データとしては京大コーパス(約4万文)を利用した．京大コーパスは人手でタグをつけた
コーパスであり，正解付きの訓練データとして利用できる．
京大コーパスの中から 950117.KNP というファイルに納められた 1,234 文
\footnote{ここではコーパス中の記号 EOS の数を文の数としている．句点 ``。'' の数ではないことを
注意しておく．}をテストデータとした．
結果，訓練データは京大コーパスからテストデータを除いた 35,717文 である．
テストデータ 1,234 文の中には，単語境界を置くか置かないかを判定する位置が
56,411 個所存在する．この 56,411 個所に対して正しいクラスを付与できた
割合を正解率とする．

訓練データから文字 tri-gram 確率を求めるために CMU-Cambridge Toolkit 
\footnote{CMU-Cambridge Toolkit は以下のアドレスから入手可能．
\mbox{{\tt http://svr-www.eng.cam.ac.uk/\(\tilde{ }\)prc14/toolkit.html}}}を利用した．
スムージングの手法としては Witten-Bell discounting を用い，カットオフは頻度 0 と設定した
\cite{kita99}．

文字 tri-gram 確率から tri-gram モデルに基づく単語分割法を実装したシステムを作成し，
テストデータに対して単語分割を行った．結果，56,411 個所の判定位置について，
52,328 個所で正しい判定を行い，4,083 個所で誤った判定を行った．つまり
正解率は 92.76\% であった．

次に上記の訓練データを利用して本論文で提案した決定リストを作成した．
頻度 7 以下の証拠は間引いた．作成できた決定リストの大きさは 136,114 であった．
この決定リストにより
テストデータに対して単語分割を行った．結果として，56,411 個所の判定位置について，
55,015 個所で正しい判定を行い，1,396 個所で誤った判定を行った．つまり
正解率は 97.52\% であった．この値は tri-gram モデルに基づく単語分割法の正解率
92.76\% を大きく上回っており，本手法の有効性が示せた．

\subsection{ブースティングの効果}

前述したアダブーストにより，決定リストのブースティングを行った．
ブースティングの回数を横軸に，テストデータに対する正解率 \% を縦軸にした
グラフが \mbox{図\ref{graph}} である．

\begin{figure*}[htbp]
\begin{center}
\atari(127,88.9)
\end{center}
\caption{ブースティングによる正解率}
\ecaption{Precision by boosting }\label{graph}
\end{figure*}

\mbox{図\ref{graph}} からわかるように，ブースティングにより 3 組の決定リストを
作成し，それらの重み付き多数決によって判別した結果が最も優れていた．
そのとき 56,411 個所の判定位置について，
55,560 個所で正しい判定を行い，851 個所で誤った判定を行った．つまり
正解率は 98.49\% まで向上した．

\subsection{未知語の検出}

ブースティングにより3組の決定リストを作成し，それらの重み付き多数決によって
各文字間に単語境界の有無を判定する手法（以下これを本手法と呼ぶ）が，
本実験において，どの程度の未知語を検出できたか調べる．

前述した訓練データ 35,717 文とテストデータ 1,234文の
正確な単語分割結果から，それぞれに含まれている単語文字列を取り出した．
ここでいう単語文字列とは，単純に単語分割された分割要素の文字列のことである．
つまり用言の活用語尾が異なるものも，異なる単語文字列として取り出す
ことに注意する．
結果，訓練データには 914,392個（41,890種類）の単語文字列，
テストデータには 32,764個（6,479 種類）の
単語文字列が存在した．そしてテストデータには含まれるが，
訓練データには含まれない単語文字列が 1,024個（832 種類）存在した．
この1,024個（832 種類）の単語文字列が本実験における未知語となる．

結論から述べると，本手法によりこの1,024個（832 種類）の未知語の中で，
正しく検出できたものは 688個（562 種類），
つまり個数で 67.2\%，種類数で 67.5\% の検出率であった．

検出できた未知語の中には，字種区切りのような単純なヒューリスティクスから
検出できるものも存在するので，本手法の未知語検出が，実質どの程度の
有用性があるのかを示すために，対象の未知語を以下のように 9 タイプに分類した．

\begin{description}
\item[(1) 用言であり，その原型を同じとする単語が訓練データに含まれる（124個（123種類））．]

例えば，「押しつぶした」という単語文字列は，テストデータには含まれるが，
訓練データには含まれないために，本手法では未知語として扱われる．
しかし通常の辞書を利用したシステムでは，「押しつぶした」の原型「押しつぶす」が辞書に
登録されていれば，正しく解析できる．訓練データには，「押しつぶす」の語尾変化形である
単語文字列「押しつぶして」が含まれている．そこで，通常のシステムの辞書には，
原型「押しつぶす」が登録されていたと考え，「押しつぶした」は正しく解析できると考える．

ここでは，このようなタイプの未知語は，
通常のシステムの用言の語尾変化の規則によって検出できるタイプの
未知語として考える．

\item[(2)  用言であり，その原型を同じとする単語が訓練データに含まれない（94個（91種類））．]

例えば，「飲みすぎて」という単語文字列は，テストデータには含まれるが，
訓練データには含まれない．しかも (1) の場合とは異なり，「飲みすぎて」の原型「飲みすぎる」を
語尾変化させた単語文字列も訓練データに含まれない．これは
通常のシステムにおいても未知語となるものである．

\item[(3) 数値表現となっている（44個（41 種類））．]

例えば，「一万九千百八十五」や「２７・７」という単語文字列は未知語となっているが，
通常のシステムはこれらの表現を数値表現として認識できる規則を持っている．
この種の未知語も通常のシステムで検出できるタイプの未知語とする．

\item[(4) アルファベットのみで構成される（7個（3 種類））．]

「ＡＣ」「ＯＥＫ」「ＰＡＨ」の単語文字列である．
これらは字種区切りのような単純なヒューリスティクスから通常のシステムでも
検出可能である．

\item[(5) カタカナのみで構成される（210個（156 種類））．]

例えば，「アロマセラピスト」や「スーザン」のような単語文字列である．
これらも字種区切りのような単純なヒューリスティクスから通常のシステムでも
検出可能である．

\item[(6) 平仮名のみで構成される（38個（32 種類））．]

例えば，「ごあいさつ」や「ぞろぞろ」のような単語文字列である．
これらの検出は通常のシステムでは不可能である．

\item[(7) 漢字１文字で構成される（21個（17 種類））．]

例えば，「魁」や「鋼」のような単語文字列である．
通常のシステムでも未知語となるが，単語分割の他の候補が生じないために，
結果的に正しく単語分割できる場合も多い．

\item[(8) 漢字のみで構成される（426個（310 種類））．]

例えば，「重文」や「三井造船」のような単語文字列である．
これらの検出は通常のシステムでは不可能である
\footnote{例えば，漢字１文字からなる未知語と既知語を全体として未知語として
認識できる可能性が指摘された．しかしそのヒューリスティクスが
どの程度妥当かは疑問がある．また，その場合 (7) との区別がつかない．
ここでは多少強引だが，(8)は既存のシステムでは検出不可能とした．}．

\item[(9) 複数の字種から構成される（64個（59 種類））．]

例えば，「寝泊まり」や「亡き後」のような単語文字列である．
これらの検出は通常のシステムでは不可能である．

\end{description}

上記 9 タイプの未知語の本手法による検出結果を\mbox{表 \ref{unknown}}に示す．同時に
通常のシステムで想定できる検出結果も示す．

\newpage

\begin{table}[h]
  \begin{center}
    \leavevmode \small
    \caption{未知語の検出}
    \ecaption{Detection of unknown words}  \label{unknown}
    \begin{tabular}{|l|r|r|r|} \hline
タイプ              &   総出現数  &  本手法による検出  &  通常のシステムによる検出   \\ \hline \hline
(1) 辞書登録の用言   &   124   &    101             &      124    \\ \hline
(2) 辞書未登録の用言 &    94   &     57             &        0    \\ \hline
(3) 数値表現         &    44   &     40             &       44    \\ \hline
(4) アルファベット列 &     7   &      5             &        7    \\ \hline
(5) カタカナ列       &   210   &    188             &      210    \\ \hline
(6) 平仮名列         &    38   &     19             &        0    \\ \hline
(7) 漢字１文字       &    21   &      4             &       21    \\ \hline
(8) 漢字列           &   426   &    246             &        0    \\ \hline
(9) 複数の字種       &    64   &     28             &        0    \\ \hline \hline
   合計              & 1,024   &    688 (67.2\%)    &      406 (39.6\%)   \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\mbox{表 \ref{unknown}}に示すように通常のシステムの検出率は 39.6\% であり，本システムの検出率
67.2\% と大きく差がある．これは本システムの未知語の検出能力の高さを示している．
また通常のシステムにより検出できるとした未知語のタイプ (1),(3),(4),(5),(7) に対して，本手法の
検出率は 83.3\% であり，通常のシステムにより検出できる未知語の多くは本システムでも
検出できると考えられる．


