また本論文では分類問題の解法として決定リストを利用したが，他の手法，例えば，決定木[CITE]や最大エントロピー法[CITE]の利用も可能である．
ただし本論文で利用した属性にあたるものを，それらの手法では単純には利用できない．
決定木を利用する場合，属性の数は7種類であり問題ないが，bi-gramあるいはtri-gramにあたる属性の値の種類数が非常に多い．
このため決定木の各ノードから出る枝の数が膨大になり，現実的には決定木を作成できない．
また最大エントロピー法では素性の設定と素性パラメータの算出が必要となる．
素性は本論文で述べた証拠自体となるため，素性の種類は頻度7で間引いて約14万弱である．
最大エントロピー法で利用できる素性の数は現実的には，数万が限度であるために，最大エントロピー法の利用も現実的には無理がある．
文字ベースの手法を利用する場合には，bi-gramやtri-gramなどの情報を直接利用できる決定リストは現実的に有効な選択である．
本論文では単語分割を分類問題としてみなして解決した．
分類問題とみなした場合，精度に関わる最も大きな要因は属性の選択である．
アダブーストを利用するという枠組みでは，属性の設定はさらに考慮すべきである．
ブースティングは弱学習アルゴリズムに対して利用できる．
具体的には精度が50%を越えるようなアルゴリズムであれば適用できる．
つまり作成できた決定木などの分類器自体の精度はそれほど高い必要はない．
属性をうまく考慮して決定リストの精度を上げるよりも，作成される決定リストの精度は低いが，ブースティングにより精度が増してゆくような属性を設定するアプローチも有望である．
いくつかの実験を行った結果，以下の点が確認できた．
属性を増やす，間引きの頻度を調整する，などの工夫を入れて決定リストの精度を上げた場合，ブースティングでは精度が上がらなかった．
属性を単純化して決定リストの精度を若干下げた場合，ブースティングによって精度は上がるが本実験で行った結果以上には精度は上がらなかった．
結論的には本論文で設定した属性の情報を利用する上では，本論文で示した値程度が限界に近いと感じられた．
分類誤りの原因を追求すると，訓練データに現れない表現あるいは頻度の低い表現の部分で分類が誤っている．
これは未知語の問題そのものであり，未知語への対処が単語分割の中心の課題と言える．
この解決策は3つ考えられる．
1つ目は規則の一般化を精度良く行うことである．
例えば文字クラス[CITE]などの導入などが考えられる．
2つ目は別リソースの利用である．
例えば辞書の利用である．
単語分割に本手法の分類手法と辞書による最長一致法を利用することも考えられる．
3つ目は訓練データの拡充である．
事例ベースの手法[CITE]は訓練データつまり事例を大規模化することで精度が上がる．
ただし大規模な正解付きの訓練データが用意できない現状では，正解のない訓練データをどう使うかが鍵となる[CITE]．
１つ目のアプローチ以外は，未知語の検出に対して理論的な保証がない．
しかしだからといって，単語分割を文字ベースの手法によって解くことに意味がないわけではない．
辞書に基づいた分割では数値表現や字種区切りが有効になるような未知語しか解析できず，解析できる未知語が限定されている．
このような未知語の多くは，実験に示したように，本手法でもその多くを検出できる．
さらに文字ベースの手法では，その他のタイプの未知語も検出できる場合が多々あるが，辞書に基づいた分割では確実に検出できない．
この違いは大きい．
