================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.42792] 我々のシステムは，入力文と対象単語が与えられたとき，翻訳メモリと呼ばれる対訳用例集合と入力文との類似度を求め，類似度が最大となる用例集合を用いて対象単語の訳語選択を行なう．
[i:2, score:0.28256] 類似度は，用例に基づく手法と機械学習モデルを用いて計算される．
[i:4, score:0.31857] 入力文と対象単語が与えられると，まず用例に基づく手法を適用し，類似した用例が見つからなかった場合に機械学習モデルを適用する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:17, score:0.41691] さらに，文対応をとる際の誤りを軽減するために，パラレルコーパスとして，対訳用例(句/文)集合(翻訳メモリ，トランスレーション・メモリー，以下TM)を用いる．
[i:18, score:0.40003] 我々のシステムは，入力文と対象単語が与えられると，その対象単語に関して入力文と対訳用例集合との類似度を求め，類似度が最大となる用例集合を用いて対象単語の訳語選択を行なう．
[i:27, score:0.37961] 見つからなかった場合には，機械学習モデルに基づく手法により対象単語に関して入力文と最も類似した用例集合を選択して翻訳に使う．

================================================================
[section type  : proposed_method]
[section title : {\sc Senseval]
================================================================
[i:36, score:0.42784] 具体的には，TMでは，日本語見出し語に対して，それを含む日本語表現とその英語翻訳のペア(以下これを用例と呼ぶ)の集合が与えられた．
[i:39, score:0.35698] 参加者には，対象単語に対して，その翻訳に利用できるTMの用例番号，または，翻訳そのものを提出することが求められた．
[i:44, score:0.33334] システムの出力がTMの用例番号の場合は，その出力が正解のいずれかと一致するとき，正しく推定できたものと見なされた．

================================================================
[section type  : proposed_method]
[section title : 訳語選択モデル]
================================================================
[i:47, score:0.37078] そして，このタスクで，対象単語に関して入力文との類似度が最大となる用例あるいは用例集合を用いて対象単語の訳語を選択するモデルを考える．
[i:52, score:0.24351] 類似度は，入力文と日本語用例との間で一致した文字列に基づいて計算する．
[i:55, score:0.40144] 入力文と対象単語が与えられたとき，まず手法1で対象単語に関して入力文との類似度が閾値以上となる用例があるかどうかを調べ，ある場合はその類似度が最大となる用例の番号あるいはその用例の英語見出し語を出力し，ない場合は，手法2で対象単語に関して入力文と最も類似した用例集合を選択し，その英語見出し語を出力する．
-----------------------------------------------------
  [subsection title : 文字列の類似性に基づく方法(手法1)]
-----------------------------------------------------
  [i:lead, score:0.44266] 対象単語に関して入力文との類似度が高い日本語用例があれば，TMを信頼しその用例の番号あるいはその英語見出し語を出力する．
.....
  [i:57, score:0.44266] 対象単語に関して入力文との類似度が高い日本語用例があれば，TMを信頼しその用例の番号あるいはその英語見出し語を出力する．
  [i:60, score:0.24584] 例えば，図[REF_fig:tm_example]の用例にこの文末処理を施すとそれぞれ，「母に遠慮」「母への遠慮」「献金を遠慮」となる．
  [i:68, score:0.42252] しかしながら，TMに全ての可能な用例を登録することは難しく，常に入力文と表層的にほぼ同じものがあることは期待できないため，類似度が最大となる用例が常に訳語選択に最適な用例であるとは限らない．
-----------------------------------------------------
  [subsection title : 機械学習モデルに基づく方法(手法2)]
-----------------------------------------------------
  [i:lead, score:0.30630] 入力文と表層的にほぼ同じ用例がない場合，より多様な情報を用いて類似度を求める必要があると考えられるが，そのために複雑な規則を作成するのは避けたいため，類似度の計算には機械学習モデルを用いることにした．
.....
  [i:74, score:0.51354] そして，日英の見出し語つまり各用例集合内で共通する対訳単語ペアのうち，日本語見出し語は共通で，英語見出し語が訳語/訳句候補となるため，各用例集合の英語見出し語がモデルにより分類するクラスとなる．
  [i:81, score:0.45177] 抽出する用例は，TMの各用例集合と同じ日英見出し語を含む対訳用例とし，抽出した用例はTMの各用例集合に追加する．
  [i:82, score:0.43343] 以降で，用例数および学習文数は，ともに各日本語見出し語に対しその語を含む用例の数を意味するものとし，TMに最初に含まれていた用例の総数を用例数，他の言語資源から抽出して追加した後の用例の総数を学習文数と呼んで区別する．

================================================================
[section type  : experiment_result]
[section title : 実験と考察]
================================================================
-----------------------------------------------------
  [subsection title : 実験の条件]
-----------------------------------------------------
  [i:lead, score:0.06334] 入力，評価はSenseval-2日本語翻訳タスクのものに従った．
.....
  [i:157, score:0.37997] TMは320語のもの(1見出し語に対する用例数は約20)が2001年3月中旬に配布された．
  [i:161, score:0.36015] ここから対訳用例を抽出する際，日英見出し語が対応関係にないものを抽出してしまった場合でも，抽出の際に検索語として用いた日英見出し語が正しい対応関係にあると仮定して学習に用いた．
  [i:163, score:0.38905] コンテストでは，手法1で類似度最大として選択された用例についてはその用例番号を，手法2で類似度最大として選択された用例集合についてはその英語見出し語を出力して提出した．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, score:0.08154] コンテストの結果を表[REF_tab:result]にあげる．
.....
  [i:175, score:0.32049] 単語ごとの精度と用例数，学習文数，クラス数との関係は表[REF_tab:result2]の通りである．
  [i:178, score:0.30063] 正解がTMの用例の場合
  [i:196, score:0.29646] 後者については，クラスの数が多く，日本語用例は似ているが異なるクラスに分類されているという場合もあり，また学習データが特定のクラスに偏っているということもなかったため，ベースラインの精度そのものが低い難しい問題であったと考えられる．
-----------------------------------------------------
  [subsection title : 手法1と精度]
-----------------------------------------------------
  [i:lead, score:0.14460] 手法1はTMを最も単純に利用した方法であり，この手法による精度は高いことが望ましい．
.....
  [i:206, score:0.44215] ただし，100語のうち31語は，TMの用例に含まれる英語見出し語ではなく対訳辞書を索いて得られた英語見出し語を選択したため評価していない．
  [i:217, score:0.46121] このように予め学習データが少ないと分かったクラスつまり訳語/訳句候補は，慣用表現である可能性が高いと考え，個別にTMに用例を追加するなどしてTMを充実させるのが効果的である可能性が高い．
  [i:218, score:0.33716] この場合，TMに用例を追加するだけでなく，表[REF_tab:error1]にあげたような手法1による誤りもなくす必要があるため，現状のTMを次の手順で変更する必要があると考えている．
-----------------------------------------------------
  [subsection title : 手法2と精度]
-----------------------------------------------------
  [i:lead, score:0.32845] 手法2ではTMの用例だけでなく他の言語資源から抽出した用例も用いる．
.....
  [i:248, score:0.41287] 学習データを補強する際，他の言語資源から抽出した対訳用例における単語対応をとり，日英見出し語が対応関係にあるものだけを選択するようにする．
  [i:251, score:0.42579] クラスである英語見出し語は，評価，比較が容易になるようにTMの用例のみから選択した．
  [i:270, score:0.44517] クラスである英語見出し語は，上述のようにTMの用例のみから選択しているため，表[REF_tab:result2]と表[REF_tab:result3]を単純に比較することはできない．
-----------------------------------------------------
  [subsection title : 素性と精度]
-----------------------------------------------------
  [i:lead, score:0.06401] この節では，各素性集合と精度との関係について述べる．
.....
  [i:288, score:0.10531] 表[REF_table:exp:feature]に，実験に用いた素性集合の種類とそのときに得られた精度をあげる．
  [i:289, score:0.15105] 「機械翻訳モデル」の欄にはクロスバリデーションによって選択された機械学習モデルの数を表わす．
  [i:290, score:0.11917] 手法1での類似度および分割数の閾値はそれぞれ，学習データに対する精度が最大になったときの値つまり1.0，0とした．
-----------------------------------------------------
  [subsection title : モデルと精度]
-----------------------------------------------------
  [i:lead, score:0.10497] この節では，複数の機械学習モデルから最適なモデルを選択した場合と，単独の機械学習モデルを用いた場合との違いについて述べる．
.....
  [i:295, score:0.13838] これまでの実験では，個々の単語に対し，複数の機械学習モデルからクロスバリデーションによりモデルを選択していたが，すべて単一の機械学習モデルを用いた場合との精度の違いが明らかではなかった．
  [i:301, score:0.16024] 混合(上限値)の行にあげた精度は，個々の単語ごとに，複数の機械学習モデルからテストデータで最も良い精度が得られるモデルを選択した場合の精度であり，複数のモデルを用いる場合の潜在的な上限値を意味している．
  [i:303, score:0.17275] これらの結果から，これまでの実験で用いてきたクロスバリデーションによるモデル選択の方法は単独の学習モデル(SVM)を用いる方法に比べて劣ること，しかし，潜在的には複数のモデルを組み合わせることにより，より良い精度(5 %程度良い精度)が得られることが分かる．
-----------------------------------------------------
  [subsection title : 学習データと精度]
-----------------------------------------------------
  [i:lead, score:0.26690] この節では，他の言語資源から対訳用例を自動抽出して用いた場合の効果について述べる．
.....
  [i:305, score:0.40817] 学習に，それぞれ，TM用例のみを用いた場合，他の言語資源から自動抽出した対訳用例のみを用いた場合，すべて用いた場合の三種類の比較実験を行なった．
  [i:309, score:0.41362] 表[REF_table:exp:data]より，TM用例だけでなく，他の言語資源から自動抽出した対訳用例も用いた場合に，より精度が良くなることが分かる．
  [i:310, score:0.40369] 他の言語資源から対訳用例を抽出する際には，日英の見出し語が出現しているかどうかだけを手がかりにしていたため，日英見出し語が対応関係にないものも抽出してしまっていたが，現段階ではこの単語対応を考慮していなかったことによる悪影響よりも自動抽出した用例が精度向上へ貢献する度合いの方が顕著に勝っていると言えそうである．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:324, score:0.42231] 本論文で述べたTMあるいはそれと同様の対訳用例を訳語選択に用いた研究としては，Baldwin [CITE]やSumita[CITE]の研究がある．
[i:332, score:0.51670] また，本論文では，対訳用例の訳語選択への利用方法に関する知見として，今回用いたTMのように一見出し語あたり30個程度の例があれば，それをもとに自動抽出した対訳用例と併せて学習に用いることで精度が向上することを示した．
[i:334, score:0.41992] 統計的機械翻訳モデルを用いて入力文の最適な翻訳を探索する際に，必ずしも最適解を探索するのではなく，入力文と一致するTM用例があればそれを優先する，という制約を課すことにより翻訳精度が向上したと報告している．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[i:342, score:0.43298] 学習には，TMの用例だけでなく，他の対訳辞書あるいは対訳コーパスから抽出した用例を用い，学習の際には，原言語と目的言語の間で互いに対応関係がない各単言語コーパスから抽出した頻度情報なども考慮する．
[i:349, score:0.42302] 他の言語資源から追加した対訳用例の英語見出し語が，日本語に訳したときその訳語に曖昧性のある場合には，データの質が精度に悪影響を及ぼす場合があった．
[i:350, score:0.37120] 今後，対訳用例における単語対応をとり，見出し語間に対応関係があるもののみ選択するようにし，学習データの質を改善したい．

