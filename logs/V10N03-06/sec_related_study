これまでに，対訳コーパスを用いた統計的なあるいは機械学習モデルに基づく訳語選択の手法が数多く提案されてきた(例えば，[CITE]など)．
我々も同様に機械学習モデルに基づく手法を用いている．
これまでに提案されてきた手法との主な違いは，SVMなど複数の機械学習モデルを利用している点と，それらの機械学習モデルと用例に基づく手法とを組み合わせて利用している点，さらに，これまでの方法がすべての単語に対し同じ機械学習モデルを用いているのに対して，我々は単語ごと(原言語見出し語ごと)に異なるモデルを作成し，その中から最適な機械学習モデルを選択している点にある．
実験では，クロスバリデーションによる選択は単独の学習モデル(SVM)より劣ることが分かったが，潜在的には複数のモデルを組み合わせることによりより良い精度(5 %程度良い精度)が得られることも示した．
用例に基づく手法として我々が用いたものはSato [CITE]が提案した手法に類似している．
我々の手法との主な違いは，類似度を計算する際に課す制約である．
Satoの手法では特に制約は課していないが，我々の場合は，入力文と用例とがいくつかの部分に分割されて一致する場合にその分割数を制限する，対象単語と同じ見出し語を持つ用例に限定する，などの制約を課している．
実験により，前者の制約を課すことによって良い結果が得られることが分かった．
Satoの手法では，文字列の並びの順序が異なる場合でも一致したと見なす柔軟さがある．
その柔軟性を我々の手法にも採り入れたい．
本論文で述べたTMあるいはそれと同様の対訳用例を訳語選択に用いた研究としては，Baldwin [CITE]やSumita[CITE]の研究がある．
Baldwinは原言語用例の情報を用いてTMから訳語選択に最も適した用例を選択する方法を提案した．
彼はbigramなどの文字列情報のみを用いたときが最も精度良く類似した用例を選択できると報告している．
我々の方法でもbigramなどの文字列情報を素性として利用するようにすれば，精度向上が期待できると考えている．
SumitaはTMの利用方法という点で我々と類似した方法を提案している．
彼の方法では，我々の手法と同様に，TMの用例を目的言語見出し語ごとに用例集合としてまとめて利用している．
そして，入力文と用例集合をそれぞれ検索質問文，文書と考え，情報検索でよく用いられるベクトル空間モデルを用いて入力文と最も類似した用例集合を選択する．
この手法では学習は行なわれないが，我々の手法では学習により，入力文と対象単語に関して最も類似した用例集合を選択する．
また，本論文では，対訳用例の訳語選択への利用方法に関する知見として，今回用いたTMのように一見出し語あたり30個程度の例があれば，それをもとに自動抽出した対訳用例と併せて学習に用いることで精度が向上することを示した．
機械翻訳では，Marcu [CITE]が用例に基づく手法と統計的機械翻訳モデルを組み合わせて一文全体を翻訳する手法を提案した．
統計的機械翻訳モデルを用いて入力文の最適な翻訳を探索する際に，必ずしも最適解を探索するのではなく，入力文と一致するTM用例があればそれを優先する，という制約を課すことにより翻訳精度が向上したと報告している．
我々の手法では，用例に基づく手法と機械学習モデルを組み合わせて，一文全体の翻訳ではなく，各単語の訳語選択を行なう．
また，Marcuは完全一致となる用例のみを用いているが，我々はいくつかの部分に分かれて一致する用例や部分一致となる用例も用いている．
実験ではこのような用例も用いた場合に精度が向上したことから，一文全体の翻訳の際にも部分一致となる用例を用いるとより良い結果が得られる可能性が高いと考えている．
今後，我々の手法が一文全体の翻訳の精度にどれだけ貢献するかを調べたい．
