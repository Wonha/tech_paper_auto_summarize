難解語の変換手法の概要

本稿で提案する難解語の変換手法は人間が自然に行う語の変換に沿い，1：1および1：$N$の変換処理を組み合わせることで行う．同義語，類義語を用いた1：1の変換処理（1語変換）と，1つの語を文で変換する1：$N$の変換処理（$N$語変換）によりこれを実現する．また，各変換処理において人間の連想能力を模倣した語概念連想を用いることで，語の表記に依存しない柔軟な語の変換を行う．語と語，文と文の意味的な近さを考慮した変換を行うことで，人間の常識に沿った語の選択や多義性の解消を図ることが出来る．語概念連想の詳しい構造については\ref{Gogainen}章に示す．

\begin{figure}[b]
 \begin{center}
  \includegraphics{20-2ia2f1.eps}
 \end{center}
 \caption{語変換処理の概要図}
 \label{fig:gaiyouzu}
\end{figure}

図\ref{fig:gaiyouzu}に提案する語変換処理の概要図を示す．入力は新聞記事とし，語の変換処理は句点を区切りとする記事中の1文ずつで行う．入力された記事中から会話に適さない馴染みの薄い語（難解語）を判別し，別の平易な語もしくは文に変換する．

難解語の判別には単語親密度\cite{Book_01}を用いる．単語親密度とは単語に対する馴染みの度合いを主観的に評価した値であり，数値が高いほどより馴染みのある単語であることを示す．これは18歳以上の被験者40名に対して単語を提示し，1から7までの数字で馴染みがあるか否かを評価した結果を平均化することで算出される．表\ref{tab:tansin_rei}に単語親密度の一部を示す．

\begin{table}[b]
\vspace{-1\Cvs}
\caption{単語親密度の例}
\label{tab:tansin_rei}
\input{02table01.txt}
\end{table}

表\ref{tab:tansin_rei}に示した通り，例えば「あいさつ」のようにごく一般的な語は単語親密度が高く，万人にとって馴染みの深い語であることがわかる．一方「サイドマイド」（睡眠薬の一種）は専門的な用語であり，一般的には馴染みが薄く単語親密度も低い値となる．日常的に使用する語とは，万人にとって馴染みのある語であると考える．新聞記事中に現れる「危ぶむ」という表現は，一般的な会話ならば「心配する」程度の表現の方が違和感なく馴染みやすい．つまり馴染みの度合いが高い語ほど会話への利用に適していると考えられる．また単語親密度が高ければ高い語ほど，その語を文字として提示された場合と音声として提示された場合の双方で語彙判断の反応時間が短く認知の誤りも少ないという結果が報告されており\cite{Article_20,Article_21,Book_05}，この事からも単語親密度が高い語ほど会話への利用に適した平易な語であるといえる．そこで本稿では単語親密度が低い語を変換すべき難解語とみなし，平易な表現への変換処理を行う．

難解語と置き換える平易な表現は語の同義・類義関係を示した関係語辞書\cite{Article_10,Article_11}および国語辞書から得る．1語変換においては国語辞典から自動構築された関係語辞書を用いて難解語の同義語・類義語を取得し，これらを変換に用いる語の候補（変換候補語）とする．辞書における同義語はある語と同じ意味を持つ別表記の語，類義語は類似の意味を持ち言い換えることの出来る語と定義されているため，これらの語を用いることで1語変換を行うことができる．$N$語変換では国語辞書を用いて難解語の意味を説明する定義文を取得し，これらを変換に用いる文の候補（変換候補文）とする．

$N$語変換に用いる変換候補文は辞書に記載されているそのままの形で語の変換を行うと，出力される文が日本語として不自然な場合がある．例えば辞書の定義文に出現する「転じて」や「〜の別名」といった言い回しは，そのままの形で変換に用いた場合に不自然さを発生させる要因となる．このような変換に必要の無い語を不要語と定義し，不要語リストを用いてこれらの削除を行う．また，元の記事中の語を定義文で変換した際にWhatやWhoといった文中の情報が重複することによって不自然さが発生する場合がある．そこで意味理解システム\cite{Article_03}を用いて不自然さを排除した上で難解語を文に変換し，会話に適した語句で構成された文を
出力する．


語概念連想
\label{Gogainen}

一般的に語や文の類似性を計る際には，ベクトル空間モデル\cite{Article_08}のように単語の出現頻度や共起，表記の一致などを利用した手法が往々にとられる．しかし人間はそのような情報に依存することなく，語と語や文と文の間に意味的な関連性を自然と連想し，処理している．そのような人間の連想能力を模倣し，人間らしい柔軟な言葉の意味理解を行う機構として語概念連想が提案されている．

語概念連想は語の意味定義を行う概念ベース\cite{Article_04}と，語と語の間の関連性を定量的に表現する手法である関連度計算方式\cite{Article_05}，そしてヒッチコック型輸送問題\cite{Book_06}で計算される距離尺度であるEarth Mover's Distance (EMD)を用いた記事関連度計算方式\cite{Article_06}を有する，人間の連想能力を表現した機構である．語概念連想に関する研究報告ではベクトル空間モデルといった従来手法と比べてその有効性が示されている\cite{Article_05}．

本稿では語の変換を行う際に，元の語と変換の候補となる語（変換候補語）との間の意味的な近さを考慮するために語概念連想を用いる．具体的には，まず1語変換においては複数得られる可能性のある同義語・類義語の中から最も元の語に近い意味を持つ変換候補語を選別するために関連度計算方式を用いる．次に$N$語変換においては多義性の解消のためにEMDを用いた記事関連度計算方式を用いる．これは難解語が多義語であった場合に辞書の定義文が複数取得されるため，文書間の関連性を定量化することで元の記事と最も関連の強い定義文を判別し，意味の特定を図るものである．

以下に概念ベース，関連度計算方式，EMDを用いた記事関連度計算方式について述べる．



\subsection{概念ベース}

概念ベースは複数の電子化国語辞書などの見出し語を概念と定義し，見出し語の定義文に使われる自立語群を概念の特徴を表す属性として構築された知識ベースである．本稿で使用した概念ベースは自動的に概念および属性を構築した後に人間の常識に沿った属性の追加や削除を行ったものであり，概念は87,242語となっている．

概念ベースのある概念$A$は，$m$個の属性$a_i$と，その属性の重要性を表す重み$w_i$の対によって次のように表現される．
\[
 \text{概念} A=\{(a_1, w_1), (a_2, w_2), \cdots , (a_m, w_m)\}
\]

概念$A$の意味定義を行う属性$a_i$を，概念$A$の一次属性と呼ぶ．概念ベースの特徴として，属性を成す単語群も概念ベースの中で概念として定義されている点がある．つまり属性$a_i$を概念とみなして更に属性を導くことができる．概念$a_i$から導かれた属性$a_i{}_j$を，元の概念$A$の二次属性と呼ぶ．概念ベースの具体例を表\ref{tab:gainenrei}に示す．

\begin{table}[t]
\caption{概念ベースの例}
\label{tab:gainenrei}
\input{02table02.txt}
\end{table}

例えば「医者」という概念が持つ属性「患者」は，概念「患者」としても定義されている．この概念「患者」の持つ「病人，看病，治療，…」といった属性群が，元の概念「医者」の二次属性ということになる．



\subsection{関連度計算方式}
\label{DOA}

関連度計算方式は概念ベースの特徴である属性の連鎖的構造を活用して，高い精度で概念間の関連性を定量化することが可能である．概念をベクトルで表現し，概念間の関連性をベクトル内積により算出した場合と比較しても，関連度計算方式は高い精度となっており，概念間の関連性の定量化における関連度の有効性が示されている\cite{Article_05}．以下に関連度計算方式の具体的な処理を述べる．

関連度計算方式では2つの概念間の関連性を関連度という値で定量的に表現する．関連性を算出する概念の二次属性を用いて，それぞれの一次属性を最も関連が強いもの同士で対応付けを行った上で算出する．以下に，概念$A$と概念$B$の関連度$DoA(A,B)$の算出方法について示す．
概念$A$および概念$B$の一次属性をそれぞれ$a_i$, $b_i$とし，対応する重みを$u_i$, $v_i$とする．それぞれが持つ属性数が$L$個と$M$個($L\leq M$)とすると，概念$A$, $B$はそれぞれ以下のようになる．
\begin{gather*}
 \text{概念} A=\{(a_1, u_1), (a_2, u_2), \cdots , (a_L, u_L)\} \\
 \text{概念} B=\{(b_1, v_1), (b_2, v_2), \cdots , (b_M, v_M)\}
\end{gather*}

なお，このとき各概念の属性の重みを，その総和が1.0となるよう正規化している．

ここで一次属性の数が少ない概念$A$の属性の並びを固定する．その上で概念$B$の各一次属性を対応する概念$A$の各一次属性との一致度$DoM(A,B)$の合計が最大になるように並べ替える．ただし，概念$A$の属性と対応付けされなかった属性については無視する．
\[
 \text{概念} B=\{(b_{x1}, v_{x1}), (b_{x2}, v_{x2}), \cdots ,(b_{xL}, v_{xL})\}
\]

このとき，概念$A$と概念$B$の関連度$DoA(A,B)$は，
\begin{equation}
 \mathit{DoA}(A,B)=\displaystyle{\sum_{i=1}^{L}\mathit{DoM}(a_i,b_{xi})\times\frac{(u_i+v_{xi})}{2}\times\frac{\mathit{min}(u_i,v_{xi})}{\mathit{max}(u_i,v_{xi})}}
\end{equation}
と定義する．ここで$\mathit{min}(u_i,v_{xi})$は$u_i$と$v_{xi}$を比較して小さい値を，$\mathit{max}(u_i,v_{xi})$は大きい値を指す．

なお，一致度$\mathit{DoM}(A,B)$は以下のように定義する．
\begin{equation}
\mathit{DoM}(A,B)=\displaystyle{\sum_{a_i=b_j}^{}\mathit{min}(u_i,v_j)}
\end{equation}

$a_i=b_j$は属性が表記的に一致した場合を示している．つまり一致度とは概念$A$と概念$B$双方が共通して持つ属性の内，小さいほうの重みを足し合わせたものとなる．共通した属性は概念$A$と概念$B$でそれぞれ重みが付与されており，このうち小さいほうの重み分は概念$A$と概念$B$両方の属性に有効であると考えるためである．



\subsection{EMDを用いた記事関連度計算方式}
\label{EMD}

EMDを用いた記事関連度計算方式は，ヒッチコック型輸送問題\cite{Book_06}（需要地の需要を満たすように供給地から輸送を行う際の最小輸送コストを解く問題）で計算される距離尺度であるEMDを文書検索へ適用したもので，2つの記事間の関連性を定量的に表現することが可能であり\cite{Article_06}によりその有用性が報告されている．

EMDとは2つの離散分布があるときに一方からもう一方の分布への変換を行う際の最小コストを指す．離散分布はそれを構成する要素と重みの対の集合で表現され，コスト算出の際には変換前の離散分布の要素が持つ重みを供給量，変換先の離散分布の要素が持つ重みを需要量と考え，要素間の距離を供給量，需要量にしたがって重みを運送すると考える．できるだけ短い距離で，かつ需要量に対して効率的に重みを運送する経路がEMDとなる．これを文書検索に適応させる際には，文章中の自立語（名詞，動詞，形容詞）を要素として捉え，自立語の集合を離散分布と考える．ある文章の離散分布を違う文章の離散分布へ変換すると考えると，その際のコストが最小となる文章が元の文章に最も近い文章となり文書検索へ適用することが可能となる．
EMDを用いた記事関連度計算方式について，以下の図\ref{fig:EMD}に示すような簡略図を用いて説明する．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f2.eps}
 \end{center}
 \caption{EMDによる記事関連度計算方式}
 \label{fig:EMD}
\end{figure}

ある文書$A$と$B$があったとき，文書$A$を文書$B$に変換する際のコストを考える．それぞれの文書を文中の自立語$\mathit{Word}_{Ai}，\mathit{Word}_{Bj}$の離散分布と考える．まず自立語それぞれには重みの付与を行うが，本稿では$tf・idf$の考え方を用いた．

語の網羅性である$tf$は，文書$A$中に出現する語$\mathit{Word}_{Ai}$の頻度$\mathit{tfreq}(\mathit{Word}_{Ai}, A)$を文書$A$中のすべての語数$\mathit{tnum}(A)$で割ったものを利用する．算出式は以下のようになる．
\begin{equation}
\mathit{tf}(\mathit{Word}_{Ai}, A)=\frac{\mathit{tfreq}(\mathit{Word}_{Ai}, A)}{\mathit{tnum}(A)}
\end{equation}

次に語の特定性である$idf$については，概念ベース$idf$\cite{Article_09}を用いた．概念ベースは一次属性，二次属性，というように$N$次までの属性の連鎖集合を持つ．この$N$次まで属性を展開した空間内で，ある概念$X$を属性として持つ概念数から算出されるのが概念ベース$idf$である．概念ベース$idf$の算出式は以下のように定義される．
\begin{equation}
 CV_N(\mathit{Word}_{Ai})=\log\frac{V_{\mathit{all}}}{\mathit{df}_N(\mathit{Word}_{Ai})}
\end{equation}
$CV_N(\mathit{Word}_{Ai})$は$N$次属性空間内における概念 $\mathit{Word}_{Ai} $の概念ベース$idf$である．$V_{\mathit{all}}$は概念ベースに定義されている全概念数，$\mathit{df}_N(\mathit{Word}_{Ai})$は$N$次属性集合内において概念 $\mathit{Word}_{Ai} $を属性として持つ概念の数である．本稿では\cite{Article_09}の報告より最も精度が良いとされる三次属性空間内における概念ベース$\mathit{idf}$を用いた．

以上で示した式により，自立語$\mathit{Word}_{Ai}$へ付与する重み$w$は次のような式で定義される．
\begin{equation}
w= \mathit{tf}(\mathit{Word}_{Ai}, A){\times} CV_3(\mathit{Word}_{Ai})
\end{equation}

つまりある自立語の重みは，自立語の網羅性$\mathit{tf}$と自立語の概念ベース$\mathit{idf}$を掛け合わせることで与えられる．

このようにして文書$A，B$共に自立語への重みを付与する．ここでは例として図\ref{fig:EMD}のように重みが付与されたとする．
EMDでは変換コストの算出を行う際に離散分布を構成する要素同士の距離を用いる．EMDを用いた記事分類方式ではこの距離を自立語同士の関連性であると考え，一致度によってこれを求める．$\mathit{Word}_{A1}$と$\mathit{Word}_{B1}$の距離$\mathit{dis}_{A1B1}$は次の式で表される．
\begin{equation}
 \mathit{dis}_{A1B1}=1-\mathit{DoM}(\mathit{Word}_{A1}, \mathit{Word}_{B1})
\end{equation}
一致度は関連性が高いと値が大きくなるため，1から引いた値を距離としている．ここで$\mathit{Word}_{A1}$と$\mathit{Word}_{B1}$の間の変換コスト$\mathit{cost}_{A1B1}$は次の式で算出される．
\begin{equation}
 \mathit{cost}_{A1B1}=\mathit{dis}_{A1B1}{\times}1.5
\end{equation}
これは$\mathit{Word}_{A1}$と$\mathit{Word}_{B1}$の距離に重みを掛けたものである．$\mathit{Word}_{A1}$と$\mathit{Word}_{B1}$が持つ重みは同じく1.5であるため供給量と需要量が合致し，$\mathit{Word}_{A1}$からの重みの運送はこの時点で終了する．
同様にコストの計算を行っていき，最終的にすべての運送経路のコストを足し合わせたものがEMDとなる．図\ref{fig:EMD}の例ではEMDは次のように表される．
\begin{gather}
 \mathit{EMD}= \mathit{cost}_{A1B1}+ \mathit{cost}_{A2B2}+ \mathit{cost}_{A2B3} \\
 \mathit{cost}_{A1B1}=\mathit{dis}_{A1B1}{\times}1.5 \\
 \mathit{cost}_{A2B2}=\mathit{dis}_{A2B2}{\times}2.0 \\
 \mathit{cost}_{A2B3}=\mathit{dis}_{A2B3}{\times}1.0
\end{gather}

以上のような式で算出されたEMDの値の最小値を最適化計算で求めて文書間の類似性を算出している．


語の変換処理の流れ
\label{nagarezu}

語の変換処理では入力された文から難解語を自動的に判別し，関係語辞書\cite{Article_10,Article_11}による馴染みのある語への変換，もしくは国語辞書による文への変換を行う．具体的な処理の流れを図\ref{fig:nagare}に示す．

まず入力文を構成する単語の内，馴染みのない語を単語親密度の閾値により判別し，難解語とする．この難解語をシソーラス\cite{Book_02}上で検索し，難解語を意味的に包含するノードの中にノード名「具体物」が存在する場合には$N$語変換を，それ以外の場合には1語変換を先に行う．これは具体的な物を示す単語は別の1語に変換することが困難であるため，シソーラスにより具体物と判断できる語に関しては$N$語変換のみによって変換を行うためである．例えば「サリドマイド」のように具体的な薬品名を別の1語に変換することを考えると，物質を示す化学式や化合物名などが挙がる．それらは平易な表現とは言いがたく，そもそも難解な具体物の別称が平易であることは少ないと考えられる．この場合ならば「睡眠薬の一種」という文による変換を行えば自然でかつ平易な表現となる．

ノード「具体物」を上位に持たない語は，まず1語変換の処理を行う．ここでは語の同義，類義関係を示した関係語辞書から難解語の同義語および類義語を取得することで変換候補語を得る．これら変換候補語と難解語との関連度を算出し，最も高い関連度の候補語を用いて変換を行う．ただし，この際の関連度には下限値を設定し，最大関連度が閾値以下の場合には1語変換によって得られた候補語の信憑性が薄いと判断して$N$語変換へ処理を移す．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f3.eps}
 \end{center}
 \caption{語の変換処理の流れ}
 \label{fig:nagare}
\end{figure}

$N$語変換では国語辞書から変換候補文を取得して変換を行う．難解語が多義性を持つ場合には複数の変換候補文を取得することになるため，元の記事中で使われている意味をもつ変換候補文を記事関連度計算方式により判別する．また，難解語をそのまま変換候補文に変換した場合，辞書特有の言い回しや記事全体での情報の重複などにより元の文が不自然になる場合がある．そこで元の文と変換候補文との比較を行い，不要語句の削除を行うことで変換による不自然さを排除する．これらの処理を行った上で得られる文を用いて新聞記事中の1文を変換する．


難解語の判別
\label{ikiti}
まず入力された新聞記事から，変換すべき馴染みの薄い語を判別する処理を行う．入力された新聞記事を句点（“。”もしくは“．”）を区切りとして1文ごとの記事文に分割して処理を行う．1文に対して形態素解析を行い，各単語の単語親密度に閾値を定めることによって馴染みの有無を判断し，馴染みの無い単語を難解語とする．本稿では会話のための資源として新聞記事を用いることを背景としているため，単語の馴染み深さの基準は「一般的な会話で使われる単語であるか否か」とする．この基準の作成には日本語話し言葉コーパス\cite{Book_03}を用いた．


\subsection{閾値の決定}
\label{ikiti_hyouka}

日本語話し言葉コーパスとは日本語による発話音声を大量に収集したデータベースである．収録されている発話音声中の語数は約750万語，時間は約66時間分となっている．発話音声には一般的な対話や学会講演といった様々なデータが収録されているが，このうち対話の音声を用いて「一般的な会話で使われる単語」の調査を行った．表\ref{tab:nihongo}にデータの一部を示す．
\begin{table}[b]
\vspace{-0.5\Cvs}
\caption{日本語話し言葉コーパスの例}
\label{tab:nihongo}
\input{02table03.txt}
\end{table}

単語親密度の閾値を決定するために，表\ref{tab:nihongo}に示したような日本語話し言葉コーパスの対話データを構成する単語2,000語と，新聞記事中の単語2,000語とを無作為に抽出し，それぞれの単語親密度の平均と分布を調査した．その結果，新聞記事における単語親密度の平均が5.74，標準偏差は0.70，対話データにおける単語親密度は平均が6.05，標準偏差が0.66となった．対話において用いられる語の単語親密度の平均の方が，新聞記事より高い値になっている．この事から会話に利用するには新聞記事中の単語は馴染みが薄いことがわかる．

新聞記事における単語親密度のデータ群（$A$とおく）と対話データにおける単語親密度のデータ群（$B$とおく）が，お互いにできるだけ他方の分布に属さないような値を閾値とすれば，「一般的な会話で使われる単語」を判別する閾値になると考えられる．そこで確率密度関数を用いて最適な閾値の調査を行った．確率密度関数は以下の式によって求める．
\begin{equation}
f_{(x)}=\frac{1}{\sqrt[ ]{\mathstrut (2\pi\sigma^{2})}}\mathrm{e}^{\frac{(x-\mu)^{2}}{\sigma^{2}}}
\end{equation}
ここで$\mu$は単語親密度の平均，$\sigma$は標準偏差である．ある閾値があった時に，$A$に属するデータが閾値を越える確率および$B$に属するデータが閾値を越える確率を算出し，双方の和が最も小さい時の閾値を$A$と$B$を区切る最適な値とした．その結果，新聞記事に用いられる単語と一般的な会話で使われる単語の単語親密度による閾値は5.82となった．よって，入力された新聞記事中の単語の内，単語親密度が5.82以下の単語を難解語と判別し，語の変換処理を行うこととした．


\subsection{閾値の評価}

前節で決定した閾値が，人間と同じレベルで馴染み深い語と難解語を判別できるかの評価を行った．単語親密度が5.82よりも大きい，つまり馴染み深いと判断された200語と，単語親密度が5.82以下，難解語と判断された200語を新聞記事からランダムに取得し，それらを人間の目視で評価した．評価は著者，共著者を含まない被験者3名（男性2名，女性1名）で行い，それぞれの語が会話に出現する語としたときに難解と感じるか，平易と感じるかの判断を行った．なおこのとき，被験者には評価を行う合計400語が単語親密度の閾値以上であるか否かは知らせていない．多数決により2名以上が難解と感じた語は「人が難解と感じる語」，2名以上が平易と判断した語を「人が平易と感じる語」とした．単語親密度の閾値によって馴染み深いと判断された200語については「人が難解と感じる語」であった場合に×，「人が平易と感じる語」であった場合に○と評価する．単語親密度の閾値によって難解語と判断された200語については，「人が難解と感じる語」であった場合に○，「人が平易と感じる語」であった場合に×と評価する．表\ref{tab:ikitiHyouka}に閾値の評価結果を示す．

\begin{table}[t]
\caption{閾値の評価結果}
\label{tab:ikitiHyouka}
\input{02table04.txt}
\end{table}

各評価者2名ずつのkappa係数はそれぞれ0.729，0.668，0.790であった．結果として，「人が難解と感じる語」を83.0\%の精度で難解語であると判断できた．また，「人が平易と感じる語」に関しては99.5\%の精度で馴染み深い語，つまり変換の必要がない語であると判断することができた．



1語変換

1語変換では1つの単語をより平易な別の1つの単語に変換する．難解語の同義語・類義語を取得してこれらを変換候補語とし，その中から変換に最も適した語を選択する．本稿における変換に適した語とは，変換前の語と比べて平易であり，かつ意味が同じ語である．平易であるかどうかの判断は単語親密度により行う．また，変換前と意味が同じ語を適切に選択するために関連度計算方式を用いた手法を提案する．


\subsection{変換候補語の取得}

変換候補語には難解語の同義語・類義語を用いる．これにより難解語と同じもしくは近い意味を持つ別の単語群を得ることができる．同義語・類義語の取得には関係語辞書を用いた．
関係語辞書とは国語辞書に記載されている定義文から，見出し語の同義語，類義語といった関係語を自動的に抽出した辞書である．関係語の抽出手法に関しては\cite{Article_10}および\cite{Article_11}において示されている．定義される関係語の例を表\ref{tab:gokankei}に示す．

\begin{table}[b]
\vspace{-0.5\Cvs}
\caption{関係語辞書の例}
\label{tab:gokankei}
\input{02table05.txt}
\end{table}

この辞書から得られる同義語，類義語を1語変換における変換候補語とする．表に示したように，1つの単語に対して複数の同義語・類義語が定義されている場合があるため，変換候補語は複数の単語群となる．


\subsection{単語親密度と関連度による変換語の選出}

\begin{figure}[b]
 \begin{center}
  \includegraphics{20-2ia2f4.eps}
 \end{center}
 \caption{変換語の選出}
 \label{fig:syorirei}
\end{figure}

変換候補語の語群から1語変換に適切な変換語を選出する．選出には変換候補語の単語親密度および，難解語と変換候補語との関連度を用いる．まず同義語・類義語として得られた語のうち，\ref{ikiti}章で述べた閾値5.82以上の単語親密度を持つ語を選出する．これは単語親密度が高く馴染みが深いと判断される語であるほど，平易な変換に適すると考えられるためである．しかし単語親密度は馴染みの深さのみを表現する数値であり，語と語の意味の近さに関しては考慮されていない．変換を行う以上，難解語と最も意味の近い語が選出されるべきである．そこで語の意味を定量化する手法として，\ref{DOA}節で述べた関連度計算方式を用いる．単語親密度が閾値以上である変換候補語の中から，元の難解語との関連度が最も高い語を選出することで「平易性がある語のうち，最も意味が近い語」を変換語とすることが出来る．具体的な変換候補語の選出方法について，「わが国は支配者の法を否定した．」というトルコの憲法改正についての記事の一部を用いて説明する（図\ref{fig:syorirei}）．

この文の中で「法」という語の単語親密度は5.75であり，これは\ref{ikiti}章で述べた閾値5.82を下回るため難解語となる．「法」の同義語・類義語から「法律」「規則」「方法」「道理」という4つの変換候補語が得られる．これら変換候補語から，最も適切な変換語を選択する．

まずそれぞれの単語親密度を見ると，「道理」は単語親密度が5.44となり閾値5.82に達していないため変換語から外れる．ここで各変換候補語と元の難解語「法」との関連度を算出し，最も関連度が高い語を変換語として選出する．この例では単語親密度が最も高い「方法」ではなく，関連度の最も高い「法律」が変換語として選ばれることになる．



\subsection{1語変換から$N$語変換へ移行する条件}
\label{1Nzyouken}

難解語と変換候補語との関連度に閾値を定め，閾値を越える変換候補語が存在しない場合には$N$語変換を行う．これは関連度が低いということは難解語と変換候補語との関連性が薄く，変換には不適切であると判断できるためである．

関連度の閾値設定は概念ベースの評価方法である$X$-$ABC$評価\cite{Article_04}を参考にして行う．この評価は関連度の値を比較することで概念ベースを評価する方法であり，表\ref{tab:xabc}に示すような評価セットを用いる．

\begin{table}[b]
\caption{$X$-$\mathit{ABC}$評価セットの例}
\label{tab:xabc}
\input{02table06.txt}
\end{table}

評価セットはある基準概念$X$と，この概念$X$と非常に関連が強い概念$A$，概念$A$ほどではないが関連があると思われる概念$B$，まったく関連のない概念$C$によって構成される．実際に用いた評価セットは\cite{Article_05}に示された方法で人手により作成された500組のセットとなっている\cite{Article_04}．

ここで，$X$-$A$の関係は基準概念$X$と非常に関連が強い概念$A$というもので，実際の評価セット作成時には\cite{Article_05}に示された方法を基に$X$の同義ないしは類義語となりうる語を収集している．このテストセットは被験者実験によって作成されており，つまり人間の感覚に合致した評価セットになっている．人間の自然な感覚を反映しているこの評価セットにおいて同義，類義関係と判断された$X$-$A$間の関連度は，本提案手法における難解語と変換候補語との関連性の有無を判断する閾値に値すると考えた．

評価セットは500組存在するため，$X$-$A$間の関連度も500個の値が算出される．そこから人間が同義，類義と感じる語同士の関連度を意味する値として平均値を算出した．これは\cite{Article_04}において用いられている評価式の中で，まったく関連のない$X$-$C$間の関連度の平均値を「関連がない語の間で算出される関連度」として用いる考え方に倣い，同義，類義関係にある$X$-$A$間の関連度の平均値を「同義，類義関係の語の間で算出される関連度」とした．$X$-$A$間の平均値は0.34，分散は0.04，$X$-$C$間の平均値は0.002，分散は$9.43×10^{-6}$であった．よって提案手法では，難解語と変換候補語との関連度が$X$-$A$間の平均値である0.34より低かった場合には$N$語変換へ処理を移行する．



$N$語変換

1語変換では変換ができない場合，つまり1つの語では説明できない語を相手に伝える際に人間はその語の意味を文で伝える．そこで$N$語変換では1つの単語を$N$語の単語群，つまり文で変換することで1語変換ができない難解語の変換を行う．

\ref{nagarezu}章に示した通り，まずシソーラスにおいて難解語の包含関係にあるノードに「具体物」が存在する場合には1語変換が不可能であると判断し，$N$語変換を行う．例えば「サリドマイド」という具体物は一般的に馴染みの薄い語であるが，「催眠薬の一種」という文章で変換されることでその内容を理解することが出来る．このように具体的な物を示す語は，同じ意味を持つ別の1語に変換するよりも具体物の説明を文章で行う方が馴染みのある表現になる．また\ref{1Nzyouken}節に示したように1語変換における変換候補語の関連度が閾値以下の場合にも，1語変換では適切な変換を行えなかったと判断して$N$語変換を行う．


\subsection{変換候補文の取得}

$N$語変換では国語辞書\cite{Book_04}に記載された語の定義文を，変換を行うための文（変換候補文）として利用する．国語辞書の定義文は語の意味を説明する文であるため，これを利用することで難解語の意味を損ねることなく$N$語による変換が可能になる．また，定義文が端的かつ正しい日本語表現で記されているため，変換後の記事表現が煩雑にならないと考えられる点で，$N$語変換の資源として国語辞書は適当である．

本稿で使用した国語辞書には238,000語の見出し語とその定義文が格納されている．このうち，固有名詞および単一で意味を成さない代名詞，助詞の見出し語を省いた94,544語の見出し語と定義文を$N$語変換に用いた．


\subsection{多義語の意味特定}

難解語が多義語であった場合，それぞれの意味から辞書の説明文が得られるため変換候補文が複数取得される．そこで適切な文を選択するために\ref{EMD}節で説明した記事関連度計算方式を用いて難解語が含まれる元の文に意味が近い変換候補文を選択して変換を行う．図\ref{fig:tagigo}に具体的な変換候補文の選択方法を示す．

\begin{figure}[b]
 \begin{center}
  \includegraphics{20-2ia2f5.eps}
 \end{center}
 \caption{多義語の意味特定の具体例}
 \label{fig:tagigo}
\end{figure}

「日中」という語には図に示すように2つの意味が定義文として記載されており，多義語である．このような多義語の場合は，辞書のそれぞれの定義文と，難解語を含む元の記事文との間で記事関連度の算出を行い，値の高い変換候補文を語の変換に用いる．例の場合では「日中」は「日本と中国」という候補文が選択され，記事は「日本と中国の未来志向の…」と変換される．


\subsection{不自然さの排除}
\label{NoNeed}

辞書の定義文の中には，そのままの形で$N$語変換に用いると日本語として不自然になってしまうものがある．例えば「財政再生計画を策定する」という文中の「策定」は単語親密度が3.16の難解語であり，1語変換では関連度が閾値より大きい変換候補語が得られず，$N$語変換が行われる語である．この時，辞書における「策定」の定義文「政策や計画などを考えて決めること」をそのまま語の変換に用いてしまうと「財政再生計画を政策や計画などを考えて決めること」となり，日本語として不自然である．このような変換によって起こる不自然さの排除方法として，不要語の削除と記事中の情報の重複排除を行う．

まず，不要語の削除について述べる．不要語とは辞書によく出現する言い回しのうち，変換を行う際には必要の無い語の事を指す．この不要語を人手で判断してリスト化したものが不要語リストである．図\ref{fig:fuyougo}に具体的な不要語の一覧を示す．

\begin{figure}[b]
 \begin{center}
  \includegraphics{20-2ia2f6.eps}
 \end{center}
 \caption{不要語の一覧}
 \label{fig:fuyougo}
\end{figure}

例えば「蜀魂」という語の定義文は「ホトトギスの別名」となっているが，実際に「蜀魂」という語を変換する際に必要となる語は「ホトトギス」の部分のみである．このように辞書の定義文に存在する不要な言い回しは変換の際に削除する．

不要語を削除した後に記事中の情報の重複排除を行うが，これには意味理解システム\cite{Article_03}を利用する．このシステムは入力された文を，6W1H (Who, What, When, Where, Whom Why, How) と用言の8種類に分類する．意味理解システムの出力例を図\ref{fig:imirikai}に示す．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f7.eps}
 \end{center}
 \caption{意味理解システム}
 \label{fig:imirikai}
\end{figure}

入力文の「誰が」にあたる語は「妹」であり，これが意味理解システムではWhoに分類される．このシステムで元の記事文と辞書から得た変換候補文をそれぞれ処理し，分類が重複した場合には不自然にならないように不要部分を削除する．具体的な例を図\ref{fig:kakusaku}に示す．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f8.eps}
 \end{center}
 \caption{格重複の排除}
 \label{fig:kakusaku}
\end{figure}

図\ref{fig:kakusaku}の例では元の記事文「財政再生計画を策定する」と不要語を削除した変換候補文「政策や計画を考えて決める」の2文である．ここで元の記事文と変換候補文の間で分類に重複があった場合，どちらか一方を用いて出力する文を作成する．具体的には難解語ではない部分で分類の重複が起こった場合には元の記事文を，難解語の部分で分類の重複が起こった場合には変換候補文を用いる．図\ref{fig:kakusaku}を見るとWhatの重複は難解語ではない部分であるため，元の記事文である「財政再生計画」が選択される．逆に用言での重複は難解語の部分であるため，変換候補文である「考えて決める」が選択される．このようにして分類の重複を排除した上で，変換を行い結果を出力する．図\ref{fig:kakusaku}の例では最終的に「財政再生計画を策定する」という元の記事文が「財政再生計画を考えて決める」と変換される．



