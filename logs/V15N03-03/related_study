本稿での提案と最も近い取り組みは，TREC 2001で行われたContext Taskで，これは質問応答システムの文脈追跡（文脈処理）能力を測定するために一連の質問に回答させるというもので，基本的な目的は本稿の提案と同じである[CITE]．
このタスクの実施では，システムがある質問に正解できるかがそれ以前の質問に正解したかに依存しないという「予想に反する」結果が得られている．
これは最初の質問によってそのシリーズの質問すべての回答を含んだ少数の記事が同定されてしまい，その後の質問に正解できるかは文脈処理の能力よりも特定のタイプの質問に回答できるかに依存してしまうためであるとされている．
このため，このようなタスクは現状では文脈処理能力を測定するのに不適切と判断され，その後のTRECでは実施されていない．
このような結果となったひとつの理由は，シリーズを構成する質問の数が3から4と少ないことにあると思われる．
IADタスクではひとつのシリーズは7つ程度の質問で構成することを考えている．
また，IADタスクでいうところのブラウジング型を含んでいないことも大きな原因であろう．
TRECのContext Taskについては，隣り合う質問の回答のうち85%が同じパラグラフに存在したという報告[CITE]があるが，NTCIR-4で用いたテストセットでは，隣り合う質問の少なくともひとつの回答が同じ記事（一概に比較できないが段落より大きい単位と言ってよいと考える）内に存在する割合は，収集型でも83%であったが，ブラウジング型では66%であった．
シリーズ全体を考えれば，ブラウジング型の場合，ニューヨーク・ヤンキーズからキャンベルスープまでを含んだ記事はありえないので，最初の質問に関する処理だけでその後の質問に正解できる記事が得られることはありえない．
収集型についても，すべてが狭義の収集型ではないので，そのトピックに関する記事すべてを検索してもそこから正しく回答を選択することは，何らかの文脈処理なしでは困難である．
狭義の収集型についても，例えば，「小沢征爾」をキーワードとする記事は知識源中に155件あり，そのうちの22件が彼のウィーンフィルへの移籍を扱っているが，その中で彼の誕生日に言及しているものは2件のみである．
また，収集型については，確かにある質問に回答できることと以前の質問への正解率との関係は不明確であるが，狭義の収集型であれば，そこに関係のある必然性はないし，そのことが文脈処理の不必要性の議論につながるとは思えない．
加えて重要なことは，このようなタスク設計がレポート作成を目的とした情報アクセス対話という場面設定の状況に近いということであり，そこに現れる状況に対処する技術として必要とされている点である．
評価尺度についての[MATH]値の提案は，IADタスクに限定されるものではなく，リスト型課題に共通するものである．
TRECのQA Trackでも，2003年より正解数を指定しないリスト型課題が開始されている[CITE]．
評価には単純な[MATH]値が用いられている．
2003年のこの課題の質問は37問とあまり多くなく，``List the names of chewing gums.'', ``Who are female boxers?''等，すべてが事物の列挙を求めるもので，その殆どは，``What Chinese provinces have a McDonald's restaurant?''のように回答のクラスが巧みに指定されており，粒度の問題が生じるような表現，例えば``Where in China does McDnald have a restaurant?''は避けられている．
質問文のみからの判断であるが，問題が出る可能性のあるのはわずかに``What foods can cause allergic reaction in people?''の1問だけである．
TRECにしてこのような状況であり，本稿で議論したようなリスト型課題の問題に注目した提案は著者の知る限り全く行われていない．
参照用のテストセットという考えについては，これもTREC-9において，同じ正解を意図した表現の異なる質問を多数テストセットに含めるという試みがなされている[CITE]．
参照用のテストセットという明確な考えはなく，そこから何が得られたかも明らかにされていないが，より深い分析のための情報を得る試みであったと思われる．
この試みはその後続けられていない．
一問一答型の質問応答システムも質問解析，文書選択，回答抽出等の複数のモジュールから構成されることを考えると，本稿で提案した参照用テストセットだけで充分な情報が得られるわけではないが，少なくとも情報アクセス対話のための質問応答技術をある程度まで区別する役割を果たしていると考える．
対話的な質問応答システムの評価ということでは，テストセットの枠組みに基づかない，より実際に近い状況での実験の報告がある[CITE]．
これらの実験と本稿で提案したテストセットによる評価は，情報検索技術の評価における検索実験での，現実状況での検証と研究室での検証[CITE]とにそれぞれ対応すると考えられる．
前者は実際の利用場面により近い環境での評価となり，多種多様な情報が得られるが，それらの情報は複雑かつ非定型で分析も難しく，実験の実施も一般に高価である．
一方で後者は，本来の利用場面の複雑さを切り捨て，理想化単純化された状況での能力を測定することになるが，得られるデータの相互比較が比較的容易で，テストセットの再利用が可能なこと等，その実施も安価である．
このように，これらにはそれぞれの長所短所があり，相補的な役割を持っていると考えている．
