準備と設計方針
\label{sec:premodel}

{\name}に必要な機能を特定するために，
\figref{fig:toyota}に，日本語，英語，中国語の3言語による，多言語{\text}の例を挙げて説明する．
中国語の下には，ピンインを表記した．

既存の手法では，\figref{fig:toyota}の文章を入力するためには，
日本語から英語への切り替えと戻す操作で2回，日本語から中国語への切り替えと戻す操作が2対あるので4回，
合計6回のIME切り替え操作が必要となる．
このようなIME切り替え操作は，文字種が違う言語間だけでなく，
同じアルファベットを使う英語やフランス語の間でも，アクセント記号付きの
文字を入力する場合に必要になる．

\begin{figure}[t]
\begin{center} 
\includegraphics{15-5ia7f1.eps}
\caption{日本語，英語，中国語による多言語{\text}の例} 
\label{fig:toyota} 
\end{center} 
\end{figure}

一方，{\name}では，キー列から言語を判別し，IMEを自動的に切り替える．
例えば\figref{fig:toyota}では，``bi-ruha,''を日本語，``beer''を英語，``pijiu''を中国語といったように
言語を判別してユーザーに提示する．言語判別が間違っていれば，ユーザーが必要に応じて言語を訂正する．
このことから，大きく分けて次の2つの機能が必要であることがわかる．
\begin{enumerate}
\item キー列から言語を判別する機能
\item 言語判別の結果をユーザーに提示し，訂正情報を受け取とるユーザーインターフェース
\end{enumerate}

(1)については\secref{sec:model}で，(2)については\secref{sec:design}で扱う．

一般に，{\text}を入力するときには，多くの言語で，{\text}を区切るための{\delim}を
仮定することが可能である．
例えば，スペースを用いた分かち書きが，その典型的な例として挙げられ
\footnote{スペースを用いた分かち書きは，英語やフランス語などアルファベットを用いる言語に限らず，
字種の異なるアラビア語，ヘブライ語，韓国語などでも行われている一般的な習慣である．}，
この場合には，スペースキーを{\delim}として採用することが可能である．
日本語や中国語では，通常，分かち書きは行わないが，漢字に変換する際にスペースキーを打鍵しているので，
やはりスペースキーを{\delim}として使用することが可能である．

そこで，{\name}では，{\delim}から次の{\delim}までに挟まれるキー列を「トークン」と定義する．
トークンを単位として入力を行い，トークンの属すべき言語\footnote{厳密には，ユーザーが入力しようとしているキーボード配列(Qwerty, Dvorak, Azertyなど)も同時に判別している．}を判別する．
例えば，\figref{fig:toyota}におけるトークンとしては，``bi-ruha,''，``beer''，``pijiu''が挙げられる．トークンは単語とは限らず，連文節変換を用いる場合などは，単語よりも長い単位となる場合もある．

トークンによっては，そもそも，その属すべき言語が曖昧である場合がある．
例えば，``sushi''というトークンは，英語としての``sushi''にも日本語の``寿司''に対する入力にも
とらえることが可能である．借用語の多くにこのような曖昧性がある．
また，ヨーロッパの多くの言語で使用されるアクセント記号は
しばしば省かれることがあり，この場合にも曖昧性が生じる場合がある．
例えば，``fur''は通常は英単語であるが，``$\rm{f\ddot{u}r}$''というドイツ語のウムラウト記号が
省かれた形としても，使用されることがあり，英語とドイツ語の間で曖昧性が生じる．

ただし，このような曖昧性は，実用上は必ずしも問題とならない場合もある．
ユーザーは，例え言語判別に失敗していても，最終的に入力したトークンが正しい文字列に
変換されていれば問題とは認識しないと考えられる．
例えば，上記の後者の例である``fur''は，英語とドイツ語の間で曖昧性があるものの，どちらに判別されたとしても，
最終的には``fur''に変換されるため，問題を生じない．
一方，上記の前者の例である``sushi''では，英語と判別された場合は``sushi''と変換され，
日本語と判別された場合は``寿司''などに変換されるため，ユーザーの観点からは問題を生じる．
以上のように，この曖昧性が問題となるか否かを判定することは，個々の言語に対する具体的な知識を必要とするため難しい．そこで本論文では，\secref{sec:evaluation}で示すように，単純に
言語判別の精度を用いて評価を行った．

トークンの属すべき言語は，事前に用意する学習コーパスが多くなるほど明確に判別することが可能になるが，
その分，{\name}が対応可能な言語は限られてくる．
{\name}は入力システムであるため，多くの言語に対応可能であることが望ましいと考えた．
そこで，より多くの言語に対応を優先する設計方針を立て，言語判別を\secref{sec:model}で述べるように設計した．
また，その言語判別を用いるユーザーインターフェースを\secref{sec:design}で述べるように設計した．


言語判別 
\label{sec:model} 


\subsection{言語判別モデル}

言語判別の確率モデルには，隠れマルコフモデル(HMM)を用いた．
隠れ状態を言語として，隠れている言語からトークンが記号列として観測されるとする． 

ここでの目的は，$\mathrm{P}(l_1^{m}, t_1^{m})$を最大にするような$\hat{l}_1^m$を求めることである
\footnote{ここで，$t_u^v$は，$v \geq u$のとき$v-u+1$個の要素からなる列$t_u^v=(t_u, t_{u+1},\dots,t_v)$を表し，$v < u$のとき空列$t^v_u=()$を表す．}．
ただし，$l \in L$は言語集合$L$中の言語であり，$t$はトークンである．
    HMMでは，$\mathrm{P}(l_1^m, t_1^m)$を\eqref{eq:approx}のようにして最大化する．
\begin{align} 
  \hat{l}_1^m &= \argmax_{l_1^m \in L} \mathrm{P}(l_1^{m}, t_1^m) \nonumber 
\\
  &= \argmax_{l_1^m \in L} \mathrm{P}(t_1^m | l_1^m)\mathrm{P}(l_1^m) \nonumber \\
  & \approx \argmax_{l_1^m \in L} \left(\prod_{i=1}^m P(t_i|l_i) \right) 
  \left(\prod_{i=1}^m P(l_i|l_{i-k}^{i-1}) \right) 
  \label{eq:approx} 
\end{align}
\eqref{eq:approx}では，第一項を
$\mathrm{P}(t_1^m|l_1^m) \approx \prod_{i=1}^m P(t_i|l_i)$のように，また，第二項を
$\mathrm{P}(l_i|l_1^{i-1}) \approx P(l_i|l_{i-k}^{i-1})$のように，近似した．
ここで，第一項は出力確率であり，第二項は遷移確率である．



\subsection{出力確率の推定} 
\label{sec:output}

出力確率$P(t_i|l_i)$は，ある1つの言語$l_i$からトークン$t_i$が出力される確率である．
トークンを単語とみなせば，この確率は単純に言語$l_i$における単語の出現確率であり，
その推定手法は自然言語処理の分野において，よく研究されている．

$P(t_i|l_i)$の推定するには，言語$l_i$のコーパスが必要となる．
十分に大規模な言語$l_i$のコーパスを用いれば，$P(t_i|l_i)$は，
単純にコーパス中にトークン$t_i$が出現した
頻度で近似することが可能である．
しかし，この方法は，入力可能な言語を大規模なコーパスを入手することが可能な言語に
限定してしまうため，\secref{sec:design}の最後で述べた，
より多くの言語に対応するという方針に反する．


そこで，本研究では，トークンを入力したキーの列と捉え，キー列に関するスムージングを行うことで，$P(t_i|l_i)$を計算する方法を採用した．まず，トークン$t_i$の長さを$|t_i|$とし，トークン$t_i$をキー列$c_1^{|t_i|}=(c_1, c_2, c_3, \dots, c_{|t_i|}) $として捉える．すなわち，$t_i=c_1^{|t_i|}$とする．
例えば，$t_i$=``pijiu''の場合，$|t_i|=5$で，$t_i=c_1^5=($`p', `i', `j', `o', `u'$)$となる．
次に，この$c_1^{|t_i|}$について，最大$n_{max}$までの$n+1$-gram確率を計算することで，スムージングを行い，$P(t_i|l_i)$を次のように計算する．
\begin{equation} 
  P(t_i|l_i)=P(c_1^{|t_i|} | l_i) \approx \prod_{r=1}^{|t_i|} P(c_r|c_{r-n_{max}+1}^{r-1}, l_i) 
  \label{eq:decompose} 
\end{equation} 

このスムージングの手法としては，さまざまなものが提案されているが，本研究では，
{\em Prediction by Partial Matching} (PPM) という手法を採用した．
このPPMは，	データ圧縮の分野で最初に提案され，後に自然言語処理に応用された手法である\cite{textcomp}，\cite{teahan00}, \cite{nle06}．

PPMは，データ圧縮の分野で提案されたため，学習を動的に行いながら判別を行うことが，可能なように設計されているという特徴がある．
この特徴によって，ユーザーが誤判別を訂正した場合，瞬時にその情報を確率値にフィードバックして次の判別に利用することが可能となる．この点が，{\name}のような入力システムに適した特徴であると考えたので採用した．
以下，PPMの詳細について説明する．

PPMは，$c_1^{r-n_{max}}$までの頻度情報をもとに，現在の文脈$c_{r-n_{max}+1}^{r-1}$の次にキー$c_r$がくる確率$P(c_r|c_{r-n_{max}+1}^{r-1})$を推定する．
\begin{equation}
  P(c_r|c_{r-n_{max}+1}^{r-1}) = \sum_{n=-1}^{n_{max}-1} w_n p_n(c_r) \label{eq:weights}
\end{equation}

ここで$p_n(c_r)$は，次のように，長さ$n$の文脈にキー$c_{r}$が続く$n+1$-gram 確率を表す．
$X_n$，$x_n$は，それぞれ，$c_1^{r-n-1}$中の$c_{r-n}^{r-1}$, $c_{r-n}^r$の頻度とする．
\[
  p_n(c_r) = \frac{x_n}{X_n}
\]

\eqref{eq:weights}において，重み$w_n$は，
基本的には，長い$n+1$-gram確率を重く，短い$n+1$-gramを軽く重みづけるのが望ましい．ただし，重みが偏りすぎることも精度を悪化させる．PPMでは，この重み$w_n$を，簡単な計算で適切に設定するために，エスケープ確率$e_n$という概念を導入して，次のように計算する．
\begin{equation} 
\begin{split}
  e_{-1}& =0\\
  w_n &= (1-e_n) \prod_{n' = n+1}^{n_{cont}} e_{n'} \ \ (-1 \le n < n_{cont}) 
  	\label{eq:ppm} \\
  w_{n_{cont}} &= (1-e_{n_{cont}})
\end{split}
\end{equation}
ただし，$n_{cont}$は，$X_n \ne 0$を満たす$n_{max}-1$以下で最大の$n$である．
エスケープ確率$e_n$は，現在の文脈に一度も続かなかったキーに割り当てる確率を表す．すなわち，現在の長さ$n$の文脈$c_{r-n+1}^{r-1}$に一度も続かなかった新しいキー（これを「エスケープ」と呼ぶ）が，エスケープ確率$e_n$で現れると考える．反対に，現在の長さ$n$の文脈$c_{r-n+1}^{r-1}$に続いたことのあるキーは，エスケープ確率$e_n$を新しいキーに割り当てた分を減らし，単純な頻度に$1-e_n$倍をした確率で出現すると考える．

このエスケープ確率をどのように定義するかによって，PPMは，PPMA，PPMB，PPMCのように分類される．
その中でも，本研究では，基礎的かつ比較的性能が高いとされる
PPMCを用いた\footnote{ PPMは大規模圧縮においてこそ性能の差が問題となるが，入力応用上はどのPPMを用いても，大きな差には
つながらないとの報告もある\cite{nle06}．}\cite{textcomp}．


PPMCでは，エスケープ確率を次のように計算する．ただし，$q_n$は，$c_1^{r-n-1}$中の，$c_{r-n}^{r-1}$のあとに続くキーの異なり数である．
\begin{equation} 
  e_n = \frac{q_n}{X_n+q_n} \label{eq:PPMC}
\end{equation} 

\eqref{eq:PPMC}から，PPMCでは，次のキー$c_r$の確率$P(c_r|c_{r-n_{max}+1}^{r-1})$は，
キー列の$n$-gramの頻度$X_n$と$n$-gramの後に続くキーの異なり数$q_n$が分かれば，推定することが可能であることがわかる．
$n$-gramの頻度と$n$-gramの異なり数は単純な加算によって学習中に更新することが容易であるため，
PPMCは動的に学習することに適している．


\subsection{遷移確率の推定} 
\label{sec:trans}

ここでは，\eqref{eq:approx}の第2項である，
$k_{max}$-gramまでの，言語$k+1$-gramによる文脈を考慮した遷移確率$P(l_m|l_{m-k_{max}+1}^{m-1})$を推定する手法について述べる．
この遷移確率は，大量の多言語{\text}から学習することが可能であるが，そのような
大量の多言語{\text}は，通常，入手することが難しい．
ユーザーが過去に確定した言語列$l_1^{m-1}$を正解とみなし，$l_1^{m-1}$から動的に遷移確率を推定する
ことが可能であれば，この学習データの入手の問題を回避することが可能となる．

この方法は，\secref{sec:output}と同様で，学習データが少量であることを，利用中のユーザーからの情報を
動的に利用して補い，精度を向上させることが狙いである．
したがって，遷移確率の推定方法には，\secref{sec:output}と同様，PPMを用いた．
具体的には，\eqref{eq:weights}における$c_r$を$l_m$と読み替えることで，
遷移確率$P(l_m|l_{m-k_{max}+1}^{m-1})$を分解して推定した．

\secref{sec:output}で述べた出力確率の推定の場合との違いの一つは，
遷移確率は，出力確率ほど出現位置の離れた要素に依存しない，すなわち，長距離依存性が小さいことである．
これは，次のように考えれば直感的に理解することが可能である．
たとえば，言語3-gramを考えた場合，英語，フランス語，日本語のトークンがこの順番で何回も
出現する{\text}は，まれであると推測される．
したがって，通常は，遷移確率の最大文脈長$k_{max}$を，出力確率の最大文脈長$n_{max}$より小さく取り，
$k_{max} \le n_{max}$としてよい．

ただし，実用上は，これらの最大文脈長の値はある程度の大きさがあれば十分であり，これらの値を細かく調整する必要性は乏しい．
その理由は，\eqref{eq:weights}のように，PPMでは文脈の長さごとに文脈の重要度$w_n$が自動的に決定されるためである．
本研究では，特別な事情がない場合は$k_{max}=n_{max}=5$とした．






ユーザーインターフェース 
\label{sec:design}

ここでは，前節で述べた言語を判別する手法を，ユーザーインターフェースに組み込む方法について説明する．
システムの構造を，\figref{fig:systemstructure}に示す．

{\name}は，\figref{fig:systemstructure}に示すように，ユーザーのキー入力と{\tes}の間に立って両者を仲介する．
まず，ユーザーが入力したキー列を，クライアントが受け取り，クライアントはそのキー列をサーバーに送る．
サーバーでは，サーバー内の「言語判別モジュール」がキー列からユーザーが入力しようとしている言語を判別して，
対応する{\tes}に送る．
{\tes}では，キー列を文字列に変換して，クライアントに送り返す．
この中の言語判別モジュールに，前節で述べた言語判別手法を実装し，組み込んだ．


\begin{figure}[b] 
  \begin{center}
\vspace{-0.5\baselineskip}
\includegraphics{15-5ia7f2.eps}
        \caption{{\name}の構造} 
        \label{fig:systemstructure} 
      \end{center}
\end{figure}

フランス語やドイツ語などヨーロッパ系の言語では，キー列に対して文字列が一意に定まるので，
{\tes}は，単純な置き換えですむ．たとえば，ドイツ語の{\tes}では，日本語のキーボードで``@''に対応するキーを，ドイツ語の``$\rm{\ddot{u}}$''に置き換えている．
一方，日本語や中国語では，キー列に対して文字列が一意に定まらないので，{\tes}がユーザーに候補を提示して
選択してもらう必要がある．
この処理には，既存のかな漢字変換／ピンイン漢字変換のシステムをそのまま用いればよい．
日本語の{\tes}には，Anthy\footnote{http://anthy.sourceforge.jp/}を用い，中国語の{\tes}には，単純なピンイン漢字変換を自作した．

\begin{figure}[b] 
  \begin{center}
\includegraphics{15-5ia7f3.eps}
    \caption{{\name}を用いた入力操作} 
    \label{fig:entryflow} 
  \end{center}
\vspace{-1.5\baselineskip}
\end{figure}

\figref{fig:entryflow}に，{\name}を用いて\figref{fig:toyota}に示す文章の入力例を示す
\footnote{ここでは，Qwerty配列上での入力を仮定している．日本語はローマ字入力，中国語はピンイン入力とする．}．
各ステップにおいて，白黒反転されているところが，ユーザーが入力中の部分である．
言語の判別は，反転部分のキー列に対して行われ，その結果が{\em Locale Window}に表示される．
以下，各ステップを説明する．

    \begin{itemize} 
\item[(a)] 初期の状態では，どの言語も選択されていない．
\item[(b)] キーを押すごとに反転部分のキー列（トークン）から言語が判別され，{\em Locale Window}に表示される．
``bi-ruha,''の``b''を打鍵した時点では，英語と判別されていることがわかる． 
\item[(c)] しかし，``bi-ruha,''まで打鍵すると，正しく日本語と判別される．
\item[(d)] 現在のトークンは日本語と判別されているので，デリミタとなるスペースキーを打鍵すると，
日本語のIMEを通じて日本語の文字列への変換が行われる．
\item[(e)] 日本語のように，キー列文字列への変換候補が複数ある場合は，さらにスペースキーを打鍵することに
よって，通常のかな漢字変換を行うことが可能である．
\item[(f)] ``beer''というトークンが，正しく英語と判別されている．
\item[(g)] ``pijiu''というトークンが，正しく中国語と判別されている．
\item[(h)] (g)でスペースキーを打鍵すると，日本語のかな漢字変換と同様に，中国語のピンイン漢字変換が行われる．
\item[(i)] その後の``toyobare,''というトークンも，正しく日本語と判別されている．
    \end{itemize} 

このように，{\name}を用いることで，ユーザーは，言語の誤判別が発生しない限りIME切り替え操作を行う必要がなく，
ユーザーの負担は大幅に軽減される．

トークンの言語を判別した結果が，ユーザーの望むものと異なる場合は，「誤判別」となる．
誤判別時の処理を，\figref{fig:detectionfail}を用いて説明する．

\begin{figure}[b] 
  \begin{center}
\includegraphics{15-5ia7f4.eps}
    \caption{誤判別時の操作} 
    \label{fig:detectionfail} 
  \end{center}
\end{figure}

言語判別の結果は常に{\em Locale Window}に表示されるので，誤判別の場合を含め，
ユーザーはその結果を常に把握することが可能である．
したがって，誤判別の場合でも，TABキーを押すことで，ユーザーはIMEを手動で
簡単に切り替えることが可能である．
例えば，\figref{fig:entryflow}の``pijiu''は正しく中国語と判別されているが，\figref{fig:detectionfail}(a)のように，
間違って日本語と判別されていたと仮定する．
ここで，ユーザーがTABキーを押すと，IMEが\figref{fig:detectionfail}(b)のように中国語に切り替わる．

{\name}における誤判別は，次の2種類に分類される．
\begin{description} 
\item[誤判別1:] {言語が切り替わるべき時に，言語が切り替わらなかったか本来の言語とは違う言語に切り替わった場合}. 
\item[誤判別2:] {言語が切り替わるべきでない時に，言語が切り替わってしまう場合}．
\end{description} 

既存手法では，言語を切り替えるごとにIME切り替え操作を行わなければならなかったのに対し，
{\name}では，IME切り替え操作は言語判別を失敗したときのみ必要になる．
{\bf 誤判別1}は，{\name}が言語判別を間違えた場合であってもIME切り替え操作回数が増える原因とはならない．
一方，{\bf 誤判別2}は，特に多言語コーパスの大半が1言語から構成されているような場合において，
既存手法と比較した場合のIME切り替え操作回数を増加させてしまう可能性がある．
したがって，{\name}の有効性は，言語を切り替える点での自動判別によるIME切り替え操作の減少量と，
言語を切り替えるべきない点での{\bf 誤判別2}によるIME切り替え操作の増加量とのトレードオフによって決まる．
このトレードオフについては，\secref{sec:decrease}で論じる．


