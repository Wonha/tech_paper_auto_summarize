実験および評価
\label{sec:experi}

本節では，
IREXワークショップの固有表現抽出タスクの訓練データおよび試験データを用いて，
複数の固有表現抽出結果の混合法の実験的評価を行なった結果について述べる．
以下では，訓練データとして用いているCRL固有表現データの
一般ドメインのものを$D_{CRL}$，
評価データとして用いている本試験データのうちの一般ドメインのものを
$D_{formal}$と記す．
ただし，いずれも，表~\ref{tab:MnNE}の「その他」のものは除いている．

\subsection{各モデル単独の出力の比較}
\label{subsec:indiv}


本節では，\ref{subsec:context}~節で述べた各モデル単独の性能について述べ，
各モデルの出力を比較する．
実験に用いたモデルは，\ref{subsubsec:3gram}~節の固定長モデルとしては，
5グラムモデル，7グラムモデル，9グラムモデル，および，
\ref{subsubsec:vgram}~節の可変長モデルである．
また，7グラムモデル，9グラムモデル，および，可変長モデルについては，
\ref{subsubsec:ftr34}~節の三種類の素性の設定も区別して実験を行なった．

まず，表~\ref{tab:indivi_res}に，個々の固有表現抽出モデルを学習するための
訓練データセット$TrI$を$D_{CRL}$とした場合の，
本試験データ$D_{formal}$に対する各モデルのF値($\beta=1$)を示す．
この結果からわかるように，単独のモデルでは，5グラムモデルが最も高い性能を示す．
また，7グラムモデルおよび9グラムモデルは，素性の設定に関わらず，ほぼ同等の性能を示している．

次に，最も性能のよい5グラムモデルの出力と，他のモデルの出力との違いを調べるために，
5グラムモデル以外の各モデルの出力について，5グラムモデルの出力との和集合を求め，
本試験データ$D_{formal}$の正解データに対する再現率を算出した．
また，5グラムモデル以外の各モデルの誤出力と5グラムモデルの誤出力の間の重複率
\begin{eqnarray*}
 誤出力の重複率 & = & 
	\frac{\begin{tabular}{c}
	二つのモデルの誤出力間で
	重複する固有表現数
	\end{tabular}}
	{\begin{tabular}{c}
	5グラムモデルの誤出力の
	固有表現数
	\end{tabular}}
\end{eqnarray*}
を求めた．これらの結果を表~\ref{tab:dif_indivi}に示す．
特に，和の再現率が最も高く，誤出力の重複率が最も低い結果
(この場合は，可変長モデル(形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性$=$全て)
との差分)を{\bf 太字}で示す．

表~\ref{tab:indivi_res}および表~\ref{tab:dif_indivi}の結果から分かるように，
7グラムモデルおよび9グラムモデルは，5グラムモデルと比べて出力の和集合の再現率が低く，
かつ誤出力の重複率も高いことから，相対的に5グラムモデルと似通ったモデルであると言える．
一方，可変長モデルは，7グラムモデルおよび9グラムモデルと比べて，
相対的に5グラムモデルとの類似性が小さいことがわかる．
特に，誤出力の重複率が比較的小さい点が目立つ．


\begin{table}
\begin{center}
\caption{本試験データ$D_{formal}$に対する各モデル単独の性能 (F値($\beta=1$) (再現率/適合率) (\%))}
\label{tab:indivi_res}
\begin{tabular}{|l||c|c|c|} \hline
	& \multicolumn{3}{|c|}{形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性} \\ \cline{2-4} 
        	& \ \ \ 全て\ \ \  & 語彙+品詞 & 語彙 \\ \hline\hline
7グラムモデル  	& 80.78 (78.44/83.27)	& 80.81	(78.44/83.33) & 80.71 (78.51/83.03)	 \\ \hline
9グラムモデル  	& 80.13	(77.87/82.54) & 80.53 (78.22/82.98) & 80.53 (78.37/82.82) \\ \hline
可変長モデル  & 45.12 (51.50/40.15) & 77.02 (75.86/78.21) & 75.16 (73.78/76.58) \\ \hline\hline
5グラムモデル  	& \multicolumn{3}{|c|}{\bf 81.16 (78.87/83.60)} \\ \hline
\end{tabular}
\vspace*{-.5cm}
\end{center}
\end{table}

\begin{table}
\begin{center}
\caption{5グラムモデルの出力と各モデルの出力との差分 (和の再現率/誤出力の重複率) (\%)}
\label{tab:dif_indivi}
\begin{tabular}{|l||c|c|c|} \hline
	& \multicolumn{3}{|c|}{形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性} \\ \cline{2-4} 
        	& \ \ \ 全て\ \ \  & 語彙+品詞 & 語彙 \\ \hline\hline
7グラムモデル  	& 79.8/85.2 & 	79.8/85.2  & 79.7/91.2 	 \\ \hline
9グラムモデル  	& 79.7/84.7 & 79.7/86.1 & 79.5/90.7  \\ \hline
可変長モデル	&	{\bf 82.6/27.3} &  81.4/63.4 & 80.4/72.7 \\ \hline
\end{tabular}
\vspace*{-.5cm}
\end{center}
\end{table}

\subsection{複数システムの出力の混合の性能評価}

\subsubsection{評価方法}

次に，7グラムモデル，9グラムモデル，可変長モデルについて，
それぞれ，\ref{subsubsec:ftr34}~節の三種類の素性の設定を区別して，
合計9種類のモデルを考え，その各々について，5グラムモデルの出力との間で
混合を行ない，その性能を評価した．
ただし，個々の固有表現抽出モデルを学習するための訓練データセット$TrI$，
複数システムの出力の正誤判別規則を学習するための訓練データセット$TrC$，
\ref{subsec:DL}~節の(\ref{eqn:lbdF})式の頻度閾値$L_f$の設定の組合わせとしては，
以下の二通りについて評価を行なった．
なお，複数システムの出力の正誤判別規則を評価するための評価データセット$Ts$については，
いずれも，本試験データ$D_{formal}$を用いた．
\begin{center}
\begin{tabular}{lll}
(a) & $TrI$: & $D_{CRL}$から200記事$D^{200}_{CRL}$を除いた残り 
 $D_{CRL}-D^{200}_{CRL}$\\
    & $TrC$: & $D_{CRL}$中の200記事$D^{200}_{CRL}$\\
    & $L_f$: & $D_{CRL}-D^{200}_{CRL}$中の200記事に対して，
正誤判別規則の性能を最大にする値\\
(b) & \multicolumn{2}{l}{$TrI=TrC=D_{CRL}$}\\
    & $L_f$: & (a)と同じ値 
\end{tabular}
\end{center}
このうち，設定(a)は，二つの訓練データセット$TrI$と$TrC$について，
重複のないデータセットを用いたものに相当する．
ただし，利用可能なデータ量に限界があることから，
混合のための正誤判別規則学習の訓練データセット$TrC$のサイズが小さくなっている．
一方，設定(b)の方は，個々の固有表現抽出モデルを訓練データ$TrI$自身に適用した
インサイド適用の結果を利用した混合となるが，
混合のための正誤判別規則学習の訓練データセット$TrC$のサイズは設定(a)よりもずっと大きい
\footnote{
  ここで，厳密に\ref{subsec:proc}~節の評価手続きに従うと，
  評価手順(\ref{enum:evproc1})において，
  評価データセット$Ts$に対する固有表現抽出結果のリスト$NEList_i(Ts)$ $(i=1,2)$を
  得る場合には，訓練の段階で用いた個々の固有表現抽出モデル$NEext_i$ $(i=1,2)$
  と同じものを用いる必要がある．
  しかし，本論文では，設定(a)と(b)の間で，混合を行なう前の
  固有表現抽出結果のリスト$NEList_i(Ts)$ $(i=1,2)$を統一して，
  同一の条件で評価を行なうことを優先した．
  そのため，設定(a)において用いる固有表現抽出結果のリスト$NEList_i(Ts)$ $(i=1,2)$
  としては，設定(b)と同じく，$D_{CRL}$の全体を用いて学習された
  各固有表現抽出モデルを適用して得られたものを用いた．
  訓練データが$D_{CRL}$であるか$D_{CRL}-D^{200}_{CRL}$であるかの違いによる
  固有表現抽出モデルの性能の差はそれほど大きくないので，
  このことによる影響は小さいと考えられる．
}．

\begin{table}
\begin{center}
\caption{5グラムモデルの出力と各モデルの出力の混合結果の性能 (F値($\beta=1$) (再現率/適合率) (\%))}
\label{tab:res-comb}
\begin{tabular}{|l||c|c|c|} \hline
	\multicolumn{4}{|c|}
	{(a)\ \ \ $TrI=D_{CRL}-D^{200}_{CRL}$，$TrC=D^{200}_{CRL}$ ($D_{CRL}$中の200記事)} \\ \hline\hline
	& \multicolumn{3}{|c|}{形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性} \\ \cline{2-4} 
        	& \ \ \ 全て\ \ \  & 語彙+品詞 & 語彙 \\ \hline\hline
7グラムモデル  	& 81.54 (78.15/85.23) & 81.53 (77.79/85.65)    & 80.60 (77.08/84.46)\\ \hline
9グラムモデル  	& 81.31 (77.58/85.41) & 81.26 (77.51/85.40)  & 80.60 (77.08/84.46) \\ \hline
可変長モデル	& {\bf 83.43} {\bf (80.23/86.89)} & 81.55 (76.29/87.58)  & 81.85 (78.51/85.49) \\ \hline
 \multicolumn{4}{c}{} \\ \hline
 \multicolumn{4}{|c|}{(b)\ \ \ $TrI=TrC=D_{CRL}$} \\ \hline\hline
	& \multicolumn{3}{|c|}{形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性} \\ \cline{2-4} 
        	& \ \ \ 全て\ \ \  & 語彙+品詞 & 語彙 \\ \hline\hline
7グラムモデル  	& 81.97 (78.51/85.76) & 81.83 (78.22/85.78) & 81.58 (78.51/84.90) \\ \hline
9グラムモデル  	& 81.53 (77.79/85.65) & 81.66 (78.15/85.50)  & 81.52 (78.51/84.76) \\ \hline
可変長モデル	& {\bf 84.07} {\bf (81.45/86.86)} & 83.07 (79.94/86.44) & 82.50 (79.87/85.31) \\ \hline
\end{tabular}
\vspace*{-.5cm}
\end{center}
\end{table}

\subsubsection{評価結果}

評価結果を表~\ref{tab:res-comb}に示す．
この結果から分かるように，設定(a)と(b)を比べると，一律に，設定(b)の方が高い性能が得られている．
このことから，正誤判別規則の学習において，
たとえ，インサイド適用の結果しか利用できなかったとしても，
混合のための正誤判別規則学習の訓練データセット$TrC$のサイズはできるだけ大きい方がよいことがわかる．
特に，設定(b)においては，どの混合結果においても5グラムモデル単独の性能を上回っていることから，
混合規則学習のための十分な訓練データがあれば，
混合により多少なりとも個々のモデルの出力の性能を向上できることが予想される．

また，設定(b)の場合，7グラムモデル，9グラムモデルといった固定長モデルの出力と5グラムモデルの出力を
混合した場合よりも，可変長モデルの出力と5グラムモデルの出力を混合した場合の方が圧倒的に高い
性能向上を達成している．
この結果は，表~\ref{tab:dif_indivi}の差分の傾向と合致しており，
5グラムモデルとの類似性が相対的に小さい可変長モデルの出力との混合において，
より高い性能向上が得られている．
また，可変長モデル同士の間で，形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性の設定が
異なる場合を比較しても，この傾向が成り立っており，5グラムモデルとの類似性が小さいほど
混合結果における性能向上は大きい．
これらの結果から，出力の和の再現率が高く，誤出力の重複率が小さくなるような，
なるべく類似性の小さい複数の日本語固有表現抽出モデルの出力を用意して，
本論文の手法により出力の混合を行なえば，単独のモデルの出力の性能向上が期待できることがわかる．



\subsubsection{固有表現の形態素長/種類ごとの分析}

次に，5グラムモデルの出力と可変長モデルの出力の混合の場合について，
固有表現を構成する形態素数ごと，および，固有表現の種類ごとに，
単独モデルの出力および混合結果の性能(F値，再現率，適合率)を
列挙したものを，それぞれ，表~\ref{tab:res-len}，および，表~\ref{tab:res-netag}に示す．
なお，表中で，固有表現を構成する形態素数ごと，あるいは，固有表現の種類ごとに，
最も高いF値を達成した結果をそれぞれ{\bf 太字}で示す．

表~\ref{tab:res-len}から分かるように，どの可変長モデルの出力との混合においても，
ほぼ全ての形態素長の固有表現において，
5グラムモデル単独の出力の再現率・適合率をともに上回っている．
特に，最高の性能を示している「5グラムモデル+可変長モデル(全て)」の結果においては，
5グラムモデルからの性能向上の度合は，形態素長が長くなるほど大きいことから，
可変長モデルでしか出力されなかった長い固有表現を，混合によってうまく抽出できている
ことがわかる．

また，表~\ref{tab:res-netag}からは，どの可変長モデルの出力との混合においても，
ほぼ全ての種類の固有表現において，5グラムモデルの出力の再現率・適合率とほぼ同等かそれ以上の
性能が得られている．
そのうち，TIME，MONEY，PERCENTの三種類については，他の種類と比較して，
訓練データ・評価データともその頻度が小さく，また，5グラムモデルにおける性能もかなり高いことから，
改善の余地があまりなかったと考えられる．
ただし，その場合でも，混合結果においては，可変長モデルの低い性能の悪影響を受けることなく，
5グラムモデルの高い性能が反映されている．





\begin{table*}
\begin{center}
\caption{混合結果の性能: 固有表現の形態素長ごと，$TrI=TrC=D_{CRL}$\\ 
(F値($\beta=1$) (再現率) (適合率) (\%))}
\label{tab:res-len}
\begin{tabular}{|c||c||c|c|c|c|} \hline
        &                  \multicolumn{5}{c|}{$n$形態素 対 一固有表現} \\ \cline{2-6}
        &                $n\geq 1$ & $n=1$ & $n=2$ & $n=3$ & $n\geq 4$  \\ \hline\hline
	& 		
	 81.16 & 83.60 &	86.94 & 68.42 &	50.59 \\ 
5グラムモデル  	& (78.87) & (84.97) &	(85.90) & (63.64) &	(35.83) \\ 
	& (83.60) & (82.28) &	(88.00) & (73.98) &	(86.00) \\ \hline
	& 
	  	45.12 & 53.77 &	56.63 & 33.74 &	16.78 \\ 
可変長モデル & (51.50) & (38.69) & (71.37) & (57.34) & (40.00) \\ 
(全て)	& (40.15) & (88.14) & (47.93) & (23.91) & (10.62) \\ \hline
	&  	77.02 & 81.86 &	79.96 & 63.19 &	50.52 \\ 
可変長モデル 	 & (75.86) & (78.57) &	(84.82) & (63.64) &	(40.83) \\
(語彙+品詞) & (78.21) & (85.44) &	(75.63) & (62.76) &	(66.22) \\ \hline
	& 75.16 & 79.11 &	83.02 & 50.46 &	22.38 \\ 
可変長モデル 	& (73.78) & (87.05) & (81.13) & (38.46) & (13.33) \\ 
(語彙)  	& (76.58) & (72.49) & (85.00) & (73.33) & (69.57) \\ \hline\hline
5グラムモデル & {\bf 84.07} & 85.06 & {\bf 88.96} & {\bf 75.19} &	{\bf 65.96} \\ 
+ 可変長モデル	& {\bf (81.45)} & (85.12) & {\bf (87.42)} & {\bf (69.93)} & {\bf (51.67)} \\ 
 (全て)  	& {\bf (86.86)} & (84.99) & {\bf (90.56)} & {\bf (81.30)} & {\bf (91.18)} \\ \hline
5グラムモデル & 83.07 & 84.97 & 87.29 & 72.80 &	63.04 \\ 
+ 可変長モデル 
	& (79.94) & (84.52) & (85.68) & (66.43) & (48.33) \\ 	
(語彙+品詞)  	& (86.44) & (85.41) & (88.96) & (80.51) & (90.63) \\ 	\hline
5グラムモデル & 
	82.50 & {\bf 85.11} &	87.73 & 71.04 &	50.89 \\ 
+ 可変長モデル 
	& (79.87) & {\bf (86.76)} & (86.12) & (64.34) & (35.83) \\ 
(語彙)    & (85.31) & {\bf (83.52)} & (89.41) & (79.31) & (87.76) \\ \hline
\end{tabular}
\end{center}
\end{table*}



\begin{table*}
\begin{scriptsize}
\begin{center}
\caption{混合結果の性能: 固有表現の種類ごと，$TrI=TrC=D_{CRL}$\\
	 (F値($\beta=1$) (再現率) (適合率) (\%))}
\label{tab:res-netag}
\hspace*{-.3cm}
\begin{tabular}{|c||c|c|c|c|c|c|c|c|} \hline
        & ORGANI- & PER- & LOCA- & ARTI- & DATE & TIME & MONEY & PER- \\ 
        & ZATION &  SON	   & TION & FACT &  &  &  		& CENT \\ \hline\hline
	& 67.74 	& 81.82 & 77.04   & 30.43   & 91.49 & {\bf 93.20} & {\bf 92.86} & 87.18 \\ 
5グラムモデル  	
	& (58.45) & (79.88) &	(71.91) & (29.17) & (88.85) & {\bf (88.89)} & {\bf (86.67)} & (80.95) \\ 
	& (80.53) & (83.85) &	(82.96) & (31.82) & (94.29) & {\bf (97.96)} & {\bf (100.00)} & (94.44) \\ \hline

	& 35.48 	& 48.45 & 38.47   & 5.80   & 78.60 & 56.90 & 60.61 & 87.18 \\ 
可変長モデル 
	& (37.40) & (48.52) &	(32.93) & (22.92) & (81.92) & (61.11) & (66.67) & (80.95) \\ 
(全て)	& (33.75) & (48.38) &	(46.26) & (3.32) & (75.53) & (53.23) & (55.56) & (94.44) \\ \hline

	& 65.30     & 78.56    & 72.46   & 26.92   & 88.51  & 77.36  & 80.00    & {\bf 89.47} \\ 
可変長モデル 
	& (57.34)   & (77.51)  &(66.59) & (29.17) & (88.85) & (75.93) & (80.00) & {\bf (80.95)} \\ 
(語彙+品詞)
	& (75.82)   & (79.64)  &(79.48) & (25.00) & (88.17) & (78.85) & (80.00) & {\bf (100.00)} \\ \hline

	& 63.96     & 76.81    & 72.29   & 25.00   & 86.96  & 54.21  & 73.33 & 81.08 \\ 
可変長モデル 
	& (54.57)   & (78.40)  &(68.52) & (20.83) & (84.62) & (53.70) & (73.33) & (71.43) \\ 
(語彙)
	& (77.25)   & (75.28)  &(76.49) & (31.25) & (89.43) & (54.72) & (73.33) & (93.75) \\ \hline\hline

5グラムモデル  
	& {\bf 72.18} 	& 84.15 & {\bf 79.58}   & {\bf 38.71}   & {\bf 92.86} & {\bf 93.20} & {\bf 92.86} & 87.18 \\ 
+ 可変長モデル 
	& {\bf (62.88)} & (81.66) & {\bf (73.61)} & {\bf (37.50)} & {\bf (90.00)} & {\bf (88.89)} & {\bf (86.67)} & (80.95)
									 \\ 
(全て)	& {\bf (84.70)} & (86.79) & {\bf (86.61)} & {\bf (40.00)} & {\bf (95.90)} & {\bf (97.96)} & {\bf (100.00)} & (94.44)
									 \\ 	\hline

5グラムモデル  
	& 70.19 	& 83.41 & 78.22   & 35.29   & 92.64 & 92.16 & {\bf 92.86} & 87.18 \\ 
+ 可変長モデル 
	& (60.66) & (81.07) &	(72.15) & (31.25) & (89.62) & (87.04) & {\bf (86.67)} & (80.95) \\ 
(語彙+品詞)
	& (83.27) & (85.89) &	(85.39) & (40.54) & (95.88) & (97.92) & {\bf (100.00)} & (94.44) \\ \hline

5グラムモデル  
	& 68.82  & {\bf 84.46} & 77.50   & 31.46   & 91.85 	& {\bf 93.20} & {\bf 92.86} & {\bf 89.47} \\ 
+ 可変長モデル 
	& (59.28) & {\bf (82.84)} &	(72.15) & (29.17) & (88.85) & {\bf (88.89)} & {\bf (86.67)} & {\bf (80.95)} \\ 
(語彙)
	& (81.99) & {\bf (86.15)} &	(83.71) & (34.15) & (95.06) & {\bf (97.96)} & {\bf (100.00)} & {\bf (100.00)} 
				\\ \hline
\end{tabular}
\end{center}
\end{scriptsize}
\end{table*}

\subsubsection{単独モデル・混合結果の出力のパターンの分析}



\begin{table*}
\begin{scriptsize}
\begin{center}
\caption{単独モデル・混合結果の出力のパターンの分析結果}
\label{tab:res-syspat}
\hspace*{-.3cm}
\begin{tabular}{|c|c||c|c|c|c|c|c|c|c|c|c|c|c|} \hline
\multicolumn{14}{|c|}{5グラムモデルと可変長モデル(形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性$=$全て)の出力の混合} 
		\\ \hline\hline
単独モデルの	& 5グラムモデル	     & 有 & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 \\ \cline{2-14} 
出力の有無	& 可変長モデル & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 & 有 \\ \hline 
\multicolumn{2}{|c||}
{混合結果の出力の有無} & \multicolumn{3}{|c|}{有} & \multicolumn{3}{|c|}{無} 
			& \multicolumn{3}{|c|}{有} & \multicolumn{3}{|c|}{無} \\ \hline
\multicolumn{2}{|c||}
{正解データにおける有無} & \multicolumn{3}{|c|}{有} & \multicolumn{3}{|c|}{無} 
			& \multicolumn{3}{|c|}{無} & \multicolumn{3}{|c|}{有} \\ \hline\hline
\multicolumn{2}{|c||}{割合 (\%)} 
		& 28.0 & 18.2 & 1.5 & 0.04 & 1.8 & 42.5 	& 2.4 & 4.8 & 0 & 0 & 0 & 0.7 \\ \hline 
\multicolumn{2}{|c||}{正誤判別率 (\%) (判別数/出力数)} 
	& \multicolumn{6}{|c|}{(判別正解率)\ \ 92.1\ \ (2194/2382)} 
	& \multicolumn{6}{|c|}{(判別誤り率)\ \ 7.9\ \ (188/2382)} \\ \hline
\multicolumn{14}{c}{} \\ \hline
\multicolumn{14}{|c|}{5グラムモデルと可変長モデル(形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性$=$語彙+品詞)の出力の混合} 
		\\ \hline\hline
単独モデルの	& 5グラムモデル	     & 有 & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 \\ \cline{2-14} 
出力の有無	& 可変長モデル & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 & 有 \\ \hline 
\multicolumn{2}{|c||}
{混合結果の出力の有無} & \multicolumn{3}{|c|}{有} & \multicolumn{3}{|c|}{無} 
			& \multicolumn{3}{|c|}{有} & \multicolumn{3}{|c|}{無} \\ \hline
\multicolumn{2}{|c||}
{正解データにおける有無} & \multicolumn{3}{|c|}{有} & \multicolumn{3}{|c|}{無} 
			& \multicolumn{3}{|c|}{無} & \multicolumn{3}{|c|}{有} \\ \hline\hline
\multicolumn{2}{|c||}{割合 (\%)} 
		& 67.8 & 4.4 & 1.7 & 0.2 & 2.6 & 10.3 	& 8.9 & 2.6 & 0.1 & 0 & 0.7 & 0.7 \\ \hline 
\multicolumn{2}{|c||}{正誤判別率 (\%) (判別数/出力数)} 
	& \multicolumn{6}{|c|}{(判別正解率)\ \ 87.1\ \ (1315/1510)} 
	& \multicolumn{6}{|c|}{(判別誤り率)\ \ 12.9\ \ (195/1510)} \\ \hline
\multicolumn{14}{c}{} \\ \hline
\multicolumn{14}{|c|}{5グラムモデルと可変長モデル(形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性$=$語彙)の出力の混合} 
		\\ \hline\hline
単独モデルの	& 5グラムモデル	     & 有 & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 \\ \cline{2-14} 
出力の有無	& 可変長モデル & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 & 有 & 有 & 無 & 有 \\ \hline 
\multicolumn{2}{|c||}
{混合結果の出力の有無} & \multicolumn{3}{|c|}{有} & \multicolumn{3}{|c|}{無} 
			& \multicolumn{3}{|c|}{有} & \multicolumn{3}{|c|}{無} \\ \hline
\multicolumn{2}{|c||}
{正解データにおける有無} & \multicolumn{3}{|c|}{有} & \multicolumn{3}{|c|}{無} 
			& \multicolumn{3}{|c|}{無} & \multicolumn{3}{|c|}{有} \\ \hline\hline
\multicolumn{2}{|c||}{割合 (\%)} 
		& 67.3 & 6.1 & 1.1 & 0.1 & 1.5 & 10.6 	& 10.4 & 2.5 & 0 & 0 & 0.1 & 0.4 \\ \hline 
\multicolumn{2}{|c||}{正誤判別率 (\%) (判別数/出力数)} 
	& \multicolumn{6}{|c|}{(判別正解率)\ \ 86.6\ \ (1297/1497)} 
	& \multicolumn{6}{|c|}{(判別誤り率)\ \ 13.4\ \ (200/1497)} \\ \hline
\end{tabular}
\end{center}
\end{scriptsize}
\end{table*}

5グラムモデルの出力と可変長モデルの出力の混合の場合について，
各単独モデルの出力における固有表現の有無，および，
混合結果における固有表現の有無と，正解データにおける固有表現の有無のパターンの
割合を調査した結果を表~\ref{tab:res-syspat}に示す．
表中で，「有」「無」は，それぞれ，単独モデルの出力，混合結果，正解データに
固有表現が存在する場合，および，存在しない場合を表す．
例えば，「有」「有」「有」「有」のパターンは，
両方の単独モデルの出力にその固有表現が存在し，混合結果においてもその固有表現が出力され，
かつ，それが正解データにも存在する正解の固有表現である場合に相当する．
また，割合(\%)の計算においては，両方の単独モデルの出力の和における固有表現数を分母，
それぞれのパターンに該当する固有表現数を分子として，割合(\%)を計算している．
さらに，混合における正誤判別結果が正解であるか否かについては，
混合結果および正解データにおける出力の有無が一致する場合は正誤判別が正解，
一致しない場合は正誤判別が誤りであるので，「正誤判別率」の欄にそれぞれの率を示した．

形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性の設定が異なる場合についてこの結果を比較すると，
「5グラムモデル+可変長モデル(全て)」において判別正解率が高くなっているが，
これは，「可変長モデル(全て)」の性能が極端に悪く，
「可変長モデル(全て)」のみが出力した固有表現の多くが誤りであり，その判別が比較的容易であったからである．
全体では，どの可変長モデルの出力との混合においても，5グラムモデルの出力を覆すことで正解となった場合
(「無」「有」「有」「有」および「有」「無」「無」「無」)が数\%あり，
これが，5グラムモデルからの性能向上に寄与している．
その一方で，判別誤りの内訳をみると，その多くは，誤出力の検出が十分できなかった場合で，
ほとんどの場合，少なくとも5グラムモデルはその誤りの固有表現を出力している．
このことから，より効果的な素性を用いる，あるいは，より高性能な学習器を用いるなどして，
誤出力検出の精度を向上させることにより，適合率を向上できる余地があることがわかる．

\subsection{最大エントロピー法による正誤判別規則学習}
\label{subsec:comb-ME}

最後に，正誤判別規則学習の学習法の比較のために，最大エントロピー法を用いて
正誤判別規則学習を行なった．

まず，最大エントロピー法を適用するために，\ref{subsubsec:event}~節の(\ref{eqn:segev})式の
事象表現$SegEv_j$を，以下のように変換する．
\begin{eqnarray}
 SegEv_j & = & \{ NEListev_{p,\ldots,q},\ldots,NEListev_{p',\ldots,q'} \}\ \ \  \label{eqn:segev-ME}
\end{eqnarray}
ここで，各事象表現$NEListev_{p,\ldots,q}$は，システムの指標のリストごとに固有表現をまとめたもので，
固有表現のリストの事象表現に相当する
\footnote{
  最大エントロピー法の適用における事象表現の形式は，
  \ref{subsubsec:event}~節の決定リスト学習の場合の事象表現の形式とは異なっているが，
  最大エントロピー法における素性の表現能力を必要以上に制限しているわけではない．
  決定リスト学習において可能な素性を表現する際にも，
  \ref{subsubsec:ftr}~節のi)およびii)の二つの制約を課しているため，
  素性の表現能力について両者の間に意図的な差はない．
}．
\ref{subsubsec:event}~節の場合と同様に，以下の二種類のどちらかに対応し，
それぞれ異なったデータ構造を持つ．
\begin{enumerate}
\item[i)] そのセグメント中で少なくとも一つのシステムにより出力された
	固有表現のリストの事象表現．
\item[ii)] そのセグメント中で一つも固有表現を出力しなかった一つのシステムに関する情報を
	表す事象表現．
\end{enumerate}
i)のタイプの事象表現$NEListev_{p,\ldots,q}$は以下のようなデータ構造を持つ．
\begin{eqnarray}
NEListev_{p,\ldots,q} & = &	\Bigl\{
	 systems =
	 \langle p,\ldots,q\rangle,\ 
mlengthList = y,\ldots,z\mbox{ morphemes},\nonumber \\
& &	 \ \  NEtagList = \cdots,\ 
  		 POSList = \cdots,\nonumber \\
 & &  		 \ \ 
classList_{NE} = +/-,\ldots,+/-
	 \Bigr\} 
\label{eqn:NEnon-emp-ME}
\end{eqnarray}
このデータ構造は，\ref{subsubsec:event}~節の(\ref{eqn:NEnon-emp})式のデータ構造とほぼ同じであるが，
固有表現のリストを表現するために，各素性に相当する情報が全てリスト表現になっている点が異なる．
一方，ii)のタイプの事象表現$NEList_{r}$は，\ref{subsubsec:event}~節の(\ref{eqn:NEemp})式と同じく，
以下のデータ構造で表現される．
\begin{eqnarray}
NEListev_{r} & = &   	
       \Bigl\{
	 systems =
	 \langle r\rangle,\ 
class_{sys} =
	 \mbox{``no output''}
	 \Bigr\} \label{eqn:NEemp-ME}
\end{eqnarray}

このような事象表現を用いて正誤判別規則の学習および適用を行なう際には，
上述の(\ref{eqn:segev-ME})式の事象表現を事象の単位とし，
\ref{subsubsec:class}~節の場合と同様に，
各システム$i$ごとにまとめた以下のクラス表現を設定し，
各システム$i$ごとにクラスの判別を行なうための
正誤判別規則の学習および適用を行なう．
\begin{eqnarray*}
class_{sys}^1  & = & 
	\left\{\begin{array}{l}
	  +/-,\ \ldots,\ +/- \\
	 \mbox{``no output''} 
	\end{array}\right. \nonumber \\
         & \cdots &  \\
class_{sys}^n  & = & 
	\left\{\begin{array}{l}
	  +/-,\ \ldots,\ +/- \\
	 \mbox{``no output''} 
	\end{array}\right. \nonumber 
\end{eqnarray*}
その際には，(\ref{eqn:NEnon-emp-ME})式の固有表現のリストの事象表現
$NEListev_{p,\ldots,q}$の$mlengthList$，$NEtagList$，$POSList$，および，
(\ref{eqn:NEemp-ME})式の固有表現の事象表現$NEList_{r}$の
$class_{sys}$を，それぞれ文脈$x$とし，
上式の，各システムごとにまとめた正誤のクラスのリストを付与するための
条件付確率モデルを，最大エントロピーモデルとして学習する．
この最大エントロピーモデルは，各システム$i$ごとに個別にモデルの学習・適用を行なう．

\begin{table}
\begin{center}
\caption{5グラムモデル/その他の各モデルの出力の最大エントロピー法による\\ 
	混合結果の性能
	(F値($\beta=1$) (再現率/適合率) (\%))}
\label{tab:res-comb-ME}
\begin{tabular}{|l||c|c|c|} \hline
	\multicolumn{4}{|c|}
	{(a)\ \ \ $TrI=TrC=D_{CRL}$，結合素性なし} \\ \hline\hline
	& \multicolumn{3}{|c|}{形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性} \\ \cline{2-4} 
        	& \ \ \ 全て\ \ \  & 語彙+品詞 & 語彙 \\ \hline\hline
7グラムモデル  	& 81.81 (78.80/85.07) & 81.70 (78.51/85.16)    & 81.47 (78.58/84.58)\\ \hline
9グラムモデル  	& 81.21 (78.01/84.68) & 81.38 (78.30/84.73)  & 81.46 (78.51/84.63) \\ \hline
可変長モデル	& 81.12 (76.65/86.15) & 81.48 (77.36/86.06)  & 81.37 (78.37/84.61) \\ \hline
 \multicolumn{4}{c}{} \\ \hline
	\multicolumn{4}{|c|}
	{(b)\ \ \ $TrI=TrC=D_{CRL}$，結合素性あり} \\ \hline\hline
	& \multicolumn{3}{|c|}{形態素$M_{l(\leq -3)}$，$M_{r(\geq 3)}$の素性} \\ \cline{2-4} 
        	& \ \ \ 全て\ \ \  & 語彙+品詞 & 語彙 \\ \hline\hline
7グラムモデル  	& 81.71 (78.72/84.93) & 81.58 (78.37/85.07) & 81.35 (78.44/84.49) \\ \hline
9グラムモデル  	& 81.16 (78.08/84.50) & 81.22 (78.37/84.28)  & 81.29 (78.58/84.19) \\ \hline
可変長モデル	& 80.94 (76.65/85.74) & 81.40 (77.29/85.98) & 81.24 (78.01/84.75) \\ \hline
\end{tabular}
\vspace*{-.5cm}
\end{center}
\end{table}

このような方法で，7グラムモデル，9グラムモデル，可変長モデルについて，
それぞれ，\ref{subsubsec:ftr34}~節の三種類の素性の設定を区別して，
合計9種類のモデルを考え，その各々について，5グラムモデルの出力との間で
混合を行ない，その性能を評価した．
ただし，$TrI=TrC=D_{CRL}$とし，評価データセット$Ts$は本試験データ$D_{formal}$とした．
最大エントロピーモデルの素性関数の頻度に下限を設け，
評価データセット$Ts$に対して最も高い性能が得られた場合の結果を
表~\ref{tab:res-comb-ME}(a)に示す．
また，決定リスト学習との間で条件を揃えるために，
\ref{subsubsec:ftr}~節の(\ref{eqn:ftr})式の形式の決定リスト学習の素性のうち，
上述の実験結果(a)では用いていなかった結合素性を追加して最大エントロピーモデルの
学習および適用を行なった結果を表~\ref{tab:res-comb-ME}(b)に示す．
この場合は，決定リスト学習における各規則の条件付確率$P(class_{sys}^i\!=\!c_i\mid f)$に
下限を設け，評価データセット$Ts$に対して最も高い性能が得られた場合の結果を示している．

表~\ref{tab:res-comb-ME}の(a)と(b)の結果を比較すると，結合素性を用いた場合の方が性能が悪くなっている．
また，いくかの結果を除いて，5グラムモデルの性能からの向上はみられるものの，
決定リスト学習による可変長モデルの出力との混合の場合のような高い性能向上は達成できていない．

この理由の一つとしては，最大エントロピーモデルと決定リスト学習の間のモデルの形式の違いの
影響が挙げられる．
最大エントロピーモデルは，あらゆる素性とクラスとの相関をそれぞれ別個のパラメータとし，
モデル内では全パラメータを考慮する形式のモデルになっている．
一方，決定リスト学習は，各々のクラス決定において最も寄与する素性の組合わせのみを考慮し，
他の素性は全く考慮しない．
したがって，素性間で寄与する度合の差がわずかしかない場合でも，
決定リスト学習では，最も寄与する素性の組合わせのみが考慮されるのに対して，
最大エントロピーモデルでは，全素性の寄与を総合的に考慮する．
本論文の正誤判別規則学習による混合の問題では，素性の種類が比較的少なく，
特に高頻度な素性
\footnote{
  例えば，複数の情報の結合でなく単独の情報のみから構成される素性など．
}
は，
実際にクラス判別に寄与する度合に関係なく，
どの事象においても常に一定の値以上の重みを持つと考えられる．
そのような問題の場合には，最大エントロピーモデルのように全素性の寄与を
総合的に考慮する学習法でなく，決定リスト学習のように各々のクラス決定に
最も寄与する素性の組合わせのみを考慮する学習法が適していると考えられる．

逆に，正誤判別規則学習による混合の前段階である，
形態素への固有表現まとめ上げ状態付与の問題の場合には，
\cite{Sassano00bjx,Sassano00a}に示されるように，決定リスト学習よりも
最大エントロピーモデルの方が高い性能を示している．
この問題の場合には，素性の種類が比較的多く，極端に高頻度な素性も少ないことから，
最大エントロピーモデルのように全素性の寄与を総合的に考慮する学習法が
適していると考えられる．







