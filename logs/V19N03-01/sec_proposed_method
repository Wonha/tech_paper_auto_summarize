本章では，言語モデルに基づくランキングアルゴリズムについて概説する．
ここで紹介する技術は，[REF_sec:proposed_method]章で説明する提案手法の基礎をなしている．
言語モデルに基づくランキングアルゴリズムは，三つのタイプに分類できる．
すなわち，クエリの尤度に基づく方法[CITE]，文書の尤度に基づく方法[CITE]，カルバック・ライブラー情報量に基づく方法[CITE]の三つである．
クエリの尤度に基づく方法では，文書セット中の各文書[MATH]について，[MATH]を表す言語モデル[MATH]を構築する．
ユーザによってクエリ[MATH]が入力されたら，各文書[MATH]について，[MATH]がクエリを生成する確率[MATH]を計算する．
そして，[MATH]が高い順に各文書をランキングする．
文書の尤度に基づく方法は，クエリの尤度に基づく方法と逆のアプローチを採る．
すなわち，クエリ[MATH]を表す言語モデル[MATH]を構築し，文書セット中の各文書[MATH]について，[MATH]を計算する．
そして，[MATH]が高い順に各文書をランキングする．
カルバック・ライブラー情報量に基づく方法では，[MATH]と[MATH]の両方を構築する．
そして，各文書[MATH]について，[MATH]と[MATH]のカルバック・ライブラー情報量[MATH]を計算し，これが小さい順に各文書をランキングする．
クエリや文書を表す言語モデルは，Maximum Likelihood Estimation (MLE)やDIRichlet smoothed estimation (DIR) [CITE]などの方法を用いて構築する．
MLEでは，テキスト[MATH]（[MATH]はクエリや文書）における単語[MATH]の生起確率[MATH]を次式によって算出する．
ただし，[MATH]は[MATH]における[MATH]の出現頻度を表す．
また，[MATH]は，[MATH]に含まれる単語数を表す．
一方，DIRでは，[MATH]における[MATH]の生起確率[MATH]を次式によって算出する．
ただし，[MATH]は文書セットを表す．
また，[MATH]はスムージングパラメータを表す．
DIRでは，MLEと異なり，[MATH]における[MATH]の出現頻度が加味されており，スムージングが行われている．
言語モデルに基づくランキングアルゴリズムに対する代表的な適合性フィードバックの手法として，Zhaiらの手法[CITE]がある．
Zhaiらの手法では，フィードバックとして与えられた文書集合[MATH]に対して，[MATH]を表す言語モデル[MATH]を構築する．
次に，[MATH]と[MATH]（初期検索結果を得るために使用したクエリモデル）を足し合わせ，新しいクエリモデルを構築する．
そして，新しいクエリモデルを用いて，初期検索結果のランキングを修正する．
Zhaiらの手法は，言語モデルに基づくランキングアルゴリズムに対する基本的な適合性フィードバックの手法として重要である．
しかし，彼らの手法では，テキストに表層的に存在する単語の情報しか用いられていない．
これに対し，提案手法では，テキストに潜在的に現れうる単語の分布を推定し，この情報も用いて適合性フィードバックを行う．
本章ではLDA [CITE]について解説する．
LDAは，提案手法において，各単語がテキストに潜在的に現れうる確率を推定するために用いられる．
LDAは文書の生成モデルの一つである．
LDAでは，文書は複数のトピックから生成されると仮定する．
また，文書中の各単語は，各トピックが持つ単語の分布から生成されると仮定する．
ある文書における各トピックの混合比[MATH]は，[MATH]単体中の一点を取る．
ただし，単体中のある一点が選択される確率は，Dirichlet分布によって決められるとする．
以上の生成過程をまとめると，LDAにおける文書[MATH]の生成確率は，次のようにして計算される．
ただし，[MATH]は，Dirichlet分布から得られる[MATH]の生成確率である．
[MATH]は正の実数から構成される[MATH]次元ベクトルで，Dirichlet分布のパラメータを表す．
また，[MATH]と[MATH]は，多項分布から得られる[MATH]と[MATH]の生成確率である．
[MATH] [MATH]はトピックを，[MATH]は[MATH]が持つ単語の分布を表す．
[MATH]はLDAで考慮する語彙数を表す．
LDAでは，変分ベイズ法やギブスサンプリングなどを用いてパラメータを推定する[CITE]．
ギブスサンプリングを用いれば，より厳密な推定結果が得られる．
実装も容易なため，一般的にはギブスサンプリングが用いられることが多い．
しかし，ギブスサンプリングには推定に時間を要するという欠点がある．
一方，変分ベイズ法は，厳密な推定結果は得られないが，高速に動作する．
即時性が要求される検索というタスクの性質を考慮し，提案手法では変分ベイズ法を用いる．
以下，変分ベイズ法による推定方法について説明する．
まず，訓練データ中の各文書[MATH] [MATH]について，変分パラメータ[MATH]と[MATH]を導入する．
ただし，[MATH]である．
そして，式([REF_equ:phi])と式([REF_equ:gamma])を交互に計算し，これらの値を更新する．
\phi_{ijk} & \propto\beta_{kj} \exp\biggl( \Psi(\gamma_{ik}) - \Psi\Bigl(\sum\limits_{k'=1}^{K} \gamma_{ik'}\Bigr)\biggr)
\gamma_{ik} & = \alpha_{k} + \sum\limits_{j=1}^{J} \phi_{ijk}  tf(w_{j},\bm{d}_{i})
ただし，[MATH]はディガンマ関数を表す．
次に，更新された[MATH]と[MATH]を用いて，[MATH]と[MATH]を更新する．
[MATH]と[MATH]の更新には，ニュートン-ラフソン法や固定点反復法を用いる[CITE]．
ここでは固定点反復法による[MATH]と[MATH]の更新式を示す．
更新式は次の通りである．
\beta_{kj} & \propto\sum\limits_{i=1}^{I} \phi_{ijk}  tf(w_{j},\bm{d}_{i})
\alpha_{k} & = \frac_{i=1}^{I} (\alpha_{k} + n_{ik}) - \Psi(\alpha_{k})  _{i=1}^{I} (\alpha_{0} + |\bm{d}_{i}|) - \Psi(\alpha_{0})   \alpha_{k}^{old}
ただし，[MATH]，[MATH]とする．
また，[MATH]は更新前の[MATH]を表すものとする．
以降，[MATH]と[MATH]の更新と，[MATH]と[MATH]の更新を繰り返すことで，各パラメータの値を推定することができる．
[MATH]と[MATH]の値が推定されれば，式([REF_equ:lda])を用いて，文書[MATH]の生成確率を求めることができる．
また，[MATH]の値が推定されれば，次式を用いて，文書[MATH]における単語[MATH]の生起確率[MATH]を求めることができる．
ここで，[MATH]は，[MATH]に潜在するトピックの分布に相当する．
これに基づいて[MATH]を足し合わせることで，[MATH]が[MATH]に潜在的に現れうる確率を求めることができる．
LDAはProbabilistic Latent Semantic Analysis (PLSA) [CITE]をベイズ的に拡張したモデルと位置付けられる．
PLSAに対するLDAの長所として，LDAは未知テキスト（訓練データ中に含まれないテキスト）に関する確率も推定できるという点が挙げられる．
未知テキスト[MATH]にLDAを適用するときは，[MATH]に対して変分パラメータ[MATH]と[MATH]を導入し，式[MATH]と式[MATH]を用いてこれらの値を推定する．
ただし，[MATH]と[MATH]には，訓練データによって推定された値を用いる．
[MATH]が推定されれば，式[MATH]を用いて，未知テキスト[MATH]における単語[MATH]の生成確率[MATH]を求めることができる．
提案手法では，LDAのこの長所を利用して，各単語がフィードバックに潜在的に現れうる確率を求めている．
LDAは，自然言語処理や画像処理，音声認識など，様々な分野で利用されている[CITE]．
情報検索の分野では，例えばWeiらが，クエリの尤度に基づくランキング手法にLDAを利用している[CITE]．
また，Yiらは文書の尤度に基づくランキング手法に，Zhouらはカルバック・ライブラー情報量に基づくランキング手法にLDAを利用している[CITE]．
これらの研究は，LDAを用いて各文書の文書モデルを構築し，それぞれのスコア（e.g.,クエリの尤度）に基づいてクエリに対する検索結果を取得するものである．
本研究では，さらに，ユーザからフィードバックが得られる問題（i.e.,適合性フィードバックの問題）に焦点を当てる．
我々は，フィードバックに対してもLDAを用いてその言語モデルを構築し，構築されたフィードバックモデルを用いて検索結果を修正する．
本章では，提案手法の概要と，提案手法を構成する各ステップについて詳説する．
提案手法では，テキストに表層的に存在する単語の情報だけでなく，テキストに潜在的に現れうる単語の情報も利用して，検索結果をリランキングする．
表層情報だけでなく潜在情報も考慮することで，表層的なレベルだけでなく潜在的なレベルでもフィードバックと類似する文書を検索結果の上位にリランキングする．
図[REF_fig:proposed_method]に提案手法の概要を示す．
以降，本稿では，テキスト[MATH]の表層情報と潜在情報の両方を含む言語モデルを[MATH]と表す（HYBはhybridを表す）．
まず，ユーザによって入力されたクエリ[MATH]に対して，その初期検索結果[MATH]を取得する(Step 1)．
次に，LDAを用いて，[MATH]中の各文書[MATH] [MATH]について，[MATH]に潜在的に現れうる単語の分布を推定する．
そして，[MATH]の表層的な単語の分布と潜在的な単語の分布の両方を考慮した言語モデル[MATH]を構築する(Step 2)．
ユーザからフィードバック[MATH]が得られたら，[MATH]に対してもLDAを実行し，[MATH]に潜在的に現れうる単語の分布を推定する．
そして，検索結果中の各文書と同様，[MATH]に対しても，[MATH]の表層的な単語の分布と潜在的な単語の分布の両方を考慮した言語モデル[MATH]を構築する(Step 3)．
最後に，構築されたフィードバックモデル[MATH]と，初期検索結果[MATH]を得るために使用したクエリモデル[MATH]を混合し，新しいクエリモデル[MATH]を構築する．
そして，検索結果中の各文書[MATH]について，文書モデル[MATH]と新しいクエリモデル[MATH]との類似度を算出し，これに基づいて[MATH]をリランキングする(Step 4)．
次節以降では，各ステップについて詳説する．
なお，提案手法とはそもそもの検索モデルが異なるが，テキストの潜在情報を利用するため，Latent Semantic Analysis (LSA)を用いることも考えられる．
すなわち，各文書をベクトルで表現し，文書セットに対してLSAを実行する．
そして，LSAの実行結果を用いて各ベクトルを低次元の意味的空間に射影することで，各文書に潜在的に現れうる単語の情報を利用することができる．
しかし，この方法では，今述べた通り，文書セット全体に対してLSAを実行する必要がある．
文書セットは時に数千万〜数億文書にも及ぶため，LSAの実行には膨大な時間を要する．
さらに，もし文書セットに対する文書の追加や削除があれば，LSAを実行しなおさなければならない．
一方，提案手法では，検索結果中の各文書に対する[MATH]やフィードバックに対する[MATH]を構築するため，検索結果に対してLDAを実行する必要がある（[REF_ssec:hdm_construction]節及び[REF_ssec:hfm_construction]節で後述）．
しかし，検索結果は文書セットより明らかに規模が小さく，これに要する時間は問題にならない（[REF_ssec:computation_time]節で後述）．
このように，LSAに基づく手法と提案手法の間には，ベースとする検索モデルや効率の面で大きな違いがある．
提案手法では，カルバック・ライブラー情報量に基づいて[CITE]，各文書をランキングする．
まず，文書セット[MATH]中の各文書[MATH] [MATH]について，DIRに基づく文書モデル[MATH]をあらかじめ構築しておく．
ユーザからクエリ[MATH]が与えられると，[MATH]に対してMLEに基づくクエリモデル[MATH]を構築する．
そして，[MATH]中の[MATH]を含む各文書について，[MATH]と[MATH]のカルバック・ライブラー情報量を計算する．
すなわち，クエリ[MATH]に対する文書[MATH]の重要度は，次式のように定義される．
この重要度に従って各文書をランキングし，[MATH]に対する初期検索結果[MATH]を得る．
クエリモデルの構築にMLEを用いたのは，言語モデルに基づくランキングに関する先行研究(e.g., [CITE])に倣ってのことである．
なお，クエリモデルの構築にMLEを用いた場合，カルバック・ライブラー情報量に基づくランキングは，クエリの尤度に基づくランキング[CITE]と等価になる．
[MATH]中の各文書[MATH] [MATH]について，[MATH]の表層情報と潜在情報の両方を含む言語モデル[MATH]を構築する．
まず，各文書[MATH]について，LDAを用いて，[MATH]の潜在情報を含む言語モデル[MATH]を構築する．
具体的な手順は次の通りである．
まず，[MATH]に対してLDAを実行し，[MATH]に対するLDAのパラメータ[MATH]と[MATH] [MATH]，[MATH] [MATH]を推定する（[REF_ssec:parameter_estimation]節参照）．
次に，各文書について，推定された各パラメータ及び式([REF_equ:pwd])を用いて[MATH]を構築する．
[MATH]は，[MATH]に潜在するトピックの分布を基に構築されており，各単語が[MATH]に潜在的に現れうる確率の分布になる（式([REF_equ:pwd])参照）．
次に，構築された[MATH]と[MATH]を次式によって混合し，[MATH]を構築する．
ただし，[MATH]とする．
[MATH]は，各文書の表層的な単語の分布を基に構築される（式([REF_equ:dir])参照）．
[MATH]と[MATH]を混合することで，[MATH]の表層情報と潜在情報の両方を含む言語モデルを構築することができる．
フィードバック[MATH]が得られたら，[MATH]に対しても，[MATH]の表層情報と潜在情報の両方を含む言語モデル[MATH]を構築する．
まず，LDAを用いて，[MATH]の潜在情報を含む言語モデル[MATH]を構築する．
具体的な手順は次の通りである．
まず，Step 2で訓練されたLDAを[MATH]に適用し，[MATH]に対する変分パラメータ[MATH]を推定する（[REF_ssec:inference]節参照）．
次に，推定された[MATH]と式([REF_equ:pwd])を用いて[MATH]を構築する．
[MATH]は，[MATH]と同様，各単語が[MATH]に潜在的に現れうる確率の分布になる．
次に，構築された[MATH]と[MATH]を次式によって混合し，[MATH]を構築する．
ただし，[MATH]は式([REF_equ:dir])を用いて構築する．
[MATH]と[MATH]を混合することで，[MATH]の表層情報と潜在情報の両方を含む言語モデルを構築することができる．
[MATH]をリランキングするため，まず新しいクエリモデルを構築する．
新しいクエリモデル[MATH]は，[MATH]を得るために使用したクエリモデル[MATH]と，Step 3で構築したフィードバックモデル[MATH]を次式のようにして混合し，構築する．
ただし，[MATH]とする．
最後に，[MATH]中の各文書[MATH]について，[MATH]と[MATH]のカルバック・ライブラー情報量を算出する．
すなわち，クエリ[MATH]とフィードバック[MATH]が与えられた下での文書[MATH]の重要度を次式のように定義する．
この重要度に従って各文書をリランキングすることで，検索結果のランキングを修正する．
本章では，言語モデルに基づくランキングアルゴリズムについて概説する．
ここで紹介する技術は，[REF_sec:proposed_method]章で説明する提案手法の基礎をなしている．
言語モデルに基づくランキングアルゴリズムは，三つのタイプに分類できる．
すなわち，クエリの尤度に基づく方法[CITE]，文書の尤度に基づく方法[CITE]，カルバック・ライブラー情報量に基づく方法[CITE]の三つである．
クエリの尤度に基づく方法では，文書セット中の各文書[MATH]について，[MATH]を表す言語モデル[MATH]を構築する．
ユーザによってクエリ[MATH]が入力されたら，各文書[MATH]について，[MATH]がクエリを生成する確率[MATH]を計算する．
そして，[MATH]が高い順に各文書をランキングする．
文書の尤度に基づく方法は，クエリの尤度に基づく方法と逆のアプローチを採る．
すなわち，クエリ[MATH]を表す言語モデル[MATH]を構築し，文書セット中の各文書[MATH]について，[MATH]を計算する．
そして，[MATH]が高い順に各文書をランキングする．
カルバック・ライブラー情報量に基づく方法では，[MATH]と[MATH]の両方を構築する．
そして，各文書[MATH]について，[MATH]と[MATH]のカルバック・ライブラー情報量[MATH]を計算し，これが小さい順に各文書をランキングする．
クエリや文書を表す言語モデルは，Maximum Likelihood Estimation (MLE)やDIRichlet smoothed estimation (DIR) [CITE]などの方法を用いて構築する．
MLEでは，テキスト[MATH]（[MATH]はクエリや文書）における単語[MATH]の生起確率[MATH]を次式によって算出する．
ただし，[MATH]は[MATH]における[MATH]の出現頻度を表す．
また，[MATH]は，[MATH]に含まれる単語数を表す．
一方，DIRでは，[MATH]における[MATH]の生起確率[MATH]を次式によって算出する．
ただし，[MATH]は文書セットを表す．
また，[MATH]はスムージングパラメータを表す．
DIRでは，MLEと異なり，[MATH]における[MATH]の出現頻度が加味されており，スムージングが行われている．
言語モデルに基づくランキングアルゴリズムに対する代表的な適合性フィードバックの手法として，Zhaiらの手法[CITE]がある．
Zhaiらの手法では，フィードバックとして与えられた文書集合[MATH]に対して，[MATH]を表す言語モデル[MATH]を構築する．
次に，[MATH]と[MATH]（初期検索結果を得るために使用したクエリモデル）を足し合わせ，新しいクエリモデルを構築する．
そして，新しいクエリモデルを用いて，初期検索結果のランキングを修正する．
Zhaiらの手法は，言語モデルに基づくランキングアルゴリズムに対する基本的な適合性フィードバックの手法として重要である．
しかし，彼らの手法では，テキストに表層的に存在する単語の情報しか用いられていない．
これに対し，提案手法では，テキストに潜在的に現れうる単語の分布を推定し，この情報も用いて適合性フィードバックを行う．
本章ではLDA [CITE]について解説する．
LDAは，提案手法において，各単語がテキストに潜在的に現れうる確率を推定するために用いられる．
LDAは文書の生成モデルの一つである．
LDAでは，文書は複数のトピックから生成されると仮定する．
また，文書中の各単語は，各トピックが持つ単語の分布から生成されると仮定する．
ある文書における各トピックの混合比[MATH]は，[MATH]単体中の一点を取る．
ただし，単体中のある一点が選択される確率は，Dirichlet分布によって決められるとする．
以上の生成過程をまとめると，LDAにおける文書[MATH]の生成確率は，次のようにして計算される．
ただし，[MATH]は，Dirichlet分布から得られる[MATH]の生成確率である．
[MATH]は正の実数から構成される[MATH]次元ベクトルで，Dirichlet分布のパラメータを表す．
また，[MATH]と[MATH]は，多項分布から得られる[MATH]と[MATH]の生成確率である．
[MATH] [MATH]はトピックを，[MATH]は[MATH]が持つ単語の分布を表す．
[MATH]はLDAで考慮する語彙数を表す．
LDAでは，変分ベイズ法やギブスサンプリングなどを用いてパラメータを推定する[CITE]．
ギブスサンプリングを用いれば，より厳密な推定結果が得られる．
実装も容易なため，一般的にはギブスサンプリングが用いられることが多い．
しかし，ギブスサンプリングには推定に時間を要するという欠点がある．
一方，変分ベイズ法は，厳密な推定結果は得られないが，高速に動作する．
即時性が要求される検索というタスクの性質を考慮し，提案手法では変分ベイズ法を用いる．
以下，変分ベイズ法による推定方法について説明する．
まず，訓練データ中の各文書[MATH] [MATH]について，変分パラメータ[MATH]と[MATH]を導入する．
ただし，[MATH]である．
そして，式([REF_equ:phi])と式([REF_equ:gamma])を交互に計算し，これらの値を更新する．
\phi_{ijk} & \propto\beta_{kj} \exp\biggl( \Psi(\gamma_{ik}) - \Psi\Bigl(\sum\limits_{k'=1}^{K} \gamma_{ik'}\Bigr)\biggr)
\gamma_{ik} & = \alpha_{k} + \sum\limits_{j=1}^{J} \phi_{ijk}  tf(w_{j},\bm{d}_{i})
ただし，[MATH]はディガンマ関数を表す．
次に，更新された[MATH]と[MATH]を用いて，[MATH]と[MATH]を更新する．
[MATH]と[MATH]の更新には，ニュートン-ラフソン法や固定点反復法を用いる[CITE]．
ここでは固定点反復法による[MATH]と[MATH]の更新式を示す．
更新式は次の通りである．
\beta_{kj} & \propto\sum\limits_{i=1}^{I} \phi_{ijk}  tf(w_{j},\bm{d}_{i})
\alpha_{k} & = \frac_{i=1}^{I} (\alpha_{k} + n_{ik}) - \Psi(\alpha_{k})  _{i=1}^{I} (\alpha_{0} + |\bm{d}_{i}|) - \Psi(\alpha_{0})   \alpha_{k}^{old}
ただし，[MATH]，[MATH]とする．
また，[MATH]は更新前の[MATH]を表すものとする．
以降，[MATH]と[MATH]の更新と，[MATH]と[MATH]の更新を繰り返すことで，各パラメータの値を推定することができる．
[MATH]と[MATH]の値が推定されれば，式([REF_equ:lda])を用いて，文書[MATH]の生成確率を求めることができる．
また，[MATH]の値が推定されれば，次式を用いて，文書[MATH]における単語[MATH]の生起確率[MATH]を求めることができる．
ここで，[MATH]は，[MATH]に潜在するトピックの分布に相当する．
これに基づいて[MATH]を足し合わせることで，[MATH]が[MATH]に潜在的に現れうる確率を求めることができる．
LDAはProbabilistic Latent Semantic Analysis (PLSA) [CITE]をベイズ的に拡張したモデルと位置付けられる．
PLSAに対するLDAの長所として，LDAは未知テキスト（訓練データ中に含まれないテキスト）に関する確率も推定できるという点が挙げられる．
未知テキスト[MATH]にLDAを適用するときは，[MATH]に対して変分パラメータ[MATH]と[MATH]を導入し，式[MATH]と式[MATH]を用いてこれらの値を推定する．
ただし，[MATH]と[MATH]には，訓練データによって推定された値を用いる．
[MATH]が推定されれば，式[MATH]を用いて，未知テキスト[MATH]における単語[MATH]の生成確率[MATH]を求めることができる．
提案手法では，LDAのこの長所を利用して，各単語がフィードバックに潜在的に現れうる確率を求めている．
LDAは，自然言語処理や画像処理，音声認識など，様々な分野で利用されている[CITE]．
情報検索の分野では，例えばWeiらが，クエリの尤度に基づくランキング手法にLDAを利用している[CITE]．
また，Yiらは文書の尤度に基づくランキング手法に，Zhouらはカルバック・ライブラー情報量に基づくランキング手法にLDAを利用している[CITE]．
これらの研究は，LDAを用いて各文書の文書モデルを構築し，それぞれのスコア（e.g.,クエリの尤度）に基づいてクエリに対する検索結果を取得するものである．
本研究では，さらに，ユーザからフィードバックが得られる問題（i.e.,適合性フィードバックの問題）に焦点を当てる．
我々は，フィードバックに対してもLDAを用いてその言語モデルを構築し，構築されたフィードバックモデルを用いて検索結果を修正する．
本章では，提案手法の概要と，提案手法を構成する各ステップについて詳説する．
提案手法では，テキストに表層的に存在する単語の情報だけでなく，テキストに潜在的に現れうる単語の情報も利用して，検索結果をリランキングする．
表層情報だけでなく潜在情報も考慮することで，表層的なレベルだけでなく潜在的なレベルでもフィードバックと類似する文書を検索結果の上位にリランキングする．
図[REF_fig:proposed_method]に提案手法の概要を示す．
以降，本稿では，テキスト[MATH]の表層情報と潜在情報の両方を含む言語モデルを[MATH]と表す（HYBはhybridを表す）．
まず，ユーザによって入力されたクエリ[MATH]に対して，その初期検索結果[MATH]を取得する(Step 1)．
次に，LDAを用いて，[MATH]中の各文書[MATH] [MATH]について，[MATH]に潜在的に現れうる単語の分布を推定する．
そして，[MATH]の表層的な単語の分布と潜在的な単語の分布の両方を考慮した言語モデル[MATH]を構築する(Step 2)．
ユーザからフィードバック[MATH]が得られたら，[MATH]に対してもLDAを実行し，[MATH]に潜在的に現れうる単語の分布を推定する．
そして，検索結果中の各文書と同様，[MATH]に対しても，[MATH]の表層的な単語の分布と潜在的な単語の分布の両方を考慮した言語モデル[MATH]を構築する(Step 3)．
最後に，構築されたフィードバックモデル[MATH]と，初期検索結果[MATH]を得るために使用したクエリモデル[MATH]を混合し，新しいクエリモデル[MATH]を構築する．
そして，検索結果中の各文書[MATH]について，文書モデル[MATH]と新しいクエリモデル[MATH]との類似度を算出し，これに基づいて[MATH]をリランキングする(Step 4)．
次節以降では，各ステップについて詳説する．
なお，提案手法とはそもそもの検索モデルが異なるが，テキストの潜在情報を利用するため，Latent Semantic Analysis (LSA)を用いることも考えられる．
すなわち，各文書をベクトルで表現し，文書セットに対してLSAを実行する．
そして，LSAの実行結果を用いて各ベクトルを低次元の意味的空間に射影することで，各文書に潜在的に現れうる単語の情報を利用することができる．
しかし，この方法では，今述べた通り，文書セット全体に対してLSAを実行する必要がある．
文書セットは時に数千万〜数億文書にも及ぶため，LSAの実行には膨大な時間を要する．
さらに，もし文書セットに対する文書の追加や削除があれば，LSAを実行しなおさなければならない．
一方，提案手法では，検索結果中の各文書に対する[MATH]やフィードバックに対する[MATH]を構築するため，検索結果に対してLDAを実行する必要がある（[REF_ssec:hdm_construction]節及び[REF_ssec:hfm_construction]節で後述）．
しかし，検索結果は文書セットより明らかに規模が小さく，これに要する時間は問題にならない（[REF_ssec:computation_time]節で後述）．
このように，LSAに基づく手法と提案手法の間には，ベースとする検索モデルや効率の面で大きな違いがある．
提案手法では，カルバック・ライブラー情報量に基づいて[CITE]，各文書をランキングする．
まず，文書セット[MATH]中の各文書[MATH] [MATH]について，DIRに基づく文書モデル[MATH]をあらかじめ構築しておく．
ユーザからクエリ[MATH]が与えられると，[MATH]に対してMLEに基づくクエリモデル[MATH]を構築する．
そして，[MATH]中の[MATH]を含む各文書について，[MATH]と[MATH]のカルバック・ライブラー情報量を計算する．
すなわち，クエリ[MATH]に対する文書[MATH]の重要度は，次式のように定義される．
この重要度に従って各文書をランキングし，[MATH]に対する初期検索結果[MATH]を得る．
クエリモデルの構築にMLEを用いたのは，言語モデルに基づくランキングに関する先行研究(e.g., [CITE])に倣ってのことである．
なお，クエリモデルの構築にMLEを用いた場合，カルバック・ライブラー情報量に基づくランキングは，クエリの尤度に基づくランキング[CITE]と等価になる．
[MATH]中の各文書[MATH] [MATH]について，[MATH]の表層情報と潜在情報の両方を含む言語モデル[MATH]を構築する．
まず，各文書[MATH]について，LDAを用いて，[MATH]の潜在情報を含む言語モデル[MATH]を構築する．
具体的な手順は次の通りである．
まず，[MATH]に対してLDAを実行し，[MATH]に対するLDAのパラメータ[MATH]と[MATH] [MATH]，[MATH] [MATH]を推定する（[REF_ssec:parameter_estimation]節参照）．
次に，各文書について，推定された各パラメータ及び式([REF_equ:pwd])を用いて[MATH]を構築する．
[MATH]は，[MATH]に潜在するトピックの分布を基に構築されており，各単語が[MATH]に潜在的に現れうる確率の分布になる（式([REF_equ:pwd])参照）．
次に，構築された[MATH]と[MATH]を次式によって混合し，[MATH]を構築する．
ただし，[MATH]とする．
[MATH]は，各文書の表層的な単語の分布を基に構築される（式([REF_equ:dir])参照）．
[MATH]と[MATH]を混合することで，[MATH]の表層情報と潜在情報の両方を含む言語モデルを構築することができる．
フィードバック[MATH]が得られたら，[MATH]に対しても，[MATH]の表層情報と潜在情報の両方を含む言語モデル[MATH]を構築する．
まず，LDAを用いて，[MATH]の潜在情報を含む言語モデル[MATH]を構築する．
具体的な手順は次の通りである．
まず，Step 2で訓練されたLDAを[MATH]に適用し，[MATH]に対する変分パラメータ[MATH]を推定する（[REF_ssec:inference]節参照）．
次に，推定された[MATH]と式([REF_equ:pwd])を用いて[MATH]を構築する．
[MATH]は，[MATH]と同様，各単語が[MATH]に潜在的に現れうる確率の分布になる．
次に，構築された[MATH]と[MATH]を次式によって混合し，[MATH]を構築する．
ただし，[MATH]は式([REF_equ:dir])を用いて構築する．
[MATH]と[MATH]を混合することで，[MATH]の表層情報と潜在情報の両方を含む言語モデルを構築することができる．
[MATH]をリランキングするため，まず新しいクエリモデルを構築する．
新しいクエリモデル[MATH]は，[MATH]を得るために使用したクエリモデル[MATH]と，Step 3で構築したフィードバックモデル[MATH]を次式のようにして混合し，構築する．
ただし，[MATH]とする．
最後に，[MATH]中の各文書[MATH]について，[MATH]と[MATH]のカルバック・ライブラー情報量を算出する．
すなわち，クエリ[MATH]とフィードバック[MATH]が与えられた下での文書[MATH]の重要度を次式のように定義する．
この重要度に従って各文書をリランキングすることで，検索結果のランキングを修正する．
