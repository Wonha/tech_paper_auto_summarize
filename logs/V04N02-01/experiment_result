係り受け距離の頻度情報に基づいて,いくつかのぺナルティ関数を定義し,総ペナルティ最小化法による係り受け解析を行った．
結果を正解検出率,一意正解率,曖昧度減少率および平均候補数によって評価し,ぺナルティ関数による結果の違いを比較検討した．
また,決定論的解析法による解析も行い,総ペナルティ最小化法の結果と比較した．
文献[CITE]を参考にして, 2文節間の形態素による整合条件を表6に示すように定めた．
{表6   係り受け規則}
実際には,この条件を,「受け文節の頭部の形態素」としての「名詞」,「名詞＋判定詞」,「動詞」のさまざまな変形に対処できるように補強して用いる．
例えば,「二時半ごろだった」(「数詞＋接尾語＋名詞＋名詞＋助動詞＋助動詞」)は「名詞＋判定詞」として認識されるようにしている．
ここではこの条件を係り受け規則と呼ぶ．
この規則は総ペナルティ最小化法と決定論的解析法の両方において共通に使用した．
係り文節[MATH],受け文節[MATH]に対してぺナルティ関数[MATH]を次のように定義する．
ここで, [MATH]は[MATH]が[MATH]に係る頻度から定まる値である．
その具体的な定め方は後で述べる．
文節[MATH]が係り受け規則を満たさない場合には[MATH]と定義する．
このときのぺナルティ値cは非零の[MATH]で生成される最大ぺナルティ値より十分大きな値に設定する．
これにより,文節[MATH]が係り受け規則を満たさない場合には大きなぺナルティが課せられる．
また,係り受け規則を満たす場合には, [MATH]が大きい程,ぺナルティは小さくなる．
[MATH]として次の4種類の関数を考え,それぞれに対して実験を行った．
距離情報なし
[MATH]は正の定数である．
すなわち, [MATH]が一様分布することを仮定する．
距離の頻度近似式
ここで, [MATH]は[MATH]と[MATH]の係り受け距離であり, [MATH]は式(1)である．
係り文節の種類別に求めた頻度分布2.3で述べたように,係り受け距離の頻度分布は係り文節の種類に依存する．
また,係り受け距離が同じでも受け文節が文末か非文末かによって係り受け頻度は大きく異る[CITE]．
そこで係り文節の種類別に,また受け文節が文末か非文末かを区別して,以下のように係り受け距離の頻度分布を求めた．
係り文節の種類(表4)を番号[MATH]で表す．
そして,  [MATH]を係り文節が第[MATH]種の文節であるような係り受け文節対の全体とする:
[MATH]m[MATH]
[MATH]の中で,係り文節と受け文節の距離が[MATH]であり,受け文節が文末であるようなものの全体を[MATH],同じく受け文節が非文末であるようなものの全体を[MATH]とする:
[MATH]  ,
[MATH]
当然,次の関係がある:
そして,以下の式により文節[MATH]が文節[MATH]に係る相対頻度の推定値[MATH]を計算する:
ここで[MATH]は係り文節[MATH]の種類を表し, [MATH]は集合の要素数を表す．
すなわち, [MATH]は,  [MATH]とするとき, [MATH]と同じ種類の文節を係り文節とする係り受け文節対の中で,距離が[MATH]であるようなものが,どれだけの割合で存在するかを示す量であり, [MATH]が文末か非文末かに分けて計算される．
ここでは,係り受け文節対の出現頻度が,係り文節の種類,係り受け距離,および受け文節が文末か非文末かの三つの変数に依存して定まる分布モデルが仮定されていることになる．
補間した頻度分布
係り受け規則がコーパスを完全にカバーしていないため,ある文節を受ける文節が文末までに存在しないことがある．
また係り受け規則で許されても,コーパスの希薄性によって,係り受け頻度が0となる場合がある．
そこで, [MATH]に次のような一種の補間を施し,その結果を[MATH]とする．
上のような問題がない場合:
上のような問題がある場合:
文節[MATH]を受ける文節が文末までに存在しない場合:
文節[MATH]がどの文節に係るかを係り受け距離の頻度分布に基づくヒューリスティクスで定める．
すなわち,文節[MATH]に対して,上の3で推定された係り受け頻度が最大となる後続文節を求め, [MATH]がその文節に係ることを許す．
また,他の文節に係ることは許さない．
これは,文節[MATH]が後続文節[MATH]に係ることが係り受け規則の上では許されなくても,もし文節間距離が[MATH]に等しい係り受け文節対の出現頻度が大きければ,それを許そうという考え方である．
その際,出現頻度が最も大きい後続文節だけに対して文節[MATH]が係ることを許し,他の文節に対しては許さないことにする．
実際の計算は次のように行なう．
文節[MATH]に対して,最大係り受け頻度を与える後続文節を[MATH]とする:
このような[MATH]が複数個あるときは,それらをすべて求める．
そして,文節[MATH]が後続文節[MATH]に係る頻度[MATH]を次のように設定する:
[MATH]に係ることが,係り受け規則で許されるにもかかわらず, [MATH]が0になる場合:
ただし,[MATH]は
を満たすような値に設定する．
ここで,最左辺の最大値は文節[MATH]に係ることが係り受け規則で許されるような[MATH]のすべての組についてとる．
これはいわゆる底上げ(flooring)の技法である．
このとき, [MATH]が[MATH]に係るペナルティは[MATH]となるが,式(3)は,このペナルティが係り受け規則により係り受けが許されない文節対のペナルティよりははるかに小さく,また,係り受け頻度から定まる最大ペナルティよりは大きくなるように[MATH]の値を設定することを意味する．
解析実験は学習データから係り受け距離の頻度情報を抽出する学習ステップと,その頻度情報に基づいて設定したペナルティ関数を用いてテストデータを係り受け解析し,結果を評価する解析ステップから成る．
まず学習法と各種のパラメータ設定法について説明する．
[MATH]を用いる場合には,頻度情報は全く使用しない,したがって学習は不要である．
αはどのような値に設定しても解析結果は同じになる．
[MATH]はパラメトリックな分布モデルである．
学習ステップにおいては,学習データを用いてパラメータ[MATH], [MATH]を推定する．
[MATH]はノンパラメトリックな分布モデルである．
学習ステップにおいては,学習データを用いて,係り文節の種類[MATH]と係り受け距離[MATH]に対して[MATH]と[MATH]を求め,記憶する．
解析ステップにおいては,各文節[MATH], [MATH]に対し, [MATH]と[MATH]から定義式に基づいて[MATH]の値を計算し,ペナルティ関数の値を設定する．
[MATH]は基本的には[MATH]から定まるので学習する必要はない．
βの値は式(3)を満たす限りどのような値に設定しても結果に大きな差はないと考えられるので,式(3)を満たす値を任意に選んで使用した．
ペナルティ関数を式(2)によって定義するとき,定数[MATH]を定める必要がある．
これは文節[MATH]が文節[MATH]に係ることが係り受け規則により許されないとき,あるいは文節[MATH]が文節[MATH]に係る頻度が0になるとき( [MATH]によって補間されない限り)文節 [MATH]が文節[MATH]に係ることを禁止するような大きなペナルティを与えるためのものである．
したがって,これは[MATH]とも言うべきものであり,十分大きな値に設定すれば,どのような値に設定しても解析結果に差はない．
このような学習法およびパラメータ設定法を用いて次のような3種類の実験を行った．
[MATH]〜[MATH]を用いてぺナルティ関数を定義し,総ペナルティ最小化法による解析実験を行った．
この実験では係り受け距離の頻度情報を抽出するための学習データとテストデータを分離せず,どちらも503文すべてを用いた．
比較のため同じデータを用いた決定論的解析法による解析実験も併せて行った．
実験1で総合的に最も良い結果が得られたのは[MATH]で定めたぺナルティ関数である．
これを用いて,学習データとテストデータを分離した解析実験を行った．
10グループ[MATH]の一つをテストデータとし,残りを学習データとした．
テストデータを[MATH]まで変えて10回の実験を行った．
学習データの量と解析結果との関係を調べるため,テストデータをグループ[MATH]に固定し,学習データを[MATH]と漸次増加させる実験を行った．
純粋に学習データの量が解析結果に与える効果を見い出すため,補間していない[MATH]を用いてぺナルティ関数を定めた．
解析結果について述べるため,まず記法と用語を定義する．
[MATH] :評価に用いるテスト文の総数;
[MATH] :番号[MATH]のテスト文;
[MATH] :文[MATH]の文節数;
文[MATH]に対する係り受け構造の中の係り受けの総数は[MATH]に等しい．
[MATH] :長さ[MATH]の文節列上に存在し得る係り受け構造の総数;
[MATH]はカタラン数と呼ばれる数列になり,次の式によって計算することができる:
ここで[MATH]は[MATH]個のものから[MATH]個のものをとる組合せの数を表す．
この式は再帰式
が成り立つ[CITE]ことと,母関数の手法[CITE]を用いることにより示すことができる．
[MATH] :文[MATH]の解析結果,すなわち係り受け構造候補の集合;
[MATH] :文[MATH]に対する[MATH]番目の解析候補の中でコーパスのラベルに示されるものと一致する係り受けの数．
評価方法 結果の評価は,  (1)  2文節間の係り受けがどの程度正しく検出されたか,  (2) 係り受け構造がどの程度正しく検出されたか,という二つの観点から行った．
また,文の検出率が高くても一つの文に対する解析結果の候補数が多ければ良い解析法とは言えない．
このため,候補数がどれだけ絞られるかを評価することとした．
さらに,解析を行うことにより,情報理論的な曖昧さがどれだけ減少するかを調べ,全体的な解析効率を評価した．
これらの評価を行うため,以下のようないくつかの評価尺度を定義した．
(1)係り受けの正しさに着目した評価尺度
係り受け検出率は,解析結果がラベルと部分的に一致する度合を示す数字である．
このような部分的一致も,結果を意味理解に利用する場合などには有用と思われる．
決定論的解析法を用いた解析実験においては,解析の途中で,ある文節を受ける文節が存在しない時には,直後の文節を受け文節として解析を続けた．
その結果をもとにして係り受け検出率を計算した．
(2)係り受け構造の正しさに着目した評価尺度(a)文検出数と文検出率
ここで
[MATH]は,出力された解析結果の候補数が[MATH]以下であり,かつ,その中にコーパス中のラベルで指定される係り受け構造と一致するものが含まれるようなテスト文の数である．
また,これをテスト文の総数に対する比で表わしたものを, [MATH]と呼ぶ:
[MATH] , [MATH]をそれぞれ単に文検出数,文検出率という．
また, [MATH] , [MATH]をそれぞれ一意正解数,一意正解率と呼ぶことにする．
一意正解数は解析結果が一意的に決定し,それがコーパスのラベルと一致したテスト文の数である．
(b)平均候補数
(c)曖昧度減少率
文[MATH]の係り受け構造の候補数の対数をその文の曖昧度と定義すると,
[MATH]
となる．
これを用いて,次の量を定義する．
曖昧度減少率は文の統語的な曖昧さが解析により減少する度合を表す．
実験結果と分析
(1)実験1の結果を表7に示す．
また,同実験において候補数を制限したときの文検出数(率)を表8に示す．
[MATH]を用いた場合は,他の場合と比べて,文検出率が高い反面,平均候補数が非常に大きい．
また,表8から[MATH] ( [MATH])は[MATH]〜[MATH]を用いた場合の方が, [MATH]を用いた場合より高い．
したがって,係り受け距離の情報は候補数を絞るのに有効であることがわかった．
[MATH]を用いた場合は, [MATH]を用いた場合と比較して, 表7における文検出率,および表8における[MATH] ( [MATH])が高い．
したがって,係り文節の種類別に求めた係り受け距離の頻度情報は,係り文節を分類せず全体で求めた情報よりも,各文検出率[MATH]を高めるのに有効である．
また,その結果,曖昧度が減少している．
[MATH]を用いた場合は, [MATH]を用いた場合と比べて,表7における係り受け検出率と表8における一意正解率が高くなっている．
したがって,補間は係り受け検出率と一意正解率を上げる効果があることが検証された．
文検出率は低下したが, [MATH]を用いた場合よりは高く, 平均候補数は[MATH]を用いた場合の半分以下になっている．
したがって,距離の頻度分布を補間することにより,ある程度係り受け規則の不完全さとコーパスの希薄性の問題を軽減できることがわかった．
また,平均候補数は1.1まで絞られており, 87.1%というかなり高い係り受け検出率が得られることから, この解析法を意味理解のための部分解析法として使用できる可能性がある．
決定論的解析法を用いた解析実験と比較すると, [MATH]を用いた場合は表7の平均候補数が大きくなったかわりに文検出率がかなり向上している．
さらに,表8において,  [MATH]〜[MATH]を用いた場合は決定論的解析法を用いた場合の一意正解率を越えるともに各[MATH]が高くなっている．
とくに[MATH]を用いた場合は決定論的解析法を用いた場合と平均候補数がほとんど等しく, 各[MATH] ,曖昧度減少率,および係り受け検出率が高くなっている．
したがって,係り受け距離の統計的知識を利用した総ペナルティ最小化法により,決定論的解析法を用いた場合に比べて解析性能を向上させることができる．
(2)実験2の結果を表9に示す．
この実験は学習データとテストデータを分離した,いわゆるオープン実験である．
文検出率と一意正解率はクローズ実験である実験1の結果に比べると若干低下し,平均候補数もやや増加している．
しかし, 1.2という平均候補数は,この解析結果に対してさらに何らかの後続処理を行う場合,処理量の上で問題となる数ではなく,表7に示される決定論的解析法の結果と比べると,文検出数,一意正解数,曖昧度減少率など全てが高い．
したがって,未知文の係り受け解析に対しても(1)と同様の結論が導かれる．
(3)実験3の結果を表10に示す．
これもオープン実験である．
学習データの量が増加するに従って,一意正解数,曖昧度減少率が向上するともに,平均候補数は減少する．
文検出数はほぼ一定に保たれる．
したがって,学習データ量を増加させることはこのような解析法の性能向上に有効である．
より大きなコーパスを使用することによって,更に解析性能が向上することが期待される．
表10     {実験3の結果}
