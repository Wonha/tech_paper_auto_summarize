この節では，新モデル(後方文脈を考慮したモデル)と旧モデルとの比較実験を行う．
実験に用いたコーパスは，京大コーパス(Version 2) [CITE]の一般文の部分で，基本的に学習には1月1日と1月3日から8日までの7日分(7,958文)，試験には1月9日の1日分(1,246文)を用いた．
[REF_sec:old_model]節に述べた旧モデルと[REF_sec:new_model]節に述べた新モデル(後方文脈を考慮したモデル)のそれぞれを文献[CITE]と同様にMEモデルとして実装し，テストコーパスに対する係り受け解析の精度を調べた．
係り受け解析の実験に用いた素性は，文献[CITE]のものと同じものとした．
これは表[REF_table:feature1]の基本素性と呼ばれるものとそれらの組み合わせである．
このうち，学習コーパス中に4回以上現れた素性約38,000個を用いている．
解析結果を表[REF_Result]に示す．
ここで，係り受けの正解率というのは文末の一文節を除く残りすべての文節に対して，係り先を正しく推定していた文節の割合を求めたものである．
また，文正解率というのは文全体の解析が正しいものの割合を意味する．
表[REF_Result]の第1行および第2行はそれぞれ新モデル，旧モデルを用いて京大コーパス1月9日の1,246文を解析した結果である．
いずれも，コーパスの形態素情報，文節区切情報を入力として，文節間係り受けの解析を決定的に(ビーム幅[MATH])行なった．
ビーム幅を大きくしても精度にほとんど違いはなかったため，決定的に解析した結果のみを示した．
ベースラインとしては各文節がすべて隣に係るとしたときの精度をあげた．
新モデルとしては[REF_sec:new_model]節に述べた後方文脈を考慮したモデルの精度をあげた．
本節では，[REF_sec:old_model]節に述べた旧モデルと[REF_sec:new_model]節に述べた新モデル(後方文脈を考慮したモデル)をそれぞれ理論と実験の観点，学習の観点から比較する．
[理論と実験の観点から]
式([REF_eq:p_db10])は式([REF_eq:p_db6])を包含するものであり，式([REF_eq:p_db6])に比べるとより多くの文節との関係(素性[MATH]で表される)が考慮されている．
ただし，式([REF_eq:p_db7])から式([REF_eq:p_db8])を導くときに用いている独立性の仮定は，実際の現象そのままではなく近似になっているので，旧モデルに比べると近似の部分が多い．
しかしながら，同じ素性を用いた実験(表[REF_Result])で，新モデルは旧モデルに比べて1%程度良い結果を得ている．
これは多少近似があっても実際に係り受け確率の計算に多くの情報を考慮している新モデルの方が良いということを示している．
[htbp]  \beginpicture\setcoordinatesystem units <6pt,6pt> \setplotarea x from 0 to 30, y from 70 to 100
\axis bottom label {文節数} ticks short quantity 7 numbered at 0 10 20 30 / / \axis left label {係り受け正解率} ticks short quantity 4 numbered at 70 80 90 100 / /
\put{*} at 20 98 \put{+} at 20 95 \put{:新モデル} at 25 98.5 \put{:旧モデル} at 25 95
\multiput{*} at 3 93.75 4 93.52 5 92.06 6 91.65 7 90.48 8 90.48 9 89.25 10 90.53 11 88.07 12 86.67 13 86.22 14 89.14 15 86.40 16 86.32 17 83.93 18 86.90 19 83.86 20 86.32 21 84.23 22 83.73 23 85.45 24 86.96 25 81.25 26 86.40 27 83.33 28 85.93 /
\setlinear\plot 3 93.75 4 93.52 5 92.06 6 91.65 7 90.48 8 90.48 9 89.25 10 90.53 11 88.07 12 86.67 13 86.22 14 89.14 15 86.40 16 86.32 17 83.93 18 86.90 19 83.86 20 86.32 21 84.23 22 83.73 23 85.45 24 86.96 25 81.25 26 86.40 27 83.33 28 85.93 /
\multiput{+} at 3 93.75 4 93.98 5 91.12 6 89.01 7 90.99 8 90.30 9 88.38 10 88.34 11 86.39 12 87.88 13 85.88 14 87.93 15 86.95 16 84.04 17 84.38 18 85.29 19 83.07 20 83.68 21 82.69 22 81.75 23 86.82 24 83.85 25 81.25 26 83.20 27 79.49 28 90.37 /
\setlinear\plot 3 93.75 4 93.98 5 91.12 6 89.01 7 90.99 8 90.30 9 88.38 10 88.34 11 86.39 12 87.88 13 85.88 14 87.93 15 86.95 16 84.04 17 84.38 18 85.29 19 83.07 20 83.68 21 82.69 22 81.75 23 86.82 24 83.85 25 81.25 26 83.20 27 79.49 28 90.37 /
\endpicture
次に，図[REF_fig:length]に文節長と解析精度の関係をあげる．
この図から，どの文節数に対しても新モデルの精度は旧モデルの精度とほぼ同等以上であることが分かる．
[学習の観点から]
学習には学習コーパス中で非交差条件を満たす任意の二文節を用いる．
旧モデルでは各二文節に対し「係る」と「係らない」の二つのカテゴリを学習しているのに対し，新モデルでは「越える」と「係る」と「間」の三つのカテゴリを学習している．
一般に学習するカテゴリを多くするとデータスパースネスになりやすいが，新モデルでは三つのカテゴリに分けてもデータスパースネスの問題は生じない．
これは新モデルで「越える」と「間」の二つのカテゴリに分けた，旧モデルの「係らない」というカテゴリにはもともと十分な学習データがあったためである．
例えば，ある文節の係り先の候補が10個あるときには，そのうち1個だけが「係る」に対するデータであり，残りの9個は「係らない」に対するデータである．
ここで「係らない」を「越える」と「間」の二つに分けても，「係る」に比べるとそれぞれ十分な量の学習データがある．
次に，新モデルが旧モデルに比べて優れていることを定量的に示すデータを図[REF_fig:learning_curve]にあげる．
これはそれぞれのモデルに対し，学習コーパスの量と解析精度の関係をプロットしたものである．
学習コーパスの量にかかわらず，新モデルの方が旧モデルに比べて常に1%程度精度がよいことが分かる．
統計的な手法では，ルールベースに比べて並列構造や従属節間の係り受け関係に対する解析誤りが多い．
西岡山らは，この後者の問題を取り上げ，二つの文節の関係が係るか係らずに越えるかを学習するモデルを提案した[CITE]．
このモデルを用いることにより，二つの文節だけでなくその二文節とそれらの間にある文節との関係も扱えるようになる．
本論文で我々が提案したモデル(後方文脈を考慮したモデル)はさらにその二文節とそれらよりも文末に近い側の文節との関係も扱うため，彼らのモデルよりも多くの情報を考慮していることになる．
表[REF_Result2]の一行目に西岡山らのモデルを用いたときの実験結果を示す．
実験に用いた素性，コーパスは[REF_sec:results]章の最初に説明したものと同じである．
後方文脈を考慮したモデルを用いた実験のときと異なるのは，「係る」と「越える」の二つのカテゴリを学習するモデルを用いている部分のみである．
表[REF_Result2]より定量的にも，後方文脈を考慮したモデルのように「間」というカテゴリも考慮した方がよいことが分かる．
次に，後方文脈を考慮したモデルにおいて三カテゴリを学習する必要があることを示す．
後方文脈を考慮したモデルでは特徴(1)としてあげたように二文節間の関係を「間」か「係る」か「越える」かの三カテゴリとして学習する．
この三カテゴリのうち二つのカテゴリ「間」と「越える」を，旧モデルの二カテゴリのうち「係らない」によって代用させたモデルを考える．
このモデルは，係り受け確率を求める際に，着目している二つの文節(前文節と後文節)だけを考慮するのではなく，前文節と前文節より文末側のすべての文節との関係(後方文脈)を考慮している点が旧モデルとは異なる．
表[REF_Result2]の二行目にこのモデルを用いたときの実験結果を示す．
この表より，「間」と「越える」の違いは区別して学習するべきであることが分かる．
