================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.22601] 依存文法に基づく日本語係り受け解析では，文を文節に分割した後，それぞれの文節がどの文節に係りやすいかを表す係り受け行列を作成し，一文全体が最適な係り受け関係になるようにそれぞれの係り受けを決定する．
[i:5, score:0.29438] これまでよく用いられていたモデル(旧モデル)では，その確率値を計算する際に，着目している二つの文節が係るか係らないかということのみを考慮していた．
[i:7, score:0.24606] このモデルをME(最大エントロピー)に基づくモデルとして実装した場合，旧モデルを同じくMEに基づくモデルとして実装した場合に比べて，京大コーパスに対する実験で，全く同じ素性を用いているにもかかわらず係り受け単位で1%程度高い精度(88%)が得られた．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:17, score:0.37308] これまでよく用いられていたモデル(旧モデル)では，係り受け確率を計算する際に，着目している二つの文節が係るか係らないかということのみを考慮していた．
[i:23, score:0.33903] 着目している二つの文節の係り受け確率を求める際に，その二文節に対しては「係る」確率，二文節の間の文節に対しては前文節がその文節を越えて後文節に係る確率(「越える」の確率)，後文節より文末側の文節に対しては前文節がその文節との間にある後文節に係る確率(「間」の確率)をそれぞれ計算し，それらをすべて掛け合わせた確率値を用いて係り受け確率を求める．
[i:24, score:0.34133] (旧モデルでは，着目している二文節が係る確率を計算し，係り受け確率としていた．

================================================================
[section type  : proposed_method]
[section title : 係り受け確率モデル]
================================================================
[i:28, score:0.14890] この確率値は係り受け確率モデルから計算される．
-----------------------------------------------------
  [subsection title : 係り受け確率モデル(旧モデル)]
-----------------------------------------------------
  [i:lead, score:0.13616] この節ではこれまでに依存文法に基づく係り受け解析によく用いられているモデル[CITE]について説明する．
.....
  [i:45, score:0.25899] この式で各々の係り受けつまり[MATH]が独立であると仮定すると，[MATH]は以下のようにそれぞれの文節に対する係り受けの確率の積で表せる．
  [i:49, score:0.24713] 旧モデルでは，[MATH]として文節[MATH]が文節[MATH]に係るか否かの1，0の二値をとると仮定していた．
  [i:50, score:0.23950] 文節[MATH]と係り受けの関係にある文節が文節[MATH]の次から数えて[MATH]番目の係り先の候補であるとき，上述の(iii)の特徴，つまり係り要素は受け要素を一つだけ持つということを仮定すると，
-----------------------------------------------------
  [subsection title : 後方文脈を考慮した係り受け確率モデル]
-----------------------------------------------------
  [i:lead, score:0.03350] この節では，我々が提案するモデルについて説明する．
.....
  [i:59, score:0.39243] 旧モデルでは，二つの文節の関係を「係る」か「係らない」かの二カテゴリとして学習し，それらの二文節が係る確率を計算して係り受け確率としていた．
  [i:60, score:0.39348] 我々のモデルでは，(A)二つの文節(前文節と後文節)間の関係を，「間」か「係る」か「越える」かの三カテゴリとして学習し，(B)着目している二つの文節の係り受け確率を求める際に，その二文節に対しては「係る」確率，二文節の間の文節に対しては前文節がその文節を越えて後文節に係る確率(「越える」の確率)，後文節より文末側の文節に対しては前文節がその文節との間にある後文節に係る確率(「間」の確率)をそれぞれ計算し，それらをすべて掛け合わせた確率値を用いて係り受け確率を求める．
  [i:83, score:0.36451] }例えば，候補3を係り先だと仮定したとき，候補1，候補2は越えて，文節[MATH]と候補4，候補5の間に係る確率は，式([REF_eq:p_db6])の文節[MATH]に関する項を用いて

================================================================
[section type  : experiment_result]
[section title : 実験結果]
================================================================
[i:104, score:0.29825] [REF_sec:old_model]節に述べた旧モデルと[REF_sec:new_model]節に述べた新モデル(後方文脈を考慮したモデル)のそれぞれを文献[CITE]と同様にMEモデルとして実装し，テストコーパスに対する係り受け解析の精度を調べた．
[i:109, score:0.21161] ここで，係り受けの正解率というのは文末の一文節を除く残りすべての文節に対して，係り先を正しく推定していた文節の割合を求めたものである．
[i:112, score:0.22729] いずれも，コーパスの形態素情報，文節区切情報を入力として，文節間係り受けの解析を決定的に(ビーム幅[MATH])行なった．
-----------------------------------------------------
  [subsection title : 旧モデルとの比較]
-----------------------------------------------------
  [i:lead, score:0.19533] 本節では，[REF_sec:old_model]節に述べた旧モデルと[REF_sec:new_model]節に述べた新モデル(後方文脈を考慮したモデル)をそれぞれ理論と実験の観点，学習の観点から比較する．
.....
  [i:117, score:0.24805] [理論と実験の観点から]式([REF_eq:p_db10])は式([REF_eq:p_db6])を包含するものであり，式([REF_eq:p_db6])に比べるとより多くの文節との関係(素性[MATH]で表される)が考慮されている．
  [i:124, score:0.32263] 旧モデルでは各二文節に対し「係る」と「係らない」の二つのカテゴリを学習しているのに対し，新モデルでは「越える」と「係る」と「間」の三つのカテゴリを学習している．
  [i:127, score:0.23946] 例えば，ある文節の係り先の候補が10個あるときには，そのうち1個だけが「係る」に対するデータであり，残りの9個は「係らない」に対するデータである．
-----------------------------------------------------
  [subsection title : その他のモデルとの比較]
-----------------------------------------------------
  [i:lead, score:0.11965] 統計的な手法では，ルールベースに比べて並列構造や従属節間の係り受け関係に対する解析誤りが多い．
.....
  [i:133, score:0.24150] 西岡山らは，この後者の問題を取り上げ，二つの文節の関係が係るか係らずに越えるかを学習するモデルを提案した[CITE]．
  [i:141, score:0.25809] 後方文脈を考慮したモデルでは特徴(1)としてあげたように二文節間の関係を「間」か「係る」か「越える」かの三カテゴリとして学習する．
  [i:143, score:0.36629] このモデルは，係り受け確率を求める際に，着目している二つの文節(前文節と後文節)だけを考慮するのではなく，前文節と前文節より文末側のすべての文節との関係(後方文脈)を考慮している点が旧モデルとは異なる．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:148, score:0.37802] 統計モデルとしてこれまでよく用いられていたもの(旧モデル)では，係り受け確率を計算する際に，着目している二つの文節が係るか係らないかということのみを考慮していた．
[i:149, score:0.20425] 本論文では，着目している二つの文節(前文節と後文節)だけを考慮するのではなく，前文節と前文節より文末側のすべての文節との関係(後方文脈)を考慮するモデルを提案した．
[i:150, score:0.24606] このモデルをME(最大エントロピー)に基づくモデルとして実装した場合，旧モデルを同じくMEに基づくモデルとして実装した場合に比べて，京大コーパスに対する実験で，全く同じ素性を用いているにもかかわらず係り受け単位で1%程度高い精度(88%)が得られた．

