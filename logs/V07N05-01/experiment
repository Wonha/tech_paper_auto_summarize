実験結果
\label{sec:results}

この節では，新モデル(後方文脈を考慮したモデル)と
旧モデルとの比較実験を行う．
実験に用いたコーパスは，京大コーパス(Version 2)
\cite{kurohashi:nlp97} の一般文の部分で，
基本的に学習には1月1日と1月3日から8日までの7日分(7,958文)，
試験には1月9日の1日分(1,246文)を用いた．

\ref{sec:old_model}節に述べた旧モデルと
\ref{sec:new_model}節に述べた新モデル(後方文脈を考慮したモデル)
のそれぞれを文献\cite{Uchimoto:ipsj99}と同様にMEモデルとして実装し，
テストコーパスに対する係り受け解析の精度を調べた．
係り受け解析の実験に用いた素性は，文献\cite{Uchimoto:ipsj99}のものと
同じものとした．これは表\ref{table:feature1}の基本素性と呼ばれるものと
それらの組み合わせである．このうち，学習コーパス中に4回以上現れた素性
約38,000個を用いている．

\begin{table}[htbp]
  \begin{center}
    \caption{解析結果}
    \label{Result} 
    \begin{tabular}{|l@{ }|c@{ }|r@{}c@{ }|}
      \hline
      モデル & 係り受け正解率 & \multicolumn{2}{c|}{文正解率}\\
      \hline      
      新モデル & 87.93\% (9904/11263) & 43.58\% & (540/1239) \\
      旧モデル & 87.02\% (9801/11263) & 40.68\% & (504/1239) \\
      ベースライン & 64.09\% (7219/11263) & 6.38\% & ( 79/1239)\\
      \hline
    \end{tabular}
  \end{center}
\end{table}

解析結果を表\ref{Result}に示す．
ここで，
係り受けの正解率というのは文末の一文節を除く残りすべての文節に対して，
係り先を正しく推定していた文節の割合を求めたものである．
また，文正解率というのは文全体の解析が正しいものの割合を意味する．
表\ref{Result}の第1行および第2行はそれぞれ
新モデル，旧モデルを用いて
京大コーパス1月9日の\mbox{1,246}文を解析した結果である．
いずれも，コーパスの形態素情報，文節区切情報を入力として，
文節間係り受けの解析を決定的に(ビーム幅$k=1$)行なった．
ビーム幅を大きくしても精度にほとんど違いはなかったため，
決定的に解析した結果のみを示した．
ベースラインとしては各文節がすべて隣に係るとしたときの精度をあげた．
新モデルとしては\ref{sec:new_model}節に述べた後方文脈を考慮したモデル
の精度をあげた．

\begin{table}[phtb]
  \begin{center}
    \caption{学習に利用した素性(基本素性)}
    \label{table:feature1}
    \renewcommand{\arraystretch}{}
    \leavevmode
    \begin{tabular}[c]{|l|l|}
      \hline
      \multicolumn{2}{|c|}{\bf 基本素性(43種類)}\\
      \hline
      素性名 & 素性値\\
      \hline
      \hline
      前(後)文節主辞見出し & (2204個) \\
      \hline
      前(後)文節主辞品詞(Major) & 動詞 名詞 $\ldots$ (11個) \\
      前(後)文節主辞品詞(Minor) & 普通名詞 数詞 $\ldots$ (24個) \\
      \hline
      前(後)文節主辞活用(Major) & 母音動詞 $\ldots$ (30個) \\
      前(後)文節主辞活用(Minor) & 語幹 基本形 命令形 $\ldots$ (60個) \\
      \hline
      前(後)文節語形(String) & と に も $\ldots$ (73個) \\
      前(後)文節語形(Major) & 助詞 子音動詞カ行 $\ldots$ (43個)\\
      前(後)文節語形(Minor) & 格助詞 基本連用形 $\ldots$ (102個)\\
      \hline
      前(後)文節助詞1(String) & から まで へ $\ldots$ (63個)\\
      前(後)文節助詞1(Minor) & (無) 格助詞 副助詞 (5個)\\
      \hline
      前(後)文節助詞2(String) & けど まま や よ か $\ldots$ (63個) \\
      前(後)文節助詞2(Minor) & 格助詞 副助詞 (4個) \\
      \hline
      前(後)文節句読点の有無 & (無) 読点 句点 (3個) \\
      \hline
      前(後)文節括弧開の有無 & (無) 「 ‘ （ “ ［ $\ldots$ (14個) \\
      \hline
      前(後)文節括弧閉の有無 & (無) 」 ’ ） ” ］ $\ldots$ (14個) \\
      \hline
      文節間距離 & A(1) B(2〜5) C(6以上) (3個) \\
      \hline
      文節間読点の有無 & 無 有 (2個) \\
      \hline
      文節間"は"の有無 & 無 有 (2個) \\
      \hline
      文節間括弧開閉の有無 & 無 開 閉 開閉 (4個) \\
      \hline
      文節間前文節同一語形の & \\
      \q\q 有無 & 無 有 (2個) \\
      \q\q 主辞品詞(Major) & 動詞 名詞 $\ldots$ (11個) \\
      \q\q 主辞品詞(Minor) & 普通名詞 数詞 $\ldots$ (24個)\\
      \q\q 主辞活用(Major) & 母音動詞 $\ldots$ (30個) \\
      \q\q 主辞活用(Minor) & 語幹 基本形 命令形 $\ldots$ (60個) \\
      \hline
      文節間後文節同一主辞の & \\
      \q\q 有無 & 無 有 (2個) \\
      \q\q 語形(String) & と に も $\ldots$ (73個) \\
      \q\q 語形(Major) & 助詞 子音動詞カ行 $\ldots$ (43個)\\
      \q\q 語形(Minor) & 格助詞 基本連用形 $\ldots$ (102個)\\
      \hline
    \end{tabular}
  \end{center}
\end{table}

\subsection{旧モデルとの比較}
\label{sec:comparison_with_old_model}

本節では，\ref{sec:old_model}節に述べた旧モデルと
\ref{sec:new_model}節に述べた新モデル(後方文脈を考慮したモデル)を
それぞれ理論と実験の観点，学習の観点から比較する．

\vspace{1em}
\noindent
[{\bf 理論と実験の観点から}]

式(\ref{eq:p_db10})は式(\ref{eq:p_db6})を包含するものであり，
式(\ref{eq:p_db6})に比べるとより多くの文節との関係
(素性$F_{i,i+j}$で表される)が考慮されている．
ただし，式(\ref{eq:p_db7})から式(\ref{eq:p_db8})を導くときに用いている
独立性の仮定は，実際の現象そのままではなく近似になっているので，
旧モデルに比べると近似の部分が多い．
しかしながら，同じ素性を用いた実験(表\ref{Result})で，
新モデルは旧モデルに比べて1\%程度良い結果を得ている．
これは多少近似があっても実際に係り受け確率の計算に
多くの情報を考慮している新モデルの方が良いということを示している．

\begin{figure}[htbp]
\hspace*{3em}
\beginpicture
\setcoordinatesystem units <6pt,6pt>
\setplotarea x from 0 to 30, y from 70 to 100

\axis bottom label { 文節数 }
      ticks short quantity 7 numbered at 0 10 20 30  /  / 
\axis left   label { 係り受け正解率 }
      ticks short quantity 4 numbered at 70 80 90 100 /  /

\put {*} at 20 98
\put {+} at 20 95
\put {: 新モデル} at 25 98.5
\put {: 旧モデル} at 25 95

\multiput {*}   at 
3 93.75   4 93.52   5 92.06   6 91.65
7 90.48   8 90.48   9 89.25   10 90.53
11 88.07   12 86.67   13 86.22   14 89.14
15 86.40   16 86.32   17 83.93   18 86.90
19 83.86   20 86.32   21 84.23   22 83.73
23 85.45   24 86.96   25 81.25   26 86.40
27 83.33   28 85.93   /

\setlinear \plot
3 93.75   4 93.52   5 92.06   6 91.65
7 90.48   8 90.48   9 89.25   10 90.53
11 88.07   12 86.67   13 86.22   14 89.14
15 86.40   16 86.32   17 83.93   18 86.90
19 83.86   20 86.32   21 84.23   22 83.73
23 85.45   24 86.96   25 81.25   26 86.40
27 83.33   28 85.93   /

\multiput {+}   at 
3 93.75   4 93.98   5 91.12   6 89.01
7 90.99   8 90.30   9 88.38   10 88.34
11 86.39   12 87.88   13 85.88   14 87.93
15 86.95   16 84.04   17 84.38   18 85.29
19 83.07   20 83.68   21 82.69   22 81.75
23 86.82   24 83.85   25 81.25   26 83.20
27 79.49   28 90.37   /

\setlinear \plot
3 93.75   4 93.98   5 91.12   6 89.01
7 90.99   8 90.30   9 88.38   10 88.34
11 86.39   12 87.88   13 85.88   14 87.93
15 86.95   16 84.04   17 84.38   18 85.29
19 83.07   20 83.68   21 82.69   22 81.75
23 86.82   24 83.85   25 81.25   26 83.20
27 79.49   28 90.37   /

\endpicture
  \caption{文節長と解析精度の関係}
  \label{fig:length}
\end{figure}


次に，図~\ref{fig:length} に文節長と解析精度の関係をあげる．
この図から，
どの文節数に対しても新モデルの精度は
旧モデルの精度とほぼ同等以上であることが分かる．

\vspace{1em}
\noindent
[{\bf 学習の観点から}]

学習には学習コーパス中で非交差条件を満たす任意の二文節を用いる．
旧モデルでは各二文節に対し「係る」と「係らない」の二つのカテゴリを
学習しているのに対し，新モデルでは「越える」と「係る」と「間」の
三つのカテゴリを学習している．
一般に学習するカテゴリを多くするとデータスパースネスになりやすいが，
新モデルでは三つのカテゴリに分けてもデータスパースネスの問題は生じない．
これは新モデルで「越える」と「間」の二つのカテゴリに分けた，
旧モデルの「係らない」というカテゴリにはもともと十分な学習データが
あったためである．
例えば，ある文節の係り先の候補が10個あるときには，そのうち1個だけが
「係る」に対するデータであり，残りの9個は「係らない」に対するデータである．
ここで「係らない」を「越える」と「間」の二つに分けても，
「係る」に比べるとそれぞれ十分な量の学習データがある．

\begin{figure}[htbp]
  \begin{center}
    \leavevmode
\atari(113,77)
    \caption{学習コーパスの量と解析精度の関係}
    \label{fig:learning_curve}
  \end{center}
\end{figure}
次に，新モデルが旧モデルに比べて優れていることを定量的に示す
データを図~\ref{fig:learning_curve} にあげる．
これはそれぞれのモデルに対し，
学習コーパスの量と解析精度の関係をプロットしたものである．
学習コーパスの量にかかわらず，新モデルの方が旧モデルに比べて
常に1\%程度精度がよいことが分かる．

\subsection{その他のモデルとの比較}
\label{sec:comparison_with_related_works}

統計的な手法では，ルールベースに比べて
並列構造や従属節間の係り受け関係に対する解析誤りが多い．
西岡山らは，この後者の問題を取り上げ，
二つの文節の関係が係るか係らずに越えるかを学習する
モデルを提案した\cite{Nishiokayama:98}．
このモデルを用いることにより，二つの文節だけでなく
その二文節とそれらの間にある文節との関係も扱えるようになる．
本論文で我々が提案したモデル(後方文脈を考慮したモデル)は
さらにその二文節とそれらよりも文末に近い側の文節との関係も扱うため，
彼らのモデルよりも多くの情報を考慮していることになる．

\begin{table}[htbp]
  \begin{center}
    \caption{解析結果}
    \label{Result2} 
    \begin{tabular}{|l@{ }|c@{ }|r@{}c@{ }|}
      \hline
      モデル & 係り受け正解率 & \multicolumn{2}{c|}{文正解率}\\
      \hline      
      「係る」と「越える」 & 85.40\% (9618/11263) & 41.40\% & (513/1239) \\
      「係る」と「係らない」 & 86.95\% (9793/11263) & 40.27\% & (499/1239) \\
      「間」「係る」「越える」 
      & 87.93\% (9904/11263) & 43.58\% & (540/1239) \\
      \hline
    \end{tabular}
  \end{center}
\end{table}

表~\ref{Result2} の一行目に西岡山らのモデルを用いたときの実験結果を示す．
実験に用いた素性，コーパスは \ref{sec:results} 章の最初に説明したものと
同じである．後方文脈を考慮したモデルを用いた実験のときと異なるのは，
「係る」と「越える」の二つのカテゴリを学習するモデルを用いている部分のみ
である．表~\ref{Result2} より定量的にも，
後方文脈を考慮したモデルのように「間」というカテゴリも
考慮した方がよいことが分かる．

次に，後方文脈を考慮したモデルにおいて
三カテゴリを学習する必要があることを示す．
後方文脈を考慮したモデルでは特徴(1)としてあげたように二文節間の関係を
「間」か「係る」か「越える」かの三カテゴリとして学習する．
この三カテゴリのうち二つのカテゴリ「間」と「越える」を，
旧モデルの二カテゴリのうち「係らない」によって代用させたモデルを考える．
このモデルは，係り受け確率を求める際に，
着目している二つの文節(前文節と後文節)だけを考慮するのではなく，
前文節と前文節より文末側のすべての文節との関係(後方文脈)を考慮している点が
旧モデルとは異なる．
表~\ref{Result2} の二行目にこのモデルを用いたときの実験結果を示す．
この表より，「間」と「越える」の違いは区別して学習するべきであることが
分かる．

