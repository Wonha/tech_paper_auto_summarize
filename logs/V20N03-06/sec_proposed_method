本研究では，ツイッター上で拡散している誤情報に対して，別の情報発信者がその情報を訂正すると仮定し，誤情報の抽出を行う．
例えば，「コスモ石油の爆発により有害な雨が降る」という誤情報に対して，ツイッター上で以下のような訂正情報を含むツイート（以下，訂正ツイート）が発信された．
\EXS{ex:tweet}{
コスモ石油の爆発により、有害な雨が降る\ulinej{という事実はない。
}
コスモ石油の科学物質を含んだ雨が降る\ulinej{というデマ}がTwitter以外にも出回ってるので注意を}
訂正ツイートは，訂正表現（下線部）と，その訂正対象である誤情報から構成される．
そこで，ツイート中の訂正表現を発見することで，誤情報を抽出できると期待できる．
本節で提案する手法の目標は，訂正表現を手がかりとして，ツイート本文から誤情報を説明する箇所を推定する抽出器を構築することである．
さらに，構築した抽出器によって，ツイート集合から誤情報を過不足なく収集したい．
図[REF_fig:zentai]に提案手法の流れを示す．
手順は大きく4つに分けられる．
まず，ツイート本文に訂正パターン（後述）を適用し，訂正対象となる部分（被訂正フレーズ）を抽出する（ステップ1）．
次に，「昨日のあれ」のように具体的な情報を含まないフレーズを取り除くために，ステップ2において被訂正フレーズに含まれやすいキーワードを選択する．
同一の被訂正情報を言及しているが，表現や情報量の異なるフレーズをまとめるために，フレーズに含まれるキーワードをクラスタリングする（ステップ3）．
その結果，「コスモ石油」や「イソジン」といった，誤情報の代表的なキーワードを含むクラスタが構築される．
図[REF_fig:zentai]左上の表は，被訂正フレーズに含まれやすいキーワードが上位に来るよう，クラスタをステップ2の条件付き確率（式[REF_eq1]，後述）で並べ替えたものである．
最後に，ステップ4で，各クラスタごとに誤情報を最もよく説明しているフレーズを選択する．
図[REF_fig:zentai]右上はステップ3で並べ替えたクラスタからフレーズを抽出し，出力された誤情報のリストである．
以降では，各ステップについて詳細に説明する．
ステップ1では，ツイート本文から被訂正フレーズを見つけ出す．
被訂正フレーズは，「デマ」や「間違い」といった表現で，訂正や打ち消されている箇所のことである．
被訂正フレーズは，「イソジンは被曝を防ぐ」といった単文や，「コスモ石油の火災により有害な雨が降る」といった複文，「うがい薬の件」といった名詞句もある．
被訂正フレーズと訂正表現は，「という」や「のような」といった連体助詞型機能表現で繋がれ，図[REF_fig:correct_pattern]に示す構造をとる．
被訂正フレーズに続く表現を，すなわち連体助詞型機能表現と訂正表現の組み合わせを，「訂正パターン」と呼ぶ．
例えば，図[REF_fig:correct_pattern]において，「というデマ」，「といった事実はありません」が訂正パターンである．
全ツイートを形態素解析し，訂正パターンに対して形態素レベルでのパターン照合を行う．
マッチしたツイートに対して，文頭から訂正パターンの直前までを被訂正フレーズとして抽出する．
被訂正フレーズを漏れなく抽出するには，質のよい訂正パターンを整備することが重要である．
そこで，どのような表現が訂正パターンになり得るのかを調べた．
具体的には，既知の誤情報15件を含むツイートを検索するようなクエリを考え，そのツイートの内容を確認することにより，訂正パターンを収集・整理した．
このようにして得られた訂正パターンの一覧を表[REF_tbl:teisei]に示した．
表[REF_tbl:teisei]の訂正パターンのいずれかを含むツイートに対して，文頭から訂正パターンの直前までを被訂正フレーズとして抽出した例を図[REF_fig:correct_pattern_extraction]に示した．
図[REF_fig:correct_pattern_extraction]の下線部が訂正パターンである．
前節で抽出された被訂正フレーズには，「昨日のあれ」のように具体的な情報が提示されていないフレーズも含まれている．
これらは誤情報としては不適切であるため，取り除く必要がある．
そこで，被訂正フレーズ中の名詞句が訂正情報中に偏って出現しているかどうかを調べる．
ここで分析の対象とする名詞句は，単名詞および名詞連続に限定する．
具体的には，ある名詞句がツイートで言及されるとき，その名詞句が被訂正フレーズに含まれる確率（条件付き確率）を算出する．
被訂正フレーズ中には頻出し，その他のツイート中では出現頻度の低い名詞句は，被訂正時にのみ頻出することから，誤情報のキーワードとなる名詞句である可能性が高い．
逆に，被訂正フレーズ以外でも頻出する名詞句は，一般的な名詞句であり，誤情報のキーワードとなる可能性は低い．
「昨日のあれ」の「昨日」や「あれ」は，被訂正フレーズ以外でも頻出するため，一般的な名詞句であると判断できる．
フレーズ中の名詞句[MATH]が誤情報のキーワードらしいかどうかを，式[REF_eq1]によって計算する．
ここで，[MATH]は訂正フレーズ集合を表す．
このように求めた条件付き確率が高い上位500個を，キーワードとして選択する．
ただし，コーパス中での出現頻度が極端に低い名詞句を除くため，コーパス全体での出現回数が10回以上かつ，被訂正フレーズ集合での出現回数が2回以上の名詞句のみをキーワードとして認定する．
また，ひらがなや記号が半数以上の名詞句（例えば「◯◯町」）はキーワードとして不適切と考え，キーワードから取り除いた．
被訂正フレーズには，「コスモ石油の火災により有害物質を含む雨が降る」と「コスモ石油の爆発は有害だ」のように，同一の被訂正情報を言及しているが，表現や情報量の異なるフレーズが含まれている．
誤情報を過不足なく抽出するために，これらをまとめる必要がある．
そこで，ステップ2で抽出されたキーワードを，同一の被訂正情報を説明するキーワードがまとまるようにクラスタリングする．
クラスタリングにおけるキーワード間の類似度計算では，キーワードと文内で共起する内容語（名詞，動詞，形容詞）を特徴量とした文脈ベクトルを用いた．
これは，周囲に同じ単語が表れていれば，2つのキーワードは類似しているという考えに基づく．
文脈ベクトルの特徴量には，各単語との共起度合いを表す尺度である自己相互情報量(PMI)を用いた．
この値が0以上の内容語を文脈ベクトルの特徴量に加えた．
各文脈ベクトルの類似度はコサイン類似度によって計算した．
クラスタリング手法は，階層クラスタリングの一種である最長距離法を用いた．
今回のデータでは，類似度の閾値を0.2に固定してクラスタリングを行ったところ，500個のキーワードから189個のクラスタが得られた．
得られた各クラスタに対し，式[REF_eq1]の示す確率が最も高いキーワードを代表キーワードとする．
代表キーワードは，クラスタの誤情報を説明するために最も重要なキーワードであると考える．
クラスタごとに被訂正フレーズを抽出し，誤情報として出力する．
誤情報に相応しい被訂正フレーズは，誤情報を過不足なく説明できるような一文である．
例えば，以下の例では，bは説明が不足しており，cは冗長な情報が含まれているため，aを誤情報として出力したい．
\EXS{ex:phrase_selection}{
コスモ石油の火災により，有害物質を含む雨が降る
コスモ石油の件で，有害な雨が降る
コスモ石油が爆発したというのは本当で，有害な雨が降るから傘やカッパが必須らしい}このような選択を可能にするため，内容語の種類と含有率に着目する．
まず，代表キーワードを含む被訂正フレーズを誤情報の候補として抽出する．
次に，この候補の中から誤情報の内容を過不足なく説明するものを抽出する．
文書自動要約における重要文抽出の考えから，前段で用いたキーワードとよく共起する内容語を多く含むものは，より重要な文であると考えられる．
そこで，共起度合いを自己相互情報量(PMI)で計る．
[MATH]は被訂正フレーズ，[MATH]は各クラスタの代表キーワード，[MATH]は[MATH]中の内容語の集合を表す．
ここで，内容語とは被訂正フレーズに含まれる名詞，動詞，形容詞とする．
この式により，誤情報クラスタを代表するキーワードと共起性の強い内容語を多く含むフレーズに対して，高いスコアが付与される．
しかし，この式では，被訂正フレーズに含まれる内容語の数が多い，長い文ほど高いスコアが付与されてしまう．
そこで，代表キーワードを含む文の中でも，典型的な長さの文に高いスコアを付与し，短い文および長い文に対して低いスコアを与える補正項を用いる．
[MATH]は被訂正フレーズ[MATH]の単語数を示す．
[MATH]は，代表キーワード[MATH]を含み，かつ単語数が[MATH]である文の出現頻度を表す．
最終的なスコアは，式[REF_eq_scorep]と式[REF_eq_scoren]を乗算したものとする（下式）．
最後に，各クラスタから式[REF_eq_score_final]のスコアが最も高いフレーズを一つずつ選択し，誤情報として出力する．
本節では，誤情報がどのように発生し，拡散・収束していくかを分析する．
誤情報およびその訂正情報の拡散状況を時系列で可視化することで，誤情報の拡散のメカニズムを詳細かつ系統的に分析する．
分析対象とする誤情報は，将来的には自動抽出結果を用いる予定だが，「東日本大震災の誤情報の拡散状況を正しく分析する」という目的から，誤情報であると確認できた事例のみを用いた．
本節で想定しているシナリオは以下の通りである．
前節までの手法で，ツイート空間上で誤情報と考えられているフレーズ（例えば「コスモ石油のコンビナート火災に伴い有害物質の雨が降る」）を抽出できる．
この誤情報がどのように発生・拡散し，その訂正情報がどのように発生・拡散したのかを調べるため，このフレーズの中からキーワードを選び，ツイート検索システムへのクエリ（例えば「コスモ石油AND有害物質」）とする．
このクエリを用いてツイートを検索すると，誤情報を拡散するツイート，誤情報を訂正するツイートが混ざって得られる．
そこで，本節ではツイートを誤情報の「拡散」と「訂正」の2グループに自動分類する手法を提案する．
図4は実際に作成した，誤情報の拡散状況を提示するシステムである．
このシステムの処理をリアルタイム化すれば，被訂正情報から抜き出したキーワードを誤情報の監視クエリとし，誤情報の拡散・訂正状況をモニタリングしたり，誤情報を発信した（もしくは発信しようとしている）者に，訂正情報の存在を通知することができる．
本節で提案する手法で「拡散」「訂正」ツイートの分類精度を測定するため，14件の誤情報に関して，正解データを作成した．
この正解データを利用すれば，提案手法の性能を評価できるだけではなく，誤情報の拡散・訂正状況を精緻に検証し，誤情報の発生から収束までのメカニズムをモデル化することができる．
最後に，自動手法の失敗解析を通じて，誤情報と訂正情報を対応づける際の技術的課題を述べる．
与えられたツイートに対して，誤情報の「拡散」もしくは「訂正」に分類する手法を，順を追って説明する．
まず，前節までの手法で獲得した誤情報に関連するツイートを集める．
ツイートの収集には本研究室で開発されたツイート全文検索システムを用いる．
誤情報に関連するツイートを収集するために，獲得した誤情報（例えば「東大が合格者の入学取り消し」）を適切なクエリ（例えば「東大AND入学」）に変換する．
次に検索によって得られた全ツイートを誤情報と訂正情報とに分類する．
分類には「デマ」や「風説」などの訂正表現を含むツイートを「訂正情報」とし，含まないものを「訂正情報ではない」ツイートとする．
訂正表現は震災時のツイートを読みながら，121個用意した．
検索で得られるツイートの中には，「誤情報」や「訂正情報」とは関係の無い「その他」のツイートが存在するが，後述する正解データの割合を示した表[REF_kakusan]から分かるように，「その他」の割合は少ない．
そこで本節では「訂正情報ではない」ツイートは誤情報の「拡散」ツイートとして見なす．
本手法の認識精度を評価するため，14件の誤情報に関連するツイート群を検索し，それらのツイートを「誤情報」「訂正情報」「その他」の手作業で分類し，正解データを作成した．
評価対象の誤情報は，人手での作業の負荷を考慮して14件とした．
関連するツイート5,195件のうち，誤情報ツイートが2,462件，訂正情報ツイートが2,376件，その他のツイートが357件であった（表[REF_kakusan]）．
評価対象として14件の誤情報は，第[REF_sec:selecting-representative-phrase]節で定義した条件付き確率（式[REF_eq1]）が高いものから誤った事例を人手で除き，順に選んだ．
今回の実験では被リツイート数の多いツイートを優先的に採用し，手作業による分類のコストを下げた．
なお，評価対象のツイートは誤情報や訂正情報に関するものと仮定しているので，「その他のツイート」は評価の対象外とする．
表[REF_kakusan]に，提案手法が訂正情報を認識する精度（再現率・適合率・F1スコア）を示した．
この評価では，リツイートは削除し，オリジナルのツイートのみを評価対象としている．
表[REF_kakusan]によると，ほとんどの誤情報について高い適合率が得られた．
適合率が高いということは「デマ」などの訂正表現を含むツイートは，かなりの確度で訂正情報と見なせるということである．
「デマ」という語を伴って誤情報の拡散を行うことは，通常では考えにくいので，これは直感的に理解できる結果である．
これに対し，再現率はユーザが誤情報の訂正のために，「デマ」などの訂正表現をどのくらい使うのかを示している．
再現率が高いということは，誤情報の訂正情報のほとんどが「デマ」等の表現を伴うということである（例えば，以下のツイートを参照）．
【拡散希望】トルコが日本に100億円の支援をするという内容のツイートが出回ってますが，誤情報だということです．
情報を発信した本人が誤りだと言ってます．
以上の結果から，訂正表現のマッチングに基づく提案手法でも，かなりの精度で誤情報の「拡散」と「訂正」のツイートを分離できることが示された．
しかし，量は少ないものの，訂正表現を含む誤情報拡散ツイートも見受けられる．
万が一原発から放射能が漏れ出した際，被爆しない為にイソジンを15 cc飲んでおいて下さい！原液です！ガセネタではありません．
お医者さんからの情報です．
これはRTではないので信じてください！
このツイートでは，「ガセ」という訂正表現を含んでいるが，「ガセ」をさらに否定しているので，二重否定により誤情報の拡散ツイートと解釈できる．
さらに，訂正表現を用いずに誤情報を否定するツイートも存在する．
千葉のコスモ石油のタンク爆発事故で中身の有害物質が雲に付着して降ってくるというツイートをよく見かけますが、公式サイトでタンクの中身がLPだったので火災で発生した大気が人体に及ぼす影響はほとんどないみたいです。
このツイートでは，「デマ」「嘘」などの訂正表現は一切使われていないが，誤情報の内容（「コスモ石油の火災により有害物質の雨が降る」）を訂正するツイートであると判断できる．
このようなツイートを訂正ツイートと認識するためには，深い処理（例えば，「タンクの爆発事故」による「人体に及ぼす影響はほとんどない」と解釈する）や，ツイートやユーザ間の関係（例えば，このツイートをRTしているユーザが，訂正表現を用いてた別の訂正ツイートをRTしている，等の手がかり）を用いる必要がある．
本研究において構築した正解データを分析すれば，様々な誤情報の拡散状況を調べることができる．
そこで，誤情報の「拡散」ツイートと「訂正」ツイートの数を，それぞれ一定時間おきに折れ線グラフにプロットし，誤情報の拡散状況を可視化するシステムを開発した．
可視化にはクロス・プラットフォームかつブラウザ上で利用できるGoogle Chart Toolsを用いた．
デモシステムでは，各時点でどのようなツイートが拡散していたのか，ツイート本文を閲覧できるようになっている．
なお，グラフにプロットするツイートの数はリツイート数も考慮し，ツイート空間上での情報の拡散状況を表した．
14件の誤情報に対して，正解データからプロットされたグラフを観察すると，誤情報の拡散状況は，以下の2つの要素で特徴付けらることが分かった．
誤情報ツイート数と訂正ツイート数のどちらが多いか．
誤情報の収束が遅いか速いか．
この2つの要素の組み合わせにより，誤情報の拡散状況を4つにタイプ分けした．
（表[REF_type_kakusan]，図[REF_fig:four-kakusan]参照）
例えば，「サーバールームで身動きが取れない」という誤情報では，人間の危険や不安を伝えているため，誤情報を見たユーザが善意でツイートを拡散する傾向にある．
このように，助けを求めたり，不安を煽るなどの情報は拡散しやすく，情報が間違いである場合は，訂正情報よりも誤情報の拡散ツイートの方が多くなりやすい．
さらに，情報の発信者がジョークとしてつぶやいた情報や，情報の裏を検証することで真偽性を判定しやすいもの，救助などで緊急性を要するものは，短時間収束型になる傾向がある．
他には，「阪神大震災では3時間後に最大の揺れが来た」などの誤情報が，このカテゴリに分類される．
例えば，「支援物資の空中投下は法律で認められていない」という誤情報は，緊急性を要するものではあったが，真偽性を判断する情報源や専門家の数が少ないため，結果として誤情報が長く拡散する傾向にある．
同じカテゴリの誤情報には，「イソジンを飲んで放射線対策」などが挙げられる．
このカテゴリの誤情報は，長期間にわたって拡散し，訂正情報の数も少ないため，情報技術での対応が最も期待されるカテゴリであると考える．
例えば，「被災地の合格者が期限までに書類を提出できないと東大の入学が取り消される」という誤情報は，このカテゴリに属する．
このカテゴリの誤情報は，誤情報を否定する情報源がウェブ等に存在する等で，訂正が容易であったと考えられる．
また，誤情報を否定する情報がすでにウェブ上に存在するか，否定情報が発表されるまでの期間が短いため，誤情報が短時間で収束した．
他には，「阪神大震災時にはレイプが多発」など，既にソースがある誤情報がこのカテゴリに属する．
例えば，「コスモ石油の爆発で有害な雨が降る」という誤情報は，コスモ石油や厚生労働省などの信頼性の高い情報源から訂正情報が流れたため，訂正情報が優勢となった．
ただ，訂正情報の公式発表が遅れたため，誤情報の収束までの時間が長くなった．
また，誤情報の内容に緊急性が無い場合（例えば「トルコが100億円寄付」）も，長時間拡散型になりやすい．
このように，誤情報の拡散と訂正のメカニズムは，情報の緊急性や真偽の検証に必要な情報の入手性・信憑性により，様々であることが分かった．
本研究では，ツイッター上で拡散している誤情報に対して，別の情報発信者がその情報を訂正すると仮定し，誤情報の抽出を行う．
例えば，「コスモ石油の爆発により有害な雨が降る」という誤情報に対して，ツイッター上で以下のような訂正情報を含むツイート（以下，訂正ツイート）が発信された．
\EXS{ex:tweet}{
コスモ石油の爆発により、有害な雨が降る\ulinej{という事実はない。
}
コスモ石油の科学物質を含んだ雨が降る\ulinej{というデマ}がTwitter以外にも出回ってるので注意を}
訂正ツイートは，訂正表現（下線部）と，その訂正対象である誤情報から構成される．
そこで，ツイート中の訂正表現を発見することで，誤情報を抽出できると期待できる．
本節で提案する手法の目標は，訂正表現を手がかりとして，ツイート本文から誤情報を説明する箇所を推定する抽出器を構築することである．
さらに，構築した抽出器によって，ツイート集合から誤情報を過不足なく収集したい．
図[REF_fig:zentai]に提案手法の流れを示す．
手順は大きく4つに分けられる．
まず，ツイート本文に訂正パターン（後述）を適用し，訂正対象となる部分（被訂正フレーズ）を抽出する（ステップ1）．
次に，「昨日のあれ」のように具体的な情報を含まないフレーズを取り除くために，ステップ2において被訂正フレーズに含まれやすいキーワードを選択する．
同一の被訂正情報を言及しているが，表現や情報量の異なるフレーズをまとめるために，フレーズに含まれるキーワードをクラスタリングする（ステップ3）．
その結果，「コスモ石油」や「イソジン」といった，誤情報の代表的なキーワードを含むクラスタが構築される．
図[REF_fig:zentai]左上の表は，被訂正フレーズに含まれやすいキーワードが上位に来るよう，クラスタをステップ2の条件付き確率（式[REF_eq1]，後述）で並べ替えたものである．
最後に，ステップ4で，各クラスタごとに誤情報を最もよく説明しているフレーズを選択する．
図[REF_fig:zentai]右上はステップ3で並べ替えたクラスタからフレーズを抽出し，出力された誤情報のリストである．
以降では，各ステップについて詳細に説明する．
ステップ1では，ツイート本文から被訂正フレーズを見つけ出す．
被訂正フレーズは，「デマ」や「間違い」といった表現で，訂正や打ち消されている箇所のことである．
被訂正フレーズは，「イソジンは被曝を防ぐ」といった単文や，「コスモ石油の火災により有害な雨が降る」といった複文，「うがい薬の件」といった名詞句もある．
被訂正フレーズと訂正表現は，「という」や「のような」といった連体助詞型機能表現で繋がれ，図[REF_fig:correct_pattern]に示す構造をとる．
被訂正フレーズに続く表現を，すなわち連体助詞型機能表現と訂正表現の組み合わせを，「訂正パターン」と呼ぶ．
例えば，図[REF_fig:correct_pattern]において，「というデマ」，「といった事実はありません」が訂正パターンである．
全ツイートを形態素解析し，訂正パターンに対して形態素レベルでのパターン照合を行う．
マッチしたツイートに対して，文頭から訂正パターンの直前までを被訂正フレーズとして抽出する．
被訂正フレーズを漏れなく抽出するには，質のよい訂正パターンを整備することが重要である．
そこで，どのような表現が訂正パターンになり得るのかを調べた．
具体的には，既知の誤情報15件を含むツイートを検索するようなクエリを考え，そのツイートの内容を確認することにより，訂正パターンを収集・整理した．
このようにして得られた訂正パターンの一覧を表[REF_tbl:teisei]に示した．
表[REF_tbl:teisei]の訂正パターンのいずれかを含むツイートに対して，文頭から訂正パターンの直前までを被訂正フレーズとして抽出した例を図[REF_fig:correct_pattern_extraction]に示した．
図[REF_fig:correct_pattern_extraction]の下線部が訂正パターンである．
前節で抽出された被訂正フレーズには，「昨日のあれ」のように具体的な情報が提示されていないフレーズも含まれている．
これらは誤情報としては不適切であるため，取り除く必要がある．
そこで，被訂正フレーズ中の名詞句が訂正情報中に偏って出現しているかどうかを調べる．
ここで分析の対象とする名詞句は，単名詞および名詞連続に限定する．
具体的には，ある名詞句がツイートで言及されるとき，その名詞句が被訂正フレーズに含まれる確率（条件付き確率）を算出する．
被訂正フレーズ中には頻出し，その他のツイート中では出現頻度の低い名詞句は，被訂正時にのみ頻出することから，誤情報のキーワードとなる名詞句である可能性が高い．
逆に，被訂正フレーズ以外でも頻出する名詞句は，一般的な名詞句であり，誤情報のキーワードとなる可能性は低い．
「昨日のあれ」の「昨日」や「あれ」は，被訂正フレーズ以外でも頻出するため，一般的な名詞句であると判断できる．
フレーズ中の名詞句[MATH]が誤情報のキーワードらしいかどうかを，式[REF_eq1]によって計算する．
ここで，[MATH]は訂正フレーズ集合を表す．
このように求めた条件付き確率が高い上位500個を，キーワードとして選択する．
ただし，コーパス中での出現頻度が極端に低い名詞句を除くため，コーパス全体での出現回数が10回以上かつ，被訂正フレーズ集合での出現回数が2回以上の名詞句のみをキーワードとして認定する．
また，ひらがなや記号が半数以上の名詞句（例えば「◯◯町」）はキーワードとして不適切と考え，キーワードから取り除いた．
被訂正フレーズには，「コスモ石油の火災により有害物質を含む雨が降る」と「コスモ石油の爆発は有害だ」のように，同一の被訂正情報を言及しているが，表現や情報量の異なるフレーズが含まれている．
誤情報を過不足なく抽出するために，これらをまとめる必要がある．
そこで，ステップ2で抽出されたキーワードを，同一の被訂正情報を説明するキーワードがまとまるようにクラスタリングする．
クラスタリングにおけるキーワード間の類似度計算では，キーワードと文内で共起する内容語（名詞，動詞，形容詞）を特徴量とした文脈ベクトルを用いた．
これは，周囲に同じ単語が表れていれば，2つのキーワードは類似しているという考えに基づく．
文脈ベクトルの特徴量には，各単語との共起度合いを表す尺度である自己相互情報量(PMI)を用いた．
この値が0以上の内容語を文脈ベクトルの特徴量に加えた．
各文脈ベクトルの類似度はコサイン類似度によって計算した．
クラスタリング手法は，階層クラスタリングの一種である最長距離法を用いた．
今回のデータでは，類似度の閾値を0.2に固定してクラスタリングを行ったところ，500個のキーワードから189個のクラスタが得られた．
得られた各クラスタに対し，式[REF_eq1]の示す確率が最も高いキーワードを代表キーワードとする．
代表キーワードは，クラスタの誤情報を説明するために最も重要なキーワードであると考える．
クラスタごとに被訂正フレーズを抽出し，誤情報として出力する．
誤情報に相応しい被訂正フレーズは，誤情報を過不足なく説明できるような一文である．
例えば，以下の例では，bは説明が不足しており，cは冗長な情報が含まれているため，aを誤情報として出力したい．
\EXS{ex:phrase_selection}{
コスモ石油の火災により，有害物質を含む雨が降る
コスモ石油の件で，有害な雨が降る
コスモ石油が爆発したというのは本当で，有害な雨が降るから傘やカッパが必須らしい}このような選択を可能にするため，内容語の種類と含有率に着目する．
まず，代表キーワードを含む被訂正フレーズを誤情報の候補として抽出する．
次に，この候補の中から誤情報の内容を過不足なく説明するものを抽出する．
文書自動要約における重要文抽出の考えから，前段で用いたキーワードとよく共起する内容語を多く含むものは，より重要な文であると考えられる．
そこで，共起度合いを自己相互情報量(PMI)で計る．
[MATH]は被訂正フレーズ，[MATH]は各クラスタの代表キーワード，[MATH]は[MATH]中の内容語の集合を表す．
ここで，内容語とは被訂正フレーズに含まれる名詞，動詞，形容詞とする．
この式により，誤情報クラスタを代表するキーワードと共起性の強い内容語を多く含むフレーズに対して，高いスコアが付与される．
しかし，この式では，被訂正フレーズに含まれる内容語の数が多い，長い文ほど高いスコアが付与されてしまう．
そこで，代表キーワードを含む文の中でも，典型的な長さの文に高いスコアを付与し，短い文および長い文に対して低いスコアを与える補正項を用いる．
[MATH]は被訂正フレーズ[MATH]の単語数を示す．
[MATH]は，代表キーワード[MATH]を含み，かつ単語数が[MATH]である文の出現頻度を表す．
最終的なスコアは，式[REF_eq_scorep]と式[REF_eq_scoren]を乗算したものとする（下式）．
最後に，各クラスタから式[REF_eq_score_final]のスコアが最も高いフレーズを一つずつ選択し，誤情報として出力する．
本節では，誤情報がどのように発生し，拡散・収束していくかを分析する．
誤情報およびその訂正情報の拡散状況を時系列で可視化することで，誤情報の拡散のメカニズムを詳細かつ系統的に分析する．
分析対象とする誤情報は，将来的には自動抽出結果を用いる予定だが，「東日本大震災の誤情報の拡散状況を正しく分析する」という目的から，誤情報であると確認できた事例のみを用いた．
本節で想定しているシナリオは以下の通りである．
前節までの手法で，ツイート空間上で誤情報と考えられているフレーズ（例えば「コスモ石油のコンビナート火災に伴い有害物質の雨が降る」）を抽出できる．
この誤情報がどのように発生・拡散し，その訂正情報がどのように発生・拡散したのかを調べるため，このフレーズの中からキーワードを選び，ツイート検索システムへのクエリ（例えば「コスモ石油AND有害物質」）とする．
このクエリを用いてツイートを検索すると，誤情報を拡散するツイート，誤情報を訂正するツイートが混ざって得られる．
そこで，本節ではツイートを誤情報の「拡散」と「訂正」の2グループに自動分類する手法を提案する．
図4は実際に作成した，誤情報の拡散状況を提示するシステムである．
このシステムの処理をリアルタイム化すれば，被訂正情報から抜き出したキーワードを誤情報の監視クエリとし，誤情報の拡散・訂正状況をモニタリングしたり，誤情報を発信した（もしくは発信しようとしている）者に，訂正情報の存在を通知することができる．
本節で提案する手法で「拡散」「訂正」ツイートの分類精度を測定するため，14件の誤情報に関して，正解データを作成した．
この正解データを利用すれば，提案手法の性能を評価できるだけではなく，誤情報の拡散・訂正状況を精緻に検証し，誤情報の発生から収束までのメカニズムをモデル化することができる．
最後に，自動手法の失敗解析を通じて，誤情報と訂正情報を対応づける際の技術的課題を述べる．
与えられたツイートに対して，誤情報の「拡散」もしくは「訂正」に分類する手法を，順を追って説明する．
まず，前節までの手法で獲得した誤情報に関連するツイートを集める．
ツイートの収集には本研究室で開発されたツイート全文検索システムを用いる．
誤情報に関連するツイートを収集するために，獲得した誤情報（例えば「東大が合格者の入学取り消し」）を適切なクエリ（例えば「東大AND入学」）に変換する．
次に検索によって得られた全ツイートを誤情報と訂正情報とに分類する．
分類には「デマ」や「風説」などの訂正表現を含むツイートを「訂正情報」とし，含まないものを「訂正情報ではない」ツイートとする．
訂正表現は震災時のツイートを読みながら，121個用意した．
検索で得られるツイートの中には，「誤情報」や「訂正情報」とは関係の無い「その他」のツイートが存在するが，後述する正解データの割合を示した表[REF_kakusan]から分かるように，「その他」の割合は少ない．
そこで本節では「訂正情報ではない」ツイートは誤情報の「拡散」ツイートとして見なす．
本手法の認識精度を評価するため，14件の誤情報に関連するツイート群を検索し，それらのツイートを「誤情報」「訂正情報」「その他」の手作業で分類し，正解データを作成した．
評価対象の誤情報は，人手での作業の負荷を考慮して14件とした．
関連するツイート5,195件のうち，誤情報ツイートが2,462件，訂正情報ツイートが2,376件，その他のツイートが357件であった（表[REF_kakusan]）．
評価対象として14件の誤情報は，第[REF_sec:selecting-representative-phrase]節で定義した条件付き確率（式[REF_eq1]）が高いものから誤った事例を人手で除き，順に選んだ．
今回の実験では被リツイート数の多いツイートを優先的に採用し，手作業による分類のコストを下げた．
なお，評価対象のツイートは誤情報や訂正情報に関するものと仮定しているので，「その他のツイート」は評価の対象外とする．
表[REF_kakusan]に，提案手法が訂正情報を認識する精度（再現率・適合率・F1スコア）を示した．
この評価では，リツイートは削除し，オリジナルのツイートのみを評価対象としている．
表[REF_kakusan]によると，ほとんどの誤情報について高い適合率が得られた．
適合率が高いということは「デマ」などの訂正表現を含むツイートは，かなりの確度で訂正情報と見なせるということである．
「デマ」という語を伴って誤情報の拡散を行うことは，通常では考えにくいので，これは直感的に理解できる結果である．
これに対し，再現率はユーザが誤情報の訂正のために，「デマ」などの訂正表現をどのくらい使うのかを示している．
再現率が高いということは，誤情報の訂正情報のほとんどが「デマ」等の表現を伴うということである（例えば，以下のツイートを参照）．
【拡散希望】トルコが日本に100億円の支援をするという内容のツイートが出回ってますが，誤情報だということです．
情報を発信した本人が誤りだと言ってます．
以上の結果から，訂正表現のマッチングに基づく提案手法でも，かなりの精度で誤情報の「拡散」と「訂正」のツイートを分離できることが示された．
しかし，量は少ないものの，訂正表現を含む誤情報拡散ツイートも見受けられる．
万が一原発から放射能が漏れ出した際，被爆しない為にイソジンを15 cc飲んでおいて下さい！原液です！ガセネタではありません．
お医者さんからの情報です．
これはRTではないので信じてください！
このツイートでは，「ガセ」という訂正表現を含んでいるが，「ガセ」をさらに否定しているので，二重否定により誤情報の拡散ツイートと解釈できる．
さらに，訂正表現を用いずに誤情報を否定するツイートも存在する．
千葉のコスモ石油のタンク爆発事故で中身の有害物質が雲に付着して降ってくるというツイートをよく見かけますが、公式サイトでタンクの中身がLPだったので火災で発生した大気が人体に及ぼす影響はほとんどないみたいです。
このツイートでは，「デマ」「嘘」などの訂正表現は一切使われていないが，誤情報の内容（「コスモ石油の火災により有害物質の雨が降る」）を訂正するツイートであると判断できる．
このようなツイートを訂正ツイートと認識するためには，深い処理（例えば，「タンクの爆発事故」による「人体に及ぼす影響はほとんどない」と解釈する）や，ツイートやユーザ間の関係（例えば，このツイートをRTしているユーザが，訂正表現を用いてた別の訂正ツイートをRTしている，等の手がかり）を用いる必要がある．
本研究において構築した正解データを分析すれば，様々な誤情報の拡散状況を調べることができる．
そこで，誤情報の「拡散」ツイートと「訂正」ツイートの数を，それぞれ一定時間おきに折れ線グラフにプロットし，誤情報の拡散状況を可視化するシステムを開発した．
可視化にはクロス・プラットフォームかつブラウザ上で利用できるGoogle Chart Toolsを用いた．
デモシステムでは，各時点でどのようなツイートが拡散していたのか，ツイート本文を閲覧できるようになっている．
なお，グラフにプロットするツイートの数はリツイート数も考慮し，ツイート空間上での情報の拡散状況を表した．
14件の誤情報に対して，正解データからプロットされたグラフを観察すると，誤情報の拡散状況は，以下の2つの要素で特徴付けらることが分かった．
誤情報ツイート数と訂正ツイート数のどちらが多いか．
誤情報の収束が遅いか速いか．
この2つの要素の組み合わせにより，誤情報の拡散状況を4つにタイプ分けした．
（表[REF_type_kakusan]，図[REF_fig:four-kakusan]参照）
例えば，「サーバールームで身動きが取れない」という誤情報では，人間の危険や不安を伝えているため，誤情報を見たユーザが善意でツイートを拡散する傾向にある．
このように，助けを求めたり，不安を煽るなどの情報は拡散しやすく，情報が間違いである場合は，訂正情報よりも誤情報の拡散ツイートの方が多くなりやすい．
さらに，情報の発信者がジョークとしてつぶやいた情報や，情報の裏を検証することで真偽性を判定しやすいもの，救助などで緊急性を要するものは，短時間収束型になる傾向がある．
他には，「阪神大震災では3時間後に最大の揺れが来た」などの誤情報が，このカテゴリに分類される．
例えば，「支援物資の空中投下は法律で認められていない」という誤情報は，緊急性を要するものではあったが，真偽性を判断する情報源や専門家の数が少ないため，結果として誤情報が長く拡散する傾向にある．
同じカテゴリの誤情報には，「イソジンを飲んで放射線対策」などが挙げられる．
このカテゴリの誤情報は，長期間にわたって拡散し，訂正情報の数も少ないため，情報技術での対応が最も期待されるカテゴリであると考える．
例えば，「被災地の合格者が期限までに書類を提出できないと東大の入学が取り消される」という誤情報は，このカテゴリに属する．
このカテゴリの誤情報は，誤情報を否定する情報源がウェブ等に存在する等で，訂正が容易であったと考えられる．
また，誤情報を否定する情報がすでにウェブ上に存在するか，否定情報が発表されるまでの期間が短いため，誤情報が短時間で収束した．
他には，「阪神大震災時にはレイプが多発」など，既にソースがある誤情報がこのカテゴリに属する．
例えば，「コスモ石油の爆発で有害な雨が降る」という誤情報は，コスモ石油や厚生労働省などの信頼性の高い情報源から訂正情報が流れたため，訂正情報が優勢となった．
ただ，訂正情報の公式発表が遅れたため，誤情報の収束までの時間が長くなった．
また，誤情報の内容に緊急性が無い場合（例えば「トルコが100億円寄付」）も，長時間拡散型になりやすい．
このように，誤情報の拡散と訂正のメカニズムは，情報の緊急性や真偽の検証に必要な情報の入手性・信憑性により，様々であることが分かった．
