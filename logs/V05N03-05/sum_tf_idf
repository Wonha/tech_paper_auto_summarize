================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:186] 我々が提案する統合的確率言語モデルは，構文的優先度などの構文的な統計情報を反映する構文モデルと，単語の出現頻度や単語の共起関係などの語彙的な統計情報を反映する語彙モデルの2つの下位モデルから成る．
[i:2, score:154] この統合的確率言語モデルは，構文的な統計情報と語彙的な統計情報を同時に学習する過去の多くのモデルと異なり，両者を個別に学習する点に特徴がある．
[i:4, score:129] この統合的確率言語モデルを評価するために，日本語文の文節の係り受け解析を行った．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:22, score:235] 例えば田辺らは，確率文脈自由文法(Probabilistic Context Free Grammar,以下PCFG)における書き換え規則の非終端記号に，その非終端記号が支配する句の主辞となる単語を付加すること(以下，これをPCFGの語彙化と呼ぶ)によって語彙的従属関係をPCFGの確率モデルに反映させる方法を提案している[CITE]．
[i:34, score:189] この統合的確率言語モデルの特徴は，単語の出現頻度，および単語の共起関係といった2つの語彙的な統計情報を局所化し，構文的な統計情報と独立に取り扱う点にある．
[i:35, score:203] また，構文的な統計情報を構文構造の生成確率として，語彙的な統計情報を単語列の生成確率としてそれぞれ学習し，これらの積を解析結果の候補に対するスコアとすることにより，曖昧性解消に両者を同時に利用することができる．

================================================================
[section type  : proposed_method]
[section title : 統合的確率言語モデル]
================================================================
[i:52, score:167] 本研究では，式([REF_eq:model])に示した通り，解析結果の生成確率を以下の2つの確率モデルの積として計算する．
[i:54, score:110] この確率モデルには構文的な統計情報を反映させる．
[i:55, score:159] 語彙モデル[MATH]構文構造[MATH]が与えられたときに，それから単語列[MATH]を生成する確率である．
-----------------------------------------------------
  [subsection title : 構文モデル$P(R)$]
-----------------------------------------------------
  [i:lead, 152] 構文モデルとしては，構文的な統計情報を反映し，かつ構文構造[MATH]の生成確率を高い精度で推定するものであれば，どのような確率モデルを利用してもよい．
.....
  [i:57, score:152] 構文モデルとしては，構文的な統計情報を反映し，かつ構文構造[MATH]の生成確率を高い精度で推定するものであれば，どのような確率モデルを利用してもよい．
  [i:58, score:124] 構文モデルに利用できる確率モデルとしては，PCFGや確率一般化LR法(Probabilistic Generalized LR Method，以下PGLR)などが挙げられる．
  [i:61, score:160] PGLRは，LR表に記述された各状態遷移の遷移確率を推定し，その遷移確率の積によって1つの状態遷移列，すなわちそれに対応する構文構造の生成確率を与えるモデルである．
-----------------------------------------------------
  [subsection title : 語彙モデル$P(W|R)$]
-----------------------------------------------------
  [i:lead, 168] 語彙モデルは，品詞列[MATH]を末端とする構文構造[MATH]が与えられたときに，それから単語列[MATH]を生成する確率である．
.....
  [i:98, score:388] このとき，これらの生成確率([REF_eq:der1-o]),([REF_eq:der1-ga])を以下のように近似しても，助詞とその係り先用言との間の語彙的従属関係，および同じ用言に係る助詞同士の従属関係(以下，これを格間の従属関係と呼ぶ)を語彙モデルに反映させることができる．
  [i:143, score:412] 従属係数を導入する利点として，単語生成文脈を複数取り扱うことができるという点の他に，式([REF_eq:lex-model-der-dp])に示すように，語彙モデル[MATH]を単語の出現頻度のみを反映した[MATH]と単語の共起関係のみを反映した[MATH]との積に分解できるという点が挙げられる．
  [i:146, score:338] これに対し，式([REF_eq:lex-model-dp])の統計量[MATH]は各単語[MATH]とその単語生成文脈[MATH]の従属係数の積を表わしており，[MATH]と[MATH]の相関関係に関する優先度(すなわち単語の共起関係)が反映される．

================================================================
[section type  : experiment_result]
[section title : 評価実験]
================================================================
[i:149, score:166] 統合的確率言語モデルは本来形態素解析，構文解析を同時に行うことを前提としているが，そのような大規模な実験を行う前の予備実験として，まずは文節列を入力とする文節間の係り受け解析のみを行った．
-----------------------------------------------------
  [subsection title : 構文モデルの学習]
-----------------------------------------------------
  [i:lead, 98] 本節の実験では，入力として単語列，品詞列，文節区切りが与えられたときに，それぞれの文節の係り先となる文節を決定する．
.....
  [i:155, score:195] 例えば，``パイ-を''や``彼女-の''など，「名詞助詞」といった品詞並びによって構成される文節は，他の文節から連体修飾を受ける可能性があるので受け属性は``(連体)''となり，他の文節を連体修飾したり用言を修飾してその格要素および表層格を表わす可能性があるので係り属性は``(連用,格関係)''となる．
  [i:157, score:136] これは，読点を末尾に持つ文節は直後の文節には係りにくく，読点を末尾に持たない文節よりも遠くに係る傾向があるので，この違いを構文モデルに反映させるためである．
  [i:160, score:159] [REF_sec:lex-model]節で例示した単語生成文脈決定規則は，単語の共起関係の中でも特に用言の格関係に注目している．
-----------------------------------------------------
  [subsection title : 語彙モデルの学習]
-----------------------------------------------------
  [i:lead, 224] 本実験では，式([REF_eq:lex-model-der-dp])に示した語彙モデル[MATH]のうち，[MATH]の計算を省略できる．
.....
  [i:173, score:350] 今回の実験では，\lcrule{lc:filler}〜#[REF_lc:josi]によって定められる従属係数([REF_eq:ldp-filler]), ([REF_eq:ldp-marker-multi2]),([REF_eq:ldp-josi])を[MATH]の要素とし，これらの学習を行った．
  [i:188, score:262] 次に，用言に係る助詞に関する従属係数([REF_eq:ldp-marker])の学習について説明する．
  [i:189, score:270] [MATH]個の助詞[MATH]が同じ用言[MATH]に係っている場合には，それぞれの[MATH]に対応する従属係数([REF_eq:ldp-marker])の積を計算すれば良い．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [i:lead, 212] [REF_sec:learn-syn-model]節にて学習した構文モデル[MATH]，および[REF_sec:learn-lex-model]節にて学習した語彙モデル[MATH]を用いて，文節の係り受け解析を行った．
.....
  [i:219, score:261] 格要素となる名詞に関する従属係数のみを用いたモデル[MATH]として，式([REF_eq:ldp-filler])によって与えられる従属係数のみを考慮したモデルである．
  [i:220, score:303] 用言に係る助詞に関する従属係数のみを用いたモデル[MATH]として，式([REF_eq:ldp-marker-multi2])によって与えられる従属係数のみを考慮したモデルである．
  [i:221, score:291] 体言に係る助詞に関する従属係数のみを用いたモデル[MATH]として，式([REF_eq:ldp-josi])によって与えられる従属係数のみを考慮したモデルである．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:251, score:172] 我々の手法の特徴は，構文的優先度，隣接する品詞間の共起関係，距離に関する優先度といった構文的な統計情報を構文モデル[MATH]として，単語の出現頻度および単語の共起関係を語彙モデル[MATH]として，それぞれ独立に学習する点にある．
[i:254, score:209] また，これらの確率モデルを用いた日本語文の文節の係り受け解析実験の結果，構文的な統計情報と語彙的な統計情報のそれぞれが曖昧性解消に大きく貢献することを確認した．
[i:259, score:118] 最後に，統合的確率言語モデルと他の統計的構文解析に関する研究とを実験的に比較することが挙げられる．

