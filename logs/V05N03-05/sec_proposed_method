まず，本論文で一貫して用いる記号について説明する．
入力文字列[MATH]
[MATH]を生成する単語列[MATH]
[MATH]を生成する品詞列[MATH]
[MATH]を生成する構文構造[MATH]
本研究では，形態素解析と構文解析を同時に取り扱うことを仮定する．
すなわち，入力文字列[MATH]が与えられたときに，その正しい単語列[MATH]，正しい品詞列[MATH]，正しい構文構造[MATH]を求めることを目的とする．
例えば，「彼女がパイを食べた」という入力文に対する解析結果の候補の例を図[REF_fig:examsent]に示す．
[htbp]
\leavevmode
各解析結果の候補に対してその生成確率[MATH]を計算し，これが最大の解析結果を選択することによって曖昧性解消を行う．
さらに，確率モデル[MATH]を以下のように分解する．
ここで，構文構造[MATH]は最終的に品詞列[MATH]を生成するものと仮定すると，[MATH]となる(図[REF_fig:examsent]参照)．
また，単語列[MATH]が決まれば入力文字列[MATH]は一意に決まるので，[MATH]となる．
したがって，式([REF_eq:model-org])は以下のように簡略化できる．
本研究では，式([REF_eq:model])に示した通り，解析結果の生成確率を以下の2つの確率モデルの積として計算する．
構文モデル[MATH]
構文構造[MATH]の生成確率である．
この確率モデルには構文的な統計情報を反映させる．
語彙モデル[MATH]
構文構造[MATH]が与えられたときに，それから単語列[MATH]を生成する確率である．
この語彙モデルには語彙的な統計情報を反映させる．
構文モデルとしては，構文的な統計情報を反映し，かつ構文構造[MATH]の生成確率を高い精度で推定するものであれば，どのような確率モデルを利用してもよい．
構文モデルに利用できる確率モデルとしては，PCFGや確率一般化LR法(Probabilistic Generalized LR Method，以下PGLR)などが挙げられる．
我々は，PGLRを構文モデルの有力な候補として考えている．
PGLRとは，構文解析手法のひとつである一般化LR法を拡張したものである．
PGLRは，LR表に記述された各状態遷移の遷移確率を推定し，その遷移確率の積によって1つの状態遷移列，すなわちそれに対応する構文構造の生成確率を与えるモデルである．
このPGLRはPCFGに比べて，次のような特長を持つ[CITE]．
文脈依存性を取り扱うことができる．
隣接する品詞間の共起関係を取り扱うことができる．
距離に関する優先度を取り扱うことができる．
ここで，隣接する品詞間の共起関係とは，品詞bi-gramのような品詞列の出現に関する統計情報であり，形態素解析の曖昧性解消に有効であると考えられる．
また，距離に関する優先度とは，単語はなるべく近い単語に係りやすいといった，係り受け関係にある単語間の距離に関する統計情報である．
語彙モデルは，品詞列[MATH]を末端とする構文構造[MATH]が与えられたときに，それから単語列[MATH]を生成する確率である．
この語彙モデルは，式([REF_eq:lex-model-org])のような各単語[MATH]の生成確率の積として計算することができる．
例えば，図[REF_fig:examsent]の例において，単語を文の後ろから順番に生成していくと仮定すると，語彙モデル[MATH]は以下のような単語の生成確率の積として計算できる．
式([REF_eq:lex-model-org])の各項(図[REF_fig:examsent]の例では式([REF_eq:der1-ta])〜([REF_eq:der1-kanojo]))のパラメタ空間は非常に大きく，これを直接学習することは一般に不可能である．
ところが，各単語[MATH]の生成に強く影響するのは各項の確率の前件[MATH]全てではなく，その一部のみであると考えられる．
例えば，図[REF_fig:examsent]の例文において，``パイ''は動詞``食べ''のヲ格の格要素となっている．
このとき，``パイ''という単語を生成する際には，式([REF_eq:der1-pai])の前件``[MATH]'' (図[REF_fig:lc-pai]の斜線部)のうち，品詞[MATH]と単語``を'',``食べ'' (図[REF_fig:lc-pai]の丸で囲まれた部分)によって十分近似できると期待できる(式([REF_eq:lc-pai1]))．
[htbp]
\leavevmode
式([REF_eq:lc-pai1])において，[MATH]は，``食べ''という動詞のヲ格の格要素となっている名詞を表わしている．
すなわち，[MATH]は，``食べ''という動詞のヲ格の格要素となっている名詞から``パイ''という単語が生成される確率を表わしている．
したがって，式([REF_eq:lc-pai1])には，``パイ''という単語そのものがどれくらい出現しやすいかといった単語の出現頻度と，``パイ''と``食べ''がどの程度共起しやすいかといった単語の共起関係が反映されている．
ここで，単語生成文脈[MATH]を以下のように定義する．
単語[MATH]の単語生成文脈[MATH]とは，[MATH]の生成確率の前件[MATH]から[MATH]の生成に強く影響する部分のみを取り出したものである．
先ほどの例においては，単語``パイ''の単語生成文脈は``[MATH]''である．
そして，各単語[MATH]の生成確率の前件``[MATH]''を，その単語の品詞[MATH]と単語生成文脈[MATH]に縮退することにより，語彙モデル[MATH]を以下のように近似する．
単語生成文脈を導入する際に問題となるのは，どのような単語に対してどのような単語生成文脈を選べばよいのかということである．
我々は，これを人手で作成した規則によって記述する．
以下，単語[MATH]の単語生成文脈[MATH]を決定する規則を単語生成文脈決定規則と呼ぶ．
単語生成文脈決定規則の例を以下に挙げる．
単語の共起関係を全く考慮しない場合
単語[MATH]について，周囲の単語との従属関係を考慮しない場合には，その単語の生成確率はその単語の品詞[MATH]のみに依存するとみなす．
例えば，図[REF_fig:examsent]の例において，助動詞``た''と動詞``食べ''を生成する際に他の単語との語彙的従属関係を考えない場合には，それぞれの生成確率([REF_eq:der1-ta]),([REF_eq:der1-tabe])は以下のように近似すればよい．
これに対応した単語生成文脈決定規則を以下に示す．
この規則は単語生成文脈を決定する際のデフォルト規則でもある．
{lc:default}単語[MATH]を生成する際に他の単語との従属関係を考慮しない場合には，単語[MATH]の単語生成文脈[MATH]を空とする．
格要素となる名詞が助詞を介して動詞に係る際の従属関係を考慮する場合
前述のように，格要素となる名詞が助詞を介して動詞に係る際には，動詞・助詞の組と名詞との間には語彙的従属関係が存在する．
このような語彙的従属関係を確率モデルに反映させるために\lcrule{lc:filler}を定義する．
{lc:filler}単語[MATH]の品詞[MATH]が[MATH](名詞)であり，かつ助詞[MATH]を介して動詞[MATH]に係っているとき，単語[MATH]の単語生成文脈[MATH]を[MATH]とする．
このとき，[MATH]の生成確率[MATH]は動詞[MATH]の格[MATH]の格要素となる名詞[MATH]から単語[MATH]が生成される確率を表わす．
例えば，図[REF_fig:examsent]の例において，名詞``パイ''は動詞``食べ''のヲ格の格要素であり，名詞``彼女''は動詞``食べ''のガ格の格要素となっている．
したがって，これらの単語を生成する際にはこの規則が適用され，それぞれの生成確率([REF_eq:der1-pai]),([REF_eq:der1-kanojo])は以下のように近似される．
助詞とその係り先用言の従属関係，格間の従属関係を考慮する場合
図[REF_fig:examsent]の例文においては，2つの助詞``が''と``を''が動詞``食べ''に係っている．
このとき，これらの生成確率([REF_eq:der1-o]),([REF_eq:der1-ga])を以下のように近似しても，助詞とその係り先用言との間の語彙的従属関係，および同じ用言に係る助詞同士の従属関係(以下，これを格間の従属関係と呼ぶ)を語彙モデルに反映させることができる．
式([REF_eq:der2-o])は，助詞[MATH]が2つの助詞の係り先となっている動詞``食べ''に係っているときに，品詞[MATH]から単語``を''が生成される確率を表わしている．
一方式([REF_eq:der2-ga])は，助詞[MATH]が2つの助詞の係り先となりかつそのうちの1つは``を''である動詞``食べ''に係っているときに，品詞[MATH]から単語``が''が生成される確率を表わしている．
助詞とその係り先用言の従属関係，および格間の従属関係を語彙モデルに導入するために，\lcrule{lc:marker}を以下のように定義する．
{lc:marker}単語[MATH]の品詞[MATH]が[MATH](助詞)でありかつ用言[MATH]に係っているとき，単語[MATH]の単語生成文脈[MATH]を[MATH]とする．
このとき，[MATH]の生成確率[MATH]は，用言[MATH]が[MATH]個の助詞の係り先となりかつ用言に近い[MATH]の助詞が既に生成されているときに，[MATH]として[MATH]が生成される確率を表わす．
\lcrule{lc:marker}において，同じ用言に係る助詞は用言に近いものから順番に生成されると仮定している．
すなわち，助詞が出現する順序も考慮されている．
助詞の係り先が用言か体言かを考慮する場合
助詞の係り先が用言である場合と体言である場合とでは，助詞の生成確率[MATH]の分布は著しく異なると考えられる．
例えば，係り先が用言の場合には``が''，``を''などの助詞は出現しやすいが，助詞``の''は出現しにくい．
これに対して，係り先が体言の場合，すなわちその助詞を含む文節が連体修飾節となっている場合には，助詞``の''が出現する場合が圧倒的に多いと予想される．
したがって，助詞の生成確率[MATH]を学習する際に，その助詞の係り先が用言もしくは体言であるかを区別しないで学習するのは望ましいことではない．
これに対応するには，以下のような\lcrule{lc:josi}を定義すればよい．
{lc:josi}単語[MATH]の品詞[MATH]が[MATH](助詞)であり，かつその助詞の係り先が体言であるとき，単語[MATH]の単語生成文脈[MATH]をnd\/とする．
nd\/はその助詞の係り先が体言であることを表わすシンボルである．
このとき，[MATH]の生成確率[MATH]は，体言を係り先とする助詞から単語[MATH]が生成される確率を表わす．
助詞の単語生成文脈を決定する際には，助詞の係り先が用言である場合には\lcrule{lc:marker}が，助詞の係り先が体言である場合には\lcrule{lc:josi}が適用される．
ここに挙げた\lcrule{lc:default}〜#[REF_lc:josi]が単語生成文脈を決定するための全ての規則というわけではない．
本節では，特に用言の格関係に注目して語彙モデルに反映させるべき語彙的従属関係(単語の共起関係)の例を挙げたが，他の種類の語彙的従属関係を語彙モデルに反映させるように単語生成文脈決定規則を拡張・洗練することもできる．
すなわち，語彙モデルにおいてどのような語彙的従属関係を考慮するかは，単語生成文脈決定規則の追加・変更によって柔軟に調整することが可能である．
単語生成文脈として何を選択するかを自動的に学習することも考えられるが，我々は言語学的知見に基づくヒューリスティクス規則によって単語生成文脈を選択する方向で研究をすすめている．
なぜなら，語彙モデルにどのような種類の語彙的従属関係を反映させるかを単語生成文脈決定規則によって明確に記述することにより，モデルに反映された統計情報が曖昧性解消に有効であるかどうかなど，モデルの特性の分析を容易に行うことができるからである．
これまでは単語を生成する際に考える単語生成文脈は常に一つであると仮定していた．
しかしながら，一般には，一つの単語を生成する際に複数の単語生成文脈を考慮しなければならない場合もある．
[tbp]
\leavevmode
例えば，図[REF_fig:exam-coord]の例文において，2つの文節``食べ-て''と``出かけ-た''は並列の関係にある．
したがって，この例文中の名詞``彼女''は動詞``食べ''のハ格の格要素であり，同時に動詞``出かけ''のハ格の格要素でもある．
したがって，\lcrule{lc:filler}に従えば，``彼女''という単語を生成する際の単語生成文脈としては[MATH]と[MATH]の2つがある．
このとき，``彼女''の生成確率は次のように推定することが望ましい．
同様に，この例文中の助詞``は''は動詞``食べ''と``出かけ''の両方に係っているとみなすことができる．
したがって，\lcrule{lc:marker}に従えば，``は''という単語を生成する際の単語生成文脈として[MATH]と[MATH]の2つがあると考えられ，``は''の生成確率も次のように推定することが望ましい．
ところが，式([REF_eq:der-cor1-kanojo])や([REF_eq:der-cor1-wa])のように複数の単語生成文脈を前件に持つ確率モデルは，推定するパラメタの数が爆発的に増大する可能性がある．
そこで本研究では，複数の単語生成文脈を以下のように取り扱う．
まず，説明を簡略化するために，単語[MATH]が2つの単語生成文脈[MATH]と[MATH]を持つとする．
このとき，単語[MATH]の生成確率[MATH]を以下のように近似する．
式([REF_eq:prove-dp-1])から式([REF_eq:prove-dp-2])の変形において，2つの単語生成文脈[MATH]と[MATH]は互いに独立であると仮定している．
ここで，従属係数[MATH]を式([REF_eq:def-dp])のように定義する．
この従属係数を用いれば，式([REF_eq:prove-dp])から式([REF_eq:double-dp])が導かれる．
以上では単語[MATH]が2つの単語生成文脈を持つ場合を考えていたが，単語[MATH]が[MATH]個の単語生成文脈[MATH]を持つ場合にも同様の近似が可能であり，最終的に以下の式が得られる．
式([REF_eq:def-dp])で定義した従属係数[MATH]は単語[MATH]と単語生成文脈[MATH]の相関関係を評価する統計量である．
例えば，[MATH]と[MATH]に相関関係がない場合，すなわち[MATH]と[MATH]が互いに独立である場合には，式([REF_eq:def-dp])の分子[MATH]は分母[MATH]にほぼ等しくなり，従属係数[MATH]は1に近い値を取る．
これに対し，[MATH]と[MATH]に正の相関関係がある場合には，単語生成文脈[MATH]を前件に加えた確率[MATH]は単語生成文脈[MATH]を無視した確率[MATH]よりも大きくなるので，その従属係数は1より大きい値を取る．
同様に，[MATH]と[MATH]に負の相関関係がある場合には従属係数は1より小さい値を取る．
複数の単語生成文脈[MATH]の下での単語[MATH]の生成確率は，単語生成文脈を無視した単語の生成確率[MATH]と，[MATH]と[MATH]の相関関係を他の単語生成文脈とは独立に評価した従属係数[MATH]の積によって計算できることを式([REF_eq:multi-dp])は示している．
従属係数[MATH]を他の単語生成文脈と独立に推定・学習することにより，確率モデルのパラメタ空間を推定可能な大きさに抑制することができる．
例えば，図[REF_fig:exam-coord]の例において，``彼女''の生成確率([REF_eq:der-cor1-kanojo])と``は''の生成確率([REF_eq:der-cor1-wa])はそれぞれ以下のように推定される．
従属係数を導入する利点として，単語生成文脈を複数取り扱うことができるという点の他に，式([REF_eq:lex-model-der-dp])に示すように，語彙モデル[MATH]を単語の出現頻度のみを反映した[MATH]と単語の共起関係のみを反映した[MATH]との積に分解できるという点が挙げられる．
上式において，[MATH]は単語[MATH]の単語生成文脈の集合を表わしている．
式([REF_eq:lex-model-der])の統計量[MATH]は，単語生成文脈を無視したときに品詞[MATH]から単語[MATH]が生成される確率の積であり，単語の出現頻度に関する優先度が反映される．
これに対し，式([REF_eq:lex-model-dp])の統計量[MATH]は各単語[MATH]とその単語生成文脈[MATH]の従属係数の積を表わしており，[MATH]と[MATH]の相関関係に関する優先度(すなわち単語の共起関係)が反映される．
このように，語彙モデルを単語の出現頻度，および単語の共起関係のみを反映させた2つの統計量の積として分解することにより，[REF_sec:intro]節で述べたように，曖昧性解消時におけるそれぞれの統計情報の働きを容易に理解することができる．
