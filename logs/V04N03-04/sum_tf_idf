================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.10659] 提案する手法では，まず各言語の言語データから確率的言語モデルを構築し，次に確率的言語モデルの間に導入した距離に基づき，元の言語に対するクラスタリングを実行する．
[i:3, score:0.19686] また，提案した手法を用いて，ECI多言語コーパス(European Corpus Initiative Multilingual Corpus)中の19ヶ国語のテキスト・データから，言語の系統樹を再構築する実験を行った．
[i:4, score:0.06794] 本実験で得られた結果は，言語学で確立された言語系統樹と非常に似ており，提案した手法の有効性を示すことができた．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:6, score:0.11027] 確率的言語モデルは，従来，自然言語処理や音声処理などの工学分野で用いられ，その有効性を実証してきたが，比較言語学，方言研究，言語類型論，社会言語学など，言語学の諸分野においても有用な手法を提供するものと思われる．
[i:9, score:0.09906] 次に，確率モデル間に距離尺度を導入し，この距離尺度に基づき言語のクラスタリングを行なう方法を提案する．
[i:12, score:0.18938] ここでは，ECI多言語コーパス(European Corpus Initiative Multilingual Corpus)中の19ヶ国語のテキスト・データから，言語の系統樹を再構築する．

================================================================
[section type  : proposed_method]
[section title : 従来の研究]
================================================================
[i:16, score:0.10206] KroeberおよびChretienは，1930年代に，音韻や語形等の言語的特徴から言語間の相関係数を求め，これに基づきインド・ヨーロッパ諸言語9ヶ国語およびヒッタイト語の間の類似性を求める研究を行っている[CITE]．
[i:21, score:0.08226] 文献[CITE]の４章で述べられている方法では，インド・ヨーロッパ諸言語の一致度を調べるために，２つの言語の対応する数詞の最初の子音が一致しているか否かを調べている．
[i:22, score:0.08329] たとえば，ドイツ語とスペイン語の数詞``1''はそれぞれ``eins''および``uno''であるが，これらの２単語において，最初に出現する子音は共に``n''であるので，数詞``1''に関しては，ドイツ語とスペイン語は一致していると考える．

================================================================
[section type  : proposed_method]
[section title : 確率モデルに基づく言語のクラスタリング]
================================================================
[i:32, score:0.07404] この方法では，まず各言語の言語データから確率的言語モデルを自動的に学習し，次に確率モデル間に距離を導入することにより，言語間の距離を定義する．
[i:35, score:0.08317] たとえば，言語によって違うジャンルのテキストであったり，あるいはデータのサイズが異なっていても，これらのデータの揺れを確率モデルの中に吸収することができる．
[i:36, score:0.08212] 確率モデルとしては，様々なものが考えられるが，４節で述べる評価実験では文字のtrigramモデルを用いた．
-----------------------------------------------------
  [subsection title : $N$-gram モデル]
-----------------------------------------------------
  [i:lead, score:0.08408] たとえば，英語では文字qには文字uが後続するとか，ドイツ語においては文字cに後続するのはhやkであるなど，文字の連鎖には確率・統計的な性質が存在する．
.....
  [i:39, score:0.08408] たとえば，英語では文字qには文字uが後続するとか，ドイツ語においては文字cに後続するのはhやkであるなど，文字の連鎖には確率・統計的な性質が存在する．
  [i:44, score:0.07844] [MATH]-gramモデルを用いた場合，文字列[MATH]の生成確率は，次のようにして計算することができる．
  [i:48, score:0.07834] [MATH]-gramの確率は，言語データ中に出現する文字の[MATH]個組と[MATH]個組の出現回数から，次のように推定することができる．
-----------------------------------------------------
  [subsection title : $N$-gram モデルのスムージング]
-----------------------------------------------------
  [i:lead, score:0.09855] [MATH]-gramの確率値は，式([REF_Eq:NgramTraining])に示すように，言語データ中の文字列の頻度から推定することができる．
.....
  [i:51, score:0.09855] [MATH]-gramの確率値は，式([REF_Eq:NgramTraining])に示すように，言語データ中の文字列の頻度から推定することができる．
  [i:53, score:0.07660] この問題に対処するために，我々の実験では，線形補間法と呼ばれる方法を用いて，[MATH]-gramモデルのスムージング(平滑化)を行った．
  [i:57, score:0.06595] 式([REF_Eq:NgramLinearInterpolation])の補間では，学習データ中に三つ組[MATH]が出現しない場合には，bigramとunigramから[MATH]の値を推定している．
-----------------------------------------------------
  [subsection title : 言語モデル間の距離]
-----------------------------------------------------
  [i:lead, score:0.05078] 次に，言語モデル間に距離を導入する．
.....
  [i:63, score:0.07073] 上記文献においては，隠れマルコフ・モデル(Hidden Markov Model; HMM)間の距離として定義されているが，一般の言語モデルに対しても同様に用いることができる．
  [i:68, score:0.10145] 式([REF_Eq:DistanceMeasure0])では，言語[MATH]と[MATH]の間の距離を，言語[MATH]のモデル[MATH]からデータ[MATH]が生成される確率と，言語[MATH]のモデル[MATH]から同一のデータ[MATH]が生成される確率の差に基づいて決めている．
  [i:69, score:0.08297] もし，言語[MATH]と[MATH]が類似していれば，モデルからのデータの生成確率も似た値になるので距離は小さくなるし，類似していなければ，データの生成確率が大きく違うので距離は大きくなる．

================================================================
[section type  : experiment_result]
[section title : 評価実験]
================================================================
-----------------------------------------------------
  [subsection title : 言語データ]
-----------------------------------------------------
  [i:lead, score:0.17228] 以上で提案した方法の有効性を実証するために，ECI多言語コーパス(European Corpus Initiative Multilingual Corpus)中の言語データを用いて，言語の系統樹を再構築する実験を行った．
.....
  [i:73, score:0.17228] 以上で提案した方法の有効性を実証するために，ECI多言語コーパス(European Corpus Initiative Multilingual Corpus)中の言語データを用いて，言語の系統樹を再構築する実験を行った．
  [i:75, score:0.12069] ECIコーパス中には，主要なヨーロッパ各国語およびトルコ語，日本語，ロシア語，中国語，マレー語等の言語データが含まれている．
  [i:82, score:0.12985] また，文字のtrigramは，表[REF_Tab:ECI_data]の識別子欄に示されているテキストの最初の1,000単語を用いた．
-----------------------------------------------------
  [subsection title : 実験結果および考察]
-----------------------------------------------------
  [i:lead, score:0.12792] 上記により作成した文字trigramモデルに対し，階層的(凝集型)クラスター分析を行ない，言語のデンドログラム(dendrogram;樹状図)を作成した．
.....
  [i:117, score:0.13165] スラブ語派(チェコ語，クロアチア語，セルビア語，スロベニア語)
  [i:127, score:0.13034] まず，実験結果では，スラブ語派に属するクロアチア語とセルビア語を，最初に一つのクラスタとしてまとめている．
  [i:134, score:0.17342] 西ゲルマン語派に関しては，オランダ語とドイツ語を，まず併合しているが，ドイツ語学では，オランダ語をドイツ語の１方言，低地フランク語として扱っており，この２言語はきわめて類似している．
-----------------------------------------------------
  [subsection title : 言語識別の実験]
-----------------------------------------------------
  [i:lead, score:0.10107] 上記実験により，確率的言語モデルは言語のクラスタリングにきわめて有効であることを示したが，クラスタリング以外の分野での確率的言語モデルの有用性を示すために，追加実験として言語識別の実験を行った．
.....
  [i:145, score:0.10660] 言語によっては，表[REF_Tab:ECI_data]以外のテキスト・データがないものもあり，言語識別用の評価データは26個(13言語)となった．
  [i:147, score:0.36578] チェコ語(cze01a02, cze01a03)，ラテン語(lat01a02, lat01a03)，マレー語(mal01a02, mal01a03)，ノルウェー語(nor01a02, nor01a03)，セルビア語(ser01a01, ser01a02)，デンマーク語(mda12a, mda12b)，オランダ語(dut01a01, dut01a02)，英語(eng01a, eng01b)，フランス語(fre01a01, fre01a02)，ドイツ語(ger02a, ger02b)，イタリア語(ita01a, ita03a)，ポルトガル語(por01a, por01b)，スペイン語(spa02a, spa02b)．
  [i:157, score:0.10830] Cavnarらは，テキスト中に頻出する[MATH]-gram文字列の出現順位に基づいた距離を用いて，高い精度で言語の自動識別ができることを示している．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:161, score:0.17095] また，ECI多言語コーパス中の19ヶ国語のテキスト・データから言語の系統樹を再構築する実験を行ない，実験結果を言語学での分類と比較することにより，提案した手法の有効性を示した．
[i:162, score:0.11724] 本稿では，確率的言語モデルとして文字の[MATH]-gramモデルを用いたため，文字の連鎖という観点からのクラスタリング結果が得られた．
[i:163, score:0.09609] 言語類型論の分野では，言語の語順等により諸言語間の比較を行うことなどが行われているが，語順等に対する言語モデルを設定することができれば，言語類型性という観点から見たクラスタリングを行うことができるであろう．

