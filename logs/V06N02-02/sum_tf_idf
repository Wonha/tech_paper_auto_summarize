================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:1, score:0.41817] このモデルはsuperwordと呼ぶ文字列の集合の上の[MATH]-gramとして定義され，従来の単語や文字列の[MATH]-gramモデルを包含するものになっている．
[i:2, score:0.40830] superwordは訓練テキスト中の文字列の再現性のみに基づいて定義される概念であり，Forward-Backwardアルゴリズムによって学習される．
[i:3, score:0.43164] 実験の結果，superwordに基づくモデルと文字のtrigramモデルを複数融合させたモデルの優位性が示され，形態素解析に基づく方法および高頻度文字列に基づく方法を上回る性能が得られた．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:30, score:0.41067] このモデルは，superwordと呼ぶ文字列の集合の上の[MATH]-gramモデルとして定義される．
[i:31, score:0.39263] superwordは訓練テキスト中の文字列の再現性のみに基づいて定義される概念であり，与えられた訓練テキストに対して一意に定まる．
[i:33, score:0.12913] 訓練テキストを明示的に分割せぬまま学習を行うため，長い文字列中の部分文字列を「再利用」することが可能となり，少量の訓練テキストでも効率の良いモデル化が期待できる．

================================================================
[section type  : proposed_method]
[section title : superwordモデルの定式化]
================================================================
[i:54, score:0.43814] ここで[MATH]の時，すなわちsuperword unigramモデルは，文全体の生起確率がそれぞれ独立なsuperwordの生起確率の積で表されるとするものであり，multigram[CITE]と呼ばれる可変長単語列に基づく言語モデルと同一のものである．
[i:55, score:0.41481] superword [MATH]-gramモデルのクラスは，単語や文字列の[MATH]-gramモデルのクラスを包含する．
[i:56, score:0.43101] この性質は，パラメータさえ適切に与えることができれば，superwordに基づくモデルの性能が単語や文字列の[MATH]-gramモデルの性能と同等かそれ以上になることを保証する．

================================================================
[section type  : proposed_method]
[section title : superwordモデルの学習法]
================================================================
-----------------------------------------------------
  [subsection title : superword集合の獲得]
-----------------------------------------------------
  [i:lead, score:0.38802] モデルの獲得にあたっては，パラメータの学習に先立ち，訓練テキストからsuperwordの集合を求める必要がある．
.....
  [i:57, score:0.38802] モデルの獲得にあたっては，パラメータの学習に先立ち，訓練テキストからsuperwordの集合を求める必要がある．
  [i:58, score:0.37015] 長さ1のsuperwordについては自明であるから，再現性のある文字列を集める作業が核心である．
  [i:61, score:0.34767] 実験で用いたテキストコーパスでは，長さ[MATH]のsuperwordの種類は大きな[MATH]では単調に減少することが観察されている．
-----------------------------------------------------
  [subsection title : 確率分布のForward-Backward学習]
-----------------------------------------------------
  [i:lead, score:0.39220] superwordモデルでは，ある状態から別の状態に移る時に，ある確率で一つのsuperwordを出力する．
.....
  [i:62, score:0.39220] superwordモデルでは，ある状態から別の状態に移る時に，ある確率で一つのsuperwordを出力する．
  [i:65, score:0.38601] superwordモデルの出力はsuperword列としてではなく文字の系列として観測される．
  [i:67, score:0.38769] 副状態は，状態を分割したもので，そこに移る時最後に出力したsuperwordの各文字に対応する．

================================================================
[section type  : proposed_method]
[section title : 長さ制限の導入]
================================================================
[i:92, score:0.39578] これは，逐次的な再現性文字列の獲得を早い段階で打ち切って小さなsuperwordの集合をつくり，その集合に基づいてForward-Backward学習を行うことで得ることができる．
[i:93, score:0.38160] 以下では，長さ[MATH]に制限されたsuperword [MATH]-gram確率を[MATH]と表記する．
[i:94, score:0.43015] 長さが[MATH]に制限されたsuperword [MATH]-gramモデルは，図[REF_ergodic]に示すような，状態数が高々字種の[MATH]乗に制限されたエルゴーディックHMMとなる．

================================================================
[section type  : proposed_method]
[section title : 複合モデル]
================================================================
[i:100, score:0.43698] superword bigram([MATH])モデルに対しては，superword unigram確率によって補間された確率は次式で与えられる．
[i:105, score:0.42866] そこで，長さ制限付きsuperword bigramモデルと一般superword unigramモデルの複合モデルを導入する．
[i:107, score:0.43450] さらに，複合superword bigramモデルを，文字のtrigramモデルによってスムージングすることを考える．

================================================================
[section type  : experiment_result]
[section title : 評価実験]
================================================================
[i:122, score:0.41297] 長さ制限の効果を見るため，superword unigramモデルについて最大長を変化させてパープレキシティを求めた．
[i:145, score:0.43781] 長さ制限付きsuperword bigramモデルと一般superword unigramモデルを融合させることで，若干の性能向上が見られた．
[i:150, score:0.44761] superwordに基づいたモデル単独では訓練テキストに対して過学習する傾向があり，未知テキストに対して脆弱な側面があるが，未知テキストに対して頑健な文字trigramモデルとの融合によりそれが克服できることを意味する．

================================================================
[section type  : conclusion]
[section title : あとがき]
================================================================
[i:154, score:0.47737] 評価実験の結果，長さ制限を施したsuperword bigramモデルを文字trigramモデルと組み合わせて頑健性を向上させたモデルの性能が高く，形態素解析に基づく手法，および高頻度文字列抽出による方法を超える能力が得られた．
[i:155, score:0.39499] superwordに基づく言語モデルは，可搬性に優れた強力なものであるが，欠点として訓練テキストに比べモデルの規模が非常に大きいことが挙げられる．
[i:160, score:0.41153] 今回構築した長さ3のsuperword bigram確率テーブルは約170Mbyteの大きさのファイルとなり，一般superword unigram確率テーブルの約10倍である．

