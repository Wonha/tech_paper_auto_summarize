 これらの手法に対して，伊藤ら\cite{aito96}は統計的な基準によって文
 \mbox{字列の集合を選}定し，その文字列に分割されたテキストを使って$n$-gramを学
 \mbox{習する方法を提案している．文字}列を選定する基準としては，単純な頻度，お
 よび語彙の自動獲得のために提案されている正規\break
 化頻度\cite{nakawatase95}の高い
 ものから選ぶ方式が\mbox{有効であったとされる．この方法は，形態素解}析を必要と
 しない点で優れている．しかし，抽出すべき文字列の最適な個数を見出す方法
 については述べられていない．また，用いられている基準と言語モデルの能力
 との理論的関係は浅く，最良の分割方法である保証はない．さらに，この手法
 ではテキストが明示的に分割される．このため，接辞を伴った語や複合語など
 の長い文字列が抽出された場合，その文字列を構成するもっと短い語は出現し
 なかったのと同様な扱いを受けることになる．有限のテキストから汎化性の高
 い言語モデルを構築したい場合に，このような明示的な分割が最良の結果を与
 えるとは限らない．

 本論文では，高い曖昧性削減能力を持つ新しい言語モデルを提案する．このモ
 デルは，superwordと呼ぶ文字列の集合の上の$n$-gramモデルとして定義され
 る．superword は訓練テキスト中の文字列の再現性のみに基づいて定義される
 概念であり，与えられた訓練テキストに対して一意に定まる．具体的な確率分
 布は，訓練テキストからForward-Backwardアルゴリズムによって求める．訓練
 テキストを明示的に分割せぬまま学習を行うため，長い文字列中の部分文字列
 を「再利用」することが可能となり，少量の訓練テキストでも効率の良いモデ
 ル化が期待できる．本論文ではまた，いくつかのモデルの融合による汎化性の
 向上についても検討する．

 実時間性が要求される大語彙連続音声認識システムにおいては，緩い言語モデ
 ルを用いて\mbox{可能性をしぼり込んだ後，詳細な言語モデルによって最終出力を導}
 く２パス処理が一般的である．本論文で提案するような字面の適格性を与える
 言語モデルは，ディクテーションシステムの第２パス，すなわち後処理用の言
 語モデルとして有用であるものと考えられる．また，文字$n$-gramを用いた認
 識手法\cite{yamada94}を本手法に応用することも可能である．
 \section{superwordモデルの定式化}
 単語\cite{mori96a}や文字列の$n$-gram\cite{aito96}では与え
 られた系列を単語ないし文字列に分割するやり方が一意に決まらないため，こ
 れらのモデルは直前の\(n-1\)個の単語や文字列を状態とする，隠れマルコフ
 モデルの一種と考えられる．単語や文字列の集合は，語彙知識として人手で与
 えられるか，あるいは経験的な規則に基づいて訓練テキストから抽出されるも
 のである．ここで定義するsuperwordとはこれら単語や文字列を一般化したも
 のであるが，それらと対照的なのは，訓練テキスト中の任意の文字列を含み得
 る点である．ただし，言語モデルとして意味を持つために必要最小限のヒュー
 リスティクスは導入せねばならない．そこで，次の条件を満たす文字列を
 superwordと定義する．
 \begin{itemize}
 \item 訓練テキスト中に最低2回出現する
 \end{itemize}
 または
 \begin{itemize}
 \item 長さ1の文字列である
 \end{itemize}
 訓練テキストにおける再現性の仮定は，ある文字列が何らかの言語的な
 まとまりを成すか否かに対する基準となるものであり，そのような基準として
 考え得る制約の中でもっとも緩い条件\break
 として与えてある．すなわち，ある文字
 列が訓練テキスト中で1回しか出現しない，または1回\break
 も出現しないならば，そ
 の文字列が何らかのまとまりを成すだろうという証拠は，他に人間が知識とし
 て与えない限り得られない．
score of this paragraph is 3
