あとがき
本論文では，superwordの概念に基づいた新しい言語モデルを提案した．このモ
デルは従来の$n$-gram の枠組を包含したより一般的なものであり，コーパス
以外の知識に全く依存しない．また，本論文で導入した長さ制限モデルとスムー
ジング手法により，現実的なコーパスの量の範囲でモデルの学習が可能となっ
た．評価実験の結果，長さ制限を施したsuperword bigramモデルを文字
trigramモデルと組み合わせて頑健性を向上させたモデルの性能が高く，形態
素解析\break
に基づく手法，および高頻度文字列抽出による方法を超える能力が得ら
れた．

superwordに基づく言語モデルは，可搬性に優れた強力なものであるが，欠点
として訓練テキストに比べモデルの規模が非常に大きいことが挙げられる．
superword unigramモデルのパラメータ数はsuperword集合の大きさにほぼ比例
する．通常の$n$-gramではモデルのサイズの上\break
界がコーパスの量に対して線形
のオーダーで与えられるのに対し，superwordの場合にはそれよりも大きくな
る可能性がある．これはsuperwordを可能な限り一般的に定義したためであり，
特に大規模なコーパスを用いてモデルを学習する場合には，再現性の仮定を見
直す必要があることが考えられる．

また，superword bigramモデルは長さ制限を加えた場合でも非常に大きくなる．
今回構築した長さ3のsuperword bigram確率テーブルは約170Mbyteの大きさの
ファイルとなり，一般superword unigram確率テーブルの約10倍である．これ
は，与えられたテキストのsuperwordによる解析結果が極めて曖昧性が大きい
ものであることが原因である．

モデルのサイズを小さくし，実際のパターン認識システムで利用できるように
するためには，モデルの最適化が必要である．すなわち，学習の過程で非常に
小さな確率を付与された状態遷移のアークは刈り取る，あるいは外から遷移し
てくる確率が十分小さな状態は削除する，などである．しかし，この種の枝刈
りは，訓練サンプルに特化する危険がある．今後はパープレキシティを上げる
ことなくモデルをコンパクトにするための枝刈り手法の開発が課題である．

\vspace{-3mm}
\bibliographystyle{jnlpbbl_old}
\bibliography{v06n2_02}

\begin{biography}
\biotitle{略歴}
\bioauthor{森 大毅}{
1993年東北大学工学部通信工学科卒業．1998年同大大学院博士後期課程修了．
博士(工学)．同年，同大大学院工学研究科助手．
文字認識，音声認識，自然言語処理の研究に従事．
電子情報通信学会，情報処理学会各会員．}
\bioauthor{阿曽 弘具}{
1974年東北大学大学院電気及通信工学専攻博士課程修了．
現在，同\break
大大学院工学研究科教授．
並列処理，文書認識，音声認識，神経回路網などの研究に従事．
平成3年度電子情報通信学会業績賞受賞．
工学博士．
}
\bioauthor{牧野 正三}{
1947年1月生まれ．1974年東北大学大学院工学研究科博士課程修了．
工学博士．現在東北大学大型計算機センター及び東北大学大学院情報科学研究科
計算機ネットワーク論講座教授．音声認識・理解，画像処理・理解，対話システム，
自然言語処理の研究に従事．}

\bioreceived{受付}
\bioaccepted{採録}

\end{biography}

