提案した言語モデルの能力を，文字を単位としたパープレキシティによって評価する．
パープレキシティは，式([REF_forward])において評価用テキストを[MATH]として次式で求められる．
ただし，[MATH]は評価用テキストの全字数である．
長さ1のsuperwordに対しては，確率が設定した底値を下回る場合には底上げした．
対象タスクは朝日新聞「社説」とした．
実験に用いたテキストの量を表[REF_tab4-1]に示す．
表中，held-outとは式([REF_limited]),式([REF_composite]),式([REF_charint])の重み係数を求めるために用いたテキストである．
各々のテキストは，共通部分を持たない．
長さ制限の効果を見るため，superword unigramモデルについて最大長を変化させてパープレキシティを求めた．
その結果を図[REF_unigram]に示す．
この結果から，長いsuperwordを許してもパープレキシティは上がらないことがわかる．
これは，superwordの再現性の条件が適当であったことを示す．
以下の実験では，[MATH]の場合を一般superword unigramモデルとして扱う．
表[REF_tab2]に，提案したモデルおよび従来のモデルのパープレキシティを示す．
上から4項目までがsuperwordに基づくモデルである．
bigramとあるのは式([REF_limited])の長さ制限付きモデルである．
ここでは最大長を3とした．
一般unigram+bigramとあるのは式([REF_composite])の複合モデル，一般unigram+bigram+文字とあるのはさらに文字trigramで補間した式([REF_charint])のモデルである．
その場合の式([REF_charmodel])の分布関数としては，指数分布を仮定した．
表[REF_tab2]の残りの4項目は比較のために示してある．
単語trigramは，訓練テキストをあらかじめ形態素解析システムJUMAN[CITE]により分割して求めたものであり，削除補間法によりスムージングしたものである．
文字+単語trigramは，さらに文字のtrigramでスムージングしたもので，式([REF_charmodel])と同様の式を用いている．
文字列trigramは，訓練テキストに伊藤らの実験[CITE]で最も有効であった左最長一致による高頻度文字列への分割法を適用し，さらに文字の trigramでスムージングしたものである．
抽出文字列数は約4000から12000まで変化させ，パープレキシティが極小となった約6000個を用いた時の値を示してある．
スムージングのためのheld-outデータにはsuperwordモデルと同じものを用いている．
この結果から，次のことがわかる．
まず，superword unigramモデルの性能が良くない．
図[REF_unigram] の結果をも考慮すると，これはsuperwordの長さの問題ではなく，unigramでは語と語の連接関係が本質的に表現できないものと考えられる．
これはATISデータベースの上でのmultigramの評価[CITE]といくぶん矛盾する結果であるが，伊藤ら[CITE]も同様の結果を導いている．
長さ制限付きsuperword bigramモデルの導入によって，性能の向上が見られた．
しかし，まだその性能は文字trigramモデルに及ばない．
長さ制限付きsuperword bigramモデルと一般superword unigramモデルを融合させることで，若干の性能向上が見られた．
これは，長いsuperwordは単独ではあまり性能に貢献しないが，語と語の連接関係だけでは表現しきれない部分を補う効果を持っているものと考えることができる．
語と語の関係に関する知識と語彙知識とを独立に表現する枠組は，形態素解析の原理と類似している．
さらに，文字trigramモデルでスムージングすることにより，大きく性能が向上した．
その結果，形態素解析を用いたモデルを超える性能が得られた．
superwordに基づいたモデル単独では訓練テキストに対して過学習する傾向があり，未知テキストに対して脆弱な側面があるが，未知テキストに対して頑健な文字trigramモデルとの融合によりそれが克服できることを意味する．
