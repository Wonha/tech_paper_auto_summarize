2000年以降の自然言語処理(NLP)の発展の一翼を担ったのはWorld Wide Web（以降，Webとする）である．
Webを大規模テキストコーパスと見なし，そこから知識や統計量を抽出することで，形態素解析[CITE]，構文解析[CITE]，固有表現抽出[CITE]，述語項構造解析[CITE]，機械翻訳[CITE]など，様々なタスクで精度の向上が報告されている．
これらは，WebがNLPを高度化した事例と言える．
同時に，誰もが発信できるメディアという特性を活かし，Webならではの新しい研究分野も形成された．
評判情報抽出[CITE]がその代表例である．
さらに，近年では，TwitterやFacebookなどのソーシャルメディアが爆発的に普及したことで，自然言語処理技術をWebデータに応用し，人間や社会をWebを通して「知ろう」とする試みにも関心が集まっている．
ソーシャルメディアのデータには，(1)大規模，(2)即時性，(3)個人の経験や主観に基づく情報など，これまでの言語データには見られなかった特徴がある．
例えば，「熱が出たので病院で検査をしてもらったらインフルエンザA型だった」という投稿から，この投稿時点（即時性）で発言者は「インフルエンザに罹った」という個人の経験を抽出し，大規模な投稿の中からこのような情報を集約できれば，インフルエンザの流行状況を調べることができる．
このように，NLPでWeb上の情報をセンシングするという研究は，地震検知[CITE]，疾病サーベイランス[CITE]を初めとして，選挙結果予測，株価予測など応用領域が広がっている．
大規模なウェブデータに対して自然言語処理技術を適用し，社会の動向を迅速かつ大規模に把握しようという取り組みは，対象とするデータの性質に強く依拠する．
そのため，より一般的な他の自然言語処理課題に転用できる知見や要素技術を抽出することが難しい．
そこで，Project Next NLPではNLPのWeb応用タスク(WebNLP)を立ち上げ，次のゴールの達成に向けて研究・議論を行った．
ソーシャルメディア上のテキストの蓄積を自然言語処理の方法論で分析し，人々の行動，意見，感情，状況を把握しようとするとき，現状の自然言語処理技術が抱えている問題を認識すること
応用事例（例えば疾患状況把握）の誤り事例の分析から，自然言語処理で解くべき一般的な（複数の応用事例にまたがって適用できる）課題を整理すること．
ある応用事例の解析精度を向上させるには，その応用における個別の事例・言語現象に対応することが近道かもしれない．
しかし，本研究では複数の応用事例に適用できる課題を見出し，その課題を新しいタスクとして切り出すことで，ソーシャルメディア応用の解析技術のモジュール化を目指す．
(2)で見出した個別の課題に対して，最先端の自然言語処理技術を適用し，新しいタスクに取り組むことで，自然言語処理のソーシャルメディア応用に関する基盤技術を発展させること
本論文では，NLPによるソーシャルリスニングを実用化した事例の1つである，ツイートからインフルエンザや風邪などの疾患・症状を認識するタスク（第[REF_sec:used-corpus]章）を題材に，現状の自然言語処理技術の問題点を検討する．
第[REF_sec:analysis]章では，既存手法の誤りを分析・体系化し，この結果から事実性の解析，状態を保有する主体の判定が重要かつ一般的な課題として切り出せることを説明する．
第[REF_sec:factuality]章では，事実性解析の本タスクへの貢献を実験的に調査し，その分析から事実性解析の課題を議論する．
第[REF_sec:subject]章では，疾患・症状を保有する主体を同定するサブタスクに対する取り組みを紹介する．
さらに第[REF_sec:factandsub]章では，事実性解析と主体解析を組み合わせた結果を示す．
その後，第[REF_sec:relatedworks]章で関連研究を紹介し，最後に，第[REF_sec:conclusion]章で本論文の結論を述べる．
