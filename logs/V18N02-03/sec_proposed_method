前節で説明したように，本稿では単語に基づく指標として，[MATH], [MATH], [MATH],また，文字列に基づく指標として[MATH]と[MATH]を用いた．
以下，各指標を順に説明する．
指標[MATH]は文書の語彙の豊富さを示す指標として1944年に統計学者のYuleによって提案された[CITE]．
今，文書の総単語数（単語数で計測した際の文書長）を[MATH],単語の種類を[MATH]とし，文書中に[MATH]回出現する単語の種類を[MATH]とすると，[MATH]は
で定義される．
ここで[MATH]は[MATH]の値が小さくなりすぎないようにするための係数であり，Yuleは[MATH]とした．
この[MATH]の値に本質的な意味はない．
また，Yuleは文書の生成モデルにつぼモデルと呼ばれる文書中の単語はランダムに出現するものとしたモデルを仮定している．
このモデルにおいて[MATH]が十分大きい時には，この[MATH]の期待値が一定となることを数学的に証明することができる[CITE]．
[MATH]が語彙の豊富さを表すことを以下簡単に説明する．
今，文書中からランダムに単語を一つ選ぶことを考える．
すると式([REF_k])において[MATH]は文書中[MATH]回出現する単語が選択される確率を表す．
よって[MATH]はそのような単語が連続で選択される確率である．
ここで同じ単語が連続で選択される確率が大きい場合は文書の語彙が乏しい場合，逆に確率が小さい場合は語彙が豊富な場合と見なすことができる．
式([REF_k])より前者の場合は[MATH]の値は大きくなり，後者の場合は[MATH]の値は小さくなることがわかる．
このように[MATH]は同じ単語が連続で出現する確率に基づいた語彙の豊富さを表す指標である．
文書中に現れる各単語の出現頻度はZipfの法則に従うということが経験的に知られている[CITE]．
[MATH]はこのZipfの法則に基づいた指標である．
今，文書の総単語数（単語数で計測した際の文書長）を[MATH],単語の種類を[MATH]とし，[MATH]を文書中に出現する単語の回数に関して降順に並べた時の順位を表す変数とする．
ここで順位が[MATH]である単語が文書中に出現する回数を[MATH]とすると，[MATH]と[MATH]の間に
というべき乗則の関係がおおよそ成り立つ．
また式([REF_eq zip])において[MATH]とおくと文書中に[MATH]回出現する単語の種類[MATH]が
と表現されることが導かれる．
Orlovらは1983年にZipfの法則を拡張して，総単語数が[MATH]である文書の単語の種類[MATH]の期待値[MATH]が一つのパラメータ[MATH]を用いて
と表すことができることを示した[CITE]．
ここで[MATH]は文書中に最も多く出現する単語の相対頻度であり，文書ごとにほぼ一定の定数と見なされる．
[MATH]は，文書が与えられた際に式([REF_eq vmn])の関係が最もよく当てはまる単語数である．
また式([REF_Z])において[MATH]を固定して考えてみると，[MATH]の値が大きくなるにつれて文書の単語の種類の期待値である[MATH]の値が大きくなるので，指標[MATH]は文書の語彙の豊富さを表す指標だと解釈することができる．
最後に[MATH]の計算方法について述べる．
式([REF_Z])において単語数が[MATH]である時の単語の種類の期待値[MATH]を実際の文書の[MATH]で置き換えると
を得る．
この式は[MATH]について陽に解くことができないので解析的な解を得ることはできない．
したがって[MATH]を求める際には
とおいて[MATH]をニュートン法の反復解法を用いて数値的に解く．
指標[MATH]は，[MATH]が複雑系の観点からの指標であることを受け，本研究で新たに試みた関連指標であり，文書の単語のネットワーク構造に着目したものである．
まず文書から構成される無向グラフ[MATH]について説明する．
文書中の単語の種類を[MATH]とすると，[MATH]は[MATH] [MATH]で定義される各単語を頂点とする頂点集合である．
また，[MATH]は[MATH]で定義される単語間のつながりを表す枝集合であり，2つの単語[MATH]と[MATH]が連続して現れる場合に枝が存在する．
つまりここで考えているネットワークは文書中の各単語を頂点として連続して現れる単語間に枝を張ったネットワークである．
本稿では文書の単語から構成されるネットワークとして上記のようなものを考える．
これ以外にも単語ネットワークの構築方法には構文解析結果を用いるものや，文書の単語間の共起関係に基づいたネットワークなど複数考えることができる．
しかし，単語から構成されるどのようなネットワークを考えたとしても，本稿の目的である文書の複雑さといった文書の大域的な特性を考えた場合には，いずれのネットワークにおいても類似した性質が現れると考えられる．
実際にいくつかを実験的に試してみたが，文書量に対して一定となるかどうかの観点では，大勢に影響はなかった．
ゆえに本稿では，文書の単語から構成されるネットワークとして上記を扱う．
さて，ここで得られたネットワークの各頂点の次数分布に着目する．
グラフにおいて頂点の次数が[MATH]である確率を[MATH]とおく．
図[REF_fig:deg]は英語とJavaの場合の次数分布の両対数をとった図である．
図の横軸は次数[MATH]の対数であり，縦軸は[MATH]の対数である．
いずれもある次数まではほぼ直線になっている．
このことから単語のネットワークの次数分布はある次数まではベキ分布に従っていると考えられる．
このような性質はスケールフリー性 [CITE]と呼ばれ，現実のさまざまな複雑系ネットワークで現れる性質である．
ベキ分布は
という形で表される．
ここで[MATH]は正規化定数であり，[MATH]の条件から定まる．
ここで式([REF_beki])の両辺において対数をとれば
となりベキ分布は両対数グラフにおいて直線になることがわかる．
今，式([REF_log])の両対数グラフ上での傾き[MATH]に着目し，指標[MATH]を
で定義する．
この指標が一定になるかということに関して特に理論的な背景はないが，[MATH]は前節までで紹介した[MATH]と同様に言語のべき乗則に関する指標で，言語の大域的特性を示すものである以上，文書ごとに文長に依らず一定となることが期待される．
最後に[MATH]の計算方法について述べる．
本稿で[MATH]を求める際には，まず実際に文書の単語から構成されるネットワークをつくり，ネットワークの各頂点の次数を調べ，図[REF_fig:deg]のような次数分布を得る．
次に，この次数分布の傾きである[MATH]を得る際には，次数が2から[MATH]を満たす最小の次数[MATH]までの範囲で，最小二乗法を用いて傾きを推定した．
これは次数が1の場合と次数がある大きさを超えた範囲では，いずれの文書から構成されるネットワークにおいても，図[REF_fig:deg]のように次数分布がべき分布から大きく外れているためである．
[MATH]は文字列の繰り返しの量を表す指標として近年Golcherによって提案された指標であり，接尾辞木の構造を利用したものである[CITE]．
接尾辞木とは，文字列が与えられた時の接尾部を木構造で表したデータ構造であり，接尾部に対するパトリシア木である[CITE]．
以下与えられた文字列を[MATH]，その文字列の長さを[MATH], [MATH]の[MATH]番目の文字を[MATH], [MATH]の[MATH]番目から[MATH]番目までの部分文字列を[MATH] [MATH]をとする．
文字列[MATH]の接尾辞木[MATH]は以下のように定義される[CITE]．
根から葉へと向かう有向木[MATH]が次の条件を満たす時，[MATH]は[MATH]の接尾辞木であるという．
1から[MATH]までの整数がラベル付けされたちょうど[MATH]個の葉が存在する．
内部節点は少なくとも2つの子をもち，各枝には[MATH]に含まれる空ではない文字列が対応する．
同じ節点からの枝のラベルは必ず異なる文字から始まる．
すべての葉[MATH]に対して根から葉[MATH]までの経路のラベルは[MATH]となる．
Golcherの用いる接尾木辞は，[MATH]に含まれない文字を終端記号として文字列の最後につけて接尾辞木を構築する．
たとえば，図[REF_fig:cocoa]は文字列`cocoa'の接尾辞木である．
これを用いて，[MATH]の定義，説明を行う．
今，与えられた文字列[MATH]の文字数を[MATH], [MATH]の接尾辞木における内部節点の数を[MATH]とすると指標[MATH]は
で定義される．
長さ[MATH]の接尾辞木は[MATH]個の葉を持つことから，内部節点の数は最大でも[MATH]個である．
よって[MATH]であるから[MATH]の値の範囲は[MATH]となる．
ここでUkkonenのアルゴリズムによると，接尾辞木の内部接点はこれまでに現れていない共通部分が新たに現れる場合に増える．
したがって[MATH]はある種の文字列の繰り返しの量を表していると考えることができる．
最後に[MATH]の計算方法について述べる．
式([REF_eq:v])で定義される[MATH]の値を求めるためには接尾辞木の内部節点の数を求めればよい．
最も素朴な方法としては，直接接尾辞木を構成することによって求める方法が考えられる．
しかし，一般に接尾辞木の構成に必要な空間領域は，入力の文書の数十倍となり，大規模な文書を扱う場合には直接接尾辞木を構成する方法は現実的ではない．
本稿では，より効率的なデータ構造である接尾辞配列と高さ配列を用いて，接尾辞木の擬似巡回を行うことによって内部節点の数を求めた．
アルゴリズムは[CITE]に詳しい．
ここで紹介するエントロピー[MATH]は情報理論の分野においてShannonによって1948年に導入された[CITE]．
文書を構成する有限個のアルファベットの集合を[MATH]とし，[MATH]を[MATH]上の確率変数とする．
この時，各アルファベット[MATH]の文書における出現確率を[MATH]とおくとエントロピー[MATH]は，
で定義される．
文書のエントロピーを求めるためには式([REF_entropy])より各アルファベット[MATH]に対し，その出現確率[MATH]を知る必要があるが，文書から得られる出現確率はあくまで真の出現確率の近似であり，文書から直接求めることはできない．
言語処理では文章のエントロピーを求める方法についてはさまざまな試みがある[CITE]．
本稿では，エントロピーの値の推定方法として，収束性が証明されている一つの方法であることから，Farachらによる手法を用いた[CITE]．
今与えられた文書を一つの文字列と見なしてこれを[MATH]とし，その長さを[MATH], [MATH]の[MATH]番目から[MATH]番目までの部分文字列を[MATH] [MATH]とする．
次に[MATH]の各位置[MATH] [MATH]に対してそれより以前の最大マッチング[MATH]を以下のように定義する．
つまり[MATH]は[MATH]の[MATH]番目から始まる文字列と，1番目から[MATH]番目までの文字列との最大共通部分文字列長である．
そしてこれら[MATH]の平均値[MATH]を，
とする．
この時Farachらのエントロピーの推定値[MATH]は，
で定義される．
今，真のエントロピーの値を[MATH]とすると，この手法によって得られる推定値[MATH]は，[MATH]の時に[MATH]となることが数学的に示されている．
前節で説明したように，本稿では単語に基づく指標として，[MATH], [MATH], [MATH],また，文字列に基づく指標として[MATH]と[MATH]を用いた．
以下，各指標を順に説明する．
指標[MATH]は文書の語彙の豊富さを示す指標として1944年に統計学者のYuleによって提案された[CITE]．
今，文書の総単語数（単語数で計測した際の文書長）を[MATH],単語の種類を[MATH]とし，文書中に[MATH]回出現する単語の種類を[MATH]とすると，[MATH]は
で定義される．
ここで[MATH]は[MATH]の値が小さくなりすぎないようにするための係数であり，Yuleは[MATH]とした．
この[MATH]の値に本質的な意味はない．
また，Yuleは文書の生成モデルにつぼモデルと呼ばれる文書中の単語はランダムに出現するものとしたモデルを仮定している．
このモデルにおいて[MATH]が十分大きい時には，この[MATH]の期待値が一定となることを数学的に証明することができる[CITE]．
[MATH]が語彙の豊富さを表すことを以下簡単に説明する．
今，文書中からランダムに単語を一つ選ぶことを考える．
すると式([REF_k])において[MATH]は文書中[MATH]回出現する単語が選択される確率を表す．
よって[MATH]はそのような単語が連続で選択される確率である．
ここで同じ単語が連続で選択される確率が大きい場合は文書の語彙が乏しい場合，逆に確率が小さい場合は語彙が豊富な場合と見なすことができる．
式([REF_k])より前者の場合は[MATH]の値は大きくなり，後者の場合は[MATH]の値は小さくなることがわかる．
このように[MATH]は同じ単語が連続で出現する確率に基づいた語彙の豊富さを表す指標である．
文書中に現れる各単語の出現頻度はZipfの法則に従うということが経験的に知られている[CITE]．
[MATH]はこのZipfの法則に基づいた指標である．
今，文書の総単語数（単語数で計測した際の文書長）を[MATH],単語の種類を[MATH]とし，[MATH]を文書中に出現する単語の回数に関して降順に並べた時の順位を表す変数とする．
ここで順位が[MATH]である単語が文書中に出現する回数を[MATH]とすると，[MATH]と[MATH]の間に
というべき乗則の関係がおおよそ成り立つ．
また式([REF_eq zip])において[MATH]とおくと文書中に[MATH]回出現する単語の種類[MATH]が
と表現されることが導かれる．
Orlovらは1983年にZipfの法則を拡張して，総単語数が[MATH]である文書の単語の種類[MATH]の期待値[MATH]が一つのパラメータ[MATH]を用いて
と表すことができることを示した[CITE]．
ここで[MATH]は文書中に最も多く出現する単語の相対頻度であり，文書ごとにほぼ一定の定数と見なされる．
[MATH]は，文書が与えられた際に式([REF_eq vmn])の関係が最もよく当てはまる単語数である．
また式([REF_Z])において[MATH]を固定して考えてみると，[MATH]の値が大きくなるにつれて文書の単語の種類の期待値である[MATH]の値が大きくなるので，指標[MATH]は文書の語彙の豊富さを表す指標だと解釈することができる．
最後に[MATH]の計算方法について述べる．
式([REF_Z])において単語数が[MATH]である時の単語の種類の期待値[MATH]を実際の文書の[MATH]で置き換えると
を得る．
この式は[MATH]について陽に解くことができないので解析的な解を得ることはできない．
したがって[MATH]を求める際には
とおいて[MATH]をニュートン法の反復解法を用いて数値的に解く．
指標[MATH]は，[MATH]が複雑系の観点からの指標であることを受け，本研究で新たに試みた関連指標であり，文書の単語のネットワーク構造に着目したものである．
まず文書から構成される無向グラフ[MATH]について説明する．
文書中の単語の種類を[MATH]とすると，[MATH]は[MATH] [MATH]で定義される各単語を頂点とする頂点集合である．
また，[MATH]は[MATH]で定義される単語間のつながりを表す枝集合であり，2つの単語[MATH]と[MATH]が連続して現れる場合に枝が存在する．
つまりここで考えているネットワークは文書中の各単語を頂点として連続して現れる単語間に枝を張ったネットワークである．
本稿では文書の単語から構成されるネットワークとして上記のようなものを考える．
これ以外にも単語ネットワークの構築方法には構文解析結果を用いるものや，文書の単語間の共起関係に基づいたネットワークなど複数考えることができる．
しかし，単語から構成されるどのようなネットワークを考えたとしても，本稿の目的である文書の複雑さといった文書の大域的な特性を考えた場合には，いずれのネットワークにおいても類似した性質が現れると考えられる．
実際にいくつかを実験的に試してみたが，文書量に対して一定となるかどうかの観点では，大勢に影響はなかった．
ゆえに本稿では，文書の単語から構成されるネットワークとして上記を扱う．
さて，ここで得られたネットワークの各頂点の次数分布に着目する．
グラフにおいて頂点の次数が[MATH]である確率を[MATH]とおく．
図[REF_fig:deg]は英語とJavaの場合の次数分布の両対数をとった図である．
図の横軸は次数[MATH]の対数であり，縦軸は[MATH]の対数である．
いずれもある次数まではほぼ直線になっている．
このことから単語のネットワークの次数分布はある次数まではベキ分布に従っていると考えられる．
このような性質はスケールフリー性 [CITE]と呼ばれ，現実のさまざまな複雑系ネットワークで現れる性質である．
ベキ分布は
という形で表される．
ここで[MATH]は正規化定数であり，[MATH]の条件から定まる．
ここで式([REF_beki])の両辺において対数をとれば
となりベキ分布は両対数グラフにおいて直線になることがわかる．
今，式([REF_log])の両対数グラフ上での傾き[MATH]に着目し，指標[MATH]を
で定義する．
この指標が一定になるかということに関して特に理論的な背景はないが，[MATH]は前節までで紹介した[MATH]と同様に言語のべき乗則に関する指標で，言語の大域的特性を示すものである以上，文書ごとに文長に依らず一定となることが期待される．
最後に[MATH]の計算方法について述べる．
本稿で[MATH]を求める際には，まず実際に文書の単語から構成されるネットワークをつくり，ネットワークの各頂点の次数を調べ，図[REF_fig:deg]のような次数分布を得る．
次に，この次数分布の傾きである[MATH]を得る際には，次数が2から[MATH]を満たす最小の次数[MATH]までの範囲で，最小二乗法を用いて傾きを推定した．
これは次数が1の場合と次数がある大きさを超えた範囲では，いずれの文書から構成されるネットワークにおいても，図[REF_fig:deg]のように次数分布がべき分布から大きく外れているためである．
[MATH]は文字列の繰り返しの量を表す指標として近年Golcherによって提案された指標であり，接尾辞木の構造を利用したものである[CITE]．
接尾辞木とは，文字列が与えられた時の接尾部を木構造で表したデータ構造であり，接尾部に対するパトリシア木である[CITE]．
以下与えられた文字列を[MATH]，その文字列の長さを[MATH], [MATH]の[MATH]番目の文字を[MATH], [MATH]の[MATH]番目から[MATH]番目までの部分文字列を[MATH] [MATH]をとする．
文字列[MATH]の接尾辞木[MATH]は以下のように定義される[CITE]．
根から葉へと向かう有向木[MATH]が次の条件を満たす時，[MATH]は[MATH]の接尾辞木であるという．
1から[MATH]までの整数がラベル付けされたちょうど[MATH]個の葉が存在する．
内部節点は少なくとも2つの子をもち，各枝には[MATH]に含まれる空ではない文字列が対応する．
同じ節点からの枝のラベルは必ず異なる文字から始まる．
すべての葉[MATH]に対して根から葉[MATH]までの経路のラベルは[MATH]となる．
Golcherの用いる接尾木辞は，[MATH]に含まれない文字を終端記号として文字列の最後につけて接尾辞木を構築する．
たとえば，図[REF_fig:cocoa]は文字列`cocoa'の接尾辞木である．
これを用いて，[MATH]の定義，説明を行う．
今，与えられた文字列[MATH]の文字数を[MATH], [MATH]の接尾辞木における内部節点の数を[MATH]とすると指標[MATH]は
で定義される．
長さ[MATH]の接尾辞木は[MATH]個の葉を持つことから，内部節点の数は最大でも[MATH]個である．
よって[MATH]であるから[MATH]の値の範囲は[MATH]となる．
ここでUkkonenのアルゴリズムによると，接尾辞木の内部接点はこれまでに現れていない共通部分が新たに現れる場合に増える．
したがって[MATH]はある種の文字列の繰り返しの量を表していると考えることができる．
最後に[MATH]の計算方法について述べる．
式([REF_eq:v])で定義される[MATH]の値を求めるためには接尾辞木の内部節点の数を求めればよい．
最も素朴な方法としては，直接接尾辞木を構成することによって求める方法が考えられる．
しかし，一般に接尾辞木の構成に必要な空間領域は，入力の文書の数十倍となり，大規模な文書を扱う場合には直接接尾辞木を構成する方法は現実的ではない．
本稿では，より効率的なデータ構造である接尾辞配列と高さ配列を用いて，接尾辞木の擬似巡回を行うことによって内部節点の数を求めた．
アルゴリズムは[CITE]に詳しい．
ここで紹介するエントロピー[MATH]は情報理論の分野においてShannonによって1948年に導入された[CITE]．
文書を構成する有限個のアルファベットの集合を[MATH]とし，[MATH]を[MATH]上の確率変数とする．
この時，各アルファベット[MATH]の文書における出現確率を[MATH]とおくとエントロピー[MATH]は，
で定義される．
文書のエントロピーを求めるためには式([REF_entropy])より各アルファベット[MATH]に対し，その出現確率[MATH]を知る必要があるが，文書から得られる出現確率はあくまで真の出現確率の近似であり，文書から直接求めることはできない．
言語処理では文章のエントロピーを求める方法についてはさまざまな試みがある[CITE]．
本稿では，エントロピーの値の推定方法として，収束性が証明されている一つの方法であることから，Farachらによる手法を用いた[CITE]．
今与えられた文書を一つの文字列と見なしてこれを[MATH]とし，その長さを[MATH], [MATH]の[MATH]番目から[MATH]番目までの部分文字列を[MATH] [MATH]とする．
次に[MATH]の各位置[MATH] [MATH]に対してそれより以前の最大マッチング[MATH]を以下のように定義する．
つまり[MATH]は[MATH]の[MATH]番目から始まる文字列と，1番目から[MATH]番目までの文字列との最大共通部分文字列長である．
そしてこれら[MATH]の平均値[MATH]を，
とする．
この時Farachらのエントロピーの推定値[MATH]は，
で定義される．
今，真のエントロピーの値を[MATH]とすると，この手法によって得られる推定値[MATH]は，[MATH]の時に[MATH]となることが数学的に示されている．
