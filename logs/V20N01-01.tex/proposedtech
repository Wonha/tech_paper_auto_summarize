\documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\usepackage{multirow}
\usepackage{url}
\usepackage{algorithm}
\usepackage{algorithmic}

\def\sec#1{}
\def\eq#1{}
\def\fig#1{}
\def\tab#1{}

\def\algo#1{}





\Volume{20}
\Number{1}
\Month{March}
\Year{2013}

\received{2012}{8}{3}
\revised{2012}{10}{26}
\accepted{2012}{11}{28}

\setcounter{page}{3}

\jtitle{意見集約における相対的特徴を考慮した評価視点の構造化}
\jauthor{
乾　　孝司\affiref{Author} \and 板谷　悠人\affiref{Author} \and 山本　幹雄\affiref{Author} \and 新里　圭司\affiref{Author_2} \and \\
	平手　勇宇\affiref{Author_2} \and 山田　　薫\affiref{Author_2}}
\jabstract{
本論文では，レビュー集合から多数の評価視点が得られる状
況において，評価対象間の相対的特徴を考慮した重要度（ス
コア）に従って評価視点をランキングする課題について述
べる．また，レビューはその数だけ書き手が存在することか
ら評価視点の異表記が生じやすく，これがランキングに悪影
響を与える．本論文では，評価視点に対してクラスタリング
を適用することで異表記問題へ対応する手法を提案する．
評価実験を通して，提案したスコア関数がランキング性能の
向上に有効であること，およびクラスタリングに基づくラン
キング補正手法によって，平均適合率（MAP指標）が向上する
ことを確認した．
}
\jkeywords{評判分析，評価視点，属性，対数尤度比，異表記}

\etitle{Structuring Opinions by Relative Characteristics \\ for User-Opinion Aggregation}
\eauthor{
Takashi Inui\affiref{Author} \and Yuto Itaya\affiref{Author} \and Mikio Yamamoto\affiref{Author}
	\and Keiji Shinzato\affiref{Author_2} \and \\
	Yu Hirate\affiref{Author_2} \and Kaoru Yamada\affiref{Author_2}} 
\eabstract{
We propose a scoring function for aspect ranking that
facilitates user-opinion aggregation.  The function
uses the log-likelihood ratio to capture relative
characteristics between opinions.  Review documents
contain many variant expressions because they are
written by different web users.  We also propose a
re-ranking method that identifies variant expressions
having the same meaning by using several clustering
techniques.  The experimental results indicate that
the proposed scoring function and the re-ranking
method are more effective than baseline methods.
}
\ekeywords{sentiment analysis, aspect, log-likelyhood ratio, variant expression}

\headauthor{乾，板谷，山本，新里，平手，山田}
\headtitle{意見集約における相対的特徴を考慮した評価視点の構造化}

\affilabel{Author}{筑波大学システム情報工学研究科コンピュータサイエンス専攻}{Department of Computer Science, Graduate school of SIE, University of Tsukuba}
\affilabel{Author_2}{楽天株式会社}{Rakuten, Inc.}



\begin{document}
\maketitle


\section{提案手法}
\label{sec:uniq_aspect_ranking}


\subsection{評価視点}

提案手法の説明の前に，ここで，評価視点という用語につい
て整理しておく．
本論文における評価視点は，基本的には，Hu ら\cite{hu}や
小林ら\cite{kobayashi,siten}の定義に従っている．後述す
る評価実験では，評価対象が宿泊施設であるので，そのこと
を踏まえると，本論文における評価視点は，
\begin{itemize}
\item 
宿泊施設に対する意見の焦点となる宿泊施設の構成物や属性，
あるいは，宿泊施設への宿泊という経験から生じる宿泊施設
に対する意見の焦点となるもの
\end{itemize}
であると言い表せる．例えば，宿泊施設の立地情報（「駅
    前」，「海沿い」）や施設が提供する設備に関する情報
（「風呂」，「加湿器」），施設のサービス（「バイキン
    グ」，「接客態度」）等が具体的な評価視点となる．


また，評価視点の表現形式は，単一単語（「バイキング」）
だけでなく，複合語（「朝食バイキング」）や句（「朝食の
    バイキング」）などの場合もある．本研究では以上の形
式は評価視点として認めているが，処理の都合上，以下に示
すように，連体修飾節を伴う場合は修飾部を除外して扱った．
下記例の場合，下線部は評価視点として認めたが，どちらの
例でも「メニューが新しくなった」は評価視点には含めてい
ない．
なお，表現形式の特定は以下のようにおこなった．単語の特
定には形態素解析器
MeCab\footnote{\url{http://mecab.sourceforge.net/}}を使
用した．複合語については，MeCabで解析後，名詞が連続して
いる箇所を複合語として特定している．句については，現在
は「名詞の名詞」というパターンで特定しており，他の形は
想定していない．ただし，上記パターンの名詞は名詞連続に
置換可能とした．
\begin{itemize}
 \item メニューが新しくなった\underline{朝食バイキング}が良かった．
 \item メニューが新しくなった\underline{朝食のバイキング}が良かった．
\end{itemize}



\subsection{評価視点ランキング}
\label{sec:llr}

提案手法について述べる．まず，使用する記号，および，評
価視点のランキング課題を以下のように定義する．
評価対象の集合を$\mathcal{O} =\{o_1, o_2,...,o_{|\mathcal{O}|}\}$とする．
全ての評価対象に対する全てのレビューの集合を
$\mathcal{R}$とし，
$\mathcal{R}$の要素であるレビューの中に書かれた評価視点(token) 
の系列を$\mathcal{V}=\langle v_1,v_2,...,v_n\rangle$，
$\mathcal{V}$の異なり要素 (type) の集合を
$\mathcal{U}=\{u_1,u_2,...,u_m\}$ ($m \le n$) とする．
例えば，以下のような，それぞれ 1 文と 2 文からなる短
い 2 つのレビューを要素とする集合$\mathcal{R}$があり，各
文の下線部が評価視点であったとすると，系列
$\mathcal{V}$と集合$\mathcal{U}$は次のようになる．
\begin{itemize}
 \item $\mathcal{R} = \big\{\text{``このホテルは\underline{\mbox{朝食$_{1}$}}と\underline{風呂}が良い．'', ``\underline{\mbox{朝食$_{2}$}}が美味しい．また来たいです．''}\big\}$
 \item $\mathcal{V}= \bigl\langle \text{朝食$_{1}$, 風呂, 朝食$_{2}$}\bigr\rangle $
 \item $\mathcal{U}= \big\{\text{朝食, 風呂}\big\}$
\end{itemize}
この時，ある評価対象$o_k$に関して評価視点をランキングす
るアルゴリズムを次の\algo{alg1}とする．このアルゴリズム
が示している通り，$\mathcal{U}$の要素$u_j$がランキング
の対象である．本論文では曖昧性を排除するために，以降，
$u_j$のことを単に評価視点と呼び，評価視点$u_j$ が
$\mathcal{R}$内で出現したものを評価視点トークンと呼ぶ．

\begin{algorithm}[h]
\caption{評価視点ランキング}         
\label{algo:alg1}
\begin{algorithmic}
\STATE{INPUT ~~~$o_k \in \mathcal{O}$：評価対象\\
~~~~~~~~~~~~~~~$\mathcal{U}$：評価視点集合}
\end{algorithmic}
\begin{algorithmic}[1]
\FOR{$u_j \in \cal{U}$}
\STATE $s[u_j] = score(o_k, u_j)$
\ENDFOR
\RETURN $\mathcal{U}の各要素u_jをs[u_j]の降順に整列$
\end{algorithmic}
\end{algorithm}

上記の\algo{alg1}で自明でない部分は，評価対象$o_k$ にお
ける評価視点$u_j$の重要度を決定するスコア関数
$\mathit{score}(o_k, u_j)$のみである．本研究では，このスコア関数
として，以下のような対数尤度比 (\textit{Log-Likelihood Ratio，LLR}) に基づく尺度を提案する．
これは内山ら\cite{uchiyama}が特定分野における単語の特徴
度を測る尺度として提案したものを評価視点ランキング課題
に適用したものである．以下，内山ら\cite{uchiyama}を参考
にしながら，上記尺度の詳細について述べる．

まず始めに，ある評価対象$o_k$と評価視点$u_j$が与えられ
た際，レビュー中で観測された評価視点トークン$v$に関する
確率変数$W_j$と$T_k$を以下のように定義する：
\begin{align}
W_j & =\begin{cases}
1 & vは評価視点u_jのレビュー内での出現である\\
0 & otherwise
\end{cases}
\label{eq:w}\\
T_k & =\begin{cases}
1 & vが観測されたのは評価対象o_kのレビュー内である\\
0 & otherwise
\end{cases}
\end{align}
ここで，評価視点トークン$v_i$ ($1 \le i \le n$) に対応
する確率変数$W_j$，$T_k$の値をそれぞれ$w^i_j$，$t^i_k$とすると，
$\mathcal{V}$ から次のような確率変数の
値の組みで表された系列$\mathcal{V}_{jk} = \bigl\langle
\langle w^1_j, t^1_k \rangle ,\langle w^2_j, t^2_k
\rangle , ... , \langle w^n_j, t^n_k \rangle
\bigr\rangle$が新たに得られる．
この時，それぞれの評価視点トークンが確率的に独立である
と仮定すると，$\mathcal{V}_{jk}$の生起確率は次式で表される：
\begin{equation}
Pr(\mathcal{V}_{jk})= \prod_{i=1}^{n}Pr(W_j=w^i_j, T_k=t^i_k)
\end{equation}

\begin{table}[b]
\vspace{-1\Cvs}
\caption{トークン集合の集計表}
\input{01table01.txt}
\end{table}

また，各トークンを変数$W_j$，$T_k$の値ごとに出現頻度を集計
\pagebreak
することを考え，各頻度を\tab{kankei}のように，それぞれ
$a$，$b$，$c$，$d$で表すことにする．ここで，$a + b + c
+ d = n$ である．

以上の準備のもと，次の対数尤度比を考える：
{\allowdisplaybreaks
\begin{align}
LLR_0(o_k,u_j) & = \log\frac{Pr(\mathcal{V}_{jk}; H_{dep})}{Pr(\mathcal{V}_{jk}; H_{indep})}
	\nonumber \\
 & = \sum_{i=1}^{n}\log\frac{Pr(W_j=w^{i}_j,T_k=t^{i}_k;H_{\mathit{dep}})}{Pr(W_j=w^{i}_j,T_k=t^{i}_k;H_{\mathit{indep}})}
	\label{eq:llr0}
\end{align}
}
ここで，$H_\mathit{dep}$および$H_\mathit{indep}$は，以下のような，確
率変数に関する仮説である．
\begin{itemize}
 \item $H_\mathit{dep}$: 確率変数$W_j$と$T_k$とは互いに依存している．
 \item $H_\mathit{indep}$: 確率変数$W_j$と$T_k$とは互いに独立である．
\end{itemize}
\eq{llr0}において，$H_\mathit{indep}$の下では，
\[
Pr(W_j=w^i_j, T_k=t^i_k; H_\mathit{indep}) = Pr(W_j=w^i_j)Pr(T_k=t^i_k)
\]
が成り立つ．また，各種の確率は，
\begin{align*}
Pr(W_j=1, T_k=1; H_\mathit{dep}) & = \frac{a}{n} ,\quad 
	Pr(W_j=1, T_k=0; H_\mathit{dep}) =  \frac{b}{n} \\
Pr(W_j=0, T_k=1; H_\mathit{dep}) & = \frac{c}{n} ,\quad 
	Pr(W_j=0, T_k=0; H_{dep}) =  \frac{d}{n} \\
Pr(W_j=1) & = \frac{a+b}{n} , \quad
	Pr(W_j=0) =  \frac{c+d}{n} \\
Pr(T_k=1) & = \frac{a+c}{n} ,\quad 
	Pr(T_k=0) =  \frac{b+d}{n}
\end{align*}
で推定する．

この尺度は，2 つの確率変数$W_j$と$T_k$とが依存している
という条件，および，独立であるという条件の下で，データ
が観測される確率の比の対数を表しており，$W_j$と$T_k$の
依存性が高い程，大きな値をとる．
もし，ある評価視点がどの評価対象にも共通するような一般
的な視点であれば，評価視点トークンは，どの評価対象のレ
ビュー中にも同じように出現すると考えられる．すなわち，
$W_j$と$T_k$とは互いに独立であると考えられ，上記尺度は
小さな値をとる．一方で，ある評価視点が特定の評価対象に
のみ特徴的な出現を示すようであれば，$W_j$と$T_k$とは依
存しており，上記尺度は大きな値をとる．つまり，この尺度
をスコア関数とすることで，特定の評価対象に特徴的な評価
視点に対して大きなスコアを割り振ることができる．

ただし，上記尺度は，ある評価視点が特定の評価対象に対し
て特徴的に言及される場合と特徴的に言及されない場合を区
別できない．そのため，どちらの状況であっても大きな値を
とってしまう．そこで，言及される場合とされない場合を区
別できるよう，実際には以下のように補正して利用する．
\pagebreak
\begin{equation}
LLR(o_k,u_j) = sign(ad - bc)LLR_{0}(o_k,u_j)
\label{eq:finalrank}
\end{equation}
ただし，
\begin{equation}
sign(z) = \begin{cases}
  +1 & z > 0 \\
  -1 & \mathit{otherwise}\\
  \end{cases}
\end{equation}
である．



\section{異表記問題への対応}
\label{sec:cl}


\subsection{異表記問題}
\label{sec:clustering_summary}

レビューではユーザの数だけ書き手が存在しており，同じ概
念が述べられていたとしても，ユーザによって異なる単語が
使われることがしばしばある．
例えば，価格について何かを述べたいときに，あるユーザは
「価格」と表記したが，別ユーザは「料金」や「値段」等，
別の単語を使うことがある．
また，レビューは，評価対象という自明な文脈をもつ文書で
あるため，同じ評価対象のもとでユーザが共有しているであ
ろう情報がしばしば省略表記される傾向があり，
例えば，最寄り駅の「東京駅」を単に「駅」と表記するユー
ザ等，その表記はユーザによってさまざまに変化する．

一般的に，このような異表記の問題や表記揺れの問題（以下，
  単に異表記の問題と呼ぶ）はよく知られているが，評価視
点のランキング課題に対しても悪影響を与えていると考えら
れる．前節で述べた提案尺度では評価視点の出現頻度の情報
を用いているが，異表記が考えられる評価視点については，
異表記の数だけ頻度が分散してカウントされてしまい，その
結果，それらの評価を誤ってしまう．

以下では，この異表記問題の影響を回避する手法について述べ
る．本手法は，評価視点をクラスタリングすることによって，
同じ意味あるいは類似した意味の評価視点をクラスタにまと
め上げ，クラスタ情報に基いてランキングを補正する．手法
は，クラスタ情報をランキングに反映させる方法によって，
事前処理法と事後処理法の 2 つに分かれる
（\fig{clustering}）．
以下ではまず，2 つの手法について述べ，その後，各手法の
中で用いるクラスタリング手法について述べる．



\subsection{事前処理法と事後処理法}

事前処理法（\fig{clustering}の(b)）では，ランキングの前
に評価視点のクラスタリングを実施し，同一の意味あるいは
類似した意味の評価視点をクラスタにまとめ上げる．
そして，同じクラスタとなる視点群をひとつの評価視点であ
るように扱い出現頻度を数えることで対数尤度比を計算し，
ランキングをおこなう．

\begin{figure}[t]
 \begin{center}
 \includegraphics{20-1ia960f1.eps}
 \end{center}
 \caption{ランキングの補正手法の概略}
 \label{fig:clustering}
\end{figure}

具体的には，\sec{llr}で導入した\eq{w}の評価視点トークン
に関する確率変数$W_j$を次の\eq{w2}のように再定義してス
コア関数を計算することで，クラスタ情報をランキングに反
映させる．ただし，下記の式中の$v$と$u_j$は\eq{w}と同様，
評価視点トークンと評価視点をそれぞれ意味する．
\begin{equation}
W_j=\begin{cases}
1 & \text{$v$ は評価視点 $u_j$ のレビュー内での出現である}\\
1 & \text{$v$ は $u_j$ と同じクラスタに属する評価視点のレビュー内での出現である}\\
0 & \mathit{otherwise}
\end{cases}
\label{eq:w2}
\end{equation}


事後処理法（\fig{clustering}の(c)）では，ランキングを先
に行い，その後，クラスタリングによって得られたクラスタ
情報に従ってランキング結果を補正する．
具体的には，ある評価視点$u_j$がクラスタ$C(u_j)$に所属す
る場合を考えると，ランキングに使用するスコア関数
\eq{finalrank}で得られた値に対して，次の
\eq{finalrank2}を計算する．
\begin{equation}
\mathit{LLR}\_\mathit{cluster}(o_k, u_j) = \frac{1}{|C(u_j)|} \sum_{ u_l \in C(u_j)} \mathit{LLR}(o_k,u_l)
\label{eq:finalrank2}
\end{equation}
\eq{finalrank2}が示すように，事後処理法では，元の重要度
をクラスタ内で平均化した値を重要度として採用する．


\subsection{評価視点クラスタリング}
\label{sec:clustering_mothod}

次に，上記の補正手法で用いるクラスタリングについて述べ
る．クラスタリングのアルゴリズムは，以下に示す標準的な
アルゴリズム\cite{clustering}を採用する．ただし，アルゴ
リズム内で利用される評価視点間の類似度尺度については，
以下で述べるシソーラスに基づく類似度において，ユーザレ
ビューの特性を踏まえて拡張を施した尺度を新たに採用する．
なお，クラスタリングの議論をおこなう場合，一般には距離
や非類似度を定義することが多いが，説明の便宜上，ここで
は類似度を定義している点に注意されたい．

以下，クラスタリング・アルゴリズムについて概要を述べた
後，評価視点間の類似度尺度について述べる．

クラスタリングには，以下に示す 3 つのアルゴリズムを採用
した．いずれも，凝集型の手法であり，もっともクラスタ間
類似度の高い 2 つのクラスタをボトムアップに再帰的に併合
しながらクラスタリングを進める点が共通しているが，クラ
スタ間類似度の定義が異なる．

単連結法(\textit{single linkage method})は，クラスタ$C_i$
と$C_j$の要素間の類似度$\mathit{wsim}(k, s)$の中で，最大の類似度
をクラスタ間の類似度$\mathit{csim}(C_i,C_j)$とする：
\begin{equation}
\label{eq:single}
\mathit{csim}(C_i,C_j) = \max_{k \in C_i, s \in C_j}\mathit{wsim}(k, s)
\end{equation} 

完全連結法(\textit{complete linkage method})は，クラ
スタ$C_i$と$C_j$の要素間の類似度の中で，最小の類似度
をクラスタ間の類似度とする：
\begin{equation}
\label{eq:complete}
\mathit{csim}(C_i,C_j) = \min_{k \in C_i, s \in C_j}\mathit{wsim}(k, s)
\end{equation} 

また，群平均法(\textit{group average method})は，クラスタ
$C_i$と$C_j$の各要素間の平均類似度をクラスタ間の類似度
とする：
\begin{equation}
\label{eq:group}
\mathit{csim}(C_i,C_j) = \frac{1}{|C_i||C_j|}\sum_{k \in C_i}\sum_{s \in C_j}\mathit{wsim}(k, s)
\end{equation} 

次に，評価視点間の類似度$\mathit{wsim}(k, s)$ について説明する．
評価視点間の類似度には，以下で述べる 3 種類の類似度尺度
を併用した．なお，どの類似度も0以上1以下の値をとり，同
じ評価視点が入力となった場合に対して最大値$1$を返す
 ($\mathit{wsim}(k, k) = 1$)．



\subsubsection{シソーラスに基づく類似度}

2 つの単語$k$と$s$の類似度を求める手法として，シソーラ
スに基づく類似度がある．これは次式のように定義される
\cite{nagao}：
\begin{equation}
\label{eq:thesaurus}
\mathit{wsim}'_\mathit{the}(k, s)=
 \begin{cases}
  \frac{2 × d_\mathit{share}(k, s)}{d(k)+d(s)} & (k,s \in T) \\
  0  & (\mathit{otherwise}) \\
\end{cases}
\end{equation}
ここで，$d(k)$と$d(s)$は階層構造をなすシソーラス中での
当該単語の位置する深さをあらわし，$d_\mathit{share}(k,s)$は階
層構造における単語$k$と単語$s$の共通祖先ノードが位置す
る深さの最大値をあらわす．また，$T$はシソーラスに含まれ
る見出し語の集合である．

一般に，シソーラスは人手により構築されていることから，
シソーラスの見出し語に含まれる単語間の類似度を測るには
この尺度は有用と言える．
しかし，今回対象としている評価視点には「施設管理」といっ
たシソーラスには登録されにくい複合語なども含まれている
ため，上記尺度そのままでは多数の評価視点間の類似度が
$0$となってしまう問題がある．
そこで，本論文では類似度が求められる評価視点ペアの被覆
率を上げるために，以下のように拡張した類似度を採用する：
\begin{equation}
\label{eq:thesaurus_k}
wsim_{the}(k, s)=
 \begin{cases}
  \mathit{wsim}'_\mathit{the}(k, s) & (k, s \in T) \\
  \frac{1}{|k|} \sum_{i=1}^{|k|} \mathit{wsim}'_\mathit{the}(k_i, s) & (k \notin T, s \in T) \\
  \frac{1}{|s|} \sum_{j=1}^{|s|} \mathit{wsim}'_\mathit{the}(k, s_j) & (k \in T, s \notin T) \\
  \frac{1}{|k||s|} \sum_{i=1}^{|k|}\sum_{j=1}^{|s|} \mathit{wsim}'_\mathit{the}(k_i, s_j) & (k \notin T, s \notin T)
 \end{cases}
\end{equation}
ここで， 形態素解析によって各評価視点を形態素に分割した
ものをそれぞれ$k_1,\ldots,k_{|k|}$，$s_1,\ldots,s_{|s|}$で表
しており，
拡張版では，従来の式で類似度が求められない場合は対象を
分割して類似度を求めていることがわかる．
例えば，引数$k$が「施設管理」である例を考える．ここで，
「施設管理」はシソーラスに含まれておらず，またもう一方
の引数$s$はシソーラスに含まれる何らかの単語であるとする．
この場合の類似度計算は\eq{thesaurus_k}の 2 行目によって
おこなわれ，「施設管理」を「施設」と「管理」に分割させ
た後，それぞれの形態素に対して\eq{thesaurus}の
$\mathit{wsim}'_\mathit{the}()$へ問合せを実行し，個別に$s$との類似度を
求める．そして，問合せ結果の平均を「施設管理」と$s$との
間の類似度であるとする．
\eq{thesaurus_k}では，分割操作によって，シソーラスのエ
ントリとの照合率が改善され，類似度が求められない事例数
を削減させる効果が期待できる．


\subsubsection{表層文字列に基づく類似度}

次に，上記のシソーラスに基づく類似度尺度を補完するため
に，評価視点の表層文字列に基づく類似度を考える．
本研究では，最長共通部分文字列 \textit{LCS} (\textit{longest common subsequence}) 
\cite{hirschberg}に基づく以下の類似度尺
度を採用する：
\begin{equation}
\mathit{wsim}_\mathit{lcs}(k, s) = \frac{2 \times \mathit{LCS}(k, s)}{|k|+|s|}
\label{eq:lcs}
\end{equation}
ここで，$\mathit{LCS}(k,s)$は$k$と$s$の最長共通部分文字列の長さ
であり，上式は，その値を$k$，$s$それぞれの文字列の長さ
を基に正規化している．
表層文字列に基づく類似度は，「焼きたてパン」と「焼き立
  てパン」のような部分的な漢字表記とひらがな表記の違い
や，「バイキング」と「朝食バイキング」のような文字数の
比較的多いカタカナ列からなる評価視点の類似性を測る際に
特に効果的であると期待できる．
例えば，6 文字で構成される「焼きたてパン」と「焼き立て
  パン」がそれぞれ$k$と$s$である例を考える．両者の違い
は，ひらがな「た」と漢字「立」の 1 文字だけであり，その
他は各文字の順序等すべて同じである．この場合，
$\mathit{LCS}(k,s)=5$で，$\mathit{wsim}_\mathit{lcs}(k,s)=10/12$となり，高い類似
度が得られる．

LCS の代わりに，不連続になる部分文字列の影響を考慮した文
字列カーネル\cite{lodhi}を用いた予備実験も行ったが，
LCSとほぼ同様の実験結果を得た．そのため，
\sec{experiment}の実験ではLCSを用いた結果のみ報告する．


\subsubsection{文脈情報に基づく類似度}

類似度を補完するもう一つの方法として，評価視点が現れる
文脈の情報に基づく類似度を考える．これは一般に，似た意
味をもつ単語は似た文脈に現れやすいと言われており，この
性質に従って，単語が現れる周辺文脈を基に類似度を求める
手法である．
本研究では，代表的な手法の一つである，次式のコサイン類
似度を採用する\cite{lin}：
\begin{equation}
\label{eq:context}
\mathit{wsim}_\mathit{cos}(k, s) = \frac{\boldsymbol{v}_{k} \cdot \boldsymbol{v}_{s}}{||\boldsymbol{v}_{k}|| ||\boldsymbol{v}_{s}||}
\end{equation}
ここで，$\boldsymbol{v}_k$と$\boldsymbol{v}_s$は，それぞれ$k$と$s$の文脈に現れる
単語から構成される単語頻度ベクトルである．
また，ここでは，当該の評価視点に対応するすべての評価視
点トークンから文脈情報を獲得し，それらの情報からひとつ
のベクトルを作成する．
文脈情報に基づく類似度は，「東京駅」と「駅」や「最寄り
  駅」のような，文脈に依存した評価視点の類似性を測る際
に特に効果的であると期待できる．


\subsubsection{各種類似度の統合}

ここまで述べたように各類似度尺度は，それぞれ異なる情報
に基いており，互いに相補関係にあると言える．そこで，ク
ラスタリングの際は，各類似度尺度を単独で用いるのではな
く，次式のように統合して用いる事とする：
\begin{equation}
\mathit{wsim}(k, s) = \max \{\mathit{wsim}_\mathit{the}(k, s),\ \mathit{wsim}_\mathit{lcs}(k, s),\ \mathit{wsim}_\mathit{cos}(k, s)\}
\label{eq:sim_mix}
\end{equation}


\end{document}
