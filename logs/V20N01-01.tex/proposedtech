\documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\usepackage{multirow}
\usepackage{url}
\usepackage{algorithm}
\usepackage{algorithmic}

\def\sec#1{}
\def\eq#1{}
\def\fig#1{}
\def\tab#1{}

\def\algo#1{}





\Volume{20}
\Number{1}
\Month{March}
\Year{2013}

\received{2012}{8}{3}
\revised{2012}{10}{26}
\accepted{2012}{11}{28}

\setcounter{page}{3}

\jtitle{意見集約における相対的特徴を考慮した評価視点の構造化}
\jauthor{
乾　　孝司\affiref{Author} \and 板谷　悠人\affiref{Author} \and 山本　幹雄\affiref{Author} \and 新里　圭司\affiref{Author_2} \and \\
	平手　勇宇\affiref{Author_2} \and 山田　　薫\affiref{Author_2}}
\jabstract{
本論文では，レビュー集合から多数の評価視点が得られる状
況において，評価対象間の相対的特徴を考慮した重要度（ス
コア）に従って評価視点をランキングする課題について述
べる．また，レビューはその数だけ書き手が存在することか
ら評価視点の異表記が生じやすく，これがランキングに悪影
響を与える．本論文では，評価視点に対してクラスタリング
を適用することで異表記問題へ対応する手法を提案する．
評価実験を通して，提案したスコア関数がランキング性能の
向上に有効であること，およびクラスタリングに基づくラン
キング補正手法によって，平均適合率（MAP指標）が向上する
ことを確認した．
}
\jkeywords{評判分析，評価視点，属性，対数尤度比，異表記}

\etitle{Structuring Opinions by Relative Characteristics \\ for User-Opinion Aggregation}
\eauthor{
Takashi Inui\affiref{Author} \and Yuto Itaya\affiref{Author} \and Mikio Yamamoto\affiref{Author}
	\and Keiji Shinzato\affiref{Author_2} \and \\
	Yu Hirate\affiref{Author_2} \and Kaoru Yamada\affiref{Author_2}} 
\eabstract{
We propose a scoring function for aspect ranking that
facilitates user-opinion aggregation.  The function
uses the log-likelihood ratio to capture relative
characteristics between opinions.  Review documents
contain many variant expressions because they are
written by different web users.  We also propose a
re-ranking method that identifies variant expressions
having the same meaning by using several clustering
techniques.  The experimental results indicate that
the proposed scoring function and the re-ranking
method are more effective than baseline methods.
}
\ekeywords{sentiment analysis, aspect, log-likelyhood ratio, variant expression}

\headauthor{乾，板谷，山本，新里，平手，山田}
\headtitle{意見集約における相対的特徴を考慮した評価視点の構造化}

\affilabel{Author}{筑波大学システム情報工学研究科コンピュータサイエンス専攻}{Department of Computer Science, Graduate school of SIE, University of Tsukuba}
\affilabel{Author_2}{楽天株式会社}{Rakuten, Inc.}



\begin{document}
\maketitle


\section{提案手法}
\label{sec:uniq_aspect_ranking}


\subsection{評価視点}

提案手法の説明の前に，ここで，評価視点という用語につい
て整理しておく．
本論文における評価視点は，基本的には，Hu ら\cite{hu}や
小林ら\cite{kobayashi,siten}の定義に従っている．後述す
る評価実験では，評価対象が宿泊施設であるので，そのこと
を踏まえると，本論文における評価視点は，
\begin{itemize}
\item 
宿泊施設に対する意見の焦点となる宿泊施設の構成物や属性，
あるいは，宿泊施設への宿泊という経験から生じる宿泊施設
に対する意見の焦点となるもの
\end{itemize}
であると言い表せる．例えば，宿泊施設の立地情報（「駅
    前」，「海沿い」）や施設が提供する設備に関する情報
（「風呂」，「加湿器」），施設のサービス（「バイキン
    グ」，「接客態度」）等が具体的な評価視点となる．


また，評価視点の表現形式は，単一単語（「バイキング」）
だけでなく，複合語（「朝食バイキング」）や句（「朝食の
    バイキング」）などの場合もある．本研究では以上の形
式は評価視点として認めているが，処理の都合上，以下に示
すように，連体修飾節を伴う場合は修飾部を除外して扱った．
下記例の場合，下線部は評価視点として認めたが，どちらの
例でも「メニューが新しくなった」は評価視点には含めてい
ない．
なお，表現形式の特定は以下のようにおこなった．単語の特
定には形態素解析器
MeCab\footnote{\url{http://mecab.sourceforge.net/}}を使
用した．複合語については，MeCabで解析後，名詞が連続して
いる箇所を複合語として特定している．句については，現在
は「名詞の名詞」というパターンで特定しており，他の形は
想定していない．ただし，上記パターンの名詞は名詞連続に
置換可能とした．
\begin{itemize}
 \item メニューが新しくなった\underline{朝食バイキング}が良かった．
 \item メニューが新しくなった\underline{朝食のバイキング}が良かった．
\end{itemize}



\subsection{評価視点ランキング}
\label{sec:llr}

提案手法について述べる．まず，使用する記号，および，評
価視点のランキング課題を以下のように定義する．
評価対象の集合を$\mathcal{O} =\{o_1, o_2,...,o_{|\mathcal{O}|}\}$とする．
全ての評価対象に対する全てのレビューの集合を
$\mathcal{R}$とし，
$\mathcal{R}$の要素であるレビューの中に書かれた評価視点(token) 
の系列を$\mathcal{V}=\langle v_1,v_2,...,v_n\rangle$，
$\mathcal{V}$の異なり要素 (type) の集合を
$\mathcal{U}=\{u_1,u_2,...,u_m\}$ ($m \le n$) とする．
例えば，以下のような，それぞれ 1 文と 2 文からなる短
い 2 つのレビューを要素とする集合$\mathcal{R}$があり，各
文の下線部が評価視点であったとすると，系列
$\mathcal{V}$と集合$\mathcal{U}$は次のようになる．
\begin{itemize}
 \item $\mathcal{R} = \big\{\text{``このホテルは\underline{\mbox{朝食$_{1}$}}と\underline{風呂}が良い．'', ``\underline{\mbox{朝食$_{2}$}}が美味しい．また来たいです．''}\big\}$
 \item $\mathcal{V}= \bigl\langle \text{朝食$_{1}$, 風呂, 朝食$_{2}$}\bigr\rangle $
 \item $\mathcal{U}= \big\{\text{朝食, 風呂}\big\}$
\end{itemize}
この時，ある評価対象$o_k$に関して評価視点をランキングす
るアルゴリズムを次の\algo{alg1}とする．このアルゴリズム
が示している通り，$\mathcal{U}$の要素$u_j$がランキング
の対象である．本論文では曖昧性を排除するために，以降，
$u_j$のことを単に評価視点と呼び，評価視点$u_j$ が
$\mathcal{R}$内で出現したものを評価視点トークンと呼ぶ．

\begin{algorithm}[h]
\caption{評価視点ランキング}         
\label{algo:alg1}
\begin{algorithmic}
\STATE{INPUT ~~~$o_k \in \mathcal{O}$：評価対象\\
~~~~~~~~~~~~~~~$\mathcal{U}$：評価視点集合}
\end{algorithmic}
\begin{algorithmic}[1]
\FOR{$u_j \in \cal{U}$}
\STATE $s[u_j] = score(o_k, u_j)$
\ENDFOR
\RETURN $\mathcal{U}の各要素u_jをs[u_j]の降順に整列$
\end{algorithmic}
\end{algorithm}

上記の\algo{alg1}で自明でない部分は，評価対象$o_k$ にお
ける評価視点$u_j$の重要度を決定するスコア関数
$\mathit{score}(o_k, u_j)$のみである．本研究では，このスコア関数
として，以下のような対数尤度比 (\textit{Log-Likelihood Ratio，LLR}) に基づく尺度を提案する．
これは内山ら\cite{uchiyama}が特定分野における単語の特徴
度を測る尺度として提案したものを評価視点ランキング課題
に適用したものである．以下，内山ら\cite{uchiyama}を参考
にしながら，上記尺度の詳細について述べる．

まず始めに，ある評価対象$o_k$と評価視点$u_j$が与えられ
た際，レビュー中で観測された評価視点トークン$v$に関する
確率変数$W_j$と$T_k$を以下のように定義する：
\begin{align}
W_j & =\begin{cases}
1 & vは評価視点u_jのレビュー内での出現である\\
0 & otherwise
\end{cases}
\label{eq:w}\\
T_k & =\begin{cases}
1 & vが観測されたのは評価対象o_kのレビュー内である\\
0 & otherwise
\end{cases}
\end{align}
ここで，評価視点トークン$v_i$ ($1 \le i \le n$) に対応
する確率変数$W_j$，$T_k$の値をそれぞれ$w^i_j$，$t^i_k$とすると，
$\mathcal{V}$ から次のような確率変数の
値の組みで表された系列$\mathcal{V}_{jk} = \bigl\langle
\langle w^1_j, t^1_k \rangle ,\langle w^2_j, t^2_k
\rangle , ... , \langle w^n_j, t^n_k \rangle
\bigr\rangle$が新たに得られる．
この時，それぞれの評価視点トークンが確率的に独立である
と仮定すると，$\mathcal{V}_{jk}$の生起確率は次式で表される：
\begin{equation}
Pr(\mathcal{V}_{jk})= \prod_{i=1}^{n}Pr(W_j=w^i_j, T_k=t^i_k)
\end{equation}

\begin{table}[b]
\vspace{-1\Cvs}
\caption{トークン集合の集計表}
\input{01table01.txt}
\end{table}

また，各トークンを変数$W_j$，$T_k$の値ごとに出現頻度を集計
\pagebreak
することを考え，各頻度を\tab{kankei}のように，それぞれ
$a$，$b$，$c$，$d$で表すことにする．ここで，$a + b + c
+ d = n$ である．

以上の準備のもと，次の対数尤度比を考える：
{\allowdisplaybreaks
\begin{align}
LLR_0(o_k,u_j) & = \log\frac{Pr(\mathcal{V}_{jk}; H_{dep})}{Pr(\mathcal{V}_{jk}; H_{indep})}
	\nonumber \\
 & = \sum_{i=1}^{n}\log\frac{Pr(W_j=w^{i}_j,T_k=t^{i}_k;H_{\mathit{dep}})}{Pr(W_j=w^{i}_j,T_k=t^{i}_k;H_{\mathit{indep}})}
	\label{eq:llr0}
\end{align}
}
ここで，$H_\mathit{dep}$および$H_\mathit{indep}$は，以下のような，確
率変数に関する仮説である．
\begin{itemize}
 \item $H_\mathit{dep}$: 確率変数$W_j$と$T_k$とは互いに依存している．
 \item $H_\mathit{indep}$: 確率変数$W_j$と$T_k$とは互いに独立である．
\end{itemize}
\eq{llr0}において，$H_\mathit{indep}$の下では，
\[
Pr(W_j=w^i_j, T_k=t^i_k; H_\mathit{indep}) = Pr(W_j=w^i_j)Pr(T_k=t^i_k)
\]
が成り立つ．また，各種の確率は，
\begin{align*}
Pr(W_j=1, T_k=1; H_\mathit{dep}) & = \frac{a}{n} ,\quad 
	Pr(W_j=1, T_k=0; H_\mathit{dep}) =  \frac{b}{n} \\
Pr(W_j=0, T_k=1; H_\mathit{dep}) & = \frac{c}{n} ,\quad 
	Pr(W_j=0, T_k=0; H_{dep}) =  \frac{d}{n} \\
Pr(W_j=1) & = \frac{a+b}{n} , \quad
	Pr(W_j=0) =  \frac{c+d}{n} \\
Pr(T_k=1) & = \frac{a+c}{n} ,\quad 
	Pr(T_k=0) =  \frac{b+d}{n}
\end{align*}
で推定する．

この尺度は，2 つの確率変数$W_j$と$T_k$とが依存している
という条件，および，独立であるという条件の下で，データ
が観測される確率の比の対数を表しており，$W_j$と$T_k$の
依存性が高い程，大きな値をとる．
もし，ある評価視点がどの評価対象にも共通するような一般
的な視点であれば，評価視点トークンは，どの評価対象のレ
ビュー中にも同じように出現すると考えられる．すなわち，
$W_j$と$T_k$とは互いに独立であると考えられ，上記尺度は
小さな値をとる．一方で，ある評価視点が特定の評価対象に
のみ特徴的な出現を示すようであれば，$W_j$と$T_k$とは依
存しており，上記尺度は大きな値をとる．つまり，この尺度
をスコア関数とすることで，特定の評価対象に特徴的な評価
視点に対して大きなスコアを割り振ることができる．

ただし，上記尺度は，ある評価視点が特定の評価対象に対し
て特徴的に言及される場合と特徴的に言及されない場合を区
別できない．そのため，どちらの状況であっても大きな値を
とってしまう．そこで，言及される場合とされない場合を区
別できるよう，実際には以下のように補正して利用する．
\pagebreak
\begin{equation}
LLR(o_k,u_j) = sign(ad - bc)LLR_{0}(o_k,u_j)
\label{eq:finalrank}
\end{equation}
ただし，
\begin{equation}
sign(z) = \begin{cases}
  +1 & z > 0 \\
  -1 & \mathit{otherwise}\\
  \end{cases}
\end{equation}
である．



\section{異表記問題への対応}
\label{sec:cl}


\subsection{異表記問題}
\label{sec:clustering_summary}

レビューではユーザの数だけ書き手が存在しており，同じ概
念が述べられていたとしても，ユーザによって異なる単語が
使われることがしばしばある．
例えば，価格について何かを述べたいときに，あるユーザは
「価格」と表記したが，別ユーザは「料金」や「値段」等，
別の単語を使うことがある．
また，レビューは，評価対象という自明な文脈をもつ文書で
あるため，同じ評価対象のもとでユーザが共有しているであ
ろう情報がしばしば省略表記される傾向があり，
例えば，最寄り駅の「東京駅」を単に「駅」と表記するユー
ザ等，その表記はユーザによってさまざまに変化する．

一般的に，このような異表記の問題や表記揺れの問題（以下，
  単に異表記の問題と呼ぶ）はよく知られているが，評価視
点のランキング課題に対しても悪影響を与えていると考えら
れる．前節で述べた提案尺度では評価視点の出現頻度の情報
を用いているが，異表記が考えられる評価視点については，
異表記の数だけ頻度が分散してカウントされてしまい，その
結果，それらの評価を誤ってしまう．

以下では，この異表記問題の影響を回避する手法について述べ
る．本手法は，評価視点をクラスタリングすることによって，
同じ意味あるいは類似した意味の評価視点をクラスタにまと
め上げ，クラスタ情報に基いてランキングを補正する．手法
は，クラスタ情報をランキングに反映させる方法によって，
事前処理法と事後処理法の 2 つに分かれる
（\fig{clustering}）．
以下ではまず，2 つの手法について述べ，その後，各手法の
中で用いるクラスタリング手法について述べる．



\subsection{事前処理法と事後処理法}

事前処理法（\fig{clustering}の(b)）では，ランキングの前
に評価視点のクラスタリングを実施し，同一の意味あるいは
類似した意味の評価視点をクラスタにまとめ上げる．
そして，同じクラスタとなる視点群をひとつの評価視点であ
るように扱い出現頻度を数えることで対数尤度比を計算し，
ランキングをおこなう．

\begin{figure}[t]
 \begin{center}
 \includegraphics{20-1ia960f1.eps}
 \end{center}
 \caption{ランキングの補正手法の概略}
 \label{fig:clustering}
\end{figure}

具体的には，\sec{llr}で導入した\eq{w}の評価視点トークン
に関する確率変数$W_j$を次の\eq{w2}のように再定義してス
コア関数を計算することで，クラスタ情報をランキングに反
映させる．ただし，下記の式中の$v$と$u_j$は\eq{w}と同様，
評価視点トークンと評価視点をそれぞれ意味する．
\begin{equation}
W_j=\begin{cases}
1 & \text{$v$ は評価視点 $u_j$ のレビュー内での出現である}\\
1 & \text{$v$ は $u_j$ と同じクラスタに属する評価視点のレビュー内での出現である}\\
0 & \mathit{otherwise}
\end{cases}
\label{eq:w2}
\end{equation}


事後処理法（\fig{clustering}の(c)）では，ランキングを先
に行い，その後，クラスタリングによって得られたクラスタ
情報に従ってランキング結果を補正する．
具体的には，ある評価視点$u_j$がクラスタ$C(u_j)$に所属す
る場合を考えると，ランキングに使用するスコア関数
\eq{finalrank}で得られた値に対して，次の
\eq{finalrank2}を計算する．
\begin{equation}
\mathit{LLR}\_\mathit{cluster}(o_k, u_j) = \frac{1}{|C(u_j)|} \sum_{ u_l \in C(u_j)} \mathit{LLR}(o_k,u_l)
\label{eq:finalrank2}
\end{equation}
\eq{finalrank2}が示すように，事後処理法では，元の重要度
をクラスタ内で平均化した値を重要度として採用する．


\subsection{評価視点クラスタリング}
\label{sec:clustering_mothod}

次に，上記の補正手法で用いるクラスタリングについて述べ
る．クラスタリングのアルゴリズムは，以下に示す標準的な
アルゴリズム\cite{clustering}を採用する．ただし，アルゴ
リズム内で利用される評価視点間の類似度尺度については，
以下で述べるシソーラスに基づく類似度において，ユーザレ
ビューの特性を踏まえて拡張を施した尺度を新たに採用する．
なお，クラスタリングの議論をおこなう場合，一般には距離
や非類似度を定義することが多いが，説明の便宜上，ここで
は類似度を定義している点に注意されたい．

以下，クラスタリング・アルゴリズムについて概要を述べた
後，評価視点間の類似度尺度について述べる．

クラスタリングには，以下に示す 3 つのアルゴリズムを採用
した．いずれも，凝集型の手法であり，もっともクラスタ間
類似度の高い 2 つのクラスタをボトムアップに再帰的に併合
しながらクラスタリングを進める点が共通しているが，クラ
スタ間類似度の定義が異なる．

単連結法(\textit{single linkage method})は，クラスタ$C_i$
と$C_j$の要素間の類似度$\mathit{wsim}(k, s)$の中で，最大の類似度
をクラスタ間の類似度$\mathit{csim}(C_i,C_j)$とする：
\begin{equation}
\label{eq:single}
\mathit{csim}(C_i,C_j) = \max_{k \in C_i, s \in C_j}\mathit{wsim}(k, s)
\end{equation} 

完全連結法(\textit{complete linkage method})は，クラ
スタ$C_i$と$C_j$の要素間の類似度の中で，最小の類似度
をクラスタ間の類似度とする：
\begin{equation}
\label{eq:complete}
\mathit{csim}(C_i,C_j) = \min_{k \in C_i, s \in C_j}\mathit{wsim}(k, s)
\end{equation} 

また，群平均法(\textit{group average method})は，クラスタ
$C_i$と$C_j$の各要素間の平均類似度をクラスタ間の類似度
とする：
\begin{equation}
\label{eq:group}
\mathit{csim}(C_i,C_j) = \frac{1}{|C_i||C_j|}\sum_{k \in C_i}\sum_{s \in C_j}\mathit{wsim}(k, s)
\end{equation} 

次に，評価視点間の類似度$\mathit{wsim}(k, s)$ について説明する．
評価視点間の類似度には，以下で述べる 3 種類の類似度尺度
を併用した．なお，どの類似度も0以上1以下の値をとり，同
じ評価視点が入力となった場合に対して最大値$1$を返す
 ($\mathit{wsim}(k, k) = 1$)．



\subsubsection{シソーラスに基づく類似度}

2 つの単語$k$と$s$の類似度を求める手法として，シソーラ
スに基づく類似度がある．これは次式のように定義される
\cite{nagao}：
\begin{equation}
\label{eq:thesaurus}
\mathit{wsim}'_\mathit{the}(k, s)=
 \begin{cases}
  \frac{2 × d_\mathit{share}(k, s)}{d(k)+d(s)} & (k,s \in T) \\
  0  & (\mathit{otherwise}) \\
\end{cases}
\end{equation}
ここで，$d(k)$と$d(s)$は階層構造をなすシソーラス中での
当該単語の位置する深さをあらわし，$d_\mathit{share}(k,s)$は階
層構造における単語$k$と単語$s$の共通祖先ノードが位置す
る深さの最大値をあらわす．また，$T$はシソーラスに含まれ
る見出し語の集合である．

一般に，シソーラスは人手により構築されていることから，
シソーラスの見出し語に含まれる単語間の類似度を測るには
この尺度は有用と言える．
しかし，今回対象としている評価視点には「施設管理」といっ
たシソーラスには登録されにくい複合語なども含まれている
ため，上記尺度そのままでは多数の評価視点間の類似度が
$0$となってしまう問題がある．
そこで，本論文では類似度が求められる評価視点ペアの被覆
率を上げるために，以下のように拡張した類似度を採用する：
\begin{equation}
\label{eq:thesaurus_k}
wsim_{the}(k, s)=
 \begin{cases}
  \mathit{wsim}'_\mathit{the}(k, s) & (k, s \in T) \\
  \frac{1}{|k|} \sum_{i=1}^{|k|} \mathit{wsim}'_\mathit{the}(k_i, s) & (k \notin T, s \in T) \\
  \frac{1}{|s|} \sum_{j=1}^{|s|} \mathit{wsim}'_\mathit{the}(k, s_j) & (k \in T, s \notin T) \\
  \frac{1}{|k||s|} \sum_{i=1}^{|k|}\sum_{j=1}^{|s|} \mathit{wsim}'_\mathit{the}(k_i, s_j) & (k \notin T, s \notin T)
 \end{cases}
\end{equation}
ここで， 形態素解析によって各評価視点を形態素に分割した
ものをそれぞれ$k_1,\ldots,k_{|k|}$，$s_1,\ldots,s_{|s|}$で表
しており，
拡張版では，従来の式で類似度が求められない場合は対象を
分割して類似度を求めていることがわかる．
例えば，引数$k$が「施設管理」である例を考える．ここで，
「施設管理」はシソーラスに含まれておらず，またもう一方
の引数$s$はシソーラスに含まれる何らかの単語であるとする．
この場合の類似度計算は\eq{thesaurus_k}の 2 行目によって
おこなわれ，「施設管理」を「施設」と「管理」に分割させ
た後，それぞれの形態素に対して\eq{thesaurus}の
$\mathit{wsim}'_\mathit{the}()$へ問合せを実行し，個別に$s$との類似度を
求める．そして，問合せ結果の平均を「施設管理」と$s$との
間の類似度であるとする．
\eq{thesaurus_k}では，分割操作によって，シソーラスのエ
ントリとの照合率が改善され，類似度が求められない事例数
を削減させる効果が期待できる．


\subsubsection{表層文字列に基づく類似度}

次に，上記のシソーラスに基づく類似度尺度を補完するため
に，評価視点の表層文字列に基づく類似度を考える．
本研究では，最長共通部分文字列 \textit{LCS} (\textit{longest common subsequence}) 
\cite{hirschberg}に基づく以下の類似度尺
度を採用する：
\begin{equation}
\mathit{wsim}_\mathit{lcs}(k, s) = \frac{2 \times \mathit{LCS}(k, s)}{|k|+|s|}
\label{eq:lcs}
\end{equation}
ここで，$\mathit{LCS}(k,s)$は$k$と$s$の最長共通部分文字列の長さ
であり，上式は，その値を$k$，$s$それぞれの文字列の長さ
を基に正規化している．
表層文字列に基づく類似度は，「焼きたてパン」と「焼き立
  てパン」のような部分的な漢字表記とひらがな表記の違い
や，「バイキング」と「朝食バイキング」のような文字数の
比較的多いカタカナ列からなる評価視点の類似性を測る際に
特に効果的であると期待できる．
例えば，6 文字で構成される「焼きたてパン」と「焼き立て
  パン」がそれぞれ$k$と$s$である例を考える．両者の違い
は，ひらがな「た」と漢字「立」の 1 文字だけであり，その
他は各文字の順序等すべて同じである．この場合，
$\mathit{LCS}(k,s)=5$で，$\mathit{wsim}_\mathit{lcs}(k,s)=10/12$となり，高い類似
度が得られる．

LCS の代わりに，不連続になる部分文字列の影響を考慮した文
字列カーネル\cite{lodhi}を用いた予備実験も行ったが，
LCSとほぼ同様の実験結果を得た．そのため，
\sec{experiment}の実験ではLCSを用いた結果のみ報告する．


\subsubsection{文脈情報に基づく類似度}

類似度を補完するもう一つの方法として，評価視点が現れる
文脈の情報に基づく類似度を考える．これは一般に，似た意
味をもつ単語は似た文脈に現れやすいと言われており，この
性質に従って，単語が現れる周辺文脈を基に類似度を求める
手法である．
本研究では，代表的な手法の一つである，次式のコサイン類
似度を採用する\cite{lin}：
\begin{equation}
\label{eq:context}
\mathit{wsim}_\mathit{cos}(k, s) = \frac{\boldsymbol{v}_{k} \cdot \boldsymbol{v}_{s}}{||\boldsymbol{v}_{k}|| ||\boldsymbol{v}_{s}||}
\end{equation}
ここで，$\boldsymbol{v}_k$と$\boldsymbol{v}_s$は，それぞれ$k$と$s$の文脈に現れる
単語から構成される単語頻度ベクトルである．
また，ここでは，当該の評価視点に対応するすべての評価視
点トークンから文脈情報を獲得し，それらの情報からひとつ
のベクトルを作成する．
文脈情報に基づく類似度は，「東京駅」と「駅」や「最寄り
  駅」のような，文脈に依存した評価視点の類似性を測る際
に特に効果的であると期待できる．


\subsubsection{各種類似度の統合}

ここまで述べたように各類似度尺度は，それぞれ異なる情報
に基いており，互いに相補関係にあると言える．そこで，ク
ラスタリングの際は，各類似度尺度を単独で用いるのではな
く，次式のように統合して用いる事とする：
\begin{equation}
\mathit{wsim}(k, s) = \max \{\mathit{wsim}_\mathit{the}(k, s),\ \mathit{wsim}_\mathit{lcs}(k, s),\ \mathit{wsim}_\mathit{cos}(k, s)\}
\label{eq:sim_mix}
\end{equation}


\section{評価実験}
\label{sec:experiment}

\subsection{実験条件}

実験には，代表的な宿泊施設予約サイトのひとつである楽天
トラベル\footnote{\url{http://travel.rakuten.co.jp/}}
に書き込まれた
\pagebreak
レビューを用いた．楽天トラベルに登録され
ている宿泊施設のうち，都内近辺に立地している11施設を対
象とし，各施設ごとに100レビューを実験に使用した．
また，上記レビュー群から人手で評価視点を抽出して実験の
入力データとして用いることにし，さらにそこから特徴的評
価視点を人手で選び出し，評価用データとして用いた．この
作業によって得られた評価視点は施設あたり平均101個であり，
得られた特徴的評価視点は施設あたり平均12.1個である．
データの信頼性を検証するために 2 名の作業者（$A$と$B$）
によってデータ作成をおこない，特徴的評価視点と判定する
際の一致度を以下の計算式で求めた．
\begin{equation}
 \mathit{agreement}(X,Y) = 
   \frac{\text{$X$ と $Y$ が共に特徴的であると判定した評価視点の数}}{\text{$X$ が特徴的であると判定した評価視点の数}}
\end{equation}
判定の一致度は，$\mathit{agreement}(A,B)=0.72$と
$\mathit{agreement}(B,A)=0.77$となり，この結果から，作業者間の判
定はある程度一致していることが確認できる．
また，事例分析から，以下のような事例において判定が一致
しない傾向があることが確認できた．
\begin{itemize}
\item 
評価視点に異表記がある場合：作業者が共に特徴的であると
判定した評価視点に異表記がある場合，作業者による異表記
の認定不足から，一部の評価視点が特徴的であると判定され
ない．
\item 
連続量を伴う評価視点の場合：例えば「駅前で良かった」や
「駅に近く良かった」のような最寄り駅からの近さについて
の言及があった場合，どの程度の距離であれば特徴的な評価
視点であると判定するかについては作業者の主観に拠る部分
が多い．
\end{itemize}
なお，一致度の測定に$\kappa$値を用いることも考えられる．
しかし，次の理由から今回は実態を把握するのに適していな
いと考え，$\kappa$値の採用を見送った．
すなわち，本実験で用いたデータは，特徴的でない評価視点
が全体の 9 割程度を占めているが，$\kappa$値ではこれらに
対して作業者が共に特徴的でないと判定した場合も一致度に
反映されるためである．

シソーラスに基づく類似度を計算するためのシソーラスには，
分類語彙表\cite{bunrui}を用いた．
また，文脈情報に基づく類似度では，予備実験の結果から経
験的に窓枠を 5 と定め，対象の前後 5 単語を文脈情報として
利用した．ただし，単語情報はMeCabによって文脈を形態素解
析することで獲得し，その際，品詞が「助詞」，「助動詞」，
「記号」である場合は窓枠のカウント対象から除外した．

実験において，スコア関数として対数尤度比を実際に計算す
る際は，ラプラススムージング\cite{map}を適用した．


スコア関数のベースラインとして，\textit{TF} および \textit{TF-IDF}\cite{map}に基づく関数を用いた．
一般に，\textit{TF}, \textit{TF-IDF}は，文書ごとに単語へ重み付
けする際に利用される．しかし，ここでは文書ごとの差異で
はなく施設ごとの差異に注目したいため，次式のように，あ
る施設に対する全レビューをひとつの文書として扱う．


\subsubsection{TF法}

\vspace{-1\abovedisplayskip}
\begin{equation}
\mathit{TF}(o_k, u_j) = \text{施設 $o_k$ の全レビューにおける評価視点}
u_j の出現頻度
\label{eq:tf}
\end{equation}
これは，言い換えると，\tab{kankei} の$a$のみをスコア関
数として考慮することに等しい．


\subsubsection{TF-IDF法}

\vspace{-1\abovedisplayskip}
\begin{equation}
\mathit{TF-IDF}(o_k, u_j) = \mathit{TF}(o_k,u_j) × \log ( \frac{|D|}{DF(u_j)} + 1 ) 
\label{eq:tfidf}
\end{equation}
$|D|$は一般的な定義では文書数であるが，上記で述べたよう
に今回は施設数に等しい．$DF(u_j)$はレビューに評価視点
$u_j$が現れた施設数である．

評価尺度には，情報検索のランキング課題の評価によく利用
される \textit{Mean Average Precision} (\textit{MAP}) を用いた．
\textit{MAP} は次式で定義される\cite{map}．
\begin{equation}
 \mathit{MAP} = \frac{1}{|\mathcal{O}|}\sum_{o_k \in \mathcal{O}}\frac{1}{|\mathcal{A}_k|}\sum_{\hat{u}_j \in \mathcal{A}_k}
	\mathit{Precision}(\mathit{rank}(o_k, \hat{u}_j))
\label{eq:map}
\end{equation}
ここで，$\mathcal{O}$は評価対象の集合であり，
$\mathcal{A}_k$は評価対象$o_k$のレビューから人手によっ
て得られた特徴的評価視点の集合である．$\mathit{rank}(o_k, \hat{u}_j)$
は$o_k$中のある特徴的評価視点$\hat{u}_j$が，何らかのランキン
グ手法によって与えられた順位を示しており，
$\mathit{Precision}(\mathit{rank}(o_k, \hat{u}_j))$は，その順位までの出力結果に
おける適合率である．
つまり，ここでは，ひとつの評価対象が情報検索におけるひ
とつの検索課題に相当するものと見なされて評価される．



\subsection{実験結果}
\label{sec:experiment1}

\begin{table}[b]
 \caption{実験結果（異表記を考慮しない場合）}
 \label{tab:ranking_result}
\input{01table02.txt}
\end{table}

まず，異表記問題への対応を考慮しない場合の結果について
述べる．この結果を\tab{ranking_result}に示す．
\tab{ranking_result}から提案手法 \textit{LLR} がベースライン手法
    （\textit{TF}および\textit{TF-IDF}）よりも性能が向上するこ
    とが確認できた．
\textit{TF} では，\eq{tf}からもわかるように，比較すべき他施設の
評価視点に関する情報を全く考慮していない．そのため，もっとも
低い性能になったと考えられる．
次に，\textit{TF-IDF}では，$\mathit{DF}(u_j)$によって他施設の情
報をある程度考慮することができるが，その情報は出現の有
無のみである．
一方の \textit{LLR} では，評価視点の他施設での出現頻度に関する情
報も反映できており，この差が\tab{ranking_result}の結果
に繋がったと考えられる．

\tab{ranking_result}の結果に対して，「手法間の
\textit{Average Precision} に差がない」という帰無仮説を立て，
対応のある両側$t$検定を実施した．その結果，\textit{LLR} 法と
\textit{TF} 法，および \textit{LLR} 法と \textit{TF-IDF} 法のどちらとの間
でも，有意水準$1\%$で統計的有意差が確認できた．

\begin{table}[b]
 \caption{評価視点ランキングの結果例（異表記を考慮しない場合）}
 \label{tab:ranking_top}
\input{01table03.txt}
\end{table}

\tab{ranking_top}に，実験データ中の 3 つの宿泊施設におけ
るランキング結果の例を示す．下線にボールド体の評価視点
が正しい特徴的評価視点をあらわす．また，括弧内は出現頻
度（\textit{TF}値）である．
評価視点の右に``＊''印があるものについては，その評価視
点が含まれていた文脈（の一部）を例として
\tab{ranking_top_example}に示す．
\tab{ranking_top}の事例の観察から，
\textit{TF} では「部屋」や「立地」，「対応」など一般的で出現頻
度が高くなりやすい語が上位を占めており，それらの一部が
誤りとなっていた．その一方で，\textit{LLR} では「武道館」などの
出現頻度は決して高くないが対象施設に固有な評価視点の順
位がベースラインよりも上がっており，提案手法では他施設
との比較がうまく機能していたことがわかる．
しかし，\tab{ranking_top}の観察によると，「パン」と「朝
  食のパン」のように，宿泊者から見れば同一の事物と考え
られるものが異なる順位として現れており，また，
\tab{ranking_top}から外れた下位の評価視点に目を向けると，
12位に「クロワッサン」，50位には「焼き立てパン」などが
含まれており，異表記が生じていることも同時に確認できた．

\begin{table}[t]
 \caption{評価視点を含む文脈の例}
 \label{tab:ranking_top_example}
\input{01table04.txt}
\end{table}

そこで次に，\sec{cl}で述べた補正手法によって異表記問題
に対応した場合の結果について述べる．
3 つのランキング手法（\textit{TF}，\textit{TF-IDF}，および，
\textit{LLR}）に対して補正手法を適用した実験をおこなったが，
\textit{TF}，\textit{TF-IDF} が \textit{LLR} を上回ることがなかったため，
以下では，\textit{LLR} に対して補正手法を適用する場合の結果を中
心に述べる．

補正手法を適用した結果を\fig{ranking_result_be}と
\fig{ranking_result_af}に示す．\fig{ranking_result_be}
が事前処理法の結果であり，\fig{ranking_result_af}が事後
処理法の結果である．
各図において，縦軸は \textit{MAP} を示し，横軸は以下で述べる類似
度への閾値を示している．凝集型クラスタリングでは，デン
ドログラムと呼ばれるクラスタをノードとする木を生成する
が，各クラスタにはその子ノードの情報から計算される類似
度が付随している．本実験では，この類似度に閾値を設け，
類似度が閾値以下になったときに併合を停止させてクラスタ
リング結果を得ることにし，閾値を変化させながら，それぞ
れの \textit{MAP} を計測した．
今回の場合，類似度の値が$1.0$ となる事例が存在していな
かったため，横軸左端の結果は，クラスタリングを行わない
場合の結果（\tab{ranking_result}の$0.574$）と同一となっ
ている．

\begin{figure}[t]
 \begin{center}
 \includegraphics{20-1ia960f2.eps}
 \end{center}
 \caption{実験結果（異表記を考慮する場合：事前処理法）}
 \label{fig:ranking_result_be}
\end{figure}
\begin{figure}[t]
 \begin{center}
 \includegraphics{20-1ia960f3.eps}
 \end{center}
 \caption{実験結果（異表記を考慮する場合：事後処理法）}
 \label{fig:ranking_result_af}
\end{figure}

\fig{ranking_result_be}，\fig{ranking_result_af}共に，
全体的な傾向として，類似度の閾値を$1.0$から下げるに従い
\textit{MAP}が上昇していくことから，クラスタリングを施すことに
一定の効果があることが確認できるが，ある類似度を契機に
下降に転ずることがわかる．
このような結果は次の理由によると考えられる．すなわち，
もともと全ての評価視点において異表記が存在するわけでは
ないため，クラスタリングすべき評価視点も部分的となる．
今回のようにボトムアップにクラスタリングを進めた時，あ
る点でクラスタリングすべき評価視点のまとめ上げが終了し，
この時点が最適なクラスタ数となり最良の \textit{MAP} 値を得る．し
かし，それ以降は本来クラスタリングすべき評価視点に対す
るまとめ上げではなくなるため本来の目的とは逆に過併合が
生じることになり，性能が悪化すると考えられる．

\textit{MAP} 値が下降するタイミングがクラスタリング手法によって
大幅に異なるが，この違いはクラスタリング手法に起因して
必然的に生じる結果であると考えられる．すなわち，単連結
法（\eq{single}）は類似度の最大値に基いて併合を進めるた
め，ノードに付随する類似度が 3 手法の中で最も速く大きく
なり，\textit{MAP}値も最も速く下降していく．完全連結法
（\eq{complete}）は，逆に，類似度の最小値に基いているた
め，\textit{MAP} 値の下降が最も遅い．また，類似度の平均値に基づ
く群平均法（\eq{group}）は，上記両者の中間に位置してい
ると言える．


\begin{table}[b]
\caption{評価視点ランキングの結果例（異表記を考慮した場合）}
\label{tab:ranking_top2}
\input{01table05.txt}
\end{table}

クラスタリングを施した場合のランキング結果の例を
\tab{ranking_top2}に示す．例示している宿泊施設は
\tab{ranking_top}と同じであり，\tab{ranking_top2}におい
て，下線にボールド体の評価視点が正しい特徴的評価視点を
あらわす．また，各表の右列がクラスタ情報である．
表の観察から，クラスタリングによって異表記がまとめ上げ
られていることが確認できる．また，
宿泊施設Aのように，クラスタリング前は「パン」，「朝食の
  パン」という情報しかわからなかった状態において，「ク
  ロワッサン」のように，詳細な情報を補う効果も事例によっ
て期待できることがわかった．
同様の観点で\tab{ranking_top2}以外の事例を観察してみる
と，クラスタリング前は「野菜」という評価視点のみが上位
にランクされていたが，クラスタリングによって野菜が「春
  野菜」であることが補えたり，クラスタリング前は「壁」
のみであったものが，クラスタリングによって「防音」の壁
であることが補える例が存在していた．


\begin{figure}[b]
 \begin{center}
 \includegraphics{20-1ia960f4.eps}
 \end{center}
 \caption{類似度尺度ごとの性能}
 \label{fig:ranking_sim}
\end{figure}
\begin{table}[b]
 \caption{クラスタリングによって構成された評価視点の異表記クラスタの例}
 \label{tab:cluster}
\input{01table06.txt}
\end{table}

最後に，3 種類の類似度を統合した効果を確認する．
\fig{ranking_sim}に 3 種類の類似度尺度を単独で用いた場合
の結果および類似度を統合した場合の結果を示す．類似度尺
度以外の実験設定は先程の結果で最良の$MAP$値となった設定，
すなわち，群平均法でクラスタリングし，事後処理法でラン
キングを補正する手法を適用した．
また，
クラスタリングによって構成されたクラスタの例を
\tab{cluster}に示す．表の各行において，そのクラスタを構
成した類似度尺度に「◯」印を付けている．また，2 つ以上
の類似度尺度で同じクラスタが構成されていた場合は類似度
の値が最も高い類似度尺度に「◯」印を付けている．
\fig{ranking_sim}から，どの類似度尺度も統合結果の最良値
を上回ることはなく，このことから，類似度を統合すること
の効果が確認できた．ただし，
今回使用したデータに対して人手でクラスタリングを施した
結果を用いてランキングを補正したところ，\textit{MAP} 値は
$0.713$まで向上した．つまり，クラスタリング手法および統
合手法に対する改善の余地が残されていることが示唆される．



\end{document}
