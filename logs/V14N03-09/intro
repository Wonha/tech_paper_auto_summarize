インターネットが普及し，ユビキタス社会が浸透するなか，人間がコンピュータと対話する機会も増加する傾向にある．
これまでの対話システムは言語情報のみを扱い，そのパラ言語情報を扱うことは少ないため，人間同士の対話と比較すると，コンピュータとの対話ではコンピュータが得る人間の情報は少ない．
本研究では音声の言語表現の特徴と音響的特徴から推定可能な感情を検出するために，感情の程度による言語表現の特徴および音響的変化を分析し，コンピュータと人間とのインタラクションにおける人間の感情および態度表出を捉えることを目指す．
それにより，両者の円滑なコミュニケーションを図ることを目的としている．
将来の具体的応用対象として考えられる対話を想定し，コールセンターなどへの自動音声応答システムにおける認識性能に対する不満からくる「苛立ち」や，真意が伝わらないことに対する「腹立ち」の表現などに着目して，ユーザの内的状態をその発話の言語表現および音響的な特徴から推定する可能性について検討する．
本報告では，感情表現を含む音声データの収録方法および感情情報を付与する主観評価法および言語表現・音響的特徴をパラメータとした決定木による「怒り」の感情の程度を推定する実験手法に関して述べ，今後の分析手法の指針について報告する．
