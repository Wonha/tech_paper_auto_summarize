\section{実験}

\subsection{実験設定}


提案手法の妥当性を検証するため，用例ベース翻訳システム
\cite{Aramaki2004}の用例選択部分を提案手法に置き換えて実験を行った．

コーパスはIWSLT04\cite{WO_tsujii}にて配布されたコーパス(トレーニングセッ
トとテストセット)を用いた．
トレーニングセットは旅行対話ドメインの2万の日英対訳文からなる．
テストセットは日本語文($500$文)とそれらの16通りの英語翻訳($500 \times 16$文)からなる．

精度を比較した翻訳システムは次のとおりである．
\begin{enumerate}
\item {\sc PROPOSED:} 提案手法.
\item {\sc WITHOUT\_SIM:} シソーラスを用いない（コンテキストの
  類似を扱わない）提案手法.
\item {\sc BASIC:} 経験則によるメジャーにより用例を選択するシステム
  \cite{Aramaki2004}．
このシステムは，IWSLT04\cite{WO_tsujii}に参加し，高い翻訳精度を示した．
また，このシステムは，{\sc PROPOSED}と同じアライメント結果を用いている．
\item {\sc BASELINE:} 用例ベース翻訳のベースライン．このシステムは，最
  も編集距離が近い用例を探索し，その用例の英語文をそのまま出力する．
\item {\sc C1,C2:} ルールベース方式の商用翻訳システム．
\end{enumerate}

\subsection{評価}

評価は，表\ref{eval}の自動評価尺度を用い，IWSLT04\cite{WO_tsujii}と同
様の以下の条件で行った．

\begin{enumerate}
\item 大文字／小文字の差異の無視．
\item 記号／句読点（−．，？”）の無視．
\item 数字はスペルアウトする（20,000 → Twenty Thousand）．
\end{enumerate}

\subsection{結果}

各手法の精度を表\ref{t1}に示す．
表\ref{t1}に示されるように，
提案手法{\sc proposed}は，経験則による{\sc basic}と比べて僅かに高い精
度を持ち，提案する確率による選択が妥当であることを示している．

また，両者の精度は，商用システム({\sc C1},{\sc C2})や用例ベース翻訳の
ベースライン({\sc baseline})と比べてはるかに高く，現実的な精度上での
比較であることが分かる．

次に，コンテキストの類似度を考慮した効果について述べる．
これは，提案手法（{\sc proposed}）とシソーラスを用いない手法（{\sc
without\_sim}）の精度を比較することで調査できる(表\ref{t1})．
実験結果は，NISTにおいては{\sc proposed}が高く，BLEUにおいては{\sc
without\_sim}が僅かに高かった．
NISTは訳語選択に鋭敏な自動評価手法であるが，
このNISTで，{\sc proposed} が高い値を持つのは，
コンテキストの類似度の導入が訳語選択に貢献しているとためだと推測される．


結果をより具体的に比較するため，両手法で翻
訳結果が異なった例の一部を表\ref{tWithoutAndWithSim}に示す．

表最上部は「ありませんか」という訳し分けが必要な表現の例である．
この表現は，旅行ドメインでは，通常は``do you have''と訳すことが多いの
だが，「（施設／場所が）ありませんか」という場合にはこの訳は不適切とな
る．
このような場合でも，{\sc proposed}は，「ありませんか」を``are there''
用いて正しく訳せている．一方，コンテキストの類似度を考慮しない{\sc
without\_sim}は，``do you have''と不適切な翻訳を行ってしまう．


このように一部の翻訳で，{\sc proposed}がより適切な翻訳を行ったが，
表中段の``notify''と``contact''の差異など，両手法のどちらの訳語が適切
か判断が困難な例も数多く確認された．
この実験は，ドメインを旅行対話に絞った翻訳実験であり，訳し分けを必要す
る入力文が，ドメインを絞った時点で減っているのが，一因であると考えられ
る．





最後に，表\ref{tWithoutAndWithSim}下部のように{\sc proposed} 
の方が誤った訳を出力する場合も観察された．
これは，{\sc proposed}の選んだ用例にアライメント誤りが含まれている
ことが原因であった．
一方，{\sc without\_sim}は，同じ用例のサイズであれば，対応する頻度が高い用例を選ぶ．
複数の用例がみな同じアライメントの誤り方をするわけではないので，{\sc without\_sim}
は必然的にアライメント誤りの影響を受けにくいと考えられる．
この違いが原因で，一部の自動評価指標においては，{\sc without\_sim}の精度の方が
{\sc proposed}よりも高くなったと推測される．




このように，今回の実験では，{\sc proposed}がすべての面で優位であること
を示すことはできなかった．
しかし，(1)アライメント誤りによる精度の低下は，モデルの定式化の妥当性
とは別個の問題である点，また，(2)実験は，ドメインを絞った翻訳実験であ
り，コンテキストを考慮する必要性が少ない点，
これらの2点を考慮すると，コンテキストの
類似度の定式化の妥当性は，実験によって確かめられたと考えられる．
また，アライメント誤りに対する頑健性をどのように{\sc proposed}に持たせ
るかは，今後の課題としたい．



\begin{table}
\caption{proposedとwithout\_simの違い}
\begin{center}
\label{tWithoutAndWithSim}
\begin{tabular}{ll}
\hline
\hline
入力文             & この近くでいいレストランは\textbf{ありませんか}\\
{\sc proposed}     & \textbf{are there} any good restaurants in the neighborhood\\
{\sc without\_sim} & $\surd$\textbf{do you have} any good restaurants in the neighborhood\\
\hline
入力文             & このカートは\textbf{使えますか}\\
{\sc proposed}     & \textbf{can I use} this cart \\
{\sc without\_sim} & $\surd$\textbf{do you accept} this cart \\
\hline
入力文             & 警察へ\textbf{連絡して}ください\\
{\sc proposed}     & please \textbf{notify} the police\\
{\sc without\_sim} & please \textbf{contact} the police\\
\hline
入力文             & サイズが\textbf{わかりません}\\
{\sc proposed}     & \textbf{i 'm not sure of} this size\\
{\sc without\_sim} & \textbf{i do n't know} this size\\
\hline
入力文             & メニューを\textbf{お願いします}\\
{\sc proposed}     & \textbf{give me} the menu \textbf{please}\\
{\sc without\_sim} & \textbf{please} the menu\\
\hline
入力文             & \textbf{アクセサリー}はどこで\textbf{買えますか}\\
{\sc proposed}     & $\surd$where can i \textbf{buy \underline{clothes for} accessory}\\
{\sc without\_sim} & where can i \textbf{get accessory}\\
\hline
入力文             & \textbf{旅行の}目的は何ですか。\\
{\sc proposed}     & $\surd$what 's the purpose of \textbf{the \underline{travel agency}}\\
{\sc without\_sim} & what 's the purpose of \textbf{the trip}\\
\hline
\hline
\end{tabular}
\end{center}
{\footnotesize * \textbf{太字}は{\sc proposed}と{\sc without\_sim}の
翻訳が異なっている箇所を示す．$\surd$は誤りと評価された文を示す．
\underline{下線}はアライメント誤りを示す．}
\end{table}



	
	
	
	\begin{table}
	\caption{自動評価手法}
	\begin{center}
	\label{eval}
	\begin{tabular}{ll}
	\hline
	\textbf{BLEU} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  正解とのn-gram の適合率の相乗(幾何)平均\cite{Papineni2002}.
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\textbf{NIST} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  正解とのn-gram の適合率の相加(算術)平均\cite{Doddington2002}.
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\textbf{WER} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  Word Error Rate. 正解との編集距離\cite{Niessen2000}．
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\textbf{PER} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  Position Independent Word Error Rate.語順を用いない正解との編集距離\cite{Och2001}．
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\textbf{GTM} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  general text matcher.
	正解と一致した最長語列の適合率，再現率の調和平均\cite{Turian2003}．
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\end{tabular}
	\end{center}
	{\footnotesize 
	* BLEU, NIST,GTMについては大きな値ほど精度がよい．WER，PERにつ
	いては小さなほど精度がよい.
        }
	\end{table}
	
	
	


	
	
	
	\begin{table}
	\caption{実験結果}
	\begin{center}
	\label{t1}
	\begin{tabular}{rlllll}
	\hline
	                        & bleu & nist & wer  & per  & gtm \\
	\hline
	{\sc proposed}           & 0.41 & 8.04 & 0.52 & 0.44 & 0.67 \\
	{\sc without\_sim}       & 0.42 & 7.67 & 0.49 & 0.42 &0.68 \\
	{\sc basic}              & 0.39 & 7.92 & 0.52 & 0.44 & 0.67 \\
	{\sc baseline}           & 0.31 & 6.65 & 0.62 & 0.54 & 0.59 \\
	{\sc C1}                 & 0.13 & 5.47 & 0.75 & 0.60 & 0.56 \\
	{\sc C2}                 & 0.27 & 7.31 & 0.54 & 0.47 & 0.65 \\
	\hline
	\end{tabular}
	\end{center}
	\end{table}
	
	
	

\subsection{誤り分析}

{\sc proposed}のより具体的な分析のため，
{\sc proposed}の翻訳結果から，100翻訳文を無作為抽出し，それらを人手でチェックし
た．

この結果，49の翻訳文が正解であり，51の翻訳文が不正解であると判定された．
不正解であった原因を人手で分類した結果を表\ref{t3}に示す．

\begin{table}
\caption{誤り分析}
\begin{center}
\label{t3}
\begin{tabular}{rll}
\hline
数 & 分類	& 説明 \\
\hline
\hline
21 & DATA-SPARSENESS	& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  用例の数が足りないことが原因である翻訳誤り．
  この場合，システムは翻訳辞書 （アライメントの際に用いた辞書）を用い
  て訳語を得るが，しばしば不適切な訳語が得られる）	  
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
 6 & ZERO-PRONOUN & 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  ゼロ代名詞による翻訳誤り．
  ゼロ代名詞が入力文にだけ含まれており，用例には含まれていない場合．
  または，逆に，ゼロ代名詞が用例にだけ含まれて，入力文には含まれていな
  い場合に，翻訳文から代名詞が抜け落ちてしまう．
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
 4 & ALIGNMENT-ERR		& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
   アライメントが不適切な用例を用いたことによる翻訳誤り.
	  \vspace{1mm}
	  \end{minipage}
  \\
\hline
 3 & WORD-ORDER		& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  語順がおかしい場合．
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
 3 & SELECTION-ERR		& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  適した用例が存在するが，それが選択されず，不適切な用例を用いた場合．
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
12 & OTHERS		& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  上記のさまざまな誤りが複数存在し，特定の原因に分類できない場合．
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
\end{tabular}
\end{center}
\end{table}


\begin{table}
\caption{翻訳例}
\begin{center}
\label{翻訳例}
\begin{tabular}{ll}
\hline
判定     & 入力文         \\
誤り原因 & システム出力 \\
\hline
\hline
 & 市役所行きのバス停はどこですか。         \\
 & where is the bus stop for the city hall  \\
\hline
 & だいぶよくなったみたい。 \\
 & i feel much better \\
\hline
 & インストラクターを紹介していただけませんか。\\
 & would you please suggest a instructor\\
\hline
 & 歩いてどのくらいですか。\\
 & how long does it take to walk please\\
\hline
 & チェックインは何時からですか。\\
 & what is the check-in time     \\
\hline
$\surd$ & ひどい頭痛がしているんです。\\
ZERO-PRONOUN       & has a bad headache\\
\hline
 & バスでそこへ行けますか。\\
 & can i get there by bus\\
\hline
$\surd$ &あの棚の本を見たいのですが。\\
WORD-ORDER &i 'd like to see the rack that are a books\\
\hline
$\surd$ &なにかメッセージが届いていませんか。\\
ZERO-PRONOUN &have received any message for something\\
\hline
$\surd$ &この綿のセーターを試着してもよろしいですか。\\
DATA-SPARSENESS &i would like to try this sweater for an cotton\\
\hline
 & バス付きの二人部屋にします。\\
 & a two people room with a bath\\
\hline
 & 日本円をドルに替えてください。\\
 & change our japanese yen please into dollars\\
\hline
 & 切符売り場はどこでしょう。\\
 & where can i find the ticket office\\
\hline
\end{tabular}
\end{center}
{\footnotesize * $\surd$は誤りと評価された文を示す．}
\end{table}

表\ref{t3}に見られるように，DATA-SPARSENESSがもっとも顕著な問題である．
このことから，もし，より多くのコーパスが利用可能であれば，精度はさらに
向上すると考えられる．

また，次にZERO-PRONOUN（ゼロ代名詞の問題）が多い．
現在，提案手法はゼロ代名詞に関して，特別な処理を行っていないが，今後，
省略解析の技術を用いて，より注意深くゼロ代名詞を扱うことが必要であろう．

参考までに，表\ref{翻訳例}に翻訳例と分類結果の一部を示す．


\subsection{コーパスサイズと精度}

	
	
	
	\begin{figure}
	\begin{center}
	\epsfxsize=80mm\epsfbox{f_g1.eps}
	\end{center}
	\caption{コーパスサイズと精度(BLEU)}
	\label{f_g1.eps}
	\end{figure}
	
	
	

最後に，コーパスサイズ（トレーニングセットの対訳文数）と翻訳精度（BLEU）
の関係について調査した．
これは，{\sc proposed}と{\sc baseline}の2つのシステムを用いて行った
(図\ref{f_g1.eps}).

図\ref{f_g1.eps}に示されるように，{\sc proposed}と{\sc baseline}の差は
コーパスサイズが小さい場合($x\simeq5,000$)に大きいことが分かる．
このことから，{\sc proposed}の方が用例の不足に対してより頑健であること
が分かる．

また，スコアは今回の実験の最大の用例数($x=20,000$)で
飽和していない．
このことから，もし，より多くの用例を得ることができれば，より高い精度を
得ることが期待される．

