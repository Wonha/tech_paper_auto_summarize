================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.19701] 階層的複数ラベル文書分類においては，あらかじめ定義されたラベル階層の利用が中心的な課題となる．
[i:2, score:0.25129] これを実現するために，まずはこのタスクを構造推定問題として定式化し，複数のラベルを同時に出力する大域モデルと，動的計画法による厳密解の探索手法を提案する．
[i:3, score:0.17654] 次に，ラベル間依存を表現する枝分かれ特徴量を導入する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:14, score:0.22505] 非階層型はラベル階層を利用しない手法であり，各ラベル候補について，入力文書が所属するか否かを独立に分類する．
[i:16, score:0.22985] 一つはラベル階層を候補の枝刈りに用いる手法（枝刈り型）である．
[i:35, score:0.34058] まずは階層型複数ラベル文書分類を構造推定問題として定式化し，複数のラベルを同時に出力する大域モデルと，動的計画法による厳密解の探索手法を提案する．

================================================================
[section type  : proposed_method]
[section title : 問題設定]
================================================================
[i:42, score:0.23173] 階層型複数ラベル文書分類では，与えられた文書に対して，それをもっともよく表すラベルの集合[MATH]を返す．
[i:45, score:0.14770] また，付与対象のラベルは葉のみであり，内部ノードはラベルとならないとする．
[i:46, score:0.14598] 図[REF_fig:tree]の場合，[MATH]，[MATH]，[MATH]および[MATH]がラベル候補となる．

================================================================
[section type  : proposed_method]
[section title : 提案手法]
================================================================
-----------------------------------------------------
  [subsection title : 大域モデル]
-----------------------------------------------------
  [i:lead, score:0.22819] ラベル間依存を利用するための準備として，入力文書[MATH]に対して出力ラベル集合[MATH]を同時に推定する大域モデルを提案する．
.....
  [i:61, score:0.22819] ラベル間依存を利用するための準備として，入力文書[MATH]に対して出力ラベル集合[MATH]を同時に推定する大域モデルを提案する．
  [i:62, score:0.25172] 具体的には，階層的複数ラベル文書分類を構造推定問題とみなし，[MATH]が作る部分木に対してスコアを定義する．
  [i:63, score:0.11275] [MATH]は重みベクトルであり，訓練データを用いて学習すべきパラメータである．
-----------------------------------------------------
  [subsection title : 動的計画法による解探索]
-----------------------------------------------------
  [i:lead, score:0.11302] [t]   \DeclarePairedDelimiter\norm   \algsetup{indent=1.2em}
.....
  [i:72, score:0.46279] [1] \REQUIRE文書[MATH],木のノード[MATH] \ENSUREラベル集合[MATH],スコア[MATH] \STATE[MATH] \FORALL{[MATH]の各子[MATH] } \IF{[MATH]が葉} \STATE[MATH] \ELSE\STATE[MATH] \STATE[MATH] \ENDIF\ENDFOR\STATE[MATH] \IF{[MATH]が空} \STATE[MATH]ただし，[MATH]は[MATH]のなかで[MATH]が最大のもの\ENDIF\STATE[MATH] \STATE[MATH] \RETURN[MATH]
  [i:77, score:0.22184] 子[MATH]は，(1) [MATH]を根とするスコア最大の部分木を作るラベル集合，および(2)そのスコアとひも付けされている．
  [i:82, score:0.21551] 採用された子の集合により，[MATH]のラベル集合とスコアが決定される（14--15行目）．
-----------------------------------------------------
  [subsection title : ラベル間依存の利用]
-----------------------------------------------------
  [i:lead, score:0.11470] 以上の準備により，ラベル間依存を利用する条件が整った．
.....
  [i:93, score:0.21020] ここで，[MATH]はラベル階層における根および内部ノードの個数とする．
  [i:104, score:0.20667] [REF_sec:introduction]節で触れた，「林業政策」と「環境問題」というラベルが付与された文書を再び例に挙げる．
  [i:105, score:0.28609] この文書に対して「林業一般」というラベルはそれほど不適切には見えないが，枝分かれ特徴量を持たないモデルは，「林業一般」を付与しない理由を，[MATH]に対応する重みですべて説明しなければならない．
-----------------------------------------------------
  [subsection title : 大域訓練]
-----------------------------------------------------
  [i:lead, score:0.12056] 大域モデルの訓練手法をここでは大域訓練と呼ぶ．
.....
  [i:115, score:0.32647] [1] \REQUIRE訓練データ[MATH] \ENSURE重みベクトル[MATH] \STATE[MATH] \FOR{[MATH]} \STATE[MATH]をシャッフル\FORALL{[MATH]} \STATE[MATH] \STATE[MATH] \IF{[MATH]} \STATE[MATH] \STATE[MATH] \STATE[MATH] \ENDIF\ENDFOR\ENDFOR
  [i:116, score:0.14754] 大域モデルの場合の擬似コードをAlgorithm [REF_alg:pa-global]に示す．
  [i:119, score:0.15936] 予測を誤った場合，正解ラベル集合を出力する方向に重みを更新する（10行目）．
-----------------------------------------------------
  [subsection title : 大域訓練の並列分散化]
-----------------------------------------------------
  [i:lead, score:0.11290] 大域訓練には学習が非常に遅いという欠点がある．
.....
  [i:124, score:0.17624] しかも，大域訓練はモデルを一枚岩とするため，モデルを局所分類器に分割して並列化することができない．
  [i:136, score:0.31328] [1] \REQUIRE訓練データ[MATH] \ENSURE重みベクトル[MATH] \STATE[MATH]を[MATH]に分割\STATE[MATH] \FOR{[MATH]} \FOR{[MATH]} \STATE[MATH]非同期的にAlgorithm [REF_alg:pa-global]を呼び出す．
  [i:141, score:0.15116] \ENDFOR\STATE非同期処理の終了を待つ\STATE[MATH] \ENDFOR

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
-----------------------------------------------------
  [subsection title : データ]
-----------------------------------------------------
  [i:lead, score:0.01366] 評価データとしてJSTPlusを用いる．
.....
  [i:146, score:0.17931] 実験では，標題と抄録を文書分類に用いるテキストとし，分類コードを付与すべきラベルとみなす．
  [i:150, score:0.16783] ラベル（分類コード）は3,209個からなり，これは4,030個の辺に対応する．
  [i:151, score:0.17688] ラベル階層は，根を除いて，最大で5階層となっている．
-----------------------------------------------------
  [subsection title : モデル設定]
-----------------------------------------------------
  [i:lead, score:0.32840] 大域訓練で訓練された大域モデル(GM-GT)について，枝分かれ特徴量(BF)を用いた場合と用いなかった場合を比較する．
.....
  [i:165, score:0.32840] 大域訓練で訓練された大域モデル(GM-GT)について，枝分かれ特徴量(BF)を用いた場合と用いなかった場合を比較する．
  [i:183, score:0.32647] [1] \REQUIRE訓練データ[MATH] \ENSURE重みベクトル[MATH] \STATE[MATH] \FOR{[MATH]} \STATE[MATH]をシャッフル\FORALL{[MATH]} \STATE[MATH] \IF{[MATH]} \STATE[MATH] \STATE[MATH] \ENDIF\ENDFOR\ENDFOR
  [i:203, score:0.44981] [1] \REQUIRE文書[MATH] \ENSUREラベル集合[MATH] \STATE[MATH],  [MATH] \WHILE{[MATH]が空でない} \STATE[MATH] [MATH]の最初の要素を取り出す,  [MATH] \FORALL{ [MATH]の子である[MATH]} \STATE[MATH] \ENDFOR\STATE[MATH] \IF{[MATH]が空} \STATE[MATH],ただし[MATH]は[MATH]の子のなかで一番高いスコア[MATH]を持つ\ENDIF\FORALL{[MATH]} \IF{[MATH]が葉} \STATE[MATH] \ELSE\STATE[MATH]を[MATH]に追加\ENDIF\ENDFOR\ENDWHILE
-----------------------------------------------------
  [subsection title : 評価尺度]
-----------------------------------------------------
  [i:lead, score:0.12471] 複数ラベル分類に対する評価尺度は数多く存在するが，大きく2種類に整理できる．
.....
  [i:215, score:0.17346] これは，出力ラベルがラベル階層上において正解と近いときに「部分点」を与えるものである．
  [i:217, score:0.17520] \mathrm{hP} = \frac_{i=1}^T |\mathrm{tree}(\mathcal{M}_i) \cap\mathrm{tree}(\hat{M}_i)| _{i=1}^T |\mathrm{tree}(\hat{M}_i)|
  [i:218, score:0.17520] \mathrm{hR} = \frac_{i=1}^T |\mathrm{tree}(\mathcal{M}_i) \cap\mathrm{tree}(\hat{M}_i)| _{i=1}^T |\mathrm{tree}(\mathcal{M}_i)|
-----------------------------------------------------
  [subsection title : 結果]
-----------------------------------------------------
  [i:lead, score:0.04842] 各種モデルの精度比較を表[REF_tb:experiments-summary]に示す．
.....
  [i:221, score:0.29716] 枝分かれ特徴量を組み込んだ大域モデル(GM-GT-BF)が7種類の尺度で最高精度を得た．
  [i:222, score:0.27230] 枝分かれ特徴量なしのモデル(GM-GT)と比較すると，EBP，LBMaR以外の尺度でGM-GT-BFが上回り，すべてのF値を改善した．
  [i:238, score:0.29172] 訓練に用いたPassive-Aggressiveアルゴリズムには重みを0につぶそうとする仕組みがないことから，大きさが削減された理由は，学習過程でGM-GT-BFがGM-GTよりも予測を誤る回数が少なかったからと考えられる．
-----------------------------------------------------
  [subsection title : 議論]
-----------------------------------------------------
  [i:lead, score:0.31819] 大域モデルの重み[MATH]自体は，大域訓練(GT)だけでなく，枝刈り型で用いた2値分類器群を連結することによっても構成できる(LT)．
.....
  [i:240, score:0.31819] 大域モデルの重み[MATH]自体は，大域訓練(GT)だけでなく，枝刈り型で用いた2値分類器群を連結することによっても構成できる(LT)．
  [i:250, score:0.33333] 訓練データに対しては非階層型(FLAT)が一番高い精度を示し，ALLにより局所訓練された大域モデル(GM-LT-ALL)がそれに続いた．
  [i:253, score:0.34293] すなわち，PRUNE-ALLを訓練データに適用したところ，33%の文書について，PRUNE-ALLが出力したラベル集合よりも，正解ラベル集合の方が大域モデルにおいて高いスコアを持っていた．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:298, score:0.25026] 一方，ラベル階層がない場合は，モデルはすべてのラベルペアを考慮する必要があり，訓練および解探索に大きな計算コストを要する．
[i:300, score:0.23994] ラベルの異なり数が大きな場合について，[CITE]は，ラベル集合を低次元の直交座標系に写像し，この空間上で非階層型の分類器を学習する手法を提案している．
[i:302, score:0.20868] [CITE]は，ラベル階層を組み込むために，木あるいは有向非循環グラフの制約を満たすような復号手法を提案している．

================================================================
[section type  : conclusion]
[section title : おわりに]
================================================================
[i:303, score:0.42211] 本稿では，階層型複数ラベル文書分類を構造推定問題として定式化し，動的計画法による厳密解探索方法，大域訓練，ラベル間依存をとらえる枝分かれ特徴量を提案した．
[i:305, score:0.19714] この結果は，人間作業者が複数のラベル候補から出力を選択する際，ラベル階層に基づいて，競合する候補の相対的な重要性を考慮していることを示唆する．
[i:306, score:0.18192] 今後の方向性としては，枝分かれ特徴量以外によってラベル間依存をとらえる方法を探究するというものが考えられる．

