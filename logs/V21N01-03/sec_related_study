階層型文書分類において，枝刈り型が非階層型にしばしば敗れることが報告されており，誤り伝播を軽減するために様々な手法が提案されてきた．
[CITE]は枝刈り探索時の枝刈り基準を緩め，最後に候補の枝刈りを行う．
すなわち，Algorithm [REF_alg:td-search]の7行目の閾値を[MATH]から[MATH]などに引き下げて，より多くの候補を採用する．
最後に，各候補について，根から葉までのパスの（シグモイド関数で変換された）局所スコアの和を取り，これに閾値を設定することによって出力ラベルを絞り込む．
S-cut [CITE]は，一律の閾値を用いるのではなく，局所分類器ごとに閾値を設定する手法である．
R-cutは上位[MATH]個の候補を採用する手法で，選び方には大域的手法[CITE]と局所的手法[CITE]がある．
[CITE]は採用されたラベル候補をメタ分類器にかけ，最終的な出力を決定する．
メタ分類器の特徴量としては，根から葉までの局所スコアやその累積などを用いる．
本稿ではこれらを総称して後付け補正とよぶ．
後付け補正では，いずれもモデルあるいは探索が本質的に不完全であることを想定し，追加のパラメータによる補正を行なっている．
そうしたパラメータは，人手で設定するか，あるいは訓練データとは別に開発データを用意して推定しなければならず煩雑である．
一方，提案手法には後付け補正は不要であり，モデル自体の改善に専念できる．
ラベル階層を下から上へ探索しながら候補を探すという点で，提案手法と似た手法が[CITE]により提案されている．
しかし，彼らの手法では，大域モデルも大域訓練も用いられていない．
代わりに，階層下位の分類器のスコアが上位の分類器のメタ特徴量として用いられている．
分類器の訓練は局所的に行われ，煩雑な交差確認を必要とする．
本稿ではあらかじめ定義されたラベル階層を利用した．
そうした手がかりがない場合にラベル間依存を捉えるための手法も研究されている．
[CITE]は，出力すべきラベル集合中のラベルペアを特徴量に組み込んでいる．
本稿のようにラベル階層が利用できる場合は，それをもとに限られた数のラベル同士の関係を考慮すればすむ．
一方，ラベル階層がない場合は，モデルはすべてのラベルペアを考慮する必要があり，訓練および解探索に大きな計算コストを要する．
こうしたモデルの検証は，ラベルの異なり数が数十程度のデータセットを用いて行われてきた．
ラベルの異なり数が大きな場合について，[CITE]は，ラベル集合を低次元の直交座標系に写像し，この空間上で非階層型の分類器を学習する手法を提案している．
予測時には，分類器の出力を元の空間へ写像するという自明でない復号が必要となる．
[CITE]は，ラベル階層を組み込むために，木あるいは有向非循環グラフの制約を満たすような復号手法を提案している．
