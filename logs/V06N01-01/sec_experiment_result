本節では、学習された決定木による省略補完の有効性を検証する。
まず、ガ格(動)に対して検証を行ない、続いてガ格(形)、ヲ格、ニ格に対しての有効性を議論する。
さらに、学習量、決定木学習の話題依存性、使用属性による相違の三点から検討を行なう。
本論文では、性能評価尺度としてF値(F-measure)を用いる。
F値は、再現率(recall)と適合率(precision)を一つの尺度として表現するために使用される尺度で、[MATH]を再現率、[MATH]を適合率としたとき、以下の式で定義する。
\y{3}
\y{3}
ここで、パラメータ[MATH]は適合率の再現率に対する相対的な重要性である。
本論文ではこのパラメータを[MATH]とした。
まず、以下の条件により実験を行なった。
実験対象はガ格(動)の省略
属性集合は表[REF_属性]に示した367属性
学習文はコーパスから100対話を無作為に抽出した集合
テスト文は学習文と同一の話題の100対話
表[REF_標準]に、以上の条件による結果を示す。
単位はF値である。
表の「学習文」の欄は、学習文とテスト文を同一にして行なったテスト(closed test)の結果である。
3種類の話題[MATH]、[MATH]、[MATH]の中から各100対話を無作為に選択して実験を行なった。
「未知文」の欄は、未学習文に対するテスト(open test)を意味する。
学習文テスト[MATH]で用意した100対話と同一の集合をテスト文にして、それに含まれない100対話をコーパスより無作為に抽出した集合で決定木学習を行なった。
また同表には比較対象として、補完内容を無作為に選択した場合の精度を(比較A)に、補完内容をすべて最多事例の人称(<1sg>)に一意に決定した場合の精度を(比較B)に示した。
また表の最下段に、未知文テストにおける学習文およびテスト文の人称別省略事例数を示した。
また、未知文テストを行なうためにコーパス100対話から作成した決定木の一部を付録の[REF_節:決定木]に示す。
決定木の再現性、弁別性を確認することを目的に行なった学習文テストでは、決定木の枝刈りを行なっていないため、話題の広さに関係なくほぼ100%の再現性を示した。
未知文に対するテストでは、(比較A)、(比較B)のいずれよりも高い値を示し、本手法の有効性が確認された。
なお、表はF値のみであるが、再現率と適合率は共にF値とほぼ同一の値となっている。
人称別では、ほぼ学習事例の多い順に精度が良くなっていることがわかる。
<1sg>、<2sg>、<a>に関しては比較的良好な性能を得ることができたが、<1pl>、<2pl>、<g>については低い精度しか得ることができなかった。
これは学習事例数の不足が一つの原因と考えられる。
誤りの主な傾向を以下に分類する。
複文の単文分割に関係する誤り
照合範囲の誤り
単複の弁別性に関係する誤り
文脈省略に関係する誤り
タグ付与のゆれ
これらのうち、単文分割に関係する誤りと照合範囲の誤りが最も多かった。
前述したように、本研究では接続助詞によって擬似的に単文分割しているが、例えば以下の例文のような場合には、「行けば」だけに対して補完処理を行なってしまい、提案手法が有効に機能しない(例文の下線は補完対象用言、`/'は形態素区切り、`//'は設定した文区切りを示す)。
どう/やっ/て//行け/ば//いい/か/分から/ない/ん/です。
また単文であっても、以下の文で「予約」の補完を行なう場合のように、補完対象の用言(「予約」)の補完に、これとは関係のない付属語(「いたす」「ます」)によって判断してしまい、その結果失敗する。
現在/ご/予約/の/フライト日/と/便名/を/お/願い/いたし/ます。
以上は本手法の問題点であるが、文分割と属性照合を共に厳密にすればよいので、今後十分に対処可能な課題である。
一方、単複の誤りと文脈省略に関係する誤りは本質的に難しい問題であり、現在用意した属性のみによるこれ以上の精度向上は難しいと考えられる。
より一層の精度向上には別の情報が必要である。
日本語格要素の省略補完を行なう手法はこれまでにもいくつか提案されている。
ここでは、このうちのいくつかの手法と定性的な比較を行なう。
補完の手がかりとなる現象を人手で得点化した{}[CITE]では対話文章中の省略のための規則も作成し、物語文を対象にした実験の結果、学習文(204文)で86%、未知文(184文)で76%の省略が補完できたと報告している。
同論文と本論文との差異を以下に示す。
同論文では物語文中の対話文章のみを対象にしている。
本論文では、これらを含む対話テキストを対象としている。
同論文では一人称と二人称に入りやすい用言として各3語を列挙している。
また命令表現と疑問表現は二人称に、ガ格の省略は一人称になりやすいと指摘している。
本論文では、命令や疑問以外の付属語や言語外情報も考慮にいれた補完手法を提案している。
同論文ではパラメータ(各規則に付与する得点)を人手で付与している。
本論文ではパラメータ(どの属性がどの順で使用されるか)を統計情報により自動的に決定している。
Aone and Bennettは文献[CITE]において、本論文と同様に機械学習による省略補完処理を行なっている。
ここでは、照応の先行詞補完の一部として省略補完処理を行ない、合弁事業に関するテキストにおいて先行詞が組織名である省略の補完実験を行なった結果、最高で再現率が40.8%、適合率が73.0%の補完精度が得られたと報告している。
同論文では先行詞の種類が所与(組織)で組織名を推定することが目的であり、先行詞の種類(人称)補完を目的とする本論文とは問題の性質が異なる。
また対話文を対象にした補完処理ではないために文脈省略の補完のみを考慮していることから、本論文と直接比較することはできない。
日本語対話文を対象に省略補完を行なっている研究として、文献[CITE]がある。
工藤らの実験は本論文と同一のコーパスに対しても行なっており、補完規則作成に使用した文に対する省略補完精度として93.2%の補完精度が得られたと述べている。
また文献{}[CITE]は日英機械翻訳システム評価用例文の175事例に対して実験を行ない、情報抽出に使用した文に対してテストを行ない、100%の精度を得たと報告している。
これら両論文はどちらも未知文に対しての報告がない。
これらを比べた時、本論文には以下の優位性があると考える。
例えば工藤らは14種類の動詞に対して人手で補完すべき値を分類しているが、これを多くの動詞に対して作成するのは容易ではない。
両論文では、ある文末表現の出現のみで、もしくは用言と文末表現の組み合わせのみで省略の多くを補完している。
しかしながら、このような少数の要素のみで正確に補完できるものばかりではないことが予想される。
本提案手法では、多数の属性の組み合わせを考慮できる枠組みとなっており、複雑な組み合わせによる省略にも対応できる。
ここでは、日本語の主たる表層格であるガ格、ヲ格、ニ格に対する補完精度の比較を行なうことによって、格との関係を考察する。
本来ならば、補完に必要な属性は格によって異なると考えるのが自然である。
しかし本論文では、手法の有効性を議論し、格による差異を明確化することを目的とするため、網羅的に属性を用意し、すべての格で学習時に同一の属性集合を用意した。
学習時に用意した属性集合は、これまでと同様、表[REF_属性]の367属性である。
実験は、それぞれの格について300対話を学習対話とし、それらに含まれない100対話をテスト対話として未知文テストを行なった。
その結果を表[REF_格]に示す。
なお、表でガ格(動)として示した値は、表[REF_学習量]の`400(対話)'の項と同一の実験である。
表からわかるように、ガ格(動)とガ格(形)との比較では全体としての補完精度に大きな差異はないが、個別の人称に対する精度では両者に明確な差異が現れている。
表には現れていないが、ガ格(形)の補完人称に比較的多くの<a>が含まれているため、<1sg>あるいは<2sg>に対する学習が十分に行なわれず、比較的低い精度になったと推察される。
一方ヲ格については、90%以上の省略が照応的(<a>)であり、外界省略がほとんどないことから非常に高い数字となった。
本手法によってヲ格の文脈省略の認知は高精度で可能であるので、認知された文脈省略に対し従来から知られている照応解決の諸手法を導入することによって解決できるものと考えられる。
ニ格に関しては十分な性能が得られた。
このように高い性能が得られた背景には、二者対話を対象にしたテキストであること、話題が旅行対話に限定されているために使用される述語がある程度限定されることなどが考えられる。
ニ格の多くは間接目的語で外界省略が多かったため、少数候補からの択一問題に有効な本手法が有利に機能したものと考えられる。
学習量との関係を見るために以下の実験を行なった。
学習量として、25、50、100、200、400対話の5種類の集合を作成した。
ここで、これらの集合は包含関係となるように作成した。
テスト集合はこれらのいずれにも含まれない100対話(ガ格(動)の省略数:1685)を用意した。
また、学習属性は表[REF_属性]のものを使用した。
主な人称に対する実験の結果をF値で表[REF_学習量]に示す。
なお、表の「100 (対話)」の欄は表[REF_標準]の「未知文」の欄と同一である。
表[REF_学習量]によれば、ほぼすべての人称に関して学習量の増加と共に性能が単調に向上している。
また、表には示されていないが、再現率、適合率共に単調増加の傾向を示している。
ただし、その増加の割合は徐々に鈍化し、<1sg>に関しては400対話で精度がわずかに減少していることがわかる。
補完内容と学習量の差をグラフにしたものを片対数グラフで図[REF_図:学習量]に示す。
グラフが示すように、比較的学習事例数の少なかった<2pl>や<g>が、学習量増加に伴い大きく精度が向上していることがわかる。
その様子から、<1pl>を含めたこれらの人称に関しては学習量の増加によって一層の精度向上が予想される。
一方、その他の人称並びに全体的な精度に関しては、全体として400対話(6806事例)でほぼ横ばいになっていることから、[MATH]事例の学習量で十分であると言える。
またグラフより、人称に関わらずほぼ一定の精度を示していることから、この時の補完精度(本手法による補完精度の上限)は[MATH]となると予想する。
ここでは、実験の結果と共に、決定木学習の話題依存性を議論する。
学習用のテキストとして、四つの話題[MATH]、[MATH]、[MATH]、[MATH]に属する対話を50対話無作為に抽出し、これによって決定木学習を行なった。
テスト用の対話は前節と同一の未学習100対話を使用し、未知文テストを行なった。
このとき、属性は表[REF_属性]の367属性を使用した。
表[REF_話題依存性]に、テスト対話(＝コーパス全体)の話題別構成比、並びに話題依存性を示す。
表の縦は学習対話の話題、横はテスト対話の話題を示し、値はF値で表現した。
表に示すように、学習対話とテスト対話が一致している時に、[MATH]を除いて最も良好な性能となった。
また[MATH]においてもかなり高い性能を示した。
この傾向は話題に関係なく言えることから、あらかじめテスト対話の話題がある程度限定される、もしくは予測できる問題に対しては、できるだけ同一の話題のみによって学習することが望ましく、その際にテスト対話以外の話題を含めて学習しないことが重要であると考えられる。
学習文の話題別性能では、話題[MATH]が最も高い性能を示した。
この理由は、話題[MATH]が何か特殊な情報を持っているためではなく、話題[MATH]の構成比が最も高かったためである。
また表によると、広範な話題で学習を行なった場合([MATH])に、全体としても平均以上の補完精度を示した。
学習文とテスト文の話題が同一の場合を除くと、[MATH]はすべての話題に対して良好な性能を示していることが観察される。
このことから、テスト文の話題が未知の場合は、広範な話題に対して学習を行なうことが最も有効であることが示唆される。
ただし表[REF_話題依存性]の最下段に示すように、全く未知の話題([MATH])に対しては若干精度が低下する。
たとえ少量の学習であっても、未学習よりはかなり優位であることがわかる。
本節では、格要素の省略補完の問題解決にどの程度使用属性が関係するかを議論する。
これまでに述べてきた諸実験は、比較のため、すべて同一の属性集合を使用して行なってきた。
ここではこの使用属性を変化させることによって補完精度がどうなるかを観察する。
ここでは、以下に示す4種類の属性集合を用意した。
これらはいずれも表[REF_属性]に示した属性の部分集合である。
言語情報のみ(366属性)
機能語のみ(166属性)
内容語のみ(200属性)
用言情報のみ(100属性)
実験は100対話の学習、未学習100対話のテストにより行なった。
この対話集合はどちらも、表[REF_標準]の未知文テスト、あるいは表[REF_学習量]の`100'の実験と同一である。
実験結果を表[REF_結果:属性]に示す。
比較対象として、全属性に実験の結果を表の「全属性」欄に示す。
表より、言語情報のみを使用した学習では、言語外情報を加えた場合とほとんど同程度の精度が得られた。
これは、言語外情報(特に実験で用意した話者情報)がそれほど省略補完に重要でないことを示す。
この結果は我々の予想に反するが、おそらく旅行対話という限られた分野での実験であったため、用言の情報が話者情報を包含するような関係になったことが理由として考えられる。
つまり用言によって話者が推測できたため、話者情報の必要性が低下した可能性がある。
これらを確認するには、両者が対等な関係にある状況での対話、例えば自由対話に対して省略補完実験を行なうことが必要であろう。
機能語のみで決定木学習を行なった場合、全体で8%程度の精度低下が観察された。
この結果は、話題に依存しない機能語のみで決定木学習した場合に、その精度に限界があることを示している。
また、機能語のみの結果は文脈省略(<a>)認知に対して大きな精度低下が見られることから、内容語は比較的照応関係の維持に寄与していることが予想される。
内容語のみの場合はさらに低い精度となった。
日本語対話文においては、内容語よりも一部の機能語の存在によって省略が可能となる場合が多いということをこの結果は示している。
さらに用言情報のみを使用した場合は最も悪い精度を示したが、これは対話文の省略補完が書き言葉のそれと異なる大きな特徴の一つと考えられる。
すなわち、用言情報などの内容語は対話文での省略補完においては相対的に重要性は低いが、文脈省略の先行詞補完など、照応処理に関しては逆に重要性が増すと予想する。
本節では、学習された決定木による省略補完の有効性を検証する。
まず、ガ格(動)に対して検証を行ない、続いてガ格(形)、ヲ格、ニ格に対しての有効性を議論する。
さらに、学習量、決定木学習の話題依存性、使用属性による相違の三点から検討を行なう。
本論文では、性能評価尺度としてF値(F-measure)を用いる。
F値は、再現率(recall)と適合率(precision)を一つの尺度として表現するために使用される尺度で、[MATH]を再現率、[MATH]を適合率としたとき、以下の式で定義する。
\y{3}
\y{3}
ここで、パラメータ[MATH]は適合率の再現率に対する相対的な重要性である。
本論文ではこのパラメータを[MATH]とした。
まず、以下の条件により実験を行なった。
実験対象はガ格(動)の省略
属性集合は表[REF_属性]に示した367属性
学習文はコーパスから100対話を無作為に抽出した集合
テスト文は学習文と同一の話題の100対話
表[REF_標準]に、以上の条件による結果を示す。
単位はF値である。
表の「学習文」の欄は、学習文とテスト文を同一にして行なったテスト(closed test)の結果である。
3種類の話題[MATH]、[MATH]、[MATH]の中から各100対話を無作為に選択して実験を行なった。
「未知文」の欄は、未学習文に対するテスト(open test)を意味する。
学習文テスト[MATH]で用意した100対話と同一の集合をテスト文にして、それに含まれない100対話をコーパスより無作為に抽出した集合で決定木学習を行なった。
また同表には比較対象として、補完内容を無作為に選択した場合の精度を(比較A)に、補完内容をすべて最多事例の人称(<1sg>)に一意に決定した場合の精度を(比較B)に示した。
また表の最下段に、未知文テストにおける学習文およびテスト文の人称別省略事例数を示した。
また、未知文テストを行なうためにコーパス100対話から作成した決定木の一部を付録の[REF_節:決定木]に示す。
決定木の再現性、弁別性を確認することを目的に行なった学習文テストでは、決定木の枝刈りを行なっていないため、話題の広さに関係なくほぼ100%の再現性を示した。
未知文に対するテストでは、(比較A)、(比較B)のいずれよりも高い値を示し、本手法の有効性が確認された。
なお、表はF値のみであるが、再現率と適合率は共にF値とほぼ同一の値となっている。
人称別では、ほぼ学習事例の多い順に精度が良くなっていることがわかる。
<1sg>、<2sg>、<a>に関しては比較的良好な性能を得ることができたが、<1pl>、<2pl>、<g>については低い精度しか得ることができなかった。
これは学習事例数の不足が一つの原因と考えられる。
誤りの主な傾向を以下に分類する。
複文の単文分割に関係する誤り
照合範囲の誤り
単複の弁別性に関係する誤り
文脈省略に関係する誤り
タグ付与のゆれ
これらのうち、単文分割に関係する誤りと照合範囲の誤りが最も多かった。
前述したように、本研究では接続助詞によって擬似的に単文分割しているが、例えば以下の例文のような場合には、「行けば」だけに対して補完処理を行なってしまい、提案手法が有効に機能しない(例文の下線は補完対象用言、`/'は形態素区切り、`//'は設定した文区切りを示す)。
どう/やっ/て//行け/ば//いい/か/分から/ない/ん/です。
また単文であっても、以下の文で「予約」の補完を行なう場合のように、補完対象の用言(「予約」)の補完に、これとは関係のない付属語(「いたす」「ます」)によって判断してしまい、その結果失敗する。
現在/ご/予約/の/フライト日/と/便名/を/お/願い/いたし/ます。
以上は本手法の問題点であるが、文分割と属性照合を共に厳密にすればよいので、今後十分に対処可能な課題である。
一方、単複の誤りと文脈省略に関係する誤りは本質的に難しい問題であり、現在用意した属性のみによるこれ以上の精度向上は難しいと考えられる。
より一層の精度向上には別の情報が必要である。
日本語格要素の省略補完を行なう手法はこれまでにもいくつか提案されている。
ここでは、このうちのいくつかの手法と定性的な比較を行なう。
補完の手がかりとなる現象を人手で得点化した{}[CITE]では対話文章中の省略のための規則も作成し、物語文を対象にした実験の結果、学習文(204文)で86%、未知文(184文)で76%の省略が補完できたと報告している。
同論文と本論文との差異を以下に示す。
同論文では物語文中の対話文章のみを対象にしている。
本論文では、これらを含む対話テキストを対象としている。
同論文では一人称と二人称に入りやすい用言として各3語を列挙している。
また命令表現と疑問表現は二人称に、ガ格の省略は一人称になりやすいと指摘している。
本論文では、命令や疑問以外の付属語や言語外情報も考慮にいれた補完手法を提案している。
同論文ではパラメータ(各規則に付与する得点)を人手で付与している。
本論文ではパラメータ(どの属性がどの順で使用されるか)を統計情報により自動的に決定している。
Aone and Bennettは文献[CITE]において、本論文と同様に機械学習による省略補完処理を行なっている。
ここでは、照応の先行詞補完の一部として省略補完処理を行ない、合弁事業に関するテキストにおいて先行詞が組織名である省略の補完実験を行なった結果、最高で再現率が40.8%、適合率が73.0%の補完精度が得られたと報告している。
同論文では先行詞の種類が所与(組織)で組織名を推定することが目的であり、先行詞の種類(人称)補完を目的とする本論文とは問題の性質が異なる。
また対話文を対象にした補完処理ではないために文脈省略の補完のみを考慮していることから、本論文と直接比較することはできない。
日本語対話文を対象に省略補完を行なっている研究として、文献[CITE]がある。
工藤らの実験は本論文と同一のコーパスに対しても行なっており、補完規則作成に使用した文に対する省略補完精度として93.2%の補完精度が得られたと述べている。
また文献{}[CITE]は日英機械翻訳システム評価用例文の175事例に対して実験を行ない、情報抽出に使用した文に対してテストを行ない、100%の精度を得たと報告している。
これら両論文はどちらも未知文に対しての報告がない。
これらを比べた時、本論文には以下の優位性があると考える。
例えば工藤らは14種類の動詞に対して人手で補完すべき値を分類しているが、これを多くの動詞に対して作成するのは容易ではない。
両論文では、ある文末表現の出現のみで、もしくは用言と文末表現の組み合わせのみで省略の多くを補完している。
しかしながら、このような少数の要素のみで正確に補完できるものばかりではないことが予想される。
本提案手法では、多数の属性の組み合わせを考慮できる枠組みとなっており、複雑な組み合わせによる省略にも対応できる。
ここでは、日本語の主たる表層格であるガ格、ヲ格、ニ格に対する補完精度の比較を行なうことによって、格との関係を考察する。
本来ならば、補完に必要な属性は格によって異なると考えるのが自然である。
しかし本論文では、手法の有効性を議論し、格による差異を明確化することを目的とするため、網羅的に属性を用意し、すべての格で学習時に同一の属性集合を用意した。
学習時に用意した属性集合は、これまでと同様、表[REF_属性]の367属性である。
実験は、それぞれの格について300対話を学習対話とし、それらに含まれない100対話をテスト対話として未知文テストを行なった。
その結果を表[REF_格]に示す。
なお、表でガ格(動)として示した値は、表[REF_学習量]の`400(対話)'の項と同一の実験である。
表からわかるように、ガ格(動)とガ格(形)との比較では全体としての補完精度に大きな差異はないが、個別の人称に対する精度では両者に明確な差異が現れている。
表には現れていないが、ガ格(形)の補完人称に比較的多くの<a>が含まれているため、<1sg>あるいは<2sg>に対する学習が十分に行なわれず、比較的低い精度になったと推察される。
一方ヲ格については、90%以上の省略が照応的(<a>)であり、外界省略がほとんどないことから非常に高い数字となった。
本手法によってヲ格の文脈省略の認知は高精度で可能であるので、認知された文脈省略に対し従来から知られている照応解決の諸手法を導入することによって解決できるものと考えられる。
ニ格に関しては十分な性能が得られた。
このように高い性能が得られた背景には、二者対話を対象にしたテキストであること、話題が旅行対話に限定されているために使用される述語がある程度限定されることなどが考えられる。
ニ格の多くは間接目的語で外界省略が多かったため、少数候補からの択一問題に有効な本手法が有利に機能したものと考えられる。
学習量との関係を見るために以下の実験を行なった。
学習量として、25、50、100、200、400対話の5種類の集合を作成した。
ここで、これらの集合は包含関係となるように作成した。
テスト集合はこれらのいずれにも含まれない100対話(ガ格(動)の省略数:1685)を用意した。
また、学習属性は表[REF_属性]のものを使用した。
主な人称に対する実験の結果をF値で表[REF_学習量]に示す。
なお、表の「100 (対話)」の欄は表[REF_標準]の「未知文」の欄と同一である。
表[REF_学習量]によれば、ほぼすべての人称に関して学習量の増加と共に性能が単調に向上している。
また、表には示されていないが、再現率、適合率共に単調増加の傾向を示している。
ただし、その増加の割合は徐々に鈍化し、<1sg>に関しては400対話で精度がわずかに減少していることがわかる。
補完内容と学習量の差をグラフにしたものを片対数グラフで図[REF_図:学習量]に示す。
グラフが示すように、比較的学習事例数の少なかった<2pl>や<g>が、学習量増加に伴い大きく精度が向上していることがわかる。
その様子から、<1pl>を含めたこれらの人称に関しては学習量の増加によって一層の精度向上が予想される。
一方、その他の人称並びに全体的な精度に関しては、全体として400対話(6806事例)でほぼ横ばいになっていることから、[MATH]事例の学習量で十分であると言える。
またグラフより、人称に関わらずほぼ一定の精度を示していることから、この時の補完精度(本手法による補完精度の上限)は[MATH]となると予想する。
ここでは、実験の結果と共に、決定木学習の話題依存性を議論する。
学習用のテキストとして、四つの話題[MATH]、[MATH]、[MATH]、[MATH]に属する対話を50対話無作為に抽出し、これによって決定木学習を行なった。
テスト用の対話は前節と同一の未学習100対話を使用し、未知文テストを行なった。
このとき、属性は表[REF_属性]の367属性を使用した。
表[REF_話題依存性]に、テスト対話(＝コーパス全体)の話題別構成比、並びに話題依存性を示す。
表の縦は学習対話の話題、横はテスト対話の話題を示し、値はF値で表現した。
表に示すように、学習対話とテスト対話が一致している時に、[MATH]を除いて最も良好な性能となった。
また[MATH]においてもかなり高い性能を示した。
この傾向は話題に関係なく言えることから、あらかじめテスト対話の話題がある程度限定される、もしくは予測できる問題に対しては、できるだけ同一の話題のみによって学習することが望ましく、その際にテスト対話以外の話題を含めて学習しないことが重要であると考えられる。
学習文の話題別性能では、話題[MATH]が最も高い性能を示した。
この理由は、話題[MATH]が何か特殊な情報を持っているためではなく、話題[MATH]の構成比が最も高かったためである。
また表によると、広範な話題で学習を行なった場合([MATH])に、全体としても平均以上の補完精度を示した。
学習文とテスト文の話題が同一の場合を除くと、[MATH]はすべての話題に対して良好な性能を示していることが観察される。
このことから、テスト文の話題が未知の場合は、広範な話題に対して学習を行なうことが最も有効であることが示唆される。
ただし表[REF_話題依存性]の最下段に示すように、全く未知の話題([MATH])に対しては若干精度が低下する。
たとえ少量の学習であっても、未学習よりはかなり優位であることがわかる。
本節では、格要素の省略補完の問題解決にどの程度使用属性が関係するかを議論する。
これまでに述べてきた諸実験は、比較のため、すべて同一の属性集合を使用して行なってきた。
ここではこの使用属性を変化させることによって補完精度がどうなるかを観察する。
ここでは、以下に示す4種類の属性集合を用意した。
これらはいずれも表[REF_属性]に示した属性の部分集合である。
言語情報のみ(366属性)
機能語のみ(166属性)
内容語のみ(200属性)
用言情報のみ(100属性)
実験は100対話の学習、未学習100対話のテストにより行なった。
この対話集合はどちらも、表[REF_標準]の未知文テスト、あるいは表[REF_学習量]の`100'の実験と同一である。
実験結果を表[REF_結果:属性]に示す。
比較対象として、全属性に実験の結果を表の「全属性」欄に示す。
表より、言語情報のみを使用した学習では、言語外情報を加えた場合とほとんど同程度の精度が得られた。
これは、言語外情報(特に実験で用意した話者情報)がそれほど省略補完に重要でないことを示す。
この結果は我々の予想に反するが、おそらく旅行対話という限られた分野での実験であったため、用言の情報が話者情報を包含するような関係になったことが理由として考えられる。
つまり用言によって話者が推測できたため、話者情報の必要性が低下した可能性がある。
これらを確認するには、両者が対等な関係にある状況での対話、例えば自由対話に対して省略補完実験を行なうことが必要であろう。
機能語のみで決定木学習を行なった場合、全体で8%程度の精度低下が観察された。
この結果は、話題に依存しない機能語のみで決定木学習した場合に、その精度に限界があることを示している。
また、機能語のみの結果は文脈省略(<a>)認知に対して大きな精度低下が見られることから、内容語は比較的照応関係の維持に寄与していることが予想される。
内容語のみの場合はさらに低い精度となった。
日本語対話文においては、内容語よりも一部の機能語の存在によって省略が可能となる場合が多いということをこの結果は示している。
さらに用言情報のみを使用した場合は最も悪い精度を示したが、これは対話文の省略補完が書き言葉のそれと異なる大きな特徴の一つと考えられる。
すなわち、用言情報などの内容語は対話文での省略補完においては相対的に重要性は低いが、文脈省略の先行詞補完など、照応処理に関しては逆に重要性が増すと予想する。
