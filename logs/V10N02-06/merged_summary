しかし，従来のベクトル空間法は，多数の単語を基底に用いるため，類似度計算にコストがかかることや，検索要求文に含まれる単語数が少ないとベクトルがスパースになり，検索漏れが多発する恐れのあることなどが問題とされている．
SCORE: 1.55058504994178, idx: 9

例えば，簡単な方法としては，[MATH]法[CITE]などによって，文書データベース中での各単語の重要度を判定し，重要と判定された語のみをベクトルの基底に使用する方法が提案されている．
SCORE: 1.52186724761038, idx: 11

これに対して，LSI法は，複数の単語の背後に潜在的に存在する意味を発見しようとする方法で，具体的には，データベース内の記事の特性ベクトル全体からなるマトリックスに対して，特異値分解（SVD）の方法[CITE]を応用して，互いに独立性の高い基底を求めるものである．
SCORE: 1.54892932802351, idx: 15

また，ベクトルの基底とする単語の意味的関係を学習する方法としては，従来から，Mining Term Associationと呼ばれる方法があり，最近，インターネット文書から体系的な知識を抽出するのに応用されている[CITE]．
SCORE: 1.50693738967291, idx: 19

