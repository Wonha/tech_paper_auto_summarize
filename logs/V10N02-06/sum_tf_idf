================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:2, score:381] これに対して，本論文では，特性ベクトルの基底として，単語の代わりに単語の意味属性（「日本語語彙大系」で規定された約2,710種類）を使用する方法を提案する．
[i:4, score:348] また，単語の表記上の揺らぎに影響されず，同義語，類義語も考慮されるため，従来の単語を基底とする文書ベクトル空間法に比べて，検索漏れを減少させることが期待される．
[i:5, score:391] BMIR-J2の新聞記事検索（文書数約5,000件）に適用した実験結果によれば，提案した方法は，次元数の削減に強い方法であり，検索精度をあまり落とすことなく，文書ベクトルの基底数を300〜600程度まで削減できることが分かった．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:8, score:404] その中で，文書中の単語を基底とする特性ベクトルによって文書の意味的類似性を表現するベクトル空間法は，利用者が検索要求を例文で与える方法であり，KW検索方式に比べて検索条件が具体的に表現されるため，検索精度が良い方法として注目されている．
[i:21, score:422] これに対して，本論文では，ベクトル空間法において，検索精度をあまり低下させることなく，基底数を容易に削減できることを期待して，単語の意味属性をベクトルの基底として使用する方法を提案する．
[i:29, score:389] すなわち，従来の単語を基底とした文書ベクトル空間法では，ベクトルの基底として使用された単語間のみでの一致性が評価されるのに対して，本方式では，すべての単語（30万語）が検索に寄与するため，検索漏れの防止に役立つと期待される．

================================================================
[section type  : proposed_method]
[section title : 意味属性体系を基底とした文書ベクトル空間法]
================================================================
[i:31, score:0] 
-----------------------------------------------------
  [subsection title : 単語を基底とした文書ベクトル空間法（W-VSM）]
-----------------------------------------------------
  [i:lead, 339] 従来の単語を基底とした文書ベクトル空間法では，文もしくは文書の意味的類似性はその中に出現した単語の組で表現されるものと仮定している．
.....
  [i:32, score:339] 従来の単語を基底とした文書ベクトル空間法では，文もしくは文書の意味的類似性はその中に出現した単語の組で表現されるものと仮定している．
  [i:34, score:328] ベクトルの基底とすべき単語としては，キーワード検索の場合と同様，データベース全体に使用された単語の出現統計から，[MATH]値などによって重要と判断された単語を通常使用している．
  [i:37, score:407] 本論文では以後，式[REF_equ1]で与えられる特性ベクトルを「単語を基底とした文書ベクトル」と呼び，このベクトルを使用したベクトル空間法を「単語を基底とした文書ベクトル空間法W-VSM（Word-Vector Space Model）」と呼ぶ．
-----------------------------------------------------
  [subsection title : 単語を基底とした文書ベクトル空間法における意味的類似度]
-----------------------------------------------------
  [i:lead, 377] 単語を基底とした文書ベクトル空間法において，文書の意味類似度を特性ベクトルで表現したとき，異なる文書[MATH]，[MATH]間の意味的類似性[MATH]は，それぞれの文書に対して求めた特性ベクトルの内積として，式[REF_equ2]のように表現される．
.....
  [i:38, score:377] 単語を基底とした文書ベクトル空間法において，文書の意味類似度を特性ベクトルで表現したとき，異なる文書[MATH]，[MATH]間の意味的類似性[MATH]は，それぞれの文書に対して求めた特性ベクトルの内積として，式[REF_equ2]のように表現される．
  [i:40, score:412] 従って，単語を基底とした文書ベクトル空間法を用いた情報検索では，利用者の与えた検索要求文について特性ベクトルを求めて，データベースに収録された各文書の特性ベクトルとの間で類似度を計算し，類似度がある一定値以上の文書を抽出している．
  [i:41, score:353] また，単語を基底とした文書ベクトル空間法では，任意の文書をつなぎ合わせた文書についての特性ベクトルも容易に合成できるから，類似度の高い文書相互間で順にベクトル合成を行えば，文書全体を容易にクラスタリングすることができる．
-----------------------------------------------------
  [subsection title : 単語意味属性を基底とした文書ベクトル空間法（S-VSM）]
-----------------------------------------------------
  [i:lead, 90] 本論文では，単語の代わりに，その単語の意味属性を使用する方法を提案する．
.....
  [i:43, score:217] 本方式では，すべての単語を[MATH]個の意味属性に分類したのち，分類された意味属性を要素とする特性ベクトルによって文書の意味的類似性を表現する．
  [i:45, score:334] 重み[MATH]の与え方としては，種々の方法が考えられるが，本論文では，単語を基底とした文書ベクトル空間法の場合と同様，[MATH]法の考えを適用し，以下の方法で得られた値とする．
  [i:50, score:470] なお，式[REF_equ1]で与えられる特性ベクトルを「単語を基底とした文書ベクトル」と呼んだのに対して，以下では，式[REF_equ3]で与えられる特性ベクトルを「単語意味属性を基底とした文書ベクトル」と呼び，このベクトルを使用したベクトル空間法を「単語意味属性を基底とした文書ベクトル空間法S-VSM（Semantic-Vector Space Model）」と呼ぶ．
-----------------------------------------------------
  [subsection title : 日本語単語の意味属性体系]
-----------------------------------------------------
  [i:lead, 382] 単語の代わりに意味属性を基底とする文書ベクトル空間法では，単語の意味属性についての分類体系が必要である．
.....
  [i:51, score:382] 単語の代わりに意味属性を基底とする文書ベクトル空間法では，単語の意味属性についての分類体系が必要である．
  [i:54, score:108] この意味属性体系は，日本語名詞の意味的な用法を2,710種類の意味属性に分類したもので，意味属性間の意味的関係（is-a関係，has-a関係）が，12段の木構造で表現されている．
  [i:56, score:221] 従って，文書中に使用された名詞の出現頻度が分かれば，[REF_equ3]式のベクトルの要素[MATH]は，[MATH]番目の意味属性を持つ名詞の出現頻度から[REF_word_meaning]章で述べた方法で容易に求めることができる．
-----------------------------------------------------
  [subsection title : 単語意味属性を基底とした文書ベクトルの効果]
-----------------------------------------------------
  [i:lead, 450] 情報検索において，従来の単語を基底とした文書ベクトル空間法W-VSMに比べて，単語意味属性を基底とする文書ベクトル空間法S-VSMが，どのような効果を持つかについて考察する．
.....
  [i:57, score:450] 情報検索において，従来の単語を基底とした文書ベクトル空間法W-VSMに比べて，単語意味属性を基底とする文書ベクトル空間法S-VSMが，どのような効果を持つかについて考察する．
  [i:67, score:489] これに対して，単語意味属性を基底とした文書ベクトル空間法では，[REF_word_meaning]，[REF_goitaikei]節で述べたように，30万語の名詞が2,710の意味属性にマッピングされ，検索要求文に使用された単語とデータベース内の記事中の単語の意味的な類似性が，単語意味属性を介して評価される．
  [i:69, score:419] 適合率の低下単語意味属性を基底とした文書ベクトル空間法では，1つの単語に対して意味属性による検索をおこなうため，複数の単語を検索するのと等価になる．

================================================================
[section type  : proposed_method]
[section title : 必要最小限の意味属性の決定]
================================================================
[i:72, score:408] 本章では，意味属性の上下関係に着目した汎化により，ベクトルの基底として使用すべき必要最小限の意味属性の組を発見する方法について述べる．
-----------------------------------------------------
  [subsection title : 汎化の方法]
-----------------------------------------------------
  [i:lead, 68] 汎化とは，モデル学習において，事例から規則を発見するための帰納的推論の一種である．
.....
  [i:74, score:437] ここでは，特性ベクトルの基底数を減少させるため，情報検索に効果が少ないと推定される意味属性を直属上位の意味属性に縮退させることを汎化と呼ぶ．
  [i:75, score:312] 本論文では，汎化によって基底から削除された意味属性の[MATH]値は，その上位の意味属性の[MATH]値に加えることとする．
  [i:77, score:337] ベクトルの基底に使用される意味属性は，12段の木構造からなり，下位になるほど意味の粒度が相対的に小さくなる．
-----------------------------------------------------
  [subsection title : 必要最小限の意味属性の決定]
-----------------------------------------------------
  [i:lead, 295] ベクトル空間法では，計算量を削減する観点から，ベクトルの基底数を減少させることが望まれる．
.....
  [i:87, score:341] 元来，特性ベクトルで表現される文書の意味の粒度は，ベクトルの基底に単語そのものを使用する場合が最も細かい．
  [i:94, score:357] [MATH]要素[MATH]の値の小さい意味属性[MATH]は，検索精度に与える影響が少ないから，情報検索において少ないベクトルの基底数で高い検索精度を得るには，各[MATH]の値がバランスしていることが必要である．
  [i:95, score:495] すなわち，[MATH]値の低い意味属性でも，基底間でアンバランスが増大するような汎化は，検索精度低下の原因となるから，高い検索精度を得るためには，データベース内の文書全体で出現する[MATH]値がバランスするような意味属性を特性ベクトルの基底に選定する必要がある．
-----------------------------------------------------
  [subsection title : ベクトル変換のための計算コスト]
-----------------------------------------------------
  [i:lead, 165] [REF_generation]節で述べた汎化は，基本となるベクトルの軸を変換する点では，従来のKL法やLSI法と同様である．
.....
  [i:113, score:264] まず，ベクトルの基底数を削減するのに要するコストについて考える．
  [i:114, score:371] データベースに収録された文書の総数と削減前のベクトルの基底数の和を[MATH]，削減後のベクトル基底数を[MATH]とすると，単語を基底とした文書ベクトル空間法の場合，通常，計算量は[MATH]もしくは[MATH]に比例すると言われている．
  [i:117, score:484] これに対して，使用される意味属性の総数を[MATH]，段数を[MATH]（日本語語彙大系の場合[MATH],[MATH]）とすると，単語意味属性を基底とした文書ベクトルにおいて粒度による汎化を行うときは，必要最小限の意味属性の数を求めるための計算コストは，ほぼ，[MATH]に比例する．

================================================================
[section type  : experiment_result]
[section title : 実験]
================================================================
[i:120, score:127] 本章では，情報検索の精度と必要最小限の意味属性の組に関する実験を行い，提案した方式の特徴を評価する．
-----------------------------------------------------
  [subsection title : 使用する文書]
-----------------------------------------------------
  [i:lead, 66] 実験には，TRECに登録された「情報検索評価用テストコレクションBMIR-J2」[CITE]（以下BMIR-J2）を利用する．
.....
  [i:121, score:66] 実験には，TRECに登録された「情報検索評価用テストコレクションBMIR-J2」[CITE]（以下BMIR-J2）を利用する．
  [i:122, score:126] BMIR-J2は，1994年の毎日新聞より国際十進分類（UDC）で経済，工学，工業技術一般に分類される記事5,080件を対象とするもので，文書集合，検索要求，正解判定結果から構成される．
  [i:123, score:56] 検索要求は「[MATH]に関する記事が欲しい」という形式で統一され，「[MATH]」の部分にあたる名詞句が列挙されている．
-----------------------------------------------------
  [subsection title : 評価のパラメータ]
-----------------------------------------------------
  [i:lead, 3] 実験結果は，以下の4つのパラメータを用いて評価する．
.....
  [i:128, score:45] [MATH] :文書類似度
  [i:129, score:129] （但し，[MATH]は，それぞれ，文書[MATH]の特性ベクトル）
  [i:132, score:41] [MATH] :検索精度（f-parameter）
-----------------------------------------------------
  [subsection title : 実験の方法]
-----------------------------------------------------
  [i:lead, 58] 検索要求として新聞記事が与えられたとき，類似した新聞記事を検索することを考え，「主題が一致している新聞記事」を正解とする．
.....
  [i:138, score:369] 従来の単語を基底とした文書ベクトル空間法による実験では，データベース記事全体を対象に使用されている名詞の[MATH]値を求め，その値の大きい順に基底とする名詞を決定する．
  [i:139, score:315] また，基底毎の重要度を考慮し，各単語ベクトルの要素の値には，単語の文書中での出現頻度に[MATH]値を掛けた値を使用する．
  [i:140, score:94] なお，情報検索では，ある一定値以上の類似度を持つ文書を抽出の対象とするが，その値の選び方によって，再現率，適合率の値は変化する．
-----------------------------------------------------
  [subsection title : 単語意味属性を基底とした文書ベクトル（S-VSM）と
単語を基底とした文書ベクトル空間法（W-VSM）の比較]
-----------------------------------------------------
  [i:lead, 470] 2,710種類の意味属性のすべてを使用する場合について情報検索実験を行い，従来の単語を基底とした文書ベクトル空間法（W-VSM）と検索精度を比較する．
.....
  [i:142, score:470] 2,710種類の意味属性のすべてを使用する場合について情報検索実験を行い，従来の単語を基底とした文書ベクトル空間法（W-VSM）と検索精度を比較する．
  [i:143, score:365] 本論文の方法による検索精度を従来の単語を基底とした文書ベクトル空間法と比べた結果を図[REF_result1]に示す．
  [i:148, score:394] 単語意味属性を基底とした文書ベクトルは，単語を基底とした文書ベクトル空間法に比べて，すべての類似度領域で，再現率が高く，適合率が低い．
-----------------------------------------------------
  [subsection title : 粒度による汎化（S-VSM(g)）と$tf \cdot idf$値による汎化（S-VSM(w)）の比較]
-----------------------------------------------------
  [i:lead, 481] [REF_decision]節で述べたような，意味属性の粒度に着目する汎化（S-VSM(g)）と意味属性の[MATH]値に着目する汎化（S-VSM(w)）の２つの汎化の方法を用いて，ベクトルの基底として使用する意味属性の数と検索精度の関係を求めた．
.....
  [i:150, score:481] [REF_decision]節で述べたような，意味属性の粒度に着目する汎化（S-VSM(g)）と意味属性の[MATH]値に着目する汎化（S-VSM(w)）の２つの汎化の方法を用いて，ベクトルの基底として使用する意味属性の数と検索精度の関係を求めた．
  [i:156, score:420] 今回の実験では，単語意味属性を基底とする文書ベクトル空間法は，従来の単語を基底とする文書ベクトル空間法に比べて，基底数が小さくても検索精度が高いことが示された．
  [i:158, score:510] 必要最小限の基底数について見ると，十分な基底数を持つ場合に比べて，検索精度を10 [MATH] 20%以上低下させないためには，単語を基底とする文書ベクトル法では，最低2,000程度の基底数が必要とされるのに対して，単語意味属性ベクトルを用いて，[MATH]値による汎化では，基底数を約300 [MATH] 600程度まで削減できる．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[i:159, score:0] 
-----------------------------------------------------
  [subsection title : 単語意味属性を基底とする文書ベクトル空間法と単語を基底とする文書ベクトル空間法の比較]
-----------------------------------------------------
  [i:lead, 387] 実験によれば，単語意味属性を基底とする文書ベクトルは，単語を基底とする文書ベクトル空間法に比べて，再現率が高いことが分かった．
.....
  [i:160, score:387] 実験によれば，単語意味属性を基底とする文書ベクトルは，単語を基底とする文書ベクトル空間法に比べて，再現率が高いことが分かった．
  [i:161, score:143] 本研究では，簡単のため，文書中に使用された単語の頻度から直接，意味属性の[MATH]値を求めることとし，複数の意味を持つ単語は，その[MATH]値を，該当する複数の意味属性に均等に加える方法を採った．
  [i:162, score:299] これは，単語を基底とする文書ベクトルの場合と同じ扱いであるが，適合率を減少させる原因の一つと考えられる．
-----------------------------------------------------
  [subsection title : 意味属性体系]
-----------------------------------------------------
  [i:lead, 102] 本研究に使用した意味属性体系は，元来，単語多義の解消を狙って開発されたものであり，複数の語義を持つ単語は，通常，複数の意味属性を持つ構造となっている．
.....
  [i:167, score:102] 本研究に使用した意味属性体系は，元来，単語多義の解消を狙って開発されたものであり，複数の語義を持つ単語は，通常，複数の意味属性を持つ構造となっている．
  [i:168, score:27] 日本語語彙大系には，さらに，動詞と名詞の共起関係から，両者の文中での意味を特定するための仕組みが定義されている．
  [i:169, score:116] そこで，これらの情報を使用した意味解析によって文書中で使用された単語の意味的用法を決定し，その後，該当する意味の重みを求めることにすれば，質問文と同じ単語が使用された文書でも意味の異なる用法の文書は検索対象外とすることができるため，適合率は向上すると期待される．
-----------------------------------------------------
  [subsection title : 基底数の削減のためのテストデータ]
-----------------------------------------------------
  [i:lead, 469] 実験では，提案した単語意味属性を基底とした文書ベクトル空間法と従来の単語を基底とした文書ベクトル空間法が基底数削減にどれだけ強いかを比較評価するため，情報検索方式の評価実験用として広く提供されているBMIRのデータセット（検索条件と正解付き）を使用した．
.....
  [i:170, score:469] 実験では，提案した単語意味属性を基底とした文書ベクトル空間法と従来の単語を基底とした文書ベクトル空間法が基底数削減にどれだけ強いかを比較評価するため，情報検索方式の評価実験用として広く提供されているBMIRのデータセット（検索条件と正解付き）を使用した．
  [i:173, score:214] すなわち，本手法では，検索対象とするデータベースに対して必要最小限の意味属性の組を発見することが必要であるが，そのためには，汎化を進める過程で検索精度が低下するかどうかの評価が必要で，検索結果についてあらかじめ正解を知っておく必要がある．
  [i:176, score:223] すなわち，大規模なデータベースでも単語の出現頻度統計を取るのは比較的容易であるから，単語統計から作成された意味属性を初期値とし，意味属性数が[MATH]となるまで汎化すれば，残った[MATH]個の意味属性は，データベース全体から見て最適な組み合わせとなり，運用段階においてもクローズドテストに近い検索精度が得られるものと期待できる．
-----------------------------------------------------
  [subsection title : 必要最小限の意味属性]
-----------------------------------------------------
  [i:lead, 292] 粒度による汎化（S-VSM(g)）において文書ベクトル数を700に汎化したときに残った単語意味属性を調査した．
.....
  [i:177, score:292] 粒度による汎化（S-VSM(g)）において文書ベクトル数を700に汎化したときに残った単語意味属性を調査した．
  [i:179, score:150] 汎化で残った単語意味属性の多くは，汎化をする前に[MATH]値が大きく，かつ頻度も多い単語意味属性であった．
  [i:180, score:65] 例として「抽象」，「名詞」，「事」など意味意味属性であった．
-----------------------------------------------------
  [subsection title :  $tf \cdot idf$値による汎化 と 頻度による汎化]
-----------------------------------------------------
  [i:lead, 213] [REF_generation]節において，必要最小限の意味属性の決定するために，粒度による汎化（S-VSM(g)）と[MATH]値による汎化（S-VSM(w)）を示した．
.....
  [i:181, score:213] [REF_generation]節において，必要最小限の意味属性の決定するために，粒度による汎化（S-VSM(g)）と[MATH]値による汎化（S-VSM(w)）を示した．
  [i:186, score:108] なお，頻度が大きいが[MATH]値が小さくなる単語意味属性は，，「自尊，卑下」，「敬称（女）」，「自信，自棄」，「生産行程」，「自信」などであった．
  [i:187, score:109] また，比較的頻度が小さいが[MATH]値が大きくなる単語意味属性は，「乗り物」，「親、祖父母，先祖」，「親」，「報償」，「庭園」，「休養」，「余暇」などであった．

================================================================
[section type  : conclusion]
[section title : 結論]
================================================================
[i:188, score:354] 従来，ベクトル空間法では，文書の意味を表す特性ベクトルの基底に，文中に現れる単語を使用していた．
[i:190, score:432] また，意味属性間の意味的上下関係に着目したベクトルの基底の汎化の方法を提案し，情報検索の精度を低下させない範囲で，基底数を削減する方法を示した．
[i:196, score:369] 今回は，単語の多義性の問題は考慮しなかったが，単語意味属性を基底とする文書ベクトルでは，意味属性体系の持つ能力を用いて単語の多義を解消した後，基底とする意味属性の重みを計算する方法が可能と考えられるので，今後は，この方法についても検討していきたい．

