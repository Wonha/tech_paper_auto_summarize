従来の単語を基底とした文書ベクトル空間法では，文もしくは文書の意味的類似性はその中に出現した単語の組で表現されるものと仮定している．
すなわち，文書の意味的類似性を表現するために使用される単語の番号を[MATH]とし，文書中での単語[MATH]の重みを[MATH]とするとき，文書は，以下のような特性ベクトルで表わされる．
ベクトルの基底とすべき単語としては，キーワード検索の場合と同様，データベース全体に使用された単語の出現統計から，[MATH]値などによって重要と判断された単語を通常使用している．
また，重み[MATH]の値としては，文中に単語[MATH]が使用されているときは1，使用されていないときは0とする方法と，文中に使用された単語の出現頻度とする方法がある．
また，各文書全体の相対的重みはいずれも等しいとする立場から，ベクトルの絶対値が1となるよう正規化する方法も採られている．
本論文では以後，式[REF_equ1]で与えられる特性ベクトルを「単語を基底とした文書ベクトル」と呼び，このベクトルを使用したベクトル空間法を「単語を基底とした文書ベクトル空間法W-VSM（Word-Vector Space Model）」と呼ぶ．
単語を基底とした文書ベクトル空間法において，文書の意味類似度を特性ベクトルで表現したとき，異なる文書[MATH]，[MATH]間の意味的類似性[MATH]は，それぞれの文書に対して求めた特性ベクトルの内積として，式[REF_equ2]のように表現される．
但し，[MATH]は，それぞれ，文書[MATH]，[MATH]の特性ベクトルを表す．
従って，単語を基底とした文書ベクトル空間法を用いた情報検索では，利用者の与えた検索要求文について特性ベクトルを求めて，データベースに収録された各文書の特性ベクトルとの間で類似度を計算し，類似度がある一定値以上の文書を抽出している．
また，単語を基底とした文書ベクトル空間法では，任意の文書をつなぎ合わせた文書についての特性ベクトルも容易に合成できるから，類似度の高い文書相互間で順にベクトル合成を行えば，文書全体を容易にクラスタリングすることができる．
本論文では，単語の代わりに，その単語の意味属性を使用する方法を提案する．
本方式では，すべての単語を[MATH]個の意味属性に分類したのち，分類された意味属性を要素とする特性ベクトルによって文書の意味的類似性を表現する．
すなわち，対象とする文書[MATH]において[MATH]番目の意味属性を持つ単語全体の重み[MATH]とするとき，文書[MATH]の特性ベクトル[MATH]は，次式で表現される．
重み[MATH]の与え方としては，種々の方法が考えられるが，本論文では，単語を基底とした文書ベクトル空間法の場合と同様，[MATH]法の考えを適用し，以下の方法で得られた値とする．
データベースに収録された文書全体に対して，意味属性[MATH]に属す単語が出現した頻度の合計を求め，それぞれの[MATH]値を計算する．
文書[MATH]を対象に，意味属性[MATH]に属す単語が出現した頻度の合計を求め，その値を文書[MATH]の[MATH]値とする．
上記で得られた[MATH]値と[MATH]値から，意味属性[MATH]の[MATH]値を求める．
上記で得られた[MATH]値を[MATH]となるように正規化する．
なお，式[REF_equ1]で与えられる特性ベクトルを「単語を基底とした文書ベクトル」と呼んだのに対して，以下では，式[REF_equ3]で与えられる特性ベクトルを「単語意味属性を基底とした文書ベクトル」と呼び，このベクトルを使用したベクトル空間法を「単語意味属性を基底とした文書ベクトル空間法S-VSM（Semantic-Vector Space Model）」と呼ぶ．
単語の代わりに意味属性を基底とする文書ベクトル空間法では，単語の意味属性についての分類体系が必要である．
本論文では，意味分類体系として，最近，「日本語語彙大系」[CITE]で提案された日本語名詞の意味属性体系を使用する．
図[REF_imi]に意味属性体系の一部を示す．
[h]
この意味属性体系は，日本語名詞の意味的な用法を2,710種類の意味属性に分類したもので，意味属性間の意味的関係（is-a関係，has-a関係）が，12段の木構造で表現されている．
また，単語意味辞書では，日本語名詞30万語のそれぞれが，どのような意味属性を持つか（一つ以上）が規定されている．
従って，文書中に使用された名詞の出現頻度が分かれば，[REF_equ3]式のベクトルの要素[MATH]は，[MATH]番目の意味属性を持つ名詞の出現頻度から[REF_word_meaning]章で述べた方法で容易に求めることができる．
情報検索において，従来の単語を基底とした文書ベクトル空間法W-VSMに比べて，単語意味属性を基底とする文書ベクトル空間法S-VSMが，どのような効果を持つかについて考察する．
ベクトルの基底数削減の可能性
従来の単語を基底とした文書ベクトル空間法では，ベクトルの基底として使用される名詞の意味は，互いに独立であることが仮定されているが，現実にはこの仮定は成り立たない．
そのため，ベクトルの基底数を減少させるため，従来，基底をクラスタリングで得られたクラスターのベクトルとしたり，特異値分解（SVD: Singular Value Decomposition）によって得られたベクトルに変換する方法の研究[CITE]が行われてきた．
しかし，これらの方法は，ベクトルの変換に多くのコストを要する点が問題であった．
これに対して，本論文で基底として使用する単語意味属性は，木構造によって意味的上下関係（is-a関係とhas-a関係）が規定されている（[REF_goitaikei]節参照）．
この関係を利用して基底数を削減するため，計算コストはきわめて小さい．
また，あまり効果のない意味属性を上位の意味属性で代用できるので，削減された意味属性も検索精度に寄与できるため，従来の方法と同様，検索精度をあまり落とすことなく，基底数が削減できると期待される．
検索漏れの減少の可能性
従来の単語を基底とした文書ベクトル空間法では，文書中に出現した単語のうち，ベクトルの基底として選択された単語のみがその文書の意味に反映する．
そのため，意味が同じであっても，表記が異なる語は別の語として判定される．
また，同義語や類義語を含む文書であっても，それが基底として採用されない限り検索の対象とならない．
これに対して，単語意味属性を基底とした文書ベクトル空間法では，[REF_word_meaning]，[REF_goitaikei]節で述べたように，30万語の名詞が2,710の意味属性にマッピングされ，検索要求文に使用された単語とデータベース内の記事中の単語の意味的な類似性が，単語意味属性を介して評価される．
すなわち，文書中に使用される語は，それが異表記語，同意語，同義語のいずれでであっても，その意味が特性ベクトルに反映するため，情報検索において，検索漏れの削減の効果が期待できる．
適合率の低下
単語意味属性を基底とした文書ベクトル空間法では，1つの単語に対して意味属性による検索をおこなうため，複数の単語を検索するのと等価になる．
そのため適合率の低下が予想される．
本論文では，[REF_vector]章で述べた単語意味属性を基底とした文書ベクトルの効果を評価するため，日本語語彙大系で定義された意味属性2,710種類のすべてを使用する場合と，その中から必要最小限と見られる意味属性を選択して使用する場合について検索精度を調べる．
本章では，意味属性の上下関係に着目した汎化により，ベクトルの基底として使用すべき必要最小限の意味属性の組を発見する方法について述べる．
汎化とは，モデル学習において，事例から規則を発見するための帰納的推論の一種である．
ここでは，特性ベクトルの基底数を減少させるため，情報検索に効果が少ないと推定される意味属性を直属上位の意味属性に縮退させることを汎化と呼ぶ．
本論文では，汎化によって基底から削除された意味属性の[MATH]値は，その上位の意味属性の[MATH]値に加えることとする．
汎化の対象とする意味属性の選び方については，様々な方法が考えられるが，ここでは，意味属性の粒度と意味属性の[MATH]値に着目する方法を考える．
ベクトルの基底に使用される意味属性は，12段の木構造からなり，下位になるほど意味の粒度が相対的に小さくなる．
そこで，各意味属性の位置する段数を粒度と考え，ある一定の粒度より小さい意味属性を汎化する．
図[REF_generation-fig]に，8段以下の意味属性を7段目の意味属性に汎化する場合の例を示す．
検索対象となるデータベースの文書全体での[MATH]値の小さい意味属性は，検索に寄与する程度が小さいと考えられるため，[MATH]値の小さい意味属性を汎化の対象とする．
汎化によって削除された意味属性の[MATH]値は，上位直属の意味属性の[MATH]値に加算する．
直属の意味属性が削除されているときは，さらに上位の意味属性の[MATH]値に加算する．
図[REF_generation-fig]に，[MATH]値が5以下の意味属性を汎化する場合の例を示す．
[ht]
ベクトル空間法では，計算量を削減する観点から，ベクトルの基底数を減少させることが望まれる．
しかし，多くの場合，検索精度は低下させずに基底数を削減することは困難である．
そこで，前節で述べた汎化の方法を使用し，検索精度をある一定値以上低下させない範囲で，必要最小限の意味属性の組を求める方法を考える．
元来，特性ベクトルで表現される文書の意味の粒度は，ベクトルの基底に単語そのものを使用する場合が最も細かい．
意味属性を使用する方法では，すでに意味的な汎化が行われており，意味の粒度は荒くなっている．
粒度に着目した汎化がさらに進めば検索精度は次第に低下すると考えられるため，必要最小限の意味属性の組を発見するには，順次，汎化を進めながら，検索精度の変化を追跡する必要がある．
その結果，検索精度が低下する直前に使用した意味属性の組を必要最小限の組とする．
{基本的な考え方}
データベース中で[MATH]値の小さい意味属性が汎化の対象となる．
しかし，必ずしも，[MATH]値の小さい意味属性のすべてを汎化すればよいとは限らない．
いま，データベース内に収録された文書が検索対象となる確率はすべて均等だとし，すべての文書を対象に求めた特性ベクトルの和を[MATH]とする．
[MATH]要素[MATH]の値の小さい意味属性[MATH]は，検索精度に与える影響が少ないから，情報検索において少ないベクトルの基底数で高い検索精度を得るには，各[MATH]の値がバランスしていることが必要である．
すなわち，[MATH]値の低い意味属性でも，基底間でアンバランスが増大するような汎化は，検索精度低下の原因となるから，高い検索精度を得るためには，データベース内の文書全体で出現する[MATH]値がバランスするような意味属性を特性ベクトルの基底に選定する必要がある．
{汎化すべき意味属性の選択基準}
汎化すべき意味属性の選択基準について考える．
データベース内に収録された文書全体の特性ベクトルを式[REF_equ vec]とする．
ただし，[MATH]は，意味属性[MATH]に属す単語のデータベース全体での[MATH]値の和を，また，[MATH]は，基底に使用される意味属性の数を示す．
ここで，各[MATH]の値の均等さを変動によって評価するとし，評価関数[MATH]を以下のように定義する．
但し[MATH]は[MATH]の平均値とする．
基底のバランスを向上させるには，[MATH]の値が，減少するような基底（意味属性[MATH]）を選んで汎化を行う．
そこで，意味属性[MATH]を汎化することを考える．
[MATH]の直属上位の意味属性の番号を[MATH]とすると，汎化では，[MATH]の値が[MATH]に加算され，基底数[MATH]が１だけ減少する．
従って，このようにして得られた[MATH]の値を[MATH]とすると，[MATH]と[MATH]の差は，近似的に式[REF_equ uvi1]が得られる．
ここで，条件から，[MATH]とおくと，式[REF_equ uvi2]が得られる．
以上から，汎化すべき基底は，その重[MATH]値と直属上位の基底の[MATH]値との積が，基底の平均値の二乗値の半分以下になるものを選択する．
汎化の手順
具体的には，以下の手順で汎化を行う．
汎化
上下関係にある意味属性[MATH]，[MATH]のすべての組のうち，積が最も小さい組を汎化する．
検索
情報検索実験を行い，検索精度を求める．
停止
検索精度の低下がある閾値以下の値のときは(a)に戻り，それ以上の時は，汎化を停止する．
[REF_generation]節で述べた汎化は，基本となるベクトルの軸を変換する点では，従来のKL法やLSI法と同様である．
そこで，そのために必要な計算コストを比較する．
まず，ベクトルの基底数を削減するのに要するコストについて考える．
データベースに収録された文書の総数と削減前のベクトルの基底数の和を[MATH]，削減後のベクトル基底数を[MATH]とすると，単語を基底とした文書ベクトル空間法の場合，通常，計算量は[MATH]もしくは[MATH]に比例すると言われている．
LSI方式でも，特異値分解に必要な計算量は，[MATH]に比例する．
このため，データベースの規模が増大すると急激に計算量が増大することが大きな問題であった．
これに対して，使用される意味属性の総数を[MATH]，段数を[MATH]（日本語語彙大系の場合[MATH],[MATH]）とすると，単語意味属性を基底とした文書ベクトルにおいて粒度による汎化を行うときは，必要最小限の意味属性の数を求めるための計算コストは，ほぼ，[MATH]に比例する．
また[MATH]値による汎化の場合は，ほぼ，[MATH]に比例する．
また，必要最小限の意味属性の組が決定した後，文書毎の特性ベクトルを変換することは容易で，その計算コストは，文書量に比例する．
従来の単語を基底とした文書ベクトル空間法では，文もしくは文書の意味的類似性はその中に出現した単語の組で表現されるものと仮定している．
すなわち，文書の意味的類似性を表現するために使用される単語の番号を[MATH]とし，文書中での単語[MATH]の重みを[MATH]とするとき，文書は，以下のような特性ベクトルで表わされる．
ベクトルの基底とすべき単語としては，キーワード検索の場合と同様，データベース全体に使用された単語の出現統計から，[MATH]値などによって重要と判断された単語を通常使用している．
また，重み[MATH]の値としては，文中に単語[MATH]が使用されているときは1，使用されていないときは0とする方法と，文中に使用された単語の出現頻度とする方法がある．
また，各文書全体の相対的重みはいずれも等しいとする立場から，ベクトルの絶対値が1となるよう正規化する方法も採られている．
本論文では以後，式[REF_equ1]で与えられる特性ベクトルを「単語を基底とした文書ベクトル」と呼び，このベクトルを使用したベクトル空間法を「単語を基底とした文書ベクトル空間法W-VSM（Word-Vector Space Model）」と呼ぶ．
単語を基底とした文書ベクトル空間法において，文書の意味類似度を特性ベクトルで表現したとき，異なる文書[MATH]，[MATH]間の意味的類似性[MATH]は，それぞれの文書に対して求めた特性ベクトルの内積として，式[REF_equ2]のように表現される．
但し，[MATH]は，それぞれ，文書[MATH]，[MATH]の特性ベクトルを表す．
従って，単語を基底とした文書ベクトル空間法を用いた情報検索では，利用者の与えた検索要求文について特性ベクトルを求めて，データベースに収録された各文書の特性ベクトルとの間で類似度を計算し，類似度がある一定値以上の文書を抽出している．
また，単語を基底とした文書ベクトル空間法では，任意の文書をつなぎ合わせた文書についての特性ベクトルも容易に合成できるから，類似度の高い文書相互間で順にベクトル合成を行えば，文書全体を容易にクラスタリングすることができる．
本論文では，単語の代わりに，その単語の意味属性を使用する方法を提案する．
本方式では，すべての単語を[MATH]個の意味属性に分類したのち，分類された意味属性を要素とする特性ベクトルによって文書の意味的類似性を表現する．
すなわち，対象とする文書[MATH]において[MATH]番目の意味属性を持つ単語全体の重み[MATH]とするとき，文書[MATH]の特性ベクトル[MATH]は，次式で表現される．
重み[MATH]の与え方としては，種々の方法が考えられるが，本論文では，単語を基底とした文書ベクトル空間法の場合と同様，[MATH]法の考えを適用し，以下の方法で得られた値とする．
データベースに収録された文書全体に対して，意味属性[MATH]に属す単語が出現した頻度の合計を求め，それぞれの[MATH]値を計算する．
文書[MATH]を対象に，意味属性[MATH]に属す単語が出現した頻度の合計を求め，その値を文書[MATH]の[MATH]値とする．
上記で得られた[MATH]値と[MATH]値から，意味属性[MATH]の[MATH]値を求める．
上記で得られた[MATH]値を[MATH]となるように正規化する．
なお，式[REF_equ1]で与えられる特性ベクトルを「単語を基底とした文書ベクトル」と呼んだのに対して，以下では，式[REF_equ3]で与えられる特性ベクトルを「単語意味属性を基底とした文書ベクトル」と呼び，このベクトルを使用したベクトル空間法を「単語意味属性を基底とした文書ベクトル空間法S-VSM（Semantic-Vector Space Model）」と呼ぶ．
単語の代わりに意味属性を基底とする文書ベクトル空間法では，単語の意味属性についての分類体系が必要である．
本論文では，意味分類体系として，最近，「日本語語彙大系」[CITE]で提案された日本語名詞の意味属性体系を使用する．
図[REF_imi]に意味属性体系の一部を示す．
[h]
この意味属性体系は，日本語名詞の意味的な用法を2,710種類の意味属性に分類したもので，意味属性間の意味的関係（is-a関係，has-a関係）が，12段の木構造で表現されている．
また，単語意味辞書では，日本語名詞30万語のそれぞれが，どのような意味属性を持つか（一つ以上）が規定されている．
従って，文書中に使用された名詞の出現頻度が分かれば，[REF_equ3]式のベクトルの要素[MATH]は，[MATH]番目の意味属性を持つ名詞の出現頻度から[REF_word_meaning]章で述べた方法で容易に求めることができる．
情報検索において，従来の単語を基底とした文書ベクトル空間法W-VSMに比べて，単語意味属性を基底とする文書ベクトル空間法S-VSMが，どのような効果を持つかについて考察する．
ベクトルの基底数削減の可能性
従来の単語を基底とした文書ベクトル空間法では，ベクトルの基底として使用される名詞の意味は，互いに独立であることが仮定されているが，現実にはこの仮定は成り立たない．
そのため，ベクトルの基底数を減少させるため，従来，基底をクラスタリングで得られたクラスターのベクトルとしたり，特異値分解（SVD: Singular Value Decomposition）によって得られたベクトルに変換する方法の研究[CITE]が行われてきた．
しかし，これらの方法は，ベクトルの変換に多くのコストを要する点が問題であった．
これに対して，本論文で基底として使用する単語意味属性は，木構造によって意味的上下関係（is-a関係とhas-a関係）が規定されている（[REF_goitaikei]節参照）．
この関係を利用して基底数を削減するため，計算コストはきわめて小さい．
また，あまり効果のない意味属性を上位の意味属性で代用できるので，削減された意味属性も検索精度に寄与できるため，従来の方法と同様，検索精度をあまり落とすことなく，基底数が削減できると期待される．
検索漏れの減少の可能性
従来の単語を基底とした文書ベクトル空間法では，文書中に出現した単語のうち，ベクトルの基底として選択された単語のみがその文書の意味に反映する．
そのため，意味が同じであっても，表記が異なる語は別の語として判定される．
また，同義語や類義語を含む文書であっても，それが基底として採用されない限り検索の対象とならない．
これに対して，単語意味属性を基底とした文書ベクトル空間法では，[REF_word_meaning]，[REF_goitaikei]節で述べたように，30万語の名詞が2,710の意味属性にマッピングされ，検索要求文に使用された単語とデータベース内の記事中の単語の意味的な類似性が，単語意味属性を介して評価される．
すなわち，文書中に使用される語は，それが異表記語，同意語，同義語のいずれでであっても，その意味が特性ベクトルに反映するため，情報検索において，検索漏れの削減の効果が期待できる．
適合率の低下
単語意味属性を基底とした文書ベクトル空間法では，1つの単語に対して意味属性による検索をおこなうため，複数の単語を検索するのと等価になる．
そのため適合率の低下が予想される．
本論文では，[REF_vector]章で述べた単語意味属性を基底とした文書ベクトルの効果を評価するため，日本語語彙大系で定義された意味属性2,710種類のすべてを使用する場合と，その中から必要最小限と見られる意味属性を選択して使用する場合について検索精度を調べる．
本章では，意味属性の上下関係に着目した汎化により，ベクトルの基底として使用すべき必要最小限の意味属性の組を発見する方法について述べる．
汎化とは，モデル学習において，事例から規則を発見するための帰納的推論の一種である．
ここでは，特性ベクトルの基底数を減少させるため，情報検索に効果が少ないと推定される意味属性を直属上位の意味属性に縮退させることを汎化と呼ぶ．
本論文では，汎化によって基底から削除された意味属性の[MATH]値は，その上位の意味属性の[MATH]値に加えることとする．
汎化の対象とする意味属性の選び方については，様々な方法が考えられるが，ここでは，意味属性の粒度と意味属性の[MATH]値に着目する方法を考える．
ベクトルの基底に使用される意味属性は，12段の木構造からなり，下位になるほど意味の粒度が相対的に小さくなる．
そこで，各意味属性の位置する段数を粒度と考え，ある一定の粒度より小さい意味属性を汎化する．
図[REF_generation-fig]に，8段以下の意味属性を7段目の意味属性に汎化する場合の例を示す．
検索対象となるデータベースの文書全体での[MATH]値の小さい意味属性は，検索に寄与する程度が小さいと考えられるため，[MATH]値の小さい意味属性を汎化の対象とする．
汎化によって削除された意味属性の[MATH]値は，上位直属の意味属性の[MATH]値に加算する．
直属の意味属性が削除されているときは，さらに上位の意味属性の[MATH]値に加算する．
図[REF_generation-fig]に，[MATH]値が5以下の意味属性を汎化する場合の例を示す．
[ht]
ベクトル空間法では，計算量を削減する観点から，ベクトルの基底数を減少させることが望まれる．
しかし，多くの場合，検索精度は低下させずに基底数を削減することは困難である．
そこで，前節で述べた汎化の方法を使用し，検索精度をある一定値以上低下させない範囲で，必要最小限の意味属性の組を求める方法を考える．
元来，特性ベクトルで表現される文書の意味の粒度は，ベクトルの基底に単語そのものを使用する場合が最も細かい．
意味属性を使用する方法では，すでに意味的な汎化が行われており，意味の粒度は荒くなっている．
粒度に着目した汎化がさらに進めば検索精度は次第に低下すると考えられるため，必要最小限の意味属性の組を発見するには，順次，汎化を進めながら，検索精度の変化を追跡する必要がある．
その結果，検索精度が低下する直前に使用した意味属性の組を必要最小限の組とする．
{基本的な考え方}
データベース中で[MATH]値の小さい意味属性が汎化の対象となる．
しかし，必ずしも，[MATH]値の小さい意味属性のすべてを汎化すればよいとは限らない．
いま，データベース内に収録された文書が検索対象となる確率はすべて均等だとし，すべての文書を対象に求めた特性ベクトルの和を[MATH]とする．
[MATH]要素[MATH]の値の小さい意味属性[MATH]は，検索精度に与える影響が少ないから，情報検索において少ないベクトルの基底数で高い検索精度を得るには，各[MATH]の値がバランスしていることが必要である．
すなわち，[MATH]値の低い意味属性でも，基底間でアンバランスが増大するような汎化は，検索精度低下の原因となるから，高い検索精度を得るためには，データベース内の文書全体で出現する[MATH]値がバランスするような意味属性を特性ベクトルの基底に選定する必要がある．
{汎化すべき意味属性の選択基準}
汎化すべき意味属性の選択基準について考える．
データベース内に収録された文書全体の特性ベクトルを式[REF_equ vec]とする．
ただし，[MATH]は，意味属性[MATH]に属す単語のデータベース全体での[MATH]値の和を，また，[MATH]は，基底に使用される意味属性の数を示す．
ここで，各[MATH]の値の均等さを変動によって評価するとし，評価関数[MATH]を以下のように定義する．
但し[MATH]は[MATH]の平均値とする．
基底のバランスを向上させるには，[MATH]の値が，減少するような基底（意味属性[MATH]）を選んで汎化を行う．
そこで，意味属性[MATH]を汎化することを考える．
[MATH]の直属上位の意味属性の番号を[MATH]とすると，汎化では，[MATH]の値が[MATH]に加算され，基底数[MATH]が１だけ減少する．
従って，このようにして得られた[MATH]の値を[MATH]とすると，[MATH]と[MATH]の差は，近似的に式[REF_equ uvi1]が得られる．
ここで，条件から，[MATH]とおくと，式[REF_equ uvi2]が得られる．
以上から，汎化すべき基底は，その重[MATH]値と直属上位の基底の[MATH]値との積が，基底の平均値の二乗値の半分以下になるものを選択する．
汎化の手順
具体的には，以下の手順で汎化を行う．
汎化
上下関係にある意味属性[MATH]，[MATH]のすべての組のうち，積が最も小さい組を汎化する．
検索
情報検索実験を行い，検索精度を求める．
停止
検索精度の低下がある閾値以下の値のときは(a)に戻り，それ以上の時は，汎化を停止する．
[REF_generation]節で述べた汎化は，基本となるベクトルの軸を変換する点では，従来のKL法やLSI法と同様である．
そこで，そのために必要な計算コストを比較する．
まず，ベクトルの基底数を削減するのに要するコストについて考える．
データベースに収録された文書の総数と削減前のベクトルの基底数の和を[MATH]，削減後のベクトル基底数を[MATH]とすると，単語を基底とした文書ベクトル空間法の場合，通常，計算量は[MATH]もしくは[MATH]に比例すると言われている．
LSI方式でも，特異値分解に必要な計算量は，[MATH]に比例する．
このため，データベースの規模が増大すると急激に計算量が増大することが大きな問題であった．
これに対して，使用される意味属性の総数を[MATH]，段数を[MATH]（日本語語彙大系の場合[MATH],[MATH]）とすると，単語意味属性を基底とした文書ベクトルにおいて粒度による汎化を行うときは，必要最小限の意味属性の数を求めるための計算コストは，ほぼ，[MATH]に比例する．
また[MATH]値による汎化の場合は，ほぼ，[MATH]に比例する．
また，必要最小限の意味属性の組が決定した後，文書毎の特性ベクトルを変換することは容易で，その計算コストは，文書量に比例する．
