\section{実験}\label{sec:exp}

\subsection{実験設定}

提案手法の有効性を評価するため，2007年3月の日本語
版WikipediaからWikipedia内部向けの記事を取り除いた276,323記事に対して，
提案手法を適用した．{Wikipedia内部向けのページは，
  ユーザページ，特別ページ，テンプレート，リダイレクション，カテゴリ，曖
  昧さ回避ページを指すものとする．}本稿では，形態素解析
にMeCab\footnote{http://mecab.sourceforge.net/}を利用しその辞書とし
てIPA辞書\footnote{http://chasen.naist.jp/chasen/distribution.html.ja}
を用いた．
SVMにはTinySVM\footnote{http://chasen.org/\~{}
  taku/software/TinySVM/}を利用した．SVMのカーネルには予備実験結果か
ら2次の多項式カーネルを用いた．またWikipediaからStep2で必要となる属性語
リストを抽出した結果，40,733個の属性語が獲得でき，ランダムに取り出し
た200語を\cite{JTokunaga_2006}の厳密な属性語を判定するための基準に従い評価
したところ，精度は73.0\%だった．

まずWikipediaの記事にStep1を適用し，記事構造から{重複を除い
  て}6,564,317対の上位下位関係候補を獲得した．{以降に示す全ての
  上位下位関係数は重複を除いた数を示す．}次に，得られた上位下位関係候補
からランダムに1,000対取り出してテストデータとした．続いて，テスト用デー
タを除いた上位下位関係候補からランダムに9,000対，抽出元の記事構造中で上
位語と下位語が直接の親子関係にあった候補から9,000対，
図~\ref{fig:list_pattern}のパターンにマッチしていた上位下位関係候補か
ら10,000対，図~\ref{fig:list_pattern}のパターンにマッチしなかった上位下
位関係候補から2,000対をそれぞれランダムに取り出し，人手で正解をつけた．
これらから重複を除いて得られた29,900対を訓練データとして用い
た．{訓練データのうち19,476対は，素性を決定するための予備実験に
  利用した．上位下位関係の正解付け
  は，Miller ら}\cite{wordnet-book_1998}{の基準に従い1名で行っ{た\nobreak．}
  具体的には，各上位下位関係候補（上位語候補の表現Aと下位語候補の表
  現Bのペア）につい{て\nobreak，}「BはAの一種あるいは1つである」という文が適切で
  あるとき正解とした．}







\subsection{比較手法}\label{sec:altermethod}

提案手法の有効性を確認するため，\ref{sec:bib}節で説明した既存の語彙統語パターンに基づく上位下位
関係獲得手法\cite{Sumida_2006}，および既存のWikipediaからの上位下位関係
獲得手法\cite{Kazama_2007,Suchanek_2007}と比較を行う．
Wikipediaからの上位下位関係の獲得手法は，英語版Wikipediaに特化したものであるため，以下で日本語版Wikipediaに応用する際に変更した点を記載する．

\begin{figure}[b]
\begin{center}
\includegraphics{16-3ia1f4.eps}
\end{center}
    \caption{定義文に適用する語彙統語パターンの一例}
    \label{fig:def_pattern}
\end{figure}

\paragraph{Wikipediaの定義文からの上位下位関係の獲得}\label{sec:definition}~~

Kazamaらの手法は英語版Wikipediaのための手法であるため，ここでは
国語辞書の語釈文から上位下位関係を獲得したTsurumaruらの手法を参考に人手で図~\ref{fig:def_pattern}の
ような語彙統語パターンを1,334パターン用意した\cite{Tsurumaru_1986,Kazama_2007}．図中の〈上位語〉は任意の
名詞の連続，〈数字〉は0〜9までの数字の連続，〈漢数字〉は〇〜九などの漢数字の連続
を示す．このパターンを定義文に適用することで見出し語を下位語，パターン
で認識された〈上位語〉を上位語とする上位下位関係を獲得する．


\paragraph{Wikipediaのカテゴリからの上位下位関係の抽出}~~

Suchanekらの手法に従い，各記事に付与されているカテゴリを上位語候補，記事の
見出し語を下位語候補として上位下位関係候補を獲得する．例えば，
図~\ref{fig:wiki}（b）の記事からは，「茶／紅茶」という上位下位関係候補が
得られる．Wikipediaのカテゴリから獲得できる関係には上位下位関係以外に
「喫茶文化／紅茶」などのように見出し語とその関連語間の関係も多く含まれ
る．Suchanekらの手法では，英語による経験則を用いて，さらに獲得した関係を選別しているが，日本語には適用できないため，ここではカテゴリ
から抽出できた全ての関係候補を上位下位関係とみなす．


\subsection{実験結果}\label{sec:exp_result}

\begin{table}[b]
\caption{提案手法と比較手法により獲得した上位下位関係の比較}
\label{tab:Method1Result}
\input{01table03.txt}
\end{table}

表\ref{tab:Method1Result}に提案手法と節~\ref{sec:altermethod}に述べた比
較手法と\cite{Sumida_2006}の手法を比較した結果を示す．
表\ref{tab:Method1Result}の各列は左から順に手法の種類，リソース，SVMの
閾値，精度，SVMにより選別された上位下位関係数，およびこれらより求めた期
待される正しい上位下位関係の数を示す．{ここでは以下のような評価尺度を用いた．}
{\allowdisplaybreaks
\begin{gather*}
\begin{split}
\mbox{精度 (Precision) } & = \frac{\mbox{SVMにより選別された上位下位関係のうち正解の関係の数}}{\mbox{SVMにより選別された上位下位関係数}}\\[0.5zw]
\mbox{再現率 (Recall)} & =  \frac{\mbox{SVMにより選別された上位下位関係のうち正解の関係の数}}{\mbox{評価データ中に存在する正しい上位下位関係数}}\\[0.5zw]
\mbox{正解率 (Accuracy)} & =  \frac{\mbox{SVMにより正しく正例・負例を識別できた関係の数}}{\mbox{評価データ中の関係候補の数}}
\end{split}\\
\mbox{期待される正しい上位下位関係数} = \mbox{抽出できた上位下位関係数} \times \mbox{精度}    
\end{gather*}
}

比較手法カテゴリ，定義文
は\ref{sec:altermethod}節で記述した手法を用い，提案手法で利用し
たWikipediaと同じデータを利用し，評価サンプル数は1,000対である．また比
較手法\cite{Sumida_2006}は，Webから無作為に収集した約700~GB（HTMLタグ含
む）のWeb文書に\cite{Sumida_2006}を適用した結果を示し，評価サンプル数
は200対である．表より提案手法はWikipediaを入力源とする手法と比較し，大
量の上位下位関係を獲得することに成功した．また，提案手法と比較手
法\cite{Sumida_2006}を比べると，提案手法は小さなリソース（2.2~GBのXML文
書）から上位下位関係を抽出したにもかかわらず，より大量の上位下位関係
（933,782語を含む約174万対）を獲得できた．

\begin{figure}[b]
\begin{center}
\includegraphics{16-3ia1f5.eps}
\end{center}
    \caption{精度と再現率とのトレードオフ}
    \label{fig:rp}
\end{figure}

獲得される上位下位関係の精度については，SVMの分類時の閾値を変更すること
であげることが可能である．精度と再現率とのトレードオフの関係を
図\ref{fig:rp}に示す．横軸は再現率，縦軸は精度を表す．このグラフよ
り，SVMの閾値を大きくすることで，より信頼性の高い上位下位関係を獲得でき
ることが確認できる．例えば閾値を0.36にすると，テストデータでの精度
は90\%まで向上する（表~\ref{tab:Method1Result}）．この精度でも，他の比
較手法より獲得できた上位下位関係は多く，またこの関係に含まれる語数は
774,135語であった．

\begin{table}[p]
    \caption{各素性による効果}
    \label{tab:ResultSVM}
\input{01table04.txt}
\end{table}
\begin{figure}[p]
\begin{center}
\includegraphics{16-3ia1f6.eps}
\end{center}
    \caption{再現率—精度グラフによる素性の比較}
    \label{fig:rp_feature}
\end{figure}

次にStep2で利用した素性の効果を調べるために，各素性を除いたときの精度の
比較を表~\ref{tab:ResultSVM}に示す．表~\ref{tab:ResultSVM}の各列は左か
ら順に素性の種類，正解率，精度，再現率，F値を表す．またこのときの精度と再現
率とのトレードオフの関係を図~\ref{fig:rp_feature}に示す．各素性は本稿で
提案した全ての素性を含む素性セットをALL，ALLから素性$X$を除いた素性セッ
トを$\text{ALL-}X$とした．また（）内は素性セット$\text{ALL-}X$の精度から素性セットALLの
精度を引いた結果であり，この値が低ければ低いほど，素性$X$が提案手法の性
能の向上に役立っていることを意味する．これらの結果より，全ての素性
がStep2のフィルタリング性能の向上に役立っていることが確認できた．また表より全
ての素性が精度の向上に寄与しており，特に素性MORPHによる効果が大きいこ
とがわかった．一方，再現率の向上には素性POS，MORPH，LAYER，LCHARが寄与し
ており，特に素性LCHARが最も高い効果をもつことがわかった．


\begin{figure}[b]
\begin{center}
\includegraphics{16-3ia1f7.eps}
\end{center}
    \caption{訓練データの量による性能の変化}
    \label{fig:learning_curve}
\end{figure}

つづいて，訓練データの量を変化させたときの提案手法の性能の変化を調べた．
訓練データはStep1の結果からランダムに抽出した9,000対を利用し，1,000対から9,000対まで3,000対ごとに評価を行った．その結果を
図~\ref{fig:learning_curve}（a），（b）に示す．
図~\ref{fig:learning_curve}（a）はSVMの分類時の閾値を0に固定したグラフで，
横軸は訓練データの量，縦軸は精度，再現率，F値を示す．また
図~\ref{fig:learning_curve}（b）はSVM分類時の閾値を変化させ精度と再現率
のトレードオフを調べたグラフで，横軸は再現率，縦軸は精度を示す．
図~\ref{fig:learning_curve}（a）より訓練データの量を増やすことで再現率の
性能が向上する傾向がわかった．また図~\ref{fig:learning_curve}（b）よ
り，SVMの閾値を変化させた場合でも，訓練データのサイズを増やすことで，性
能が向上する傾向にあることが確認できた．この結果は訓練データをさらに増
やせば提案手法の性能がさらに向上する可能性を示唆している．


\subsection{考察}

提案手法により得られた上位下位関係の例を表~\ref{tab:sample}に示す．ここ
では，人手で選んだ25語についてランダムに10対の下位語を選択した．表中の
${}^\ast$は上位下位関係が誤りの例を，${}^\#$は{小説や映画などの
  フィクション上でなりたつ}架空の上位下位関係を示す．{ このよう
  な架空の上位{語\nobreak，}あるいは下位語は，フィクション自体に関する記述（感想）
  や，比喩表現として日常的に用いられることも多いため，本稿ではそれ以外
  の上位下位関係と特に区別せず，有用な上位下位関係知識とみなし
  Millerら}\cite{wordnet-book_1998}{の基準で正解か誤りかを判断し
  た．これらの架空の上位下位関係とそうでない上位下位関係を識別すること
  は今後の課題の一つである．} また表の各列は左から人手で選んだ上位語と
その下位語の例を示している．{この例より，ほとんどの上位下位関係
  は，上位語ごとに多少の精度の偏りがみられるものの正しく認識できているこ
  とが確認できる．}
  

\begin{table}[p]
    \caption{獲得した上位下位関係の例}
\label{tab:sample}
\input{01table05.txt}
\end{table}


最後に，提案手法の性能を悪化させている原因を探るべく，SVM分類器により誤
りとされた上位下位関係候補を人手で分析した．テストデータ，訓練データ以外の上
位下位関係候補からランダムに1,000対抽出し，人手で評価した．誤り分析用デー
タに提案手法を適用した結果，その精度は89.1\%であり，この内訳は内訳は陽
性が233対，陰性が658対，偽陽性が22対，偽陰性が87対であった．

\begin{table}[t]
    \caption{偽陽性の分類結果}
    \label{tab:false_positive}
\input{01table06.txt}
\end{table}
\begin{table}[t]
    \caption{陰性の分類結果}
    \label{tab:true_negative}
\input{01table07.txt}
\end{table}

表~\ref{tab:false_positive}に偽陽性の分類結果を示す．表の各列は，左から
分類の種類，数，SVMスコアの平均，例を示す．この結果から，部分全体関係が
最も頻出する誤りであるうえに，SVMスコアの平均から最も除去しにくい誤りで
あることがわかった．このような誤りを取り除くことは今後の課題である．
また，精度を低下させる原因として，属性・属性値とfacetを含む関係を上位下
位関係と誤判定する問題が多いことも分かった．ここでいうfacetとはインスタ
ンスを分類するための属性の値である．例えば，図~\ref{fig:wiki}（c）の記事
構造中の「主な紅茶ブランド」と「Wedgwood」との間に挿入されている「イギ
リス」は「Wedgwood」などのブランドを国別で分類するためのfacetであるとい
える．提案手法では自動抽出した属性リストを用いてこのような誤りの除去を
試みたが，表~\ref{tab:false_positive}より提案手法の対策だけでは不十分で
あり，新たに記事構造中の他のノードの情報を素性とするなど改善が必要であ
ることがわかった．また「プロレス技／代表的な技」のように，素性LCHARが悪
影響を及ぼしていると思われる例も存在した．

つづいて，陽性と偽陰性と判定された関係の上位語が訓練データ中に存在した
か否かを調査した．陽性では66.6\%，偽陰性では16.7\%の上位語が訓練データ
中に存在していることがわかった．未知の上位語であっても正しく判定できる
ようにするために，より上位の語や同義語の利用を考えている．

最後に，表~\ref{tab:true_negative}に陰性を人手で分類した結果を示す．表
の各列は左から誤りの分類，数を示す．ここでは，上位下位関係以外の何ら
かの概念間関係に分類できるかどうかに注目して分類した．この結果，
約80\%については何らかの概念間関係になっていることが分かった．これらに
ついては，正しく分類できれば語彙知識として有用である．本稿では上位下位
関係に注目し，二値分類の分類器を用いたが，適切な関係に分類する多値分類
を構築することで，Wikipediaの記事構造を余すことなく，語彙知識に変換する
ことができそうである．


