================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[i:0, score:0.64124] ソースドメインのデータによって分類器を学習し，ターゲットドメインに適応することを領域適応といい，近年さまざまな手法が研究されている．
[i:1, score:0.73757] しかし，語義曖昧性解消(WSD: Word Sense Disambiguation)について領域適応を行った場合，最も効果的な領域適応手法は，ソースデータとターゲットデータの性質により異なる．
[i:2, score:0.76670] 本稿ではそれらの性質から，WSDの対象単語タイプ，ソースドメインとターゲットドメインの組み合わせに対して，最も効果的な領域適応手法を決定木学習を用いて自動的に選択する手法について述べるとともに，どのような性質が効果的な領域適応手法の決定に影響を与えたかについて考察する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[i:5, score:0.58400] このとき，ドメインA（ソースドメイン）のデータによって分類器を学習し，ドメインB（ターゲットドメイン）のデータに適応することを考える．
[i:7, score:0.76024] しかし，語義曖昧性解消(Word Sense Disambiguation，WSD)について領域適応を行った場合，最も効果的な領域適応手法は，ソースドメインのデータ（ソースデータ）とターゲットドメインのデータ（ターゲットデータ）の性質により異なる．
[i:8, score:0.67096] SVM等の分類器を利用してWSDを行う際にモデルを作る単位である，WSDの対象単語タイプ，ソースドメイン，ターゲットドメインの三つ組を1ケースとして数えるとする．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[i:16, score:0.72671] まずsupervisedの領域適応は，訓練事例として少量のターゲットドメインだけでなく大量のソースドメインのデータを加えて学習を行うもので，訓練事例としてソースデータまたは少量のターゲットデータだけを利用する場合よりも，分類器を改良することを目指す．
[i:17, score:0.70844] 次のsemi-supervisedの領域適応は，ラベルつきのソースデータに加え，ラベルなしのターゲットデータを利用し，訓練事例としてソースデータだけを利用する場合よりも，分類器を改良することを目指す．
[i:35, score:0.65869] [CITE]はターゲットデータとソースデータの周辺確率を似せるようにカーネル空間を学習した後，条件確率がターゲットデータに似ているソースデータの事例をクラスタリングベースの事例選択を用いて選び，その事例を利用して領域適応を行っている．

================================================================
[section type  : proposed_method]
[section title : 領域適応手法の自動選択]
================================================================
[i:55, score:0.00000] 
-----------------------------------------------------
  [subsection title : ケースごとの領域適応手法の自動選択]
-----------------------------------------------------
  [i:lead, score:0.32095] 本論文では，ケースという単位を定義し，ケースごとに適切な領域適応を行う．
.....
  [i:60, score:0.80751] 最適な領域適応手法は，ソースデータとターゲットデータの性質により異なるが，WSDにおけるソースデータとターゲットデータの訓練事例集合は，ソースやターゲットになるコーパスのドメインだけでなく，WSDの対象単語も含めたケースごとに定まる．
  [i:63, score:0.82950] 決定木学習の素性にはソースデータとターゲットデータの性質を利用し，ラベル（教師値）には，WSDの正解率を比較した際に，そのケースにおいて最も正解率が高かった領域適応手法を用いる．
  [i:68, score:0.67239] これらのラベル付きデータの素性ベクトルには，ソースデータとターゲットデータのJS距離などを用いており，それぞれのケースの対象単語タイプ，ソースドメイン，ターゲットドメインが何なのかという情報は与えていない．
-----------------------------------------------------
  [subsection title : WSDのための領域適応手法]
-----------------------------------------------------
  [i:lead, score:0.36833] WSDのための領域適応手法として，本研究では以下に示す三つを用いる．
.....
  [i:72, score:0.80292] したがって，pairwise方式で三つ（TOとRS，TOとFD，RSとFD）の二分決定木をつくり，最終的にそれらを統合することで，ひとつのケースにつきひとつの領域適応手法を決定する．
  [i:79, score:0.71203] ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものとソースデータの両方を訓練事例にする．
  [i:81, score:0.71203] ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものとソースデータの両方を訓練事例にする．
-----------------------------------------------------
  [subsection title : 決定木学習のラベル]
-----------------------------------------------------
  [i:lead, score:0.58453] 作成する三つの二分決定木のうち，ここではTOとRSの決定木のラベル（教師値）について述べる．
.....
  [i:104, score:0.79093] ケースごとに，最もWSDの正解率がよかった手法によって，TOとRSとSameの三種類のうちのひとつのラベルをつける．
  [i:106, score:0.88586] 決定木は，ケースごとにソースデータとターゲットデータの性質から，TOかRSのどちらの手法を使って領域適応するべきかを判定していることに留意いただきたい．
  [i:110, score:0.84931] なお，TOとRSのどちらを使ってもWSDの正解率に差がないケースには，Sameラベルを使用せず，どちらかの手法に強制的に割りつけることも可能であるが，このような正解率に差がないケースが比較的多かったため(c.f. \tabref{決定木とラベル付け手法別に見たラベルの分布})，本論文ではSameラベルを使って決定木の分類性能をあげている．
-----------------------------------------------------
  [subsection title : 決定木学習の素性]
-----------------------------------------------------
  [i:lead, score:0.69042] 最適な領域適応手法はソースデータとターゲットデータの分布や距離などの性質によって異なると考えられるため，決定木には以下の24種類の合計40の素性を利用する．
.....
  [i:113, score:0.81350] また，データ1とデータ2は手法1と手法2に準じ，それぞれRSの場合にはソースデータ，TOの場合にはターゲットデータ，FDの場合にはターゲットデータに閾値以上似たソースデータが相当する．
  [i:172, score:0.88292] RSとTOの決定木：語義をタグ付けしたターゲットデータ10トークンに出現せず，全ソースデータのみに出現する語義の異なり数
  [i:174, score:0.89381] TOとFDの決定木：語義をタグ付けしたターゲットデータ10トークンに出現せず，全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークンのみに出現する語義の異なり数

================================================================
[section type  : proposed_method]
[section title : データ]
================================================================
[i:191, score:0.77882] RSの場合には，ソースデータの4/5（ソースデータの濃い灰色の部分）に加え，ターゲットデータの4/5（ターゲットデータの白の部分と薄い灰色の部分）から10トークン（白い部分）を訓練事例とする．
[i:192, score:0.75857] FDの際には，ソースデータの4/5（ソースデータの濃い灰色の部分）に関して，ターゲットデータの4/5（ターゲットデータの白の部分と薄い灰色の部分）との類似度を測り，一定以上似たデータと10トークン（白い部分）を訓練事例とする．
[i:194, score:0.74191] \tabref{tab:table0}に，白書⇔Yahoo!知恵袋でソースデータとターゲットデータを逆にしたときの領域適応別のWSDの正解率を示す．

================================================================
[section type  : proposed_method]
[section title : 決定木学習におけるラベル付きデータの作成方法と学習方法]
================================================================
[i:201, score:0.59917] 本研究では，決定木のSameラベルの付け方や，Sameラベルのついたトークンの扱い，決定木におけるケースの重みを変えて8通りの決定木を作成した．
[i:202, score:0.32445] 本節ではそれらの手法の詳細と，pairwiseに作成した複数の決定木の結果を統合して，最終的に領域適応手法を一意に定める手法について述べる．
[i:203, score:0.59930] ここでも，[REF_Sec:決定木学習のラベル]節と同様，TOとRSの決定木のラベルについて述べる．
-----------------------------------------------------
  [subsection title : Sameラベルの付け方]
-----------------------------------------------------
  [i:lead, score:0.84434] [REF_Sec:決定木学習のラベル]節で述べたように，決定木学習の教師値として，ケースごとに，最もWSDの正解率がよかった手法によって，TOとRSとSameの三種類のうちのひとつのラベルをつける．
.....
  [i:205, score:0.84434] [REF_Sec:決定木学習のラベル]節で述べたように，決定木学習の教師値として，ケースごとに，最もWSDの正解率がよかった手法によって，TOとRSとSameの三種類のうちのひとつのラベルをつける．
  [i:206, score:0.77087] このうち，SameはTOでもRSでもWSDの正解率に差がないケースに対するラベルであるが，どこまでが正解率に差がなく，どこからが差があるかという点についてはいくつかの考え方がある．
  [i:209, score:0.75987] 「カイ二乗検定」：TOとRSのWSDの正解率を比較してカイ二乗検定を行い，有意差がないものにSameをつけ，あるものにTOかRSを付与する．
-----------------------------------------------------
  [subsection title : 決定木学習におけるSameの扱い]
-----------------------------------------------------
  [i:lead, score:0.75031] 前節のように全てのケースに三つのラベルを付与したが，三つ目のラベルSameについてはTOでもRSでも差がないケースであり，決定木学習の際にいくつかの扱い方が考えられる．
.....
  [i:214, score:0.75031] 前節のように全てのケースに三つのラベルを付与したが，三つ目のラベルSameについてはTOでもRSでも差がないケースであり，決定木学習の際にいくつかの扱い方が考えられる．
  [i:217, score:0.76435] 「訓練事例からSameの事例を削除した2値分類」：Sameが付与されたケースを訓練事例から削除してTOとRSの2値分類の決定木学習を行う．
  [i:226, score:0.76285] しかし，Sameラベルがふられたケースはもともと，どちらの手法を利用してもよいケースであるため，便宜的な割り付けを行っても問題ないとの考えから，本稿では学習した決定木を用いて全てのケースに自動的にTOかRSかを割り付けた．
-----------------------------------------------------
  [subsection title : ケースによる分類とトークン数による重みづけを用いた分類]
-----------------------------------------------------
  [i:lead, score:0.23251] \tabref{tab:table1}にあるように，ケースにはたくさんの事例があるケースと，少量の事例しかないケースがある．
.....
  [i:228, score:0.76387] このため，決定木において，少量のトークン（WSDの事例）しかないケースよりも，たくさんのトークンがあるケースについて，利用する領域適応手法を正確に予測できた方が，より全体のWSDの正解率に寄与する可能性がある．
  [i:232, score:0.48669] 具体的には，トークン数による重みづけを用いた分類は，決定木学習の際，エントロピーの計算において，ひとつのケースをひとつのケースとして数えるかわりに，トークン数分のケースとして数えることで重みを付けている．
  [i:233, score:0.63921] [REF_sec:Sameラベルの付け方]--[REF_sec:ケースによる分類とトークン数による重みづけを用いた分類]節でそれぞれ二通りの選択肢があるため，本稿では全組み合わせの合計8通りの決定木を作成した．
-----------------------------------------------------
  [subsection title : 決定木の統合]
-----------------------------------------------------
  [i:lead, score:0.10717] 決定木の統合は，以下のように行った．
.....
  [i:240, score:0.60672] たとえば，テストデータが，実行時に「学習時に，TOが1ケース，RSが2ケース割り当てられた葉」に割り当てられた場合，そのテストデータは2/3の確率でRSとなる．
  [i:242, score:0.68563] 三つ巴のときに，ふたつの決定木で割りつけられた葉の確率が同率一位である場合には，RS[MATH]TOかつFD[MATH]RSなら，FD[MATH]RS[MATH]TOなのでFDを選択，というように論理的に選択された手法を選択した．
  [i:243, score:0.74476] また，三つ巴でどれも確率が等しい時など，上記のルールを利用してもどうしても領域適応手法が選べない時には，一括的に領域適応を行ったときに正解率が高い順，つまり，FD，TO，RSの順で割りつけた．

================================================================
[section type  : proposed_method]
[section title : 結果]
================================================================
[i:250, score:0.67515] \tabref{tab:table3}の決定木学習の方法の列はそれぞれ，一列目が[REF_sec:Sameラベルの付け方]節の分類に，二列目が[REF_sec:決定木学習におけるSameの扱い]節の分類に，三列目が[REF_sec:ケースによる分類とトークン数による重みづけを用いた分類]節の分類にあたる．
[i:253, score:0.88264] 「Sameを利用した3値分類」の決定木でSameが割りつけられたケースは，本来はTOでもRSでもどちらでもよいというように，二つの領域適応手法の選択肢のどちらを用いてもよいケースであるが，本稿では一括的に領域適応を行ったときに正解率が高い方の手法を用いて，最終的なWSDの平均正解率を算出した．
[i:256, score:0.71651] \tabref{tab:table3}から，決定木学習を用いて選択した手法を利用した際のWSDの平均正解率のうち，最も高いWSDの平均正解率は，「カイ二乗検定」，「訓練事例からSameの事例を削除した2値分類」，「ケースによる分類」を利用した83.52%である．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[i:259, score:0.00000] 
-----------------------------------------------------
  [subsection title : 決定木学習のラベル付きデータの作成方法と学習方法についての比較]
-----------------------------------------------------
  [i:lead, score:0.20816] 本節では，決定木学習におけるラベル付きデータの作成方法と学習方法による違いを比較する．
.....
  [i:264, score:0.60597] 8種類の決定木の作成手法のうち最も良かったのは，決定木学習のデータのSameのラベル付けには「カイ二乗検定」を利用し，決定木学習におけるSameの扱いにおいては「訓練事例からSameの事例を削除した2値分類」を利用し，決定木学習の際には「ケースによる分類」を用いた決定木学習（カイ二乗検定，2値，ケース）であった．
  [i:265, score:0.64202] このとき，決定木の正解率はそれぞれ，TOとRSの決定木は69.57%，TOとFDの決定木は64.81%，RSとFDの決定木は52.63%であった．
  [i:270, score:0.68777] WSDの領域適応の実際のタスクにおいて，本論文が提案する決定木を作る際には，ソースドメインのコーパス以外に，語義タグ付きのコーパスが少なくともひとつ以上存在する必要がある．
-----------------------------------------------------
  [subsection title : 学習された決定木についての考察]
-----------------------------------------------------
  [i:lead, score:0.70378] WSDの平均正解率が最高だった「カイ二乗検定」，「訓練事例からSameの事例を削除した2値分類」，「ケースによる分類」の決定木学習の五回の検定のうち，最も高い正解率だった決定木を付録として示し，生成に特に貢献した素性と素性値について以下に述べる．
.....
  [i:290, score:0.86795] また，TOとFDの決定木のルートノードでは，「ターゲットデータ10トークン中のMFSの，ターゲットデータに閾値以上似たソースデータ中のパーセンテージ=12.58以下」である場合に，TOが割り当てられた．
  [i:291, score:0.86127] このことにより，ターゲットデータ10トークン中に最頻出する語義が，FDの訓練事例として利用される，「ターゲットデータに一定以上似ているソースデータ」に少ない時には，TOを用いた方がよいことが分かる．
  [i:298, score:0.81859] このように同じJS距離でも素性によって似ているときにソースデータを利用した方がよかったり，そうでなかったりするのは，本決定木ではTOとFDの二手法から領域適応手法を選択しているためであると考えられる．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[i:303, score:0.94026] WSDの対象単語タイプ，ソースドメイン，ターゲットドメインの三つ組を1ケースとして数え，決定木学習を利用してケースごとに，TO，RS，FDの三種類から適切な領域適応手法を選択した．
[i:304, score:0.86997] なお，TOはソースデータを用いず，ランダムに選んだ少量のターゲットデータに語義をタグ付けしたものだけを訓練事例とする手法，RSはソースデータと語義をタグ付けした少量のターゲットデータの両方を訓練事例とする手法，FDはターゲットデータに似たソースデータと語義をタグ付けした少量のターゲットデータを訓練事例とする手法である．
[i:307, score:0.80396] また，ラベル付きデータの作成方法と学習方法を8通り試したが，このうち最もWSDの平均正解率が高かったのは，決定木学習のケースへのラベル付けの際，ふたつの領域適応手法のWSDの正解率に有意差がないケースにSameラベルを付与し，Sameの割りつけられたケースは訓練事例から取り除いて2値分類を行い，ケースごとに分類を行う決定木学習であった．

