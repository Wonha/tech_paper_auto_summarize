================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[4168] 本稿ではそれらの性質から，WSDの対象単語タイプ，ソースドメインとターゲットドメインの組み合わせに対して，最も効果的な領域適応手法を決定木学習を用いて自動的に選択する手法について述べるとともに，どのような性質が効果的な領域適応手法の決定に影響を与えたかについて考察する．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[4028] 本稿では，このケースごとに，データの性質から，最も効果的な領域適応手法を，決定木学習を用いて自動的に選択する手法について述べるとともに，どのような性質が効果的な領域適応手法の決定に影響を与えたかについて考察する．

================================================================
[section type  : related_study]
[section title : 関連研究]
================================================================
[3994] また，領域適応に悪影響を及ぼすソースデータを特定して削除することも試みているが，ソースデータの削除は事例の重み付けを行わなければ有効であるが，事例の重み付けを行った場合には有効ではないと結論づけている．

================================================================
[section type  : proposed_method]
[section title : 領域適応手法の自動選択]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : ケースごとの領域適応手法の自動選択]
-----------------------------------------------------
  [4218] 決定木学習の素性にはソースデータとターゲットデータの性質を利用し，ラベル（教師値）には，WSDの正解率を比較した際に，そのケースにおいて最も正解率が高かった領域適応手法を用いる．
-----------------------------------------------------
  [subsection title : WSDのための領域適応手法]
-----------------------------------------------------
  [3094] ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものとソースデータの両方を訓練事例にする．
-----------------------------------------------------
  [subsection title : 決定木学習のラベル]
-----------------------------------------------------
  [4274] なお，TOとRSのどちらを使ってもWSDの正解率に差がないケースには，Sameラベルを使用せず，どちらかの手法に強制的に割りつけることも可能であるが，このような正解率に差がないケースが比較的多かったため(c.f. \tabref{決定木とラベル付け手法別に見たラベルの分布})，本論文ではSameラベルを使って決定木の分類性能をあげている．
-----------------------------------------------------
  [subsection title : 決定木学習の素性]
-----------------------------------------------------
  [3616] TOとFDの決定木：語義をタグ付けしたターゲットデータ10トークンに出現せず，全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークンのみに出現する語義の異なり数

================================================================
[section type  : proposed_method]
[section title : データ]
================================================================
[3792] ここで，タグつきターゲットデータが手に入ったと仮定して，supervisedの学習を5分割交差検定を用いて行ったselfと，ターゲットデータに対して，ソースデータだけで5分割交差検定を用いて学習を行ったSource OnlyについてのWSDも行い，その正解率も参考として示した．

================================================================
[section type  : proposed_method]
[section title : 決定木学習におけるラベル付きデータの作成方法と学習方法]
================================================================
[3302] 本節ではそれらの手法の詳細と，pairwiseに作成した複数の決定木の結果を統合して，最終的に領域適応手法を一意に定める手法について述べる．
-----------------------------------------------------
  [subsection title : Sameラベルの付け方]
-----------------------------------------------------
  [3631] [REF_Sec:決定木学習のラベル]節で述べたように，決定木学習の教師値として，ケースごとに，最もWSDの正解率がよかった手法によって，TOとRSとSameの三種類のうちのひとつのラベルをつける．
-----------------------------------------------------
  [subsection title : 決定木学習におけるSameの扱い]
-----------------------------------------------------
  [4173] しかし，Sameラベルがふられたケースはもともと，どちらの手法を利用してもよいケースであるため，便宜的な割り付けを行っても問題ないとの考えから，本稿では学習した決定木を用いて全てのケースに自動的にTOかRSかを割り付けた．
-----------------------------------------------------
  [subsection title : ケースによる分類とトークン数による重みづけを用いた分類]
-----------------------------------------------------
  [3518] [REF_sec:Sameラベルの付け方]--[REF_sec:ケースによる分類とトークン数による重みづけを用いた分類]節でそれぞれ二通りの選択肢があるため，本稿では全組み合わせの合計8通りの決定木を作成した．
-----------------------------------------------------
  [subsection title : 決定木の統合]
-----------------------------------------------------
  [3628] また，三つ巴でどれも確率が等しい時など，上記のルールを利用してもどうしても領域適応手法が選べない時には，一括的に領域適応を行ったときに正解率が高い順，つまり，FD，TO，RSの順で割りつけた．

================================================================
[section type  : proposed_method]
[section title : 結果]
================================================================
[4336] 「Sameを利用した3値分類」の決定木でSameが割りつけられたケースは，本来はTOでもRSでもどちらでもよいというように，二つの領域適応手法の選択肢のどちらを用いてもよいケースであるが，本稿では一括的に領域適応を行ったときに正解率が高い方の手法を用いて，最終的なWSDの平均正解率を算出した．

================================================================
[section type  : conclusion]
[section title : 考察]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : 決定木学習のラベル付きデータの作成方法と学習方法についての比較]
-----------------------------------------------------
  [3875] 8種類の決定木の作成手法のうち最も良かったのは，決定木学習のデータのSameのラベル付けには「カイ二乗検定」を利用し，決定木学習におけるSameの扱いにおいては「訓練事例からSameの事例を削除した2値分類」を利用し，決定木学習の際には「ケースによる分類」を用いた決定木学習（カイ二乗検定，2値，ケース）であった．
-----------------------------------------------------
  [subsection title : 学習された決定木についての考察]
-----------------------------------------------------
  [4663] このように同じJS距離でも素性によって似ているときにソースデータを利用した方がよかったり，そうでなかったりするのは，本決定木ではTOとFDの二手法から領域適応手法を選択しているためであると考えられる．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[4816] また，ラベル付きデータの作成方法と学習方法を8通り試したが，このうち最もWSDの平均正解率が高かったのは，決定木学習のケースへのラベル付けの際，ふたつの領域適応手法のWSDの正解率に有意差がないケースにSameラベルを付与し，Sameの割りつけられたケースは訓練事例から取り除いて2値分類を行い，ケースごとに分類を行う決定木学習であった．

