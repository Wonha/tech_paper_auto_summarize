本論文では，ケースという単位を定義し，ケースごとに適切な領域適応を行う．
本論文におけるケースとは，SVM等の分類器を利用してWSDを行う際にモデルを作る単位である．
WS Dの分類器は，対象単語タイプ，ソースドメイン，ターゲットドメインの三つ組に対してひとつ作られるので，この三つ組をケースと呼ぶ．
例えば，ケースを（対象単語タイプ，ソースドメイン，ターゲットドメイン）の順に書くと，（出る，新聞，Yahoo!知恵袋），（出る，Yahoo!知恵袋，新聞），（手，Yahoo!知恵袋，新聞）は全て別のケースである．
最適な領域適応手法は，ソースデータとターゲットデータの性質により異なるが，WSDにおけるソースデータとターゲットデータの訓練事例集合は，ソースやターゲットになるコーパスのドメインだけでなく，WSDの対象単語も含めたケースごとに定まる．
したがって，ケースごとに適切な領域適応手法を自動的に選択し，その手法を適宜用いて領域適応を行えば，どれかひとつの手法を用いるよりも，WSDの性能が向上することが予想される．
このため，決定木学習を用いて，ケースごとに領域適応手法の自動選択を行う．
決定木学習の素性にはソースデータとターゲットデータの性質を利用し，ラベル（教師値）には，WSDの正解率を比較した際に，そのケースにおいて最も正解率が高かった領域適応手法を用いる．
決定木学習を用いるのは，どのような性質が最適な領域適応手法の決定に影響を与えるのかを明示的に示すことができる上，少量の訓練事例から学習しても十分な分類精度が得られるからである．
また，n個の領域適応手法から選択する際には，pairwise方式で[MATH]通りの二分決定木をつくり，最終的にそれらを統合することで，ひとつのケースにつきひとつの領域適応手法を決定する．
なお，本論文で扱う領域適応手法は，どれもsupervisedの領域適応であるため，最終的にどの領域適応手法が選択されるかは不明な段階でも，先にターゲットデータに対する少量の語義のタグ付けが必要である．
本論文では，一般公開されているYahoo!知恵袋，白書，新聞の三つのタグ付きコーパスから，144ケースのラベル付きデータを作成して決定木学習を行った．
これらのラベル付きデータの素性ベクトルには，ソースデータとターゲットデータのJS距離などを用いており，それぞれのケースの対象単語タイプ，ソースドメイン，ターゲットドメインが何なのかという情報は与えていない．
WSDの領域適応の問題が生じた場合には，問題のケースごとに，本論文で叙述するように素性ベクトルを作成して決定木への入力とし，決定木によって最適な領域適応手法を選択する．
本論文では決定木学習の有効性を144ケースの交差検定によって示す．
WSDのための領域適応手法として，本研究では以下に示す三つを用いる．
したがって，pairwise方式で三つ（TOとRS，TOとFD，RSとFD）の二分決定木をつくり，最終的にそれらを統合することで，ひとつのケースにつきひとつの領域適応手法を決定する．
以降，決定木の用例の単位であるケースと区別するために，WSDの用例の単位をトークンと呼ぶ．
WSDの対象単語をwとすると，トークンはwの用例と等しい．
それぞれソースドメインとターゲットドメインのコーパス中のwの用例が，ソースデータとターゲットデータの訓練事例であるため，ケースごとにソースデータとターゲットデータの数や性質は異なる．
TO: Target Only．
ソースデータを用いず，ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものだけを訓練事例にする．
RS: Random Sampling．
ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものとソースデータの両方を訓練事例にする．
FD:フィルタリングによる削除．
ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものとソースデータの両方を訓練事例にする．
このときソースデータは，フィルタリングによりターゲットデータにある一定の閾値以上似ているデータのみを用いる．
FDでは以下の手順を取る．
なお，ターゲットデータやソースデータのトークンは，後述するWSDの素性を要素としたベクトルとして表されている．
ターゲットデータのトークン[MATH]について，全ソースデータのトークン[MATH]とのコサイン類似度[MATH]を計算する．
ソースデータのトークン[MATH]について，それぞれ最も自身と近いターゲットデータのトークン[MATH]を特定する．
ソースデータのトークン[MATH]について[MATH]との類似度[MATH]をもとに，訓練事例とするかどうかを判定する．
ここで，[MATH]が0.8以上のソースデータ[MATH]を訓練事例に含めた．
なお[MATH]を計算する際，重みづけや正規化は行っていない．
なお，追加するターゲットデータ数は常に10トークンとした．
分類器としてはマルチクラス対応のSVM (libsvm)を使用した．
カーネルは予備実験の結果，線形カーネルが最も高い正解率を示したため，これを採用した．
また，学習の素性には，[CITE]で使われている以下の17素性を用いた．
WSDの対象単語の前後二語までの形態素の表記（4素性）
WSDの対象単語の前後二語までの品詞（4素性）
WSDの対象単語の前後二語までの品詞の細分類（4素性）
WSDの対象単語の前後二語までの分類コード（4素性）
係り受け（1素性）
対象単語が名詞の場合はその名詞が係る動詞
対象単語が動詞の場合はその動詞のヲ格の格要素
分類語彙表の分類コードには[CITE]を使用した．
作成する三つの二分決定木のうち，ここではTOとRSの決定木のラベル（教師値）について述べる．
作成する決定木によって，TOとRSを，それぞれTOとFD，またはRSとFDに読み替えていただきたい．
ケースごとに，最もWSDの正解率がよかった手法によって，TOとRSとSameの三種類のうちのひとつのラベルをつける．
これらのつけ方は[REF_sec:Sameラベルの付け方]節で述べる．
決定木は，ケースごとにソースデータとターゲットデータの性質から，TOかRSのどちらの手法を使って領域適応するべきかを判定していることに留意いただきたい．
TO: RSよりTOを使用した方がWSDの正解率が良いケース
RS: TOよりRSを使用した方がWSDの正解率が良いケース
Same: TOとRSのどちらを使ってもWSDの正解率に差がないケース
なお，TOとRSのどちらを使ってもWSDの正解率に差がないケースには，Sameラベルを使用せず，どちらかの手法に強制的に割りつけることも可能であるが，このような正解率に差がないケースが比較的多かったため(c.f. \tabref{決定木とラベル付け手法別に見たラベルの分布})，本論文ではSameラベルを使って決定木の分類性能をあげている．
最適な領域適応手法はソースデータとターゲットデータの分布や距離などの性質によって異なると考えられるため，決定木には以下の24種類の合計40の素性を利用する．
なお，手法1と手法2は作成する二分決定木によって，RSとTO，またはRSとFD，またはTOとFDが相当する．
また，データ1とデータ2は手法1と手法2に準じ，それぞれRSの場合にはソースデータ，TOの場合にはターゲットデータ，FDの場合にはターゲットデータに閾値以上似たソースデータが相当する．
手法1のシミュレーションの正解率
手法2のシミュレーションの正解率
ふたつの正解率の比(([REF_1])/([REF_2]))
データ1のトークン数
データ2のトークン数
ふたつのデータのトークン数の比(([REF_4])/([REF_5]))
データ1の語義数
データ2の語義数
辞書中の語義数
データ1のMFS（Most Frequent Sense:データ中最も頻出する語義）のトークン数
データ2のMFSのトークン数
MFSの語義がデータ1とデータ2で同じか
データ1のMFSのパーセンテージ(([REF_10])/([REF_4]))
データ2のMFSのパーセンテージ(([REF_11]9/([REF_5]))
データ2のMFSのデータ1中でのパーセンテージ(([REF_11])/([REF_4]))
データ1のMFSのデータ2中のパーセンテージ(([REF_10])/([REF_5]))
データ1とデータ2の語義タグのジェンセン・シャノン・ダイバージェンス（JS距離）
データ1とデータ2の間のWSDの素性ごとの分布のJS距離
データ1とデータ2の間の素性ごとのJS距離を足しあわせたもの（([REF_18])を17種類足しあわせた値）
データ1とデータ2の素性をひとつの単位としたときのJS距離
新語義の数
データ1とデータ2で共通する語義数
データ1とデータ2で共通する語義の，データ1中のパーセンテージ(([REF_22])/([REF_4]))
データ1とデータ2で共通する語義の，データ2中のパーセンテージ(([REF_22])/([REF_5]))
なお，([REF_1])と([REF_2])のシミュレーションの正解率としては，手法ごとに以下を用いる．
RS：ソースデータのシミュレーションの正解率．
ソースデータで分類器を学習し，語義をタグ付けしたターゲットデータ10トークンで評価した正解率
TO：TOのシミュレーションの正解率．
ターゲットデータ10トークンに語義をタグ付けし，Leave One Out法で評価を行った際の正解率
FD：FDのシミュレーションの正解率．
ターゲットデータに閾値以上似たソースデータで分類器を学習し，語義をタグ付けしたターゲットデータ10トークンで評価した正解率
また，([REF_4])と([REF_5])のトークン数には，手法ごとに以下を用いる．
ただし，([REF_13])〜([REF_16])，([REF_23])，([REF_24])において，TOのデータ数は10トークンとする．
RS：全ソースデータのトークン数
TO：全ターゲットデータのトークン数
FD：全ソースデータの4/5（5分割交差検定のうち一試行）のうち，ターゲットデータに閾値以上似ているトークンの数
また，([REF_7])と([REF_8])の語義数には，手法ごとに以下を用いる．
RS：全ソースデータ中に出現する語義の異なり数
TO：語義をタグ付けした10トークンのターゲットデータ中に出現する語義の異なり数
FD：ソースデータの全トークンの4/5のうち，ターゲットデータに閾値以上似たデータに出現する語義の異なり数
また，([REF_10])と([REF_11])，([REF_12])のMFSには，手法ごとに以下を用いる．
RS：全ソースデータ中の，全ソースデータのMFSを語義に持つトークンの数
TO：語義をタグ付けしたターゲットデータ10トークンの中の，語義をタグ付けしたターゲットデータ10トークンのMFSを語義に持つトークンの数
FD：「全ソースデータの4/5のうち，ターゲットデータに閾値以上似たデータ」中の，「全ソースデータの4/5のうち，ターゲットデータに閾値以上似たデータ」のMFSを語義に持つトークンの数
さらに，([REF_17])〜([REF_20])のJS距離は，カルバック・ライブラー・ダイバージェンスを対称にしたものであり，H(P)が分布Pのエントロピーであるとき，以下の式で与えられる．
また，([REF_17])では，
RS：全ソースデータの4/5
TO：ターゲットデータの10トークン
FD：全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークン
の語義タグの分布間のJS距離を用いたが，([REF_18])のJS距離では，
RS：全ソースデータ
TO：全ターゲットデータ
FD：全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークン
の間のWSDの素性（形態素情報など17種類．
[REF_sec:item17]節参照）の素性ごとの分布のJS距離を，([REF_19])のJS距離では，これらのデータのWSDの素性（形態素情報など17種類）をつなげて，ひとつの単位としたものの分布のJS距離を用いた．
これは，17種類全ての素性が等しいときにだけ，同じ要素と考えてJS距離を求めるものである．
また，([REF_22])の共通語義も，([REF_17])のJS距離の際のデータのうち，手法に対応したふたつのデータに出現した語義の異なり数である．
また，([REF_21])の新語義の数は，
RSとTOの決定木：語義をタグ付けしたターゲットデータ10トークンに出現せず，全ソースデータのみに出現する語義の異なり数
RSとFDの決定木：全ソースデータの4/5のうち，ターゲットデータに閾値以上似たデータに出現せず，全ソースデータのみに出現する語義の異なり数
TOとFDの決定木：語義をタグ付けしたターゲットデータ10トークンに出現せず，全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークンのみに出現する語義の異なり数
になる．
決定木作成アルゴリズムにはC4.5 [CITE]を利用し，二分決定木を作成した．
また，五分割交差検定を行った．
決定木作成の枝刈りの閾値は訓練事例の1/4を開発用データとした予備実験により最適化した．
なお，このとき決定木作成の閾値にはノードのエントロピーの値を使用し，0, 0.1, 0.2..
.というように0.1きざみで試した．
閾値の最適化の際に，最高の正解率の決定木の閾値が複数ある場合には，決定木がより小さいときの閾値を採用した．
実験には，現代日本語書き言葉均衡コーパス（BCCWJコーパス）[CITE]の白書のデータとYahoo!知恵袋のデータ，またRWCコーパスの毎日新聞コーパス[CITE]の三つのデータを利用し，ソースデータとターゲットデータを変えることで，全部で6通りの領域適応を行った．
これらのデータには岩波国語辞典[CITE]の語義が付与されている．
これらのコーパス中の多義語のうち，ソースデータおよびターゲットデータ中にともに50トークン以上存在する単語を実験対象とした．
WSDを行う単語の異なり数は，白書⇔Yahoo!知恵袋：24白書⇔新聞：22 Yahoo!知恵袋⇔新聞：26であり，最終的なケースの数は，28単語，合計144のケースとなった．
ターゲットコーパス別に見たケースの最小，最大，平均トークン数を\tabref{tab:table1}に示す．
また，実験には岩波国語辞典の小分類の語義を採用した．
全WSDの対象単語の語義数ごとの内訳を\tabref{tab:The list of target words}に示す．
また，領域適応によるWSDの実験には五分割交差検定を用いた．
RSのときのこの様子を\figref{fig:two-1}に示す．
RSの場合には，ソースデータの4/5（ソースデータの濃い灰色の部分）に加え，ターゲットデータの4/5（ターゲットデータの白の部分と薄い灰色の部分）から10トークン（白い部分）を訓練事例とする．
FDの際には，ソースデータの4/5（ソースデータの濃い灰色の部分）に関して，ターゲットデータの4/5（ターゲットデータの白の部分と薄い灰色の部分）との類似度を測り，一定以上似たデータと10トークン（白い部分）を訓練事例とする．
テストデータは，ターゲットデータの残りの1/5（黒い部分）である．
\tabref{tab:table0}に，白書⇔Yahoo!知恵袋でソースデータとターゲットデータを逆にしたときの領域適応別のWSDの正解率を示す．
これらの結果は，すべてのトークンごとの平均の正解率（マイクロ平均）である．
ここで，タグつきターゲットデータが手に入ったと仮定して，supervisedの学習を5分割交差検定を用いて行ったselfと，ターゲットデータに対して，ソースデータだけで5分割交差検定を用いて学習を行ったSource OnlyについてのWSDも行い，その正解率も参考として示した．
\tabref{tab:table0}から，使用するコーパスによって効果の出る手法が異なることが分かる．
また，\tabref{ソースデータとターゲットデータのコーパス別に見たケースごとの最適な領域適応手法の分布}に，ソースデータとターゲットデータのコーパス別に見たケースごとの最適な領域適応手法の分布を示す．
この表において，例えば「RSとTO」は，RSとTOが同率一位であることを表す．
この表から，最適な領域適応手法は，コーパスごとよりも，ケースごとに異なることが分かる．
本研究では，決定木のSameラベルの付け方や，Sameラベルのついたトークンの扱い，決定木におけるケースの重みを変えて8通りの決定木を作成した．
本節ではそれらの手法の詳細と，pairwiseに作成した複数の決定木の結果を統合して，最終的に領域適応手法を一意に定める手法について述べる．
ここでも，[REF_Sec:決定木学習のラベル]節と同様，TOとRSの決定木のラベルについて述べる．
作成する決定木によって，WSDの手法は読み替えていただきたい．
[REF_Sec:決定木学習のラベル]節で述べたように，決定木学習の教師値として，ケースごとに，最もWSDの正解率がよかった手法によって，TOとRSとSameの三種類のうちのひとつのラベルをつける．
このうち，SameはTOでもRSでもWSDの正解率に差がないケースに対するラベルであるが，どこまでが正解率に差がなく，どこからが差があるかという点についてはいくつかの考え方がある．
本稿では，以下の二通りのSameの定義を考え，両方について実験を行う．
「同じもの」：TOとRSのWSDの正解率が全く等しいものにSameをつけ，それ以外にTOかRSを付与する．
「カイ二乗検定」：TOとRSのWSDの正解率を比較してカイ二乗検定を行い，有意差がないものにSameをつけ，あるものにTOかRSを付与する．
なお，カイ二乗検定の有意水準は0.05を利用した．
「同じもの」では，全く同じ正解率のケースだけを，TOとRSに差がないケースと考え，「カイ二乗検定」では，カイ二乗検定により有意差がないケースを，TOとRSに差がないケースと考えている．
決定木とラベル付け手法別に見たラベルの分布を\tabref{決定木とラベル付け手法別に見たラベルの分布}に示す．
また，コーパスとラベル付け手法別に見たラベルが割りつけられたケースの数と合計の単語タイプ数を\tabref{tab:The number of cases}に示す．
前節のように全てのケースに三つのラベルを付与したが，三つ目のラベルSameについてはTOでもRSでも差がないケースであり，決定木学習の際にいくつかの扱い方が考えられる．
本稿では，決定木学習の際，以下の二通りのSameの扱い方で実験を行う．
「Sameを利用した3値分類」：TO，RS，Sameの3値分類の決定木学習とテストを行う．
「訓練事例からSameの事例を削除した2値分類」：Sameが付与されたケースを訓練事例から削除してTOとRSの2値分類の決定木学習を行う．
なお，テストには全ケースを利用する．
\figref{fig:three}に，「訓練事例からSameの事例を削除した2値分類」のときの決定木学習の五分割交差検定の様子を示す．
全体が144ケースあり，最終的に訓練データとして用いるケースはそのうちのTOかRSのラベルをもつケースである．
「同じもの」を使用するときは129ケースがこれにあたり，「カイ二乗検定」を用いるときには69ケースがこれにあたる（濃い灰色の部分）．
五分割交差検定の一試行において，この訓練データとなる濃い灰色の部分の4/5（白い部分）で訓練を行い，全体のケースの144ケースのうちの1/5（薄い灰色の部分）でテストを行う．
これを五回交差して行うことで決定木学習の五分割交差検定を行った．
「訓練事例からSameの事例を削除した2値分類」を利用してテストを行う場合，Sameラベルがふられたケースに正解はない．
そのため，決定木のノードにおけるラベルの確からしさの度合いなどの閾値をもうけることで，「Sameを利用した3値分類」のSameのようなどちらの手法を利用してもよいという結果を出力することも考えられる．
しかし，Sameラベルがふられたケースはもともと，どちらの手法を利用してもよいケースであるため，便宜的な割り付けを行っても問題ないとの考えから，本稿では学習した決定木を用いて全てのケースに自動的にTOかRSかを割り付けた．
\tabref{tab:table1}にあるように，ケースにはたくさんの事例があるケースと，少量の事例しかないケースがある．
このため，決定木において，少量のトークン（WSDの事例）しかないケースよりも，たくさんのトークンがあるケースについて，利用する領域適応手法を正確に予測できた方が，より全体のWSDの正解率に寄与する可能性がある．
本稿では，以下のようにケースによる分類のほかに，トークン数による重みづけを行う分類についても実験を行った．
「ケースによる分類」：全てのケースに同等の重みがあるとして決定木学習を行う．
「トークン数による重みづけを用いた分類」：ケースごとにケース中のトークン数の重みをつけて決定木学習を行う．
具体的には，トークン数による重みづけを用いた分類は，決定木学習の際，エントロピーの計算において，ひとつのケースをひとつのケースとして数えるかわりに，トークン数分のケースとして数えることで重みを付けている．
[REF_sec:Sameラベルの付け方]--[REF_sec:ケースによる分類とトークン数による重みづけを用いた分類]節でそれぞれ二通りの選択肢があるため，本稿では全組み合わせの合計8通りの決定木を作成した．
決定木の統合は，以下のように行った．
pairwiseの性質上，三つの決定木が三つとも同じ方法がよいと答えることはなく，答えが2:1に分かれるか，三つ巴になるはずである．
このうち，2:1に分かれるときは，かならず2つの決定木が出した答えが理論的に一番良くなるため，その答えを選択すればよい．
手法1[MATH]手法2のとき手法1のほうがよい手法であるとすると，例えば，TO[MATH]RSかつ，FD[MATH]RSかつTO[MATH]FDであれば，TO[MATH]FD[MATH]RSなので，TOを選択する．
次に，三つ巴のときには，事例が割りつけられた葉についている確率を比較し，一番高い確率のところに割り付けた．
確率は，「学習時にその葉に割りつけられたその手法のケース数/学習時に，その葉に割りつけられた全ケース数」として計算した．
たとえば，テストデータが，実行時に「学習時に，TOが1ケース，RSが2ケース割り当てられた葉」に割り当てられた場合，そのテストデータは2/3の確率でRSとなる．
三つ巴の場合には，この確率で比較し，最も高い確率の手法を割り当てた．
三つ巴のときに，ふたつの決定木で割りつけられた葉の確率が同率一位である場合には，RS[MATH]TOかつFD[MATH]RSなら，FD[MATH]RS[MATH]TOなのでFDを選択，というように論理的に選択された手法を選択した．
また，三つ巴でどれも確率が等しい時など，上記のルールを利用してもどうしても領域適応手法が選べない時には，一括的に領域適応を行ったときに正解率が高い順，つまり，FD，TO，RSの順で割りつけた．
\tabref{tab:table2}に，もともとの手法を一括的に用いた際のWSDの平均正解率を示す．
なお，144のケースには合計232,116のWSDのトークンが含まれており，本稿の平均正解率はそれらのトークンの平均の正解率（マイクロ平均）である．
\tabref{tab:table2}からTO，RS，FDのうち，最も良い正解率はFDの82.27%であることが分かる．
\tabref{tab:table3}に，[REF_sec:決定木学習におけるラベル付きデータの作成方法と学習方法]節の決定木を用いて自動的にケースごとに選択した手法を利用した際のWSDの平均正解率を示す．
なお，選択の仕方は，決定木学習による選択の8種類と，Golden Answerの一種類の合計9種類である．
ここで，決定木学習による選択の8種類は，[REF_sec:Sameラベルの付け方]--[REF_sec:ケースによる分類とトークン数による重みづけを用いた分類]節でのそれぞれ二通りの選択肢による，全組み合わせに対応する．
\tabref{tab:table3}の決定木学習の方法の列はそれぞれ，一列目が[REF_sec:Sameラベルの付け方]節の分類に，二列目が[REF_sec:決定木学習におけるSameの扱い]節の分類に，三列目が[REF_sec:ケースによる分類とトークン数による重みづけを用いた分類]節の分類にあたる．
それぞれ，3値と2値は「Sameを利用した3値分類」と「訓練事例からSameの事例を削除した2値分類」を，ケースとトークンは「ケースによる分類」と「トークン数による重みづけを用いた分類」を示す．
なお，Golden Answerは，決定木学習を用いる代わりに，ラベルとなっているふたつの領域適応のうち，WSDの正解率の高い領域適応手法をケースごとに人手で選択して，WSDの平均正解率を求めた値であり，upper boundである．
「Sameを利用した3値分類」の決定木でSameが割りつけられたケースは，本来はTOでもRSでもどちらでもよいというように，二つの領域適応手法の選択肢のどちらを用いてもよいケースであるが，本稿では一括的に領域適応を行ったときに正解率が高い方の手法を用いて，最終的なWSDの平均正解率を算出した．
「訓練事例からSameの事例を削除した2値分類」を利用した場合は，[REF_sec:決定木学習におけるSameの扱い]節で述べたように，学習した決定木を用いて自動的に全てのケースを分類した．
そのため，Sameの割りつけられたケースも，決定木によって選択された手法を利用して最終的なWSDの平均正解率を算出した．
\tabref{tab:table3}から，決定木学習を用いて選択した手法を利用した際のWSDの平均正解率のうち，最も高いWSDの平均正解率は，「カイ二乗検定」，「訓練事例からSameの事例を削除した2値分類」，「ケースによる分類」を利用した83.52%である．
\tabref{tab:table2}の，個別の手法を用いた際の最高の正解率，FDの82.27%よりも正解率が高いため，決定木を利用して適切な領域適応手法を利用した方が，個々の領域適応手法を使った時よりも正解率が上がることが分かる．
またこのとき，カイ二乗検定により十分な有意差が認められた．
