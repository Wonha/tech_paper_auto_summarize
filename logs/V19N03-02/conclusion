考察 \label{Sec:考察}

\subsection{決定木学習のラベル付きデータの作成方法と学習方法についての比較}

本節では，決定木学習におけるラベル付きデータの作成方法と学習方法による違いを比較する．
まずSameラベルの付け方について比べると，決定木学習におけるSameの扱いを「訓練事例からSameの事例を削除した2値分類」
にしたときには「同じもの」が「カイ二乗検定」よりもよいが，「Sameを利用した3値分類」にしたときには
「カイ二乗検定」が「同じもの」よりもよい
ことが分かる．


また決定木学習におけるSameの扱いについて比べると，
「訓練事例からSameの事例を削除した2値分類」のほうがいつも「Sameを利用した3値分類」よりもよいことが分かる．


さらにケースによる分類とトークン数による重みづけを用いた分類について比べると，
「ケースによる分類」のほうがいつも「トークン数による重みづけを用いた分類」よりもよいことが分かる．


8種類の決定木の作成手法のうち最も良かったのは，
決定木学習のデータのSameのラベル付けには「カイ二乗検定」を利用し，
決定木学習におけるSameの扱いにおいては「訓練事例からSameの事例を削除した2値分類」を利用し，
決定木学習の際には「ケースによる分類」を用いた決定木学習（カイ二乗検定，2値，ケース）であった．

このとき，決定木の正解率はそれぞれ，TOとRSの決定木は69.57\%，
TOとFDの決定木は64.81\%，
RSとFDの決定木は52.63\%であった．

また，上記の実験は，コーパスを考慮しない五分割交差検定であるため，語義タグがついて
いないコーパスに対しての性能を見るために，ケースをコーパスごとに分け，コーパスごとの
交差検定を行った．上記の実験で最高の正解率だった（カイ二乗検定，2値，ケース）の決定
木学習の手法で実験を行ったところ，WSDの平均正解率は82.32\%となった．FD の82.27\%よ
りも高いが，カイ二乗検定による有意差は得られなかった．利用したコーパスは3つであるた
め，144ケースのおおよそ三分割交差検定を行うこととなっており，訓練事例数が足りず，決
定木の十分な分類性能が得られなかったためだと考えられる．
WSDの領域適応の実際のタスクにおいて，本論文が提案する決定木を
作る際には，ソースドメインのコーパス以外に，語義タグ付きのコーパスが
少なくともひとつ以上存在する必要がある．その中にターゲットドメインのコー
パスを含めずに済むかどうかは不明である．しかし，上記の実験から，含めな
い場合にもある程度の効果は得られると考える．あるいはターゲットドメイン
のコーパスに決定木を作るのに必要な程度の語義タグをつけることも考え
られる．


\subsection{学習された決定木についての考察}

WSDの平均正解率が最高だった「カイ二乗検定」，「訓練事例からSameの事例を削除した2値分類」，「ケースによる分類」の決定木学習の五回の検定のうち，最も高い正解率だった決定木を
付録として示し，生成に特に貢献した素性と素性値について以下に述べる．

まず，TOとRSの決定木のルートノードでは，「ふたつの正解率の比=0.70以上」がnoのときTOが割り当てられた．
これは「the Other のシミュレーションの正解率/ TOのシミュレーションの正解率」の割合が0.70以下であれば，
TOが割り当てられたということである．
つまり，10トークンのターゲットデータに語義をタグ付けし，Leave One Out法で評価を行った際の正解率のほうが，
ソースデータで分類器を学習し，
10トークンのターゲットデータに語義をタグ付けしたもので評価した正解率よりも高いときには
TOが割り当てられたということに等しい．
このことから，10ケースの語義をタグ付けしたターゲットデータによるシミュレーションの予測が，
最適な領域適応の手法を予想する強力な手がかりになることが分かる．

次に，決定木の深さが1のノードでは，
「JS 距離（WSD の対象単語の一つ前の形態素）=0.61以上」のときにTOが選ばれている．
このことから，
WSD の対象単語の一つ前の形態素に関する素性の分布がソースデータとターゲットデータで異なっているときには，
ソースデータを訓練事例に利用せず，ターゲットデータの10トークンに語義をタグ付けして訓練事例にした方がよいことが分かる．
JS距離が大きいのは素性の分布が異なっていることを意味し，逆にJS距離が小さいのは素性の分布が似通っていることを意味する．
WSDにおいて鍵となる素性の分布が遠く，ソースデータが十分に似ていない時には，
ソースデータを利用しない方がよいため，JS距離が大きいときにはTO になりやすいと考えられる．
同様に素性の分布が近く，ソースデータが十分に似ている時には，
ソースデータを利用した方がよいため，
JS距離が小さいときにはRSになりやすいと考えられる．

また，RSとFDの決定木のルートノードでは，「ソースデータの数/ターゲットデータに一定以上似ているソースデータの数=186.85以上」
のときFDが割り当てられた．FDは，ターゲットデータに閾値以上似た
ソースデータだけを訓練事例に利用する手法であるため，ターゲットデータに閾値以上似ていないソースデータが多量にあるときには，
全ソースデータではなく，ターゲットデータに似ているデータだけを利用すればよいことが分かる．
このことから，ターゲットデータに十分似ていないデータを足しすぎると，誤った学習が行われてしまうことが推察できる．

次に，決定木の深さが1のノードでは，「JS 距離（WSD の対象単語の二つ前の形態素）=0.74以上」がyesであればFDが，
noであればRSが割り当てられた．このことから，
WSD の対象単語の二つ前の形態素に関する素性の分布がソースデータ
と「ターゲットデータに一定以上似ているソースデータ」で似ているときには，
ソースデータを訓練事例にすべて利用した方がよく，似ていない時には，
ソースデータを利用せずに語義をタグ付けしたターゲットデータの10トークンを訓練事例にした方がよいことが分かる．
本決定木では，TOとRSの決定木の深さ1のノードと同様に，素性の分布が似ているときに，ソースデータを利用した
ほうがよいという結果になっている．

また，TOとFDの決定木のルートノードでは，
「ターゲットデータ10トークン中のMFSの，ターゲットデータに閾値以上似たソースデータ中のパーセンテージ=12.58以下」である場合に，
TOが割り当てられた．このことにより，ターゲットデータ10トークン中に最頻出する語義が，
FDの訓練事例として利用される，「ターゲットデータに一定以上似ているソースデータ」に少ない時には，
TOを用いた方がよいことが分かる．このことから，
二つのデータの語義タグが似ていないときは，ソースデータから
訓練事例を一切足すことなく，ターゲットデータだけで学習した方がよいと考えられる．

次に，決定木の深さが1のノードでは，「JS距離（WSDの対象単語の一つ後の形態素の分類語彙表の値）=0.15以下」であれば，
TOが割り当てられた．WSD の対象単語の一つ後の形態素の分類語彙表の値に関する素性の分布が，ターゲットデータ
と「ターゲットデータに一定以上似ているソースデータ」で似ているときには，
ソースデータを訓練事例に一切利用せず，ターゲットデータを10トークンタグ付けして訓練事例にした方がよいことが分かる．
ここで注目したいのは，
これまでの決定木とは逆に，素性の分布が似ているときに，ソースデータを利用しない
ほうがよいという結果になっていることである．
TOとFDの決定木全体を見てみると，ノードにJS距離についての条件は四度現れる．そのうち，二回は素性の分布が似ているときに，ソースデータを利用しない
ほうがよいという結果であり，残りの二回は逆に素性の分布が似ているときに，ソースデータを利用した
ほうがよいという結果になっている．
このように同じJS距離でも素性によって似ているときにソースデータを利用した方がよかったり，そうでなかったりするのは，
本決定木ではTOとFDの二手法から
領域適応手法を選択しているためであると考えられる．全てのソースデータを訓練事例に含めるRSと異なり，
FDでは，ターゲットデータに一定以上似ているソースデータを訓練事例に含めるため，
素性によって似ていたらソースデータを使用すべきものと，ソースデータを使用すべきでないものに分かれているのではないかと考えられる．
「WSDの対象単語の一つ後の形態素の分類語彙表の値」は後者であることが決定木から読みとれる．


まとめ \label{Sec:まとめ}

語義曖昧性解消 (WSD; Word Sense Disambiguation) について領域適応を行った場合，
ソースデータとターゲットデータのデータの性質により，最も効果的な領域適応手法が異なる．
そのため本稿では，決定木学習を用いてソースデータとターゲットデータの性質
から，最も効果的な領域適応手法を自動的に選択する手法について述べた．
WSDの対象単語タイプ，ソースドメイン，ターゲットドメインの三つ組を
1ケースとして数え，決定木学習を利用してケースごとに，
TO，RS，FDの三種類から
適切な領域適応手法を選択した．
なお，TOはソースデータを用いず，ランダムに選んだ少量のターゲットデータに語義をタグ付けしたものだけを
訓練事例とする手法，
RSはソースデータと語義をタグ付けした少量のターゲットデータの両方を訓練事例とする手法，
FDはターゲットデータに似たソースデータと語義をタグ付けした少量のターゲットデータを訓練事例とする手法である．
三つの手法から領域適応手法を一意に選ぶため，pairwise方式に三つの決定木を作成し，最後に統合して用いた．
ケースごとに自動的に選択された手法を用いて領域適応を行うことで，もともとの手法を一括的に使った時に比べ，
WSDの正解率が有意に向上した．

また，ラベル付きデータの作成方法と学習方法を8通り試したが，
このうち最もWSDの平均正解率が高かったのは，
決定木学習のケースへのラベル付けの際，ふたつの領域適応手法の
WSDの正解率に有意差がないケースにSameラベルを付与し，
Sameの割りつけられたケースは訓練事例から取り除いて
2値分類を行い，ケースごとに分類を行う決定木学習であった．

作成した決定木から，語義をタグ付けした少量のターゲットデータによるシミュレーションの予測や，
同ターゲットデータの最頻出語義の「ターゲットデータに一定以上似ているソースデータ」中の出現率，
ソースデータの数と「ターゲットデータに一定以上似ているソースデータ」の数の比が，
最適な領域適応の手法を予想する強力な手がかりになることが分かった．

\acknowledgment

文部科学省科学研究費補助金特定領域研究「現代日本語書き言葉均衡コーパス」の助成により行われた．
ここに，謹んで御礼申し上げる．また，本論文の内容の一部は，5th International Joint Conference on Natural Language Processingで発表した
ものである\cite{article22}.


\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Agirre \BBA\ de~Lacalle}{Agirre \BBA\
  de~Lacalle}{2008}]{article5}
Agirre, E.\BBACOMMA\ \BBA\ de~Lacalle, O.~L. \BBOP 2008\BBCP.
\newblock \BBOQ On Robustness and Domain Adaptation using SVD for Word Sense
  Disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of the 22nd International Conference on
  Computational Linguistics}, \mbox{\BPGS\ 17--24}.

\bibitem[\protect\BCAY{Agirre \BBA\ de~Lacalle}{Agirre \BBA\
  de~Lacalle}{2009}]{article6}
Agirre, E.\BBACOMMA\ \BBA\ de~Lacalle, O.~L. \BBOP 2009\BBCP.
\newblock \BBOQ Supervised Domain Adaption for WSD.\BBCQ\
\newblock In {\Bem Proceedings of the 12th Conference of the European Chapter
  of the Association of Computational Linguistics}, \mbox{\BPGS\ 42--50}.

\bibitem[\protect\BCAY{Asch \BBA\ Daelemans}{Asch \BBA\
  Daelemans}{2010}]{article11}
Asch, V.~V.\BBACOMMA\ \BBA\ Daelemans, W. \BBOP 2010\BBCP.
\newblock \BBOQ Using Domain Similarity for Performance Estimation.\BBCQ\
\newblock In {\Bem Proceedings of the 2010 Workshop on Domain Adaptation for
  Natural Language Processing, ACL 2010}, \mbox{\BPGS\ 31--36}.

\bibitem[\protect\BCAY{Blitzer, McDonald, \BBA\ Pereira}{Blitzer
  et~al.}{2006}]{article17}
Blitzer, J., McDonald, R., \BBA\ Pereira, F. \BBOP 2006\BBCP.
\newblock \BBOQ Domain Adaptation with Structural Coppespondence
  Learning.\BBCQ\
\newblock In {\Bem Proceedings of the 2006 Conference on Empirical Methods in
  Natural Language Processing}, \mbox{\BPGS\ 120--128}.

\bibitem[\protect\BCAY{Chan \BBA\ Ng}{Chan \BBA\ Ng}{2006}]{article2}
Chan, Y.~S.\BBACOMMA\ \BBA\ Ng, H.~T. \BBOP 2006\BBCP.
\newblock \BBOQ Estimating Class Priors in Domain Adaptation for Word Sense
  Disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of the 21st International Conference on
  Computational Linguistics and 44th Annual Meeting of the Association for
  Computational Linguistics}, \mbox{\BPGS\ 89--96}.

\bibitem[\protect\BCAY{Chan \BBA\ Ng}{Chan \BBA\ Ng}{2007}]{article3}
Chan, Y.~S.\BBACOMMA\ \BBA\ Ng, H.~T. \BBOP 2007\BBCP.
\newblock \BBOQ Domain Adaptation with Active Learning for Word Sense
  Disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of the 45th Annual Meeting of the Association of
  Computational Linguistics}, \mbox{\BPGS\ 49--56}.

\bibitem[\protect\BCAY{Daum\'{e}}{Daum\'{e}}{2007}]{article4}
Daum\'{e}, III, H. \BBOP 2007\BBCP.
\newblock \BBOQ Frustratingly Easy Domain Adaptation.\BBCQ\
\newblock In {\Bem Proceedings of the 45th Annual Meeting of the Association of
  Computational Linguistics}, \mbox{\BPGS\ 256--263}.

\bibitem[\protect\BCAY{Daum\'{e}, Kumar, \BBA\ Saha}{Daum\'{e}
  et~al.}{2010}]{article12}
Daum\'{e}, III, H., Kumar, A., \BBA\ Saha, A. \BBOP 2010\BBCP.
\newblock \BBOQ Frustratingly Easy Semi-Supervised Domain Adaptation.\BBCQ\
\newblock In {\Bem Proceedings of the 2010 Workshop on Domain Adaptation for
  Natural Language Processing, ACL 2010}, \mbox{\BPGS\ 23--59}.

\bibitem[\protect\BCAY{Hashida, Isahara, Tokunaga, Hashimoto, Ogino, \BBA\
  Kashino}{Hashida et~al.}{1998}]{article19}
Hashida, K., Isahara, H., Tokunaga, T., Hashimoto, M., Ogino, S., \BBA\
  Kashino, W. \BBOP 1998\BBCP.
\newblock \BBOQ The RWC text databases.\BBCQ\
\newblock In {\Bem Proceedings of The First International Conference on
  Language Resource and Evaluation}, \mbox{\BPGS\ 457--461}.

\bibitem[\protect\BCAY{Jiang \BBA\ Zhai}{Jiang \BBA\ Zhai}{2007}]{article7}
Jiang, J.\BBACOMMA\ \BBA\ Zhai, C. \BBOP 2007\BBCP.
\newblock \BBOQ Instance Weighting for Domain Adaptation in NLP.\BBCQ\
\newblock In {\Bem Proceedings of the 45th Annual Meeting of the Association of
  Computational Linguistics}, \mbox{\BPGS\ 264--271}.

\bibitem[\protect\BCAY{Komiya \BBA\ Okumura}{Komiya \BBA\
  Okumura}{2011}]{article22}
Komiya, K.\BBACOMMA\ \BBA\ Okumura, M. \BBOP 2011\BBCP.
\newblock \BBOQ Automatic Determination of a Domain Adaptation Method for Word
  Sense Disambiguation Using Decision Tree Learning.\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Joint Conference on
  Natural Language Processing, IJCNLP 2011}, \mbox{\BPGS\ 1107--1115}.

\bibitem[\protect\BCAY{Maekawa}{Maekawa}{2008}]{article18}
Maekawa, K. \BBOP 2008\BBCP.
\newblock \BBOQ Balanced Corpus of Contemporary Written Japanese.\BBCQ\
\newblock In {\Bem Proceedings of the 6th Workshop on Asian Language Resources
  (ALR)}, \mbox{\BPGS\ 101--102}.

\bibitem[\protect\BCAY{McClosky, Charniak, \BBA\ Johnson}{McClosky
  et~al.}{2010}]{article20}
McClosky, D., Charniak, E., \BBA\ Johnson, M. \BBOP 2010\BBCP.
\newblock \BBOQ Automatic Domain Adaptation for Parsing.\BBCQ\
\newblock In {\Bem Proceedings of the 2010 Annual Conference of the North
  American Chapter of the Association for Computational Linguistics},
  \mbox{\BPGS\ 28--36}.

\bibitem[\protect\BCAY{Quinlan}{Quinlan}{1993}]{book2}
Quinlan, J.~R. \BBOP 1993\BBCP.
\newblock {\Bem C4.5: Programs for Machine Learning}.
\newblock Morgan Kaufmann Publishers.

\bibitem[\protect\BCAY{Raina, Battle, Lee, Packer, \BBA\ Ng}{Raina
  et~al.}{2007}]{article15}
Raina, R., Battle, A., Lee, H., Packer, B., \BBA\ Ng, A.~Y. \BBOP 2007\BBCP.
\newblock \BBOQ Self-taught Learning: Transfer Learning from Unlabeled
  Data.\BBCQ\
\newblock In {\Bem ICML '07: Proceedings of the 24th international conference
  on Machine learning}, \mbox{\BPGS\ 759--766}.

\bibitem[\protect\BCAY{Sugiyama \BBA\ Okumura}{Sugiyama \BBA\
  Okumura}{2009}]{article21}
Sugiyama, K.\BBACOMMA\ \BBA\ Okumura, M. \BBOP 2009\BBCP.
\newblock \BBOQ Semi-supervised Clustering for Word Instances and Its Effect on
  Word Sense Disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of the 10th International Conference on
  Intelligent Text Processing and Computational Linguistics (CICLing 2009)},
  \mbox{\BPGS\ 266--279}.

\bibitem[\protect\BCAY{Tur}{Tur}{2009}]{article16}
Tur, G. \BBOP 2009\BBCP.
\newblock \BBOQ Co-adaptation: Adaptive Co-training for Semi-supervised
  Learning.\BBCQ\
\newblock In {\Bem Proceedings of the IEEE International Conference on
  Acoustics, Speech and Signal Processing, 2009. ICASSP 2009}, \mbox{\BPGS\
  3721--3724}.

\bibitem[\protect\BCAY{Zhong, Fan, Peng, Zhang, Ren, Turaga, \BBA\
  Verscheure}{Zhong et~al.}{2009}]{article14}
Zhong, E., Fan, W., Peng, J., Zhang, K., Ren, J., Turaga, D., \BBA\ Verscheure,
  O. \BBOP 2009\BBCP.
\newblock \BBOQ Cross Domain Distribution Adaptation via Kernel Mapping.\BBCQ\
\newblock In {\Bem Proceedings of the 15th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, \mbox{\BPGS\ 1027--1036}.

\bibitem[\protect\BCAY{張本\JBA 宮尾\JBA 辻井}{張本 \Jetal }{2010}]{article10}
張本佳子\JBA 宮尾祐介\JBA 辻井潤一 \BBOP 2010\BBCP.
\newblock
  構文解析の分野適応における精度低下要因の分析及び分野間距離の測定手法.\
\newblock \Jem{言語処理学会　第16回年次大会発表論文集}, \mbox{\BPGS\ 27--30}.

\bibitem[\protect\BCAY{国立国語研究所}{国立国語研究所}{1964}]{book1}
国立国語研究所 \BBOP 1964\BBCP.
\newblock \Jem{分類語彙表}.
\newblock 秀英出版.

\bibitem[\protect\BCAY{西尾\JBA 岩淵\JBA 水谷}{西尾 \Jetal }{1994}]{book3}
西尾実\JBA 岩淵悦太郎\JBA 水谷静夫 \BBOP 1994\BBCP.
\newblock \Jem{岩波国語辞典 第五版}.
\newblock 岩波書店.

\end{thebibliography}

