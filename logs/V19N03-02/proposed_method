領域適応手法の自動選択
\label{Sec:領域適応手法の自動選択}


\subsection{ケースごとの領域適応手法の自動選択}
\label{Sec:ケースごとの領域適応手法の自動選択}

本論文では，ケースという単位を定義し，ケースごとに適切な領域適応を行う．本論文にお
けるケースとは，SVM等の分類器を利用してWSDを行う際にモデルを作る単位である．WS
Dの分類器は，対象単語タイプ，ソースドメイン，ターゲットドメインの三つ組に対してひと
つ作られるので，この三つ組をケースと呼ぶ．例えば，ケースを（対象単語タイプ，ソースド
メイン，ターゲットドメイン）の順に書くと，（出る，新聞，Yahoo!知恵袋），（出る，Yahoo!
知恵袋，新聞），（手，Yahoo!知恵袋，新聞）は全て別のケースである．


最適な領域適応手法は，ソースデータとターゲットデータの性質により異なるが，WSDにお
けるソースデータとターゲットデータの訓練事例集合は，ソースやターゲットになるコーパス
のドメインだけでなく，WSDの対象単語も含めたケースごとに定まる．したがって，
ケースごとに適切な領域適応手法を自動的に選択し，その手法を適宜用いて領域適応を行えば，
どれかひとつの手法を用いるよりも，WSDの性能が向上することが予想される．このため，決定木学習を用いて，
ケースごとに領域適応手法の自動選択を行う．
決定木学習の素性にはソースデータとターゲ
ットデータの性質を利用し，ラベル（教師値）には，WSDの正解率を比較した際に，そのケ
ースにおいて最も正解率が高かった領域適応手法を用いる．
決定木学習を用いるのは，どのような性質が最適な領域適応手法の決定に影響を与えるのかを明示的に
示すことができる上，少量の訓練事例から学習しても十分な分類精度が得られるからである．
また，n個の領域適応手法から選択する際には，pairwise方式で$_{n}C_{2}$通りの二分決定木をつくり，最終的にそれらを
統合することで，ひとつのケースにつきひとつの領域適応手法を決定する\footnote{
	pairwise方式を利用するのは，多値分類では十分な分類性能が得られなかったためである．この原因は，入手できた事例数が144ケースという少数であったためだと思われる．}．

なお，本論文で扱う領域適応手法は，どれもsupervisedの領域適応であるため，最終的にど
の領域適応手法が選択されるかは不明な段階でも，先にターゲットデータに対する少量の語義
のタグ付けが必要である．

本論文では，一般公開されているYahoo!知恵袋，白書，新聞の三つのタグ付きコーパスか
ら，144ケースのラベル付きデータを作成して決定木学習を行った．これらのラベル付きデータ
の素性ベクトルには，ソースデータとターゲットデータのJS距離などを用いており，それぞれ
のケースの対象単語タイプ，ソースドメイン，ターゲットドメインが何なのかという情報は与え
ていない．WSD の領域適応の問題が生じた場合には，問題のケースごとに，本論文で叙述する
ように素性ベクトルを作成して決定木への入力とし，決定木によって最適な領域適応手法を選択
する．本論文では決定木学習の有効性を144ケースの交差検定によって示す．


\subsection{WSDのための領域適応手法}
\label{sec:item17}

WSDのための領域適応手法として，本研究では以下に示す三つ
を用いる．したがって，pairwise方式で三つ（TOとRS，TOとFD，RSとFD）の二分決定木
をつくり，最終的にそれらを
統合することで，ひとつのケースにつきひとつの領域適応手法を決定する．

以降，決定木の用例の単位であるケースと区別するために，WSDの用例の単位をトークンと
呼ぶ．WSDの対象単語をwとすると，トークンはwの用例と等しい．それぞれソースドメイン
とターゲットドメインのコーパス中のwの用例が，ソースデータとターゲットデータの訓練事
例であるため，ケースごとにソースデータとターゲットデータの数や性質は異なる．

\begin{itemize}
\item\ TO: Target Only．ソースデータを用いず，ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものだけを訓練事例にする．
\item\ RS: Random Sampling．ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものとソースデータの両方を訓練事例にする．
\item\ FD: フィルタリングによる削除．ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものとソースデータの両方を訓練事例にする．
このときソースデータは，フィルタリングによりターゲットデータにある一定の閾値以上似ているデータのみを用いる．
\end{itemize}

FDでは以下の手順を取る．なお，ターゲットデータやソースデータのトークンは，後述する
WSDの素性を要素としたベクトルとして表されている．

\begin{itemize}
\item[(1)] ターゲットデータのトークン$\forall t_{i}\in T$について，全ソースデータのトークン$\forall s_{j}\in S$とのコサイン類似度$sim_{i,j}$を計算する．
\item[(2)] ソースデータのトークン$\forall s_{j}\in S$について，それぞれ最も自身と近いターゲットデータのトークン$ t_{j,nearest}$を特定する．
\item[(3)] ソースデータのトークン$\forall s_{j}\in S$について$t_{j,nearest}$との類似度$sim_{j,nearest}$をもとに，訓練事例とするかどうかを判定する．

ここで，$sim_{j,nearest}$が0.8以上のソースデータ$s_{j}$を訓練事例に含めた．なお$sim_{i,j}$を計算
する際，重みづけや正規化は行っていない．
\end{itemize}

なお，追加するターゲットデータ数は常に10トークンとした．

分類器としてはマルチクラス対応のSVM (libsvm) を使用した．
カーネルは予備実験の結果，線形カーネルが最も高い正解率を示したため，これを採用した．また，学習の素性には，
\cite{article21}で使われている以下の17素性を用いた．

\begin{itemize}
\item WSDの対象単語の前後二語までの形態素の表記（4素性）
\item WSDの対象単語の前後二語までの品詞（4素性）
\item WSDの対象単語の前後二語までの品詞の細分類（4素性）
\item WSDの対象単語の前後二語までの分類コード（4素性）
\item 係り受け（1素性）
	\begin{itemize}
	\item 対象単語が名詞の場合はその名詞が係る動詞
	\item 対象単語が動詞の場合はその動詞のヲ格の格要素
	\end{itemize}
\end{itemize}

分類語彙表の分類コードには\cite{book1}を使用した．



\subsection{決定木学習のラベル}
\label{Sec:決定木学習のラベル}

作成する三つの二分決定木のうち，ここではTOとRSの決定木のラベル（教師値）について述べる．
作成する決定木によって，TOとRSを，それぞれTOとFD，
またはRSとFDに読み替えていただきたい．

ケースごとに，最もWSDの正解率がよかった手法によって，TOとRSとSameの三種類のうちのひとつのラベルをつける．
これらのつけ方は\ref{sec:Sameラベルの付け方}節で述べる．
決定木は，ケースごとにソースデータとターゲットデータの性質から，TOかRSのどちらの手法を使って領域適応するべきかを
判定していることに留意いただきたい\footnote{
	TOとFDの決定木なら，ラベルはTOとFD，Sameから選ぶことになり，
TOかFDのどちらの手法を使って領域適応するべきかを判定することになる．また，
RSとFDの決定木なら，ラベルはRSとFD，Sameから選ぶことになり，
RSかFDのどちらの手法を使って領域適応するべきかを判定する．}．

\begin{itemize}
\item\ TO: RSよりTOを使用した方がWSDの正解率が良いケース
\item\ RS: TOよりRSを使用した方がWSDの正解率が良いケース
\item\ Same: TOとRSのどちらを使ってもWSDの正解率に差がないケース
\end{itemize}

なお，TOとRSのどちらを使ってもWSDの正解率に差がないケースには，Sameラベルを
使用せず，どちらかの手法に強制的に割りつけることも可能であるが，このような正解率に差
がないケースが比較的多かったため (c.f. \tabref{決定木とラベル付け手法別に見たラベルの分布})，本論文ではSameラベルを使って決定木の分
類性能をあげている．



\subsection{決定木学習の素性}

最適な領域適応手法はソースデータとターゲットデータの分布や距離などの性質によって異なると考えられるため，
決定木には以下の24種類の合計40の素性を利用する\footnote{
	41番目の素性として品詞を追加した実験も行ったが，正解率が低下したため，最終的には含めなかった．}．
なお，手法1と手法2は作成する二分決定木によって，
RSとTO，またはRSとFD，またはTOとFDが相当する．
また，データ1とデータ2は手法1と手法2に準じ，それぞれRSの場合にはソースデータ，TOの場合にはターゲットデータ，
FDの場合にはターゲットデータに閾値以上似たソースデータが相当する．

\begin{enumerate}
\item 手法1のシミュレーションの正解率 \label{1}
\item 手法2のシミュレーションの正解率 \label{2}
\item ふたつの正解率の比 ((\ref{1})/(\ref{2}))
\item データ1のトークン数 \label{4}
\item データ2のトークン数  \label{5}
\item ふたつのデータのトークン数の比 ((\ref{4})/(\ref{5}))
\item データ1の語義数 \label{7}
\item データ2の語義数 \label{8}
\item 辞書中の語義数 
\item データ1のMFS（Most Frequent Sense:データ中最も頻出する語義）のトークン数 \label{10}
\item データ2のMFSのトークン数 \label{11}
\item MFSの語義がデータ1とデータ2で同じか \label{12}
\item データ1のMFSのパーセンテージ ((\ref{10})/(\ref{4})) \label{13}
\item データ2のMFSのパーセンテージ ((\ref{11}9/(\ref{5})) \label{14}
\item データ2のMFSのデータ1中でのパーセンテージ ((\ref{11})/(\ref{4})) \label{15}
\item データ1のMFSのデータ2中のパーセンテージ ((\ref{10})/(\ref{5})) \label{16}
\item データ1とデータ2の語義タグのジェンセン・シャノン・ダイバージェンス（JS距離） \label{17}
\item データ1とデータ2の間のWSDの素性ごとの分布のJS距離 \label{18}
\item データ1とデータ2の間の素性ごとのJS距離を足しあわせたもの（(\ref{18})を17種類足しあわせた値） \label{19}
\item データ1とデータ2の素性をひとつの単位としたときのJS距離 \label{20}
\item 新語義の数 \label{21}
\item データ1とデータ2で共通する語義数 \label{22}
\item データ1とデータ2で共通する語義の，データ1中のパーセンテージ ((\ref{22})/(\ref{4})) \label{23}
\item データ1とデータ2で共通する語義の，データ2中のパーセンテージ ((\ref{22})/(\ref{5})) \label{24}
\end{enumerate}

なお，(\ref{1}) と (\ref{2}) のシミュレーションの正解率としては，手法ごとに以下を用いる．
\begin{itemize}
\item RS：ソースデータのシミュレーションの正解率．ソースデータで分類器を学習し，語義をタグ付けしたターゲットデータ10トークンで評価した正解率
\item TO：TOのシミュレーションの正解率．ターゲットデータ10トークンに語義をタグ付けし，
Leave One Out法で評価を行った際の正解率
\item FD：FDのシミュレーションの正解率．ターゲットデータに閾値以上似たソースデータで分類器を学習し，語義をタグ付けしたターゲットデータ10トークン
で評価した正解率
\end{itemize}

また，(\ref{4}) と (\ref{5}) のトークン数には，手法ごとに以下を用いる．ただし，(\ref{13})〜(\ref{16})，(\ref{23})，(\ref{24}) 
において，TOのデータ数は10トークンとする．
\begin{itemize}
\item RS：全ソースデータのトークン数
\item TO：全ターゲットデータのトークン数
\item FD：全ソースデータの4/5（5分割交差検定のうち一試行）のうち，ターゲットデータに閾値以上似ているトークンの数
\end{itemize}

また，(\ref{7}) と (\ref{8}) の語義数には，手法ごとに以下を用いる．
\begin{itemize}
\item RS：全ソースデータ中に出現する語義の異なり数
\item TO：語義をタグ付けした10トークンのターゲットデータ中に出現する語義の異なり数
\item FD：ソースデータの全トークンの4/5のうち，ターゲットデータに閾値以上似たデータに出現する語義の異なり数
\end{itemize}

また，(\ref{10}) と (\ref{11})，(\ref{12}) のMFSには，手法ごとに以下を用いる．
\begin{itemize}
\item RS：全ソースデータ中の，全ソースデータのMFSを語義に持つトークンの数
\item TO：語義をタグ付けしたターゲットデータ10トークンの中の，語義をタグ付けしたターゲットデータ10トークンのMFSを語義に持つ
トークンの数
\item FD：「全ソースデータの4/5のうち，ターゲットデータに閾値以上似たデータ」中の，
「全ソースデータの4/5のうち，ターゲットデータに閾値以上似たデータ」のMFSを語義に持つトークンの数
\end{itemize}

さらに，(\ref{17})〜(\ref{20}) のJS距離は，カルバック・ライブラー・ダイバージェンスを対称に
したものであり，H(P) が分布Pのエントロピーであるとき，以下の式で与えられる．
\begin{equation}
D_{JSD}(P||Q)=H(\frac{1}{2}P+\frac{1}{2}Q)-\frac{1}{2}H(P)-\frac{1}{2}H(Q)\label{eq1}
\end{equation}

また，(\ref{17})では，
\begin{itemize}
\item RS：全ソースデータの4/5
\item TO：ターゲットデータの10トークン
\item FD：全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークン
\end{itemize}
の語義タグの分布間のJS距離を用いたが，(\ref{18}) のJS距離では，
\begin{itemize}
\item RS：全ソースデータ
\item TO：全ターゲットデータ
\item FD：全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークン
\end{itemize}
の間のWSDの素性（形態素情報など17種類．\ref{sec:item17}節参照）
の素性ごとの分布のJS距離を，(\ref{19}) のJS距離では，これらのデータのWSDの素性（形態素情報など17種類）をつなげて，
ひとつの単位としたものの分布のJS距離を用いた．
これは，17種類全ての素性が等しいときにだけ，同じ要素と考えてJS距離を求めるものである．
また，(\ref{22}) の共通語義も，(\ref{17}) のJS距離の際のデータのうち，手法に対応したふたつのデータに出現した語義の異なり数である．

また，(\ref{21}) の新語義の数は，
\begin{itemize}
\item RSとTOの決定木：語義をタグ付けしたターゲットデータ10トークンに出現せず，全ソースデータのみに出現する語義の異なり数
\item RSとFDの決定木：全ソースデータの4/5のうち，ターゲットデータに閾値以上似たデータに出現せず，全ソースデータのみに出現する語義の異なり数
\item TOとFDの決定木：語義をタグ付けしたターゲットデータ10トークンに出現せず，全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークン
のみに出現する語義の異なり数
\end{itemize}
になる．


決定木作成アルゴリズムにはC4.5 \cite{book2}を利用し，二分決定木を作成した．
また，五分割交差検定を行った．
決定木作成の枝刈りの閾値は訓練事例の1/4を開発用データとした予備実験により最適化した．
なお，このとき決定木作成の閾値にはノードのエントロピーの値を使用し，0, 0.1, 0.2...というように0.1きざみで試した．
閾値の最適化の際に，最高の正解率の決定木の閾値が複数ある場合には，決定木がより小さいときの閾値を採用した．



データ \label{Sec:データ}

実験には，現代日本語書き言葉均衡コーパス（BCCWJコーパス）\cite{article18}の白書のデータとYahoo! 知恵袋のデータ，
またRWCコーパスの毎日新聞コーパス\cite{article19}の三つのデータを利用し，
ソースデータとターゲットデータを変えることで，全部で6通りの領域適応を行った．
これらのデータには岩波国語辞典\cite{book3}の語義が付与されている．
これらのコーパス中の多義語のうち，ソースデータおよびターゲットデータ中にともに50トークン以上存在する単語を実験対象とした．
WSDを行う単語の異なり数は，白書⇔Yahoo! 知恵袋：24　白書⇔新聞：22　Yahoo! 知恵袋⇔新聞：26であり，
最終的なケースの数は，28単語，合計144のケースとなった．
ターゲットコーパス別に見たケースの最小，最大，平均トークン数を\tabref{tab:table1}に示す．
また，実験には岩波国語辞典の小分類の語義を採用した．
全WSDの対象単語の語義数ごとの内訳を\tabref{tab:The list of target words}に示す．

\begin{table}[b] 
\caption{ターゲットコーパス別に見たケースの最小，最大，平均トークン数}
\label{tab:table1}
\input{02table01.txt}
\end{table}
\begin{table}[b]
\caption{全WSDの対象単語の語義数ごとの内訳}
\label{tab:The list of target words}
\input{02table02.txt}
\end{table}


また，領域適応によるWSDの実験には五分割交差検定を用いた．
    RSのときのこの様子を\figref{fig:two-1}
に示す．RSの場合には，ソースデータの4/5（ソースデータの濃い灰色の部分）に加え，ター
ゲットデータの4/5（ターゲットデータの白の部分と薄い灰色の部分）から10トークン（白い
部分）を訓練事例とする．FDの際には，ソースデータの4/5（ソースデータの濃い灰色の部分）
に関して，ターゲットデータの4/5（ターゲットデータの白の部分と薄い灰色の部分）との類似
度を測り，一定以上似たデータと10トークン（白い部分）を訓練事例とする．テストデータは，
ターゲットデータの残りの1/5（黒い部分）である．

\begin{figure}[b]
 \begin{center}
  \includegraphics{19-3ia945f1.eps}
 \end{center}
 \caption{RSによるWSDの実験の五分割交差検定}
     \label{fig:two-1}
\end{figure}
\begin{table}[b]
\begin{center}
\hangcaption{Yahoo! 知恵袋と白書でソースデータとターゲットデータを逆にしたときの領域適応別のWSDの正解率} \label{tab:table0}
\input{02table03.txt}
\end{table}



\tabref{tab:table0}に，白書⇔Yahoo! 知恵袋でソースデータとターゲットデータを逆にしたときの領域適応
別のWSD の正解率を示す．
これらの結果は，すべてのトークンごとの平均の正解率（マイクロ平均）である．
ここで，タグつきターゲットデータが手に入ったと仮定して，supervisedの学習を5分割交差検定を用いて行った
selfと，ターゲットデータに対して，ソースデータだけで5分割交差検定を用いて学習を行ったSource Onlyについて
のWSDも行い，その正解率も参考として示した．
\tabref{tab:table0}から，使用するコーパスによって効果の出る手法が異なることが分かる．
また，\tabref{ソースデータとターゲットデータのコーパス別に見たケースごとの最適な領域適応手法の分布}に，ソー
スデータとターゲットデータのコーパス別に見たケースごとの最適な領域適応手法の分布を示
す．この表において，例えば「RSとTO」は，RSとTOが同率一位であることを表す．この
表から，最適な領域適応手法は，コーパスごとよりも，ケースごとに異なることが分かる．


\begin{table}[t]
\caption{ソースデータとターゲットデータのコーパス別に見たケースごとの最適な領域適応手法の分布}
\label{ソースデータとターゲットデータのコーパス別に見たケースごとの最適な領域適応手法の分布}
\input{02table04.txt}
\end{table}

決定木学習におけるラベル付きデータの作成方法と学習方法
\label{sec:決定木学習におけるラベル付きデータの作成方法と学習方法}

本研究では，決定木のSameラベルの付け方や，Sameラベルのついたトークンの扱い，決定
木におけるケースの重みを変えて8通りの決定木を作成した．本節ではそれらの手法の詳細と，
pairwiseに作成した複数の決定木の結果を統合して，最終的に領域適応手法を一意に定める手法
について述べる．

ここでも，\ref{Sec:決定木学習のラベル}節と同様，TOとRSの決定木のラベルについて述べる．
作成する決定木によって，WSDの手法は読み替えていただきたい．


\subsection{Sameラベルの付け方}
\label{sec:Sameラベルの付け方}

\ref{Sec:決定木学習のラベル}節で述べたように，決定木学習の教師値として，ケースごとに，最もWSD の正解率が
よかった手法によって，TO とRS とSame の三種類のうちのひとつのラベルをつける．このう
ち，Same はTO でもRS でもWSD の正解率に差がないケースに対するラベルであるが，
どこまでが正解率に差がなく，どこからが差があるかという点については
いくつかの考え方がある．本稿では，以下の二通りのSameの定義を考え，両方について実験を行う．

\begin{itemize}
\item\ 「同じもの」：TOとRSのWSDの正解率が全く等しいものにSameをつけ，
それ以外にTOかRSを付与する．
\item\ 「カイ二乗検定」：TOとRSのWSDの正解率を比較してカイ二乗検定を
行い，有意差がないものにSameをつけ，あるものにTOかRSを付与する．
なお，カイ二乗検定の有意水準は0.05を利用した．
\end{itemize}

「同じもの」では，全く同じ正解率のケースだけを，TOとRSに差がないケースと考え，「カイ二乗検定」では，
カイ二乗検定により有意差がないケースを，TOとRSに差がないケースと考えている．

決定木とラベル付け手法別に見たラベルの分布を\tabref{決定木とラベル付け手法別に見たラベルの分布}に示す．
また，コーパスとラベル付け手法別に見たラベルが割りつけられたケースの数と
合計の単語タイプ数を\tabref{tab:The number of cases} 
に示す．

\begin{table}[t]
\caption{決定木とラベル付け手法別に見たラベルの分布}
\label{決定木とラベル付け手法別に見たラベルの分布}
\input{02table05.txt}
\end{table}
\begin{table}[t]
\caption{コーパスとラベル付け手法別に見たラベルが割りつけられたケースの数と
合計の単語タイプ数} 
\label{tab:The number of cases}
\input{02table06.txt}
\end{table}



\subsection{決定木学習におけるSameの扱い}
\label{sec:決定木学習におけるSameの扱い}

前節のように全てのケースに三つのラベルを付与したが，三つ目のラベルSameについては
TOでもRSでも差がないケースであり，決定木学習の際に
いくつかの扱い方が考えられる．
本稿では，決定木学習の際，以下の二通りのSameの扱い方で実験を行う．

\begin{itemize}
\item\ 「Sameを利用した3値分類」：TO，RS，Sameの3値分類の決定木学習とテストを行う．
\item\ 「訓練事例からSameの事例を削除した2値分類」：Sameが付与されたケースを
訓練事例から削除してTOとRSの2値分類の決定木学習を行う．
なお，テストには 全ケースを利用する．
\end{itemize}

\figref{fig:three}に，「訓練事例からSameの事例を削除した2値分類」のときの
決定木学習の五分割交差検定の様子を示す．
全体が144ケースあり，最終的に訓練データとして用いる
ケースはそのうちのTOかRSのラベルをもつケースである．「同じもの」を使用するときは129ケースがこれにあたり，
「カイ二乗検定」を用いるときには69ケースがこれにあたる（濃い灰色の部分）．
五分割交差検定の一試行において，この訓練データとなる濃い灰色の部分の4/5（白い部分）で訓練を行い，全体の
ケースの144ケースのうちの1/5（薄い灰色の部分）でテストを行う．
これを五回交差して行うことで決定木学習の五分割交差検定を行った．

\begin{figure}[t]
 \begin{center}
  \includegraphics{19-3ia945f2.eps}
  \end{center}
 \caption{訓練事例からSameの事例を削除した2値分類のときの決定木学習の五分割交差検定}
 \label{fig:three}
\end{figure}

「訓練事例からSameの事例を削除した2値分類」を利用してテストを行う場合，
Sameラベルがふられたケースに正解はない．
そのため，決定木のノードにおけるラベルの確からしさの度合いなどの閾値をもうけることで，
「Sameを利用した3値分類」のSameのようなどちらの手法を利用してもよい
という結果を出力することも考えられる．しかし，Sameラベルがふられたケースはもともと，
どちらの手法を利用してもよい
ケースであるため，便宜的な割り付けを行っても問題ないとの考えから，本稿では学習した決定木を用いて
全てのケースに自動的にTOかRSかを割り付けた．


\subsection{ケースによる分類とトークン数による重みづけを用いた分類}
\label{sec:ケースによる分類とトークン数による重みづけを用いた分類}

\tabref{tab:table1}にあるように，ケースにはたくさんの事例があるケースと，少量の事例しかないケースがある．
このため，決定木において，少量のトークン（WSDの事例）しかないケースよりも，たくさんのトークンがあるケースについて，
利用する領域適応手法を正確に予測できた方が，より全体のWSDの正解率に寄与する可能性がある．
本稿では，以下のようにケースによる分類のほかに，トークン数による重みづけを行う分類についても実験を行った．


\begin{itemize}
\item\ 「ケースによる分類」：全てのケースに同等の重みがあるとして決定木学習を行う．
\item\ 「トークン数による重みづけを用いた分類」：ケースごとにケース中のトークン数の
重みをつけて決定木学習を行う．
\end{itemize}

具体的には，トークン数による重みづけを用いた分類は，
決定木学習の際，エントロピーの計算において，ひとつのケースをひとつのケースとして数えるかわりに，
トークン数分のケースとして数えることで重みを付けている．

\ref{sec:Sameラベルの付け方}--\ref{sec:ケースによる分類とトークン数による重みづけを用いた分類}節でそれぞれ二通りの選択肢があるため，
本稿では全組み合わせの合計8通りの決定木を作成した．



\subsection{決定木の統合} \label{sec:決定木の統合}

決定木の統合は，以下のように行った．
pairwiseの性質上，三つの決定木が三つとも同じ方法がよいと答えることはなく，答えが2:1に分かれるか，三つ巴になるはずである．

このうち，2:1に分かれるときは，かならず2つの決定木が出した答えが理論的に一番良くなるため，その答えを選択すればよい．
手法1$>$手法2のとき手法1のほうがよい手法であるとすると，例えば， TO$>$RSかつ，
FD$>$RSかつTO$>$FDであれば，
TO$>$FD$>$RSなので，TOを選択する．

次に，三つ巴のときには，事例が割りつけられた葉についている確率を比較し，一番高い確率のところに割り付けた．確率は，
「学習時にその葉に割りつけられたその手法のケース数/学習時に，その葉に割りつけられた全ケース数」として計算した．
たとえば，テストデータが，実行時に「学習時に，TOが1ケース，RSが2ケース割り当てられた葉」に割り当てられた場合，
そのテストデータは2/3の確率でRSとなる．三つ巴の場合には，この確率で比較し，最も高い確率の手法を割り当てた．

三つ巴のときに，ふたつの決定木で割りつけられた葉の確率が同率一位である場合には，
RS$>$TOかつFD$>$RSなら，
FD$>$RS$>$TOなのでFDを選択，
というように論理的に選択された手法を選択した．

また，三つ巴でどれも確率が等しい時など，上記のルールを利用してもどうしても領域適応手法が選べない時には，
一括的に領域適応を行ったときに正解率が高い順，つまり，FD，TO，RSの順で割りつけた．


結果 \label{Sec:結果}

\tabref{tab:table2}に，もともとの手法を一括的に用いた際のWSDの平均正解率を示す．
なお，144のケースには合計232,116のWSDのトークンが含まれており，本稿の平均正解率はそれらのトークンの平均の正解率（マイクロ平均）である．
\tabref{tab:table2}からTO，RS，FDのうち，最も良い
正解率はFDの82.27\%であることが分かる．

\begin{table}[b] 
\caption{個別の手法を用いた際のWSDの平均正解率} \label{tab:table2}
\input{02table07.txt}
\end{table}

\tabref{tab:table3}に，\ref{sec:決定木学習におけるラベル付きデータの作成方法と学習方法}節の決定木を用いて自動的にケースごとに
選択した手法を利用した際のWSDの平均正解率を示す．なお，選択の仕方は，
決定木学習による選択の8種類と，Golden Answerの一種類の合計9種類である．
ここで，決定木学習による選択の8種類は，\ref{sec:Sameラベルの付け方}--\ref{sec:ケースによる分類とトークン数による重みづけを用いた分類}節でのそれぞれ二通りの選択肢による，
全組み合わせに対応する．
\tabref{tab:table3}の決定木学習の方法の列はそれぞれ，一
列目が\ref{sec:Sameラベルの付け方}節の分類に，二列目が\ref{sec:決定木学習におけるSameの扱い}節の分類に，
三列目が\ref{sec:ケースによる分類とトークン数による重みづけを用いた分類}節の分類にあたる．
それぞれ，3値と2値は「Sameを利用した3値分類」と「訓練事例からSameの事例を削除した2値分類」を，
ケースとトークンは「ケースによる分類」と「トークン数による重みづけを用いた分類」を示す．
なお，Golden Answerは，決定木学習を用いる代わりに，ラベルとなっているふたつの領域適応
のうち，WSDの正解率の高い領域適応手法をケースごとに人手で選択して，WSDの平均正解率を求めた値であり，upper boundである．

\begin{table}[t] 
\caption{選択した手法を利用した際のWSDの平均正解率} \label{tab:table3}
\input{02table08.txt}
\end{table}

「Sameを利用した3値分類」の決定木でSameが割りつけられたケースは，
本来はTOでもRSでもどちらでもよいというように，二つの領域適応手法の選択肢のどちらを用いてもよいケースであるが，
本稿では一括的に領域適応を行ったときに正解率が高い方の手法を用いて，最終的なWSDの平均正解率を算出した．
「訓練事例からSameの事例を削除した2値分類」を利用した場合は，
\ref{sec:決定木学習におけるSameの扱い}節で述べたように，
学習した決定木を用いて自動的に全てのケースを
分類した．そのため，Sameの割りつけられたケースも，
決定木によって選択された手法を利用して最終的なWSDの平均正解率を算出した．

\tabref{tab:table3}から，決定木学習を用いて選択した手法を利用した際のWSDの平均正解率のうち，
最も高いWSDの平均正解率は，「カイ二乗検定」，「訓練事例からSameの事例を削除した2値分類」，「ケースによる分類」を利用した83.52\%で
ある．\tabref{tab:table2}の，個別の手法を用いた際の最高の正解率，FDの82.27\%よりも
正解率が高いため，
決定木を利用して適切な領域適応手法を利用した方が，個々の領域適応手法を使った時よりも正解率が上がることが分かる．
またこのとき，カイ二乗検定により十分な有意差が認められた．


考察 \label{Sec:考察}

\subsection{決定木学習のラベル付きデータの作成方法と学習方法についての比較}

本節では，決定木学習におけるラベル付きデータの作成方法と学習方法による違いを比較する．
まずSameラベルの付け方について比べると，決定木学習におけるSameの扱いを「訓練事例からSameの事例を削除した2値分類」
にしたときには「同じもの」が「カイ二乗検定」よりもよいが，「Sameを利用した3値分類」にしたときには
「カイ二乗検定」が「同じもの」よりもよい
ことが分かる．


また決定木学習におけるSameの扱いについて比べると，
「訓練事例からSameの事例を削除した2値分類」のほうがいつも「Sameを利用した3値分類」よりもよいことが分かる．


さらにケースによる分類とトークン数による重みづけを用いた分類について比べると，
「ケースによる分類」のほうがいつも「トークン数による重みづけを用いた分類」よりもよいことが分かる．


8種類の決定木の作成手法のうち最も良かったのは，
決定木学習のデータのSameのラベル付けには「カイ二乗検定」を利用し，
決定木学習におけるSameの扱いにおいては「訓練事例からSameの事例を削除した2値分類」を利用し，
決定木学習の際には「ケースによる分類」を用いた決定木学習（カイ二乗検定，2値，ケース）であった．

このとき，決定木の正解率はそれぞれ，TOとRSの決定木は69.57\%，
TOとFDの決定木は64.81\%，
RSとFDの決定木は52.63\%であった．

また，上記の実験は，コーパスを考慮しない五分割交差検定であるため，語義タグがついて
いないコーパスに対しての性能を見るために，ケースをコーパスごとに分け，コーパスごとの
交差検定を行った．上記の実験で最高の正解率だった（カイ二乗検定，2値，ケース）の決定
木学習の手法で実験を行ったところ，WSDの平均正解率は82.32\%となった．FD の82.27\%よ
りも高いが，カイ二乗検定による有意差は得られなかった．利用したコーパスは3つであるた
め，144ケースのおおよそ三分割交差検定を行うこととなっており，訓練事例数が足りず，決
定木の十分な分類性能が得られなかったためだと考えられる．
WSDの領域適応の実際のタスクにおいて，本論文が提案する決定木を
作る際には，ソースドメインのコーパス以外に，語義タグ付きのコーパスが
少なくともひとつ以上存在する必要がある．その中にターゲットドメインのコー
パスを含めずに済むかどうかは不明である．しかし，上記の実験から，含めな
い場合にもある程度の効果は得られると考える．あるいはターゲットドメイン
のコーパスに決定木を作るのに必要な程度の語義タグをつけることも考え
られる．


\subsection{学習された決定木についての考察}

WSDの平均正解率が最高だった「カイ二乗検定」，「訓練事例からSameの事例を削除した2値分類」，「ケースによる分類」の決定木学習の五回の検定のうち，最も高い正解率だった決定木を
付録として示し，生成に特に貢献した素性と素性値について以下に述べる．

まず，TOとRSの決定木のルートノードでは，「ふたつの正解率の比=0.70以上」がnoのときTOが割り当てられた．
これは「the Other のシミュレーションの正解率/ TOのシミュレーションの正解率」の割合が0.70以下であれば，
TOが割り当てられたということである．
つまり，10トークンのターゲットデータに語義をタグ付けし，Leave One Out法で評価を行った際の正解率のほうが，
ソースデータで分類器を学習し，
10トークンのターゲットデータに語義をタグ付けしたもので評価した正解率よりも高いときには
TOが割り当てられたということに等しい．
このことから，10ケースの語義をタグ付けしたターゲットデータによるシミュレーションの予測が，
最適な領域適応の手法を予想する強力な手がかりになることが分かる．

次に，決定木の深さが1のノードでは，
「JS 距離（WSD の対象単語の一つ前の形態素）=0.61以上」のときにTOが選ばれている．
このことから，
WSD の対象単語の一つ前の形態素に関する素性の分布がソースデータとターゲットデータで異なっているときには，
ソースデータを訓練事例に利用せず，ターゲットデータの10トークンに語義をタグ付けして訓練事例にした方がよいことが分かる．
JS距離が大きいのは素性の分布が異なっていることを意味し，逆にJS距離が小さいのは素性の分布が似通っていることを意味する．
WSDにおいて鍵となる素性の分布が遠く，ソースデータが十分に似ていない時には，
ソースデータを利用しない方がよいため，JS距離が大きいときにはTO になりやすいと考えられる．
同様に素性の分布が近く，ソースデータが十分に似ている時には，
ソースデータを利用した方がよいため，
JS距離が小さいときにはRSになりやすいと考えられる．

また，RSとFDの決定木のルートノードでは，「ソースデータの数/ターゲットデータに一定以上似ているソースデータの数=186.85以上」
のときFDが割り当てられた．FDは，ターゲットデータに閾値以上似た
ソースデータだけを訓練事例に利用する手法であるため，ターゲットデータに閾値以上似ていないソースデータが多量にあるときには，
全ソースデータではなく，ターゲットデータに似ているデータだけを利用すればよいことが分かる．
このことから，ターゲットデータに十分似ていないデータを足しすぎると，誤った学習が行われてしまうことが推察できる．

次に，決定木の深さが1のノードでは，「JS 距離（WSD の対象単語の二つ前の形態素）=0.74以上」がyesであればFDが，
noであればRSが割り当てられた．このことから，
WSD の対象単語の二つ前の形態素に関する素性の分布がソースデータ
と「ターゲットデータに一定以上似ているソースデータ」で似ているときには，
ソースデータを訓練事例にすべて利用した方がよく，似ていない時には，
ソースデータを利用せずに語義をタグ付けしたターゲットデータの10トークンを訓練事例にした方がよいことが分かる．
本決定木では，TOとRSの決定木の深さ1のノードと同様に，素性の分布が似ているときに，ソースデータを利用した
ほうがよいという結果になっている．

また，TOとFDの決定木のルートノードでは，
「ターゲットデータ10トークン中のMFSの，ターゲットデータに閾値以上似たソースデータ中のパーセンテージ=12.58以下」である場合に，
TOが割り当てられた．このことにより，ターゲットデータ10トークン中に最頻出する語義が，
FDの訓練事例として利用される，「ターゲットデータに一定以上似ているソースデータ」に少ない時には，
TOを用いた方がよいことが分かる．このことから，
二つのデータの語義タグが似ていないときは，ソースデータから
訓練事例を一切足すことなく，ターゲットデータだけで学習した方がよいと考えられる．

次に，決定木の深さが1のノードでは，「JS距離（WSDの対象単語の一つ後の形態素の分類語彙表の値）=0.15以下」であれば，
TOが割り当てられた．WSD の対象単語の一つ後の形態素の分類語彙表の値に関する素性の分布が，ターゲットデータ
と「ターゲットデータに一定以上似ているソースデータ」で似ているときには，
ソースデータを訓練事例に一切利用せず，ターゲットデータを10トークンタグ付けして訓練事例にした方がよいことが分かる．
ここで注目したいのは，
これまでの決定木とは逆に，素性の分布が似ているときに，ソースデータを利用しない
ほうがよいという結果になっていることである．
TOとFDの決定木全体を見てみると，ノードにJS距離についての条件は四度現れる．そのうち，二回は素性の分布が似ているときに，ソースデータを利用しない
ほうがよいという結果であり，残りの二回は逆に素性の分布が似ているときに，ソースデータを利用した
ほうがよいという結果になっている．
このように同じJS距離でも素性によって似ているときにソースデータを利用した方がよかったり，そうでなかったりするのは，
本決定木ではTOとFDの二手法から
領域適応手法を選択しているためであると考えられる．全てのソースデータを訓練事例に含めるRSと異なり，
FDでは，ターゲットデータに一定以上似ているソースデータを訓練事例に含めるため，
素性によって似ていたらソースデータを使用すべきものと，ソースデータを使用すべきでないものに分かれているのではないかと考えられる．
「WSDの対象単語の一つ後の形態素の分類語彙表の値」は後者であることが決定木から読みとれる．


生成された決定木
上の枝がyes，下の枝がnoに相当する．
JS 距離（語義）は，決定木の素性の(\ref{17})データ1とデータ2の語義タグのJS距離の略記，
JS距離（*）は，(\ref{18})データ1とデータ2の間のWSDの素性ごとの分布のJS距離の略記であり，
 *には\ref{sec:item17}節のWSDの素性名が入る．
JS距離 (Featureplus) は(\ref{19})データ1とデータ2の間の素性ごとのJS距離を足しあわせたものの略記で，(\ref{18}) を17種類足しあわせた値であり，
JS距離 (Featureall) は(\ref{20})データ1とデータ2の素性をひとつの単位としたときのJS距離の略記である．


\begin{figure}[h]
 \begin{center}
  \includegraphics{19-3ia945f3.eps}
 \end{center}
 \caption{TOとRSの決定木}
\end{figure}
\begin{figure}[h]
 \begin{center}
  \includegraphics{19-3ia945f4.eps}
 \end{center}
 \caption{RSとFDの決定木}
\end{figure}
\begin{figure}[h]
 \begin{center}
  \includegraphics{19-3ia945f5.eps}
 \end{center}
 \caption{TOとFDの決定木}
\end{figure}


\begin{biography}
\bioauthor{古宮嘉那子}{
2005年東京農工大学工学部情報コミュニケーション工学科卒．2009年同大大学院
博士後期課程電子情報工学専攻修了．博士（工学）．同年東京工業大学精密工学研究所研究員，
2010年東京農工大学工学研究院特任助教，現在に至る．自然言語処理の研究に従事．
情報処理学会，人工知能学会，言語処理学会各会員．
}
\bioauthor{奥村　　学}{
1962生．1984年東京工業大学工学部情報工学科卒業．1989年同大学院博士課程修了．
工学博士．同年，東京工業大学工学部情報工学科助手．1992年北陸先端科学技術大学
院大学情報科学研究科助教授，2000年東京工業大学精密工学研究所助教授，
2009年同教授，現在に至る．自然言語処理，知的情報提示技術，語学学習支援，
テキスト評価分析，テキストマイニングに関する研究に従事．
情報処理学会，電子情報通信学会，人工知能学会，AAAI，言語処理学会，
ACL，認知科学会，計量国語学会各会員．
}

\end{biography}


\biodate


\clearpage








\clearpage
















