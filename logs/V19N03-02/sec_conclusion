本節では，決定木学習におけるラベル付きデータの作成方法と学習方法による違いを比較する．
まずSameラベルの付け方について比べると，決定木学習におけるSameの扱いを「訓練事例からSameの事例を削除した2値分類」にしたときには「同じもの」が「カイ二乗検定」よりもよいが，「Sameを利用した3値分類」にしたときには「カイ二乗検定」が「同じもの」よりもよいことが分かる．
また決定木学習におけるSameの扱いについて比べると，「訓練事例からSameの事例を削除した2値分類」のほうがいつも「Sameを利用した3値分類」よりもよいことが分かる．
さらにケースによる分類とトークン数による重みづけを用いた分類について比べると，「ケースによる分類」のほうがいつも「トークン数による重みづけを用いた分類」よりもよいことが分かる．
8種類の決定木の作成手法のうち最も良かったのは，決定木学習のデータのSameのラベル付けには「カイ二乗検定」を利用し，決定木学習におけるSameの扱いにおいては「訓練事例からSameの事例を削除した2値分類」を利用し，決定木学習の際には「ケースによる分類」を用いた決定木学習（カイ二乗検定，2値，ケース）であった．
このとき，決定木の正解率はそれぞれ，TOとRSの決定木は69.57%，TOとFDの決定木は64.81%，RSとFDの決定木は52.63%であった．
また，上記の実験は，コーパスを考慮しない五分割交差検定であるため，語義タグがついていないコーパスに対しての性能を見るために，ケースをコーパスごとに分け，コーパスごとの交差検定を行った．
上記の実験で最高の正解率だった（カイ二乗検定，2値，ケース）の決定木学習の手法で実験を行ったところ，WSDの平均正解率は82.32%となった．
FDの82.27%よりも高いが，カイ二乗検定による有意差は得られなかった．
利用したコーパスは3つであるため，144ケースのおおよそ三分割交差検定を行うこととなっており，訓練事例数が足りず，決定木の十分な分類性能が得られなかったためだと考えられる．
WSDの領域適応の実際のタスクにおいて，本論文が提案する決定木を作る際には，ソースドメインのコーパス以外に，語義タグ付きのコーパスが少なくともひとつ以上存在する必要がある．
その中にターゲットドメインのコーパスを含めずに済むかどうかは不明である．
しかし，上記の実験から，含めない場合にもある程度の効果は得られると考える．
あるいはターゲットドメインのコーパスに決定木を作るのに必要な程度の語義タグをつけることも考えられる．
WSDの平均正解率が最高だった「カイ二乗検定」，「訓練事例からSameの事例を削除した2値分類」，「ケースによる分類」の決定木学習の五回の検定のうち，最も高い正解率だった決定木を付録として示し，生成に特に貢献した素性と素性値について以下に述べる．
まず，TOとRSの決定木のルートノードでは，「ふたつの正解率の比=0.70以上」がnoのときTOが割り当てられた．
これは「the Otherのシミュレーションの正解率/ TOのシミュレーションの正解率」の割合が0.70以下であれば，TOが割り当てられたということである．
つまり，10トークンのターゲットデータに語義をタグ付けし，Leave One Out法で評価を行った際の正解率のほうが，ソースデータで分類器を学習し，10トークンのターゲットデータに語義をタグ付けしたもので評価した正解率よりも高いときにはTOが割り当てられたということに等しい．
このことから，10ケースの語義をタグ付けしたターゲットデータによるシミュレーションの予測が，最適な領域適応の手法を予想する強力な手がかりになることが分かる．
次に，決定木の深さが1のノードでは，「JS距離（WSDの対象単語の一つ前の形態素）=0.61以上」のときにTOが選ばれている．
このことから，WSDの対象単語の一つ前の形態素に関する素性の分布がソースデータとターゲットデータで異なっているときには，ソースデータを訓練事例に利用せず，ターゲットデータの10トークンに語義をタグ付けして訓練事例にした方がよいことが分かる．
JS距離が大きいのは素性の分布が異なっていることを意味し，逆にJS距離が小さいのは素性の分布が似通っていることを意味する．
WSDにおいて鍵となる素性の分布が遠く，ソースデータが十分に似ていない時には，ソースデータを利用しない方がよいため，JS距離が大きいときにはTOになりやすいと考えられる．
同様に素性の分布が近く，ソースデータが十分に似ている時には，ソースデータを利用した方がよいため，JS距離が小さいときにはRSになりやすいと考えられる．
また，RSとFDの決定木のルートノードでは，「ソースデータの数/ターゲットデータに一定以上似ているソースデータの数=186.85以上」のときFDが割り当てられた．
FDは，ターゲットデータに閾値以上似たソースデータだけを訓練事例に利用する手法であるため，ターゲットデータに閾値以上似ていないソースデータが多量にあるときには，全ソースデータではなく，ターゲットデータに似ているデータだけを利用すればよいことが分かる．
このことから，ターゲットデータに十分似ていないデータを足しすぎると，誤った学習が行われてしまうことが推察できる．
次に，決定木の深さが1のノードでは，「JS距離（WSDの対象単語の二つ前の形態素）=0.74以上」がyesであればFDが，noであればRSが割り当てられた．
このことから，WSDの対象単語の二つ前の形態素に関する素性の分布がソースデータと「ターゲットデータに一定以上似ているソースデータ」で似ているときには，ソースデータを訓練事例にすべて利用した方がよく，似ていない時には，ソースデータを利用せずに語義をタグ付けしたターゲットデータの10トークンを訓練事例にした方がよいことが分かる．
本決定木では，TOとRSの決定木の深さ1のノードと同様に，素性の分布が似ているときに，ソースデータを利用したほうがよいという結果になっている．
また，TOとFDの決定木のルートノードでは，「ターゲットデータ10トークン中のMFSの，ターゲットデータに閾値以上似たソースデータ中のパーセンテージ=12.58以下」である場合に，TOが割り当てられた．
このことにより，ターゲットデータ10トークン中に最頻出する語義が，FDの訓練事例として利用される，「ターゲットデータに一定以上似ているソースデータ」に少ない時には，TOを用いた方がよいことが分かる．
このことから，二つのデータの語義タグが似ていないときは，ソースデータから訓練事例を一切足すことなく，ターゲットデータだけで学習した方がよいと考えられる．
次に，決定木の深さが1のノードでは，「JS距離（WSDの対象単語の一つ後の形態素の分類語彙表の値）=0.15以下」であれば，TOが割り当てられた．
WSDの対象単語の一つ後の形態素の分類語彙表の値に関する素性の分布が，ターゲットデータと「ターゲットデータに一定以上似ているソースデータ」で似ているときには，ソースデータを訓練事例に一切利用せず，ターゲットデータを10トークンタグ付けして訓練事例にした方がよいことが分かる．
ここで注目したいのは，これまでの決定木とは逆に，素性の分布が似ているときに，ソースデータを利用しないほうがよいという結果になっていることである．
TOとFDの決定木全体を見てみると，ノードにJS距離についての条件は四度現れる．
そのうち，二回は素性の分布が似ているときに，ソースデータを利用しないほうがよいという結果であり，残りの二回は逆に素性の分布が似ているときに，ソースデータを利用したほうがよいという結果になっている．
このように同じJS距離でも素性によって似ているときにソースデータを利用した方がよかったり，そうでなかったりするのは，本決定木ではTOとFDの二手法から領域適応手法を選択しているためであると考えられる．
全てのソースデータを訓練事例に含めるRSと異なり，FDでは，ターゲットデータに一定以上似ているソースデータを訓練事例に含めるため，素性によって似ていたらソースデータを使用すべきものと，ソースデータを使用すべきでないものに分かれているのではないかと考えられる．
「WSDの対象単語の一つ後の形態素の分類語彙表の値」は後者であることが決定木から読みとれる．
語義曖昧性解消(WSD; Word Sense Disambiguation)について領域適応を行った場合，ソースデータとターゲットデータのデータの性質により，最も効果的な領域適応手法が異なる．
そのため本稿では，決定木学習を用いてソースデータとターゲットデータの性質から，最も効果的な領域適応手法を自動的に選択する手法について述べた．
WSDの対象単語タイプ，ソースドメイン，ターゲットドメインの三つ組を1ケースとして数え，決定木学習を利用してケースごとに，TO，RS，FDの三種類から適切な領域適応手法を選択した．
なお，TOはソースデータを用いず，ランダムに選んだ少量のターゲットデータに語義をタグ付けしたものだけを訓練事例とする手法，RSはソースデータと語義をタグ付けした少量のターゲットデータの両方を訓練事例とする手法，FDはターゲットデータに似たソースデータと語義をタグ付けした少量のターゲットデータを訓練事例とする手法である．
三つの手法から領域適応手法を一意に選ぶため，pairwise方式に三つの決定木を作成し，最後に統合して用いた．
ケースごとに自動的に選択された手法を用いて領域適応を行うことで，もともとの手法を一括的に使った時に比べ，WSDの正解率が有意に向上した．
また，ラベル付きデータの作成方法と学習方法を8通り試したが，このうち最もWSDの平均正解率が高かったのは，決定木学習のケースへのラベル付けの際，ふたつの領域適応手法のWSDの正解率に有意差がないケースにSameラベルを付与し，Sameの割りつけられたケースは訓練事例から取り除いて2値分類を行い，ケースごとに分類を行う決定木学習であった．
作成した決定木から，語義をタグ付けした少量のターゲットデータによるシミュレーションの予測や，同ターゲットデータの最頻出語義の「ターゲットデータに一定以上似ているソースデータ」中の出現率，ソースデータの数と「ターゲットデータに一定以上似ているソースデータ」の数の比が，最適な領域適応の手法を予想する強力な手がかりになることが分かった．
本節では，決定木学習におけるラベル付きデータの作成方法と学習方法による違いを比較する．
まずSameラベルの付け方について比べると，決定木学習におけるSameの扱いを「訓練事例からSameの事例を削除した2値分類」にしたときには「同じもの」が「カイ二乗検定」よりもよいが，「Sameを利用した3値分類」にしたときには「カイ二乗検定」が「同じもの」よりもよいことが分かる．
また決定木学習におけるSameの扱いについて比べると，「訓練事例からSameの事例を削除した2値分類」のほうがいつも「Sameを利用した3値分類」よりもよいことが分かる．
さらにケースによる分類とトークン数による重みづけを用いた分類について比べると，「ケースによる分類」のほうがいつも「トークン数による重みづけを用いた分類」よりもよいことが分かる．
8種類の決定木の作成手法のうち最も良かったのは，決定木学習のデータのSameのラベル付けには「カイ二乗検定」を利用し，決定木学習におけるSameの扱いにおいては「訓練事例からSameの事例を削除した2値分類」を利用し，決定木学習の際には「ケースによる分類」を用いた決定木学習（カイ二乗検定，2値，ケース）であった．
このとき，決定木の正解率はそれぞれ，TOとRSの決定木は69.57%，TOとFDの決定木は64.81%，RSとFDの決定木は52.63%であった．
また，上記の実験は，コーパスを考慮しない五分割交差検定であるため，語義タグがついていないコーパスに対しての性能を見るために，ケースをコーパスごとに分け，コーパスごとの交差検定を行った．
上記の実験で最高の正解率だった（カイ二乗検定，2値，ケース）の決定木学習の手法で実験を行ったところ，WSDの平均正解率は82.32%となった．
FDの82.27%よりも高いが，カイ二乗検定による有意差は得られなかった．
利用したコーパスは3つであるため，144ケースのおおよそ三分割交差検定を行うこととなっており，訓練事例数が足りず，決定木の十分な分類性能が得られなかったためだと考えられる．
WSDの領域適応の実際のタスクにおいて，本論文が提案する決定木を作る際には，ソースドメインのコーパス以外に，語義タグ付きのコーパスが少なくともひとつ以上存在する必要がある．
その中にターゲットドメインのコーパスを含めずに済むかどうかは不明である．
しかし，上記の実験から，含めない場合にもある程度の効果は得られると考える．
あるいはターゲットドメインのコーパスに決定木を作るのに必要な程度の語義タグをつけることも考えられる．
WSDの平均正解率が最高だった「カイ二乗検定」，「訓練事例からSameの事例を削除した2値分類」，「ケースによる分類」の決定木学習の五回の検定のうち，最も高い正解率だった決定木を付録として示し，生成に特に貢献した素性と素性値について以下に述べる．
まず，TOとRSの決定木のルートノードでは，「ふたつの正解率の比=0.70以上」がnoのときTOが割り当てられた．
これは「the Otherのシミュレーションの正解率/ TOのシミュレーションの正解率」の割合が0.70以下であれば，TOが割り当てられたということである．
つまり，10トークンのターゲットデータに語義をタグ付けし，Leave One Out法で評価を行った際の正解率のほうが，ソースデータで分類器を学習し，10トークンのターゲットデータに語義をタグ付けしたもので評価した正解率よりも高いときにはTOが割り当てられたということに等しい．
このことから，10ケースの語義をタグ付けしたターゲットデータによるシミュレーションの予測が，最適な領域適応の手法を予想する強力な手がかりになることが分かる．
次に，決定木の深さが1のノードでは，「JS距離（WSDの対象単語の一つ前の形態素）=0.61以上」のときにTOが選ばれている．
このことから，WSDの対象単語の一つ前の形態素に関する素性の分布がソースデータとターゲットデータで異なっているときには，ソースデータを訓練事例に利用せず，ターゲットデータの10トークンに語義をタグ付けして訓練事例にした方がよいことが分かる．
JS距離が大きいのは素性の分布が異なっていることを意味し，逆にJS距離が小さいのは素性の分布が似通っていることを意味する．
WSDにおいて鍵となる素性の分布が遠く，ソースデータが十分に似ていない時には，ソースデータを利用しない方がよいため，JS距離が大きいときにはTOになりやすいと考えられる．
同様に素性の分布が近く，ソースデータが十分に似ている時には，ソースデータを利用した方がよいため，JS距離が小さいときにはRSになりやすいと考えられる．
また，RSとFDの決定木のルートノードでは，「ソースデータの数/ターゲットデータに一定以上似ているソースデータの数=186.85以上」のときFDが割り当てられた．
FDは，ターゲットデータに閾値以上似たソースデータだけを訓練事例に利用する手法であるため，ターゲットデータに閾値以上似ていないソースデータが多量にあるときには，全ソースデータではなく，ターゲットデータに似ているデータだけを利用すればよいことが分かる．
このことから，ターゲットデータに十分似ていないデータを足しすぎると，誤った学習が行われてしまうことが推察できる．
次に，決定木の深さが1のノードでは，「JS距離（WSDの対象単語の二つ前の形態素）=0.74以上」がyesであればFDが，noであればRSが割り当てられた．
このことから，WSDの対象単語の二つ前の形態素に関する素性の分布がソースデータと「ターゲットデータに一定以上似ているソースデータ」で似ているときには，ソースデータを訓練事例にすべて利用した方がよく，似ていない時には，ソースデータを利用せずに語義をタグ付けしたターゲットデータの10トークンを訓練事例にした方がよいことが分かる．
本決定木では，TOとRSの決定木の深さ1のノードと同様に，素性の分布が似ているときに，ソースデータを利用したほうがよいという結果になっている．
また，TOとFDの決定木のルートノードでは，「ターゲットデータ10トークン中のMFSの，ターゲットデータに閾値以上似たソースデータ中のパーセンテージ=12.58以下」である場合に，TOが割り当てられた．
このことにより，ターゲットデータ10トークン中に最頻出する語義が，FDの訓練事例として利用される，「ターゲットデータに一定以上似ているソースデータ」に少ない時には，TOを用いた方がよいことが分かる．
このことから，二つのデータの語義タグが似ていないときは，ソースデータから訓練事例を一切足すことなく，ターゲットデータだけで学習した方がよいと考えられる．
次に，決定木の深さが1のノードでは，「JS距離（WSDの対象単語の一つ後の形態素の分類語彙表の値）=0.15以下」であれば，TOが割り当てられた．
WSDの対象単語の一つ後の形態素の分類語彙表の値に関する素性の分布が，ターゲットデータと「ターゲットデータに一定以上似ているソースデータ」で似ているときには，ソースデータを訓練事例に一切利用せず，ターゲットデータを10トークンタグ付けして訓練事例にした方がよいことが分かる．
ここで注目したいのは，これまでの決定木とは逆に，素性の分布が似ているときに，ソースデータを利用しないほうがよいという結果になっていることである．
TOとFDの決定木全体を見てみると，ノードにJS距離についての条件は四度現れる．
そのうち，二回は素性の分布が似ているときに，ソースデータを利用しないほうがよいという結果であり，残りの二回は逆に素性の分布が似ているときに，ソースデータを利用したほうがよいという結果になっている．
このように同じJS距離でも素性によって似ているときにソースデータを利用した方がよかったり，そうでなかったりするのは，本決定木ではTOとFDの二手法から領域適応手法を選択しているためであると考えられる．
全てのソースデータを訓練事例に含めるRSと異なり，FDでは，ターゲットデータに一定以上似ているソースデータを訓練事例に含めるため，素性によって似ていたらソースデータを使用すべきものと，ソースデータを使用すべきでないものに分かれているのではないかと考えられる．
「WSDの対象単語の一つ後の形態素の分類語彙表の値」は後者であることが決定木から読みとれる．
語義曖昧性解消(WSD; Word Sense Disambiguation)について領域適応を行った場合，ソースデータとターゲットデータのデータの性質により，最も効果的な領域適応手法が異なる．
そのため本稿では，決定木学習を用いてソースデータとターゲットデータの性質から，最も効果的な領域適応手法を自動的に選択する手法について述べた．
WSDの対象単語タイプ，ソースドメイン，ターゲットドメインの三つ組を1ケースとして数え，決定木学習を利用してケースごとに，TO，RS，FDの三種類から適切な領域適応手法を選択した．
なお，TOはソースデータを用いず，ランダムに選んだ少量のターゲットデータに語義をタグ付けしたものだけを訓練事例とする手法，RSはソースデータと語義をタグ付けした少量のターゲットデータの両方を訓練事例とする手法，FDはターゲットデータに似たソースデータと語義をタグ付けした少量のターゲットデータを訓練事例とする手法である．
三つの手法から領域適応手法を一意に選ぶため，pairwise方式に三つの決定木を作成し，最後に統合して用いた．
ケースごとに自動的に選択された手法を用いて領域適応を行うことで，もともとの手法を一括的に使った時に比べ，WSDの正解率が有意に向上した．
また，ラベル付きデータの作成方法と学習方法を8通り試したが，このうち最もWSDの平均正解率が高かったのは，決定木学習のケースへのラベル付けの際，ふたつの領域適応手法のWSDの正解率に有意差がないケースにSameラベルを付与し，Sameの割りつけられたケースは訓練事例から取り除いて2値分類を行い，ケースごとに分類を行う決定木学習であった．
作成した決定木から，語義をタグ付けした少量のターゲットデータによるシミュレーションの予測や，同ターゲットデータの最頻出語義の「ターゲットデータに一定以上似ているソースデータ」中の出現率，ソースデータの数と「ターゲットデータに一定以上似ているソースデータ」の数の比が，最適な領域適応の手法を予想する強力な手がかりになることが分かった．
