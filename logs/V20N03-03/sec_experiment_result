本節では，ここまでで述べた方法を実装したシステムを評価する実験について述べる．
システムが実際に運用される場面を想定したシステムの性能を評価することが望ましいが，本論文で提案するシステムは非常に多くのモジュールから構成され，その複雑性や，開発途上にあることを考慮して，システムの基本機能，すなわち質問応答に関して評価を行った．
したがって，本論文での実験では入出力モジュールは，直接的にもシステムに組み込まれた形でも評価されていない．
システムを評価するために用いたのは，2011年3月9日から同年4月4日までのtweetデータ（約2億2千万tweet，（株）ホットリンク提供）である．
ただし，実験では，災害に関連する345個のキーワードによりフィルターした約5,400万のtweetを用いた．
この全tweetから，システムが回答を取得するためのインデックスとして，約1億2千万エントリを持つ回答インデックス1と，約7億6千万エントリの回答インデックス2（部分パターン用）が生成された．
また，提案システムの評価に加え，次の項目について実験を行った．
(1)含意関係認識における活性・不活性極性の有用性を確認する実験．
(2)固有表現認識器(NER)の有効性を確認する実験．
(3)教師有り学習を用いた回答のランキングの有効性を確認する実験．
このそれぞれについても本節で報告する．
災害時における膨大な情報を整理・分析し，全体的な把握を可能とする本システムでは，入力された質問に対して対象データにおいて目立った回答だけではなく，想定外も含めたロングテール部分に存在する被災者の要望や事実を回答として網羅的に取得する必要がある．
そのため，その再現率が重要な評価指標である．
本システムの性能を評価するためにこれまで我々が大規模に作成してきた評価セットを用いる[CITE]．
この評価セットは，6名で予め作成した質問300問の各々について，質問に関連するキーワードでシステムが対象とするtweetを全文検索した結果をランダムに1,000件を取得し，その結果から人手で回答を抽出することができた192問とその正しい回答（以下，正答と呼び，その数は17,524個である）のセットである．
評価セットの正答には質問とは表層的に大きく異なる表現で記載された表現から抽出されたものも多数含まれる．
我々が用意した質問は回答が一意に求まるものではなく，ひとつの質問に対して複数の正解が存在する．
また，この評価セットは単に質問と正答，つまり名詞句のペアをデータベース化しただけではなく，正答が抽出されたtweetも含んでいる．
実験では，この評価セットを用いた．
再現率は，評価セットに含まれる正答のうちいくつシステムが回答できたかで評価する．
当然ながら，評価セットに含まれていないが，正解と判定される回答をシステムが出力することが考えられるが，それを考慮して再現率を計算すると，新たな正解が見つかる度に再現率がかわるため，評価セットに含まれる正答のみ考慮して再現率を求めた．
一方，適合率は，システムの回答をランダムサンプルし，正解かどうかを人間が判定して求めた．
表[REF_Q_example]に実験に利用した質問の一部を示す．
評価では，再現率を計算する際に，システムの回答が正答を部分文字列として含んでいるか，システムの回答が正答に部分文字列として含まれているいずれかの場合を正解とした．
その結果，再現率0.519 (9,099/17,524)が得られた．
この部分文字列による照合では，正答かシステムの回答が一文字である場合に，多数の回答にマッチし，評価の精度が問題になる可能性があるが，前述したように提案システムは一文字からなる単語を回答として出力しない．
また，評価セットの正答で一文字のものは全部で106個あったが，システムの出力でそれらにマッチしたものは67個であった．
これはシステムの回答の4%程度に相当する．
しかし，これらすべてを回答から除外した場合の再現率は，0.519 ([MATH])と変わらず，この影響は小さいと考える．
また，192の質問ごとに再現率を求め，その平均をとると0.428であった．
これは，もともとの正答数が小さい質問において，再現率が0となってしまう場合が多い（192問中41問，そのうち回答数が0のものは32問）ためであり，このことから，逆に質問の正解が得られた場合の再現率は，この数値よりも大きい場合が多いことを期待できる．
適合率に関しては，全回答から質問と回答のペア250個をランダムサンプルし3名の評価者で正解かどうかを調べ，その多数決により正解を決めた．
評価者間の一致度合はKappa値[CITE]が0.507であった．
回答の評価に際しては，回答が抽出された元のtweetが非常に大量の場合があるが，ランダムに選択した最大3個のtweetから正解かどうかを判断した．
評価の結果，250問の適合率は，0.608 (152/250)となった．
例えば，構文パターンを利用した質問では，「どこで風評被害が起きていますか」という質問の回答では，「YでX（＝風評被害）が出ている」「X（＝風評被害）がYで発生している」「Yで起きているX（＝風評被害）」「X（＝風評被害）がYで起こる」「X（＝風評被害）がYで起きている」などのパターンにより回答を取得している．
また，部分パターンを利用した質問では，「なにが汚染していますか」という質問で「Yが汚染されてしまう」「Yが汚染される」「Yの汚染」などのほか，「Yから検出される」「Yからは検出される」などの部分パターンが含意パターンデータベースから取得され利用された．
これにより「4号機，正門，ヘリ」などのtweetに「汚染」を含んでいない回答も得ることができている．
再現率を下げている要因の一つとしては，回答がまったく取得できない質問が32問あることがある．
これらの多くは，質問文を構成する名詞句がtweetにおいて非常に低頻度であり，手掛かりとして役に立たない場合である．
例えば，「専門職ボランティア」，「被災者相談窓口」，「被ばく相談」，「被災者就労支援」などの複合名詞や，「津波肺」「クラッシュ症候群」「誤嚥性肺炎」などの固有名である．
これらは，該当する複合名詞や固有名が回答インデックスに存在しないか登録されていても非常に少数であった．
対応策としては，「被災者相談窓口」を「被災者の相談窓口」とするなどの複合語の分割が有効であり，さらにサ変名詞を語尾にもつ「被ばく相談」「就学支援」のように複合名詞が「行う」「できる」「実施する」などに係る場合は，「被ばくを相談する」，「就学を支援する」などのより汎用的な表現に変換することが必要である．
今後，複合語の構造解析手法などを取り入れ，より幅広い質問にも対応できるようにする予定である．
また，適合率を評価した回答250についてより詳細に分析した．
これらの回答がどういった処理によって抽出されるかを見るとまず，クラス依存，クラス非依存をふくめて「XがYで不足している」のように二つの変数を含むパターンによって得られた回答は全体の6%（15個）であり，その適合率は0.933であった．
また，「Yが不足している」のような部分パターンで抽出された回答は72％（180個）を占め，適合率は0.656であった．
さらに部分パターンの内容語を抽出して得られた回答は22％（55個）であり適合率は0.364であった．
期待されるように制約の強いパターンで取得されている回答は適合率が高いものの，変数を二つ含む複雑なパターンの適用例はきわめて少なかった．
これは「どこが渋滞していますか？」のようなそもそも二つの変数を含むパターンが抽出できない比較的簡単な質問が我々の評価セットに多かったことも理由である．
今後「宮城県のどこで渋滞していますか？」のようなより複雑な質問を評価セットに加えると，この制約が強いパターンが適用される割合も増加するものと考える．
誤った回答が抽出された要因を見ていくと，もちろん，パターン間の含意の認識誤りも含まれてはいるが，むしろ目立つのは「水は不足していますか？」「水が不足したりして」「水は不足していません」などのように単純な肯定文以外の文から「Xが（は）不足する」のようなパターンが抽出されている場合である．
これらの文をムード等の分析ルーチンを導入することによって除くことで最大で10％以上の適合率改善ができると予想している．
一方で，「水は不足していますか？」のような質問や要望，「水が不足していたとしたら」のような仮定も，災害時において非常に有用な情報であり，個別に認識することは重要な課題だと考えている．
また，地名補完処理の誤りによって，パターンやその内容語から離れた位置に出現する場所名が誤って回答として抽出されるケースがあった．
これらは今後，省略，照応解析を導入することで改善していく予定である．
[REF_extract_entailment]節で述べた部分パターン間の含意関係のクリーニングが質問応答全体に及ぼす影響について評価を行った．
部分パターン間の含意関係とは，例えば「Xが崩落する」「Xが崩壊する」の間に成立する含意関係である．
[REF_extract_entailment]節で述べたように，このクリーニングにおいては，活性・不活性極性を用いたクリーニング（活性・不活性クリーニング），ならびに同一の動詞を含む部分パターン間で助詞のみが異なるものを削除するクリーニング（助詞クリーニング）の二種類を行った．
まず，提案システムの再現率は0.519，適合率は0.608であったが，部分パターン間の含意関係に対して助詞クリーニングのみ適用し，活性・不活性クリーニングを適用しなかった場合の回答を，提案システムと同様に回答250サンプル（評価者3名による評価）を抽出し，評価したところ，表[REF_cleaning_effect]に示すとおり，再現率0.524，適合率が0.536となった．
つまり，再現率は0.005とわずかに向上したが，適合率が0.072と大きく低下したことになる．
さらに，活性・不活性クリーニング，助詞クリーニングの両方を適用しなかったときの性能は，再現率が0.533，適合率が0.448となり，やはり再現率がわずかに向上したものの適合率の大幅な低下が見られた．
最終的にいっさいクリーニングを行わなかった場合と提案手法を比べると，再現率が0.014程度向上するのに対して，適合率は0.160と大幅に低下している．
まとめると，部分パターン対のクリーニングは最終的な回答の質において非常に重要であるということが分かった．
特に，一見含意関係とは関係の薄い，活性・不活性という意味極性がそのクリーニングにおいて重要な役割を果たすことが確認できた．
本研究での提案システムは地名補完モジュールにNERを使用しなかったが，それは以下の実験結果により，NERの有用性が本システムにおいて認められなかったからである．
まず，IREX固有表現コーパス[CITE]においてLOCATIONタグのみを残し，これをNER学習データ1とした．
次に，Twitter APIを使用して，実験で用いるtweetとは異なる期間のtweet 22万5千件を取得し，これに対し，災害関連のキーワード345個のいずれかを含む11万tweetに対して学習データ1から作成した既存のNERを適用し，LOCATIONタグを付与した．
この結果のうち4万文を人手で修正し，これをNER学習データ2とした．
これらのNER学習データ1ならびに2をあわせてNER構成用学習データとし，CRF++を用いて形態素単位のNERを構成した．
素性テンプレートはCRF++パッケージのサンプルとして含まれているものをそのまま利用した．
このNERを評価するために，我々が対象としている5,400万のtweetから1,000 tweet（3,017文）をランダムサンプルし，構成したNERを適用した．
その結果を人手で修正し，評価用テストセットを作成した．
この評価用テストセットの形態素数は約33,000であり，LOCATIONとされる名詞句は，521（866形態素）存在する．
これを用いて構成したNERを評価したところ適合率は0.930，再現率は0.839であった．
次に我々の質問応答システムで，地名補完モジュールにおける処理対象の特定にNERを組み入れた場合と，形態素単位の文字列によって直接辞書引きすることで特定する場合との違いがシステム全体の質問応答性能に与える影響を調べた．
実験に使用したのは，部分パターン対のクリーニングを行う前のシステムであるが，NERの効果を調べるには問題がないと考える．
表[REF_NER_effect]に示すとおり，実験結果は，NERを用いない場合が再現率0.533，適合率0.448であり，NERを用いた場合には再現率0.516，適合率0.392と再現率，適合率ともに低下した．
この結果から，あるエンティティが地名・場所名辞書に存在しているにもかかわらず，NERがそれを特定できなかった場合や，逆にNERが地名補完モジュールでの処理対象を特定できても地名・場所名辞書に登録されていない場合などがあり，地名・場所名辞書を直接辞書引きしたほうが，より高い性能を発揮できたと考える．
より具体的に，NERで特定されたものがどれだけ地名・場所名辞書を用いて地名補完処理されたかを見てみると次のようになった．
NERはテストセットに521あるエンティティのうち，437（再現率0.839）相当を正しく特定できているが，このうち，地名補完処理の対象となったのは，わずか157個である．
この数字が小さい理由は，現在の地名補完処理はシステムの持つ地名・場所名辞書にあるエントリしか処理対象としないからであり，さらにはNERの認識結果と地名・場所名辞書との食い違いが大きいからである．
一方，地名補完モジュールにて行っている処理では，214個の地名・場所名を特定し，地名補完処理がなされた．
もちろん，この地名補完処理がなされた地名・場所名には誤ったものも多数含まれていよう．
もともとNERを導入した動機は，NERによって一般名詞や人名等を地名として誤認識することを防げるかもしれないということであった．
つまり，地名補完処理対象認識の適合率の向上をねらったということである．
おそらく，地名・場所名の誤認識がNERによって防がれたケースもあったものと推測されるが，そもそも地名補完処理が起動されないことのデメリットの方が大きく，最終的な質問回答の性能が低下したものと考える．
もちろん，今後NERの認識結果を地名・場所名辞書に追加していくことによって，性能向上を見ることは可能かもしれない．
しかしながら，そこで障害となるのはエンティティの基準と，地名補完処理において処理対象とするエンティティ，すなわち地名・場所名辞書のエントリの認定基準とが異なっていることである．
例えば，NERの認識結果には外国の地名などあきらかに本タスクでは不要と思われるものも多数存在するし，複合名詞中，例えば「富士スピードウェイ」の「富士」が地名として認識されるといった問題も存在する．
また，地名・場所名辞書では地名間の包含関係が情報として含まれているが，NERの認識結果にはそうしたものは含まれない．
これらの問題をどう解決していくかが，今後の課題の一つとなる．
まとめると，風間ら(風間他2012)の報告と同様に提案システムにおけるNERの効果は確認出来なかった．
これをうけて，我々の提案システムではNERを使用していない．
この理由は，現状の地名補完処理では，固有表現特定後に地名・場所名辞書にて詳細な地名情報を取得する必要があり，この辞書の網羅性等が性能に影響するためである．
さらには，地元でだけ用いられる通称など考慮しなければならない点もあり，これらの問題点をいかに低コストで解決していくかも重要な点であると考えている．
今後，自治体などの協力を得て，そうした通称や未登録の避難所をリストアップしていくなどの作業も必要であろう．
したがって，システムの性能を向上させるためには，NERの認定基準と本タスクで必要とされる地名・場所名の認定基準との擦り合わせ，さらには地名・場所名辞書との整合性をとる自明でない作業が必要となる．
本論文におけるシステムでは，ロングテールに存在する回答についてもすべて出力するという目的から，再現率を重視し，今まで述べてきた手法で発見できたすべての回答を出力している．
一方で，自明な拡張は回答にランキングメカニズムを導入し，さらなる拡張を図ることである．
本来，再現率を重視しつつ，ランキングを導入し，提案手法よりも高い性能を達成するためには，提案手法よりも公汎な回答を出力し，ランキングに基づいて回答の足切りを行うべきであるが，現状はそこまでの実験は行えていない．
代わりに，提案システムが出力する回答全部を教師あり学習に基づいてランキングした結果について報告する．
今回行った実験で使ったランキング手法は，回答とパターンに関する素性をもとに学習したSVMのスコアによりランキングを行うものである．
表[REF_feature]に，SVMの学習に利用した素性を示す．
まず，パターンの属性に基づく素性として，質問構文パターン，クラス依存パターン，クラス非依存パターン，部分パターンからのいずれのパターンで回答が得られたか，あるいは部分パターンと部分パターンの内容語によるキーワード検索を用いたかを示す2値の素性を用いる．
これに加え，クラス依存パターン，クラス非依存パターン，部分パターンの各スコアを用いる．
ある回答が複数の異なるパターンから得られた場合には，その全パターン数，パターンが回答を連体修飾していないどうか，全パターン数と回答を連体修飾していないパターンとの比率を利用する．
また回答を抽出した含意パターンや部分パターンが，質問構文パターンと共通の漢字を持つかどうかも利用する．
回答の属性に基づく素性では，まず，様々なパターンから得られた同じ回答の個数，その文字数及び形態素数を用いる．
次に，回答の意味的な情報として，回答の意味クラス，その意味クラスを特定する際に部分文字列を用いたか，回答のクラスが未特定かどうかの2値の素性を用いる．
また，回答を獲得したパターントリプルの構文パターンと2つの名詞句の意味クラスのPMI（相互情報量：Point-wise Mutual Information），質問構文パターンと質問文中の名詞に基づく回答の意味クラスの尤度[CITE]を利用する．
また質問文から得られる疑問代名詞と主題語を利用した素性として，疑問代名詞タイプ，回答が疑問代名詞の対応するクラスに属するかどうか，回答と主題語との分布類似度，回答が主題語の下位概念となるかどうか，回答の末尾に主題語を含むかどうかを用いる．
上記の素性を用いて，線形，多項式（二次），放射基底関数（RBF,比例定数1）の各カーネルを用いてSVMの学習を行い，いずれのカーネル関数を用いるべきか検討した．
学習データは，災害に関連の深い質問60問（これまでの評価で利用した質問とは別である）と，システムが出力した回答のペア合計5,044個に対して正解／不正解のラベルを付与したデータである．
なお，このデータは提案システムの古いバージョン，つまり，場所名フィルターや部分パターン含意データベースのクリーニングを行っていないシステムの出力を含んでおり，現在の提案システムでは出力できない回答も含まれている．
10分割交叉検定の結果，線形カーネルでF値0.642（適合率0.681，再現率0.607），多項式カーネルでF値0.631（適合率0.626，再現率0.634）, RBFカーネルでF値0.529（適合率0.719，再現率0.419）が得られた．
本システムではF値が最も高かった線形カーネルにより学習された分類器の出力するスコアを利用することを検討した．
[REF_Eval_QA]節の実験にて利用した250個の回答サンプル（適合率0.608）を以上の分類器のスコアでランキングした結果が図[REF_recall_prec_pic]である．
グラフの再現率は提案システムの出力すべてをSVMのスコアにしきい値をもうけて足切りを行い，足切りを生き延びた回答集合を17,254件の正解データに照らし合わせて計算されたものである．
これによると，再現率が0.1前後のところでは適合率が0.90前後でており，きわめて高いものとなっている一方，システムの全回答の再現率0.508に近いところ，例えば，再現率0.4前後のところでは提案手法の適合率に比して，わずかな適合率の向上（0.05前後）しか見られず，また，もうすこし離れたデータポイント（例えば，再現率0.3前後のデータポイント）までの適合率の改善具合もきわめてなだらかである．
この評価はあくまで現状のシステムの出力結果のみをランキングしているため，確定的なことは言えないが，前述したように学習データは現在のシステムが出力できない回答に関するものも含まれていないことも考え合わせると，仮に現在のシステムをより大量の回答を出力するように改変し，ランキングによる足切りをおこなったとしても，例えば，再現率0.5前後の部分での適合率向上はきわめて小さなものになる可能性が高いと考えられる．
これは再現率を重視するという我々の立場とは相容れないものであり，提案システムにはランキング手法は導入しなかった．
一つ今後システムを改善できる可能性があるとすれば，今後さらに学習データを増やしていくことが重要であるが，現在でも約5,000件という少なくない量の学習データを利用していること，また，次回の災害はおそらく東日本大震災とは大きく異なることが予想され，東日本大震災に特化した学習データを作ることは望ましくないと考えられることから，少なくともランキング手法の導入については慎重に検討する必要があると考えている．
実際に大規模な災害が発生した後，アノテーションをクラウドソーシングなどで行い，質問応答の精度を高めるといったシナリオは魅力的に見えるかもしれない．
しかし，そうしたシナリオを実現するためには，NERの場合と同様にシステム全体としての最適化の枠組みなどが必要だということかもしれず，これも慎重に検討する必要があると考えている．
