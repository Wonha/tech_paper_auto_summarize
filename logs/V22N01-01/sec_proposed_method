まず我々は，2名の参加者による雑談対話を収集し，その対話に述語項構造データの付与を行った．
雑談対話は，参加者が自由なテーマ（話題）を設定し，キーボード対話形式で収集した．
したがって，音声対話に含まれるような相槌や言い直しは少ない．
参加者の話題は，食事，旅行，趣味，テレビ・ラジオなどである．
述語項構造アノテーションは，NAISTテキストコーパス[CITE]に準拠する形で行った．
雑談対話と，その述語項構造解析アノテーションの例を図[REF_fig-chat-dialog]に示す．
今回作成した雑談対話コーパスと，NAISTコーパスの統計量を表[REF_tbl-corpus-size]に示す．
対話コーパスは，NAISTコーパスの約1/10のサイズである．
また，1文/発話の長さ（形態素数）は，雑談対話コーパスはNAISTコーパスの1/3程度と短い．
NAISTコーパスは，訓練，開発，テストに3分割したのに対し，対話コーパスは訓練とテストの2分割とした．
対話の特徴を分析するため，この2つのコーパスの比較を行った．
表[REF_tbl-arg-distrib]は，訓練セットにおける項の分布を示したものである．
各項は，述語との位置関係や文法関係などにより問題の難しさが異なるため，以下の6タイプに分類した．
最初の2つ（係受および文内ゼロ）は述語と項が同じ文に存在する場合である．
係受:述語と項が直接の係り受け関係にある場合
文内ゼロ:述語と項が同じ文（発話）内にあるが，直接の係り受け関係がない場合
文間ゼロ:述語と項が異なる文にある場合
exo1/exo2/exog:項が記事（対話）内に存在しない外界照応．
それぞれ，一人称ゼロ代名詞，二人称ゼロ代名詞，それ以外（一般）を表す．
これを見ると，対話ではすべての格で，係受タイプの項が減少している．
それ以外のタイプについては，ガ格と，ヲ格ニ格で傾向が異なっている．
ガ格では，文内ゼロ代名詞も対話の場合に減少し，減少分は一人称・二人称外界照応(exo1, exo2)に割り当てられている．
つまり，ガ格では，文内の項が減少し，ゼロ代名詞が新聞に比べて頻発する．
ただし，その先行詞は一人称・二人称代名詞である可能性が高いと言うことができる．
ヲ格ニ格では，係受タイプの項の減少分は，文間ゼロ代名詞またはその他の外界照応(exog)に割り振られている．
つまり，新聞記事では，大部分は述語と同じ文内に現れていたヲ格ニ格の項が，対話では別の発話に現れることが多くなり，1文に閉じない照応解析が重要となる．
本稿でベースとする述語項構造解析は，[CITE]の方法である．
これは，新聞記事を対象とした方法であるが，文内に存在する項，文間の項，外界照応を同時に解析できるという特徴があるため，対話の解析にも適していると判断した．
処理は，記事（対話）全体を入力とし，各文（発話）ごとに以下のステップを実行する．
入力文を形態素・構文解析する．
構文解析時には，同時に文節とその主辞を特定しておく．
なお，今回は対話コーパスに関しては，形態素解析器MeCab [CITE]，構文解析器CaboCha [CITE]で形態素・文節係り受け・主辞情報を自動付与した．
NAISTコーパスに関しては，NAISTコーパス1.5付属のIPA体系の形態素・構文情報を利用した．
文から述語文節を特定する．
今回は評価のため，コーパスの正解述語を用いたが，対話システム組み込みの際には，主辞が動詞，形容詞，形容動詞，名詞＋助動詞「だ」の文節を述語文節とし，品詞パターンで決定する．
対象述語の存在する文，およびそれより前方の文から，項の候補となる文節を取得する．
文節の内容語部を候補名詞句とする．
具体的には，以下の文節が候補となる．
対象述語の文に含まれる，内容語部が名詞句であるすべての文節を文内の候補とする．
その際，述語文節との係り受け関係は考慮しない．
対象述語より前方の文から，文脈的に項の候補となりうる文節を加え，文間の候補とする．
詳細は[REF_sec-context-processing]節で述べる．
記事内に実体を持たない疑似候補として，外界照応(exo1, exo2, exog)と，任意格のため格を必要としない(NULL)を特殊名詞句として加える．
述語文節，項の候補名詞句，両者の関係を素性化し，ガ，ヲ，ニ格独立に，候補からもっとも各格にふさわしい名詞句を選択器で選択する（図[REF_fig-struct]）．
本稿では，[CITE]の方式から，若干の変更を行っている．
変更点は以下のとおりである．
[CITE]では，特殊名詞句は1種類（NULLのみ）であったが，本稿では4種類(NULL, exo1, exo2, exog)に拡張した．
[CITE]は，外界照応を含む一人称，二人称ゼロ代名詞（論文では著者・読者表現）の照応解析を行うことで，それ以外のゼロ代名詞の照応解析精度も向上したと報告している．
本稿でも，特殊名詞句の種別を増やすこととする．
素性が異なる．
本稿では，[REF_sec-features]節で述べる素性を使用したが，これは[CITE]の基本素性を拡張，追加したものである．
また，文脈を考慮する素性（文献ではSRLOrder，Used）は使用せず，簡略化した．
これは，文脈管理を外部モジュールに任せるためで，詳細は[REF_sec-context-processing]で述べる．
係り受け言語モデル（[REF_sec-dependency-lm]節参照）を1種類から3種類に拡張した．
選択器のモデルは，最大エントロピー分類に基づく．
具体的には，選択器は記事内の述語[MATH]ごとに，候補名詞句集合[MATH]から，以下の式を満たす名詞句[MATH]を選択する．
\hat{n} & = \mathopargmax_{n_j \inN} P(d(n_j)=1 | X_j; M_c)
P(d(n_j)=1|X_j;M_c) & = \frac{1}{Z_{c}(X)} \exp\sum_{k} _{ck} f_k(d(n_j)=1,X_j)
Z_{c}(X) & = \sum_{n_j \inN} \exp\sum_k _{ck} f_k(d(n_j)=1,X_j)
X_j & = \langle n_j, v, A \rangle
ただし，[MATH]は1つの候補名詞句，[MATH]は候補名詞句集合，[MATH]は，名詞句[MATH]が項となったときのみ1となる関数，[MATH]は格[MATH]（ガ，ヲ，ニのいずれか）のモデルである．
また，[MATH]は素性関数，[MATH]は格毎の素性関数の重み，[MATH],[MATH]はそれぞれ述語，および形態素・構文解析済みの記事全体である．
訓練時には，ある述語の候補名詞句集合ごとに，正解の名詞句と，それ以外のすべての候補名詞句との事後確率差を大きくするように学習する．
具体的には，以下の損失関数を最小化するモデル[MATH]を，格ごとに学習する．
\ell_{c} & = - \sum_{i} \log P(d(n_i)=1|X_i;M_c) + \frac{1}{2C} \sum_{k} ||\lambda_{ck}||^{2}
ただし，[MATH]は，訓練セットの[MATH]番目の述語に対する正解名詞句，[MATH]は，訓練セットの[MATH]番目の正解名詞句，述語，記事の組[MATH]，[MATH]は過学習を制御するためのハイパーパラメータで，開発セットにおける精度が最高になるように，あらかじめ設定しておく．
式([REF_eqn-normalizer])で，述語の候補名詞句集合毎に正規化を行っているため，([REF_eqn-loss-function])式では，候補名詞句集合から，正解名詞句が選ばれた時に確率1.0，それ以外の名詞句では確率0.0に近づくようにモデルが学習される．
選択器で使用する素性に関しては，英語の意味役割付与に関する研究（たとえば[CITE]）と同様に，(1)述語に関する素性，(2)名詞句に関する素性，(3)両者の関係に関する素性を使用する．
詳細を表[REF_tbl-feature-list]に示す．
二値の素性関数は，テンプレートの引数が完全一致したときのみ1，それ以外では0を返す関数である．
たとえばPred素性において，主辞形態素の見出しが1万種類あったとすると，1万の二値関数が定義され，主辞形態素の見出しと一致した関数だけが1を返す．
実数値の素性関数は，テンプレートの引数に応じた実数を返す．
なお，これらは名詞句の選択用モデルの素性であるので，名詞句Nounと，すべての二値素性を組み合わせた素性も使用している．
本稿で特徴的な素性は，大規模データから自動構築した必須格情報Frameと係り受け言語モデル（3種類）であるが，これらについては[REF_sec-large-resources]節で述べる．
本稿では，人とコンピュータの対話システム実現のための解析器を想定している．
この対話システムは，ユーザとシステムが交互に発話するもので，システムに組み込まれた対話管理部が両者の発話履歴や，現在話されている話題（焦点）を管理する．
述語項構造解析部はユーザ発話を解析し，発話生成部がシステム発話を生成するというものである．
従来の述語項構造解析器も，現在の解析対象文より以前の文を文脈として利用し，ゼロ代名詞照応解析に利用している．
[CITE]は，解析器内部で以前の文や話題（焦点）の管理（これを文脈管理と呼ぶ）を行っていた．
しかし，述語項構造解析器内部で文脈管理を行うより，対話システムの対話管理部が文脈管理を行った方が，ユーザ発話とシステム発話を協調的に管理できる可能性が高い．
本稿ではこのように考え，文脈管理は外部モジュールの担当と位置付ける．
そして評価用に，新聞記事と対話で同じ文脈管理方法を使用する．
なお，本稿の方式は，選択器に与える文間の候補名詞句を取捨選択することによって文脈の制御を行っているので，候補名詞句を外部モジュールから陽に与えることで，文脈管理方法を変更することができる．
今回使用した文脈管理方法は，具体的には以下のとおりである．
対象述語の発話より以前の発話をさかのぼり，他の述語を含む発話（これを有効発話と呼ぶ）を見つける．
これは，述語を含まない発話を無視するためである．
有効発話と対象述語の発話の間に出現した全名詞句と，有効発話の述語で項として使われた名詞句（有効発話内の場合もあれば，それ以前の発話の名詞句の場合もある）を候補として加える．
項として使われた名詞句は，その後も繰り返し使われることが多く，これに制限することで，効率的に候補を削減することができるという観察結果に基づく[CITE]．
また，項として使われている限り，さかのぼる文数に制限がないため，広い文脈を見ることができる．
前節で述べた方法は，対話，新聞記事に共通の処理である．
これを対話解析に適したものにするため，パラメータの適応，および大規模コーパスから自動獲得した知識の適用を行う．
NAISTコーパスと対話コーパスの項分布の差異は，選択器のモデルパラメータをドメイン適応することで調整する．
本稿では，モデルパラメータの適応手法として，素性空間拡張法[CITE]を用いる．
これは，素性空間を3倍に拡張することで，ソースドメインデータをターゲットドメインの事前分布とみなすのと同じ効果を得る方法である．
具体的には，以下の手順で選択器のモデルを学習・適用する．
まず，素性空間を共通，ソース，ターゲットの3つに分割する．
NAISTコーパスをソースドメインデータ，対話コーパスをターゲットドメインデータとみなし，NAISTコーパスから得られた素性を共通とソース空間にコピーして配置する．
対話コーパスから得られた素性は共通とターゲット空間にコピーして配置する．
拡張された素性空間上で，通常通りパラメータ推定を行う．
結果，ソース・ターゲットデータ間で無矛盾な素性は，共通空間のパラメータが強調され（絶対値が大きくなる），ドメインに依存する素性は，ソースまたはターゲット空間のパラメータが強調される．
選択器が項を選択する際は，ターゲット空間と共通空間の素性だけ用いる．
この空間のパラメータは，ターゲットドメインに最適化されているだけでなく，ソースドメインデータだけに現れた共通空間の素性も利用して，項選択ができる．
本稿では，訓練コーパスに含まれない未知語への対策として，大規模コーパスから自動獲得した2種類の知識を利用する．
どちらも大規模平文コーパスを自動解析して，集計やフィルタリングをすることで獲得する[CITE]．
当然誤りも含むが，新出語に対しても，ある程度の確かさで情報を与えることができる．
これらを選択器の素性として使い，モデルを学習することにより，情報の信頼度に応じたパラメータが学習される．
格フレームは，述語の必須格と，その格を埋める名詞句の種類（通常は意味クラス）を保持するフレーム形式の情報で，述語項構造解析や意味役割付与の重要な手がかりとなる．
本稿で使う必須格情報は，格フレームのうち，格が必要か否か（必須格か任意格か）だけについて情報を与える辞書である．
本稿の必須格情報は，大規模平文テキストコーパスから，以下の方法で自動構築する．
これは，(1)項が述語と直接係り受け関係にある場合，述語に対する項の格は，項の名詞句に付随する格助詞と一致することが多い，(2)必須格なら，その格の出現率は他の述語より平均的に高い，という仮定をもとにしている．
まず，本稿の述語項構造解析と同様（[REF_sec-architecture]節参照）に，平文を形態素・構文解析し，品詞パターンで述語文節とその主辞を特定する．
述語文節に直接係る文節を取得し，機能語部に格助詞を持つ文節だけを残す．
もし，そのような文節が1つ以上あるなら，その述語を集計対象として，述語頻度，格助詞の出現頻度を集計する．
述語に関しては，高頻度述語から順番に，最終的な辞書サイズを考慮して選択する．
個々の格に関しては，以下の条件をすべて満たす格を，必須格とみなす．
[MATH]が，対数尤度比検定において，危険率0.1%以下で有意に多く共起していること（[MATH]; [MATH]）．
各述語における格[MATH]の出現率が，全述語における格の出現率（平均）より10%以上高いこと．
以上の方法で，2種類の必須格情報辞書を作成した．
一つは，ブログ約1年分（約23億文．
以下Blogコーパスと呼ぶ）から，48万述語の情報を獲得した（これをBlog辞書と呼ぶ）．
もう一つは新聞記事12年分（約770万文．
以下Newsコーパスと呼ぶ）から約20万述語の情報を獲得した（同News辞書）．
表[REF_tbl-oci-dict]は，雑談対話コーパス訓練セットの正解述語項構造と必須格情報辞書を比較し，必須格情報辞書の述語カバー率と格毎の精度を算出したものである．
述語カバー率は，対話コーパスに出現した述語が必須格情報辞書に含まれている場合，カバーしたと判断した．
結果，Blog辞書で98.5%，News辞書で96.4%で，ほぼ等しかった．
また，格毎の精度は，正解の述語項構造に格が付与されているか否かと，必須格情報上の必須格性が一致しているかどうかを測定したもので，Blog辞書，News辞書でほぼ同じ傾向を示している．
格毎に見ると，ガ格の精度が低いが，これは，雑談対話コーパスでは，ほぼすべての述語に対してガ格が付与されている（つまり，ガ格が必須）にも関わらず，BlogコーパスやNewsコーパスではそれがゼロ代名詞化されているため，自動獲得では必須格とは判断できなかったためである．
ヲ格の全体精度は91%以上と，格によっては高い精度を持つ辞書となっている．
係り受け言語モデル(language model; LM)は，三つ組[MATH]の共起のしやすさを表現するモデルである．
頻出表現に高いスコアを与えることによって，出現する単語間に意味的関連が存在することを表現する意図がある．
ここでは，述語[MATH],格[MATH],名詞句[MATH]それぞれの生成確率をn-gramモデルで算出し，選択器の識別モデルで全体最適化を行う．
具体的には，以下の実数値を算出し，表[REF_tbl-feature-list]の係り受け言語モデル素性の素性関数値として使用する．
その結果，選択器は，候補名詞句集合から，頻出表現に含まれる名詞句[MATH]を優先して選択することになる．
なお，未知語を表す特殊単語<unk>を含む確率で補正してる理由は，対数確率（{[MATH]〜[MATH]}の範囲）を正の値に補正するためである．
[MATH]
[MATH]
[MATH]
本稿の係り受け言語モデルは，[CITE]が1種類（{[MATH]}相当）のみ使用していたのに対し，識別モデルが互いに依存しあう素性を含めることができるという特徴を利用し，3種類に拡張している．
また，述語[MATH]から見た格[MATH]の生成確率({[MATH]})は，述語ごとに格を必要とする度合であり，必須格情報と重なるため，係り受け言語モデルからは除外した．
3種類の係り受け言語モデルは，[REF_sec-case-lex]節で抽出した述語，格，名詞句を集計し，SRILM [CITE]でバックオフモデルを構築した．
係り受け言語モデルも，Blogコーパス，Newsコーパスからそれぞれ作成した．
これを，それぞれBlog言語モデル，News言語モデルと呼ぶ．
言語モデルのカバー率を，雑談対話コーパス訓練セットに出現する三つ組が係り受け言語モデルの元になった三つ組に含まれるかどうかで測定すると，Blog言語モデルの場合，76.4%をカバーしていた．
一方，Newsの言語モデルの場合，カバー率は38.3%だった．
News言語モデルに比べ，Blog言語モデルは対話コーパスに出現する係り受けの三つ組のカバレッジが高い．
まず我々は，2名の参加者による雑談対話を収集し，その対話に述語項構造データの付与を行った．
雑談対話は，参加者が自由なテーマ（話題）を設定し，キーボード対話形式で収集した．
したがって，音声対話に含まれるような相槌や言い直しは少ない．
参加者の話題は，食事，旅行，趣味，テレビ・ラジオなどである．
述語項構造アノテーションは，NAISTテキストコーパス[CITE]に準拠する形で行った．
雑談対話と，その述語項構造解析アノテーションの例を図[REF_fig-chat-dialog]に示す．
今回作成した雑談対話コーパスと，NAISTコーパスの統計量を表[REF_tbl-corpus-size]に示す．
対話コーパスは，NAISTコーパスの約1/10のサイズである．
また，1文/発話の長さ（形態素数）は，雑談対話コーパスはNAISTコーパスの1/3程度と短い．
NAISTコーパスは，訓練，開発，テストに3分割したのに対し，対話コーパスは訓練とテストの2分割とした．
対話の特徴を分析するため，この2つのコーパスの比較を行った．
表[REF_tbl-arg-distrib]は，訓練セットにおける項の分布を示したものである．
各項は，述語との位置関係や文法関係などにより問題の難しさが異なるため，以下の6タイプに分類した．
最初の2つ（係受および文内ゼロ）は述語と項が同じ文に存在する場合である．
係受:述語と項が直接の係り受け関係にある場合
文内ゼロ:述語と項が同じ文（発話）内にあるが，直接の係り受け関係がない場合
文間ゼロ:述語と項が異なる文にある場合
exo1/exo2/exog:項が記事（対話）内に存在しない外界照応．
それぞれ，一人称ゼロ代名詞，二人称ゼロ代名詞，それ以外（一般）を表す．
これを見ると，対話ではすべての格で，係受タイプの項が減少している．
それ以外のタイプについては，ガ格と，ヲ格ニ格で傾向が異なっている．
ガ格では，文内ゼロ代名詞も対話の場合に減少し，減少分は一人称・二人称外界照応(exo1, exo2)に割り当てられている．
つまり，ガ格では，文内の項が減少し，ゼロ代名詞が新聞に比べて頻発する．
ただし，その先行詞は一人称・二人称代名詞である可能性が高いと言うことができる．
ヲ格ニ格では，係受タイプの項の減少分は，文間ゼロ代名詞またはその他の外界照応(exog)に割り振られている．
つまり，新聞記事では，大部分は述語と同じ文内に現れていたヲ格ニ格の項が，対話では別の発話に現れることが多くなり，1文に閉じない照応解析が重要となる．
本稿でベースとする述語項構造解析は，[CITE]の方法である．
これは，新聞記事を対象とした方法であるが，文内に存在する項，文間の項，外界照応を同時に解析できるという特徴があるため，対話の解析にも適していると判断した．
処理は，記事（対話）全体を入力とし，各文（発話）ごとに以下のステップを実行する．
入力文を形態素・構文解析する．
構文解析時には，同時に文節とその主辞を特定しておく．
なお，今回は対話コーパスに関しては，形態素解析器MeCab [CITE]，構文解析器CaboCha [CITE]で形態素・文節係り受け・主辞情報を自動付与した．
NAISTコーパスに関しては，NAISTコーパス1.5付属のIPA体系の形態素・構文情報を利用した．
文から述語文節を特定する．
今回は評価のため，コーパスの正解述語を用いたが，対話システム組み込みの際には，主辞が動詞，形容詞，形容動詞，名詞＋助動詞「だ」の文節を述語文節とし，品詞パターンで決定する．
対象述語の存在する文，およびそれより前方の文から，項の候補となる文節を取得する．
文節の内容語部を候補名詞句とする．
具体的には，以下の文節が候補となる．
対象述語の文に含まれる，内容語部が名詞句であるすべての文節を文内の候補とする．
その際，述語文節との係り受け関係は考慮しない．
対象述語より前方の文から，文脈的に項の候補となりうる文節を加え，文間の候補とする．
詳細は[REF_sec-context-processing]節で述べる．
記事内に実体を持たない疑似候補として，外界照応(exo1, exo2, exog)と，任意格のため格を必要としない(NULL)を特殊名詞句として加える．
述語文節，項の候補名詞句，両者の関係を素性化し，ガ，ヲ，ニ格独立に，候補からもっとも各格にふさわしい名詞句を選択器で選択する（図[REF_fig-struct]）．
本稿では，[CITE]の方式から，若干の変更を行っている．
変更点は以下のとおりである．
[CITE]では，特殊名詞句は1種類（NULLのみ）であったが，本稿では4種類(NULL, exo1, exo2, exog)に拡張した．
[CITE]は，外界照応を含む一人称，二人称ゼロ代名詞（論文では著者・読者表現）の照応解析を行うことで，それ以外のゼロ代名詞の照応解析精度も向上したと報告している．
本稿でも，特殊名詞句の種別を増やすこととする．
素性が異なる．
本稿では，[REF_sec-features]節で述べる素性を使用したが，これは[CITE]の基本素性を拡張，追加したものである．
また，文脈を考慮する素性（文献ではSRLOrder，Used）は使用せず，簡略化した．
これは，文脈管理を外部モジュールに任せるためで，詳細は[REF_sec-context-processing]で述べる．
係り受け言語モデル（[REF_sec-dependency-lm]節参照）を1種類から3種類に拡張した．
選択器のモデルは，最大エントロピー分類に基づく．
具体的には，選択器は記事内の述語[MATH]ごとに，候補名詞句集合[MATH]から，以下の式を満たす名詞句[MATH]を選択する．
\hat{n} & = \mathopargmax_{n_j \inN} P(d(n_j)=1 | X_j; M_c)
P(d(n_j)=1|X_j;M_c) & = \frac{1}{Z_{c}(X)} \exp\sum_{k} _{ck} f_k(d(n_j)=1,X_j)
Z_{c}(X) & = \sum_{n_j \inN} \exp\sum_k _{ck} f_k(d(n_j)=1,X_j)
X_j & = \langle n_j, v, A \rangle
ただし，[MATH]は1つの候補名詞句，[MATH]は候補名詞句集合，[MATH]は，名詞句[MATH]が項となったときのみ1となる関数，[MATH]は格[MATH]（ガ，ヲ，ニのいずれか）のモデルである．
また，[MATH]は素性関数，[MATH]は格毎の素性関数の重み，[MATH],[MATH]はそれぞれ述語，および形態素・構文解析済みの記事全体である．
訓練時には，ある述語の候補名詞句集合ごとに，正解の名詞句と，それ以外のすべての候補名詞句との事後確率差を大きくするように学習する．
具体的には，以下の損失関数を最小化するモデル[MATH]を，格ごとに学習する．
\ell_{c} & = - \sum_{i} \log P(d(n_i)=1|X_i;M_c) + \frac{1}{2C} \sum_{k} ||\lambda_{ck}||^{2}
ただし，[MATH]は，訓練セットの[MATH]番目の述語に対する正解名詞句，[MATH]は，訓練セットの[MATH]番目の正解名詞句，述語，記事の組[MATH]，[MATH]は過学習を制御するためのハイパーパラメータで，開発セットにおける精度が最高になるように，あらかじめ設定しておく．
式([REF_eqn-normalizer])で，述語の候補名詞句集合毎に正規化を行っているため，([REF_eqn-loss-function])式では，候補名詞句集合から，正解名詞句が選ばれた時に確率1.0，それ以外の名詞句では確率0.0に近づくようにモデルが学習される．
選択器で使用する素性に関しては，英語の意味役割付与に関する研究（たとえば[CITE]）と同様に，(1)述語に関する素性，(2)名詞句に関する素性，(3)両者の関係に関する素性を使用する．
詳細を表[REF_tbl-feature-list]に示す．
二値の素性関数は，テンプレートの引数が完全一致したときのみ1，それ以外では0を返す関数である．
たとえばPred素性において，主辞形態素の見出しが1万種類あったとすると，1万の二値関数が定義され，主辞形態素の見出しと一致した関数だけが1を返す．
実数値の素性関数は，テンプレートの引数に応じた実数を返す．
なお，これらは名詞句の選択用モデルの素性であるので，名詞句Nounと，すべての二値素性を組み合わせた素性も使用している．
本稿で特徴的な素性は，大規模データから自動構築した必須格情報Frameと係り受け言語モデル（3種類）であるが，これらについては[REF_sec-large-resources]節で述べる．
本稿では，人とコンピュータの対話システム実現のための解析器を想定している．
この対話システムは，ユーザとシステムが交互に発話するもので，システムに組み込まれた対話管理部が両者の発話履歴や，現在話されている話題（焦点）を管理する．
述語項構造解析部はユーザ発話を解析し，発話生成部がシステム発話を生成するというものである．
従来の述語項構造解析器も，現在の解析対象文より以前の文を文脈として利用し，ゼロ代名詞照応解析に利用している．
[CITE]は，解析器内部で以前の文や話題（焦点）の管理（これを文脈管理と呼ぶ）を行っていた．
しかし，述語項構造解析器内部で文脈管理を行うより，対話システムの対話管理部が文脈管理を行った方が，ユーザ発話とシステム発話を協調的に管理できる可能性が高い．
本稿ではこのように考え，文脈管理は外部モジュールの担当と位置付ける．
そして評価用に，新聞記事と対話で同じ文脈管理方法を使用する．
なお，本稿の方式は，選択器に与える文間の候補名詞句を取捨選択することによって文脈の制御を行っているので，候補名詞句を外部モジュールから陽に与えることで，文脈管理方法を変更することができる．
今回使用した文脈管理方法は，具体的には以下のとおりである．
対象述語の発話より以前の発話をさかのぼり，他の述語を含む発話（これを有効発話と呼ぶ）を見つける．
これは，述語を含まない発話を無視するためである．
有効発話と対象述語の発話の間に出現した全名詞句と，有効発話の述語で項として使われた名詞句（有効発話内の場合もあれば，それ以前の発話の名詞句の場合もある）を候補として加える．
項として使われた名詞句は，その後も繰り返し使われることが多く，これに制限することで，効率的に候補を削減することができるという観察結果に基づく[CITE]．
また，項として使われている限り，さかのぼる文数に制限がないため，広い文脈を見ることができる．
前節で述べた方法は，対話，新聞記事に共通の処理である．
これを対話解析に適したものにするため，パラメータの適応，および大規模コーパスから自動獲得した知識の適用を行う．
NAISTコーパスと対話コーパスの項分布の差異は，選択器のモデルパラメータをドメイン適応することで調整する．
本稿では，モデルパラメータの適応手法として，素性空間拡張法[CITE]を用いる．
これは，素性空間を3倍に拡張することで，ソースドメインデータをターゲットドメインの事前分布とみなすのと同じ効果を得る方法である．
具体的には，以下の手順で選択器のモデルを学習・適用する．
まず，素性空間を共通，ソース，ターゲットの3つに分割する．
NAISTコーパスをソースドメインデータ，対話コーパスをターゲットドメインデータとみなし，NAISTコーパスから得られた素性を共通とソース空間にコピーして配置する．
対話コーパスから得られた素性は共通とターゲット空間にコピーして配置する．
拡張された素性空間上で，通常通りパラメータ推定を行う．
結果，ソース・ターゲットデータ間で無矛盾な素性は，共通空間のパラメータが強調され（絶対値が大きくなる），ドメインに依存する素性は，ソースまたはターゲット空間のパラメータが強調される．
選択器が項を選択する際は，ターゲット空間と共通空間の素性だけ用いる．
この空間のパラメータは，ターゲットドメインに最適化されているだけでなく，ソースドメインデータだけに現れた共通空間の素性も利用して，項選択ができる．
本稿では，訓練コーパスに含まれない未知語への対策として，大規模コーパスから自動獲得した2種類の知識を利用する．
どちらも大規模平文コーパスを自動解析して，集計やフィルタリングをすることで獲得する[CITE]．
当然誤りも含むが，新出語に対しても，ある程度の確かさで情報を与えることができる．
これらを選択器の素性として使い，モデルを学習することにより，情報の信頼度に応じたパラメータが学習される．
格フレームは，述語の必須格と，その格を埋める名詞句の種類（通常は意味クラス）を保持するフレーム形式の情報で，述語項構造解析や意味役割付与の重要な手がかりとなる．
本稿で使う必須格情報は，格フレームのうち，格が必要か否か（必須格か任意格か）だけについて情報を与える辞書である．
本稿の必須格情報は，大規模平文テキストコーパスから，以下の方法で自動構築する．
これは，(1)項が述語と直接係り受け関係にある場合，述語に対する項の格は，項の名詞句に付随する格助詞と一致することが多い，(2)必須格なら，その格の出現率は他の述語より平均的に高い，という仮定をもとにしている．
まず，本稿の述語項構造解析と同様（[REF_sec-architecture]節参照）に，平文を形態素・構文解析し，品詞パターンで述語文節とその主辞を特定する．
述語文節に直接係る文節を取得し，機能語部に格助詞を持つ文節だけを残す．
もし，そのような文節が1つ以上あるなら，その述語を集計対象として，述語頻度，格助詞の出現頻度を集計する．
述語に関しては，高頻度述語から順番に，最終的な辞書サイズを考慮して選択する．
個々の格に関しては，以下の条件をすべて満たす格を，必須格とみなす．
[MATH]が，対数尤度比検定において，危険率0.1%以下で有意に多く共起していること（[MATH]; [MATH]）．
各述語における格[MATH]の出現率が，全述語における格の出現率（平均）より10%以上高いこと．
以上の方法で，2種類の必須格情報辞書を作成した．
一つは，ブログ約1年分（約23億文．
以下Blogコーパスと呼ぶ）から，48万述語の情報を獲得した（これをBlog辞書と呼ぶ）．
もう一つは新聞記事12年分（約770万文．
以下Newsコーパスと呼ぶ）から約20万述語の情報を獲得した（同News辞書）．
表[REF_tbl-oci-dict]は，雑談対話コーパス訓練セットの正解述語項構造と必須格情報辞書を比較し，必須格情報辞書の述語カバー率と格毎の精度を算出したものである．
述語カバー率は，対話コーパスに出現した述語が必須格情報辞書に含まれている場合，カバーしたと判断した．
結果，Blog辞書で98.5%，News辞書で96.4%で，ほぼ等しかった．
また，格毎の精度は，正解の述語項構造に格が付与されているか否かと，必須格情報上の必須格性が一致しているかどうかを測定したもので，Blog辞書，News辞書でほぼ同じ傾向を示している．
格毎に見ると，ガ格の精度が低いが，これは，雑談対話コーパスでは，ほぼすべての述語に対してガ格が付与されている（つまり，ガ格が必須）にも関わらず，BlogコーパスやNewsコーパスではそれがゼロ代名詞化されているため，自動獲得では必須格とは判断できなかったためである．
ヲ格の全体精度は91%以上と，格によっては高い精度を持つ辞書となっている．
係り受け言語モデル(language model; LM)は，三つ組[MATH]の共起のしやすさを表現するモデルである．
頻出表現に高いスコアを与えることによって，出現する単語間に意味的関連が存在することを表現する意図がある．
ここでは，述語[MATH],格[MATH],名詞句[MATH]それぞれの生成確率をn-gramモデルで算出し，選択器の識別モデルで全体最適化を行う．
具体的には，以下の実数値を算出し，表[REF_tbl-feature-list]の係り受け言語モデル素性の素性関数値として使用する．
その結果，選択器は，候補名詞句集合から，頻出表現に含まれる名詞句[MATH]を優先して選択することになる．
なお，未知語を表す特殊単語<unk>を含む確率で補正してる理由は，対数確率（{[MATH]〜[MATH]}の範囲）を正の値に補正するためである．
[MATH]
[MATH]
[MATH]
本稿の係り受け言語モデルは，[CITE]が1種類（{[MATH]}相当）のみ使用していたのに対し，識別モデルが互いに依存しあう素性を含めることができるという特徴を利用し，3種類に拡張している．
また，述語[MATH]から見た格[MATH]の生成確率({[MATH]})は，述語ごとに格を必要とする度合であり，必須格情報と重なるため，係り受け言語モデルからは除外した．
3種類の係り受け言語モデルは，[REF_sec-case-lex]節で抽出した述語，格，名詞句を集計し，SRILM [CITE]でバックオフモデルを構築した．
係り受け言語モデルも，Blogコーパス，Newsコーパスからそれぞれ作成した．
これを，それぞれBlog言語モデル，News言語モデルと呼ぶ．
言語モデルのカバー率を，雑談対話コーパス訓練セットに出現する三つ組が係り受け言語モデルの元になった三つ組に含まれるかどうかで測定すると，Blog言語モデルの場合，76.4%をカバーしていた．
一方，Newsの言語モデルの場合，カバー率は38.3%だった．
News言語モデルに比べ，Blog言語モデルは対話コーパスに出現する係り受けの三つ組のカバレッジが高い．
