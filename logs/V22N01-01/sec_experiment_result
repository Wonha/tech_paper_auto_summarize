本節では，表[REF_tbl-corpus-size]に示したコーパスを用い，対話における述語項構造解析の精度を，パラメータ適応，大規模コーパスから自動獲得した知識の効果という観点から評価する．
評価はすべて雑談対話コーパステストセットで行う．
評価指標には，項の適合率，再現率から算出したF値を用いる．
まず，パラメータ適応の効果を測定するため，訓練方法を変えた3方式の比較を行った．
表[REF_tbl-result-dialog]の(a)，(b)，(c)カラムがその結果で，それぞれ(a)素性空間拡張によるドメイン適応を行った場合（適応．
提案法），(b) NAISTコーパスだけで訓練した場合（NAIST訓練．
従来の新聞記事用解析に相当），(c)対話コーパスだけで訓練した場合（対話訓練）を表す．
まず，(a)適応と(b) NAIST訓練を比較すると，多くの場合，適応の方が有意に精度がよいという結果になった（[MATH]記号が有意差ありを表す）．
特に合計の精度では，すべての格で適応が有意に勝っている．
タイプ別の精度を見ると，特徴的なのは，ガ格の一人称，二人称外界照応(exo1, exo2)である．
これらはガ格の項のうちの約28%を占めているが，exo1で70.2%，exo2で46.8%のF値で解析可能となった．
他にも，ヲ格ニ格の文間ゼロ，exogなど，NAIST訓練ではほとんど解析できなかったタイプの項が解析できるようになった．
(a)適応と(c)対話訓練を比較すると（[MATH]参照），雑談対話コーパスは訓練セットのサイズが小さいにも関わらず，両者の精度が近くなった．
適応の合計精度が有意に良かったのは，ニ格のみである．
これには2つの理由が考えられる．
対話コーパス量が十分であり，NAISTコーパスの影響をほとんど受けない場合．
適応がNAISTコーパスの知識を活かしきっていない場合．
言い換えると，NAISTコーパスに出現する言語現象と，対話に出現する言語現象に重なりが少ないため，NAISTコーパスが影響しない場合．
前者の場合，コーパスサイズに対する学習曲線が今回のデータ量で飽和していることで検証できる．
本稿で作成した対話コーパスはNAISTコーパスの約1/10の訓練セットであるため，学習曲線は描かなかった．
後者の場合，対話コーパスサイズを大きくすると，述語項構造解析の精度も向上する．
今後，さらに対話コーパスを作成し，検証する必要がある．
表[REF_tbl-result-dialog]の(a) (d) (e)は，提案方法（適応）の評価結果である．
ただし，必須格情報および係り受け言語モデルは，それぞれ(a) [MATH]Blog, Blog[MATH]，(d) [MATH]News, Blog[MATH]，(e) [MATH]Blog, News[MATH]に変えて評価している．
まず，必須格情報辞書を(a) Blogから(d) Newsに変えた場合を比較すると（[MATH]参照），両者の間で有意差があったのは，ヲ格の文内ゼロのみで，ほぼすべての場合で有意差はなかった．
一方，係り受け言語モデルを(a) Blogから(e) Newsに変更すると（[MATH]参照），若干精度に差が出た．
特に，文法関係より意味関係を重視する文内・文間ゼロでは，有意に精度が悪化したものが多く（ガ格の文間ゼロ，ヲ格の文内・文間ゼロ，ニ格の文内ゼロ），その結果，合計の精度でも，ヲ格は約3ポイント低下した．
ゼロ代名詞照応のように，述語と項の間に文法的な関係が弱い場合，意味的関連性を共起から判断する係り受け言語モデルが相対的に重要となる．
そのため，係り受け言語モデルの違いが精度に影響しやすい．
図[REF_fig-coverages]は，適応方式において，それぞれ必須格情報辞書の述語カバー率，係り受け言語モデルの三つ組[MATH]のカバー率を意図的に変化させて，述語項構造解析のF値を測定したグラフである．
必須格情報，係り受け言語モデルともに，Blogコーパスから作成したものを利用した．
必須格情報のカバー率は高頻度述語から順番に，雑談対話コーパス訓練セットの述語のカバー率が指定した割合になるまで選択した．
係り受け言語モデルの三つ組は，同じく雑談対話コーパス訓練セット上での三つ組カバー率が指定した割合になるまで，ランダムに選択した．
グラフに示したF値は，格の合計である．
図[REF_fig-coverages](a)をみると，必須格情報については，格の種類にかかわらず，述語カバー率を変えてもほぼ同じ精度となった．
この理由を分析したところ，テストセットに出現する大部分の述語は，訓練セットに出現したためであった．
実際，雑談対話テストセットに出現する5,333述語のうち，4,442述語（83.3%）は雑談対話コーパス訓練セット，またはNAISTコーパス訓練セットに出現していた．
つまり，訓練セットだけでテストセットの大部分をカバーできており，それ以外の述語しか，必須格情報が有効に作用しなかったため，カバー率の影響がほとんど出なかったと考えられる．
一方，係り受け言語モデルの三つ組は，雑談対話テストセットに出現した5,056組（外界照応exo1, exo2, exogは除く）のうち，訓練セットがカバーしたのは1,063組（21.0%）であった．
そのため，図[REF_fig-coverages](b)のように，係り受け言語モデルのカバー率を上げると，述語項構造解析の精度も向上した．
ただし，ガ格に関しては，自動獲得元コーパスにおいてもガ格がゼロ代名詞化され，自動獲得精度が十分ではなかったため，カバー率を上げても述語項構造解析精度は向上しなかった．
まとめると，自動獲得した知識は，訓練コーパスのカバレッジが高い部分では効果がほとんどなく，低い部分を補完するのに有効である．
そのため，雑談対話のように幅広い話題を対象とする対話には適している．
ドメイン適応のシチュエーションとして，新聞記事コーパスしか存在しない状況で，述語項構造解析器を対話に適応させなければならない場合が考えられる．
本節では，NAISTテキストコーパスと自動獲得知識だけでモデルを学習し，自動獲得知識がどの程度有効か，検証する．
表[REF_tbl-effect-of-knowledge]は，NAISTコーパス訓練セットでモデルを学習し，雑談対話コーパステストセットでF値を測定した結果である．
ただし，自動獲得知識の組み合わせ{[MATH]}は，(b){[MATH]}，(b-1){[MATH]}，(b-2){[MATH]}，(b-3){[MATH]}に変えている．
(b)は，表[REF_tbl-result-dialog]の再掲である．
これを見ると，多くの場合で(b){[MATH]}が有意に勝っており，自動獲得知識が有効に作用していると言ってよい．
しかし，これらはすべてNAIST訓練の結果であり，ほとんど（またはまったく）解析できなかったタイプの項（たとえば，ガ格のexo1, exo2，ヲ格の文間ゼロ，ニ格の文内・文間ゼロ）は，必須格情報辞書，係り受け言語モデルをどのように変えようとも，ほとんど解析できない状況には変わりはなかった．
本稿の提案方式である表[REF_tbl-result-dialog]の(a)適応は，NAIST訓練では解析できなかったタイプの項も解析できるようにする効果があった．
自動獲得した知識は，すでに解析できるタイプの項の精度改善には効果があるが，対話で新たに出現したタイプの項を解析する効果はない．
したがって，たとえ少量でも対話の述語項構造データを作成し，適応させることが望ましい．
図[REF_fig-analysis-example]は，旅行に関する雑談対話の一部について，正解述語項構造，(a)適応方式，(b) NAIST訓練方式，(b-3) NAIST訓練（ただし，必須格情報辞書，係り受け言語モデルなし）の出力を並べて表示したものである．
発話ごとに差異を分析すると，以下の特徴が得られた．
発話番号1で，正解がexogになっているのは，アノテータは，「話した」のは発話者ABの両方であると判断したためである．
本発話の解釈によっては，exo1でも誤りではないと思われる．
発話番号2のガ格の正解はexo2である．
しかし，(a)適応は，exo1を選択した．
日本語の場合，一人称・二人称は，文末表現（この例では「下さい」）に特徴が現れるが，選択器にSuffix素性があるにも関わらず，正しく選択できなかった．
発話番号3のガ格の正解はexo1である．
(a)適応は正しく選択したが，(b)(b-3) NAIST訓練は，一人称／二人称の外界照応をほとんど選択しないため，発話番号1に現れた「私」を選択した．
しかし，発話番号1の「私」は発話者Aを示しており，発話番号3のexo1（発話者B）とは異なる．
もし文間ゼロタイプの項を割り当てるとすると，発話番号2の「あなた」が正解となる．
本稿では，外界照応と人称代名詞を別に扱っているが，本来は共参照解析を導入して，exo1/exo2と「私」「あなた」が同一実体であることを認識すべきである．
その際，発話者がどちらなのか意識して，同一性を判断する必要がある．
発話番号6にも同様な現象が現れているが，ガ格正解exo2に相当する表現が発話番号2「あなた」まで遡らなければならないため，(b)(b-3) NAIST訓練では，exogとなった．
発話番号3のニ格の正解は「海外旅行」だが，(b-3) NAIST訓練（自動獲得知識なし）では，NULLと誤った．
「海外旅行にはまる」は，NAISTコーパス訓練セットには出現せず，係り受け言語モデルの三つ組に出現する表現だったため，係り受け言語モデルなしのNAIST訓練では解析に失敗した．
発話番号5のニ格の正解は，「スペインとポルトガル」であるべきだが，本稿の方式は文節を単位に処理するため，2文節以上にまたがる名詞句は，主辞だけを付与する仕様である．
また，発話番号4のガ格の正解は，直前発話（発話番号3）全体と考えることもできる．
しかし，文節単位に格要素を割り当てるため，アノテータはもっとも近い表現「海外旅行」を正解として割り当てた．
発話番号6において，(a)適応は，ニ格「ポルトガル」を前文から正しく補完した．
なお，「ポルトガルに行く」は，NAISTコーパス訓練セットには存在しないが，係り受け言語モデルの三つ組には存在する表現である．
本節では，表[REF_tbl-corpus-size]に示したコーパスを用い，対話における述語項構造解析の精度を，パラメータ適応，大規模コーパスから自動獲得した知識の効果という観点から評価する．
評価はすべて雑談対話コーパステストセットで行う．
評価指標には，項の適合率，再現率から算出したF値を用いる．
まず，パラメータ適応の効果を測定するため，訓練方法を変えた3方式の比較を行った．
表[REF_tbl-result-dialog]の(a)，(b)，(c)カラムがその結果で，それぞれ(a)素性空間拡張によるドメイン適応を行った場合（適応．
提案法），(b) NAISTコーパスだけで訓練した場合（NAIST訓練．
従来の新聞記事用解析に相当），(c)対話コーパスだけで訓練した場合（対話訓練）を表す．
まず，(a)適応と(b) NAIST訓練を比較すると，多くの場合，適応の方が有意に精度がよいという結果になった（[MATH]記号が有意差ありを表す）．
特に合計の精度では，すべての格で適応が有意に勝っている．
タイプ別の精度を見ると，特徴的なのは，ガ格の一人称，二人称外界照応(exo1, exo2)である．
これらはガ格の項のうちの約28%を占めているが，exo1で70.2%，exo2で46.8%のF値で解析可能となった．
他にも，ヲ格ニ格の文間ゼロ，exogなど，NAIST訓練ではほとんど解析できなかったタイプの項が解析できるようになった．
(a)適応と(c)対話訓練を比較すると（[MATH]参照），雑談対話コーパスは訓練セットのサイズが小さいにも関わらず，両者の精度が近くなった．
適応の合計精度が有意に良かったのは，ニ格のみである．
これには2つの理由が考えられる．
対話コーパス量が十分であり，NAISTコーパスの影響をほとんど受けない場合．
適応がNAISTコーパスの知識を活かしきっていない場合．
言い換えると，NAISTコーパスに出現する言語現象と，対話に出現する言語現象に重なりが少ないため，NAISTコーパスが影響しない場合．
前者の場合，コーパスサイズに対する学習曲線が今回のデータ量で飽和していることで検証できる．
本稿で作成した対話コーパスはNAISTコーパスの約1/10の訓練セットであるため，学習曲線は描かなかった．
後者の場合，対話コーパスサイズを大きくすると，述語項構造解析の精度も向上する．
今後，さらに対話コーパスを作成し，検証する必要がある．
表[REF_tbl-result-dialog]の(a) (d) (e)は，提案方法（適応）の評価結果である．
ただし，必須格情報および係り受け言語モデルは，それぞれ(a) [MATH]Blog, Blog[MATH]，(d) [MATH]News, Blog[MATH]，(e) [MATH]Blog, News[MATH]に変えて評価している．
まず，必須格情報辞書を(a) Blogから(d) Newsに変えた場合を比較すると（[MATH]参照），両者の間で有意差があったのは，ヲ格の文内ゼロのみで，ほぼすべての場合で有意差はなかった．
一方，係り受け言語モデルを(a) Blogから(e) Newsに変更すると（[MATH]参照），若干精度に差が出た．
特に，文法関係より意味関係を重視する文内・文間ゼロでは，有意に精度が悪化したものが多く（ガ格の文間ゼロ，ヲ格の文内・文間ゼロ，ニ格の文内ゼロ），その結果，合計の精度でも，ヲ格は約3ポイント低下した．
ゼロ代名詞照応のように，述語と項の間に文法的な関係が弱い場合，意味的関連性を共起から判断する係り受け言語モデルが相対的に重要となる．
そのため，係り受け言語モデルの違いが精度に影響しやすい．
図[REF_fig-coverages]は，適応方式において，それぞれ必須格情報辞書の述語カバー率，係り受け言語モデルの三つ組[MATH]のカバー率を意図的に変化させて，述語項構造解析のF値を測定したグラフである．
必須格情報，係り受け言語モデルともに，Blogコーパスから作成したものを利用した．
必須格情報のカバー率は高頻度述語から順番に，雑談対話コーパス訓練セットの述語のカバー率が指定した割合になるまで選択した．
係り受け言語モデルの三つ組は，同じく雑談対話コーパス訓練セット上での三つ組カバー率が指定した割合になるまで，ランダムに選択した．
グラフに示したF値は，格の合計である．
図[REF_fig-coverages](a)をみると，必須格情報については，格の種類にかかわらず，述語カバー率を変えてもほぼ同じ精度となった．
この理由を分析したところ，テストセットに出現する大部分の述語は，訓練セットに出現したためであった．
実際，雑談対話テストセットに出現する5,333述語のうち，4,442述語（83.3%）は雑談対話コーパス訓練セット，またはNAISTコーパス訓練セットに出現していた．
つまり，訓練セットだけでテストセットの大部分をカバーできており，それ以外の述語しか，必須格情報が有効に作用しなかったため，カバー率の影響がほとんど出なかったと考えられる．
一方，係り受け言語モデルの三つ組は，雑談対話テストセットに出現した5,056組（外界照応exo1, exo2, exogは除く）のうち，訓練セットがカバーしたのは1,063組（21.0%）であった．
そのため，図[REF_fig-coverages](b)のように，係り受け言語モデルのカバー率を上げると，述語項構造解析の精度も向上した．
ただし，ガ格に関しては，自動獲得元コーパスにおいてもガ格がゼロ代名詞化され，自動獲得精度が十分ではなかったため，カバー率を上げても述語項構造解析精度は向上しなかった．
まとめると，自動獲得した知識は，訓練コーパスのカバレッジが高い部分では効果がほとんどなく，低い部分を補完するのに有効である．
そのため，雑談対話のように幅広い話題を対象とする対話には適している．
ドメイン適応のシチュエーションとして，新聞記事コーパスしか存在しない状況で，述語項構造解析器を対話に適応させなければならない場合が考えられる．
本節では，NAISTテキストコーパスと自動獲得知識だけでモデルを学習し，自動獲得知識がどの程度有効か，検証する．
表[REF_tbl-effect-of-knowledge]は，NAISTコーパス訓練セットでモデルを学習し，雑談対話コーパステストセットでF値を測定した結果である．
ただし，自動獲得知識の組み合わせ{[MATH]}は，(b){[MATH]}，(b-1){[MATH]}，(b-2){[MATH]}，(b-3){[MATH]}に変えている．
(b)は，表[REF_tbl-result-dialog]の再掲である．
これを見ると，多くの場合で(b){[MATH]}が有意に勝っており，自動獲得知識が有効に作用していると言ってよい．
しかし，これらはすべてNAIST訓練の結果であり，ほとんど（またはまったく）解析できなかったタイプの項（たとえば，ガ格のexo1, exo2，ヲ格の文間ゼロ，ニ格の文内・文間ゼロ）は，必須格情報辞書，係り受け言語モデルをどのように変えようとも，ほとんど解析できない状況には変わりはなかった．
本稿の提案方式である表[REF_tbl-result-dialog]の(a)適応は，NAIST訓練では解析できなかったタイプの項も解析できるようにする効果があった．
自動獲得した知識は，すでに解析できるタイプの項の精度改善には効果があるが，対話で新たに出現したタイプの項を解析する効果はない．
したがって，たとえ少量でも対話の述語項構造データを作成し，適応させることが望ましい．
図[REF_fig-analysis-example]は，旅行に関する雑談対話の一部について，正解述語項構造，(a)適応方式，(b) NAIST訓練方式，(b-3) NAIST訓練（ただし，必須格情報辞書，係り受け言語モデルなし）の出力を並べて表示したものである．
発話ごとに差異を分析すると，以下の特徴が得られた．
発話番号1で，正解がexogになっているのは，アノテータは，「話した」のは発話者ABの両方であると判断したためである．
本発話の解釈によっては，exo1でも誤りではないと思われる．
発話番号2のガ格の正解はexo2である．
しかし，(a)適応は，exo1を選択した．
日本語の場合，一人称・二人称は，文末表現（この例では「下さい」）に特徴が現れるが，選択器にSuffix素性があるにも関わらず，正しく選択できなかった．
発話番号3のガ格の正解はexo1である．
(a)適応は正しく選択したが，(b)(b-3) NAIST訓練は，一人称／二人称の外界照応をほとんど選択しないため，発話番号1に現れた「私」を選択した．
しかし，発話番号1の「私」は発話者Aを示しており，発話番号3のexo1（発話者B）とは異なる．
もし文間ゼロタイプの項を割り当てるとすると，発話番号2の「あなた」が正解となる．
本稿では，外界照応と人称代名詞を別に扱っているが，本来は共参照解析を導入して，exo1/exo2と「私」「あなた」が同一実体であることを認識すべきである．
その際，発話者がどちらなのか意識して，同一性を判断する必要がある．
発話番号6にも同様な現象が現れているが，ガ格正解exo2に相当する表現が発話番号2「あなた」まで遡らなければならないため，(b)(b-3) NAIST訓練では，exogとなった．
発話番号3のニ格の正解は「海外旅行」だが，(b-3) NAIST訓練（自動獲得知識なし）では，NULLと誤った．
「海外旅行にはまる」は，NAISTコーパス訓練セットには出現せず，係り受け言語モデルの三つ組に出現する表現だったため，係り受け言語モデルなしのNAIST訓練では解析に失敗した．
発話番号5のニ格の正解は，「スペインとポルトガル」であるべきだが，本稿の方式は文節を単位に処理するため，2文節以上にまたがる名詞句は，主辞だけを付与する仕様である．
また，発話番号4のガ格の正解は，直前発話（発話番号3）全体と考えることもできる．
しかし，文節単位に格要素を割り当てるため，アノテータはもっとも近い表現「海外旅行」を正解として割り当てた．
発話番号6において，(a)適応は，ニ格「ポルトガル」を前文から正しく補完した．
なお，「ポルトガルに行く」は，NAISTコーパス訓練セットには存在しないが，係り受け言語モデルの三つ組には存在する表現である．
