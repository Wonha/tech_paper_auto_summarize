
タスク依存の言語モデルを構築する場合，ターゲットとするタスクに関するデータのみを用いて学習する方がよいと考えられる[CITE]．
学習と評価用のコーパスとして毎日新聞の1991年[MATH]1994年の記事を用いた．
形態素解析にはRWCPが提供している毎日新聞形態素解析データを，電総研で作成された括弧除去ツールで加工し，使用している[CITE]．
学習には1991年1月から1994年11月までの記事を用い，評価には1994年12月の記事を用いた．
毎日新聞には全部で13面種に分類されているが，「社説」，「科学」，「読書」などの面種にはデータが少な過ぎるので，面種別の結果は省いた．
登録した形態素数は5000 , 20000の2通りで，bigram , trigramの学習と評価にCMU SLM toolkitを使用した．
表[REF_base]に用いたコーパスの諸量をまとめた(学習テキストが1994年1月〜11月の場合の結果は，文献[CITE]を参照されたい)．
これらのデータを用いて作成したbigramとtrigramの評価結果を表[REF_tbl:pp_bi_20k],[REF_tbl:pp_tri_20k]に示す．
紙数の関係で，5000形態素に関する結果は省略した．
これらの表では，実験結果をエントロピーではなくパープレキシティで表示している．
これは音声認識実験を行なうことを踏まえ，情報理論的にある単語から後続可能な単語の種類数を示すパープキシティという指標の方が直観的にわかりやすいためである．
またカバー率とは，unigramのヒット率のことである．
これらの結果より以下の事がわかる．
bigramとtrigramを比較すると，bigramより，trigramで言語モデルを構築した方が，トレーニングデータとテストデータのどちらのパープレキシティも小さくなる．
テストデータとトレーニングデータを比較すると，形態素数5000のbigramでは，テストデータとトレーニングデータとの間にパープレキシティの差はほとんど見られなかった．
しかし，それ以外の言語モデル(bigram形態素数20000, trigram形態素数5000, trigram形態素数20000)では，テストデータとトレーニングデータとの間にパープレキシティの差が大きい．
これは補正パープレキシティでも同様である．
特に形態素数20000のtrigramで差が大きい．
これは，9000万形態素では，トレーニングデータ量が不足していることを示している．
全面種で学習した場合と面種別で学習した場合の比較をすると，面種別に語彙を設定する方がカバー率は向上する．
また，テストデータのパープレキシティに関しては，形態素数20000のbigramでは全面種で学習するより面種別で学習する方がパープレキシティが小さくなる．
trigramでは面種別で学習するより全面種で学習する方がパープレキシティが小さくなる．
これは，面種別ではトレーニングデータが不足することによると考えられる．
なお，テストデータの補正パープレキシティに関しては，形態素数20000のtrigramでは面種別で学習するより全面種で学習する方が補正パープレキシティが小さくなる．
bigramでは全面種で学習するより面種別で学習する方が補正パープレキシティが小さくなる．
また，スポーツ面に関しては全面種で学習するより，面種別(すなわち，スポーツ面)で学習する方がパープレキシティが小さくなる傾向が見られる．
これは，スポーツ面は他の面種と異なった文が多いことによる．
表には示さなかったが，形態素数5000のbigramに関しては，全面種での学習では4年分の新聞記事で十分な学習が出来ている．
一方，面種別での学習ではトレーニングデータとテストデータのパープレキシティの間に差があるのでトレーニングデータの不足が見られる．
しかしトレーニングデータの不足が見られるものの，全面種で学習した言語モデルより面種別で学習した言語モデルの方がテストデータのパープレキシティが小さい．
つまり，全面種で学習した言語モデルより面種別で学習した言語モデルを使用する方がよいことになる．
形態素数5000のtrigramに関しては，面種別学習による効果はパープレキシティでは見られないが，補正パープレキシティでは効果が見られる．
形態素数20000のtrigramに関しては，トレーニングデータとテストデータの(補正)パープレキシティの比較によって，面種別での学習のみならず全面種での学習でもトレーニングデータ量の不足が起きていることが分かる．
全面種で学習した言語モデルと面種別で学習した言語モデルをテストデータの(補正)パープレキシティで比較すると，形態素数5000のbigramでの比較とは逆に，面種別で学習した言語モデルより全面種で学習した言語モデルの方が，(補正)パープレキシティが小さく，面種別で学習した言語モデルを使用するより，全面種で学習した言語モデルを使用する方がよいという結論が得られた．
以上から，形態素数5000のbigramを言語モデルに使用する場合は，面種別で学習した言語モデルを用いればよいことがわかった．
しかし，最近の大語彙音声認識に用いられる形態素数は20000以上で，また第2パスに言語モデルとしてtrigramを使用するのが主流となりつつある．
形態素数20000のtrigramだと，本研究で用いたトレーニングデータ量程度では，面種別で学習した言語モデルを使用するより，全面種で学習した言語モデルを使用する方がよい．
そこで，タスク(新聞では，面種)依存のより精度のよい言語モデルを構築するために全面種の記事で構築した言語モデルを，ターゲットとするタスク(面種)に適応化する手法をとる必要がある．
{  } {   }
新聞記事では数日間に渡って関連のある記事が載っていることがある．
そこで記事の評価時に，過去の数日間の記事で言語モデルを適応化しておけば，適応前より精度のよい言語モデルが出来ると考えられる．
ここで，N-gram言語モデルの適応化にはMAP推定(最大事後確率推定)[CITE]を用いる．
適応化サンプルを与えた後の推定値は次式で与えられ，推定前の条件確率と現在与えたサンプルとの間で，サンプル数で重み付けされた線形補間の形になっている．
\gt
今回の実験では標準言語モデルと適応化サンプルによる言語モデルの２つを構築しておき，バックオフを行なってスムージングした２つの条件確率を用いてMAP推定を行なっている．
この過程のブロック図を図[REF_fig:block]に示す．
標準言語モデルでは，新聞記事の全面種に対応する学習サンプルで出現頻度の高い形態素20000に限定した．
適応化サンプルでは語彙を限定せず，全ての形態素を語彙リストに登録した．
そのため，２つのモデルの語彙リストは独立している．
実験手順としては，{[MATH]}1形態素数20000の標準言語モデル(trigram)を構築し，{[MATH]}2標準言語モデルを事前モデルとして，面種別の適応化サンプルでターゲットタスクの言語モデルをMAP推定し，{[MATH]}3テストデータのパープレキシティを求める．
本実験では，[MATH]を種々変えてパープレキシティが最小となる場合を求めた．
実験結果を表[REF_tbl:MAP_pp_20k],[REF_tbl:MAP_app_20k]に示す．
最適な[MATH]の値は5日間の適応化データに対してはほとんどの面種で0.01，14日間の適応化データに対しては0.02[MATH]0.04であり，ほぼデータ量に比例した．
これらの表より
適応化前より適応化後の方がパープレキシティが小さくなること
5日より14日間の適応化サンプルの方がパープレキシティが小さくなること
6カ月前の数日間より直前の数日間の記事での適応化の方がパープレキシティが小さくなること
が分かる．
通常，直前の数百単語をキャッシュとして用いて適応化する方法が効果があると言われているが[CITE]，これよりも大量の直前データを用いる方が効果があるということである[CITE]．
特に，スポーツ面において，直前の記事による適応化の効果が大きい．
これは，他の面種記事よりも特定の話題が短期間継続するためと考えられる．
国際面とスポーツ面で適応化サンプルの期間を5,14日,1,2,3,6カ月にして求めたパープレキシティと補正パープレキシティを図[REF_fig:pp2]に示す．
これを見ると，適応化サンプルの量が多くなるほど，パープレキシティが小さくなること，日数が多くなるにつれてパープレキシティが飽和していくことが分かる．
また，直前の適応化データと6カ月前の適応化データを比べると，後者の場合の方がやや最適な[MATH]の値が大きくなった．
これは直前の適応化データの方が6カ月前の適応化データよりも有用であることを示している．
{ }
前述したように，新聞記事では数日間に渡って関連のある記事が載っていることが多い．
音声認識では特に固有名詞の扱いが重要となってくるので，固有名詞の登録法について検討した．
固有名詞はトピックに依存するものが多いので，数日間に渡って局所的に出現する傾向があると考えられる．
そこで数日間〜数週間中に出現した固有名詞を基本語彙に追加することにより，評価文の固有名詞をどの程度カバーすることが出来るかを調べた．
実験手順を以下に示す．
形態素数5000,20000の基本語彙を構築する．
基本語彙でテストデータのカバー率を求める．
基本語彙に数日間〜数週間の適応化サンプル中に出現した固有名詞を高出現頻度順に追加し，固有名詞のカバー率を求める．
実験は，追加登録する形態素を5000に限定した場合と出現したすべてを登録する場合を行なった．
実験結果を表[REF_tbl:Cover1],[REF_tbl:Cover2]に示す．
表中の括弧内の数値は出現した固有名詞をすべて登録した場合の数を示している．
この結果より次のことが言える．
６ヶ月前の記事より直前の記事に出現する固有名詞を追加する方がカバー率が高い．
これより，新しく出現した固有名詞の多くは直前の数日間に渡って出現していることが分かる．
追加する固有名詞の数を制限しない場合は，適応化サンプルが多いほどカバー率が高くなるのは当然だが，固有名詞の数を制限した場合でも，10日間より30日間の適応化サンプルを用いた方が，カバー率は少し高くなる．
テストデータ全体でのカバー率を見て分かるように，固有名詞を追加することによるカバー率の上昇は高々2%程度である．
このことは，基本語彙に登録されなかった単語(未知語)において，固有名詞の占める割合が低いことを示している(5000語彙に対しては約20%，20000語彙に対しては約25%)．
なお，固有名詞に限定せずに，出現頻度の多い形態素を登録した場合の結果を表[REF_tbl:Cover3]に示す．
表[REF_tbl:Cover3]より，登録する単語を固有名詞に限定しない方がカバー率は大きくなることかがわかる．
しかし，このような新しい登録単語のbigram,trigramの算出は困難なので固有名詞に限定した方が扱いやすいと思われる．
また表[REF_tbl:Cover3]より，カバー率を98%にするためには直前に出現した形態素を中心とした55000形態素程度が必要なことがわかる．
但し，面種別で学習すれば，20000〜30000形態素でも十分である(表2,3参照)．
新聞テキスト文には，定型表現が多いことに着目し，これらの高頻出定型表現を1形態素として捉えた上で，言語モデルを構築すれば，より精度の良いモデルが出来ると考られる．
今回の実験では，定型表現を抽出するアルゴリズムとして，池原らの提案した方法[CITE]を用いる．
エントロピー基準で連語を抽出する方法も考えられるが[CITE]，今回は簡略化のため出現頻度に着目した．
どのような基準で連語を抽出し，言語モデルを構築するかは興味ある課題であるが，手法による実質的な差は少ないと思われる[CITE]．
この方法では，最長一致の文字列抽出(ある文字列が抽出されたとき，その文字列に含まれる部分文字列は統計量を求める際にはこの部分文字列を定型表現とはカウントしない)を条件とし，任意の長さ以上，任意の使用頻度以上の表現を，もれなく自動的に抽出する．
文献[CITE]では文字列単位で抽出していたが，これを形態素単位で抽出するように変更した．
抽出例を表[REF_rei]に示す．
標準言語モデルは，表[REF_base]に示した全面種の学習用データから作成した表[REF_tbl:pp_bi_20k]のモデルを用いる．
まず，RWC[CITE]の毎日新聞形態素解析結果を用いて，出現頻度が上位20000番目までの形態素を語彙として辞書に登録した．
言語モデルの構築には，CMU SLM Toolkit Ver.1を用いた．
バックオフ・スムージングにはGood-Turing推定を用いた．
定型表現を用いた言語モデル構築のための手順を以下に示す．
RWCの毎日新聞形態素解析結果に対して，定型表現抽出プログラムを実行し，連結数2または3の定型表現を抽出する．
定型表現を用いる前のトレーニングデータから，各形態素の頻度リストを求める．
上位15000番目くらいの形態素の出現頻度が50回であるので，定型表現の出現頻度が50回以上のものを新しい形態素候補として用いることにする．
Step.2の定型表現を用い，トレーニングデータ内の定型表現を図 [REF_renketu]のように1つの単語にまとめる．
トレーニングデータから出現頻度の多い順に20000を求め，語彙サイズ20000の辞書を作成する．
このとき，上位20000の辞書に登録された定型表現は2連結で9430個，3連結で9357個(このうち2連語が7010，3連語が2347)である．
登録されなかった定型表現が多数あるので，これは未知語の数を増やすだけなので図[REF_bun]のようにもとの形態素に分解しておく．
分解後のトレーニングデータから，もう一度語彙サイズ20000の辞書を作成する．
これは，Step.3で定型表現を分解したことによって形態素の出現頻度が変わってしまうためである．
当然ここでも登録されない定型表現がでてくる．
登録された定型表現は2連結で8944個，3連結で9282個(このうち2連語が6967，3連語が2315)になった．
ここでも，登録されなかった定型表現はもとの形態素に分解する．
厳密に行なうなら，辞書作成と定型表現の分解といった作業を繰り返し行ない，辞書に登録される定型表現の数が収束するまで行わないといけないが，今回は1回だけしか行なっていない．
CMU SLM Toolkitを用いてトレーニングデータから，語彙サイズ20000の辞書を作成し，bigram,trigram言語モデルを構築する．
評価を行なう時，注意しなければならないことは，いずれの比較対象に対しても同じ定義の1形態素あたりのパープレキシティを求めないといけないということである．
通常パープレキシティを求める式はbigramの場合で，
であるが，これは1連結形態素(定型表現として形態素を連結したもの)あたりのパープレキシティを求めている．
形態素を連結する前の従来の1形態素あたりのパープレキシティを求めるには，
を用いなければならない．
ここで[MATH]:定型表現を1つの形態素としたときの連結形態素と従来の形態素の総数[MATH]:定型表現を使わなかったときの従来の形態素の総数また，定型表現は述語表現に多く現れるため，それらの形態素は比較的短いものが多い．
そのため形態素単位のパープレキシティでは全体に及ぼす影響が大きいと考えられる．
そこで同時に文字単位のパープレキシティも求めた．
標準言語モデルと，前節に述べた方法で定型表現を用いた言語モデルを構築し，その評価を行なった．
トレーニングデータには，標準言語モデル作成の場合と同じ，表[REF_base]の学習用データを用いている．
テストデータには，標準言語モデル，定型表現を用いた言語モデルともに表[REF_base]の評価用データを使用した．
実験結果を表[REF_kekka20k]と図[REF_hyouka]に示す．
まず，bigramモデルでは，トレーニングデータに関しては約半分，テストデータに関しては約3割，パープレキシティが減少しているのがわかる．
しかし，trigramモデルではトレーニングデータでは効果があったが，テストデータに対しては大きな効果が得られなかった．
これは，語彙サイズを一定にしたため，定型表現を登録したためにもとの語彙から省かれた単語が未知語となったのが原因であると考えられる．
実際，定型表現を用いた場合，定型表現を用いなかった場合と比べて，未知語の種類数が約8000個増加している．
次に，標準言語モデルを作成した時の語彙サイズ20000の辞書に，2および3連結の定型表現をそれぞれ高出現頻度順で上位2000個,5000個分を追加した場合の辞書で言語モデルを構築した．
その評価結果を表[REF_kekka22k],[REF_kekka25k]に示す．
ここで表[REF_kekka22k],[REF_kekka25k]の``定型表現の連結なし''は通常の形態素を22000個および25000個用いた時の結果である．
この言語モデルの作成方法の場合でも，パープレキシティの改善が見られた．
bigramでは定型表現を用いることにより，補正パープレキシティも大幅に減少している．
また，定型表現5000個追加のものの方が，定型表現2000個追加のものと比べて，語彙サイズが大きいのにも関わらず，パープレキシティが減少している．
これより，出来るだけ多くの定型表現を辞書に登録すれば良いということが言える．
以上より，trigramではトレーニングデータに対しては大きな効果があったが，テストデータに対しては効果がなかった．
これはトレーニングデータの不足によるものと考えられる．
一方，bigramでは大きな効果があった．
同じパラメータ数(bigram)でもパープレキシティが小さいモデルが構築できたことは，これを大語彙連続音声認識の第1パスに使用すると認識率の向上に繋がると考えられる．
{
}
