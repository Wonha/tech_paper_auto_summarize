================================================================
[section type  : abstract]
[section title : abstract]
================================================================
[2505] 最後に新聞テキストには，使用頻度の高い(特殊)表現や，固定的な言い回しなどの表現(以下，定型表現と呼ぶ)が多いことに注目し，複数形態素から成る定型表現を抽出し，これを1形態素として捉えた上で，N-gram言語モデルを構築する方法を検討し，有用性を示す．

================================================================
[section type  : intro]
[section title : はじめに]
================================================================
[2207] 評価実験の結果，長さ2および3以下である定型表現を1形態素化してbigram, trigram言語モデルを作成することで，bigramに関しては，エントロピーが小さくなり，言語モデルとして有効であることを示す．

================================================================
[section type  : experiment_result]
[section title : 言語モデルの評価基準]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : エントロピーとパープレキシティ]
-----------------------------------------------------
  [1736] エントロピーとパープレキシティは共に，対象とする文集合の複雑さを定量的に示す指標で，その文集合が複雑なほど，それぞれの値は大きくなる．
-----------------------------------------------------
  [subsection title : 補正パープレキシティ]
-----------------------------------------------------
  [1538] 勿論，これは評価テキストの大きさに依存する(テキストが大きくなると未知語の種類が増える)ので，簡易的な補正である．

================================================================
[section type  : proposed_method]
[section title : 言語モデルの適応化]
================================================================
[0] 
-----------------------------------------------------
  [subsection title : 面種別での学習と評価]
-----------------------------------------------------
  [2487] 全面種で学習した言語モデルと面種別で学習した言語モデルをテストデータの(補正)パープレキシティで比較すると，形態素数5000のbigramでの比較とは逆に，面種別で学習した言語モデルより全面種で学習した言語モデルの方が，(補正)パープレキシティが小さく，面種別で学習した言語モデルを使用するより，全面種で学習した言語モデルを使用する方がよいという結論が得られた．
-----------------------------------------------------
  [subsection title : 適応化法]
-----------------------------------------------------
  [1893] そこで記事の評価時に，過去の数日間の記事で言語モデルを適応化しておけば，適応前より精度のよい言語モデルが出来ると考えられる．
-----------------------------------------------------
  [subsection title : 実験結果]
-----------------------------------------------------
  [1866] 通常，直前の数百単語をキャッシュとして用いて適応化する方法が効果があると言われているが[CITE]，これよりも大量の直前データを用いる方が効果があるということである[CITE]．
-----------------------------------------------------
  [subsection title : 固有名詞の適応化]
-----------------------------------------------------
  [1738] 追加する固有名詞の数を制限しない場合は，適応化サンプルが多いほどカバー率が高くなるのは当然だが，固有名詞の数を制限した場合でも，10日間より30日間の適応化サンプルを用いた方が，カバー率は少し高くなる．

================================================================
[section type  : proposed_method]
[section title : 定型表現]
================================================================
[2243] 新聞テキスト文には，定型表現が多いことに着目し，これらの高頻出定型表現を1形態素として捉えた上で，言語モデルを構築すれば，より精度の良いモデルが出来ると考られる．
-----------------------------------------------------
  [subsection title : 標準言語モデル]
-----------------------------------------------------
  [1683] 標準言語モデルは，表[REF_base]に示した全面種の学習用データから作成した表[REF_tbl:pp_bi_20k]のモデルを用いる．
-----------------------------------------------------
  [subsection title : 定型表現を用いた言語モデル]
-----------------------------------------------------
  [1972] 登録されなかった定型表現が多数あるので，これは未知語の数を増やすだけなので図[REF_bun]のようにもとの形態素に分解しておく．
-----------------------------------------------------
  [subsection title : 評価実験]
-----------------------------------------------------
  [2155] 同じパラメータ数(bigram)でもパープレキシティが小さいモデルが構築できたことは，これを大語彙連続音声認識の第1パスに使用すると認識率の向上に繋がると考えられる．

================================================================
[section type  : conclusion]
[section title : まとめ]
================================================================
[2014] 定型表現を用いた言語モデルを作成することで，bigramモデルに関しては，テストデータに対し約3割程度パープレキシティを低く押えるとこができ，言語モデルの有効性を示すことができた．

